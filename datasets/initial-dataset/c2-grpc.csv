user_id,user_login,pull_request_url,comment_id,created_at,path,diff_hunk,content,code_smell
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/9194,96450460,2017-01-17T16:28:00Z,src/core/ext/client_channel/client_channel_factory.c,"@@ -85,3 +90,120 @@ grpc_arg grpc_client_channel_factory_create_channel_arg(   arg.value.pointer.vtable = &factory_arg_vtable;   return arg; }++struct grpc_channel_targets_info {","Ideally, yes. This implementation uses this naive approach for simplicity, as initially we have only 1-1 name-target mappings.On a side note, the mdstr_hash_table doesn't look generic enough, due to its usage of mdstr. It's mostly a naming issue, though. Let me finish merging and getting it to green and then based on priorities explore changing it. We may find a way to ""fix"" the mdstr_hash_table. ",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/9194,96456639,2017-01-17T16:53:41Z,src/core/ext/client_channel/client_channel_factory.c,"@@ -85,3 +90,120 @@ grpc_arg grpc_client_channel_factory_create_channel_arg(   arg.value.pointer.vtable = &factory_arg_vtable;   return arg; }++struct grpc_channel_targets_info {",Note that in #8842 I'm renaming mdstr_hash_table to slice_hash_table (because mdstr isn't a thing anymore).,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/9194,96476216,2017-01-17T18:25:00Z,src/core/ext/client_channel/client_channel_factory.c,"@@ -85,3 +90,120 @@ grpc_arg grpc_client_channel_factory_create_channel_arg(   arg.value.pointer.vtable = &factory_arg_vtable;   return arg; }++struct grpc_channel_targets_info {","@markdroth Are you ok with changing the code over to use slice_hash_table from #8842 once that's merged? If you feel strongly about it, I could use avl right away, but I feel that a hash table is better suited for this usecase for performance reasons (unsubstantiated claim though).",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/8842,96488511,2017-01-17T19:20:20Z,src/core/lib/slice/slice_hash_table.c,"@@ -29,78 +29,87 @@ // OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. // -#include ""src/core/lib/transport/mdstr_hash_table.h""+#include ""src/core/lib/slice/slice_hash_table.h""  #include <stdbool.h> #include <string.h>  #include <grpc/support/alloc.h> #include <grpc/support/log.h> +#include ""src/core/lib/slice/slice_internal.h"" #include ""src/core/lib/transport/metadata.h"" -struct grpc_mdstr_hash_table {+struct grpc_slice_hash_table {   gpr_refcount refs;   size_t size;-  grpc_mdstr_hash_table_entry* entries;+  grpc_slice_hash_table_entry* entries; }; +static bool is_empty(grpc_slice_hash_table_entry* entry) {+  return entry->vtable == NULL;+}+ // Helper function for insert and get operations that performs quadratic // probing (https://en.wikipedia.org/wiki/Quadratic_probing).-static size_t grpc_mdstr_hash_table_find_index(-    const grpc_mdstr_hash_table* table, const grpc_mdstr* key,-    bool find_empty) {+static size_t grpc_slice_hash_table_find_index(+    const grpc_slice_hash_table* table, const grpc_slice key, bool find_empty) {+  size_t hash = grpc_slice_hash(key);   for (size_t i = 0; i < table->size; ++i) {-    const size_t idx = (key->hash + i * i) % table->size;-    if (table->entries[idx].key == NULL) return find_empty ? idx : table->size;-    if (table->entries[idx].key == key) return idx;+    const size_t idx = (hash + i * i) % table->size;+    if (is_empty(&table->entries[idx])) {+      return find_empty ? idx : table->size;+    }+    if (grpc_slice_cmp(table->entries[idx].key, key) == 0) {",Is there going to be any performance impact from the fact that this is no longer a simple pointer comparison?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/8842,96491236,2017-01-17T19:31:54Z,src/core/lib/transport/method_config.h,"@@ -37,7 +37,7 @@ #include <grpc/impl/codegen/gpr_types.h>","The method_config.h and method_config.c files were removed in #8617, but it looks like they were accidentally re-added in #8705.  They're not used anywhere, so they can be removed.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/9194,96492390,2017-01-17T19:37:12Z,src/core/ext/client_channel/client_channel_factory.c,"@@ -85,3 +90,120 @@ grpc_arg grpc_client_channel_factory_create_channel_arg(   arg.value.pointer.vtable = &factory_arg_vtable;   return arg; }++struct grpc_channel_targets_info {","I'm skeptical about there being any significant performance issue here, since this code isn't on the fast path.  But regardless, yes, I'm fine with using slice_hash_table once #8842 is merged.My concern here is really about avoiding unnecessary wheel reinvention.  As long as we don't do that, I don't really care which of the existing wheels we use. :)",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/9194,96493103,2017-01-17T19:40:17Z,src/core/ext/client_channel/client_channel_factory.c,"@@ -85,3 +90,120 @@ grpc_arg grpc_client_channel_factory_create_channel_arg(   arg.value.pointer.vtable = &factory_arg_vtable;   return arg; }++struct grpc_channel_targets_info {","Agreed. Given that this PR is not high priority but #8842 is and will likely be merged very soon, I'll  start making the changes to use mdstr_hash_table and then s/mdstr/slice. This allows reviews to happen in the meantime and once #8842 is in, this one can shortly follow.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/9194,96524522,2017-01-17T22:18:16Z,src/core/ext/transport/chttp2/client/secure/secure_channel_create.c,"@@ -55,8 +56,79 @@ static void client_channel_factory_unref( static grpc_subchannel *client_channel_factory_create_subchannel(     grpc_exec_ctx *exec_ctx, grpc_client_channel_factory *cc_factory,     const grpc_subchannel_args *args) {+  grpc_subchannel_args final_sc_args;+  memcpy(&final_sc_args, args, sizeof(grpc_subchannel_args));+  const grpc_arg *target_info_arg =+      grpc_channel_args_find(args->args, GRPC_ARG_GRPCLB_BALANCER_NAMES);+  grpc_channel_args *new_channel_args = NULL;++  if (target_info_arg != NULL) {+    // For LB channels, regenerate the security connector. The credentials used+    // for the new security connection are stripped of call credentials and has+    // knowledge about the balancer names, which are to be used as the ""target""+    // for the purposes of secure naming.+    const grpc_channel_targets_info *targets_info =+        target_info_arg->value.pointer.p;++    // To which address are we connecting?+    char *target;+    GPR_ASSERT(+        grpc_sockaddr_to_string(&target, args->addr, true /* normalize */));++    // Find the balancer name for that target.+    const char *balancer_name_target =+        grpc_channel_targets_info_find(targets_info, target);+    gpr_free(target);++    if (balancer_name_target != NULL) {+      // Remove the call credentials from the parent channel's credentials.","Unfortunately, no. The name grpclb.c deals with is a comma separated sequence of IP:port. However, we need to know the concrete address to which we are connecting in order to look up the name be used for secure naming. We don't know which of the LB addresses ",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/9106,96534460,2017-01-17T23:15:51Z,doc/load-balancing.md,"@@ -41,104 +41,92 @@ It would also significantly complicate the client's code: the new design hides the load balancing complexity of multiple layers and presents it as a simple list of servers to the client. -### External Load Balancing Service+## External Load Balancing Service  The client load balancing code is kept simple and portable, implementing-well-known algorithms (ie, Round Robin) for server selection.-Complex load balancing algorithms are instead provided by the load balancer. The-client relies on the load balancer to provide _load balancing configuration_ and-_the list of servers_ to which the client should send requests. The balancer-updates the server list as needed to balance the load as well as handle server+well-known algorithms (e.g., Round Robin) for server selection.+Complex load balancing algorithms are instead provided by the load+balancer. The client relies on the load balancer to provide _load+balancing configuration_ and _the list of servers_ to which the client+should send requests. The balancer updates the server list as needed+to balance the load as well as handle server unavailability or health+issues. The load balancer will make any necessary complex decisions and+inform the client. The load balancer may communicate with the backend+servers to collect load and health information.++# Requirements++## Simple API and client++The gRPC client load balancing code must be simple and portable. The+client should only contain simple algorithms (e.g., Round Robin) for+server selection.  For complex algorithms, the client should rely on+a load balancer to provide load balancing configuration and the list of+servers to which the client should send requests. The balancer will update+the server list as needed to balance the load as well as handle server unavailability or health issues. The load balancer will make any necessary-complex decisions and inform the client. The load balancer may communicate with-the backend servers to collect load and health information.+complex decisions and inform the client. The load balancer may communicate+with the backend servers to collect load and health information. --## Requirements--#### Simple API and client--The gRPC client load balancing code must be simple and portable. The client-should only contain simple algorithms (ie Round Robin) for server selection. For-complex algorithms, the client should rely on a load balancer to provide load-balancing configuration and the list of servers to which the client should send-requests. The balancer will update the server list as needed to balance the load-as well as handle server unavailability or health issues. The load balancer will-make any necessary complex decisions and inform the client. The load balancer-may communicate with the backend servers to collect load and health information.--#### Security+## Security  The load balancer may be separate from the actual server backends and a compromise of the load balancer should only lead to a compromise of the loadbalancing functionality. In other words, a compromised load balancer should not be able to cause a client to trust a (potentially malicious) backend server any more than in a comparable situation without loadbalancing. -# Proposed Architecture--The gRPC load balancing implements the external load balancing server approach:-an external load balancer provides simple clients with an up-to-date list of-servers.--![image](images/load_balancing_design.png)--1. On startup, the gRPC client issues a name resolution request for the service.-   The name will resolve to one or more IP addresses to gRPC servers, a hint on-   whether the IP address(es) point to a load balancer or not, and also return a-   client config.-2. The gRPC client connects to a gRPC Server.-   1. If the name resolution has hinted that the endpoint is a load balancer,-      the client's gRPC LB policy will attempt to open a stream to the load-      balancer service. The server may respond in only one of the following-      ways.-      1. `status::UNIMPLEMENTED`. There is no loadbalancing in use. The client-         call will fail.-      2. ""I am a Load Balancer and here is the server list."" (Goto Step 4.)-      3. ""Please contact Load Balancer X"" (See Step 3.) The client will close-         this connection and cancel the stream.-      4. If the server fails to respond, the client will wait for some timeout-         and then re-resolve the name (process to Step 1 above).-   2. If the name resolution has not hinted that the endpoint is a load-      balancer, the client connects directly to the service it wants to talk to.-3. The gRPC client's gRPC LB policy opens a separate connection to the Load-   Balancer. If this fails, it will go back to step 1 and try another address.-   1. During channel initialization to the Load Balancer, the client will-      attempt to open a stream to the Load Balancer service.-   2. The Load Balancer will return a server list to the gRPC client. If the-      server list is empty, the call will wait until a non-empty one is-      received. Optional: The Load Balancer will also open channels to the gRPC-      servers if load reporting is needed.-4. The gRPC client will send RPCs to the gRPC servers contained in the server-   list from the Load Balancer.-5. Optional: The gRPC servers may periodically report load to the Load Balancer.--## Client--When establishing a gRPC _stream_ to the balancer, the client will send an initial-request to the load balancer (via a regular gRPC message). The load balancer-will respond with client config (including, for example, settings for flow-control, RPC deadlines, etc.) or a redirect to another load balancer. If the-balancer did not redirect the client, it will then send a list of servers to the-client. The client will contain simple load balancing logic for choosing the-next server when it needs to send a request.--## Load Balancer--The Load Balancer is responsible for providing the client with a list of servers-and client RPC parameters. The balancer chooses when to update the list of-servers and can decide whether to provide a complete list, a subset, or a-specific list of “picked” servers in a particular order. The balancer can-optionally provide an expiration interval after which the server list should no-longer be trusted and should be updated by the balancer.--The load balancer may open reporting streams to each server contained in the-server list. These streams are primarily used for load reporting. For example,-Weighted Round Robin requires that the servers report utilization to the load-balancer in order to compute the next list of servers.--## Server--The gRPC Server is responsible for answering RPC requests and providing-responses to the client. The server will also report load to the load balancer-if a reporting stream was opened for this purpose.+# Architecture++## Overview++The primary mechanism for load-balancing in gRPC is external+load-balancing, where an external load balancer provides simple clients+with an up-to-date list of servers.++The gRPC client does support an API for built-in load balancing policies.+However, there are only a small number of these (one of which is the+`grpclb` policy, which implements external load balancing), and users+are discouraged from trying to extend gRPC by adding more.  Instead, new+load balancing policies should be implemented in external load balancers.++## Workflow++Load-balancing policies fit into the gRPC client workflow in between+name resolution and the connection to the server.  Here's how it all+works:++![image](images/load-balancing.png)++1. On startup, the gRPC client issues a [name resolution](naming.md) request+   for the server name.  The name will resolve to one or more IP addresses,+   each of which will indicate whether it is a server address or+   a load balancer address, and a [service config](service_config.md)+   that indicates which client-side load-balancing policy to use (e.g.,+   `round_robin` or `grpclb`).+2. The client instantiates the load balancing policy, which is then+   responsible for deciding which requests will be sent to which+   addresses.+   - Note: If all addresses returned by the resolver are balancer+     addresses, then the client will use the `grpclb` policy, regardless+     of what load-balancing policy was requested by the service config.+     Otherwise, the client will use the load-balancing policy requested+     by the service config.  If no load-balancing policy is requested","For completeness, we may want to mention that grpclb addresses will be ignored if we end up using a different policy but some lb addresses are still in the list.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/9106,96535206,2017-01-17T23:20:53Z,doc/naming.md,"@@ -1,30 +1,59 @@-#gRPC Naming and Discovery Support+# gRPC Name Resolution  ## Overview -gRPC supports DNS as the default name-system. A number of alternative name-systems are used in various deployments. We propose an API that is general enough to support a range of name-systems and the corresponding syntax for names. The gRPC client library in various languages will provide a plugin mechanism so resolvers for different name-systems can be plugged in.+gRPC supports DNS as the default name-system. A number of alternative+name-systems are used in various deployments. We support an API that is+general enough to support a range of name-systems and the corresponding+syntax for names. The gRPC client library in various languages will+provide a plugin mechanism so resolvers for different name-systems can+be plugged in. -## Detailed Proposal+## Detailed Design - A fully qualified, self contained name used for gRPC channel construction uses the syntax:+### Name Syntax++A fully qualified, self contained name used for gRPC channel construction+uses the syntax:  ``` scheme://authority/endpoint_name ``` -Here, scheme indicates the name-system to be used. Example schemes to be supported include: +Here, `scheme` indicates the name-system to be used. Example schemes to+be supported include:  * `dns`  * `etcd` -Authority indicates some scheme-specific bootstrap information, e.g., for DNS, the authority may include the IP[:port] of the DNS server to use. Often, a DNS name may used as the authority, since the ability to resolve DNS names is already built into all gRPC client libraries.+The `authority` indicates some scheme-specific bootstrap information, e.g.,+for DNS, the authority may include the IP[:port] of the DNS server to+use. Often, a DNS name may be used as the authority, since the ability to+resolve DNS names is already built into all gRPC client libraries.++Finally, the `endpoint_name` indicates a concrete name to be looked up+in a given name-system identified by the scheme and the authority. The+syntax of the endpoint name is dictated by the scheme in use. -Finally, the  endpoint_name indicates a concrete name to be looked up in a given name-system identified by the scheme and the authority. The syntax of endpoint name is dictated by the scheme in use.+### Resolver Plugins -### Plugins+The gRPC client library will switch on the scheme to pick the right","s/switch on/decide based on? I took me a double take to disambiguate ""switch on"" in this context.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/9106,96536095,2017-01-17T23:26:27Z,doc/service_config.md,"@@ -0,0 +1,147 @@+Service Config in gRPC+======================++# Objective++The service config is a mechanism that allows service owners to publish+parameters to be automatically used by all clients of their service.++# Format++The service config is a JSON string of the following form:++```+{+  # Load balancing policy name.+  # Supported values are 'round_robin' and 'grpclb'.+  # Optional; if unset, the default behavior is pick the first available+  # backend.+  # Note that if the resolver returns only balancer addresses and no+  # backend addresses, gRPC will always use the 'grpclb' policy,+  # regardless of what this field is set to.+  'loadBalancingPolicy': string,++  # Per-method configuration.  Optional.+  'methodConfig': [+    {+      # The names of the methods to which this method config applies. There+      # must be at least one name. Each name entry must be unique across the+      # entire service config. If the 'method' field is empty, then this+      # method config specifies the defaults for all methods for the specified+      # service.+      #+      # For example, let's say that the service config contains the following+      # method config entries:+      #+      # 'methodConfig': [+      #   { 'name': [ { 'service': 'MyService' } ] ... },+      #   { 'name': [ { 'service': 'MyService', 'method': 'Foo' } ] ... }+      # ]+      #+      # For a request for MyService/Foo, we will use the second entry, because+      # it exactly matches the service and method name.+      # For a request for MyService/Bar, we will use the first entry, because+      # it provides the default for all methods of MyService.+      'name': [+        {+          # RPC service name.  Required.+          # If using gRPC with protobuf as the IDL, then this will be of+          # the form ""pkg.service_name"", where ""pkg"" is the package name+          # defined in the proto file.+          'service': string,++          # RPC method name.  Optional (see above).+          'method': string,+        }+      ],++      # Whether RPCs sent to this method should wait until the connection is+      # ready by default. If false, the RPC will abort immediately if there+      # is a transient failure connecting to the server. Otherwise, gRPC will+      # attempt to connect until the deadline is exceeded.+      #+      # The value specified via the gRPC client API will override the value+      # set here. However, note that setting the value in the client API will+      # also affect transient errors encountered during name resolution,+      # which cannot be caught by the value here, since the service config+      # is obtained by the gRPC client via name resolution.+      'waitForReady': bool,++      # The default timeout in seconds for RPCs sent to this method. This can+      # be overridden in code. If no reply is received in the specified amount+      # of time, the request is aborted and a deadline-exceeded error status+      # is returned to the caller.+      #+      # The actual deadline used will be the minimum of the value specified+      # here and the value set by the application via the gRPC client API.+      # If either one is not set, then the other will be used.+      # If neither is set, then the request has no deadline.+      #+      # The format of the value is that of the 'Duration' type defined here:+      # https://developers.google.com/protocol-buffers/docs/proto3#json+      'timeout': string,++      # The maximum allowed payload size for an individual request or object+      # in a stream (client->server) in bytes. The size which is measured is+      # the serialized, uncompressed payload in bytes. This applies both+      # to streaming and non-streaming requests.+      #+      # The actual value used is the minimum of the value specified here and+      # the value set by the application via the gRPC client API.+      # If either one is not set, then the other will be used.+      # If neither is set, then the built-in default is used.+      #+      # If a client attempts to send an object larger than this value, it+      # will not be sent and the client will see an error.+      # Note that 0 is a valid value, meaning that the request message must+      # be empty.+      #+      # The format of the value is that of the 'uint64' type defined here:+      # https://developers.google.com/protocol-buffers/docs/proto3#json+      'maxRequestMessageBytes': string,++      # The maximum allowed payload size for an individual response or object+      # in a stream (server->client) in bytes. The size which is measured is+      # the serialized, uncompressed payload in bytes. This applies both+      # to streaming and non-streaming requests.+      #+      # The actual value used is the minimum of the value specified here and+      # the value set by the application via the gRPC client API.+      # If either one is not set, then the other will be used.+      # If neither is set, then the built-in default is used.+      #+      # If a server attempts to send an object larger than this value, it+      # will not be sent, and the client will see an error.+      # Note that 0 is a valid value, meaning that the response message must+      # be empty.+      #+      # The format of the value is that of the 'uint64' type defined here:+      # https://developers.google.com/protocol-buffers/docs/proto3#json+      'maxResponseMessageBytes': string+    }+  ]+}+```++Note that new per-method parameters may be added in the future as new+functionality is introduced.++# Architecture++A service config is associated with a server name.  The [name+resolver](naming.md) plugin, when asked to resolve a particular server+name, will return both the resolved addresses and the service config.++TODO(roth): Design how the service config will be encoded in DNS.",does it TODO belong in the published docs? Maybe we want to hide it behind a markdown comment? (http://stackoverflow.com/questions/4823468/comments-in-markdown),
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/9213,96571380,2017-01-18T05:54:38Z,test/cpp/util/cli_credentials.cc,"@@ -33,10 +33,15 @@  #include ""test/cpp/util/cli_credentials.h"" +#include <fstream>+#include <sstream> #include <gflags/gflags.h>  DEFINE_bool(enable_ssl, false, ""Whether to use ssl/tls.""); DEFINE_bool(use_auth, false, ""Whether to create default google credentials."");+DEFINE_string(ssl_server_ca_file, """", ""Path to server CA file."");+DEFINE_string(ssl_client_cert_file, """", ""Path to client certificate file."");",`ssl_client_cert_chain_file` (and associated comment to specify that this is a chain).,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/9106,96679955,2017-01-18T16:48:55Z,doc/naming.md,"@@ -1,30 +1,59 @@-#gRPC Naming and Discovery Support+# gRPC Name Resolution  ## Overview -gRPC supports DNS as the default name-system. A number of alternative name-systems are used in various deployments. We propose an API that is general enough to support a range of name-systems and the corresponding syntax for names. The gRPC client library in various languages will provide a plugin mechanism so resolvers for different name-systems can be plugged in.+gRPC supports DNS as the default name-system. A number of alternative+name-systems are used in various deployments. We support an API that is+general enough to support a range of name-systems and the corresponding+syntax for names. The gRPC client library in various languages will+provide a plugin mechanism so resolvers for different name-systems can+be plugged in. -## Detailed Proposal+## Detailed Design - A fully qualified, self contained name used for gRPC channel construction uses the syntax:+### Name Syntax++A fully qualified, self contained name used for gRPC channel construction+uses the syntax:  ``` scheme://authority/endpoint_name ``` -Here, scheme indicates the name-system to be used. Example schemes to be supported include: +Here, `scheme` indicates the name-system to be used. Example schemes to+be supported include:",I've updated this to list all schemes that we support today (including the ones from the sockaddr resolver).,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/9194,96897912,2017-01-19T16:26:15Z,src/core/ext/client_channel/client_channel_factory.c,"@@ -85,3 +90,120 @@ grpc_arg grpc_client_channel_factory_create_channel_arg(   arg.value.pointer.vtable = &factory_arg_vtable;   return arg; }++struct grpc_channel_targets_info {","I've used mdstr_hash_table, but behind a couple of typedefs and some wrapping functions that encapsulate the actual data structure used. ",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/9194,96909105,2017-01-19T17:12:13Z,src/core/ext/client_channel/client_channel_factory.h,"@@ -71,6 +77,35 @@ struct grpc_client_channel_factory_vtable {                                          const grpc_channel_args *args); }; +/** Type for the mapping of target addresses to names for the purpose of secure+ * naming. */+typedef grpc_mdstr_hash_table grpc_channel_targets_info;","It's not clear to me what the benefit is of the channel_targets_info abstraction.  It looks like this wraps the hash table API, but the wrapping doesn't actually provide any significant new functionality.  The only methods that are not simple wrappers around the hash table API are grpc_channel_targets_info_find(), grpc_channel_targets_info_entry_create(), and grpc_channel_targets_info_entry_destroy(), all of which are only needed until #8842 is merged.  Given that, why not just use the hash table API directly, and provide only these temporary methods (with a comment about them going away once #8842 is merged)?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/9194,96915903,2017-01-19T17:46:01Z,src/core/lib/security/transport/security_connector.c,"@@ -319,7 +319,7 @@ static grpc_security_connector_vtable fake_server_vtable = {fake_server_destroy,                                                             fake_check_peer};  grpc_channel_security_connector *grpc_fake_channel_security_connector_create(-    grpc_call_credentials *request_metadata_creds) {+    grpc_call_credentials *request_metadata_creds, const char *target) {",Is this change actually needed?  It doesn't look like the target parameter is being used anywhere.,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/9194,96926305,2017-01-19T18:36:42Z,src/core/lib/security/transport/security_handshaker.c,"@@ -185,6 +188,58 @@ static void on_peer_checked(grpc_exec_ctx *exec_ctx, void *arg,   security_handshaker_unref(exec_ctx, h); } +static grpc_security_connector *find_lb_connector(grpc_exec_ctx *exec_ctx,+                                                  grpc_channel_args *args) {+  grpc_channel_security_connector *lb_channel_connector = NULL;+  char *target = NULL;++  const grpc_arg *target_info_arg =+      grpc_channel_args_find(args, GRPC_ARG_GRPCLB_BALANCER_NAMES);+  if (target_info_arg == NULL) goto done;++  // To which address are we connecting?+  grpc_resolved_address addr;+  grpc_get_subchannel_address_arg(args, &addr);+  GPR_ASSERT(grpc_sockaddr_to_string(&target, &addr, true /* normalize */));++  const grpc_channel_targets_info *targets_info =+      target_info_arg->value.pointer.p;+  GPR_ASSERT(targets_info != NULL);++  // Find the balancer name for the target.+  const char *balancer_name =+      grpc_channel_targets_info_find(targets_info, target);+  if (balancer_name == NULL) {+    gpr_log(GPR_ERROR, ""Missing secure name for target address '%s'"", target);+    goto done;+  }++  // Get the LB channel's credentials+  grpc_channel_credentials *lb_creds =+      grpc_find_channel_credentials_in_args(args);+  if (lb_creds == NULL) goto done;++  // For LB channels, regenerate the security connector. The credentials used+  // for the new security connection are stripped of call credentials and has+  // knowledge about the balancer names, which are to be used as the ""target""+  // for the purposes of secure naming.+  grpc_channel_args *new_args_from_connector = NULL;+  const grpc_security_status security_status =+      grpc_channel_credentials_create_security_connector(","check_peer() doesn't currently have access to channel args. Are you also suggesting it be added? Its current signature is ```void grpc_security_connector_check_peer(grpc_exec_ctx* exec_ctx, grpc_security_connector* sc, tsi_peer peer, grpc_auth_context** auth_context, grpc_closure* on_peer_checked)```security handshaker invokes it as (from [here](https://github.com/grpc/grpc/blob/master/src/core/lib/security/transport/security_handshaker.c#L196))```grpc_security_connector_check_peer(exec_ctx, h->connector, peer,                                     &h->auth_context, &h->on_peer_checked);```Two options1. Simply add a new arg, passing h->args->args (<- preferred)1. Pass in `h`, a `security_handshaker` instance and let the check_peer function read off it what it needs.",
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/9406,96944122,2017-01-19T19:56:58Z,src/compiler/cpp_generator.cc,"@@ -1272,7 +1274,6 @@ void PrintSourceService(Printer *printer, const Service *service,    printer->Print(*vars, ""$ns$$Service$::Service::Service() {\n"");   printer->Indent();-  printer->Print(*vars, ""(void)$prefix$$Service$_method_names;\n"");","The purpose of this line is to solve a similar problem. That is when there is no rpc methods defined in the service, some compilers will complain the global method_names array is not used. Since we do not generate them any more in that case, we do not need it. This is also the reason why I did not add NULL to the end of the array: so that we handle the case in one place rather than two. Not that really matters though.",
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/9213,96992145,2017-01-20T00:40:56Z,test/cpp/util/cli_credentials.cc,"@@ -49,7 +56,40 @@ std::shared_ptr<grpc::ChannelCredentials> CliCredentials::GetCredentials()     if (FLAGS_use_auth) {","Some flags combinations are still meaningless and error prone. I would have a helper function like:```cppvoid CheckForInvalidSslFlags(const string& flag) {  if (!FLAGS_ssl_cleint_cert_chain_file.empty() || !FLAGS_...) {    std::cerr << ""SSL specific flags cannot be used with "" << flag << "" flag."" << std::endl;    exit(2);  }}```and call this from:```cppif (!FLAGS_enable_ssl) {  CheckForInvalidSslFlags(""--noenable_ssl"");  return grpc::InsecureCredentials();} else {  if (FLAGS_use_auth) {    CheckForInvalidSslFlags(""--use_auth"");    return grpc::GoogleDefaultCredentials();  } ...```",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/9194,97167953,2017-01-20T22:23:20Z,src/core/ext/transport/chttp2/client/secure/secure_channel_create.c,"@@ -97,15 +98,15 @@ grpc_channel *grpc_secure_channel_create(grpc_channel_credentials *creds,   GRPC_API_TRACE(       ""grpc_secure_channel_create(creds=%p, target=%s, args=%p, ""       ""reserved=%p)"",-      4, (creds, target, args, reserved));+      4, ((void *)creds, target, (void *)args, (void *)reserved));   GPR_ASSERT(reserved == NULL);   // Make sure security connector does not already exist in args.","I'm not sure that I buy the performance argument, since (a) it's not clear that there's any significant amount of overhead in creating a security connector, and (b) subchannel creation is not on the fast path, so performance isn't a big deal anyway.With regard to reporting errors, it seems like we wouldn't actually need a lame client channel.  If the security connector creation fails, then we'd fail to create all of the subchannels, at which point any call requested on the channel would fail.  (Note that this is essentially the same thing that will happen if we create the new security connector in grpclb: if the creation fails, then the LB policy creation will fail, at which point any call requested on the channel would fail.)All of that having been said, I guess I can live with recreating the security connector in the grpclb code.  It's unfortunate that we'd have to pass down both the security connector and the credentials, but I guess that's offset by the benefit that all of the grpclb-related code would be contained in one place.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/9194,97354008,2017-01-23T16:18:05Z,src/core/ext/client_channel/client_channel_factory.h,"@@ -71,6 +73,14 @@ struct grpc_client_channel_factory_vtable {                                          const grpc_channel_args *args); }; +/** Return a channel argument containing \a targets_info. */+grpc_arg grpc_channel_targets_info_create_channel_arg(","I'm still not sure that this code belongs in the client_channel_factory module, since it's not used by anything that directly creates or uses a client channel factory.  It might be better to put it in the grpclb module.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/9372,97602422,2017-01-24T17:23:57Z,src/core/ext/client_channel/proxy_mapper_registry.h,"@@ -0,0 +1,53 @@+/*+ *+ * Copyright 2017, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#ifndef GRPC_CORE_EXT_CLIENT_CHANNEL_PROXY_MAPPER_REGISTRY_H+#define GRPC_CORE_EXT_CLIENT_CHANNEL_PROXY_MAPPER_REGISTRY_H++#include ""src/core/ext/client_channel/proxy_mapper.h""++void grpc_proxy_mapper_registry_init();+void grpc_proxy_mapper_registry_shutdown();++/// Registers a new proxy mapper.  Takes ownership.+/// If \a at_start is true, the new mapper will be at the beginning of+/// the list.  Otherwise, it will be added to the end.+void grpc_proxy_mapper_register(bool at_start, grpc_proxy_mapper* mapper);","I'm not aware of a concrete use-case, but it's conceivable that someone could have a client that wants to talk to two different environments similar to cases 2 or 3 in the gRFC.  It that case, it would make sense to have a different proxy mapper for each environment.",
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/9194,97627594,2017-01-24T19:16:53Z,src/core/ext/lb_policy/grpclb/grpclb_channel.h,"@@ -0,0 +1,47 @@+/*+ *+ * Copyright 2017, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#ifndef GRPC_CORE_EXT_LB_POLICY_GRPCLB_GRPCLB_CHANNEL_H+#define GRPC_CORE_EXT_LB_POLICY_GRPCLB_GRPCLB_CHANNEL_H++#include ""src/core/ext/client_channel/lb_policy_factory.h""++/** Create the channel used for communicating with an LB service.+ * Note that an LB *service* may be comprised of several LB *servers*. The+ * addresses of these servers are in \a addresses. */+grpc_channel *grpc_lb_policy_grpclb_create_lb_channel(+    grpc_exec_ctx *exec_ctx, const char *lb_service_target,","Since `lb_service_target` can contain more than one address, I find it a bit misleading to use singular as opposed to plural. Maybe a bit of documentation explaining what this parameter contains would help.",
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/9194,97648034,2017-01-24T20:55:10Z,src/core/lib/security/transport/security_connector.c,"@@ -42,13 +42,19 @@ #include <grpc/support/log.h> #include <grpc/support/string_util.h> +#include ""src/core/ext/client_channel/client_channel_factory.h""+#include ""src/core/ext/client_channel/uri_parser.h""+#include ""src/core/ext/lb_policy/grpclb/grpclb.h""",I am slightly concerned about adding this dependency here as this means that we won't be able to have a non-lb secure gRPC stack (some folks are worried about the size of the stack). I could live with it though...,
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/9194,97650528,2017-01-24T21:07:37Z,src/core/lib/security/transport/security_connector.c,"@@ -278,6 +287,44 @@ static void fake_check_peer(grpc_exec_ctx *exec_ctx,       *auth_context, GRPC_TRANSPORT_SECURITY_TYPE_PROPERTY_NAME,       GRPC_FAKE_TRANSPORT_SECURITY_TYPE); +  const grpc_slice_hash_table *targets_info =+      grpc_glb_targets_info_find_in_args(args);+  if (targets_info != NULL) {+    /* For LB channels, verify the target name passed in matches the+     * expectation, if any. */++    /* To which address are we connecting? */+    const char *target_uri_str = grpc_get_subchannel_address_uri_arg(args);+    grpc_uri *target_uri =+        grpc_uri_parse(target_uri_str, true /* suppress errors */);++    /* Find the balancer name for the target. */+    const grpc_slice key = grpc_slice_from_static_string(target_uri->path);+    const char *balancer_name = grpc_slice_hash_table_get(targets_info, key);+    grpc_slice_unref_internal(exec_ctx, key);++    grpc_uri_destroy(target_uri);+    if (balancer_name == NULL) {+      char *error_msg;+      gpr_asprintf(&error_msg, ""Missing secure name for target address '%s'"",",nit: the name is not `secure` here since it came from the naming system.,
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/9194,97657845,2017-01-24T21:42:04Z,src/core/lib/security/transport/security_connector.c,"@@ -509,7 +556,8 @@ static grpc_error *ssl_check_peer(grpc_security_connector *sc, static void ssl_channel_check_peer(grpc_exec_ctx *exec_ctx,","It looks to me that here, in the case of LB, you should do the secure naming check on the `targets_info[target_uri]`.",
10503072,a-veitch,https://api.github.com/repos/grpc/grpc/pulls/9371,97691855,2017-01-25T01:21:01Z,src/core/ext/census/trace_propagation.h,"@@ -0,0 +1,62 @@+/*+ *+ * Copyright 2016, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#ifndef GRPC_CORE_EXT_CENSUS_TRACE_PROPAGATION_H+#define GRPC_CORE_EXT_CENSUS_TRACE_PROPAGATION_H++#include ""src/core/ext/census/tracing.h""++/* Encoding and decoding functions for receiving and sending propagating data",suggest s/propagating data/trace contexts/,
10503072,a-veitch,https://api.github.com/repos/grpc/grpc/pulls/9371,97692058,2017-01-25T01:22:31Z,src/core/ext/census/trace_propagation.h,"@@ -0,0 +1,62 @@+/*+ *+ * Copyright 2016, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#ifndef GRPC_CORE_EXT_CENSUS_TRACE_PROPAGATION_H+#define GRPC_CORE_EXT_CENSUS_TRACE_PROPAGATION_H++#include ""src/core/ext/census/tracing.h""++/* Encoding and decoding functions for receiving and sending propagating data+   over the wire.  Only RPC libraries should be calling these+   functions.  These functions return the number of bytes encoded/decoded+   (0 if a failure has occurred). buf_size indicates the size of the+   input/output buffer. trace_span_context is a struct that includes the+   trace ID, span ID, and a set of option flags (is_sampled, etc.). */++/* Converts a span context to a binary byte buffer. */+size_t trace_span_context_to_binary(const trace_span_context *ctxt, char *buf,+                                    size_t buf_size);++/* Reads a binary byte buffer and populates a span context structure. */+size_t binary_to_trace_span_context(const char *buf, size_t buf_size,+                                    trace_span_context *ctxt);++/* Converts a span context to a http format buffer. */",s/a http format buffer/an http metadata compatible string/,
10503072,a-veitch,https://api.github.com/repos/grpc/grpc/pulls/9371,97692771,2017-01-25T01:28:27Z,src/core/ext/census/trace_string.h,"@@ -0,0 +1,47 @@+/*+ *+ * Copyright 2016, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#ifndef GRPC_CORE_EXT_CENSUS_TRACE_STRING_H+#define GRPC_CORE_EXT_CENSUS_TRACE_STRING_H++#include <grpc/slice.h>","I think we should avoid relying on grpc_slice for now. At some point in the future we want to separate grpc and census into separate packages, and we don't want a dependency on anything except gpr. When/if slide moves back into gpr, we can use it.",
14932100,adelez,https://api.github.com/repos/grpc/grpc/pulls/9458,97843701,2017-01-25T18:20:23Z,tools/jenkins/run_interop.sh,"@@ -37,3 +37,5 @@ export LANG=en_US.UTF-8 cd $(dirname $0)/../..  tools/run_tests/run_interop_tests.py -l all -s all --cloud_to_prod --cloud_to_prod_auth --use_docker --http2_interop -t -j 12 $@ || true+tools/run_tests/run_interop_tests.py -l java --use_docker --http2_badserver_interop $@ || true","I was going to click the ""HTML Report"" link for gRPC_interop_pull_requests 10846 to see if it contains results from both runs, but this test failed to build docker image: https://grpc-testing.appspot.com/job/gRPC_interop_pull_requests/10846/console. It's strange that the build is still shown successful.Also currently it probably won't show results for the 2nd test in HTML because the test cases are not added to https://github.com/grpc/grpc/blob/master/tools/run_tests/run_interop_tests.py#L995. One fix for this would be combining the two commands into:tools/run_tests/run_interop_tests.py -l all -s all --cloud_to_prod --cloud_to_prod_auth --use_docker --http2_interop **--http2_badserver_interop**In the test script if --http2_badserver_interop is true, automatically run all languages that support this case, currently java only, i.e., ignore -l arg for http2_badserver_interop cases. Then it'll be easy to add this case to HTML. I can take care of that.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/9194,97849776,2017-01-25T18:48:22Z,src/core/ext/lb_policy/grpclb/grpclb.c,"@@ -751,6 +785,116 @@ static void glb_rr_connectivity_changed(grpc_exec_ctx *exec_ctx, void *arg,   GRPC_ERROR_UNREF(error); } +static void destroy_balancer_name(grpc_exec_ctx *exec_ctx,+                                  void *balancer_name) {+  gpr_free(balancer_name);+}++static void *copy_balancer_name(void *balancer_name) {+  return gpr_strdup(balancer_name);+}++static grpc_slice_hash_table_entry *targets_info_entry_create(+    const char *address, const char *balancer_name) {+  static const grpc_slice_hash_table_vtable vtable = {destroy_balancer_name,+                                                      copy_balancer_name};+  grpc_slice_hash_table_entry *entry = gpr_malloc(sizeof(*entry));+  entry->key = grpc_slice_from_copied_string(address);+  entry->value = (void *)balancer_name;+  entry->vtable = &vtable;+  return entry;+}++static char *get_lb_target(grpc_exec_ctx *exec_ctx,+                           const grpc_lb_addresses *addresses,+                           grpc_slice_hash_table **targets_info) {+  size_t num_grpclb_addrs = 0;+  for (size_t i = 0; i < addresses->num_addresses; ++i) {+    if (addresses->addresses[i].is_balancer) ++num_grpclb_addrs;+  }++  grpc_slice_hash_table_entry **targets_info_entries = NULL;+  targets_info_entries =+      gpr_malloc(sizeof(*targets_info_entries) * num_grpclb_addrs);++  /* construct a target ipvX://ip1:port1,ip2:port2,... from the addresses in \a+   * addresses */+  /* TODO(dgq): support mixed ip version */+  char **addr_strs = gpr_malloc(sizeof(char *) * num_grpclb_addrs);+  size_t addr_index = 0;++  for (size_t i = 0; i < addresses->num_addresses; i++) {+    if (addresses->addresses[i].user_data != NULL) {+      gpr_log(GPR_ERROR,+              ""This LB policy doesn't support user data. It will be ignored"");+    }+    if (addresses->addresses[i].is_balancer) {+      char *addr_str;+      GPR_ASSERT(grpc_sockaddr_to_string(+                     &addr_str, &addresses->addresses[i].address, true) > 0);+      addr_strs[addr_index++] = addr_str;+      targets_info_entries[i] = targets_info_entry_create(+          addr_str, addresses->addresses[i].balancer_name);+    }+  }++  size_t uri_path_len;+  char *uri_path = gpr_strjoin_sep((const char **)addr_strs, num_grpclb_addrs,+                                   "","", &uri_path_len);+  for (size_t i = 0; i < num_grpclb_addrs; i++) gpr_free(addr_strs[i]);+  gpr_free(addr_strs);++  char *target_uri_str = NULL;+  gpr_asprintf(&target_uri_str, ""%s:%s"",+               grpc_sockaddr_get_uri_scheme(&addresses->addresses[0].address),+               uri_path);+  gpr_free(uri_path);++  *targets_info =+      grpc_slice_hash_table_create(num_grpclb_addrs, *targets_info_entries);","`grpc_slice_hash_table_*` is a renaming of `grpc_mdstr_hash_table_*` which happened in #8842 (temporarily rolled back, which is why I'm not changing these signatures back). Refer to https://github.com/grpc/grpc/blob/master/src/core/lib/transport/mdstr_hash_table.h#L65 for now. In any case, I *am* providing the size: as the first argument, `num_grpclb_addrs`.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/9194,97866596,2017-01-25T20:03:49Z,src/core/lib/security/transport/security_connector.c,"@@ -42,13 +42,19 @@ #include <grpc/support/log.h> #include <grpc/support/string_util.h> +#include ""src/core/ext/client_channel/client_channel_factory.h""+#include ""src/core/ext/client_channel/uri_parser.h""+#include ""src/core/ext/lb_policy/grpclb/grpclb.h""","Only `fake_check_peer` uses it (for the `grpc_glb_targets_info_find_in_args` function). I wonder if the fake security connector should be moved outside of security_connector.cIn any case, given how localized the dependency is (single function in test related code), I'd argue we can deal with the dependency when/if it becomes a concern.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/9054,97880095,2017-01-25T21:16:53Z,test/core/iomgr/pollset_set_test.c,"@@ -0,0 +1,476 @@+/*+ *+ * Copyright 2016, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */+#include ""src/core/lib/iomgr/port.h""++/* This test only relevant on linux systems */+#ifdef GRPC_POSIX_SOCKET+#include ""src/core/lib/iomgr/ev_posix.h""++#include <errno.h>",move standard headers to the top of the #includes list?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/9194,98025749,2017-01-26T16:02:27Z,src/core/ext/transport/chttp2/client/secure/secure_channel_create.c,"@@ -97,15 +98,15 @@ grpc_channel *grpc_secure_channel_create(grpc_channel_credentials *creds,   GRPC_API_TRACE(       ""grpc_secure_channel_create(creds=%p, target=%s, args=%p, ""       ""reserved=%p)"",-      4, (creds, target, args, reserved));+      4, ((void *)creds, target, (void *)args, (void *)reserved));   GPR_ASSERT(reserved == NULL);   // Make sure security connector does not already exist in args.","David, in light of Julien's comments about all security connectors needing to know the right target name, I'd like to renew my suggestion of moving the security connector creation into client_channel_factory_create_subchannel().  While it's true that this would result in a separate security connector for each subchannel, I think that would allow us to centralize the use of the GRPC_ARG_BALANCER_NAME_MAP channel arg in one place, so that the target name lookup doesn't have to be done in each individual security connector implementation.Julien, would there be any adverse affects of this approach, in terms of either memory usage or performance?  In particular, I'm thinking of situations where there are a large number of servers (and hence a large number of subchannels).Other thoughts?",
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/9466,98063571,2017-01-26T18:53:04Z,test/core/end2end/tests/authority_not_supported.c,"@@ -50,7 +50,8 @@ static grpc_end2end_test_fixture begin_test(grpc_end2end_test_config config,                                             grpc_channel_args *client_args,                                             grpc_channel_args *server_args) {   grpc_end2end_test_fixture f;-  gpr_log(GPR_INFO, ""%s/%s"", test_name, config.name);+  gpr_log(GPR_INFO, ""Running test: Running test: %s/%s"", test_name,",duplicate~,
6879942,Vizerai,https://api.github.com/repos/grpc/grpc/pulls/9371,98064284,2017-01-26T18:56:19Z,src/core/ext/census/trace_label.h,"@@ -0,0 +1,59 @@+/*+ *+ * Copyright 2016, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#ifndef GRPC_CORE_EXT_CENSUS_TRACE_LABEL_H+#define GRPC_CORE_EXT_CENSUS_TRACE_LABEL_H++#include ""src/core/ext/census/trace_string.h""++/* Trace label (key/value pair) stores a label name and the label value. */+typedef struct trace_label {+  trace_string key;+  enum label_type {",Can the label ever actually be unknown?  I thought it had to be one the 3 types listed.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/9194,98467206,2017-01-30T15:39:18Z,src/core/ext/transport/chttp2/client/secure/secure_channel_create.c,"@@ -52,12 +57,98 @@ static void client_channel_factory_ref( static void client_channel_factory_unref(     grpc_exec_ctx *exec_ctx, grpc_client_channel_factory *cc_factory) {} +static grpc_subchannel_args *get_secure_naming_subchannel_args(+    grpc_exec_ctx *exec_ctx, const grpc_subchannel_args *args) {+  grpc_channel_credentials *channel_credentials =+      grpc_find_channel_credentials_in_args(args->args);+  if (channel_credentials == NULL) return NULL;++  const grpc_slice_hash_table *targets_info =+      grpc_glb_targets_info_find_in_args(args->args);+  if (targets_info == NULL) return NULL;++  /* To which address are we connecting? */+  const char *target_uri_str = grpc_get_subchannel_address_uri_arg(args->args);+  grpc_uri *target_uri =+      grpc_uri_parse(target_uri_str, true /* suppress errors */);+  /* Find the balancer name for the target. */+  const grpc_slice key = grpc_slice_from_static_string(target_uri->path);+  const char *secure_name = grpc_slice_hash_table_get(targets_info, key);+  grpc_slice_unref_internal(exec_ctx, key);+  grpc_uri_destroy(target_uri);+  if (secure_name == NULL) return NULL;++  /* Remove some channel args:+   *+   * Channel credentials aren't needed down the stack.+   *+   * The security connector is being substituted by a newly created one based","We shouldn't need to remove the security connector, since it should no longer be added anywhere else.",
10503072,a-veitch,https://api.github.com/repos/grpc/grpc/pulls/9429,98777032,2017-01-31T21:38:20Z,test/core/census/trace_context_test.c,"@@ -144,49 +144,48 @@ static void test_span_only() {       &ctxt, ""test/core/census/data/context_span_only.pb"", false); } -// Test proto-buffer without is_sampled value.-static void test_no_sample() {+// Test proto-buffer without span_options value.+static void test_no_span_options() {   google_trace_TraceContext ctxt = google_trace_TraceContext_init_zero;   read_and_validate_context_from_file(-      &ctxt, ""test/core/census/data/context_no_sample.pb"", true);-  GPR_ASSERT(ctxt.has_is_sampled == false && ctxt.is_sampled == false);+      &ctxt, ""test/core/census/data/context_no_span_options.pb"", true);+  GPR_ASSERT(ctxt.has_span_options == false && ctxt.span_options == false);","Since span_options is numeric, shouldn't the last part of the condition here be ""ctxt.span_options == 0"" ?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/9516,98777666,2017-01-31T21:41:02Z,src/node/src/client.js,"@@ -831,13 +831,12 @@ exports.waitForClientReady = function(client, deadline, callback) {  */ exports.makeProtobufClientConstructor =  function(service, options) {   var method_attrs = common.getProtobufServiceAttrs(service, options);-  var deprecatedArgumentOrder = false;-  if (options) {-    deprecatedArgumentOrder = options.deprecatedArgumentOrder;+  if (!options) {+    options = {deprecatedArgumentOrder: false};   }   var Client = exports.makeClientConstructor(       method_attrs, common.fullyQualifiedName(service),-      deprecatedArgumentOrder);","nit: perhaps only use boolean `deprecatedArgumentOrder` instead of the `options` object. In `makeClientConstructor`, looks like only this field is used.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/9531,98802929,2017-02-01T00:07:33Z,test/core/end2end/bad_server_response_test.c,"@@ -82,7 +82,7 @@ #define HTTP1_DETAIL_MSG ""Trying to connect an http1.x server""  /* TODO(zyc) Check the content of incomming data instead of using this length */-#define EXPECTED_INCOMING_DATA_LENGTH (size_t)310+#define EXPECTED_INCOMING_DATA_LENGTH (size_t)300",@y-zeng can you shed some light on the role this plays in the test? The naming is a bit misleading currently.,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/9536,98811824,2017-02-01T01:21:34Z,src/core/ext/transport/chttp2/client/insecure/channel_create.c,"@@ -64,14 +66,37 @@ static grpc_channel *client_channel_factory_create_channel(     const char *target, grpc_client_channel_type type,     const grpc_channel_args *args) {   // Add channel arg containing the server URI.+  // Firstly, let's make sure \a target is a valid URI.+  grpc_uri *target_uri = NULL;+  char *target_uri_str = NULL;+  grpc_uri_section uri_section = GRPC_URI_SECTION_NONE;+  if ((target_uri = grpc_uri_parse(target, true /* suppress errors */,+                                   &uri_section)) == NULL) {+    if (uri_section == GRPC_URI_SECTION_SCHEME) {+      // If the parsing error was due to the lack of scheme, try to fix that by+      // prepending the default resolver prefix.+      gpr_asprintf(&target_uri_str, ""%s%s"",+                   grpc_resolver_registry_get_default_prefix(), target);+      // try again...+      if ((target_uri = grpc_uri_parse(+               target_uri_str, true /* suppress errors */, NULL)) == NULL) {+        gpr_free(target_uri_str);+        return NULL;+      }+    } else {+      return NULL;+    }+  }+  grpc_uri_destroy(target_uri);",I don't like the code duplication (secure/insecure versions). I'll likely place this code in some util file (suggestions welcome). I wanted to put the review out anyway though.,
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/9194,98836656,2017-02-01T06:55:27Z,src/core/lib/security/transport/secure_naming.c,"@@ -0,0 +1,70 @@+/*",I don't think that `secure_naming.c` is a good name for this file since it just deals with lb targets info. How about `lb_targets_info.c`?,
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/9194,98836788,2017-02-01T06:57:06Z,src/core/lib/security/transport/secure_naming.h,"@@ -0,0 +1,47 @@+/*+ *+ * Copyright 2017, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#ifndef GRPC_CORE_EXT_LB_POLICY_GRPCLB_SECURE_NAMING_H",Same remark as above for the file name. `lb_targets_info.h`?Also it doesn't look the path of the macro `GRPC_CORE_EXT_LB_POLICY_GRPCLB_SECURE_NAMING_H` matches the path of this file: `src/core/lib/security/transport/secure_naming.h'.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/9194,98923061,2017-02-01T15:48:33Z,src/core/ext/transport/chttp2/client/secure/secure_channel_create.c,"@@ -124,19 +150,21 @@ static grpc_subchannel_args *get_secure_naming_subchannel_args( static grpc_subchannel *client_channel_factory_create_subchannel(     grpc_exec_ctx *exec_ctx, grpc_client_channel_factory *cc_factory,     const grpc_subchannel_args *args) {-  grpc_subchannel_args *final_sc_args =+  grpc_subchannel_args *subchannel_args =       get_secure_naming_subchannel_args(exec_ctx, args);-+  if (subchannel_args == NULL) {+    gpr_log(+        GPR_ERROR,+        ""Failed to create subchannel arguments during subchannel creation."");+    return NULL;+  }   grpc_connector *connector = grpc_chttp2_connector_create();   grpc_subchannel *s = grpc_subchannel_create(-      exec_ctx, connector, final_sc_args != NULL ? final_sc_args : args);+      exec_ctx, connector, subchannel_args != NULL ? subchannel_args : args);","subchannel_args should never be NULL here, so I think we can use it unconditionally here.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/9194,98937854,2017-02-01T16:45:08Z,src/core/lib/security/credentials/fake/fake_credentials.c,"@@ -35,20 +35,90 @@  #include <string.h> -#include ""src/core/lib/channel/channel_args.h""-#include ""src/core/lib/iomgr/executor.h""- #include <grpc/support/alloc.h> #include <grpc/support/log.h> #include <grpc/support/string_util.h> +#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/iomgr/executor.h""+#include ""src/core/lib/security/transport/secure_naming.h""+#include ""src/core/lib/support/string.h""+ /* -- Fake transport security credentials. -- */ +static bool check_target(const char *target_type, const char *target,+                         const char *set_str) {+  GPR_ASSERT(target_type != NULL);+  GPR_ASSERT(target != NULL);+  char **set = NULL;+  size_t set_size = 0;+  gpr_string_split(set_str, "","", &set, &set_size);+  bool found = false;+  for (size_t i = 0; i < set_size; ++i) {+    if (set[i] != NULL && strcmp(target, set[i]) == 0) found = true;+  }+  for (size_t i = 0; i < set_size; ++i) {+    gpr_free(set[i]);+  }+  gpr_free(set);+  return found;+}++static bool is_lb_channel(const grpc_channel_args *args) {+  return grpc_glb_targets_info_find_in_args(args) != NULL;+}+ static grpc_security_status fake_transport_security_create_security_connector(     grpc_exec_ctx *exec_ctx, grpc_channel_credentials *c,     grpc_call_credentials *call_creds, const char *target,     const grpc_channel_args *args, grpc_channel_security_connector **sc,     grpc_channel_args **new_args) {+  const grpc_arg *expected_target_arg =","Based on [previous comments](https://github.com/grpc/grpc/pull/9194#discussion_r98025749) the idea was to instantiate the security connector at subchannel creation time, which allowed us to use the appropriate target name for the security connector. This would mean that `check_peer` can ""do its thing"" without knowing about mappings etc. As you recall, a previous commit was doing the checking in the fake security connector's `check_peer`. It could be performed there, but given that the `target` argument passed to the `*_security_create_security_connector` constructors is the definitive one, it can readily be performed here too (unless you feel that doing it in `check_peer` is better as, perhaps, an example).",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/9458,98966630,2017-02-01T18:54:14Z,tools/jenkins/run_interop.sh,"@@ -37,3 +37,5 @@ export LANG=en_US.UTF-8 cd $(dirname $0)/../..  tools/run_tests/run_interop_tests.py -l all -s all --cloud_to_prod --cloud_to_prod_auth --use_docker --http2_interop -t -j 12 $@ || true+tools/run_tests/run_interop_tests.py -l java --use_docker --http2_badserver_interop $@ || true","Probable explanation of why Jenkins shows success:The first run of run_interop_tests.py generates report.xml and the other 2 http badserver runs fail already in the build docker image phase, so they don't have a change to create the report.xml - Jenkins ends up seeing report.xml from the first run and if that run succeeded, the run will look green on Jenkins.",
17460127,y-zeng,https://api.github.com/repos/grpc/grpc/pulls/9531,98980771,2017-02-01T19:56:29Z,test/core/end2end/bad_server_response_test.c,"@@ -82,7 +82,7 @@ #define HTTP1_DETAIL_MSG ""Trying to connect an http1.x server""  /* TODO(zyc) Check the content of incomming data instead of using this length */-#define EXPECTED_INCOMING_DATA_LENGTH (size_t)310+#define EXPECTED_INCOMING_DATA_LENGTH (size_t)300",The 'bad' server will start sending responses after reading this amount of data from the client. Sorry for the confusion :anguished:,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/9194,99249691,2017-02-02T23:52:19Z,src/core/lib/security/credentials/fake/fake_credentials.c,"@@ -35,20 +35,90 @@  #include <string.h> -#include ""src/core/lib/channel/channel_args.h""-#include ""src/core/lib/iomgr/executor.h""- #include <grpc/support/alloc.h> #include <grpc/support/log.h> #include <grpc/support/string_util.h> +#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/iomgr/executor.h""+#include ""src/core/lib/security/transport/secure_naming.h""+#include ""src/core/lib/support/string.h""+ /* -- Fake transport security credentials. -- */ +static bool check_target(const char *target_type, const char *target,+                         const char *set_str) {+  GPR_ASSERT(target_type != NULL);+  GPR_ASSERT(target != NULL);+  char **set = NULL;+  size_t set_size = 0;+  gpr_string_split(set_str, "","", &set, &set_size);+  bool found = false;+  for (size_t i = 0; i < set_size; ++i) {+    if (set[i] != NULL && strcmp(target, set[i]) == 0) found = true;+  }+  for (size_t i = 0; i < set_size; ++i) {+    gpr_free(set[i]);+  }+  gpr_free(set);+  return found;+}++static bool is_lb_channel(const grpc_channel_args *args) {+  return grpc_glb_targets_info_find_in_args(args) != NULL;+}+ static grpc_security_status fake_transport_security_create_security_connector(     grpc_exec_ctx *exec_ctx, grpc_channel_credentials *c,     grpc_call_credentials *call_creds, const char *target,     const grpc_channel_args *args, grpc_channel_security_connector **sc,     grpc_channel_args **new_args) {+  const grpc_arg *expected_target_arg =",I think I'll re-do the check in `check_peer` with a big comment about it. I'll send out a new commit with that shortly.,
5120183,jcanizales,https://api.github.com/repos/grpc/grpc/pulls/9246,99414356,2017-02-03T20:15:27Z,src/objective-c/tests/CronetUnitTests/CronetUnitTests.m,"@@ -270,8 +270,11 @@ - (void)testInternalError { }  - (void)PacketCoalescing:(bool)use_coalescing {",nit:* methods and parameters are named in lowerCamelCase* s/bool/BOOL/,
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/9246,99665139,2017-02-06T19:34:29Z,src/objective-c/tests/CronetUnitTests/CronetUnitTests.m,"@@ -270,8 +270,11 @@ - (void)testInternalError { }  - (void)PacketCoalescing:(bool)use_coalescing {-  grpc_cronet_use_packet_coalescing(use_coalescing);-+  grpc_arg arg;+  arg.key = GRPC_ARG_USE_CRONET_PACKET_COALESCING;+  arg.type = GRPC_ARG_INTEGER;+  arg.value.integer = use_coalescing ? 1:0;+  grpc_channel_args *args = grpc_channel_args_copy_and_add(NULL, &arg, 1);","Since things being tested here are core changes, I would rather not to invoke something in ObjC library. Besides that I feel it is a bit over weight to move that code here and create `grpc_channel_args` with it; I would more like to stay with this core tests style of creating channel args.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/9522,100006088,2017-02-08T07:36:09Z,tools/run_tests/run_microbenchmark.py,"@@ -0,0 +1,134 @@+#!/usr/bin/env python2.7+# Copyright 2017, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.++import multiprocessing+import os+import subprocess+import sys++import python_utils.jobset as jobset+import python_utils.start_port_server as start_port_server++flamegraph_dir = os.path.join(os.path.expanduser('~'), 'FlameGraph')++os.chdir(os.path.join(os.path.dirname(sys.argv[0]), '../..'))+if not os.path.exists('reports'):+  os.makedirs('reports')++port_server_port = 32766+start_port_server.start_port_server(port_server_port)++def fnize(s):+  out = ''+  for c in s:+    if c in '<>, /':+      if len(out) and out[-1] == '_': continue+      out += '_'+    else:+      out += c+  return out++# index html+index_html = """"""+<html>+<head>+<title>Microbenchmark Results</title>+</head>+<body>+""""""++def heading(name):+  global index_html+  index_html += ""<h1>%s</h1>\n"" % name++def link(txt, tgt):+  global index_html+  index_html += ""<p><a href=\""%s\"">%s</a></p>\n"" % (tgt, txt)++benchmarks = []+profile_analysis = []+cleanup = []++for bm_name in sys.argv[1:]:+  # generate latency profiles+  heading('Latency Profiles: %s' % bm_name)+  subprocess.check_call(+      ['make', bm_name,+       'CONFIG=basicprof', '-j', '%d' % multiprocessing.cpu_count()])+  for line in subprocess.check_output(['bins/basicprof/%s' % bm_name,+                                       '--benchmark_list_tests']).splitlines():+    link(line, '%s.txt' % fnize(line))+    benchmarks.append(+        jobset.JobSpec(['bins/basicprof/%s' % bm_name, '--benchmark_filter=^%s$' % line],+                       environ={'LATENCY_TRACE': '%s.trace' % fnize(line)}))+    profile_analysis.append(+        jobset.JobSpec([sys.executable,+                        'tools/profiling/latency_profile/profile_analyzer.py',+                        '--source', '%s.trace' % fnize(line), '--fmt', 'simple',+                        '--out', 'reports/%s.txt' % fnize(line)], timeout_seconds=None))+    cleanup.append(jobset.JobSpec(['rm', '%s.trace' % fnize(line)]))+    if len(benchmarks) >= 2 * multiprocessing.cpu_count():",Do we need the if else here? Shouldn't always clear the job lists?,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/9522,100157047,2017-02-08T20:03:54Z,tools/run_tests/run_microbenchmark.py,"@@ -0,0 +1,134 @@+#!/usr/bin/env python2.7+# Copyright 2017, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.++import multiprocessing+import os+import subprocess+import sys++import python_utils.jobset as jobset+import python_utils.start_port_server as start_port_server++flamegraph_dir = os.path.join(os.path.expanduser('~'), 'FlameGraph')++os.chdir(os.path.join(os.path.dirname(sys.argv[0]), '../..'))+if not os.path.exists('reports'):+  os.makedirs('reports')++port_server_port = 32766+start_port_server.start_port_server(port_server_port)++def fnize(s):+  out = ''+  for c in s:+    if c in '<>, /':+      if len(out) and out[-1] == '_': continue+      out += '_'+    else:+      out += c+  return out++# index html+index_html = """"""+<html>+<head>+<title>Microbenchmark Results</title>+</head>+<body>+""""""++def heading(name):+  global index_html+  index_html += ""<h1>%s</h1>\n"" % name++def link(txt, tgt):+  global index_html+  index_html += ""<p><a href=\""%s\"">%s</a></p>\n"" % (tgt, txt)++benchmarks = []+profile_analysis = []+cleanup = []++for bm_name in sys.argv[1:]:+  # generate latency profiles+  heading('Latency Profiles: %s' % bm_name)+  subprocess.check_call(+      ['make', bm_name,+       'CONFIG=basicprof', '-j', '%d' % multiprocessing.cpu_count()])+  for line in subprocess.check_output(['bins/basicprof/%s' % bm_name,+                                       '--benchmark_list_tests']).splitlines():+    link(line, '%s.txt' % fnize(line))+    benchmarks.append(+        jobset.JobSpec(['bins/basicprof/%s' % bm_name, '--benchmark_filter=^%s$' % line],+                       environ={'LATENCY_TRACE': '%s.trace' % fnize(line)}))+    profile_analysis.append(+        jobset.JobSpec([sys.executable,+                        'tools/profiling/latency_profile/profile_analyzer.py',+                        '--source', '%s.trace' % fnize(line), '--fmt', 'simple',+                        '--out', 'reports/%s.txt' % fnize(line)], timeout_seconds=None))+    cleanup.append(jobset.JobSpec(['rm', '%s.trace' % fnize(line)]))+    if len(benchmarks) >= min(4, multiprocessing.cpu_count()):+      jobset.run(benchmarks, maxjobs=multiprocessing.cpu_count()/2,+                 add_env={'GRPC_TEST_PORT_SERVER': 'localhost:%d' % port_server_port})+      jobset.run(profile_analysis, maxjobs=multiprocessing.cpu_count())+      jobset.run(cleanup, maxjobs=multiprocessing.cpu_count())+      benchmarks = []",actually still a bit hung up on why we clear the lists in this case but not in `if len(benchmarks)` case.for```benchmarks = []profile_analysis = []cleanup = []```not clearing them in latter case? Won't a second round of the loop have them kept in unintentionally?,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/9392,100166299,2017-02-08T20:49:04Z,tools/run_tests/performance/scenario_config.py,"@@ -145,14 +140,15 @@ def _ping_pong_scenario(name, rpc_type,   if use_generic_payload:     if server_type != 'ASYNC_GENERIC_SERVER':       raise Exception('Use ASYNC_GENERIC_SERVER for generic payload.')-    scenario['client_config']['payload_config'] = EMPTY_GENERIC_PAYLOAD-    scenario['server_config']['payload_config'] = EMPTY_GENERIC_PAYLOAD-  else:-    # For proto payload, only the client should get the config.-    scenario['client_config']['payload_config'] = EMPTY_PROTO_PAYLOAD+  scenario['client_config']['payload_config'] = _payload_type(use_generic_payload, req_size, resp_size)+  scenario['server_config']['payload_config'] = _payload_type(use_generic_payload, req_size, resp_size)","I think the problem here is that payload_config should only be set for client for non-generic server. The reason is that the non-generic server (Async and Sync) are supposed to respond with a message size that corresponds to what is requested in SimpleRequest (which is constructed based on client's payload config).Setting payload config for a server should be illegal (and so C# qps worker is asserting that it is only set for generic server), which is what's breaking C# benchmarks (https://github.com/grpc/grpc/issues/9587).https://github.com/grpc/grpc/blob/master/src/proto/grpc/testing/messages.proto#L76https://github.com/grpc/grpc/blob/2e096b0fec7d56a71dc0bcb4ca5c9b6b918a330a/src/proto/grpc/testing/control.proto#L143https://github.com/grpc/grpc/blob/f9b87301aada7bd80f8487bb0527bfb4c0eaa034/test/cpp/qps/server_async.cc#L366",
4578188,pmarks-net,https://api.github.com/repos/grpc/grpc/pulls/7771,100183030,2017-02-08T22:09:50Z,src/core/ext/resolver/dns/c_ares/grpc_ares_wrapper.c,"@@ -0,0 +1,282 @@+/*+ *+ * Copyright 2016, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#include <grpc/support/port_platform.h>+#if GRPC_ARES == 1++#include ""src/core/ext/resolver/dns/c_ares/grpc_ares_wrapper.h""+#include ""src/core/lib/iomgr/sockaddr.h""+#include ""src/core/lib/iomgr/socket_utils_posix.h""++#include <string.h>+#include <sys/types.h>++#include <ares.h>+#include <grpc/support/alloc.h>+#include <grpc/support/host_port.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>+#include <grpc/support/time.h>+#include <grpc/support/useful.h>+#include ""src/core/ext/resolver/dns/c_ares/grpc_ares_ev_driver.h""+#include ""src/core/lib/iomgr/executor.h""+#include ""src/core/lib/iomgr/iomgr_internal.h""+#include ""src/core/lib/iomgr/sockaddr_utils.h""+#include ""src/core/lib/support/string.h""++static gpr_once g_basic_init = GPR_ONCE_INIT;+static gpr_mu g_init_mu;++typedef struct grpc_ares_request {+  /** following members are set in grpc_resolve_address_ares_impl */+  /** host to resolve, parsed from the name to resolve */+  char *host;+  /** port to fill in sockaddr_in, parsed from the name to resolve */+  char *port;+  /** default port to use */+  char *default_port;+  /** closure to call when the request completes */+  grpc_closure *on_done;+  /** the pointer to receive the resolved addresses */+  grpc_resolved_addresses **addrs_out;","For a related example, Go shipped https://github.com/golang/go/blob/master/src/net/addrselect.go with their `getaddrinfo()` alternative.  (Although it's not completely perfect because it doesn't parse `/etc/gai.conf`.)",
5120183,jcanizales,https://api.github.com/repos/grpc/grpc/pulls/9247,100241899,2017-02-09T07:07:07Z,src/objective-c/GRPCClient/GRPCCall+Tests.h,"@@ -63,4 +63,19 @@  * cache.  */ + (void)resetHostSettings;++/**+ * Enables logging of op batches. Memory consumption increases as more ops are logged.+ */++ (void)enableOpBatchLog:(BOOL)enabled;++/**+ * Add an op batch to log.+ */++ (void)addOpBatchToLog:(NSArray *)batch;++/**+ * Obtain the logged op batches. Invoking this method will clean the log.+ */++ (NSArray *)obtainAndCleanOpBatchLog;","You're right, the best we can do is put it under `GRPCClient/testing/` or `GRPCClient/internal_testing/`, and `NSLog` on `enableOpBatchLog` and `obtainAndCleanOpBatchLog` that these should be used only for testing gRPC itself. And let's make it very clear in the docs of each of these methods that they're not part of the public interface of the library.",
5120183,jcanizales,https://api.github.com/repos/grpc/grpc/pulls/9247,100464502,2017-02-10T03:12:45Z,src/objective-c/GRPCClient/internal_testing/GRPCCall+Tests.h,"@@ -45,6 +45,9 @@  *  * Must be called before any gRPC call to that host is made. It's illegal to pass the same host to  * more than one invocation of the methods of this category.+ *+ * This function is for internal testing of gRPC only. It is not part of gRPC's public interface.+ * Do not use in production. To enable, set the preprocessor flag GRPC_TEST_OBJC.","No, not these! :D These are for users to test their apps, not only for us. These are already part of the public interface too: even if we wanted to hide them the only way would be to deprecate them and keep them until 2.0.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/9699,100955998,2017-02-14T03:53:27Z,tools/run_tests/run_microbenchmark.py,"@@ -133,11 +133,9 @@ def collect_perf(bm_name, args):                            'bins/mutrace/%s' % bm_name,                            '--benchmark_filter=^%s$' % line,                            '--benchmark_min_time=20'])-    with open('bm.perf', 'w') as f:-      f.write(subprocess.check_output(['sudo', 'perf', 'script', '-i', 'perf.data']))-    with open('bm.folded', 'w') as f:-      f.write(subprocess.check_output([-          '%s/stackcollapse-perf.pl' % flamegraph_dir, 'bm.perf']))+    subprocess.check_call(['sudo', 'perf', 'script', '-i', 'perf.data', '>', 'bm.perf'], shell=True)",Probably not causing a problem but does perf here need to be ran under sudo?I think shouldn't have to after the setup in https://github.com/grpc/grpc/blob/master/tools/gce/linux_performance_worker_init.sh#L157 (unless using kernel probes).,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/9699,100956031,2017-02-14T03:53:51Z,tools/run_tests/run_microbenchmark.py,"@@ -133,11 +133,9 @@ def collect_perf(bm_name, args):                            'bins/mutrace/%s' % bm_name,                            '--benchmark_filter=^%s$' % line,                            '--benchmark_min_time=20'])-    with open('bm.perf', 'w') as f:-      f.write(subprocess.check_output(['sudo', 'perf', 'script', '-i', 'perf.data']))-    with open('bm.folded', 'w') as f:-      f.write(subprocess.check_output([-          '%s/stackcollapse-perf.pl' % flamegraph_dir, 'bm.perf']))+    subprocess.check_call(['sudo', 'perf', 'script', '-i', 'perf.data', '>', 'bm.perf'], shell=True)+    subprocess.check_call([",May be able to use https://github.com/grpc/grpc/blob/master/tools/run_tests/performance/process_local_perf_flamegraphs.sh?,
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/9683,101087877,2017-02-14T17:05:54Z,src/core/lib/iomgr/error.h,"@@ -136,13 +136,15 @@ typedef enum {   GRPC_ERROR_TIME_CREATED, } grpc_error_times; + /// The following ""special"" errors can be propagated without allocating memory. /// They are always even so that other code (particularly combiner locks) can /// safely use the lower bit for themselves.  #define GRPC_ERROR_NONE ((grpc_error *)NULL) #define GRPC_ERROR_OOM ((grpc_error *)2) #define GRPC_ERROR_CANCELLED ((grpc_error *)4)+#define GRPC_ERROR_INTERNAL ((grpc_error *)8)",Yes - but then we ideally should not have any 'special' error like `(grpc_error *) 1` in future; because we would not be able to distinguish between a legitimate error versus CLOSURE_SHUTDOWN_BIT if `fd_shutdown` is called with `why == (grpc_error *) 1`.  This is not a big deal (its just that we miss reporting the correct error for debugging purposes) but I felt that adding a special error was the correct way to do this.I can rename `GRPC_ERROR_INTERNAL` to `GRPC_FD_SHUTDOWN` and make it `(grpc_error *) 1` if you prefer that (It was my first choice but something stopped me :) ),
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/9683,101088704,2017-02-14T17:09:29Z,src/core/lib/iomgr/ev_epoll_linux.c,"@@ -1060,101 +1095,182 @@ static void fd_orphan(grpc_exec_ctx *exec_ctx, grpc_fd *fd,   GRPC_ERROR_UNREF(error); } -static grpc_error *fd_shutdown_error(grpc_fd *fd) {-  if (!fd->shutdown) {-    return GRPC_ERROR_NONE;-  } else {-    return GRPC_ERROR_CREATE_REFERENCING(""FD shutdown"", &fd->shutdown_error, 1);+static void notify_on(grpc_exec_ctx *exec_ctx, grpc_fd *fd, gpr_atm *state,+                      grpc_closure *closure) {+  bool is_done = false;+  while (!is_done) {","ok - what you wrote does look a bit cleaner. I'll do it.  FWIW, I am very scared of having `return` statements in between the functions and always strive to have just one `return` at the end (and sometimes an extra `return`  at the beginning after some initial-condition validations)",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/9683,101089522,2017-02-14T17:12:55Z,src/core/lib/iomgr/error.h,"@@ -136,13 +136,15 @@ typedef enum {   GRPC_ERROR_TIME_CREATED, } grpc_error_times; + /// The following ""special"" errors can be propagated without allocating memory. /// They are always even so that other code (particularly combiner locks) can /// safely use the lower bit for themselves.  #define GRPC_ERROR_NONE ((grpc_error *)NULL) #define GRPC_ERROR_OOM ((grpc_error *)2) #define GRPC_ERROR_CANCELLED ((grpc_error *)4)+#define GRPC_ERROR_INTERNAL ((grpc_error *)8)",Happy for that comment to be updated to list the files that depend on this property.,
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/9696,101105527,2017-02-14T18:25:10Z,src/core/lib/iomgr/network_status_tracker.c,"@@ -40,58 +40,72 @@ typedef struct endpoint_ll_node {   struct endpoint_ll_node *next; } endpoint_ll_node; -static endpoint_ll_node *head = NULL;-static gpr_mu g_endpoint_mutex;+typedef struct {+  gpr_mu mu;+  endpoint_ll_node *head;+} shard_type;++#define SHARD_COUNT 32+static shard_type g_shards[SHARD_COUNT];  void grpc_network_status_shutdown(void) {-  if (head != NULL) {-    gpr_log(GPR_ERROR,-            ""Memory leaked as not all network endpoints were shut down"");+  for (size_t i = 0; i < SHARD_COUNT; i++) {+    shard_type *s = &g_shards[i];+    if (s->head != NULL) {+      gpr_log(GPR_ERROR,+              ""Memory leaked as not all network endpoints were shut down"");+    }   }-  gpr_mu_destroy(&g_endpoint_mutex); }  void grpc_network_status_init(void) {-  gpr_mu_init(&g_endpoint_mutex);+  for (size_t i = 0; i < SHARD_COUNT; i++) {+    shard_type *s = &g_shards[i];+    gpr_mu_init(&s->mu);+    s->head = NULL;+  }   // TODO(makarandd): Install callback with OS to monitor network status. }  void grpc_destroy_network_status_monitor() {-  for (endpoint_ll_node *curr = head; curr != NULL;) {-    endpoint_ll_node *next = curr->next;-    gpr_free(curr);-    curr = next;+  for (size_t i = 0; i < SHARD_COUNT; i++) {+    shard_type *s = &g_shards[i];+    gpr_mu_destroy(&s->mu);   }-  gpr_mu_destroy(&g_endpoint_mutex);+}++// pointer hash function copied from timer_generic.c","Can I (beg perhaps) that this be moved to useful.h... it's getting duplicated around a bit too much.```c#define GPR_HASH_POINTER(x, range) (((x) >> 4) ^ ((x) >> 9) ^ ((x) >> 14)) % (range)```",
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/9648,101220689,2017-02-15T08:11:39Z,include/grpc++/test/server_context_test_spouse.h,"@@ -48,10 +48,22 @@ class ServerContextTestSpouse {    // Inject client metadata to the ServerContext for the test. The test spouse   // must be alive when ServerContext::client_metadata is called.-  void AddClientMetadata(const grpc::string& key, const grpc::string& value);+  void AddClientMetadata(const grpc::string& key, const grpc::string& value) {+    client_metadata_storage_.insert(+        std::pair<grpc::string, grpc::string>(key, value));+    ctx_->client_metadata_.map()->clear();+    for (auto iter = client_metadata_storage_.begin();+         iter != client_metadata_storage_.end(); ++iter) {+      ctx_->client_metadata_.map()->insert(+          std::pair<grpc::string_ref, grpc::string_ref>(iter->first.c_str(),+                                                        iter->second.c_str()));",I think for the value you want to create string_ref with c_str and size since there could be null in the middle.,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/9648,101353712,2017-02-15T18:53:08Z,include/grpc++/test/server_context_test_spouse.h,"@@ -48,10 +48,22 @@ class ServerContextTestSpouse {    // Inject client metadata to the ServerContext for the test. The test spouse   // must be alive when ServerContext::client_metadata is called.-  void AddClientMetadata(const grpc::string& key, const grpc::string& value);+  void AddClientMetadata(const grpc::string& key, const grpc::string& value) {+    client_metadata_storage_.insert(+        std::pair<grpc::string, grpc::string>(key, value));+    ctx_->client_metadata_.map()->clear();+    for (auto iter = client_metadata_storage_.begin();+         iter != client_metadata_storage_.end(); ++iter) {+      ctx_->client_metadata_.map()->insert(+          std::pair<grpc::string_ref, grpc::string_ref>(iter->first.c_str(),+                                                        iter->second.c_str()));","with `data()`, not `c_str()`, but yes good point. Done.",
10135909,dklempner,https://api.github.com/repos/grpc/grpc/pulls/9683,101385347,2017-02-15T21:19:09Z,src/core/lib/iomgr/ev_epoll_linux.c,"@@ -1060,101 +1104,181 @@ static void fd_orphan(grpc_exec_ctx *exec_ctx, grpc_fd *fd,   GRPC_ERROR_UNREF(error); } -static grpc_error *fd_shutdown_error(grpc_fd *fd) {-  if (!fd->shutdown) {-    return GRPC_ERROR_NONE;-  } else {-    return GRPC_ERROR_CREATE_REFERENCING(""FD shutdown"", &fd->shutdown_error, 1);+static void notify_on(grpc_exec_ctx *exec_ctx, grpc_fd *fd, gpr_atm *state,+                      grpc_closure *closure) {+  while (true) {+    /* Fast-path: CLOSURE_NOT_READY -> <closure> */+    if (gpr_atm_acq_cas(state, CLOSURE_NOT_READY, (gpr_atm)closure)) {+      return; /* Fast-path successful. Return */+    }++    /* Slowpath */+    gpr_atm curr = gpr_atm_acq_load(state);+    switch (curr) {+      case CLOSURE_NOT_READY: {+        break; /* retry */+      }++      case CLOSURE_READY: {+        /* Change the state to CLOSURE_NOT_READY.+             If successful: Schedule the closure+             If not: Most likely the state transitioned to CLOSURE_NOT_READY.+                     Retry the fast-path again */+        if (gpr_atm_rel_cas(state, CLOSURE_READY, CLOSURE_NOT_READY)) {+          grpc_closure_sched(exec_ctx, closure, GRPC_ERROR_NONE);+          return; /* Slow-path successful. Return */+        }++        break; /* retry */+      }++      default: {+        /* 'curr' is either a closure or the fd is shutdown(in which case 'curr'+           contains a pointer to the shutdown-error). If the fd is shutdown,+           schedule the closure with the shutdown error */+        if ((curr & FD_SHUTDOWN_BIT) > 0) {+          grpc_error *shutdown_err = (grpc_error *)(curr & ~FD_SHUTDOWN_BIT);+          grpc_closure_sched(+              exec_ctx, closure,+              GRPC_ERROR_CREATE_REFERENCING(""FD Shutdown"", &shutdown_err, 1));+          return;+        }++        /* There is already a closure!. This indicates a bug in the code */+        gpr_log(GPR_ERROR,+                ""notify_on called with a previous callback still pending"");+        abort();+      }+    }   }++  GPR_UNREACHABLE_CODE(return ); } -static void notify_on_locked(grpc_exec_ctx *exec_ctx, grpc_fd *fd,-                             grpc_closure **st, grpc_closure *closure) {-  if (fd->shutdown) {-    grpc_closure_sched(exec_ctx, closure, GRPC_ERROR_CREATE(""FD shutdown""));-  } else if (*st == CLOSURE_NOT_READY) {-    /* not ready ==> switch to a waiting state by setting the closure */-    *st = closure;-  } else if (*st == CLOSURE_READY) {-    /* already ready ==> queue the closure to run immediately */-    *st = CLOSURE_NOT_READY;-    grpc_closure_sched(exec_ctx, closure, fd_shutdown_error(fd));-  } else {-    /* upcallptr was set to a different closure.  This is an error! */-    gpr_log(GPR_ERROR,-            ""User called a notify_on function with a previous callback still ""-            ""pending"");-    abort();+static void set_shutdown(grpc_exec_ctx *exec_ctx, grpc_fd *fd, gpr_atm *state,+                         grpc_error *shutdown_err) {+  /* Try the fast-path first (i.e expect the current value to be+     CLOSURE_NOT_READY */+  gpr_atm curr = CLOSURE_NOT_READY;+  gpr_atm new_state = (gpr_atm)shutdown_err | FD_SHUTDOWN_BIT;",I suspect that FD_SHUTDOWN_BIT wants to leave the atomic and could almost certainly survive as a separate gpr_atm as long as you forced the state to READY once.It might require an extra load but it would eliminate the need to CAS on the CLOSURE_READY path above.,
10135909,dklempner,https://api.github.com/repos/grpc/grpc/pulls/9683,101386113,2017-02-15T21:22:58Z,src/core/lib/iomgr/ev_epoll_linux.c,"@@ -1060,101 +1104,181 @@ static void fd_orphan(grpc_exec_ctx *exec_ctx, grpc_fd *fd,   GRPC_ERROR_UNREF(error); } -static grpc_error *fd_shutdown_error(grpc_fd *fd) {-  if (!fd->shutdown) {-    return GRPC_ERROR_NONE;-  } else {-    return GRPC_ERROR_CREATE_REFERENCING(""FD shutdown"", &fd->shutdown_error, 1);+static void notify_on(grpc_exec_ctx *exec_ctx, grpc_fd *fd, gpr_atm *state,+                      grpc_closure *closure) {+  while (true) {+    /* Fast-path: CLOSURE_NOT_READY -> <closure> */+    if (gpr_atm_acq_cas(state, CLOSURE_NOT_READY, (gpr_atm)closure)) {+      return; /* Fast-path successful. Return */+    }++    /* Slowpath */+    gpr_atm curr = gpr_atm_acq_load(state);+    switch (curr) {+      case CLOSURE_NOT_READY: {+        break; /* retry */+      }++      case CLOSURE_READY: {+        /* Change the state to CLOSURE_NOT_READY.+             If successful: Schedule the closure+             If not: Most likely the state transitioned to CLOSURE_NOT_READY.+                     Retry the fast-path again */+        if (gpr_atm_rel_cas(state, CLOSURE_READY, CLOSURE_NOT_READY)) {+          grpc_closure_sched(exec_ctx, closure, GRPC_ERROR_NONE);+          return; /* Slow-path successful. Return */+        }++        break; /* retry */+      }++      default: {+        /* 'curr' is either a closure or the fd is shutdown(in which case 'curr'+           contains a pointer to the shutdown-error). If the fd is shutdown,+           schedule the closure with the shutdown error */+        if ((curr & FD_SHUTDOWN_BIT) > 0) {+          grpc_error *shutdown_err = (grpc_error *)(curr & ~FD_SHUTDOWN_BIT);+          grpc_closure_sched(+              exec_ctx, closure,+              GRPC_ERROR_CREATE_REFERENCING(""FD Shutdown"", &shutdown_err, 1));+          return;+        }++        /* There is already a closure!. This indicates a bug in the code */+        gpr_log(GPR_ERROR,+                ""notify_on called with a previous callback still pending"");+        abort();+      }+    }   }++  GPR_UNREACHABLE_CODE(return ); } -static void notify_on_locked(grpc_exec_ctx *exec_ctx, grpc_fd *fd,-                             grpc_closure **st, grpc_closure *closure) {-  if (fd->shutdown) {-    grpc_closure_sched(exec_ctx, closure, GRPC_ERROR_CREATE(""FD shutdown""));-  } else if (*st == CLOSURE_NOT_READY) {-    /* not ready ==> switch to a waiting state by setting the closure */-    *st = closure;-  } else if (*st == CLOSURE_READY) {-    /* already ready ==> queue the closure to run immediately */-    *st = CLOSURE_NOT_READY;-    grpc_closure_sched(exec_ctx, closure, fd_shutdown_error(fd));-  } else {-    /* upcallptr was set to a different closure.  This is an error! */-    gpr_log(GPR_ERROR,-            ""User called a notify_on function with a previous callback still ""-            ""pending"");-    abort();+static void set_shutdown(grpc_exec_ctx *exec_ctx, grpc_fd *fd, gpr_atm *state,","This looks sufficiently similar to notify_on that I suspect it wants to be merged, unless it gains a substantially different algorithm.",
10135909,dklempner,https://api.github.com/repos/grpc/grpc/pulls/9683,101388586,2017-02-15T21:34:52Z,src/core/lib/iomgr/ev_epoll_linux.c,"@@ -1060,101 +1104,181 @@ static void fd_orphan(grpc_exec_ctx *exec_ctx, grpc_fd *fd,   GRPC_ERROR_UNREF(error); } -static grpc_error *fd_shutdown_error(grpc_fd *fd) {-  if (!fd->shutdown) {-    return GRPC_ERROR_NONE;-  } else {-    return GRPC_ERROR_CREATE_REFERENCING(""FD shutdown"", &fd->shutdown_error, 1);+static void notify_on(grpc_exec_ctx *exec_ctx, grpc_fd *fd, gpr_atm *state,+                      grpc_closure *closure) {+  while (true) {+    /* Fast-path: CLOSURE_NOT_READY -> <closure> */+    if (gpr_atm_acq_cas(state, CLOSURE_NOT_READY, (gpr_atm)closure)) {+      return; /* Fast-path successful. Return */+    }++    /* Slowpath */+    gpr_atm curr = gpr_atm_acq_load(state);+    switch (curr) {+      case CLOSURE_NOT_READY: {+        break; /* retry */+      }++      case CLOSURE_READY: {+        /* Change the state to CLOSURE_NOT_READY.+             If successful: Schedule the closure+             If not: Most likely the state transitioned to CLOSURE_NOT_READY.+                     Retry the fast-path again */+        if (gpr_atm_rel_cas(state, CLOSURE_READY, CLOSURE_NOT_READY)) {+          grpc_closure_sched(exec_ctx, closure, GRPC_ERROR_NONE);+          return; /* Slow-path successful. Return */+        }++        break; /* retry */+      }++      default: {+        /* 'curr' is either a closure or the fd is shutdown(in which case 'curr'+           contains a pointer to the shutdown-error). If the fd is shutdown,+           schedule the closure with the shutdown error */+        if ((curr & FD_SHUTDOWN_BIT) > 0) {+          grpc_error *shutdown_err = (grpc_error *)(curr & ~FD_SHUTDOWN_BIT);+          grpc_closure_sched(+              exec_ctx, closure,+              GRPC_ERROR_CREATE_REFERENCING(""FD Shutdown"", &shutdown_err, 1));+          return;+        }++        /* There is already a closure!. This indicates a bug in the code */+        gpr_log(GPR_ERROR,+                ""notify_on called with a previous callback still pending"");+        abort();+      }+    }   }++  GPR_UNREACHABLE_CODE(return ); } -static void notify_on_locked(grpc_exec_ctx *exec_ctx, grpc_fd *fd,-                             grpc_closure **st, grpc_closure *closure) {-  if (fd->shutdown) {-    grpc_closure_sched(exec_ctx, closure, GRPC_ERROR_CREATE(""FD shutdown""));-  } else if (*st == CLOSURE_NOT_READY) {-    /* not ready ==> switch to a waiting state by setting the closure */-    *st = closure;-  } else if (*st == CLOSURE_READY) {-    /* already ready ==> queue the closure to run immediately */-    *st = CLOSURE_NOT_READY;-    grpc_closure_sched(exec_ctx, closure, fd_shutdown_error(fd));-  } else {-    /* upcallptr was set to a different closure.  This is an error! */-    gpr_log(GPR_ERROR,-            ""User called a notify_on function with a previous callback still ""-            ""pending"");-    abort();+static void set_shutdown(grpc_exec_ctx *exec_ctx, grpc_fd *fd, gpr_atm *state,+                         grpc_error *shutdown_err) {+  /* Try the fast-path first (i.e expect the current value to be+     CLOSURE_NOT_READY */+  gpr_atm curr = CLOSURE_NOT_READY;+  gpr_atm new_state = (gpr_atm)shutdown_err | FD_SHUTDOWN_BIT;++  while (true) {+    if (gpr_atm_acq_cas(state, curr, new_state)) {+      return; /* Fast-path successful. Return */+    }++    /* Fallback to slowpath */+    curr = gpr_atm_acq_load(state);+    switch (curr) {+      case CLOSURE_READY: {+        break; /* retry */+      }++      case CLOSURE_NOT_READY: {+        break; /* retry */+      }++      default: {+        /* 'curr' is either a closure or the fd is already shutdown */++        /* If fd is already shutdown, we are done */+        if ((curr & FD_SHUTDOWN_BIT) > 0) {+          return;+        }++        /* Fd is not shutdown. Schedule the closure and move the state to+           shutdown state */+        if (gpr_atm_rel_cas(state, curr, new_state)) {+          grpc_closure_sched(+              exec_ctx, (grpc_closure *)curr,+              GRPC_ERROR_CREATE_REFERENCING(""FD Shutdown"", &shutdown_err, 1));+          return;+        }++        /* 'curr' was a closure but now changed to a different state. We will+          have to retry */+        break;+      }+    }   }++  GPR_UNREACHABLE_CODE(return ); } -/* returns 1 if state becomes not ready */-static int set_ready_locked(grpc_exec_ctx *exec_ctx, grpc_fd *fd,-                            grpc_closure **st) {-  if (*st == CLOSURE_READY) {-    /* duplicate ready ==> ignore */-    return 0;-  } else if (*st == CLOSURE_NOT_READY) {-    /* not ready, and not waiting ==> flag ready */-    *st = CLOSURE_READY;-    return 0;-  } else {-    /* waiting ==> queue closure */-    grpc_closure_sched(exec_ctx, *st, fd_shutdown_error(fd));-    *st = CLOSURE_NOT_READY;-    return 1;+static void set_ready(grpc_exec_ctx *exec_ctx, grpc_fd *fd, gpr_atm *state) {+  /* Try the fast-path first (i.e expect the current value to be+   * CLOSURE_NOT_READY */",I'm surprised that this would be the fast path. Do you have data to back that up?,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/9736,101408936,2017-02-15T23:18:13Z,tools/distrib/yapf_code.sh,"@@ -53,7 +53,7 @@ for dir in $DIRS; do   tempdir=`mktemp -d`   cp -RT $dir $tempdir   $PYTHON -m yapf -i -r -p $exclusion_args $dir-  if ! diff -rq $dir $tempdir; then+  if ! diff -r $dir $tempdir; then","1. Wouldn't we like to learn about all the problems in a single test run rather than learn about problems in one directory, fix them, learn about problems in another directory, fix them, learn about problems in a third directory, fix them, and so on?2. How certain are we that we want to keep the temporary directory contents?",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/9736,101410325,2017-02-15T23:26:52Z,tools/distrib/yapf_code.sh,"@@ -53,7 +53,7 @@ for dir in $DIRS; do   tempdir=`mktemp -d`   cp -RT $dir $tempdir   $PYTHON -m yapf -i -r -p $exclusion_args $dir-  if ! diff -rq $dir $tempdir; then+  if ! diff -r $dir $tempdir; then","I did debate the former point with myself on the pylint_code.sh case, and eventually decided on a quick exit.  I like quick exits as, in principle, the more you stay in a test after a failure is detected, the greater the risk of a potential bug in the test script incorrectly masking the output, and since the test does not seem to generate a useful summary that shows specifically which diff command failed, the user will likely have to manually investigate after noticing a yapf test failure anyway. (Of course your point 2 was not applicable in the pylint case, as it does not generate temporary data, but cleaning up is possible in the branch). [In any case, I think either way is fine.]",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/9736,101412923,2017-02-15T23:44:04Z,tools/distrib/yapf_code.sh,"@@ -53,7 +53,7 @@ for dir in $DIRS; do   tempdir=`mktemp -d`   cp -RT $dir $tempdir   $PYTHON -m yapf -i -r -p $exclusion_args $dir-  if ! diff -rq $dir $tempdir; then+  if ! diff -r $dir $tempdir; then","I agree with your reasoning about successive steps of a test. Here all the directories seem like one single test step, like a single-instruction-multiple-data kind of thing. :smile:",
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/9683,101431716,2017-02-16T02:09:47Z,src/core/lib/iomgr/ev_epoll_linux.c,"@@ -1060,101 +1104,181 @@ static void fd_orphan(grpc_exec_ctx *exec_ctx, grpc_fd *fd,   GRPC_ERROR_UNREF(error); } -static grpc_error *fd_shutdown_error(grpc_fd *fd) {-  if (!fd->shutdown) {-    return GRPC_ERROR_NONE;-  } else {-    return GRPC_ERROR_CREATE_REFERENCING(""FD shutdown"", &fd->shutdown_error, 1);+static void notify_on(grpc_exec_ctx *exec_ctx, grpc_fd *fd, gpr_atm *state,+                      grpc_closure *closure) {+  while (true) {+    /* Fast-path: CLOSURE_NOT_READY -> <closure> */+    if (gpr_atm_acq_cas(state, CLOSURE_NOT_READY, (gpr_atm)closure)) {+      return; /* Fast-path successful. Return */+    }++    /* Slowpath */+    gpr_atm curr = gpr_atm_acq_load(state);+    switch (curr) {+      case CLOSURE_NOT_READY: {+        break; /* retry */+      }++      case CLOSURE_READY: {+        /* Change the state to CLOSURE_NOT_READY.+             If successful: Schedule the closure+             If not: Most likely the state transitioned to CLOSURE_NOT_READY.+                     Retry the fast-path again */+        if (gpr_atm_rel_cas(state, CLOSURE_READY, CLOSURE_NOT_READY)) {+          grpc_closure_sched(exec_ctx, closure, GRPC_ERROR_NONE);+          return; /* Slow-path successful. Return */+        }++        break; /* retry */+      }++      default: {+        /* 'curr' is either a closure or the fd is shutdown(in which case 'curr'+           contains a pointer to the shutdown-error). If the fd is shutdown,+           schedule the closure with the shutdown error */+        if ((curr & FD_SHUTDOWN_BIT) > 0) {+          grpc_error *shutdown_err = (grpc_error *)(curr & ~FD_SHUTDOWN_BIT);+          grpc_closure_sched(+              exec_ctx, closure,+              GRPC_ERROR_CREATE_REFERENCING(""FD Shutdown"", &shutdown_err, 1));+          return;+        }++        /* There is already a closure!. This indicates a bug in the code */+        gpr_log(GPR_ERROR,+                ""notify_on called with a previous callback still pending"");+        abort();+      }+    }   }++  GPR_UNREACHABLE_CODE(return ); } -static void notify_on_locked(grpc_exec_ctx *exec_ctx, grpc_fd *fd,-                             grpc_closure **st, grpc_closure *closure) {-  if (fd->shutdown) {-    grpc_closure_sched(exec_ctx, closure, GRPC_ERROR_CREATE(""FD shutdown""));-  } else if (*st == CLOSURE_NOT_READY) {-    /* not ready ==> switch to a waiting state by setting the closure */-    *st = closure;-  } else if (*st == CLOSURE_READY) {-    /* already ready ==> queue the closure to run immediately */-    *st = CLOSURE_NOT_READY;-    grpc_closure_sched(exec_ctx, closure, fd_shutdown_error(fd));-  } else {-    /* upcallptr was set to a different closure.  This is an error! */-    gpr_log(GPR_ERROR,-            ""User called a notify_on function with a previous callback still ""-            ""pending"");-    abort();+static void set_shutdown(grpc_exec_ctx *exec_ctx, grpc_fd *fd, gpr_atm *state,",Yes they could and I considered doing it before. The resulting function looked a bit too complex and I thought its better to split them back to two readable functions (`set_ready` and `set_shutdown` ).,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/9739,101569555,2017-02-16T16:51:37Z,tools/run_tests/python_utils/start_port_server.py,"@@ -50,8 +51,7 @@ def start_port_server(port_server_port):     print('detected port server running version %d' % version)     running = True   except Exception as e:-    print('failed to detect port server: %s' % sys.exc_info()[0])-    print(e.strerror)+    print('failed to detect port server: %s' % e)",Why is `print` better here than `logging.exception`?,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/9739,101596472,2017-02-16T18:48:08Z,tools/run_tests/python_utils/start_port_server.py,"@@ -111,15 +112,15 @@ def start_port_server(port_server_port):       try:         urllib.request.urlopen('http://localhost:%d/get' % port_server_port,                         timeout=1).read()-        print('port server is up and ready')+        logging.info('port server is up and ready')         break       except socket.timeout:-        print('waiting for port_server: timeout')+        logging.exception('waiting for port_server: timeout')         traceback.print_exc();",I think this is no longer necessary; I think the call to `logging.exception` prints this information to the log.,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/9739,101606996,2017-02-16T19:34:09Z,tools/run_tests/python_utils/start_port_server.py,"@@ -92,39 +92,37 @@ def start_port_server(port_server_port):     waits = 0     while True:       if waits > 10:-        print('killing port server due to excessive start up waits')+        logging.warning('killing port server due to excessive start up waits')         port_server.kill()       if port_server.poll() is not None:-        print('port_server failed to start')+        logging.error('port_server failed to start')         # try one final time: maybe another build managed to start one         time.sleep(1)         try:           urllib.request.urlopen('http://localhost:%d/get' % port_server_port,                           timeout=1).read()-          print('last ditch attempt to contact port server succeeded')+          logging.info('last ditch attempt to contact port server succeeded')           break         except:-          traceback.print_exc()+          logging.exception()",`TypeError: exception() takes at least 1 argument (0 given)` - what message is worth emitting here?,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/9739,101607119,2017-02-16T19:34:41Z,tools/run_tests/python_utils/start_port_server.py,"@@ -92,39 +92,37 @@ def start_port_server(port_server_port):     waits = 0     while True:       if waits > 10:-        print('killing port server due to excessive start up waits')+        logging.warning('killing port server due to excessive start up waits')         port_server.kill()       if port_server.poll() is not None:-        print('port_server failed to start')+        logging.error('port_server failed to start')         # try one final time: maybe another build managed to start one         time.sleep(1)         try:           urllib.request.urlopen('http://localhost:%d/get' % port_server_port,                           timeout=1).read()-          print('last ditch attempt to contact port server succeeded')+          logging.info('last ditch attempt to contact port server succeeded')           break         except:-          traceback.print_exc()+          logging.exception()           port_log = open(logfile, 'r').read()           print(port_log)           sys.exit(1)       try:         urllib.request.urlopen('http://localhost:%d/get' % port_server_port,                         timeout=1).read()-        print('port server is up and ready')+        logging.info('port server is up and ready')         break       except socket.timeout:-        print('waiting for port_server: timeout')-        traceback.print_exc();+        logging.exception('while waiting for port_server')         time.sleep(1)         waits += 1       except urllib.error.URLError:-        print('waiting for port_server: urlerror')-        traceback.print_exc();+        logging.exception('while waiting for port_server')         time.sleep(1)         waits += 1       except:-        traceback.print_exc()+        logging.exception()",`TypeError: exception() takes at least 1 argument (0 given)` - what message is worth emitting here?,
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/9683,101649919,2017-02-16T23:05:26Z,src/core/lib/iomgr/ev_epoll_linux.c,"@@ -180,8 +217,10 @@ static void fd_unref(grpc_fd *fd); static void fd_global_init(void); static void fd_global_shutdown(void); -#define CLOSURE_NOT_READY ((grpc_closure *)0)-#define CLOSURE_READY ((grpc_closure *)1)+#define CLOSURE_NOT_READY ((gpr_atm)0)+#define CLOSURE_READY ((gpr_atm)1)",ouch!! - that is bad. thanks for catching this,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/9807,102322760,2017-02-21T21:30:06Z,test/cpp/qps/client_sync.cc,"@@ -170,8 +172,16 @@ class SynchronousStreamingClient final : public SynchronousClient {     if (stream_[thread_idx]->Write(request_) &&         stream_[thread_idx]->Read(&responses_[thread_idx])) {       entry->set_value((UsageTimer::Now() - start) * 1e9);+      // don't set the status since there isn't one yet       return true;     }+    Status s = stream_[thread_idx]->Finish();+    // don't set the value since the stream is failed and shouldn't be timed+    entry->set_status(s.error_code());+    if (!s.ok()) {+      gpr_log(GPR_ERROR, ""Stream %zu received an error %s"", thread_idx,",I think windows doesn't support `%zu`. We usually end up casting `size_t` to `unsigned long`. :/,
17325098,makdharma,https://api.github.com/repos/grpc/grpc/pulls/9776,102347495,2017-02-21T23:32:50Z,test/http2_test/test_data_frame_padding.py,"@@ -0,0 +1,113 @@+# Copyright 2016, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.++import http2_base_server+import logging+import messages_pb2++class TestDataFramePadding(object):+  """"""+    In response to an incoming request, this test sends headers, followed by+    data, followed by a reset stream frame. Client asserts that the RPC failed.+    Client needs to deliver the complete message to the application layer.+  """"""+  def __init__(self, use_padding=True):+    self._base_server = http2_base_server.H2ProtocolBaseServer()+    self._base_server._handlers['DataReceived'] = self.on_data_received+    self._base_server._handlers['WindowUpdated'] = self.on_window_update+    self._base_server._handlers['RequestReceived'] = self.on_request_received+    self._base_server._handlers['SendDone'] = self.on_send_done+    self._base_server._handlers['ConnectionMade'] = self.on_connection_made+    self._base_server._handlers['ConnectionLost'] = self.on_connection_lost+    self._serving_active_connection = True+    self._reset_connection_state()+    if use_padding:+      self._pad_length = 255+    else:+      self._pad_length = None++  def get_base_server(self):+    return self._base_server++  def _reset_connection_state(self):+    # maps stream ids to total flow control updates received+    self._total_updates = {}+    self._total_updates[0] = 0+    self._read_chunk_size = 5+    # currently active streams with connections sent on them+    self._cur_sending = []++  def on_connection_made(self):+    self._base_server.on_connection_made_default()+    self._reset_connection_state()+    assert not self._serving_active_connection+    self._serving_active_connection = True++  def on_connection_lost(self, reason):+    self._base_server.on_connection_lost(reason)+    self._serving_active_connection = False++  def on_data_received(self, event):+    logging.info('on data received. Stream id: %d. Data length: %d' % (event.stream_id, len(event.data)))+    self._base_server.on_data_received_default(event)+    if len(event.data) == 0:+      return+    sr = self._base_server.parse_received_data(event.stream_id)+    stream_bytes = ''+    # Check if full grpc msg has been read into the recv buffer yet+    if sr:+      response_data = self._base_server.default_response_data(sr.response_size)+      logging.info('Stream id: %d. total resp size: %d' % (event.stream_id, len(response_data)))+      assert event.stream_id not in self._cur_sending+      self._cur_sending.append(event.stream_id)+      self._ready_to_send = True+      self._base_server.setup_send(response_data , event.stream_id, pad_length=self._pad_length, read_chunk_size=self._read_chunk_size)++  def on_send_done(self, stream_id):+    assert stream_id in self._cur_sending+    self._cur_sending.remove(stream_id)+    self._base_server.on_send_done_default(stream_id)++  def on_request_received(self, event):+    self._base_server.on_request_received_default(event)+    logging.info('on request received. Stream id: %s.' % event.stream_id)+    self._total_updates[event.stream_id] = 0++  def on_window_update(self, event):+    logging.info('on window update. Stream id: %s. Delta: %s' % (event.stream_id, event.delta))+    self._total_updates[event.stream_id] += event.delta+    total = self._total_updates[event.stream_id]+    logging.info('... - total updates for stream %d : %d' % (event.stream_id, total))+    p = []+    if event.stream_id == 0:+      p = self._cur_sending+    else:+      p = [event.stream_id]+    for p in self._cur_sending:",You create a list named 'p' but reuse the name again. What is the purpose of assigning anything to p before the for loop?,
17325098,makdharma,https://api.github.com/repos/grpc/grpc/pulls/9776,102347560,2017-02-21T23:33:14Z,test/http2_test/test_data_frame_padding.py,"@@ -0,0 +1,113 @@+# Copyright 2016, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.++import http2_base_server+import logging+import messages_pb2++class TestDataFramePadding(object):+  """"""+    In response to an incoming request, this test sends headers, followed by+    data, followed by a reset stream frame. Client asserts that the RPC failed.+    Client needs to deliver the complete message to the application layer.+  """"""+  def __init__(self, use_padding=True):+    self._base_server = http2_base_server.H2ProtocolBaseServer()+    self._base_server._handlers['DataReceived'] = self.on_data_received+    self._base_server._handlers['WindowUpdated'] = self.on_window_update+    self._base_server._handlers['RequestReceived'] = self.on_request_received+    self._base_server._handlers['SendDone'] = self.on_send_done+    self._base_server._handlers['ConnectionMade'] = self.on_connection_made+    self._base_server._handlers['ConnectionLost'] = self.on_connection_lost+    self._serving_active_connection = True+    self._reset_connection_state()+    if use_padding:+      self._pad_length = 255+    else:+      self._pad_length = None++  def get_base_server(self):+    return self._base_server++  def _reset_connection_state(self):+    # maps stream ids to total flow control updates received+    self._total_updates = {}+    self._total_updates[0] = 0+    self._read_chunk_size = 5+    # currently active streams with connections sent on them+    self._cur_sending = []++  def on_connection_made(self):+    self._base_server.on_connection_made_default()+    self._reset_connection_state()+    assert not self._serving_active_connection+    self._serving_active_connection = True++  def on_connection_lost(self, reason):+    self._base_server.on_connection_lost(reason)+    self._serving_active_connection = False++  def on_data_received(self, event):+    logging.info('on data received. Stream id: %d. Data length: %d' % (event.stream_id, len(event.data)))+    self._base_server.on_data_received_default(event)+    if len(event.data) == 0:+      return+    sr = self._base_server.parse_received_data(event.stream_id)+    stream_bytes = ''+    # Check if full grpc msg has been read into the recv buffer yet+    if sr:+      response_data = self._base_server.default_response_data(sr.response_size)+      logging.info('Stream id: %d. total resp size: %d' % (event.stream_id, len(response_data)))+      assert event.stream_id not in self._cur_sending+      self._cur_sending.append(event.stream_id)+      self._ready_to_send = True+      self._base_server.setup_send(response_data , event.stream_id, pad_length=self._pad_length, read_chunk_size=self._read_chunk_size)++  def on_send_done(self, stream_id):+    assert stream_id in self._cur_sending+    self._cur_sending.remove(stream_id)+    self._base_server.on_send_done_default(stream_id)++  def on_request_received(self, event):+    self._base_server.on_request_received_default(event)+    logging.info('on request received. Stream id: %s.' % event.stream_id)+    self._total_updates[event.stream_id] = 0++  def on_window_update(self, event):+    logging.info('on window update. Stream id: %s. Delta: %s' % (event.stream_id, event.delta))",Some comments here will go a long way,
961599,murgatroid99,https://api.github.com/repos/grpc/grpc/pulls/9766,102367647,2017-02-22T01:57:35Z,test/core/handshake/client_ssl.c,"@@ -31,6 +31,11 @@  *  */ +#include ""src/core/lib/iomgr/port.h""++// This test won't work except with posix sockets enabled","Right, there are several instances of this pattern, and that is the primary motivation for it. It's also a failsafe: if you ever try to run the test without posix sockets, it's guaranteed to fail, and opening the file immediately shows why.",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/9817,102394212,2017-02-22T06:50:08Z,doc/internationalization.md,"@@ -0,0 +1,44 @@+gRPC Internationalization+=========================++As a universal RPC framework, gRPC needs to be fully usable within/across different international environments. +This document describes gRPC API and behavior specifics when used in a non-english environment.++## API Concepts++While some API elements need to be able to represent non-english content, some are intentionally left as ASCII-only+for simplicity & performance reasons.++### Method name (in RPC Invocation)+Method names are ASCII-only. Most gRPC services will use protobuf which only allows ASCII based method names anyway.+Also, handling method names is a very hot code path.++Recommended representation in language-specific APIs: string type.++### Host name (in RPC Invocation)+Host names are punycode encoded. Currently, the punycode needs to be provided by the user.++Recommended representation in language-specific APIs: string/unicode string.++NOTE: overriding host name when invoking RPCs is only supported by C-core based gRPC implementations.++### Status detail/message (accompanies RPC status code)++Status messages are expected to contain national-alphabet characters.+Allowed values are unicode strings (content will be percent-encoded on the wire).++Recommended representation in language-specific APIs: unicode string.++### Metadata key+Allowed values are defined by HTTP/2 standard (metadata keys are represented as HTTP/2 header/trailer names).++Recommended representation in language-specific APIs: string.++### Metadata value (text-valued metadata)+Allowed values are defined by HTTP/2 standard (metadata values are represented as HTTP/2 header/trailer text values).++Recommended representation in language-specific APIs: string.++### Channel name","Is this a feature in most languages?  AFAIK, Python doesn't allow naming channels.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/9750,102557697,2017-02-22T19:57:44Z,src/core/lib/channel/deadline_filter.c,"@@ -80,11 +78,15 @@ static void start_timer_if_needed(grpc_exec_ctx* exec_ctx,       (grpc_deadline_timer_state)gpr_atm_acq_load(&deadline_state->timer_state);   switch (cur_state) {     case GRPC_DEADLINE_STATE_PENDING:+      // Note: We do not start the timer if there is already a timer       return;     case GRPC_DEADLINE_STATE_FINISHED:       if (gpr_atm_rel_cas(&deadline_state->timer_state,                           GRPC_DEADLINE_STATE_FINISHED,                           GRPC_DEADLINE_STATE_PENDING)) {+        // If we've already created and destroyed a timer, we always create a","Instead of using two different closures, how about simply initializing the inline closure just once in `grpc_deadline_state_init()`, and then re-using it for both the initial timer and the updated timer?If you do that, then the FINISHED and INITIAL cases become exactly the same, at which point the atomic here can become a simple bool instead of an enum (which is what it was before this PR).",
22083734,matt-kwong,https://api.github.com/repos/grpc/grpc/pulls/9812,102577166,2017-02-22T21:27:07Z,tools/run_tests/python_utils/jobset.py,"@@ -128,7 +129,8 @@ def alarm_handler(unused_signum, unused_frame):     'SKIPPED': 'cyan'     } -+FORMAT = '%(asctime)-15s %(message)s'","To go along with the style of constants in this file, FORMAT should be _FORMAT",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/9833,102594518,2017-02-22T22:44:29Z,src/core/ext/client_channel/parse_address.c,"@@ -49,9 +49,10 @@  int parse_unix(grpc_uri *uri, grpc_resolved_address *resolved_addr) {   struct sockaddr_un *un = (struct sockaddr_un *)resolved_addr->addr;+  memset(un, 0, sizeof(*un));    un->sun_family = AF_UNIX;-  strcpy(un->sun_path, uri->path);+  strncpy(un->sun_path, uri->path, sizeof(un->sun_path) - 1 /* null term'd */);","strncpy() is notoriously difficult to use in a safe way, because if the string is longer than the specified length, it does not copy the trailing NUL byte to the destination string.  strlcpy() is a much safer alternative to strncpy(), but it's unfortunately not portable. :(I assume that this misfeature of strncpy() is why you're using memset() above to initialize the whole struct.  However, that seems a bit fragile, because a future developer looking at this code might think ""the memset() isn't really necessary, because we're explicitly setting all of the fields below"".  An alternative would be to do something like this right after this line:```un->sun_path[sizeof(un->sun_path) - 1] = '\0';```",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/9833,102649701,2017-02-23T06:59:11Z,src/core/ext/client_channel/parse_address.c,"@@ -51,7 +51,8 @@ int parse_unix(grpc_uri *uri, grpc_resolved_address *resolved_addr) {   struct sockaddr_un *un = (struct sockaddr_un *)resolved_addr->addr;    un->sun_family = AF_UNIX;-  strcpy(un->sun_path, uri->path);+  strncpy(un->sun_path, uri->path, sizeof(un->sun_path) - 1 /* null term'd */);",Should we just `return 0` if uri->path is too long?,
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/9850,102773809,2017-02-23T17:48:29Z,src/core/ext/client_channel/client_channel.c,"@@ -977,20 +1063,47 @@ static void start_transport_stream_op_locked_inner(grpc_exec_ctx *exec_ctx,   add_waiting_locked(calld, op); } -static void cc_start_transport_stream_op_locked(grpc_exec_ctx *exec_ctx,-                                                void *arg,-                                                grpc_error *error_ignored) {-  GPR_TIMER_BEGIN(""cc_start_transport_stream_op_locked"", 0);+static void on_complete_locked(grpc_exec_ctx *exec_ctx, void *arg,+                               grpc_error *error) {+  grpc_call_element *elem = arg;+  channel_data *chand = elem->channel_data;+  call_data *calld = elem->call_data;+  if (chand->retry_throttle_data != NULL) {+    if (error == GRPC_ERROR_NONE) {+      grpc_server_retry_throttle_data_record_success(+          &chand->retry_throttle_data);+    } else {+      // TODO(roth): In a subsequent PR, check the return value here and+      // decide whether or not to retry.+      grpc_server_retry_throttle_data_record_failure(","This may be already encompassed by the above TODO, but may be a good idea to also note here that only failures with a retryable or non-fatal status code and RPCs that received ""do not retry"" pushback should be counted for throttling purposes.(last paragraph of https://github.com/ncteisen/proposal/blob/75e08fa10405430e8177cfd91bf63a25ff4ad617/A6.md#throttling-retry-attempts-and-hedged-rpcs)",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/9850,102786035,2017-02-23T18:42:44Z,src/core/ext/client_channel/client_channel.c,"@@ -260,6 +263,64 @@ static void watch_lb_policy(grpc_exec_ctx *exec_ctx, channel_data *chand,                                         &w->on_changed); } +typedef struct {+  char *server_name;+  grpc_server_retry_throttle_data *retry_throttle_data;+} service_config_parsing_state;++static void parse_retry_throttle_params(const grpc_json *field, void *arg) {+  service_config_parsing_state *parsing_state = arg;+  if (strcmp(field->key, ""retryThrottling"") == 0) {+    if (parsing_state->retry_throttle_data != NULL) return;  // Duplicate.+    if (field->type != GRPC_JSON_OBJECT) return;+    int max_milli_tokens = 0;+    int milli_token_ratio = 0;+    for (grpc_json *sub_field = field->child; sub_field != NULL;+         sub_field = sub_field->next) {+      if (sub_field->key == NULL) continue;",Should this be an error condition?,
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/9850,102786575,2017-02-23T18:45:07Z,src/core/ext/client_channel/client_channel.c,"@@ -260,6 +263,64 @@ static void watch_lb_policy(grpc_exec_ctx *exec_ctx, channel_data *chand,                                         &w->on_changed); } +typedef struct {+  char *server_name;+  grpc_server_retry_throttle_data *retry_throttle_data;+} service_config_parsing_state;++static void parse_retry_throttle_params(const grpc_json *field, void *arg) {+  service_config_parsing_state *parsing_state = arg;+  if (strcmp(field->key, ""retryThrottling"") == 0) {+    if (parsing_state->retry_throttle_data != NULL) return;  // Duplicate.+    if (field->type != GRPC_JSON_OBJECT) return;+    int max_milli_tokens = 0;+    int milli_token_ratio = 0;+    for (grpc_json *sub_field = field->child; sub_field != NULL;+         sub_field = sub_field->next) {+      if (sub_field->key == NULL) continue;+      if (strcmp(sub_field->key, ""maxTokens"") == 0) {+        if (max_milli_tokens != 0) return;  // Duplicate.","Again, should we explicitly treat this as an error? I don't know the mechanics of service config, but wouldn't reaching this state mean that the state of the service config is bad?Same question applies to all of the early returns in this function.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/9850,102792112,2017-02-23T19:09:02Z,src/core/ext/client_channel/retry_throttle.c,"@@ -0,0 +1,242 @@+/*+ *+ * Copyright 2017, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#include ""src/core/ext/client_channel/retry_throttle.h""++#include <limits.h>+#include <string.h>++#include <grpc/support/alloc.h>+#include <grpc/support/atm.h>+#include <grpc/support/avl.h>+#include <grpc/support/string_util.h>+#include <grpc/support/sync.h>++//+// server_retry_throttle_data+//++struct grpc_server_retry_throttle_data {+  gpr_refcount refs;+  int max_milli_tokens;+  int milli_token_ratio;+  gpr_atm milli_tokens;+  // A pointer to the replacement for this grpc_server_retry_throttle_data+  // entry.  If non-NULL, then this entry is stale and must not be used.+  // We hold a reference to the replacement.+  gpr_atm replacement;+};++static void get_replacement_throttle_data_if_needed(+    grpc_server_retry_throttle_data** throttle_data) {+  while (true) {+    grpc_server_retry_throttle_data* new_throttle_data =+        (grpc_server_retry_throttle_data*)gpr_atm_acq_load(+            &(*throttle_data)->replacement);+    if (new_throttle_data == NULL) return;+    // Reset *throttle_data to its replacement, updating refcounts as+    // appropriate.+    // Note: It's safe to do this here, because the caller ensures that+    // this will only be called with a given value of throttle_data from+    // one thread at a time.+    grpc_server_retry_throttle_data_ref(new_throttle_data);+    grpc_server_retry_throttle_data* old_throttle_data = *throttle_data;+    *throttle_data = new_throttle_data;+    grpc_server_retry_throttle_data_unref(old_throttle_data);+  }+}++bool grpc_server_retry_throttle_data_record_failure(+    grpc_server_retry_throttle_data** throttle_data) {+  // First, check if we are stale and need to be replaced.+  get_replacement_throttle_data_if_needed(throttle_data);+  // We decrement milli_tokens by 1000 (1 token) for each failure.+  const int delta = -1000;+  const int old_value = (int)gpr_atm_full_fetch_add(+      &(*throttle_data)->milli_tokens, (gpr_atm)delta);+  // If the above change takes us below 0, then re-add the excess.  Note+  // that between these two atomic operations, the value will be+  // artificially low by as much as 1000, but this window should be+  // brief.+  int new_value = old_value - 1000;+  if (new_value < 0) {+    const int excess_value = new_value - (old_value < 0 ? old_value : 0);+    gpr_atm_full_fetch_add(&(*throttle_data)->milli_tokens,",Would it make sense to do an atomic store of zero here? Otherwise aren't race conditions introduced in which the milli_tokens data is mutated since the original gpr_atm_full_fetch_add call?,
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/9683,102815082,2017-02-23T20:53:45Z,src/core/lib/iomgr/ev_epoll_linux.c,"@@ -1060,101 +1104,182 @@ static void fd_orphan(grpc_exec_ctx *exec_ctx, grpc_fd *fd,   GRPC_ERROR_UNREF(error); } -static grpc_error *fd_shutdown_error(grpc_fd *fd) {-  if (!fd->shutdown) {-    return GRPC_ERROR_NONE;-  } else {-    return GRPC_ERROR_CREATE_REFERENCING(""FD shutdown"", &fd->shutdown_error, 1);+static void notify_on(grpc_exec_ctx *exec_ctx, grpc_fd *fd, gpr_atm *state,+                      grpc_closure *closure) {+  while (true) {+    /* Fast-path: CLOSURE_NOT_READY -> <closure> */+    /* Also do a release-cas here so that any acqire-loads in set_ready or+       set_shutdown see this */+    if (gpr_atm_rel_cas(state, CLOSURE_NOT_READY, (gpr_atm)closure)) {+      return; /* Fast-path successful. Return */+    }++    /* Slowpath */+    gpr_atm curr = gpr_atm_acq_load(state);+    switch (curr) {+      case CLOSURE_NOT_READY: {+        break; /* retry */+      }++      case CLOSURE_READY: {+        /* Change the state to CLOSURE_NOT_READY. If successful: Schedule the+           closure. If not, most likely the state transitioned to shutdown. We+           should retry */+        if (gpr_atm_rel_cas(state, CLOSURE_READY, CLOSURE_NOT_READY)) {+          grpc_closure_sched(exec_ctx, closure, GRPC_ERROR_NONE);+          return; /* Slow-path successful. Return */+        }++        break; /* retry */+      }++      default: {+        /* 'curr' is either a closure or the fd is shutdown(in which case 'curr'+           contains a pointer to the shutdown-error). If the fd is shutdown,+           schedule the closure with the shutdown error */+        if ((curr & FD_SHUTDOWN_BIT) > 0) {+          grpc_error *shutdown_err = (grpc_error *)(curr & ~FD_SHUTDOWN_BIT);+          grpc_closure_sched(+              exec_ctx, closure,+              GRPC_ERROR_CREATE_REFERENCING(""FD Shutdown"", &shutdown_err, 1));+          return;+        }++        /* There is already a closure!. This indicates a bug in the code */+        gpr_log(GPR_ERROR,+                ""notify_on called with a previous callback still pending"");+        abort();+      }+    }   }++  GPR_UNREACHABLE_CODE(return ); } -static void notify_on_locked(grpc_exec_ctx *exec_ctx, grpc_fd *fd,-                             grpc_closure **st, grpc_closure *closure) {-  if (fd->shutdown) {-    grpc_closure_sched(exec_ctx, closure, GRPC_ERROR_CREATE(""FD shutdown""));-  } else if (*st == CLOSURE_NOT_READY) {-    /* not ready ==> switch to a waiting state by setting the closure */-    *st = closure;-  } else if (*st == CLOSURE_READY) {-    /* already ready ==> queue the closure to run immediately */-    *st = CLOSURE_NOT_READY;-    grpc_closure_sched(exec_ctx, closure, fd_shutdown_error(fd));-  } else {-    /* upcallptr was set to a different closure.  This is an error! */-    gpr_log(GPR_ERROR,-            ""User called a notify_on function with a previous callback still ""-            ""pending"");-    abort();+static void set_shutdown(grpc_exec_ctx *exec_ctx, grpc_fd *fd, gpr_atm *state,+                         grpc_error *shutdown_err) {+  /* Try the fast-path first (i.e expect the current value to be+     CLOSURE_NOT_READY */+  gpr_atm curr = CLOSURE_NOT_READY;+  gpr_atm new_state = (gpr_atm)shutdown_err | FD_SHUTDOWN_BIT;++  while (true) {+    if (gpr_atm_rel_cas(state, curr, new_state)) {+      return; /* Fast-path successful. Return */+    }++    /* Fallback to slowpath */+    curr = gpr_atm_acq_load(state);+    switch (curr) {+      case CLOSURE_READY: {+        break; /* retry */+      }++      case CLOSURE_NOT_READY: {+        break; /* retry */+      }++      default: {+        /* 'curr' is either a closure or the fd is already shutdown */++        /* If fd is already shutdown, we are done */+        if ((curr & FD_SHUTDOWN_BIT) > 0) {+          return;+        }++        /* Fd is not shutdown. Schedule the closure and move the state to+           shutdown state */+        if (gpr_atm_rel_cas(state, curr, new_state)) {+          grpc_closure_sched(+              exec_ctx, (grpc_closure *)curr,+              GRPC_ERROR_CREATE_REFERENCING(""FD Shutdown"", &shutdown_err, 1));+          return;+        }++        /* 'curr' was a closure but now changed to a different state. We will+          have to retry */+        break;+      }+    }   }++  GPR_UNREACHABLE_CODE(return ); } -/* returns 1 if state becomes not ready */-static int set_ready_locked(grpc_exec_ctx *exec_ctx, grpc_fd *fd,-                            grpc_closure **st) {-  if (*st == CLOSURE_READY) {-    /* duplicate ready ==> ignore */-    return 0;-  } else if (*st == CLOSURE_NOT_READY) {-    /* not ready, and not waiting ==> flag ready */-    *st = CLOSURE_READY;-    return 0;-  } else {-    /* waiting ==> queue closure */-    grpc_closure_sched(exec_ctx, *st, fd_shutdown_error(fd));-    *st = CLOSURE_NOT_READY;-    return 1;+static void set_ready(grpc_exec_ctx *exec_ctx, grpc_fd *fd, gpr_atm *state) {+  /* Try an optimistic case first (i.e assume current state is+     CLOSURE_NOT_READY) */+  if (gpr_atm_rel_cas(state, CLOSURE_NOT_READY, CLOSURE_READY)) {+    return; /* early out */+  }++  gpr_atm curr = gpr_atm_acq_load(state);+  switch (curr) {+    case CLOSURE_READY: {+      /* Already ready. We are done here */+      break;+    }++    case CLOSURE_NOT_READY: {+      /* The state was not CLOSURE_NOT_READY when we checked initially at the+         beginning of this function but now it is CLOSURE_NOT_READY again.+         This is only possible if the state transitioned out of+         CLOSURE_NOT_READY to either CLOSURE_READY or <some closure> and then+         back to CLOSURE_NOT_READY again (i.e after we entered this function,+         the fd became ""ready"" and the necessary actions were already done).+         So there is no need to make the state CLOSURE_READY now */+      break;+    }++    default: {+      /* 'curr' is either a closure or the fd is shutdown */+      if ((curr & FD_SHUTDOWN_BIT) > 0) {+        /* The fd is shutdown. Do nothing */+      } else if (gpr_atm_rel_cas(state, curr, CLOSURE_NOT_READY)) {","Looks like I didn't :).  Wouldn't the reason be similar to why we were doing a 'release' cas at the beginning ? - i.e to match 'acquire' loads in notify_on / set_shutdown.  (I know that since this sets the state to CLOSURE_NOT_READY, no closure would be executed when transitioning out of this state in notify_on or set_shutdown... is that the only reason you are recommending a no_barrier cas here? )",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/9850,102820121,2017-02-23T21:17:30Z,src/core/ext/client_channel/client_channel.c,"@@ -260,6 +263,64 @@ static void watch_lb_policy(grpc_exec_ctx *exec_ctx, channel_data *chand,                                         &w->on_changed); } +typedef struct {+  char *server_name;+  grpc_server_retry_throttle_data *retry_throttle_data;+} service_config_parsing_state;++static void parse_retry_throttle_params(const grpc_json *field, void *arg) {+  service_config_parsing_state *parsing_state = arg;+  if (strcmp(field->key, ""retryThrottling"") == 0) {+    if (parsing_state->retry_throttle_data != NULL) return;  // Duplicate.+    if (field->type != GRPC_JSON_OBJECT) return;+    int max_milli_tokens = 0;+    int milli_token_ratio = 0;+    for (grpc_json *sub_field = field->child; sub_field != NULL;+         sub_field = sub_field->next) {+      if (sub_field->key == NULL) continue;+      if (strcmp(sub_field->key, ""maxTokens"") == 0) {+        if (max_milli_tokens != 0) return;  // Duplicate.","The intent here is that if the service config data is invalid, we will just ignore it.  We should not actually return an error, because we don't want the channel initialization to fail.We could probably log a message indicating why we're ignoring the config, but none of the existing service config parsing code does that, so let's handle that as a separate change.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/9850,102822091,2017-02-23T21:25:51Z,src/core/ext/client_channel/retry_throttle.c,"@@ -0,0 +1,242 @@+/*+ *+ * Copyright 2017, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#include ""src/core/ext/client_channel/retry_throttle.h""++#include <limits.h>+#include <string.h>++#include <grpc/support/alloc.h>+#include <grpc/support/atm.h>+#include <grpc/support/avl.h>+#include <grpc/support/string_util.h>+#include <grpc/support/sync.h>++//+// server_retry_throttle_data+//++struct grpc_server_retry_throttle_data {+  gpr_refcount refs;+  int max_milli_tokens;+  int milli_token_ratio;+  gpr_atm milli_tokens;+  // A pointer to the replacement for this grpc_server_retry_throttle_data+  // entry.  If non-NULL, then this entry is stale and must not be used.+  // We hold a reference to the replacement.+  gpr_atm replacement;","Any time there are multiple channels pointing to the same server name, they will share the same throttling data.  If we're getting the service config data via the DNS resolver, we only re-resolve the name when we see a channel failure, so there may be a long delay between when the first channel sees the new throttling policy and when all of the other channels see it.  During that delay, we do not want the channels using different throttling policies, because then we'll be recording successes and failures in different places.  So this mechanism ensures that all channels switch to the most recent policy as soon as possible.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/9850,102837195,2017-02-23T22:36:25Z,src/core/ext/client_channel/retry_throttle.c,"@@ -0,0 +1,242 @@+/*+ *+ * Copyright 2017, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#include ""src/core/ext/client_channel/retry_throttle.h""++#include <limits.h>+#include <string.h>++#include <grpc/support/alloc.h>+#include <grpc/support/atm.h>+#include <grpc/support/avl.h>+#include <grpc/support/string_util.h>+#include <grpc/support/sync.h>++//+// server_retry_throttle_data+//++struct grpc_server_retry_throttle_data {+  gpr_refcount refs;+  int max_milli_tokens;+  int milli_token_ratio;+  gpr_atm milli_tokens;+  // A pointer to the replacement for this grpc_server_retry_throttle_data+  // entry.  If non-NULL, then this entry is stale and must not be used.+  // We hold a reference to the replacement.+  gpr_atm replacement;+};++static void get_replacement_throttle_data_if_needed(+    grpc_server_retry_throttle_data** throttle_data) {+  while (true) {+    grpc_server_retry_throttle_data* new_throttle_data =+        (grpc_server_retry_throttle_data*)gpr_atm_acq_load(+            &(*throttle_data)->replacement);+    if (new_throttle_data == NULL) return;+    // Reset *throttle_data to its replacement, updating refcounts as+    // appropriate.+    // Note: It's safe to do this here, because the caller ensures that+    // this will only be called with a given value of throttle_data from+    // one thread at a time.+    grpc_server_retry_throttle_data_ref(new_throttle_data);+    grpc_server_retry_throttle_data* old_throttle_data = *throttle_data;+    *throttle_data = new_throttle_data;+    grpc_server_retry_throttle_data_unref(old_throttle_data);+  }+}++bool grpc_server_retry_throttle_data_record_failure(+    grpc_server_retry_throttle_data** throttle_data) {+  // First, check if we are stale and need to be replaced.+  get_replacement_throttle_data_if_needed(throttle_data);+  // We decrement milli_tokens by 1000 (1 token) for each failure.+  const int delta = -1000;+  const int old_value = (int)gpr_atm_full_fetch_add(+      &(*throttle_data)->milli_tokens, (gpr_atm)delta);+  // If the above change takes us below 0, then re-add the excess.  Note+  // that between these two atomic operations, the value will be+  // artificially low by as much as 1000, but this window should be+  // brief.+  int new_value = old_value - 1000;+  if (new_value < 0) {+    const int excess_value = new_value - (old_value < 0 ? old_value : 0);+    gpr_atm_full_fetch_add(&(*throttle_data)->milli_tokens,","There is indeed a race condition here, and this code is an attempt to deal with it.We don't know what changes might have been made by some other thread since our first atomic add above, but we do know the original value from before our atomic add and the amount we added, which means that we know the exact amount by which we over-adjusted.  What we're doing here is to compensate for only the amount that we are responsible for over-adjusting.  If every individual thread compensates for its own over-adjustment, then the result after all threads have finished should be that we have the right value.I don't think it will work to simply do an atomic store of zero here, because if another thread recorded a success since our first atomic add, then we would wind up failing to record that success.  For example, let's say that the token ratio is 0.5 and the current number of tokens is 0.25.  Now let's say that the current thread is recording a failure, and some other thread is recording a success.  If we first do the atomic add of -1, the current value goes down to -0.75 (i.e., we over-adjusted by 0.75).  Next, the other thread starts to record a success and does an atomic add of 0.5, bringing the value to -0.25.  And now the current thread gets to this point in the code, where it's trying to compensate for its over-adjustment.  If we simply did an atomic store of zero here, we would be wiping out the success recorded by the other thread.  What we want here is to re-add the amount that we over-adjusted by (0.75), thus bringing the value up to 0.5.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/9866,103002118,2017-02-24T18:29:11Z,src/python/grpcio/grpc/_auth.py,"@@ -60,15 +69,7 @@ def __call__(self, context, callback):         else:             future = self._pool.submit(self._credentials.get_access_token)         future.add_done_callback(-            lambda x: self._get_token_callback(callback, x))--    def _get_token_callback(self, callback, future):-        try:-            access_token = future.result().access_token-        except Exception as e:-            _sign_request(callback, None, e)-        else:-            _sign_request(callback, access_token, None)+            lambda ignored_future: _get_token_callback(callback, future))","I'm not sure I understand, but I'll say that this code is going to look strange no matter the circumstances because of the way that `add_done_callback` has semantics of ""the value passed to your behavior will be an object to which we already know you have access"". Can you sketch out the shape of the implementation that you think might be more sensible?",
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/9810,103055887,2017-02-24T23:39:14Z,tools/grpcz/BUILD,"@@ -0,0 +1,73 @@+# Copyright 2017, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.++licenses([""notice""])  # 3-clause BSD++package(default_visibility = [""//visibility:public""])++load(""//:bazel/generate_cc.bzl"", ""generate_cc"")++proto_library (+    name = ""monitoring_proto_local_copy"",+    srcs = [+        # TODO (ericgribkoff) : remove the local copies of these protos+        ""monitoring.proto"",+        ""empty.proto"",+        ""any.proto"",+        ""census.proto"",+    ],+)++generate_cc(+    name = ""monitoring_codegen"",+    srcs = ["":monitoring_proto_local_copy""],+)++generate_cc(+    name = ""monitoring_grpc_codegen"",+    srcs = ["":monitoring_proto_local_copy""],+    plugin = ""//:grpc_cpp_plugin"",+)++cc_library(+    name = ""proto_lib"",+    srcs = ["":monitoring_codegen"", "":monitoring_grpc_codegen""],+    hdrs = ["":monitoring_codegen"", "":monitoring_grpc_codegen""],+    deps = [""//:grpc++"", ""//:grpc++_codegen_proto"", ""//external:protobuf""],",Each dependency on a separate line?,
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/9810,103057811,2017-02-24T23:57:09Z,tools/grpcz/grpcz_client.cc,"@@ -0,0 +1,174 @@+/*+ *+ * Copyright 2017, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#include <iostream>+#include <memory>+#include <string>++#include <google/protobuf/util/json_util.h>+#include <grpc++/grpc++.h>+#include <grpc/support/log.h>++#include ""gflags/gflags.h""+#include ""mongoose.h""++// TODO (makdharma): remove local copies of these protos+#include ""tools/grpcz/census.grpc.pb.h""+#include ""tools/grpcz/monitoring.grpc.pb.h""++DEFINE_string(server, ""127.0.0.1:50052"",+              ""file path (or host:port) where grpcz server is running"");","Maybe rename this to `grpcz_server` to disambiguate more between the grpcz and http server?Might be helpful to include an example of UDS path, e.g., `unix:///path/to/uds/file` ",
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/9810,103060037,2017-02-25T00:20:30Z,tools/grpcz/grpcz_client.cc,"@@ -0,0 +1,174 @@+/*+ *+ * Copyright 2017, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#include <iostream>+#include <memory>+#include <string>++#include <google/protobuf/util/json_util.h>+#include <grpc++/grpc++.h>+#include <grpc/support/log.h>++#include ""gflags/gflags.h""+#include ""mongoose.h""++// TODO (makdharma): remove local copies of these protos+#include ""tools/grpcz/census.grpc.pb.h""+#include ""tools/grpcz/monitoring.grpc.pb.h""++DEFINE_string(server, ""127.0.0.1:50052"",+              ""file path (or host:port) where grpcz server is running"");+DEFINE_string(http_port, ""8000"",+              ""Port id for accessing the HTTP server that renders /grpcz page"");+DEFINE_bool(print, false, ""only print the output and quit"");++using grpc::Channel;+using grpc::ClientContext;+using grpc::Status;++using ::grpc::instrumentation::v1alpha::CanonicalRpcStats;+using ::grpc::instrumentation::v1alpha::Monitoring;++static const std::string static_html_header =+    ""<!DOCTYPE html> <html> <head> <style> \+table { border-collapse: collapse; width: 100%; } \+table, td, th { border: 1px solid black; } \+</style> </head> <body>\+<div id='stats' stats='"";",The attribute should be `data-stats` instead of `stats` to be valid html5,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/9817,103172248,2017-02-27T10:08:57Z,doc/internationalization.md,"@@ -0,0 +1,44 @@+gRPC Internationalization+=========================++As a universal RPC framework, gRPC needs to be fully usable within/across different international environments. +This document describes gRPC API and behavior specifics when used in a non-english environment.++## API Concepts++While some API elements need to be able to represent non-english content, some are intentionally left as ASCII-only+for simplicity & performance reasons.++### Method name (in RPC Invocation)+Method names are ASCII-only. Most gRPC services will use protobuf which only allows ASCII based method names anyway.+Also, handling method names is a very hot code path.++Recommended representation in language-specific APIs: string type.++### Host name (in RPC Invocation)+Host names are punycode encoded. Currently, the punycode needs to be provided by the user.++Recommended representation in language-specific APIs: string/unicode string.","To move on with this, I suggest just saying that the punycode needs to be user-provided. Punycode encoding by gRPC adds some extra complexity (at least in C core I assume) and no users have asked for this feature so far.Later, if we see that the community demands support for IDN, we can introduce such support (e.g. either through adding a new API taking java.net.IDN as a parameter or as a utility/new function in C).Any objections?",
3523733,hvardhanx,https://api.github.com/repos/grpc/grpc/pulls/8063,103318992,2017-02-27T21:39:59Z,src/compiler/schema_interface.h,"@@ -0,0 +1,128 @@+/*+ *+ * Copyright 2015, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#ifndef GRPC_INTERNAL_COMPILER_SCHEMA_INTERFACE_H+#define GRPC_INTERNAL_COMPILER_SCHEMA_INTERFACE_H++#include ""src/compiler/config.h""++#include <memory>+#include <vector>++#ifndef GRPC_CUSTOM_STRING+#include <string>+#define GRPC_CUSTOM_STRING std::string+#endif++namespace grpc {++typedef GRPC_CUSTOM_STRING string;++}  // namespace grpc++namespace grpc_generator {++// A common interface for objects having comments in the source.+// Return formatted comments to be inserted in generated code.+struct CommentHolder {+  virtual ~CommentHolder() {}+  virtual grpc::string GetLeadingComments(const grpc::string prefix) const = 0;+  virtual grpc::string GetTrailingComments(const grpc::string prefix) const = 0;+  virtual std::vector<grpc::string> GetAllComments() const = 0;+};++// An abstract interface representing a method.+struct Method : public CommentHolder {+  virtual ~Method() {}++  virtual grpc::string name() const = 0;++  virtual grpc::string input_type_name() const = 0;+  virtual grpc::string output_type_name() const = 0;++  virtual bool get_module_and_message_path_input(+      grpc::string *str, grpc::string generator_file_name,+      bool generate_in_pb2_grpc) const = 0;+  virtual bool get_module_and_message_path_output(+      grpc::string *str, grpc::string generator_file_name,+      bool generate_in_pb2_grpc) const = 0;++  virtual grpc::string get_input_type_name() const = 0;+  virtual grpc::string get_output_type_name() const = 0;+  virtual bool NoStreaming() const = 0;+  virtual bool ClientStreaming() const = 0;+  virtual bool python_ClientStreaming() const = 0;","One workaround we can have here is like pass a language related parameter to the Streaming methods. Something like,```bool ClientStreaming(string lang) {  if(lang == ""c++"") { // do some work }  else if(lang == ""python"") { // return some boolean }}```It still looks cumbersome but we'll then have a single method instead of multiple methods.",
961599,murgatroid99,https://api.github.com/repos/grpc/grpc/pulls/9004,103512133,2017-02-28T17:41:18Z,templates/package.json.template,"@@ -34,9 +34,10 @@     ""dependencies"": {       ""arguejs"": ""^0.2.3"",       ""lodash"": ""^4.15.0"",+      ""long"": ""^3.2.0"",","Where are you using the long module? If you're not using it, please remove it, and if you're only using it for tests, please move it to `devDependencies`.",
534887,paralin,https://api.github.com/repos/grpc/grpc/pulls/9004,103512455,2017-02-28T17:42:55Z,templates/package.json.template,"@@ -34,9 +34,10 @@     ""dependencies"": {       ""arguejs"": ""^0.2.3"",       ""lodash"": ""^4.15.0"",+      ""long"": ""^3.2.0"",","It's being used in the `longsAsStrings` option. In Protobuf.JS 5, Long was included in protobuf.js. Now, it's a separate module. Protobuf needs the long dependency, then, to produce Long objects when `longsAsStrings` is unset.",
534887,paralin,https://api.github.com/repos/grpc/grpc/pulls/9004,103512658,2017-02-28T17:43:48Z,templates/package.json.template,"@@ -34,9 +34,10 @@     ""dependencies"": {       ""arguejs"": ""^0.2.3"",       ""lodash"": ""^4.15.0"",+      ""long"": ""^3.2.0"",","Quote from the docs:If you need int64 support, explicitly require the long module somewhere in your project as it will be excluded otherwise. This assumes that a global require function is present that protobuf.js can call to obtain the long module.",
961599,murgatroid99,https://api.github.com/repos/grpc/grpc/pulls/9004,103597968,2017-03-01T02:14:08Z,src/node/interop/interop_client.js,"@@ -305,8 +305,8 @@ function customMetadata(client, done) {   metadata.set(ECHO_INITIAL_KEY, 'test_initial_metadata_value');   metadata.set(ECHO_TRAILING_KEY, new Buffer('ababab', 'hex'));   var arg = {-    response_type: 'COMPRESSABLE',-    response_size: 314159,+    responseType: 'COMPRESSABLE',+    responseSize: 314159,",A similar change is needed for `streaming_arg` a few lines down.,
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/9809,103617297,2017-03-01T06:17:35Z,doc/server_side_auth.md,"@@ -0,0 +1,57 @@+Server-side Authentication+==========================++NOTE: This document describes how server-side authentication works in C-core based gRPC implementations only. In gRPC Java and Go, server side authentication is handled differently.++## AuthContext++To perform server-side authentication, gRPC exposes the *authentication context* for each call. The context exposes important authentication-related information about the RPC such as the type of security/authentication type being used and the peer identity.++The authentication context is structured as a multi-map of key-value pairs - the *auth properties*. In addition to that, for authenticated RPCs, the set of properties corresponding to a selected key will represent the verified identity of the caller - the *peer identity*. +The contents of the *auth properties* are populated by an *auth interceptor*. The interceptor also chooses which property key will act as the peer identity (e.g. for client certificate authentication this property will be `""x509_common_name""` or `""x509_subject_alternative_name""`).++WARNING: AuthContext is the only reliable source of truth when it comes to authenticating RPCs. Using any other call/context properties for authentication purposes is wrong and inherently unsafe.++####Example AuthContext contents++For secure channel using mutual TLS authentication with both client and server certificates (test certificates from this repository are used).++Populated auth properties:+```+""transport_security_type"": ""ssl""  # connection is secured using TLS/SSL+""x509_common_name"": ""*.test.google.com""  # from client's certificate+""x509_pem_cert"": ""-----BEGIN CERTIFICATE-----\n...""  # client's PEM encoded certificate+""x509_subject_alternative_name"": ""*.test.google.fr""+""x509_subject_alternative_name"": ""waterzooi.test.google.be""+""x509_subject_alternative_name"": ""*.test.youtube.com""+""x509_subject_alternative_name"": ""192.168.1.3""+```++The peer identity is set of all properties named `""x509_subject_alternative_name""`:+```+peer_identity_property_name = ""x509_subject_alternative_name""+```++## AuthProperty++Auth properties are elements of the auth context. They have a name (a key of type string) and a value which can be a string or binary data.++## Auth Interceptors++Auth interceptors are gRPC components that populate contents of the auth context based on gRPC's internal state and/or call metadata.+gRPC comes with some basic ""interceptors"" already built-in. Auth interceptors can be composed and more interceptors can be active at the same time (e.g. each interceptor can add their auth properties and the last auth interceptor will select the property name that will be used when retrieving the peer identity).","Right now, you can attach only one interceptor (on the server credentials). The TLS/SSL auth context does not come from an interceptor (see below). We could have a composite interceptor just like we do for credentials to be able to chain them but that is not the case at the moment (at least in C).",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/9850,103733663,2017-03-01T16:56:16Z,src/core/ext/client_channel/client_channel.c,"@@ -977,20 +1064,50 @@ static void start_transport_stream_op_locked_inner(grpc_exec_ctx *exec_ctx,   add_waiting_locked(calld, op); } -static void cc_start_transport_stream_op_locked(grpc_exec_ctx *exec_ctx,-                                                void *arg,-                                                grpc_error *error_ignored) {-  GPR_TIMER_BEGIN(""cc_start_transport_stream_op_locked"", 0);+static void on_complete_locked(grpc_exec_ctx *exec_ctx, void *arg,+                               grpc_error *error) {+  grpc_call_element *elem = arg;+  channel_data *chand = elem->channel_data;+  call_data *calld = elem->call_data;+  if (chand->retry_throttle_data != NULL) {+    if (error == GRPC_ERROR_NONE) {+      grpc_server_retry_throttle_data_record_success(+          &chand->retry_throttle_data);+    } else {+      // TODO(roth): In a subsequent PR, check the return value here and+      // decide whether or not to retry.  Note that we should only+      // record failures whose statuses match the configured retryable+      // or non-fatal status codes.+      grpc_server_retry_throttle_data_record_failure(+          &chand->retry_throttle_data);+    }+  }+  grpc_closure_run(exec_ctx, calld->original_on_complete,+                   GRPC_ERROR_REF(error));+}++static void start_transport_stream_op_locked(grpc_exec_ctx *exec_ctx, void *arg,+                                             grpc_error *error_ignored) {+  GPR_TIMER_BEGIN(""start_transport_stream_op_locked"", 0);    grpc_transport_stream_op *op = arg;   grpc_call_element *elem = op->handler_private.args[0];+  channel_data *chand = elem->channel_data;   call_data *calld = elem->call_data; +  if (op->recv_trailing_metadata != NULL) {+    GPR_ASSERT(op->on_complete != NULL);+    calld->original_on_complete = op->on_complete;+    grpc_closure_init(&calld->on_complete, on_complete_locked, elem,","Suggest: storing the retry throttle data when sending initial metadata on call data, and then using the fact that we have an atomic in the actual throttle data to avoid the lock.",
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/9934,103738806,2017-03-01T17:17:58Z,test/cpp/interop/http2_client.cc,"@@ -134,20 +134,29 @@ bool Http2Client::DoRstDuringData() { bool Http2Client::DoGoaway() {   gpr_log(GPR_DEBUG, ""Sending two RPCs and expecting goaway""); -  int numCalls = 2;-  for (int i = 0; i < numCalls; i++) {-    ClientContext context;-    SimpleRequest request;-    SimpleResponse response;-    request.set_response_size(kLargeResponseSize);-    grpc::string payload(kLargeRequestSize, '\0');-    request.mutable_payload()->set_body(payload.c_str(), kLargeRequestSize);--    Status s = serviceStub_.Get()->UnaryCall(&context, request, &response);-    AssertStatusCode(s, grpc::StatusCode::OK);-    GPR_ASSERT(response.payload().body() ==-               grpc::string(kLargeResponseSize, '\0'));-  }+  SimpleRequest request;+  request.set_response_size(kLargeResponseSize);+  grpc::string payload(kLargeRequestSize, '\0');+  request.mutable_payload()->set_body(payload.c_str(), kLargeRequestSize);++  ClientContext context1;+  SimpleResponse response1;+  Status s = serviceStub_.Get()->UnaryCall(&context1, request, &response1);+  AssertStatusCode(s, grpc::StatusCode::OK);+  GPR_ASSERT(response1.payload().body() ==+             grpc::string(kLargeResponseSize, '\0'));++  // Sleep for one second to give time for client to receive goaway frame.+  gpr_timespec sleep_time = gpr_time_add(","`gpr_sleep_until` is used in other C++ tests, e.g., https://github.com/grpc/grpc/blob/9b1ad661bacfc232da2991d24fc2da35fae9285a/test/cpp/end2end/server_crash_test.cc#L77. If the other tests should also be using sleep(1), I can change this, but didn't want to assume it was avoided for no reason - it looks like the only sleep that doesn't use `gpr_sleep_until` is in the route chat example.",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/8063,103755405,2017-03-01T18:31:46Z,src/compiler/schema_interface.h,"@@ -0,0 +1,128 @@+/*+ *+ * Copyright 2015, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#ifndef GRPC_INTERNAL_COMPILER_SCHEMA_INTERFACE_H+#define GRPC_INTERNAL_COMPILER_SCHEMA_INTERFACE_H++#include ""src/compiler/config.h""++#include <memory>+#include <vector>++#ifndef GRPC_CUSTOM_STRING+#include <string>+#define GRPC_CUSTOM_STRING std::string+#endif++namespace grpc {++typedef GRPC_CUSTOM_STRING string;++}  // namespace grpc++namespace grpc_generator {++// A common interface for objects having comments in the source.+// Return formatted comments to be inserted in generated code.+struct CommentHolder {+  virtual ~CommentHolder() {}+  virtual grpc::string GetLeadingComments(const grpc::string prefix) const = 0;+  virtual grpc::string GetTrailingComments(const grpc::string prefix) const = 0;+  virtual std::vector<grpc::string> GetAllComments() const = 0;+};++// An abstract interface representing a method.+struct Method : public CommentHolder {","In my opinion, Method should not contain any Python specific/protobuf specific stuff.Method should be a container class that contains all the information of a service method.You can then have 2 implementations, a Protobuf one (which can be constructed from a protobuf method), and a flatbuffer one (which can be constructed from a flatbuffer method).",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/9850,103767695,2017-03-01T19:24:42Z,src/core/ext/client_channel/client_channel.c,"@@ -977,20 +1064,50 @@ static void start_transport_stream_op_locked_inner(grpc_exec_ctx *exec_ctx,   add_waiting_locked(calld, op); } -static void cc_start_transport_stream_op_locked(grpc_exec_ctx *exec_ctx,-                                                void *arg,-                                                grpc_error *error_ignored) {-  GPR_TIMER_BEGIN(""cc_start_transport_stream_op_locked"", 0);+static void on_complete_locked(grpc_exec_ctx *exec_ctx, void *arg,+                               grpc_error *error) {+  grpc_call_element *elem = arg;+  channel_data *chand = elem->channel_data;+  call_data *calld = elem->call_data;+  if (chand->retry_throttle_data != NULL) {+    if (error == GRPC_ERROR_NONE) {+      grpc_server_retry_throttle_data_record_success(+          &chand->retry_throttle_data);+    } else {+      // TODO(roth): In a subsequent PR, check the return value here and+      // decide whether or not to retry.  Note that we should only+      // record failures whose statuses match the configured retryable+      // or non-fatal status codes.+      grpc_server_retry_throttle_data_record_failure(+          &chand->retry_throttle_data);+    }+  }+  grpc_closure_run(exec_ctx, calld->original_on_complete,+                   GRPC_ERROR_REF(error));+}++static void start_transport_stream_op_locked(grpc_exec_ctx *exec_ctx, void *arg,+                                             grpc_error *error_ignored) {+  GPR_TIMER_BEGIN(""start_transport_stream_op_locked"", 0);    grpc_transport_stream_op *op = arg;   grpc_call_element *elem = op->handler_private.args[0];+  channel_data *chand = elem->channel_data;   call_data *calld = elem->call_data; +  if (op->recv_trailing_metadata != NULL) {+    GPR_ASSERT(op->on_complete != NULL);+    calld->original_on_complete = op->on_complete;+    grpc_closure_init(&calld->on_complete, on_complete_locked, elem,","If we do that, then we won't be able to update chand->retry_throttle_data to point to the newest version of the throttle data.  That means that on each subsequent RPC (until the channel gets the updated service config, which could be a while in the case of DNS), we will need to follow pointers to find the most recent throttle data, updating refcounts as we go.  Is that a reasonable trade-off?",
5120183,jcanizales,https://api.github.com/repos/grpc/grpc/pulls/9247,103825968,2017-03-02T00:35:21Z,src/objective-c/GRPCClient/private/GRPCOpBatchLog.h,"@@ -0,0 +1,54 @@+/*+ *+ * Copyright 2016, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++/**+ * Logs the op batches of a client. Used for testing.+ */+@interface GRPCOpBatchLog : NSObject",Surround this class (.h and .m) with the macro guard too?,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/9866,103830753,2017-03-02T01:12:25Z,src/python/grpcio/grpc/_auth.py,"@@ -60,15 +69,7 @@ def __call__(self, context, callback):         else:             future = self._pool.submit(self._credentials.get_access_token)         future.add_done_callback(-            lambda x: self._get_token_callback(callback, x))--    def _get_token_callback(self, callback, future):-        try:-            access_token = future.result().access_token-        except Exception as e:-            _sign_request(callback, None, e)-        else:-            _sign_request(callback, access_token, None)+            lambda ignored_future: _get_token_callback(callback, future))",So the renaming of `x` is because [the style guide forbids single-letter identifiers](https://google.github.io/styleguide/pyguide.html?showone=Naming#Naming).The preference for `future` over `ignored_future` comes from a practice of using a value by the earliest name to which it was bound among all available names for the value (this comes up so rarely that I'm not sure I've ever thought it through in these words before...). The indication to the reader of the used future being the same future bound in the enclosing scope is worth whatever dynamic penalty is incurred (if it's even present and measureable rather than optimized away?).Also I like to feel like I'm rebelling against the `Future.add_done_callback` API which I don't think should have been designed to pass itself to the callbacks registered with it. :stuck_out_tongue:,
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/9809,103861546,2017-03-02T06:55:16Z,doc/server_side_auth.md,"@@ -0,0 +1,59 @@+Server-side API for Authenticating Clients+==========================================++NOTE: This document describes how server-side authentication works in C-core based gRPC implementations only. In gRPC Java and Go, server side authentication is handled differently.++## AuthContext++To perform server-side authentication, gRPC exposes the *authentication context* for each call. The context exposes important authentication-related information about the RPC such as the type of security/authentication type being used and the peer identity.++The authentication context is structured as a multi-map of key-value pairs - the *auth properties*. In addition to that, for authenticated RPCs, the set of properties corresponding to a selected key will represent the verified identity of the caller - the *peer identity*.++The contents of the *auth properties* are populated by an *auth interceptor*. The interceptor also chooses which property key will act as the peer identity (e.g. for client certificate authentication this property will be `""x509_common_name""` or `""x509_subject_alternative_name""`).++WARNING: AuthContext is the only reliable source of truth when it comes to authenticating RPCs. Using any other call/context properties for authentication purposes is wrong and inherently unsafe.++####Example AuthContext contents++For secure channel using mutual TLS authentication with both client and server certificates (test certificates from this repository are used).++Populated auth properties:+```+""transport_security_type"": ""ssl""  # connection is secured using TLS/SSL+""x509_common_name"": ""*.test.google.com""  # from client's certificate+""x509_pem_cert"": ""-----BEGIN CERTIFICATE-----\n...""  # client's PEM encoded certificate+""x509_subject_alternative_name"": ""*.test.google.fr""+""x509_subject_alternative_name"": ""waterzooi.test.google.be""+""x509_subject_alternative_name"": ""*.test.youtube.com""+""x509_subject_alternative_name"": ""192.168.1.3""+```++The peer identity is set of all properties named `""x509_subject_alternative_name""`:+```+peer_identity_property_name = ""x509_subject_alternative_name""+```++## AuthProperty++Auth properties are elements of the AuthContext. They have a name (a key of type string) and a value which can be a string or binary data.++## Auth Interceptors++Auth interceptors are gRPC components that populate contents of the auth context based on gRPC's internal state and/or call metadata.+gRPC comes with some basic ""interceptors"" already built-in.++WARNING: While there is a public API that allows anyone to write their own custom interceptor, please think twice before using it.+There are legitimate uses for custom interceptors but you should keep in mind that as auth interceptors essentially decide which RPCs are authenticated and which are not, their code is very sensitive from the security perspective and getting things wrong might have terrible consequences. If unsure, we strongly recommend to rely on official & proven interceptors that come with gRPC.","s/terrible consequences/serious consequences/You can add:""as server applications could see as authenticated some metadata that is not validated properly or not at all."".",
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/9809,103861896,2017-03-02T06:58:46Z,doc/server_side_auth.md,"@@ -0,0 +1,59 @@+Server-side API for Authenticating Clients+==========================================++NOTE: This document describes how server-side authentication works in C-core based gRPC implementations only. In gRPC Java and Go, server side authentication is handled differently.++## AuthContext++To perform server-side authentication, gRPC exposes the *authentication context* for each call. The context exposes important authentication-related information about the RPC such as the type of security/authentication type being used and the peer identity.++The authentication context is structured as a multi-map of key-value pairs - the *auth properties*. In addition to that, for authenticated RPCs, the set of properties corresponding to a selected key will represent the verified identity of the caller - the *peer identity*.++The contents of the *auth properties* are populated by an *auth interceptor*. The interceptor also chooses which property key will act as the peer identity (e.g. for client certificate authentication this property will be `""x509_common_name""` or `""x509_subject_alternative_name""`).++WARNING: AuthContext is the only reliable source of truth when it comes to authenticating RPCs. Using any other call/context properties for authentication purposes is wrong and inherently unsafe.++####Example AuthContext contents++For secure channel using mutual TLS authentication with both client and server certificates (test certificates from this repository are used).++Populated auth properties:+```+""transport_security_type"": ""ssl""  # connection is secured using TLS/SSL+""x509_common_name"": ""*.test.google.com""  # from client's certificate+""x509_pem_cert"": ""-----BEGIN CERTIFICATE-----\n...""  # client's PEM encoded certificate+""x509_subject_alternative_name"": ""*.test.google.fr""+""x509_subject_alternative_name"": ""waterzooi.test.google.be""+""x509_subject_alternative_name"": ""*.test.youtube.com""+""x509_subject_alternative_name"": ""192.168.1.3""+```++The peer identity is set of all properties named `""x509_subject_alternative_name""`:+```+peer_identity_property_name = ""x509_subject_alternative_name""+```++## AuthProperty++Auth properties are elements of the AuthContext. They have a name (a key of type string) and a value which can be a string or binary data.++## Auth Interceptors++Auth interceptors are gRPC components that populate contents of the auth context based on gRPC's internal state and/or call metadata.+gRPC comes with some basic ""interceptors"" already built-in.++WARNING: While there is a public API that allows anyone to write their own custom interceptor, please think twice before using it.+There are legitimate uses for custom interceptors but you should keep in mind that as auth interceptors essentially decide which RPCs are authenticated and which are not, their code is very sensitive from the security perspective and getting things wrong might have terrible consequences. If unsure, we strongly recommend to rely on official & proven interceptors that come with gRPC.++####Available auth interceptors+- TLS/SSL certificate authentication (built into gRPC's security layer, automatically used whenever you use a secure connection)+- (coming soon) JWT auth token authentication+- more will be added over time++## Status (by language)+C-core exposes low level API to access auth context contents and to implement a auth interceptor. ++A high level API to access AuthContext contents is available in these languages:+- C++","C++ also has support for the interceptor API (it's called AuthMetadataProcessor, it would be nice to rename but this is a public API).",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/9866,103992653,2017-03-02T18:18:03Z,src/python/grpcio/grpc/_auth.py,"@@ -60,15 +69,7 @@ def __call__(self, context, callback):         else:             future = self._pool.submit(self._credentials.get_access_token)         future.add_done_callback(-            lambda x: self._get_token_callback(callback, x))--    def _get_token_callback(self, callback, future):-        try:-            access_token = future.result().access_token-        except Exception as e:-            _sign_request(callback, None, e)-        else:-            _sign_request(callback, access_token, None)+            lambda ignored_future: _get_token_callback(callback, future))","Summary of our offline discussion: the closure is bound to a mutable variable, not a value—using the argument as opposed to closure will prevent future bugs that might arise by accidentally reassigning the `future` variable in a possible future CL (however improbable due to our pervasive use of single assignments where possible). ",
17325098,makdharma,https://api.github.com/repos/grpc/grpc/pulls/9247,104056649,2017-03-02T23:26:51Z,src/objective-c/RxLibrary/GRXImmediateSingleWriter.m,"@@ -0,0 +1,83 @@+/*+ *+ * Copyright 2016, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#import ""GRXImmediateSingleWriter.h""++@implementation GRXImmediateSingleWriter {+  id _value;+  NSError *_errorOrNil;+  id<GRXWriteable> _writeable;+}++@synthesize state = _state;++- (instancetype)initWithValue:(id)value error:(NSError *)errorOrNil {+  if (self = [super init]) {+    _value = value;+    _errorOrNil = errorOrNil;+    _state = GRXWriterStateNotStarted;+  }+  return self;+}+++ (GRXWriter *)writerWithValue:(id)value {+  return [[self alloc] initWithValue:value error:nil];+}++- (void)startWithWriteable:(id<GRXWriteable>)writeable {+  _state = GRXWriterStateStarted;+  _writeable = writeable;+  [writeable writeValue:_value];+  [self finishWithError:_errorOrNil];+}++- (void)finishWithError:(NSError *)errorOrNil {+  _state = GRXWriterStateFinished;+  _errorOrNil = nil;+  _value = nil;+  id<GRXWriteable> writeable = _writeable;+  _writeable = nil;+  [writeable writesFinishedWithError:errorOrNil];+}++- (void)setState:(GRXWriterState)newState {",Is state management needed in this class? How about just assign something constant to _state since nobody will use it when using GRXImmediateWriter?,
17325098,makdharma,https://api.github.com/repos/grpc/grpc/pulls/9247,104058957,2017-03-02T23:42:37Z,src/objective-c/GRPCClient/internal_testing/GRPCCall+InternalTests.m,"@@ -0,0 +1,61 @@+/*+ *+ * Copyright 2017, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#import ""GRPCCall+InternalTests.h""++#import ""../private/GRPCOpBatchLog.h""","wrap the entire class in the GRPC_TEST_OBJC macro, otherwise ObjC creates memory even when you are not calling it - says jcanizales@ the great.",
176950,vapier,https://api.github.com/repos/grpc/grpc/pulls/9965,104098146,2017-03-03T06:56:27Z,tools/distrib/yapf_code.sh,"@@ -34,28 +34,40 @@ set -ex cd $(dirname $0)/../..  DIRS=src/python-EXCLUSIONS='src/python/grpcio/grpc_*.py src/python/grpcio_health_checking/grpc_*.py src/python/grpcio_reflection/grpc_*.py src/python/grpcio_tests/grpc_*.py'+EXCLUSIONS='grpcio/grpc_*.py grpcio_health_checking/grpc_*.py grpcio_reflection/grpc_*.py grpcio_tests/grpc_*.py' -VIRTUALENV=python_format_venv+VIRTUALENV=yapf_virtual_environment  virtualenv $VIRTUALENV PYTHON=`realpath $VIRTUALENV/bin/python`-$PYTHON -m pip install futures+$PYTHON -m pip install --upgrade pip+$PYTHON -m pip install --upgrade futures $PYTHON -m pip install yapf==0.16.0 -exclusion_args=""""-for exclusion in $EXCLUSIONS; do-  exclusion_args=""$exclusion_args --exclude $exclusion""-done+function yapf {+    for exclusion in $EXCLUSIONS; do+        exclusion_args=""$exclusion_args --exclude $1/$exclusion""+    done+    set -f  # We do not want to expand the wildcard on the next line.+    $PYTHON -m yapf -i -r --style=setup.cfg -p $exclusion_args $1+} -script_result=0-for dir in $DIRS; do-  tempdir=`mktemp -d`-  cp -RT $dir $tempdir-  $PYTHON -m yapf -i -r -p $exclusion_args $dir-  if ! diff -r $dir $tempdir; then-    script_result=1-  fi-  rm -rf $tempdir-done-exit $script_result+if [ ""$TEST"" == """" ]+then+    for dir in $DIRS; do+	yapf $dir+    done+else+    ok=yes+    for dir in $DIRS; do+	tempdir=`mktemp -d`+	cp -RT $dir $tempdir",all of these path vars are missing quoting which can lead to really bad behavior if `$tempdir` contains a space,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/9916,104134731,2017-03-03T11:19:27Z,tools/run_tests/run_interop_tests.py,"@@ -733,6 +738,63 @@ def aggregate_http2_results(stdout):     'percent': 1.0 * passed / (passed + failed)   } +def push_to_gke_registry(image, gcr_path, gcr_tag='latest', with_files=[]):","Again, our testing scripts are already way too complicated and they are hard enough to maintain already. I understand the intention here (and it is reasonable), but in general, I'd like to set a really high bar for adding functionality to run_*_tests.py scripts.I'd prefer to have some very minimal changes to run_interop_tests.py to help you obtain the information you need (e.g. get the list of commands you need, list of identifiers of the docker images and a flag for avoiding deleting of them) and all other logic would be accomplished by a separate (and specialized) script.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/9916,104134978,2017-03-03T11:21:15Z,tools/run_tests/run_interop_tests.py,"@@ -769,6 +831,9 @@ def aggregate_http2_results(stdout):                   action='store_const',                   const=True,                   help='Run cloud_to_prod_auth tests.')+argp.add_argument('--gcr_tag',","I'd prefer something very minimal like ""--keep_docker_images"" that would avoid removing docker images once the script finishes and printed/saved the list of image names kept.With that input, you can then have a separate script that does the rest.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/9916,104135943,2017-03-03T11:28:02Z,tools/run_tests/run_interop_tests.py,"@@ -733,6 +738,63 @@ def aggregate_http2_results(stdout):     'percent': 1.0 * passed / (passed + failed)   } +def push_to_gke_registry(image, gcr_path, gcr_tag='latest', with_files=[]):+  """"""Tags and Pushes a docker image in Google Containger Registry.++  image: docker image name grpc_interop_java:26328ad8+  gcr_path: the name path for docker image on Google Container Registry (GCR).+  gcr_tag: tag for uploading docker image to GCR.+  with_files: additional files to copied into the docker image.+  """"""+  tag_idx = image.find(':')+  if tag_idx == -1:+    print('Failed to parse docker image name %s' % image)+    return False++  # Create an empty tmp directory.+  tmp_dir = os.path.join('/tmp', os.path.basename(DOCKER_TEST_INFO))+  shutil.rmtree(tmp_dir, ignore_errors=True)+  os.makedirs(tmp_dir)++  # Stores the original image:tag which will be referenced by tests+  # during replay.+  with open(os.path.join(tmp_dir, 'original_image'), 'w') as f:+    f.write(image + '\n')++  # Copy with_files inside the tmp directory.+  for f in with_files:+    shutil.copy(f, tmp_dir)++  # Store all files with the image and commit it.+  tag_name = '%s/%s:%s' % (gcr_path, image[:tag_idx], gcr_tag)+  tmp_container_name = str(uuid.uuid4())+  cmd = (","the `withfiles` step adds some extra complexity (add to existing image and commit, delete old image, etc....), it would be good if we could avoid it.I understand how testcase_cmds.txt file would be useful, but report.xml doesn't seem to be useful at all.",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/9843,104526742,2017-03-06T21:26:03Z,src/core/lib/iomgr/udp_server.h,"@@ -58,12 +58,11 @@ typedef void (*grpc_udp_server_orphan_cb)(grpc_exec_ctx *exec_ctx,                                           grpc_fd *emfd);  /* Create a server, initially not bound to any ports */-grpc_udp_server *grpc_udp_server_create(void);+grpc_udp_server *grpc_udp_server_create(struct grpc_server *server);","I'd like to expunge grpc_server from udp_server entirely (what if I want a UDP socket without a grpc_server -- the use case for which is the reason this code is still in this repository)... I didn't realize it was already there, and I'd like to see it expunged quickly. It looks like it's there solely so it can be passed up in a read callback. A `void* user_data` field would be more appropriate there.As for this usage, I think passing down channel args explicitly is entirely appropriate. You'll probably want to make a copy of them during construction (which is something we plan on making cheap... around EOQ3).",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/8934,104713352,2017-03-07T16:34:39Z,examples/cpp/helloworld/greeter_async_bidi_client.cc,"@@ -0,0 +1,213 @@+/*+ *+ * Copyright 2016, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#include <iostream>+#include <memory>+#include <string>+#include <thread>++#include <grpc++/grpc++.h>++#include ""hellostreamingworld.grpc.pb.h""++using grpc::Channel;+using grpc::ClientAsyncReaderWriter;+using grpc::ClientContext;+using grpc::CompletionQueue;+using grpc::Status;+using hellostreamingworld::HelloRequest;+using hellostreamingworld::HelloReply;+using hellostreamingworld::MultiGreeter;++// NOTE: This is a complex example for an asynchronous, bidirectional streaming+// client. For a simpler example, start with the+// greeter_client/greeter_async_client first.+class AsyncBidiGreeterClient {+  enum class Type {+    READ = 1,+    WRITE = 2,+    CONNECT = 3,+    WRITES_DONE = 4,+    FINISH = 5+  };++ public:+  explicit AsyncBidiGreeterClient(std::shared_ptr<Channel> channel)+      : stub_(MultiGreeter::NewStub(channel)) {+    grpc_thread_.reset(+        new std::thread(std::bind(&AsyncBidiGreeterClient::GrpcThread, this)));+    stream_ = stub_->AsyncSayHello(&context_, &cq_,+                                   reinterpret_cast<void*>(Type::CONNECT));+  }++  // Similar to the async hello example in greeter_async_client but does not+  // wait for the response. Instead queues up a tag in the completion queue+  // that is notified when the server responds back (or when the stream is+  // closed). Returns false when the stream is requested to be closed.+  bool AsyncSayHello(const std::string& user) {+    if (user == ""quit"") {+      stream_->WritesDone(reinterpret_cast<void*>(Type::WRITES_DONE));+      return false;+    }++    // Data we are sending to the server.+    HelloRequest request;+    request.set_name(user);++    // This is important: You can have at most one write or at most one read+    // at any given time. The throttling is performed by gRPC completion+    // queue. If you queue more than one write/read, the stream will crash.+    // Because this stream is bidirectional, you *can* have a single read+    // and a single write request queued for the same stream. Writes and reads+    // are independent of each other in terms of ordering/delivery.+    std::cout << "" ** Sending request: "" << user << std::endl;+    stream_->Write(request, reinterpret_cast<void*>(Type::WRITE));+    return true;+  }++  ~AsyncBidiGreeterClient() {+    std::cout << ""Shutting down client...."" << std::endl;+    grpc::Status status;+    cq_.Shutdown();+    grpc_thread_->join();","So this is tricky. I think it will work in this case, but not necessarily in general. In particular, if the thread code calls any virtual function of this class, you'll have the problem of having a vtbl reference concurrent with the destructor. I like ending multithreading before getting to the destructor. In this case, it doesn't matter probably since there are no virtual functions; maybe declare the class `final` to leave no doubt.  ",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/8934,104718095,2017-03-07T16:51:46Z,examples/cpp/helloworld/greeter_async_bidi_server.cc,"@@ -0,0 +1,197 @@+/*+ *+ * Copyright 2016, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#include <iostream>+#include <memory>+#include <string>+#include <thread>++#include <grpc++/grpc++.h>++#include ""hellostreamingworld.grpc.pb.h""++using grpc::Server;+using grpc::ServerAsyncReaderWriter;+using grpc::ServerBuilder;+using grpc::ServerContext;+using grpc::ServerCompletionQueue;+using grpc::Status;+using hellostreamingworld::HelloRequest;+using hellostreamingworld::HelloReply;+using hellostreamingworld::MultiGreeter;++enum class Type { READ = 1, WRITE = 2, CONNECT = 3, DONE = 4, FINISH = 5 };++// NOTE: This is a complex example for an asynchronous, bidirectional streaming+// server. For a simpler example, start with the+// greeter_server/greeter_async_server first.++// Most of the logic is similar to AsyncBidiGreeterClient, so follow that class+// for detailed comments. Two main differences between the server and the client+// are: (a) Server cannot initiate a connection, so it first waits for a+// 'connection'. (b) Server can handle multiple streams at the same time, so+// the completion queue/server have a longer lifetime than the client(s).+class AsyncBidiGreeterServer {+ public:+  AsyncBidiGreeterServer() {+    // In general avoid setting up the server in the main thread (specifically,+    // in a constructor-like function such as this). We ignore this in the+    // context of an example.+    std::string server_address(""0.0.0.0:50051"");++    ServerBuilder builder;+    builder.AddListeningPort(server_address, grpc::InsecureServerCredentials());+    builder.RegisterService(&service_);+    cq_ = builder.AddCompletionQueue();+    server_ = builder.BuildAndStart();++    // This initiates a single stream for a single client. To allow multiple+    // clients in different threads to connect, simply 'request' from the+    // different threads. Each stream is independent but can use the same+    // completion queue/context objects.+    stream_.reset(+        new ServerAsyncReaderWriter<HelloReply, HelloRequest>(&context_));","And changing this would require a list or vector of contexts, streams, etc, as well as a state-machine-based CQ (as opposed to a single type-based tag).",
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/10018,104732607,2017-03-07T17:49:35Z,src/core/lib/iomgr/tcp_server_posix.c,"@@ -114,6 +114,8 @@ struct grpc_tcp_server {    /* is this server shutting down? */   bool shutdown;+  /* have listeners been shutdown? */+  bool shutdown_listeners;",We do not have a memset on the server creation. I guess a s->shutdown_listerners = false; is needed in the tcp_server_create?,
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/10018,104746228,2017-03-07T18:48:07Z,src/core/lib/iomgr/tcp_server_posix.c,"@@ -422,7 +424,12 @@ static void on_read(grpc_exec_ctx *exec_ctx, void *arg, grpc_error *err) {           grpc_fd_notify_on_read(exec_ctx, sp->emfd, &sp->read_closure);           return;         default:-          gpr_log(GPR_ERROR, ""Failed accept4: %s"", strerror(errno));+          if (!sp->server->shutdown_listeners) {",Do we need to take a lock on checking shutdown_listeners?,
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/10012,104789944,2017-03-07T21:56:17Z,src/php/tests/qps/client.php,"@@ -0,0 +1,166 @@+<?php+/*+ *+ * Copyright 2017, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++/*+ * PHP client for QPS testing works as follows:+ * 1. Gets initiated by a call from a proxy that implements the worker service. The+ *    argument to this client is the proxy connection information+ * 2. Initiate an RPC to the proxy to get ClientConfig+ * 3. Initiate a client-side telemetry RPC to the proxy+ * 4. Parse the client config, which includes server target information and then start+ *    a unary or streaming test as appropriate.+ * 5. After each completed RPC, send its timing to the proxy. The proxy does all histogramming+ * 6. Proxy will respond on the timing channel when it's time to complete. Our+ *    next timing write will fail and we know that it's time to stop+ * The above complex dance is since threading and async are not idiomatic and we+ * shouldn't ever be waiting to read a mark+ *+ * This test only supports a single channel since threading/async is not idiomatic+ * This test supports unary or streaming ping-pongs, as well as open-loop+ * + */++require dirname(__FILE__).'/vendor/autoload.php';++/**+ * Assertion function that always exits with an error code if the assertion is+ * falsy.+ *+ * @param $value Assertion value. Should be true.+ * @param $error_message Message to display if the assertion is false+ */+function hardAssert($value, $error_message)+{+    if (!$value) {+        echo $error_message.""\n"";+        exit(1);+    }+}++function hardAssertIfStatusOk($status)+{+    if ($status->code !== Grpc\STATUS_OK) {+        echo ""Call did not complete successfully. Status object:\n"";+        var_dump($status);+        exit(1);+    }+}++/* Start the actual client */++function qps_client_main($proxy_address) {+  echo ""Initiating php client\n"";++  $proxystubopts = [];+  $proxystubopts['credentials'] = Grpc\ChannelCredentials::createInsecure();+  $proxystub = new Grpc\Testing\ProxyClientServiceClient($proxy_address, $proxystubopts);+  list($config, $status) = $proxystub->GetConfig(new Grpc\Testing\Void())->wait();+  hardAssertIfStatusOk($status);+  hardAssert($config->getClientChannels() == 1, ""Only 1 channel supported"");+  hardAssert($config->getOutstandingRpcsPerChannel() == 1, ""Only 1 outstanding RPC supported"");++  echo ""Got configuration from proxy, target is "" . $config->getServerTargets()[0] . ""\n"";++  $stubopts = [];+  if ($config->getSecurityParams()) {+     if ($config->getSecurityParams()->getUseTestCa()) {+        $stubopts['credentials'] = Grpc\ChannelCredentials::createSsl(+            file_get_contents(dirname(__FILE__).'/../data/ca.pem'));+     } else {+       $stubopts['credentials'] = Grpc\ChannelCredentials::createSsl(null);+     }+     $override = $config->getSecurityParams()->getServerHostOverride();+     if ($override) {+     	$stubopts['grpc.ssl_target_name_override'] = $override;+     	$stubopts['grpc.default_authority'] = $override;+     }+  } else {+    $stubopts['credentials'] = Grpc\ChannelCredentials::createInsecure();+  }+  echo ""Initiating php benchmarking client\n"";++  $stub = new Grpc\Testing\BenchmarkServiceClient($config->getServerTargets()[0], $stubopts);+  $req = new Grpc\Testing\SimpleRequest();++  echo ""Set up php testing request\n"";++$req->setResponseType(Grpc\Testing\PayloadType::COMPRESSABLE);+  $req->setResponseSize($config->getPayloadConfig()->getSimpleParams()->getRespSize());+  $payload = new Grpc\Testing\Payload();+  $payload->setType(Grpc\Testing\PayloadType::COMPRESSABLE);+  $payload->setBody(str_repeat(""\0"", $config->getPayloadConfig()->getSimpleParams()->getReqSize()));+  $req->setPayload($payload);++  if (0 && $config->getLoadParams()->getLoad() == ""poisson"") {",The proto definition is here: https://github.com/grpc/grpc/blob/master/src/proto/grpc/testing/control.proto#L68,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/10022,104798829,2017-03-07T22:36:17Z,src/python/grpcio/grpc/_server.py,"@@ -560,7 +570,22 @@ def _handle_unrecognized_method(rpc_event):     return rpc_state  -def _handle_with_method_handler(rpc_event, method_handler, thread_pool):+def _reject_call(rpc_event):","But for the code and details this is a copy-and-past of `_handle_unrecognized_method` (right?). Please rename `_handle_unrecognized_method` `_reject_rpc`, add `code` and `details` parameters to it, and use it twice?",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/10022,104811899,2017-03-07T23:54:20Z,src/python/grpcio/grpc/_server.py,"@@ -560,7 +570,22 @@ def _handle_unrecognized_method(rpc_event):     return rpc_state  -def _handle_with_method_handler(rpc_event, method_handler, thread_pool):+def _reject_call(rpc_event):+    operations = (cygrpc.operation_send_initial_metadata(_common.EMPTY_METADATA,+                                                         _EMPTY_FLAGS),+                  cygrpc.operation_receive_close_on_server(_EMPTY_FLAGS),+                  cygrpc.operation_send_status_from_server(+                      _common.EMPTY_METADATA,+                      cygrpc.StatusCode.resource_exhausted,+                      b'Max requests exceeded!', _EMPTY_FLAGS),)+    rpc_state = _RPCState()+    rpc_event.operation_call.start_server_batch(+        operations, lambda ignored_event: (rpc_state, (),))+    return rpc_state+++def _handle_with_method_handler(rpc_event, method_handler, thread_pool,+                                server_state):","What was an attractive property of this code before and that I'd like to preserve is that server state happens in the high-level functions located toward the end of the file and RPC state happens in the low-level functions located toward the beginning of the file and [there's currently only one painful exception](https://github.com/grpc/grpc/issues/6597). I think that rather than seeing this function take a server state, it should instead return a means by which the higher-level server-wide function can know that the RPC handled in this lower-level RPC-specific function has terminated. And the way for it to do that is... to return the [`concurrent.futures.Future`](https://docs.python.org/3/library/concurrent.futures.html#future-objects) that came from submitting the even-lower-level RPC-handling function to the server's thread pool (so this function would have two return values), so that _handle_call can just a few lines below where it has incremented `state.active_rpc_count` register a decrementing call with `add_done_callback`.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/10012,104851332,2017-03-08T06:12:15Z,src/ruby/qps/proxy-worker.rb,"@@ -0,0 +1,167 @@+#!/usr/bin/env ruby++# Copyright 2017, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.++# Proxy of worker service implementation for running a PHP client++this_dir = File.expand_path(File.dirname(__FILE__))+lib_dir = File.join(File.dirname(this_dir), 'lib')+$LOAD_PATH.unshift(lib_dir) unless $LOAD_PATH.include?(lib_dir)+$LOAD_PATH.unshift(this_dir) unless $LOAD_PATH.include?(this_dir)++require 'grpc'+require 'optparse'+require 'histogram'+require 'etc'+require 'facter'+require 'qps-common'+require 'src/proto/grpc/testing/services_services_pb'+require 'src/proto/grpc/testing/proxy-service_services_pb'++class ProxyBenchmarkClientServiceImpl < Grpc::Testing::ProxyClientService::Service+  def initialize(port)+    @mytarget = ""localhost:"" + port.to_s+  end+  def setup(config)+    @config = config+    @histres = config.histogram_params.resolution+    @histmax = config.histogram_params.max_possible+    @histogram = Histogram.new(@histres, @histmax)+    @start_time = Time.now+    @timestream = nil+    # TODO(vjpai): Support multiple client channels by spawning off a PHP client per channel+    command = ""php "" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/tests/qps/client.php "" + @mytarget+    puts ""Starting command: "" + command+    @php_pid = spawn(command)+  end+  def stop+    if !@timestream.nil?+      # @timestream.cancel+      @timestream = nil+    end+    Process.kill(""TERM"", @php_pid)+    Process.wait(@php_pid)+  end+  def get_config(_args, _call)+    puts ""Answering get_config""+    @config+  end+  def report_time(call)+    puts ""Starting a time reporting stream""+    @timestream = call+    call.each_remote_read do |lat|+      @histogram.add((lat.latency)*1e9)+    end+    @timestream = nil+    Grpc::Testing::Void.new+  end+  def mark(reset)+    lat = Grpc::Testing::HistogramData.new(+      bucket: @histogram.contents,+      min_seen: @histogram.minimum,+      max_seen: @histogram.maximum,+      sum: @histogram.sum,+      sum_of_squares: @histogram.sum_of_squares,+      count: @histogram.count+    )+    elapsed = Time.now-@start_time+    if reset+      @start_time = Time.now+      @histogram = Histogram.new(@histres, @histmax)+    end+    Grpc::Testing::ClientStats.new(latencies: lat, time_elapsed: elapsed)+  end+end++class WorkerServiceImpl < Grpc::Testing::WorkerService::Service",nit: rename the class here? - worried there might be silent overrides with the other `WorkerServiceImpl`,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/10012,104961048,2017-03-08T16:40:08Z,src/ruby/qps/proxy-worker.rb,"@@ -0,0 +1,160 @@+#!/usr/bin/env ruby++# Copyright 2017, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.++# Proxy of worker service implementation for running a PHP client++this_dir = File.expand_path(File.dirname(__FILE__))+lib_dir = File.join(File.dirname(this_dir), 'lib')+$LOAD_PATH.unshift(lib_dir) unless $LOAD_PATH.include?(lib_dir)+$LOAD_PATH.unshift(this_dir) unless $LOAD_PATH.include?(this_dir)++require 'grpc'+require 'optparse'+require 'histogram'+require 'etc'+require 'facter'+require 'qps-common'+require 'src/proto/grpc/testing/services_services_pb'+require 'src/proto/grpc/testing/proxy-service_services_pb'++class ProxyBenchmarkClientServiceImpl < Grpc::Testing::ProxyClientService::Service+  def initialize(port)+    @mytarget = ""localhost:"" + port.to_s+  end+  def setup(config)+    @config = config+    @histres = config.histogram_params.resolution+    @histmax = config.histogram_params.max_possible+    @histogram = Histogram.new(@histres, @histmax)+    @start_time = Time.now+    # TODO(vjpai): Support multiple client channels by spawning off a PHP client per channel+    command = ""php "" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/tests/qps/client.php "" + @mytarget+    puts ""Starting command: "" + command+    @php_pid = spawn(command)+  end+  def stop+    Process.kill(""TERM"", @php_pid)+    Process.wait(@php_pid)+  end+  def get_config(_args, _call)+    puts ""Answering get_config""+    @config+  end+  def report_time(call)+    puts ""Starting a time reporting stream""+    call.each_remote_read do |lat|+      @histogram.add((lat.latency)*1e9)+    end+    Grpc::Testing::Void.new+  end+  def mark(reset)+    lat = Grpc::Testing::HistogramData.new(+      bucket: @histogram.contents,+      min_seen: @histogram.minimum,+      max_seen: @histogram.maximum,+      sum: @histogram.sum,+      sum_of_squares: @histogram.sum_of_squares,+      count: @histogram.count+    )+    elapsed = Time.now-@start_time+    if reset+      @start_time = Time.now+      @histogram = Histogram.new(@histres, @histmax)+    end+    Grpc::Testing::ClientStats.new(latencies: lat, time_elapsed: elapsed)+  end+end++class ProxyWorkerServiceImpl < Grpc::Testing::WorkerService::Service+  def cpu_cores+    Facter.value('processors')['count']+  end+  def run_server(reqs)+    raise 'PHP proxy worker doesn\'t support server'","small nit: fine leaving as is but this could also raise `GRPC::BadStatus.new_status_exception(GRPC::Core::StatusCodes::UNIMPLEMENTED, 'PHP proxy...')`(ruby server also gives unimplemented if the method isn't defined in the subclass)",
25518558,yongni,https://api.github.com/repos/grpc/grpc/pulls/10037,104967832,2017-03-08T17:05:31Z,tools/run_tests/run_interop_tests.py,"@@ -1029,5 +1096,8 @@ def aggregate_http2_results(stdout):   dockerjob.finish_jobs([j for j in server_jobs.itervalues()])    for image in docker_images.itervalues():-    print('Removing docker image %s' % image)-    dockerjob.remove_image(image)+    if not args.manual_run:+      print('Removing docker image %s' % image)+      dockerjob.remove_image(image)+    else:+      print('Preserving docker image: %s' % image)",Can we save the list of images produced in this cycle to a docker_images file so it can be 1) cleaned up manually; and/or 2) uploaded to GCR by another script?,
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/9984,105054832,2017-03-08T23:46:21Z,test/cpp/microbenchmarks/bm_pollset.cc,"@@ -0,0 +1,164 @@+/*+ *+ * Copyright 2017, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++/* Test out pollset latencies */++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>++extern ""C"" {+#include ""src/core/lib/iomgr/ev_posix.h""+#include ""src/core/lib/iomgr/pollset.h""+#include ""src/core/lib/iomgr/wakeup_fd_posix.h""+}++#include ""test/cpp/microbenchmarks/helpers.h""+#include ""third_party/benchmark/include/benchmark/benchmark.h""++#include <string.h>++auto& force_library_initialization = Library::get();++static void shutdown_ps(grpc_exec_ctx* exec_ctx, void* ps, grpc_error* error) {+  grpc_pollset_destroy(static_cast<grpc_pollset*>(ps));+}++static void BM_CreateDestroyPollset(benchmark::State& state) {+  TrackCounters track_counters;+  size_t ps_sz = grpc_pollset_size();+  grpc_pollset* ps = static_cast<grpc_pollset*>(gpr_malloc(ps_sz));+  gpr_mu* mu;+  grpc_exec_ctx exec_ctx = GRPC_EXEC_CTX_INIT;+  grpc_closure shutdown_ps_closure;+  grpc_closure_init(&shutdown_ps_closure, shutdown_ps, ps,+                    grpc_schedule_on_exec_ctx);+  while (state.KeepRunning()) {+    memset(ps, 0, ps_sz);+    grpc_pollset_init(ps, &mu);+    gpr_mu_lock(mu);+    grpc_pollset_shutdown(&exec_ctx, ps, &shutdown_ps_closure);+    gpr_mu_unlock(mu);+    grpc_exec_ctx_flush(&exec_ctx);+  }+  grpc_exec_ctx_finish(&exec_ctx);+  gpr_free(ps);+  track_counters.Finish(state);+}+BENCHMARK(BM_CreateDestroyPollset);++static void BM_PollEmptyPollset(benchmark::State& state) {+  TrackCounters track_counters;+  size_t ps_sz = grpc_pollset_size();+  grpc_pollset* ps = static_cast<grpc_pollset*>(gpr_zalloc(ps_sz));+  gpr_mu* mu;+  grpc_pollset_init(ps, &mu);+  grpc_exec_ctx exec_ctx = GRPC_EXEC_CTX_INIT;+  gpr_timespec now = gpr_time_0(GPR_CLOCK_MONOTONIC);+  gpr_timespec deadline = gpr_inf_past(GPR_CLOCK_MONOTONIC);+  gpr_mu_lock(mu);+  while (state.KeepRunning()) {+    grpc_pollset_worker* worker;+    GRPC_ERROR_UNREF(grpc_pollset_work(&exec_ctx, ps, &worker, now, deadline));+  }+  grpc_closure shutdown_ps_closure;+  grpc_closure_init(&shutdown_ps_closure, shutdown_ps, ps,+                    grpc_schedule_on_exec_ctx);+  grpc_pollset_shutdown(&exec_ctx, ps, &shutdown_ps_closure);+  gpr_mu_unlock(mu);+  grpc_exec_ctx_finish(&exec_ctx);+  gpr_free(ps);+  track_counters.Finish(state);+}+BENCHMARK(BM_PollEmptyPollset);++template <class F>+grpc_closure* MakeClosure(F f, grpc_closure_scheduler* scheduler) {+  struct C : public grpc_closure {+    C(F f, grpc_closure_scheduler* scheduler) : f_(f) {+      grpc_closure_init(this, C::cbfn, this, scheduler);+    }+    static void cbfn(grpc_exec_ctx* exec_ctx, void* arg, grpc_error* error) {+      static_cast<C*>(arg)->f_();+    }+    F f_;+  };+  return new C(f, scheduler);+}++static void BM_PollAfterWakeup(benchmark::State& state) {","If possible, I suggest renaming `BM_PollAfterWakeup` which this is technically correct, I feel a name like `BM_SingleThreadPollOneFd` or `BM_PollOneFd` is more descriptive ?",
14932100,adelez,https://api.github.com/repos/grpc/grpc/pulls/9776,105285419,2017-03-09T22:19:37Z,tools/run_tests/run_interop_tests.py,"@@ -816,6 +836,11 @@ def aggregate_http2_results(stdout):                   action='store_const',                   const=True,                   help='Enable HTTP/2 server edge case testing. (Good client, bad server)')+argp.add_argument('--http2_edge_server_interop',",Can this be combined with http2_badserver_interop and we can call it http2_server_interop? Or do they work with different sets of client languages?,
14932100,adelez,https://api.github.com/repos/grpc/grpc/pulls/9776,105286365,2017-03-09T22:24:58Z,tools/run_tests/run_interop_tests.py,"@@ -475,8 +476,17 @@ def __str__(self):  _HTTP2_TEST_CASES = ['tls', 'framing'] +# test cases ran against http2 bad server but from usual grpc interop clients.+_POSITIVE_HTTP2_SERVER_TEST_CASES = { 'data_frame_padding': 'large_unary', 'no_df_padding_sanity_test': 'large_unary' }++# ""badserver_test_cases holds"" both ""bad server only"" tests and the ""positive+# http2 server"" tests. _HTTP2_BADSERVER_TEST_CASES = ['rst_after_header', 'rst_after_data', 'rst_during_data',-                     'goaway', 'ping', 'max_streams']+                               'goaway', 'ping', 'max_streams']++# positive and negative http2 tests are in the same list since they both target the same http2 server.+_HTTP2_BADSERVER_TEST_CASES.extend(_POSITIVE_HTTP2_SERVER_TEST_CASES.keys())","In stead of adding positive tests to the negative list, we should create a new var called _HTTP2_SERVER_TEST_CASES.",
14932100,adelez,https://api.github.com/repos/grpc/grpc/pulls/9776,105288161,2017-03-09T22:35:07Z,tools/run_tests/run_interop_tests.py,"@@ -1019,7 +1062,9 @@ def aggregate_http2_results(stdout):       _LANGUAGES_FOR_HTTP2_BADSERVER_TESTS, resultset, num_failures,","You need to add these new cases to ""http2_badserver_test_cases, _LANGUAGES_FOR_HTTP2_BADSERVER_TESTS"" in order for them to show up in the HTML report. I suggest renaming these vars by removing ""bad"" to incorporate both cases. You'll also need to modify https://github.com/grpc/grpc/blob/master/tools/run_tests/python_utils/report_utils.py#L83 and https://github.com/grpc/grpc/blob/master/tools/run_tests/interop/interop_html_report.template#L109 accordingly. It'll be nice to put them in the same table and call it ""HTTP/2 Server Tests"" as in https://grpc-testing.appspot.com/job/gRPC_interop_master/HTML_Report/. If neg and pos cases work with different client languages, you can pass a superset of those. I believe if the language is not supported, it'll just say ""unimplemented"".",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/10037,105347801,2017-03-10T08:09:15Z,tools/run_tests/run_interop_tests.py,"@@ -1029,5 +1096,8 @@ def aggregate_http2_results(stdout):   dockerjob.finish_jobs([j for j in server_jobs.itervalues()])    for image in docker_images.itervalues():-    print('Removing docker image %s' % image)-    dockerjob.remove_image(image)+    if not args.manual_run:+      print('Removing docker image %s' % image)+      dockerjob.remove_image(image)+    else:+      print('Preserving docker image: %s' % image)","Yes, the build will happen every time. And no, it will build a ""different"" image each time. It takes the base image (same each time unless the base dockerfile changes) and construct the image using ""docker run"" and then storing the resulting image.@yongni  yes, we could save the list of images kept, fine to do that in a followup PR? It's a tiny change.Btw, we can fine-tune the behavior of ""--manual_run"" in a followup PR because it's not really used by and automated tests scripts at this point, so changing the semantics a little bit is fine.",
22083734,matt-kwong,https://api.github.com/repos/grpc/grpc/pulls/10079,105369150,2017-03-10T10:22:53Z,tools/jenkins/run_performance.sh,"@@ -34,4 +34,5 @@ set -ex # Enter the gRPC repo root cd $(dirname $0)/../.. -tools/run_tests/run_performance_tests.py -l c++ node ruby csharp python --netperf --category smoketest+tools/run_tests/run_microbenchmark.py -c summary --diff_perf origin/$ghprbTargetBranch","I think it does? @ctiller please correct me if I'm wrong. The idea behind this change is that the performance PR test results were mostly being ignored. This new performance test will show a diff in performance between a PR and the master branch and this is supposed to offer more valuable data than what the current performance PR test. This was decided by the C core team, so there definitely should be more input before this change is made. Maybe run a separate performance test for wrapper languages?",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/10079,105412196,2017-03-10T14:56:49Z,tools/jenkins/run_performance.sh,"@@ -34,4 +34,5 @@ set -ex # Enter the gRPC repo root cd $(dirname $0)/../.. -tools/run_tests/run_performance_tests.py -l c++ node ruby csharp python --netperf --category smoketest+tools/run_tests/run_microbenchmark.py -c summary --diff_perf origin/$ghprbTargetBranch","ok, so if this really disables non-C/C++ scenarios, I am against it.It is fine to reduce number of scenarios we are running if there's a problem with the tests running for too long (I think majority of them is C/C++ anyway) but this suite is our only protection against breaking performance tests in master (and as a side effect this works as a de-facto stress test for wrapped languages and has lead to discovering issue in the past) - so removing it seems really off.I think microbenchmarks are great and so is getting a clear signal about regression on a PR, but they should be added as a new Jenkins job. Killing an existing test suite for OTHER languages in order to save a bit of time setting up a new job is not the right way to do things.",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/10052,105419299,2017-03-10T15:29:41Z,src/core/lib/surface/call.c,"@@ -1336,11 +1324,9 @@ static void receiving_initial_metadata_ready(grpc_exec_ctx *exec_ctx,         receiving_stream_ready, call->saved_receiving_stream_ready_bctlp,         grpc_schedule_on_exec_ctx);     call->saved_receiving_stream_ready_bctlp = NULL;-    grpc_closure_sched(exec_ctx, saved_rsr_closure, GRPC_ERROR_REF(error));+    grpc_closure_run(exec_ctx, saved_rsr_closure, GRPC_ERROR_REF(error));","We no longer have a mutex around here, which makes this an execution context safe point ==> we can call _run instead of _sched (and save some cycles).",
17325098,makdharma,https://api.github.com/repos/grpc/grpc/pulls/10009,105457161,2017-03-10T18:21:20Z,src/core/ext/transport/cronet/transport/cronet_transport.c,"@@ -155,7 +156,9 @@ struct op_state {   bool flush_read;   bool flush_cronet_when_ready;   bool pending_write_for_trailer;-  bool unprocessed_send_message;+  bool pending_send_message;+  bool pending_recv_trailing_metadata;","add ""// User has requested trailing metadata or status"". Also explain the condition for flushing.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/10093,105471168,2017-03-10T19:29:46Z,src/node/test/surface_test.js,"@@ -143,6 +143,32 @@ describe('Server.prototype.addProtoService', function() {       server.addProtoService(mathService, dummyImpls);     });   });+  it('Should allow method names as originally written', function() {+    var altDummyImpls = {+      'Div': function() {},+      'DivMany': function() {},+      'Fib': function() {},+      'Sum': function() {}+    };+    assert.doesNotThrow(function() {+      server.addProtoService(mathService, altDummyImpls);+    });+  });+  it('Should have a conflict between name variations', function() {+    /* This is really testing that both name variations are actually used,+       by checking that the method actually gets registered, for the+       corresponding function, in both cases */+    var altDummyImpls = {+      'Div': function() {},",could this let a bad name like `randomName` get registered for `Div`?,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/10113,105679218,2017-03-13T14:52:49Z,tools/run_tests/run_tests_matrix.py,"@@ -130,6 +130,15 @@ def _create_test_jobs(extra_args=[], inner_jobs=_DEFAULT_INNER_JOBS):                              extra_args=extra_args,                              inner_jobs=inner_jobs) +  for compiler in ['python3.4', 'python3.5', 'python3.6', 'pypy']:","Depending on how long each of the tests suites takes, we might not have the capacity to run full build and tests for all 4 python configuration (I remember python tests used to take much longer than tests for other languages - it might not be the case anymore).It might make sense to run tests for python2.7 and python3.6 (oldest and newest) and only run the build for the others? Not an expert on what the differences between python versions are though.Also, it doesn't make sense to add the same configurations to both  ""basictests"" and ""portability"" (portability does exactly the same build but it skips the tests) -  e.g. adding  python3.6 to portability once it's already in basic tests only wastes resources.",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/9964,105699296,2017-03-13T16:04:34Z,include/grpc++/impl/codegen/async_stream.h,"@@ -505,6 +640,40 @@ class ServerAsyncReaderWriter final     call_.PerformOps(&write_ops_);   } +  void Write(const W& msg, WriteOptions options, void* tag) override {","Just be wary here: too much abstraction is going to hurt readability and performance.I can definitely see adding an 'EnsureInitialMetadataSent()' method that takes over this stanza however:```   if (!ctx_->sent_initial_metadata_) {      write_ops_.SendInitialMetadata(ctx_->initial_metadata_,                                     ctx_->initial_metadata_flags());      if (ctx_->compression_level_set()) {        write_ops_.set_compression_level(ctx_->compression_level());      }      ctx_->sent_initial_metadata_ = true;    }```",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/10131,105723485,2017-03-13T17:37:52Z,src/core/lib/iomgr/error_internal.h,"@@ -48,12 +48,12 @@ struct grpc_linked_error {  struct grpc_error {   gpr_refcount refs;+  gpr_atm error_string;","I would suggest one of two alternatives here:1. Put the atomics in a struct within a struct (there would be no runtime overhead of doing so) and then just incrementing by the size of that inner struct. That way there's no problem in maintaining this line in the future if you realize you need to add more atomics there. But that would make this CL substantially uglier since every reference to refs or error_string would need to be changed to error_atomic_struct.{refs,error_string} . This is optional and I could see going either way on that one.2. Put a comment in the struct clearly identifying that any atomic variables need to go at the top since the rest will be copied in bulk by raw memcpy. This is mandatory since this will not be easy to follow otherwise.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/10131,105738078,2017-03-13T18:34:14Z,src/core/lib/iomgr/error_internal.h,"@@ -48,12 +48,12 @@ struct grpc_linked_error {  struct grpc_error {   gpr_refcount refs;+  gpr_atm error_string;","I chose to do 1, I agree that that is cleaner, and seemed worth the bigger modification of the code. I also took this opportunity to be a bit less terse with my comments :)",
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/10134,105755043,2017-03-13T19:50:53Z,src/php/lib/Grpc/AbstractCall.php,"@@ -154,7 +156,11 @@ protected function _deserializeResponse($value)         if (is_array($this->deserialize)) {             list($className, $deserializeFunc) = $this->deserialize;             $obj = new $className();-            $obj->$deserializeFunc($value);+            if (method_exists($obj, $deserializeFunc)) {","The code generator is passing [response proto className, ""decode""] as `$this->deserialize` right now. I opt not to change codegen now and just defensively handle it here. Once protobuf 3.3.0 is released, I will update grpc's composer.json to require protobuf 3.3.0+. Then we can change all `decode` to `mergeFromString`.",
426013,lyuxuan,https://api.github.com/repos/grpc/grpc/pulls/9964,105770012,2017-03-13T20:59:05Z,include/grpc++/impl/codegen/async_stream.h,"@@ -225,7 +275,8 @@ class ClientAsyncWriter final : public ClientAsyncWriterInterface<W> {   Call call_;   CallOpSet<CallOpSendInitialMetadata> init_ops_;   CallOpSet<CallOpRecvInitialMetadata> meta_ops_;-  CallOpSet<CallOpSendMessage> write_ops_;+  CallOpSet<CallOpSendInitialMetadata, CallOpSendMessage, CallOpClientSendClose>+      write_ops_;   CallOpSet<CallOpClientSendClose> writes_done_ops_;   CallOpSet<CallOpRecvInitialMetadata, CallOpGenericRecvMessage,","You mean merge read op (i.e RecvInitialMetdata) with write ops on client side?I think for ServerAsyncReader we may merge meta_ops with finish_ops, and for ServerAsyncWriter and ServerAsyncReaderWriter we may merge meta_ops with write_ops",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/10100,105780728,2017-03-13T21:49:07Z,tools/run_tests/run_interop_tests.py,"@@ -635,10 +635,7 @@ def cloud_to_cloud_jobspec(language, test_case, server_name, server_host,       '--server_host=%s' % server_host,   ]   if test_case in _HTTP2_BADSERVER_TEST_CASES:-    # We are running the http2_badserver_interop test. Adjust command line accordingly.-    offset = sorted(_HTTP2_BADSERVER_TEST_CASES).index(test_case)-    client_options = common_options + ['--server_port=%s' %-                                       (int(server_port)+offset)]+    client_options = common_options + ['--server_port=%s' % server_port]","Nit, but now that we don't handle offset here, you could include server port in common_options again. Might as well for readability. Also would suggest hoisting client_options out of this conditional, and then just doing a += in the block for interop_only_options",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/10131,105794977,2017-03-13T23:14:00Z,src/core/lib/iomgr/error.c,"@@ -191,15 +192,16 @@ void grpc_error_unref(grpc_error *err, const char *file, int line,                       const char *func) {   if (grpc_error_is_special(err)) return;   gpr_log(GPR_DEBUG, ""%p: %"" PRIdPTR "" -> %"" PRIdPTR "" [%s:%d %s]"", err,-          err->refs.count, err->refs.count - 1, file, line, func);-  if (gpr_unref(&err->refs)) {+          err->atomics.refs.count, err->atomics.refs.count - 1, file, line,",Done. I called it on both parameters of the gpr_log call as I figure saving it as a temp variable defeats the purpose of the atomic load.,
10135909,dklempner,https://api.github.com/repos/grpc/grpc/pulls/10122,105801603,2017-03-14T00:04:48Z,src/core/lib/support/arena.c,"@@ -0,0 +1,99 @@+/*+ *+ * Copyright 2017, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#include ""src/core/lib/support/arena.h""+#include <grpc/support/alloc.h>+#include <grpc/support/atm.h>+#include <grpc/support/log.h>+#include <grpc/support/useful.h>++#define ROUND_UP_TO_ALIGNMENT_SIZE(x) \+  (((x) + GPR_MAX_ALIGNMENT - 1u) & ~(GPR_MAX_ALIGNMENT - 1u))++typedef struct zone {+  size_t size_begin;+  size_t size_end;+  gpr_atm next_atm;+} zone;++struct gpr_arena {+  gpr_atm size_so_far;+  zone initial_zone;+};++gpr_arena *gpr_arena_create(size_t initial_size) {+  initial_size = ROUND_UP_TO_ALIGNMENT_SIZE(initial_size);+  gpr_arena *a = gpr_zalloc(sizeof(gpr_arena) + initial_size);+  a->initial_zone.size_end = initial_size;+  return a;+}++size_t gpr_arena_destroy(gpr_arena *arena) {+  gpr_atm size = gpr_atm_no_barrier_load(&arena->size_so_far);+  zone *z = (zone *)gpr_atm_no_barrier_load(&arena->initial_zone.next_atm);+  gpr_free(arena);+  while (z) {+    zone *next_z = (zone *)gpr_atm_no_barrier_load(&z->next_atm);+    gpr_free(z);+    z = next_z;+  }+  return (size_t)size;+}++void *gpr_arena_alloc(gpr_arena *arena, size_t size) {+  size = ROUND_UP_TO_ALIGNMENT_SIZE(size);+  size_t start =+      (size_t)gpr_atm_no_barrier_fetch_add(&arena->size_so_far, size);+  zone *z = &arena->initial_zone;+  while (start > z->size_end) {+    zone *next_z = (zone *)gpr_atm_acq_load(&z->next_atm);+    if (next_z == NULL) {+      size_t next_z_size =+          GPR_MAX((size_t)gpr_atm_no_barrier_load(&arena->size_so_far), size);+      next_z = gpr_zalloc(sizeof(zone) + next_z_size);+      next_z->size_begin = z->size_end;+      next_z->size_end = z->size_end + next_z_size;+      if (!gpr_atm_rel_cas(&z->next_atm, (gpr_atm)NULL, (gpr_atm)next_z)) {+        gpr_free(next_z);+        next_z = (zone *)gpr_atm_acq_load(&z->next_atm);+      }+    }+    z = next_z;+  }+  if (start + size > z->size_end) {+    return gpr_arena_alloc(arena, size);","Possible TODO: It might be worthwhile to attempt to CAS the size back down to un-allocate the first bytes of the next block.I'm rather worried that your GPR_MAX logic above to rapidly grow in response to a large allocation won't quite work right -- the common path for a large allocation will be that it will reach the middle of a block and find the remaining space isn't big enough. Then it allocates a block of size ""size"", of which the first few bytes are already in use by the current allocation, so the next block won't be big enough either. (the following one will be, though)",
13909816,daniel-j-born,https://api.github.com/repos/grpc/grpc/pulls/10123,105823086,2017-03-14T03:49:44Z,src/core/lib/iomgr/tcp_server_posix.c,"@@ -523,11 +500,11 @@ static grpc_error *add_socket_to_server(grpc_tcp_server *s, int fd,  /* If successful, add a listener to s for addr, set *dsmode for the socket, and    return the *listener. */-static grpc_error *add_addr_to_server(grpc_tcp_server *s,-                                      const grpc_resolved_address *addr,-                                      unsigned port_index, unsigned fd_index,-                                      grpc_dualstack_mode *dsmode,-                                      grpc_tcp_listener **listener) {+grpc_error *grpc_tcp_server_add_addr(grpc_tcp_server *s,","grpc_tcp_server_add_addr is declared in tcp_server_utils_posix.h, called from tcp_server_posix.c and tcp_server_utils_posix_ifaddrs.c, and defined in tcp_server_posix.c.There is a circular dependency between tcp_server_utils_posix_ifaddrs.c and tcp_server_posix.c, because tcp_server_utils_posix_ifaddrs.c depends on tcp_server_posix.c for the definition of grpc_tcp_server_add_addr, and tcp_server_posix.c depends on tcp_server_utils_posix_ifaddrs.c for everything it defines.The dependency structure is confusing. Maybe grpc_tcp_server_add_addr needs to be in a separate file or library?",
17460127,y-zeng,https://api.github.com/repos/grpc/grpc/pulls/10123,106065539,2017-03-15T01:07:21Z,src/core/lib/iomgr/tcp_server_posix.c,"@@ -523,11 +500,11 @@ static grpc_error *add_socket_to_server(grpc_tcp_server *s, int fd,  /* If successful, add a listener to s for addr, set *dsmode for the socket, and    return the *listener. */-static grpc_error *add_addr_to_server(grpc_tcp_server *s,-                                      const grpc_resolved_address *addr,-                                      unsigned port_index, unsigned fd_index,-                                      grpc_dualstack_mode *dsmode,-                                      grpc_tcp_listener **listener) {+grpc_error *grpc_tcp_server_add_addr(grpc_tcp_server *s,","- Moved `init_max_accept_queue_size`, `get_max_accept_queue_size`, `add_socket_to_server`, `grpc_tcp_server_add_addr`, `prepare_socket` to `tcp_server_utils_posix_common.c`.- Moved `find_listener_with_addr` to `tcp_server_utils_posix_ifaddrs.c`After the change,- `tcp_server_utils_posix_common.c` does not depend on any other .c files. - `tcp_server_utils_posix_ifaddrs.c` and  `tcp_server_posix.c` depend on `tcp_server_utils_posix_common.c`.- `tcp_server_posix.c` depends on `tcp_server_utils_posix_ifaddrs.c`.",
11148519,eduherminio,https://api.github.com/repos/grpc/grpc/pulls/8934,106145014,2017-03-15T11:45:26Z,examples/cpp/helloworld/greeter_async_bidi_server.cc,"@@ -0,0 +1,197 @@+/*+ *+ * Copyright 2016, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#include <iostream>+#include <memory>+#include <string>+#include <thread>++#include <grpc++/grpc++.h>++#include ""hellostreamingworld.grpc.pb.h""++using grpc::Server;+using grpc::ServerAsyncReaderWriter;+using grpc::ServerBuilder;+using grpc::ServerContext;+using grpc::ServerCompletionQueue;+using grpc::Status;+using hellostreamingworld::HelloRequest;+using hellostreamingworld::HelloReply;+using hellostreamingworld::MultiGreeter;++enum class Type { READ = 1, WRITE = 2, CONNECT = 3, DONE = 4, FINISH = 5 };++// NOTE: This is a complex example for an asynchronous, bidirectional streaming+// server. For a simpler example, start with the+// greeter_server/greeter_async_server first.++// Most of the logic is similar to AsyncBidiGreeterClient, so follow that class+// for detailed comments. Two main differences between the server and the client+// are: (a) Server cannot initiate a connection, so it first waits for a+// 'connection'. (b) Server can handle multiple streams at the same time, so+// the completion queue/server have a longer lifetime than the client(s).+class AsyncBidiGreeterServer {+ public:+  AsyncBidiGreeterServer() {+    // In general avoid setting up the server in the main thread (specifically,+    // in a constructor-like function such as this). We ignore this in the+    // context of an example.+    std::string server_address(""0.0.0.0:50051"");++    ServerBuilder builder;+    builder.AddListeningPort(server_address, grpc::InsecureServerCredentials());+    builder.RegisterService(&service_);+    cq_ = builder.AddCompletionQueue();+    server_ = builder.BuildAndStart();++    // This initiates a single stream for a single client. To allow multiple+    // clients in different threads to connect, simply 'request' from the+    // different threads. Each stream is independent but can use the same+    // completion queue/context objects.+    stream_.reset(+        new ServerAsyncReaderWriter<HelloReply, HelloRequest>(&context_));","I am on my own way to implement a multiple-RPC/client solution example.The two main problems I'm facing are the following:- Clients aren't able to wait for the info to be generated by the server (they do in both simple async and simple stream, if I am not wrong).- I want the server to send multiple streams, when available (see the previous issue), but once a stream ends, I am having a hard time trying clients to keep listening to another one:After the server does a `stream_Finish()`, clients don't seem to recognize the end of the stream with `!cq_.Next(&got_tag, &ok)` and they just keep sending requests with `stream_->Write()` in a thread while blocked in the other one, so they need to be restarted to read another stream from the server (which I assume works properly since no restart is needed to send new streams to another clients that ask for them, or to the previous, restarted client).Any clues?",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/10126,106217893,2017-03-15T16:41:19Z,tools/gce/linux_performance_worker_init.sh,"@@ -135,6 +135,12 @@ curl -sSL https://get.rvm.io | bash -s stable --ruby source ~/.rvm/scripts/rvm gem install bundler +# PHP dependencies","Oh, you mean the currently running workers. No, it's not on those yet. Ok, I'll get that list from you and can figure out how to do this. I have run it on a new worker built from scratch.",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/9850,106220302,2017-03-15T16:50:03Z,src/core/ext/client_channel/client_channel.c,"@@ -1045,6 +1138,27 @@ static void start_transport_stream_op_locked_inner(grpc_exec_ctx *exec_ctx,   add_waiting_locked(calld, op); } +static void on_complete_locked(grpc_exec_ctx *exec_ctx, void *arg,",rename to on_complete (no longer under any lock),
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/9850,106225461,2017-03-15T17:08:49Z,src/core/ext/client_channel/retry_throttle.c,"@@ -0,0 +1,234 @@+/*+ *+ * Copyright 2017, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#include ""src/core/ext/client_channel/retry_throttle.h""++#include <limits.h>+#include <string.h>++#include <grpc/support/alloc.h>+#include <grpc/support/atm.h>+#include <grpc/support/avl.h>+#include <grpc/support/string_util.h>+#include <grpc/support/sync.h>++//+// server_retry_throttle_data+//++struct grpc_server_retry_throttle_data {+  gpr_refcount refs;+  int max_milli_tokens;+  int milli_token_ratio;+  gpr_atm milli_tokens;+  // A pointer to the replacement for this grpc_server_retry_throttle_data+  // entry.  If non-NULL, then this entry is stale and must not be used.+  // We hold a reference to the replacement.+  gpr_atm replacement;+};++static void get_replacement_throttle_data_if_needed(+    grpc_server_retry_throttle_data** throttle_data) {+  while (true) {+    grpc_server_retry_throttle_data* new_throttle_data =+        (grpc_server_retry_throttle_data*)gpr_atm_acq_load(+            &(*throttle_data)->replacement);+    if (new_throttle_data == NULL) return;+    *throttle_data = new_throttle_data;+  }+}++bool grpc_server_retry_throttle_data_record_failure(+    grpc_server_retry_throttle_data* throttle_data) {+  // First, check if we are stale and need to be replaced.+  get_replacement_throttle_data_if_needed(&throttle_data);+  // We decrement milli_tokens by 1000 (1 token) for each failure.+  const int delta = -1000;+  const int old_value = (int)gpr_atm_full_fetch_add(+      &throttle_data->milli_tokens, (gpr_atm)delta);+  // If the above change takes us below 0, then re-add the excess.  Note+  // that between these two atomic operations, the value will be+  // artificially low by as much as 1000, but this window should be+  // brief.+  int new_value = old_value - 1000;+  if (new_value < 0) {+    const int excess_value = new_value - (old_value < 0 ? old_value : 0);+    gpr_atm_full_fetch_add(&throttle_data->milli_tokens,+                           (gpr_atm)-excess_value);+    new_value = 0;+  }+  // Retries are allowed as long as the new value is above the threshold+  // (max_milli_tokens / 2).+  return new_value > throttle_data->max_milli_tokens / 2;+}++void grpc_server_retry_throttle_data_record_success(+    grpc_server_retry_throttle_data* throttle_data) {+  // First, check if we are stale and need to be replaced.+  get_replacement_throttle_data_if_needed(&throttle_data);+  // We increment milli_tokens by milli_token_ratio for each success.+  const int delta = throttle_data->milli_token_ratio;+  const int old_value = (int)gpr_atm_full_fetch_add(+      &throttle_data->milli_tokens, (gpr_atm)delta);+  // If the above change takes us over max_milli_tokens, then subtract+  // the excess.  Note that between these two atomic operations, the+  // value will be artificially high by as much as milli_token_ratio,+  // but this window should be brief.+  const int new_value = old_value + throttle_data->milli_token_ratio;+  if (new_value > throttle_data->max_milli_tokens) {+    const int excess_value =","I think this wants to be a CAS loop that guarantees that the new value is <= max.Maybe we want something like:```cvoid gpr_atm_no_barrier_clamped_add(gpr_atm *val, gpr_atm delta, gpr_atm min, gpr_atm max) {  gpr_atm cur, new;  do {    cur = gpr_atm_no_barrier_load(val);    new = GPR_CLAMP(cur + delta, min, max);  } while (!gpr_atm_no_barrier_cas(val, cur, new));}```Sidenote: since there's no dependent memory on the tokens value, I don't think a barrier is required here.",
961599,murgatroid99,https://api.github.com/repos/grpc/grpc/pulls/9336,106466239,2017-03-16T16:30:25Z,src/ruby/qps/multiprocess_server_worker.rb,"@@ -0,0 +1,72 @@+# Copyright 2017, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.++this_dir = File.expand_path(File.dirname(__FILE__))+$LOAD_PATH.unshift(this_dir) unless $LOAD_PATH.include?(this_dir)++require 'optparse'+require 'thread'++require 'server'++class SimpleServerConfig+  attr_accessor :security_params+end++def main+  config = SimpleServerConfig.new+  config.security_params = false+  port = 0+  OptionParser.new do |opts|+    opts.on('--port=P', Integer) do |p|+      port = p+    end+    opts.on('--tls') do+      config.security_params = true+    end+  end.parse!+  p ""Server worker listening on port #{port}""+  bms = BenchmarkServer.new(config, port)+  stopping = false+  stop_mutex = Mutex.new+  stop_cv = ConditionVariable.new+  Signal.trap(""USR1"") do+    stopping = true+    stop_cv.signal","Can you be more specific? I am waiting on this CV below, the condition variable `signal` method does appear to be signal safe.",
5120183,jcanizales,https://api.github.com/repos/grpc/grpc/pulls/9247,106547841,2017-03-16T22:35:04Z,src/objective-c/GRPCClient/GRPCCall.m,"@@ -269,7 +274,7 @@ - (void)sendHeaders:(NSDictionary *)headers {   // TODO(jcanizales): Add error handlers for async failures   GRPCOpSendMetadata *op = [[GRPCOpSendMetadata alloc] initWithMetadata:headers                                                                   flags:[GRPCCall callFlagsForHost:_host path:_path]-                                                                handler:nil];+                                                                handler:nil];  // No clean-up needed after SEND_INITIAL_METADATA","Let's just remove the parameter (and if you want, add the comment in `GRPCOpSendMetadata` explaining why there's no handler).",
5120183,jcanizales,https://api.github.com/repos/grpc/grpc/pulls/9247,106550006,2017-03-16T22:49:54Z,src/objective-c/RxLibrary/GRXImmediateSingleWriter.m,"@@ -0,0 +1,83 @@+/*+ *+ * Copyright 2016, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#import ""GRXImmediateSingleWriter.h""++@implementation GRXImmediateSingleWriter {+  id _value;+  NSError *_errorOrNil;+  id<GRXWriteable> _writeable;+}++@synthesize state = _state;++- (instancetype)initWithValue:(id)value error:(NSError *)errorOrNil {","If the error parameter is never used, let's remove it and its ivar.",
5120183,jcanizales,https://api.github.com/repos/grpc/grpc/pulls/9247,106550646,2017-03-16T22:54:07Z,src/objective-c/GRPCClient/private/GRPCOpBatchLog.h,"@@ -0,0 +1,54 @@+/*+ *+ * Copyright 2016, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++/**+ * Logs the op batches of a client. Used for testing.+ */+@interface GRPCOpBatchLog : NSObject",Surround this class (.h and .m) with the macro guard too?,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/10194,106593085,2017-03-17T06:58:16Z,src/core/lib/iomgr/timer_generic.c,"@@ -178,7 +191,7 @@ void grpc_timer_init(grpc_exec_ctx *exec_ctx, grpc_timer *timer,   GPR_ASSERT(deadline.clock_type == g_clock_type);   GPR_ASSERT(now.clock_type == g_clock_type);   timer->closure = closure;-  timer->deadline = deadline;+  timer->deadline = timespec_to_atm(deadline);","So timespec_to_atm seems to always round down, but the timer specification is that we won't fire before the specified deadline. In this case, we'll fire up to .999 ms before the specified deadline and that may cause some issues. I think it would be fine to round up in timespec_to_atm without violating our expectations of timers, though this change does limit the use of very high-frequency timers (which were not guaranteed to be very precise anyway)",
17325098,makdharma,https://api.github.com/repos/grpc/grpc/pulls/10210,106764255,2017-03-17T23:47:49Z,src/core/ext/transport/chttp2/transport/chttp2_transport.c,"@@ -1775,6 +1776,26 @@ static void close_from_api(grpc_exec_ctx *exec_ctx, grpc_chttp2_transport *t,      It's complicated by the fact that our send machinery would be dead by      the time we got around to sending this, so instead we ignore HPACK      compression and just write the uncompressed bytes onto the wire. */+  if (!s->sent_initial_metadata) {",Please comment the thinking behind this condition?,
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/10211,106765735,2017-03-18T00:09:24Z,src/core/lib/slice/slice_buffer.c,"@@ -61,12 +56,15 @@ static void maybe_embiggen(grpc_slice_buffer *sb) {     if (sb->base_slices == sb->inlined) {       sb->base_slices = gpr_malloc(sb->capacity * sizeof(grpc_slice));       memcpy(sb->base_slices, sb->inlined, slice_count * sizeof(grpc_slice));+      sb->slices = sb->base_slices + slice_offset;     } else {+      if (sb->base_slices != sb->slices) {","It would be good to do this *before* growing the capacity: i.e line 54 above  `sb->capacity = GROW(sb->capacity)` Because after the `memmove`, we might have some space and no longer have to do a `gpr_realloc`So perhaps it would be just good do the memmove just before checking for `if (slice_count == sb->capacity)`..i.e something like:``` C static void maybe_embiggen(grpc_slice_buffer *sb) {    size_t slice_offset = (size_t)(sb->slices - sb->base_slices);    size_t slice_count = sb->count + slice_offset;      if (slice_count == sb->capacity && sb->base_slices != sb->slices) {      /* do the memmove */      /* re-calculate slice_offset or rather just reset slice_count to sb->count */    }    ..}```",
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/9810,106967646,2017-03-20T17:41:15Z,tools/grpcz/grpcz_client.cc,"@@ -0,0 +1,174 @@+/*+ *+ * Copyright 2017, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#include <iostream>+#include <memory>+#include <string>++#include <google/protobuf/util/json_util.h>+#include <grpc++/grpc++.h>+#include <grpc/support/log.h>++#include ""gflags/gflags.h""+#include ""mongoose.h""++// TODO (makdharma): remove local copies of these protos+#include ""tools/grpcz/census.grpc.pb.h""+#include ""tools/grpcz/monitoring.grpc.pb.h""++DEFINE_string(server, ""127.0.0.1:50052"",+              ""file path (or host:port) where grpcz server is running"");+DEFINE_string(http_port, ""8000"",+              ""Port id for accessing the HTTP server that renders /grpcz page"");+DEFINE_bool(print, false, ""only print the output and quit"");++using grpc::Channel;+using grpc::ClientContext;+using grpc::Status;++using ::grpc::instrumentation::v1alpha::CanonicalRpcStats;+using ::grpc::instrumentation::v1alpha::Monitoring;++static const std::string static_html_header =+    ""<!DOCTYPE html> <html> <head> <style> \+table { border-collapse: collapse; width: 100%; } \+table, td, th { border: 1px solid black; } \+</style> </head> <body>\+<div id='stats' stats='"";","Sorry for the ambiguity: I think the line should be `<div id='stats' data-stats='"";`",
961599,murgatroid99,https://api.github.com/repos/grpc/grpc/pulls/9986,107306560,2017-03-22T00:09:05Z,src/ruby/ext/grpc/rb_channel.c,"@@ -169,83 +213,125 @@ static VALUE grpc_rb_channel_init(int argc, VALUE *argv, VALUE self) {   }   rb_ivar_set(self, id_target, target);   wrapper->wrapped = ch;-  wrapper->queue = grpc_completion_queue_create(NULL);   return self; }  /*   call-seq:-    insecure_channel = Channel:new(""myhost:8080"", {'arg1': 'value1'})-    creds = ...-    secure_channel = Channel:new(""myhost:443"", {'arg1': 'value1'}, creds)+    ch.connectivity_state       -> state+    ch.connectivity_state(true) -> state -  Creates channel instances. */+  Indicates the current state of the channel, whose value is one of the+  constants defined in GRPC::Core::ConnectivityStates.++  It also tries to connect if the chennel is idle in the second form. */ static VALUE grpc_rb_channel_get_connectivity_state(int argc, VALUE *argv,                                                     VALUE self) {-  VALUE try_to_connect = Qfalse;+  VALUE try_to_connect_param = Qfalse;+  int grpc_try_to_connect = 0;   grpc_rb_channel *wrapper = NULL;   grpc_channel *ch = NULL;    /* ""01"" == 0 mandatory args, 1 (try_to_connect) is optional */-  rb_scan_args(argc, argv, ""01"", try_to_connect);+  rb_scan_args(argc, argv, ""01"", &try_to_connect_param);+  grpc_try_to_connect = RTEST(try_to_connect_param) ? 1 : 0;    TypedData_Get_Struct(self, grpc_rb_channel, &grpc_channel_data_type, wrapper);   ch = wrapper->wrapped;   if (ch == NULL) {     rb_raise(rb_eRuntimeError, ""closed!"");     return Qnil;   }-  return NUM2LONG(-      grpc_channel_check_connectivity_state(ch, (int)try_to_connect));+  return LONG2NUM(+      grpc_channel_check_connectivity_state(ch, grpc_try_to_connect)); } -/* Watch for a change in connectivity state.+typedef struct watch_state_stack {+  grpc_rb_channel *wrapper;+  gpr_timespec deadline;+  int last_state;+} watch_state_stack;++static void *watch_channel_state_without_gvl(void *arg) {+  watch_state_stack *stack = (watch_state_stack*)arg;++  gpr_timespec deadline = stack->deadline;+  grpc_rb_channel *wrapper = stack->wrapper;+  int last_state = stack->last_state;++  gpr_mu_lock(&wrapper->channel_mu);+  if (wrapper->current_connectivity_state != last_state) {+    gpr_mu_unlock(&wrapper->channel_mu);","For these if statements, I don't like having multiple unlocks. I think it makes it a bit hard to track the locks. I would instead write something like```cmu_lock()return_value = 0;if (!(condition! || condition2 || condition3)) {  gpr_cv_wait()  if (new_state != last_state) {    return_value = 1;  }}mu_unlock();return return_value;```",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/10197,107391032,2017-03-22T11:34:26Z,tools/gcp/comp_test/create_comptest_images.sh,"@@ -0,0 +1,60 @@+#!/usr/bin/env bash","I am not a big fan of the ""comp_test"" name - without knowing the context, it's totally unclear what they are good for. Btw, ""comp"" could stand for ""comparison"" as well as ""compatibility"" tests.In my mind, these tests are ""backward compatility interop tests"", ""cross-version interop tests"", ""cross-release interop tests"" or something in that sense.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/10197,107394367,2017-03-22T11:54:44Z,tools/gcp/comp_test/run_comp_test.py,"@@ -0,0 +1,147 @@+#!/usr/bin/env python2.7","IMHO, this is just way too complicated for what it's doing.After running, run_interop_tests.py --manual_run, you basically have a list of dockerimages you could just push to GCR, but instead you use a 100line script to ""enhance"" the existing docker images with 3 extra files and only then you push.To run the tests, you pull the docker images from GCR and the first thing you do is you you extract those files from the docker images using another 100line script (and you need to patch the client commands file because you changed the tags of the docker images before).Besides doing unnecessary work, I feel this still doesn't solve the question of managing which docker images/grpc version that will get tested and where will be the list of versions to be tested stored.Example: with these scripts, you would run e.g. `run_comp_test.py --gcr_tag java_cloud_to_prod:v1.0.0`, but that's pretty much equivalent as keeping the interop_clients_cmds.sh  and renaming it to `interop_clients_cmds_java_cloud_to_prod_v1.0.0.sh' - excepts for your approach you need to introduce 3 new python scripts that someone has to understand and maintain.",
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/9776,107457409,2017-03-22T16:09:26Z,tools/run_tests/run_interop_tests.py,"@@ -1049,15 +1071,15 @@ def aggregate_http2_results(stdout):                                           manual_cmd_log=client_manual_cmd_log)         jobs.append(test_job) -  if args.http2_badserver_interop:+  if args.http2_server_interop:     if not args.manual_run:-      http2_badserver_job.wait_for_healthy(timeout_seconds=600)-    for language in languages_http2_badserver_interop:-      for test_case in _HTTP2_BADSERVER_TEST_CASES:-        offset = sorted(_HTTP2_BADSERVER_TEST_CASES).index(test_case)+      http2_server_job.wait_for_healthy(timeout_seconds=600)+    for language in languages_http2_clients_for_http2_server_interop:+      for test_case in set(_HTTP2_SERVER_TEST_CASES) - set(_HTTP2_SERVER_TEST_CASES_THAT_USE_GRPC_CLIENTS):+        offset = sorted(_HTTP2_SERVER_TEST_CASES).index(test_case)",This looks broken to me. _HTTP2_SERVER_TEST_CASES now includes `data_frame_padding` and `no_df_padding_sanity_test`. Grabbing the offset from this sorted set will no longer match the 6 test cases implemented by the http2 badserver.,
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/9776,107457884,2017-03-22T16:10:57Z,tools/run_tests/run_interop_tests.py,"@@ -1049,15 +1071,15 @@ def aggregate_http2_results(stdout):                                           manual_cmd_log=client_manual_cmd_log)         jobs.append(test_job) -  if args.http2_badserver_interop:+  if args.http2_server_interop:     if not args.manual_run:-      http2_badserver_job.wait_for_healthy(timeout_seconds=600)-    for language in languages_http2_badserver_interop:-      for test_case in _HTTP2_BADSERVER_TEST_CASES:-        offset = sorted(_HTTP2_BADSERVER_TEST_CASES).index(test_case)+      http2_server_job.wait_for_healthy(timeout_seconds=600)+    for language in languages_http2_clients_for_http2_server_interop:+      for test_case in set(_HTTP2_SERVER_TEST_CASES) - set(_HTTP2_SERVER_TEST_CASES_THAT_USE_GRPC_CLIENTS):+        offset = sorted(_HTTP2_SERVER_TEST_CASES).index(test_case)","Ah, nevermind - I missed that these tests are in the http2 (no longer bad) server script as well.",
25518558,yongni,https://api.github.com/repos/grpc/grpc/pulls/10197,107505230,2017-03-22T19:07:48Z,tools/gcp/comp_test/run_comp_test.py,"@@ -0,0 +1,147 @@+#!/usr/bin/env python2.7","There are two points you raised.a) the cmds sh script can be maintained externally to the docker image;b) extra scripts introduced are unnecessary.For a), I understand.  There are pros and cons of keeping the script within docker image.  The biggest benefit is that we potentially can run the comp test independently from github so we are not tied to any github repo version control.  In fact, if we go for an extra step (which I prefer but yet to introduce), we could run these tests without even a local github clone, simply by doing  gcloud docker -- pull gcr.io/grpc-testing/java:v1.0.0; docker run ... bash -c ./run-all-saved_tests.shWe are not quite there yet, but that is the direction I'd like to suggest.  Current PR is a step towards this direction.Admittedly, the drawback of distributing the test scripts with the docker image is that it makes managing the test cases  across all releases a bit more work, especially when we try to globally adding/deleting tests.  However, I feel it is not necessarily a deal breaker.For b), I respectively disagree.  At the bare minimum, you still need to1.  run_interop_tests.py --manual_run2.  rename the scripts generated and submit a PR in github3.  upload the images to GCR and maintain a mapping of script in github <-> corresponding gcr images.4. clean up the images.5. For running the tests, download the gcr image.6. change the image tag used in the shell script to reference the gcr image rather than the original image (containing uuid tag).7. run the script and format the result to be consumed by kokoro etc.8. clean up.Step 1-4 need to be invoked every time when someone creates a snapshot.  Step5-8 need to invoked from kokoro unattended.  Hence, we do need scripts to standardize the steps instead of writing text based instructions for people (or kokoro) to follow. @makdharma @nicolasnoble Any comment here?",
10135909,dklempner,https://api.github.com/repos/grpc/grpc/pulls/10218,107514409,2017-03-22T19:51:14Z,include/grpc/impl/codegen/atm_gcc_atomic.h,"@@ -85,6 +85,11 @@ static __inline int gpr_atm_rel_cas(gpr_atm *p, gpr_atm o, gpr_atm n) {       p, &o, n, 0, __ATOMIC_RELEASE, __ATOMIC_RELAXED)); } +static __inline int gpr_atm_full_cas(gpr_atm *p, gpr_atm o, gpr_atm n) {","Remark: I think this ""full"" terminology is probably bad -- we should probably go with acq_rel, since we're already using those terms, to avoid potential confusion with, say, sequential consistency. (This shouldn't be addressed here).",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/10216,107529700,2017-03-22T20:55:32Z,src/python/grpcio_tests/tests/reflection/_reflection_servicer_test.py,"@@ -39,14 +39,18 @@ from google.protobuf import descriptor_pool from google.protobuf import descriptor_pb2 -from src.proto.grpc.testing.proto2 import empty2_extensions_pb2 from src.proto.grpc.testing import empty_pb2++from src.proto.grpc.testing.proto2 import empty2_pb2","It is unused directly in the file, but it has side effects.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/10216,107531453,2017-03-22T21:02:40Z,src/python/grpcio_tests/tests/reflection/_reflection_servicer_test.py,"@@ -39,14 +39,18 @@ from google.protobuf import descriptor_pool from google.protobuf import descriptor_pb2 -from src.proto.grpc.testing.proto2 import empty2_extensions_pb2 from src.proto.grpc.testing import empty_pb2++from src.proto.grpc.testing.proto2 import empty2_pb2","```py# empty2_pb2 is imported for import-consequent side-effects.from src.proto.grpc.testing.proto2 import empty2_pb2  # pylint: disable=unused-import```in that case, please?",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/10216,107534361,2017-03-22T21:12:49Z,src/python/grpcio_reflection/grpc_reflection/v1alpha/reflection.py,"@@ -84,13 +84,17 @@ def _file_containing_symbol(self, fully_qualified_name):         else:             return _file_descriptor_response(descriptor) -    def _file_containing_extension(containing_type, extension_number):-        # TODO(atash) Python protobuf currently doesn't support querying extensions.-        # https://github.com/google/protobuf/issues/2248-        return reflection_pb2.ServerReflectionResponse(-            error_response=reflection_pb2.ErrorResponse(-                error_code=grpc.StatusCode.UNIMPLEMENTED.value[0],-                error_message=grpc.StatusCode.UNIMPLMENTED.value[1].encode(),))+    def _file_containing_extension(self, containing_type, extension_number):",I am a huge advocate for small commits. There are a number of advantages to small commits and almost none to bigger ones. _I could go on but the margin on this page is too small for that..._ :),
8943572,carl-mastrangelo,https://api.github.com/repos/grpc/grpc/pulls/10258,107539289,2017-03-22T21:35:50Z,doc/service_config.md,"@@ -13,12 +13,20 @@ The service config is a JSON string of the following form: ``` {   // Load balancing policy name.-  // Supported values are 'round_robin' and 'grpclb'.-  // Optional; if unset, the default behavior is pick the first available-  // backend.-  // Note that if the resolver returns only balancer addresses and no-  // backend addresses, gRPC will always use the 'grpclb' policy,-  // regardless of what this field is set to.+  // Currently, the only selectable client-side policy provided with gRPC+  // is 'round_robin', but third parties may add their own policies.+  // This field is optional; if unset, the default behavior is to pick+  // the first available backend.+  // If the policy name is set via the client API, that value overrides+  // the value specified here.+  //+  // Note that if the resolver returns at least one balancer address (as+  // opposed to backend addresses), gRPC will use grpclb (see+  // https://github.com/grpc/grpc/blob/master/doc/load-balancing.md),",`[grpclb](https://github.com/grpc/grpc/blob/master/doc/load-balancing.md)`,
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/10259,107687084,2017-03-23T14:45:39Z,src/core/lib/channel/channel_tracer.c,"@@ -0,0 +1,325 @@+/*+ *+ * Copyright 2016, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#include ""src/core/lib/channel/channel_tracer.h""+#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>+#include <grpc/support/useful.h>+#include <stdlib.h>+#include <string.h>+#include ""src/core/lib/iomgr/error.h""+#include ""src/core/lib/support/string.h""+#include ""src/core/lib/transport/connectivity_state.h""++// One node of tracing data+struct grpc_trace_node {+  const char* data;+  grpc_error* error;+  gpr_timespec time_created;+  grpc_connectivity_state connectivity_state;+  grpc_trace_node* next;++  // The tracer object that owns this trace node. This is used to ref and+  // unref the tracing object as nodes are added or overwritten+  grpc_channel_tracer* subchannel;+};++struct grpc_trace_node_list {+  size_t size;+  size_t max_size;+  grpc_trace_node* head_trace;+  grpc_trace_node* tail_trace;+};++/* the channel tracing object */+struct grpc_channel_tracer {+  gpr_refcount refs;+  gpr_mu tracer_mu;+  int64_t num_nodes_logged;+  grpc_trace_node_list node_list;+  gpr_timespec time_created;+};++#ifdef GRPC_CHANNEL_TRACER_REFCOUNT_DEBUG+grpc_channel_tracer* grpc_channel_tracer_create(size_t max_nodes,+                                                const char* file, int line,+                                                const char* func) {+#else+grpc_channel_tracer* grpc_channel_tracer_create(size_t max_nodes) {+#endif+  grpc_channel_tracer* tracer = gpr_zalloc(sizeof(grpc_channel_tracer));+  gpr_mu_init(&tracer->tracer_mu);+  gpr_ref_init(&tracer->refs, 1);+#ifdef GRPC_CHANNEL_TRACER_REFCOUNT_DEBUG+  gpr_log(GPR_DEBUG, ""%p create [%s:%d %s]"", tracer, file, line, func);+#endif+  tracer->node_list.max_size = max_nodes;+  tracer->time_created = gpr_now(GPR_CLOCK_REALTIME);+  return tracer;+}++#ifdef GRPC_CHANNEL_TRACER_REFCOUNT_DEBUG+grpc_channel_tracer* grpc_channel_tracer_ref(grpc_channel_tracer* tracer,+                                             const char* file, int line,+                                             const char* func) {+  if (!tracer) return tracer;+  gpr_log(GPR_DEBUG, ""%p: %"" PRIdPTR "" -> %"" PRIdPTR "" [%s:%d %s]"", tracer,+          gpr_atm_no_barrier_load(&tracer->refs.count),+          gpr_atm_no_barrier_load(&tracer->refs.count) + 1, file, line, func);+  gpr_ref(&tracer->refs);+  return tracer;+}+#else+grpc_channel_tracer* grpc_channel_tracer_ref(grpc_channel_tracer* tracer) {+  if (!tracer) return tracer;+  gpr_ref(&tracer->refs);+  return tracer;+}+#endif++static void free_node(grpc_trace_node* node) {+  // no need to free string, since they are always static+  GRPC_ERROR_UNREF(node->error);+  if (node->subchannel) {+    GRPC_CHANNEL_TRACER_UNREF(node->subchannel);+  }+  gpr_free(node);+}++void grpc_channel_tracer_destroy(grpc_channel_tracer* tracer) {+  grpc_trace_node* it = tracer->node_list.head_trace;+  while (it) {+    grpc_trace_node* to_free = it;+    it = it->next;+    free_node(to_free);+  }+  gpr_free(tracer);+}++#ifdef GRPC_CHANNEL_TRACER_REFCOUNT_DEBUG+void grpc_channel_tracer_unref(grpc_channel_tracer* tracer, const char* file,+                               int line, const char* func) {+  if (!tracer) return;+  gpr_log(GPR_DEBUG, ""%p: %"" PRIdPTR "" -> %"" PRIdPTR "" [%s:%d %s]"", tracer,+          gpr_atm_no_barrier_load(&tracer->refs.count),+          gpr_atm_no_barrier_load(&tracer->refs.count) - 1, file, line, func);+  if (gpr_unref(&tracer->refs)) {+    grpc_channel_tracer_destroy(tracer);+  }+}+#else+void grpc_channel_tracer_unref(grpc_channel_tracer* tracer) {+  if (!tracer) return;+  if (gpr_unref(&tracer->refs)) {+    grpc_channel_tracer_destroy(tracer);+  }+}+#endif++static void add_trace(grpc_trace_node_list* list, const char* trace,+                      grpc_error* error,+                      grpc_connectivity_state connectivity_state,+                      grpc_channel_tracer* subchannel) {+  grpc_trace_node* new_trace_node = gpr_malloc(sizeof(grpc_trace_node));+  new_trace_node->data = trace;+  new_trace_node->error = error;+  new_trace_node->time_created = gpr_now(GPR_CLOCK_REALTIME);+  new_trace_node->connectivity_state = connectivity_state;+  new_trace_node->next = NULL;+  new_trace_node->subchannel = subchannel;++  if (subchannel) {+    GRPC_CHANNEL_TRACER_REF(subchannel);+  }++  // first node in case+  if (!list->head_trace) {+    list->head_trace = list->tail_trace = new_trace_node;+  }+  // regular node add case+  else {+    list->tail_trace->next = new_trace_node;+    list->tail_trace = list->tail_trace->next;+  }+  list->size++;++  // maybe garbage collect the end+  if (list->size > list->max_size) {+    grpc_trace_node* to_free = list->head_trace;+    list->head_trace = list->head_trace->next;+    free_node(to_free);+    list->size--;+  }+}++void grpc_channel_tracer_add_trace(grpc_channel_tracer* tracer,+                                   const char* trace, grpc_error* error,+                                   grpc_connectivity_state connectivity_state,+                                   grpc_channel_tracer* subchannel) {+  if (!tracer) return;+  tracer->num_nodes_logged++;+  add_trace(&tracer->node_list, trace, error, connectivity_state, subchannel);+}++// TODO(ncteisen): pull this function into a helper location+static grpc_json* link_json(grpc_json* child, grpc_json* brother,+                            grpc_json* parent) {","(1) What's the advantage of creating a json tree here (versus just generating a string)?(2) Given we're already thinking about a proto format for this, is it worth pulling the presentation of traces (the json generation) into a utility file so that we don't accidentally link presentation with runtime storage?",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/10259,107694604,2017-03-23T15:10:32Z,src/core/lib/channel/channel_tracer.c,"@@ -0,0 +1,325 @@+/*+ *+ * Copyright 2016, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#include ""src/core/lib/channel/channel_tracer.h""+#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>+#include <grpc/support/useful.h>+#include <stdlib.h>+#include <string.h>+#include ""src/core/lib/iomgr/error.h""+#include ""src/core/lib/support/string.h""+#include ""src/core/lib/transport/connectivity_state.h""++// One node of tracing data+struct grpc_trace_node {+  const char* data;","My thought was that the data would always be a string literal. But I guess if that were the case then a slice would still be just as fast, and if would additionally provide the opportunity for custom strings. I will make that change.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/10259,107694660,2017-03-23T15:10:40Z,src/core/lib/channel/channel_tracer.c,"@@ -0,0 +1,325 @@+/*+ *+ * Copyright 2016, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#include ""src/core/lib/channel/channel_tracer.h""+#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>+#include <grpc/support/useful.h>+#include <stdlib.h>+#include <string.h>+#include ""src/core/lib/iomgr/error.h""+#include ""src/core/lib/support/string.h""+#include ""src/core/lib/transport/connectivity_state.h""++// One node of tracing data+struct grpc_trace_node {+  const char* data;+  grpc_error* error;+  gpr_timespec time_created;+  grpc_connectivity_state connectivity_state;+  grpc_trace_node* next;++  // The tracer object that owns this trace node. This is used to ref and+  // unref the tracing object as nodes are added or overwritten+  grpc_channel_tracer* subchannel;+};++struct grpc_trace_node_list {+  size_t size;+  size_t max_size;+  grpc_trace_node* head_trace;+  grpc_trace_node* tail_trace;+};++/* the channel tracing object */+struct grpc_channel_tracer {+  gpr_refcount refs;+  gpr_mu tracer_mu;+  int64_t num_nodes_logged;+  grpc_trace_node_list node_list;+  gpr_timespec time_created;+};++#ifdef GRPC_CHANNEL_TRACER_REFCOUNT_DEBUG+grpc_channel_tracer* grpc_channel_tracer_create(size_t max_nodes,+                                                const char* file, int line,+                                                const char* func) {+#else+grpc_channel_tracer* grpc_channel_tracer_create(size_t max_nodes) {+#endif+  grpc_channel_tracer* tracer = gpr_zalloc(sizeof(grpc_channel_tracer));+  gpr_mu_init(&tracer->tracer_mu);+  gpr_ref_init(&tracer->refs, 1);+#ifdef GRPC_CHANNEL_TRACER_REFCOUNT_DEBUG+  gpr_log(GPR_DEBUG, ""%p create [%s:%d %s]"", tracer, file, line, func);+#endif+  tracer->node_list.max_size = max_nodes;+  tracer->time_created = gpr_now(GPR_CLOCK_REALTIME);+  return tracer;+}++#ifdef GRPC_CHANNEL_TRACER_REFCOUNT_DEBUG+grpc_channel_tracer* grpc_channel_tracer_ref(grpc_channel_tracer* tracer,+                                             const char* file, int line,+                                             const char* func) {+  if (!tracer) return tracer;+  gpr_log(GPR_DEBUG, ""%p: %"" PRIdPTR "" -> %"" PRIdPTR "" [%s:%d %s]"", tracer,+          gpr_atm_no_barrier_load(&tracer->refs.count),+          gpr_atm_no_barrier_load(&tracer->refs.count) + 1, file, line, func);+  gpr_ref(&tracer->refs);+  return tracer;+}+#else+grpc_channel_tracer* grpc_channel_tracer_ref(grpc_channel_tracer* tracer) {+  if (!tracer) return tracer;+  gpr_ref(&tracer->refs);+  return tracer;+}+#endif++static void free_node(grpc_trace_node* node) {+  // no need to free string, since they are always static+  GRPC_ERROR_UNREF(node->error);+  if (node->subchannel) {+    GRPC_CHANNEL_TRACER_UNREF(node->subchannel);+  }+  gpr_free(node);+}++void grpc_channel_tracer_destroy(grpc_channel_tracer* tracer) {+  grpc_trace_node* it = tracer->node_list.head_trace;+  while (it) {+    grpc_trace_node* to_free = it;+    it = it->next;+    free_node(to_free);+  }+  gpr_free(tracer);+}++#ifdef GRPC_CHANNEL_TRACER_REFCOUNT_DEBUG+void grpc_channel_tracer_unref(grpc_channel_tracer* tracer, const char* file,+                               int line, const char* func) {+  if (!tracer) return;+  gpr_log(GPR_DEBUG, ""%p: %"" PRIdPTR "" -> %"" PRIdPTR "" [%s:%d %s]"", tracer,+          gpr_atm_no_barrier_load(&tracer->refs.count),+          gpr_atm_no_barrier_load(&tracer->refs.count) - 1, file, line, func);+  if (gpr_unref(&tracer->refs)) {+    grpc_channel_tracer_destroy(tracer);+  }+}+#else+void grpc_channel_tracer_unref(grpc_channel_tracer* tracer) {+  if (!tracer) return;+  if (gpr_unref(&tracer->refs)) {+    grpc_channel_tracer_destroy(tracer);+  }+}+#endif++static void add_trace(grpc_trace_node_list* list, const char* trace,+                      grpc_error* error,+                      grpc_connectivity_state connectivity_state,+                      grpc_channel_tracer* subchannel) {+  grpc_trace_node* new_trace_node = gpr_malloc(sizeof(grpc_trace_node));+  new_trace_node->data = trace;+  new_trace_node->error = error;+  new_trace_node->time_created = gpr_now(GPR_CLOCK_REALTIME);+  new_trace_node->connectivity_state = connectivity_state;+  new_trace_node->next = NULL;+  new_trace_node->subchannel = subchannel;++  if (subchannel) {+    GRPC_CHANNEL_TRACER_REF(subchannel);+  }++  // first node in case+  if (!list->head_trace) {+    list->head_trace = list->tail_trace = new_trace_node;+  }+  // regular node add case+  else {+    list->tail_trace->next = new_trace_node;+    list->tail_trace = list->tail_trace->next;+  }+  list->size++;++  // maybe garbage collect the end+  if (list->size > list->max_size) {+    grpc_trace_node* to_free = list->head_trace;+    list->head_trace = list->head_trace->next;+    free_node(to_free);+    list->size--;+  }+}++void grpc_channel_tracer_add_trace(grpc_channel_tracer* tracer,+                                   const char* trace, grpc_error* error,+                                   grpc_connectivity_state connectivity_state,+                                   grpc_channel_tracer* subchannel) {+  if (!tracer) return;+  tracer->num_nodes_logged++;+  add_trace(&tracer->node_list, trace, error, connectivity_state, subchannel);+}++// TODO(ncteisen): pull this function into a helper location+static grpc_json* link_json(grpc_json* child, grpc_json* brother,+                            grpc_json* parent) {",This could potentially share a utility file with the error string generation. They accomplish similar goals. We can discuss this one more offline.,
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/10256,107710739,2017-03-23T16:05:47Z,src/python/grpcio/grpc/__init__.py,"@@ -348,6 +348,82 @@ def details(self):         raise NotImplementedError()  +##############  Invocation-Side Interceptor Interfaces & Classes  ##############+++class UnaryClientInfo(six.with_metaclass(abc.ABCMeta)):","I think it might be simpler to just invoke the callback with this data directly, rather than trying to wrap some of it up in a class.",
1923871,rnburn,https://api.github.com/repos/grpc/grpc/pulls/10256,107713385,2017-03-23T16:15:59Z,src/python/grpcio/grpc/__init__.py,"@@ -348,6 +348,82 @@ def details(self):         raise NotImplementedError()  +##############  Invocation-Side Interceptor Interfaces & Classes  ##############+++class UnaryClientInfo(six.with_metaclass(abc.ABCMeta)):",I can make that change. But one advantage of doing it this way is that it's easy to support adding additional data in the future without breaking existing interceptors.,
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/10256,107716797,2017-03-23T16:29:03Z,src/python/grpcio/grpc/__init__.py,"@@ -348,6 +348,82 @@ def details(self):         raise NotImplementedError()  +##############  Invocation-Side Interceptor Interfaces & Classes  ##############+++class UnaryClientInfo(six.with_metaclass(abc.ABCMeta)):+    """"""Consists of various information about a unary RPC on the invocation-side.++  Attributes:+    full_method: A string of the full RPC method, i.e., /package.service/method.+    timeout: The length of time in seconds to wait for the computation to+      terminate or be cancelled, or None if this method should block until+      the computation is terminated or is cancelled no matter how long that+      takes.+  """"""+++class StreamClientInfo(six.with_metaclass(abc.ABCMeta)):+    """"""Consists of various information about a stream RPC on the invocation-side.++  Attributes:+    full_method: A string of the full RPC method, i.e., /package.service/method.+    is_client_stream: Indicates whether the RPC is client-streaming.+    is_server_stream: Indicates whether the RPC is server-streaming.+    timeout: The length of time in seconds to wait for the computation to+      terminate or be cancelled, or None if this method should block until+      the computation is terminated or is cancelled no matter how long that+      takes.+  """"""+++class UnaryClientInterceptor(six.with_metaclass(abc.ABCMeta)):+    """"""Affords intercepting unary-unary RPCs on the invocation-side.""""""++    @abc.abstractmethod+    def intercept_unary(self, request, metadata, client_info, invoker):+        """"""Intercepts unary-unary RPCs on the invocation-side.++    Args:+      request: The request value for the RPC.+      metadata: Optional :term:`metadata` to be transmitted to the+        service-side of the RPC.+      client_info: A UnaryClientInfo containing various information about+        the RPC.+      invoker: The handler to complete the RPC on the client. It is the+        interceptor's responsibility to call it.++    Returns:+      The result from calling invoker(request, metadata).+    """"""+        raise NotImplementedError()+++class StreamClientInterceptor(six.with_metaclass(abc.ABCMeta)):+    """"""Affords intercepting stream RPCs on the invocation-side.""""""++    @abc.abstractmethod+    def intercept_stream(self, request_or_iterator, metadata, client_info,+                         invoker):+        """"""Intercepts stream RPCs on the invocation-side.++    Args:+      request_or_iterator: The request value for the RPC if+        `client_info.is_client_stream` is `false`; otherwise, an iterator of+        request values.+      metadata: Optional :term:`metadata` to be transmitted to the service-side","I think this shouldn't be an optional param, if there is no metadata, it would just be an empty sequence.",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/10256,107717160,2017-03-23T16:30:22Z,src/python/grpcio/grpc/__init__.py,"@@ -348,6 +348,82 @@ def details(self):         raise NotImplementedError()  +##############  Invocation-Side Interceptor Interfaces & Classes  ##############+++class UnaryClientInfo(six.with_metaclass(abc.ABCMeta)):+    """"""Consists of various information about a unary RPC on the invocation-side.++  Attributes:+    full_method: A string of the full RPC method, i.e., /package.service/method.+    timeout: The length of time in seconds to wait for the computation to+      terminate or be cancelled, or None if this method should block until+      the computation is terminated or is cancelled no matter how long that+      takes.+  """"""+++class StreamClientInfo(six.with_metaclass(abc.ABCMeta)):+    """"""Consists of various information about a stream RPC on the invocation-side.++  Attributes:+    full_method: A string of the full RPC method, i.e., /package.service/method.+    is_client_stream: Indicates whether the RPC is client-streaming.+    is_server_stream: Indicates whether the RPC is server-streaming.+    timeout: The length of time in seconds to wait for the computation to+      terminate or be cancelled, or None if this method should block until+      the computation is terminated or is cancelled no matter how long that+      takes.+  """"""+++class UnaryClientInterceptor(six.with_metaclass(abc.ABCMeta)):+    """"""Affords intercepting unary-unary RPCs on the invocation-side.""""""++    @abc.abstractmethod+    def intercept_unary(self, request, metadata, client_info, invoker):+        """"""Intercepts unary-unary RPCs on the invocation-side.++    Args:+      request: The request value for the RPC.+      metadata: Optional :term:`metadata` to be transmitted to the+        service-side of the RPC.+      client_info: A UnaryClientInfo containing various information about+        the RPC.+      invoker: The handler to complete the RPC on the client. It is the+        interceptor's responsibility to call it.++    Returns:+      The result from calling invoker(request, metadata).+    """"""+        raise NotImplementedError()+++class StreamClientInterceptor(six.with_metaclass(abc.ABCMeta)):+    """"""Affords intercepting stream RPCs on the invocation-side.""""""++    @abc.abstractmethod+    def intercept_stream(self, request_or_iterator, metadata, client_info,+                         invoker):+        """"""Intercepts stream RPCs on the invocation-side.++    Args:+      request_or_iterator: The request value for the RPC if+        `client_info.is_client_stream` is `false`; otherwise, an iterator of+        request values.+      metadata: Optional :term:`metadata` to be transmitted to the service-side+        of the RPC.+      client_info: A StreamClientInfo containing various information about+        the RPC.+      invoker:  The handler to complete the RPC on the client. It is the+        interceptor's responsibility to call it.++      Returns:+        The result from calling invoker(metadata).","What if instead of requiring that the interceptor calls ```invoker(metadata)```, the interceptor just returns ```(request_iterator, metadata)```, and the internals of the library then invoke the original rpc with the new metadata/request iterator.I think this will allow us to simplify a lot of the implementation logic.",
9053690,zhangkun83,https://api.github.com/repos/grpc/grpc/pulls/10258,107723355,2017-03-23T16:53:09Z,doc/service_config.md,"@@ -13,12 +13,20 @@ The service config is a JSON string of the following form: ``` {   // Load balancing policy name.-  // Supported values are 'round_robin' and 'grpclb'.-  // Optional; if unset, the default behavior is pick the first available-  // backend.-  // Note that if the resolver returns only balancer addresses and no-  // backend addresses, gRPC will always use the 'grpclb' policy,-  // regardless of what this field is set to.+  // Currently, the only selectable client-side policy provided with gRPC+  // is 'round_robin', but third parties may add their own policies.+  // This field is optional; if unset, the default behavior is to pick+  // the first available backend.+  // If the policy name is set via the client API, that value overrides+  // the value specified here.+  //+  // Note that if the resolver returns at least one balancer address (as+  // opposed to backend addresses), gRPC will use grpclb (see+  // https://github.com/grpc/grpc/blob/master/doc/load-balancing.md),+  // regardless of what LB policy is requested either here or via the+  // client API.  However, if the resolver returns backend addresses as+  // well as balancer addresses, the client may fall back to the requested+  // policy if it is unable to reach any of the grpclb load balancers.","> Giving the pick_first policy a name here would still allow people to set it explicitly, which is exactly what Abhishek wanted to avoid. Is the intention that we don't give people the option to stick to pick_first behavior?> However, in cases where grpclb is intentionally not being used, I think that's misleading, because we never tried to use grpclb in the first place.In contrast, I find the current config language misleading, because the option doesn't have any notion of ""fallback"" or ""secondary"" but is in fact **used only when the conditions for the primary choice are not met**. The current spec is disguising the primary/secondary relation as some special-case rules. IMHO, specs should avoid special cases whenever possible, i.e., if they can be instead expressed by more generalized rules. If ""fallback"" doesn't sound right to you, how about ""secondary""?",
1923871,rnburn,https://api.github.com/repos/grpc/grpc/pulls/10256,107728017,2017-03-23T17:10:04Z,src/python/grpcio/grpc/__init__.py,"@@ -348,6 +348,82 @@ def details(self):         raise NotImplementedError()  +##############  Invocation-Side Interceptor Interfaces & Classes  ##############+++class UnaryClientInfo(six.with_metaclass(abc.ABCMeta)):+    """"""Consists of various information about a unary RPC on the invocation-side.++  Attributes:+    full_method: A string of the full RPC method, i.e., /package.service/method.+    timeout: The length of time in seconds to wait for the computation to+      terminate or be cancelled, or None if this method should block until+      the computation is terminated or is cancelled no matter how long that+      takes.+  """"""+++class StreamClientInfo(six.with_metaclass(abc.ABCMeta)):+    """"""Consists of various information about a stream RPC on the invocation-side.++  Attributes:+    full_method: A string of the full RPC method, i.e., /package.service/method.+    is_client_stream: Indicates whether the RPC is client-streaming.+    is_server_stream: Indicates whether the RPC is server-streaming.+    timeout: The length of time in seconds to wait for the computation to+      terminate or be cancelled, or None if this method should block until+      the computation is terminated or is cancelled no matter how long that+      takes.+  """"""+++class UnaryClientInterceptor(six.with_metaclass(abc.ABCMeta)):+    """"""Affords intercepting unary-unary RPCs on the invocation-side.""""""++    @abc.abstractmethod+    def intercept_unary(self, request, metadata, client_info, invoker):+        """"""Intercepts unary-unary RPCs on the invocation-side.++    Args:+      request: The request value for the RPC.+      metadata: Optional :term:`metadata` to be transmitted to the+        service-side of the RPC.+      client_info: A UnaryClientInfo containing various information about+        the RPC.+      invoker: The handler to complete the RPC on the client. It is the+        interceptor's responsibility to call it.++    Returns:+      The result from calling invoker(request, metadata).+    """"""+        raise NotImplementedError()+++class StreamClientInterceptor(six.with_metaclass(abc.ABCMeta)):+    """"""Affords intercepting stream RPCs on the invocation-side.""""""++    @abc.abstractmethod+    def intercept_stream(self, request_or_iterator, metadata, client_info,+                         invoker):+        """"""Intercepts stream RPCs on the invocation-side.++    Args:+      request_or_iterator: The request value for the RPC if+        `client_info.is_client_stream` is `false`; otherwise, an iterator of+        request values.+      metadata: Optional :term:`metadata` to be transmitted to the service-side+        of the RPC.+      client_info: A StreamClientInfo containing various information about+        the RPC.+      invoker:  The handler to complete the RPC on the client. It is the+        interceptor's responsibility to call it.++      Returns:+        The result from calling invoker(metadata).","One use case of interceptors is being able to determine the duration of the RPC call. For example, this was developed to support open-tracing where the [interceptor](https://github.com/rnburn/grpc-opentracing-1/blob/master/python/grpc_opentracing/_client.py#L167) measures the duration and processes the response. I don't see how you could do this if you passed control back. This is also more aligned with how the Go [implementation](https://github.com/grpc/grpc-go/blob/master/interceptor.go#L54) works.",
1923871,rnburn,https://api.github.com/repos/grpc/grpc/pulls/10256,107729226,2017-03-23T17:14:22Z,src/python/grpcio/grpc/__init__.py,"@@ -348,6 +348,82 @@ def details(self):         raise NotImplementedError()  +##############  Invocation-Side Interceptor Interfaces & Classes  ##############+++class UnaryClientInfo(six.with_metaclass(abc.ABCMeta)):+    """"""Consists of various information about a unary RPC on the invocation-side.++  Attributes:+    full_method: A string of the full RPC method, i.e., /package.service/method.+    timeout: The length of time in seconds to wait for the computation to+      terminate or be cancelled, or None if this method should block until+      the computation is terminated or is cancelled no matter how long that+      takes.+  """"""+++class StreamClientInfo(six.with_metaclass(abc.ABCMeta)):+    """"""Consists of various information about a stream RPC on the invocation-side.++  Attributes:+    full_method: A string of the full RPC method, i.e., /package.service/method.+    is_client_stream: Indicates whether the RPC is client-streaming.+    is_server_stream: Indicates whether the RPC is server-streaming.+    timeout: The length of time in seconds to wait for the computation to+      terminate or be cancelled, or None if this method should block until+      the computation is terminated or is cancelled no matter how long that+      takes.+  """"""+++class UnaryClientInterceptor(six.with_metaclass(abc.ABCMeta)):+    """"""Affords intercepting unary-unary RPCs on the invocation-side.""""""++    @abc.abstractmethod+    def intercept_unary(self, request, metadata, client_info, invoker):+        """"""Intercepts unary-unary RPCs on the invocation-side.++    Args:+      request: The request value for the RPC.+      metadata: Optional :term:`metadata` to be transmitted to the+        service-side of the RPC.+      client_info: A UnaryClientInfo containing various information about+        the RPC.+      invoker: The handler to complete the RPC on the client. It is the+        interceptor's responsibility to call it.++    Returns:+      The result from calling invoker(request, metadata).+    """"""+        raise NotImplementedError()+++class StreamClientInterceptor(six.with_metaclass(abc.ABCMeta)):+    """"""Affords intercepting stream RPCs on the invocation-side.""""""++    @abc.abstractmethod+    def intercept_stream(self, request_or_iterator, metadata, client_info,",One advantage of having it as a named function is that a single class can support both the stream and unary interceptor interfaces.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/10258,107753190,2017-03-23T18:46:56Z,doc/service_config.md,"@@ -13,12 +13,20 @@ The service config is a JSON string of the following form: ``` {   // Load balancing policy name.-  // Supported values are 'round_robin' and 'grpclb'.-  // Optional; if unset, the default behavior is pick the first available-  // backend.-  // Note that if the resolver returns only balancer addresses and no-  // backend addresses, gRPC will always use the 'grpclb' policy,-  // regardless of what this field is set to.+  // Currently, the only selectable client-side policy provided with gRPC+  // is 'round_robin', but third parties may add their own policies.+  // This field is optional; if unset, the default behavior is to pick+  // the first available backend.+  // If the policy name is set via the client API, that value overrides+  // the value specified here.+  //+  // Note that if the resolver returns at least one balancer address (as+  // opposed to backend addresses), gRPC will use grpclb (see+  // https://github.com/grpc/grpc/blob/master/doc/load-balancing.md),+  // regardless of what LB policy is requested either here or via the+  // client API.  However, if the resolver returns backend addresses as+  // well as balancer addresses, the client may fall back to the requested+  // policy if it is unable to reach any of the grpclb load balancers.","> Is the intention that we don't give people the option to stick to pick_first behavior?No.  People can get pick_first behavior by just not specifying any value here.  We just don't want people to explicitly set this field to a value that is already the default value.> In contrast, I find the current config language misleading, because the option doesn't have any notion of ""fallback"" or ""secondary"" but is in fact **used only when the conditions for the primary choice are not met**. The current spec is disguising the primary/secondary relation as some special-case rules. IMHO, specs should avoid special cases whenever possible, i.e., if they can be instead expressed by more generalized rules. If ""fallback"" doesn't sound right to you, how about ""secondary""?The core problem here is that there are two cases: (a) grpclb is in use and (b) client-side load balancing is in use.  In case (a), you can indeed look at grpclb as the ""primary"" mechanism, and the client-side load balancing policy (the value specified here) is a ""secondary"" or ""fallback"" mechanism.  But in case (b), the primary mechanism *is* the value specified here, so this is not a fallback.Adding a term like ""fallback"" or ""secondary"" here would slightly clarify things in case (a), but it would be misleading in case (b).  In contrast, not having that term is slightly less clear in case (a) (although I don't think it's actually misleading), but it's fully accurate in case (b).  If we have a choice between being slightly less clear in case (a) or being misleading in case (b), I think the former is a better choice.From the user's perspective, I think a better model for this behavior is that grpclb is a completely different mechanism than client-side load balancing, and the field in the service config controls only the latter.  We only use client-side load balancing if (1) grpclb is not configured or (2) grpclb is configured but we cannot reach any of the balancers.  I think that's a fairly easy-to-understand description and does not cause any confusion in either case.",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/10218,107770279,2017-03-23T20:04:57Z,include/grpc/impl/codegen/atm_gcc_atomic.h,"@@ -85,6 +85,11 @@ static __inline int gpr_atm_rel_cas(gpr_atm *p, gpr_atm o, gpr_atm n) {       p, &o, n, 0, __ATOMIC_RELEASE, __ATOMIC_RELAXED)); } +static __inline int gpr_atm_full_cas(gpr_atm *p, gpr_atm o, gpr_atm n) {","Yeah happy to take an AI to globally search replace atm_full with atm_acq_rel, but right now consistency wins for me (also I'd need to do some planning for such a rename as technically this is public API)",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/10258,107914775,2017-03-24T14:29:08Z,doc/service_config.md,"@@ -13,12 +13,20 @@ The service config is a JSON string of the following form: ``` {   // Load balancing policy name.-  // Supported values are 'round_robin' and 'grpclb'.-  // Optional; if unset, the default behavior is pick the first available-  // backend.-  // Note that if the resolver returns only balancer addresses and no-  // backend addresses, gRPC will always use the 'grpclb' policy,-  // regardless of what this field is set to.+  // Currently, the only selectable client-side policy provided with gRPC+  // is 'round_robin', but third parties may add their own policies.+  // This field is optional; if unset, the default behavior is to pick+  // the first available backend.+  // If the policy name is set via the client API, that value overrides+  // the value specified here.+  //+  // Note that if the resolver returns at least one balancer address (as+  // opposed to backend addresses), gRPC will use grpclb (see+  // https://github.com/grpc/grpc/blob/master/doc/load-balancing.md),+  // regardless of what LB policy is requested either here or via the+  // client API.  However, if the resolver returns backend addresses as+  // well as balancer addresses, the client may fall back to the requested+  // policy if it is unable to reach any of the grpclb load balancers.","> Maybe you are conflating the users that just don't care and are willing to use whatever default we give them, and the users that explicitly want pick_first. Us changing the default in the future will serve right for the first kind, but will break the second, unless we allow the second to explicitly specify ""pick_first"". I am not saying we should support the second kind, but instead asking whether we should.What I'm saying is that @a11r doesn't want to support the second case.  He thinks that anyone who wants pick_first should leave this field unset and rely on the default.I don't personally think this is a big deal either way, and it's not something that is being changed by this PR, so let's take this offline.  If you're concerned about this, I suggest you talk with Abhishek about it directly.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/9964,108036688,2017-03-25T13:54:58Z,include/grpc++/impl/codegen/async_stream.h,"@@ -416,31 +496,52 @@ class ServerAsyncWriter final : public ServerAsyncWriterInterface<W> {     call_.PerformOps(&meta_ops_);   } -  void Write(const W& msg, void* tag) override {-    write_ops_.set_output_tag(tag);+  void EnsureInitialMetadataSent(CallOpSetInterface* ops_in) {+    CallOpSet<CallOpSendInitialMetadata>* ops =+        static_cast<CallOpSet<CallOpSendInitialMetadata>*>(ops_in);","This doesn't look so good to me. `static_cast` from a base-class to a derived-class should always be treated with extreme suspicion. I think that a better approach would be to declare this class as```cpptemplate <class T>void EnsureInitialMetadataSent(T* ops) {```because what you really care about in this case is whether `ops` supports these member functions, not saving aside a pointer to it for later.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/10197,108195314,2017-03-27T15:09:27Z,tools/gcp/comp_test/run_comp_test.py,"@@ -0,0 +1,147 @@+#!/usr/bin/env python2.7","I totally agree there's some actions that need to be performed to 1. prepare backwards compatibility interop tests to be able to run them 2. to actually run them on a selected list of versions.  The problem is that your scripts don't address what I believe is the most interesting part of the problem: the management of the existing versions to test and deciding what tests to run against what. I have trouble believing that just dumping docker images to GCR and then running tests against what's found in GCR (after querying) is a manageable way to tests things - you'll quickly lose track of what are the versions you're testing against (and the version list is going to differ for different kinds of tests e.g. after you find out some specific test in an older version is failing and you don't what that to pollute your test results) - so you will probably need some version controlled script/configuration file to decide what things to run when. Once we have that part, decisions about other parts of the problem (like if we should include specific files inside the docker images or not) will become much more straightforward.",
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/9902,108216740,2017-03-27T16:32:39Z,src/core/ext/transport/chttp2/transport/internal.h,"@@ -790,6 +798,8 @@ void grpc_chttp2_incoming_byte_stream_finished( void grpc_chttp2_ack_ping(grpc_exec_ctx *exec_ctx, grpc_chttp2_transport *t,                           uint64_t id); +void grpc_chttp2_ping_strike(grpc_exec_ctx *exec_ctx, grpc_chttp2_transport *t);",Suggest renaming this function. Not exactly sure what - but maybe something like `grpc_chttp2_check_max_ping_strikes` and adding a comment that this sends a go-away frame if num pings > max-ping-strikes,
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/9902,108718450,2017-03-29T16:08:28Z,include/grpc/impl/codegen/grpc_types.h,"@@ -193,15 +193,24 @@ typedef struct {      a data frame or header frame) */ #define GRPC_ARG_HTTP2_MAX_PINGS_WITHOUT_DATA \   ""grpc.http2.max_pings_without_data""+/** How many misbehaving pings the server can bear before sending goaway and+    closing the transport?+    (0 indicates that the server can bear an infinite number of misbehaving+     pings) */+#define GRPC_ARG_HTTP2_MAX_PING_STRIKES ""grpc.http2.max_ping_strikes""+/** Minimum allowed time between two pings without sending any data frame. Int+    valued, seconds */+#define GRPC_ARG_HTTP2_MIN_PING_INTERVAL_WITHOUT_DATA_S \+  ""grpc.http2.min_ping_interval_without_data"" /** How much data are we willing to queue up per stream if     GRPC_WRITE_BUFFER_HINT is set? This is an upper bound */ #define GRPC_ARG_HTTP2_WRITE_BUFFER_SIZE ""grpc.http2.write_buffer_size"" /** After a duration of this time the client pings the server to see if the     transport is still alive. Int valued, seconds. */-#define GRPC_ARG_HTTP2_KEEPALIVE_TIME ""grpc.http2.keepalive_time""+#define GRPC_ARG_HTTP2_KEEPALIVE_TIME_S ""grpc.http2.keepalive_time_s""",All of our other parameters are milliseconds... is there a good reason to break consistency?,
14932100,adelez,https://api.github.com/repos/grpc/grpc/pulls/10311,108745521,2017-03-29T18:01:32Z,tools/run_tests/performance/README.md,"@@ -0,0 +1,70 @@+# Overview of performance test suite, with steps for manual runs:++For design of the tests, see+http://www.grpc.io/docs/guides/benchmarking.html.++## Pre-reqs for running these manually:+In general the benchmark workers and driver build scripts expect+[linux_performance_worker_init.sh](../../gce/linux_performance_worker_init.sh) to have been ran already.++### To run benchmarks locally:+* From the grpc repo root, start the+[run_performance_tests.py](../run_performance_tests.py) runner script.++### On remote machines, to start the driver and workers manually:+The [run_performance_test.py](../run_performance_tests.py) top-level runner script can also+be used with remote machines, but for e.g., profiling the server,+it might be useful to run workers manually.++1. You'll need a ""driver"" and separate ""worker"" machines.+For example, you might use one GCE ""driver"" machine and 3 other+GCE ""worker"" machines that are in the same zone.++2. Connect to each worker machine and start up a benchmark worker with a ""driver_port"".+  * For example, to start the grpc-go benchmark worker:",Can you please list the commands for running workers in other languages?,
22083734,matt-kwong,https://api.github.com/repos/grpc/grpc/pulls/10336,108793087,2017-03-29T21:33:52Z,tools/jenkins/run_performance.sh,"@@ -37,6 +37,7 @@ BENCHMARKS_TO_RUN=""bm_closure bm_cq bm_call_create bm_error bm_chttp2_hpack bm_c # Enter the gRPC repo root cd $(dirname $0)/../.. -tools/run_tests/run_performance_tests.py -l c++ node ruby csharp python --netperf --category smoketest # todo(mattkwong): Change performance test to use microbenchmarking-# tools/run_tests/run_microbenchmark.py -c summary --diff_perf origin/$ghprbTargetBranch -b $BENCHMARKS_TO_RUN+tools/profiling/microbenchmarks/bm_diff.py -d origin/$ghprbTargetBranch -b $BENCHMARKS_TO_RUN++tools/run_tests/run_performance_tests.py -l c++ node ruby csharp python --netperf --category smoketest","Remove this; I don't think we should run both of these in a single Jenkins job. Side question: with microbenchmarks being added, can c++ be removed from the list of languages to run `tools/run_tests/run_performance_tests.py` with?",
17460127,y-zeng,https://api.github.com/repos/grpc/grpc/pulls/9902,108799720,2017-03-29T22:09:53Z,include/grpc/impl/codegen/grpc_types.h,"@@ -193,15 +193,24 @@ typedef struct {      a data frame or header frame) */ #define GRPC_ARG_HTTP2_MAX_PINGS_WITHOUT_DATA \   ""grpc.http2.max_pings_without_data""+/** How many misbehaving pings the server can bear before sending goaway and+    closing the transport?+    (0 indicates that the server can bear an infinite number of misbehaving+     pings) */+#define GRPC_ARG_HTTP2_MAX_PING_STRIKES ""grpc.http2.max_ping_strikes""+/** Minimum allowed time between two pings without sending any data frame. Int+    valued, seconds */+#define GRPC_ARG_HTTP2_MIN_PING_INTERVAL_WITHOUT_DATA_S \+  ""grpc.http2.min_ping_interval_without_data"" /** How much data are we willing to queue up per stream if     GRPC_WRITE_BUFFER_HINT is set? This is an upper bound */ #define GRPC_ARG_HTTP2_WRITE_BUFFER_SIZE ""grpc.http2.write_buffer_size"" /** After a duration of this time the client pings the server to see if the     transport is still alive. Int valued, seconds. */-#define GRPC_ARG_HTTP2_KEEPALIVE_TIME ""grpc.http2.keepalive_time""+#define GRPC_ARG_HTTP2_KEEPALIVE_TIME_S ""grpc.http2.keepalive_time_s""","Changed to milliseconds. The design doc says second is enough for keepalive, but it would be better to keep them consistent with other parameters. Thanks for the review!",
22083734,matt-kwong,https://api.github.com/repos/grpc/grpc/pulls/10113,108804277,2017-03-29T22:38:06Z,tools/run_tests/run_tests_matrix.py,"@@ -141,6 +141,15 @@ def _create_test_jobs(extra_args=[], inner_jobs=_DEFAULT_INNER_JOBS):                              extra_args=extra_args,                              inner_jobs=inner_jobs) +  for compiler in ['python3.6', 'python3.4']:","I would get rid of all of this. Instead, add the new compilers to https://github.com/grpc/grpc/blob/master/tools/run_tests/run_tests.py#L671 - this should fix the failures in Linux Basictests",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/9820,109088446,2017-03-31T05:06:21Z,tools/run_tests/performance/scenario_config.py,"@@ -215,6 +215,29 @@ def scenarios(self):           categories=smoketest_categories+[SCALABLE])        yield _ping_pong_scenario(+          'cpp_generic_async_streaming_qps_1channel_1MBmsg_%s' % secstr,","nit: I think other perf tests use ""secstr_msgsize"" naming pattern and not  ""msgsize_secstr"". Also, they're not using the ""msg"" suffix.",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/10394,109173123,2017-03-31T14:32:01Z,tools/jenkins/run_performance.sh,"@@ -32,7 +32,7 @@ set -ex  # List of benchmarks that provide good signal for analyzing performance changes in pull requests-BENCHMARKS_TO_RUN=""bm_closure bm_cq bm_call_create bm_error bm_chttp2_hpack bm_chttp2_transport bm_pollset bm_metadata""+BENCHMARKS_TO_RUN=""bm_fullstack_unary_ping_pong bm_fullstack_streaming_ping_pong bm_fullstack_streaming_pump bm_closure bm_cq bm_call_create bm_error bm_chttp2_hpack bm_chttp2_transport bm_pollset bm_metadata""","Trickle takes far too long, and arena isn't providing much real data just yet.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/10436,109455984,2017-04-03T16:01:19Z,src/core/lib/channel/channel_args.c,"@@ -329,7 +329,8 @@ const grpc_arg *grpc_channel_args_find(const grpc_channel_args *args,   return NULL; } -int grpc_channel_arg_get_integer(grpc_arg *arg, grpc_integer_options options) {+int grpc_channel_arg_get_integer(const grpc_arg *arg,+                                 grpc_integer_options options) {","As long as you're in here, this parameter could probably be const as well.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/10436,109458861,2017-04-03T16:13:49Z,test/core/end2end/fake_resolver.h,"@@ -32,8 +32,23 @@ #ifndef GRPC_TEST_CORE_END2END_FAKE_RESOLVER_H #define GRPC_TEST_CORE_END2END_FAKE_RESOLVER_H +#include ""src/core/lib/channel/channel_args.h"" #include ""test/core/util/test_config.h""  void grpc_fake_resolver_init(); +// Return a \a grpc_arg enabling LB.+grpc_arg grpc_fake_resolver_lb_enabled_arg();","The approach you've implemented here is certainly fine for now.  However, I think that ultimately, it would be better to have a more flexible interface.  For example, we can define a new object called something like `grpc_fake_resolver_response_generator`.  The object will have a method that will be used to pass in a set of channel args (including the resolved address arg) to be returned by the fake resolver.  That approach will allow us to test things like (a) the resolver returning some backend address and some balancer addresses and (b) the resolver returning a new list of addresses after the LB channel is already warmed up.",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/10427,109483595,2017-04-03T17:58:53Z,src/core/lib/surface/lame_client.cc,"@@ -147,18 +154,22 @@ static grpc_error *init_channel_elem(grpc_exec_ctx *exec_ctx, static void destroy_channel_elem(grpc_exec_ctx *exec_ctx,                                  grpc_channel_element *elem) {} -const grpc_channel_filter grpc_lame_filter = {-    lame_start_transport_stream_op,-    lame_start_transport_op,-    sizeof(call_data),-    init_call_elem,+}  // namespace++}  // namespace grpc_core++extern ""C"" const grpc_channel_filter grpc_lame_filter = {","Additionally: channel_filter.h pulls in all sorts of stuff from `std::` (function, vector for instance) that depend on libstdc++ - which would be unallowed within the core library.",
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/10468,109793635,2017-04-04T22:29:59Z,src/node/ext/call.cc,"@@ -521,6 +523,7 @@ Call::Call(grpc_call *call) : wrapped_call(call), Call::~Call() {   if (wrapped_call != NULL) {","Since that code is duplicated into line 571, I'm usually more in favor of adding a ""destroy"" method that's containing the code in a unique manner, but called from the two locations. That way you can keep the `if (wrapped_call != NULL)` logic segregated into that specialized function.",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/9626,110703550,2017-04-10T16:37:27Z,src/core/ext/transport/chttp2/transport/chttp2_transport.c,"@@ -2374,12 +2422,204 @@ static void set_pollset_set(grpc_exec_ctx *exec_ctx, grpc_transport *gt,  * BYTE STREAM  */ +static void reset_byte_stream(grpc_exec_ctx *exec_ctx, void *arg,+                              grpc_error *error) {+  grpc_chttp2_stream *s = (grpc_chttp2_stream *)arg;++  s->pending_byte_stream = false;+  if (error == GRPC_ERROR_NONE) {+    grpc_chttp2_maybe_complete_recv_message(exec_ctx, s->t, s);+    grpc_chttp2_maybe_complete_recv_trailing_metadata(exec_ctx, s->t, s);+  } else {+    GPR_ASSERT(error != GRPC_ERROR_NONE);+    grpc_closure_sched(exec_ctx, s->on_next, GRPC_ERROR_REF(error));+    s->on_next = NULL;+    GRPC_ERROR_UNREF(s->byte_stream_error);+    s->byte_stream_error = GRPC_ERROR_NONE;+    grpc_chttp2_cancel_stream(exec_ctx, s->t, s, GRPC_ERROR_REF(error));+    s->byte_stream_error = error;+  }+}++static grpc_error *deframe_unprocessed_incoming_frames(",move this code to frame_data.c,
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/9626,110705003,2017-04-10T16:44:15Z,src/core/ext/transport/chttp2/transport/chttp2_transport.c,"@@ -2374,12 +2422,204 @@ static void set_pollset_set(grpc_exec_ctx *exec_ctx, grpc_transport *gt,  * BYTE STREAM  */ +static void reset_byte_stream(grpc_exec_ctx *exec_ctx, void *arg,+                              grpc_error *error) {+  grpc_chttp2_stream *s = (grpc_chttp2_stream *)arg;++  s->pending_byte_stream = false;+  if (error == GRPC_ERROR_NONE) {+    grpc_chttp2_maybe_complete_recv_message(exec_ctx, s->t, s);+    grpc_chttp2_maybe_complete_recv_trailing_metadata(exec_ctx, s->t, s);+  } else {+    GPR_ASSERT(error != GRPC_ERROR_NONE);+    grpc_closure_sched(exec_ctx, s->on_next, GRPC_ERROR_REF(error));+    s->on_next = NULL;+    GRPC_ERROR_UNREF(s->byte_stream_error);+    s->byte_stream_error = GRPC_ERROR_NONE;+    grpc_chttp2_cancel_stream(exec_ctx, s->t, s, GRPC_ERROR_REF(error));+    s->byte_stream_error = error;+  }+}++static grpc_error *deframe_unprocessed_incoming_frames(",just prior to grpc_chttp2_data_parser_parse so that the diffs line up :),
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/10522,110788464,2017-04-10T23:49:09Z,src/core/tsi/transport_security_interface.h,"@@ -208,76 +209,195 @@ typedef struct { /* Destructs the tsi_peer object. */ void tsi_peer_destruct(tsi_peer *self); +/*  --- tsi_handshaker_result object ---++  This object contains all necessary handshake results and data such as peer+  info, negotiated keys, unused handshake bytes, when the handshake completes.+  Implementations of this object must be thread compatible.  */++typedef struct tsi_handshaker_result tsi_handshaker_result;++/* This method extracts tsi peer. It returns TSI_OK assuming there is no fatal+   error.+   The caller is responsible for destructing the peer.  */+tsi_result tsi_handshaker_result_extract_peer(const tsi_handshaker_result *self,+                                              tsi_peer *peer);++/* This method creates a tsi_frame_protector object. It returns TSI_OK assuming+   there is no fatal error.+   The caller is responsible for destroying the protector.  */+tsi_result tsi_handshaker_result_create_frame_protector(+    const tsi_handshaker_result *self, size_t *max_output_protected_frame_size,+    tsi_frame_protector **protector);++/* This method returns the unused bytes from the handshake. It returns TSI_OK+   assuming there is no fatal error.+   The caller should not free the bytes.  */+tsi_result tsi_handshaker_result_get_unused_bytes(+    const tsi_handshaker_result *self, unsigned char **bytes,+    size_t *byte_size);++/* This method releases the tsi_handshaker_handshaker object. After this method+   is called, no other method can be called on the object.  */+void tsi_handshaker_result_destroy(tsi_handshaker_result *self);+ /* --- tsi_handshaker objects ----     Implementations of this object must be thread compatible. -   A typical usage of this object would be:+   ------------------------------------------------------------------------++   A typical usage of the synchronous TSI handshaker would be:     -------------------------------------------------------------------------   tsi_result result = TSI_OK;+   tsi_result status = TSI_OK;    unsigned char buf[4096];-   size_t buf_offset;-   size_t buf_size;+   const size_t buf_size = 4906;+   size_t bytes_received_size = 0;+   unsigned char *bytes_to_send = NULL;+   size_t bytes_to_send_size = 0;+   tsi_handshaker_result *result = NULL;+    while (1) {-     // See if we need to send some bytes to the peer.-     do {-       size_t buf_size_to_send = sizeof(buf);-       result = tsi_handshaker_get_bytes_to_send_to_peer(handshaker, buf,-                                                         &buf_size_to_send);-       if (buf_size_to_send > 0) send_bytes_to_peer(buf, buf_size_to_send);-     } while (result == TSI_INCOMPLETE_DATA);-     if (result != TSI_OK) return result;-     if (!tsi_handshaker_is_in_progress(handshaker)) break;--     do {-       // Read bytes from the peer.-       buf_size = sizeof(buf);-       buf_offset = 0;-       read_bytes_from_peer(buf, &buf_size);-       if (buf_size == 0) break;--       // Process the bytes from the peer. We have to be careful as these bytes-       // may contain non-handshake data (protected data). If this is the case,-       // we will exit from the loop with buf_size > 0.-       size_t consumed_by_handshaker = buf_size;-       result = tsi_handshaker_process_bytes_from_peer(-           handshaker, buf, &consumed_by_handshaker);-       buf_size -= consumed_by_handshaker;-       buf_offset += consumed_by_handshaker;-     } while (result == TSI_INCOMPLETE_DATA);--     if (result != TSI_OK) return result;-     if (!tsi_handshaker_is_in_progress(handshaker)) break;+     status = tsi_handshaker_next(+         handshaker, buf, bytes_received_size,+         &bytes_to_send, &bytes_to_send_size, &result, NULL, NULL);+     if (status == TSI_INCOMPLETE_DATA) {+       // Need more data from the peer.+       bytes_received_size = buf_size;+       read_bytes_from_peer(buf, &bytes_received_size);+       continue;+     }+     if (status != TSI_OK) return status;+     if (bytes_to_send_size > 0) {+       send_bytes_to_peer(bytes_to_send, bytes_to_send_size);+     }+     if (result != NULL) break;+     bytes_received_size = buf_size;+     read_bytes_from_peer(buf, &bytes_received_size);    }     // Check the Peer.    tsi_peer peer;-   do {-     result = tsi_handshaker_extract_peer(handshaker, &peer);-     if (result != TSI_OK) break;-     result = check_peer(&peer);-   } while (0);+   status = tsi_handshaker_result_extract_peer(result, &peer);+   if (status != TSI_OK) return status;+   status = check_peer(&peer);    tsi_peer_destruct(&peer);-   if (result != TSI_OK) return result;+   if (status != TSI_OK) return status;     // Create the protector.    tsi_frame_protector* protector = NULL;-   result = tsi_handshaker_create_frame_protector(handshaker, NULL,-                                                  &protector);-   if (result != TSI_OK) return result;+   status = tsi_handshaker_result_create_frame_protector(result, NULL,+                                                         &protector);+   if (status != TSI_OK) return status;     // Do not forget to unprotect outstanding data if any.-   if (buf_size > 0) {-     result = tsi_frame_protector_unprotect(protector, buf + buf_offset,-                                            buf_size, ..., ...);+   unsigned char *unused_bytes = NULL;+   size_t unused_bytes_size = 0;+   status = tsi_handshaker_result_get_unused_bytes(result, &unused_bytes,+                                                   &unused_bytes_size);+   if (status != TSI_OK) return status;+   if (unused_bytes_size > 0) {+     status = tsi_frame_protector_unprotect(protector, unused_bytes,+                                            unused_bytes_size, ..., ...);      ....    }    ...+   ------------------------------------------------------------------------++   A typical usage supporting both synchronous and asynchronous TSI handshaker+   implementations would be:++   ------------------------------------------------------------------------++   typedef struct {+     tsi_handshaker *handshaker;+     tsi_handshaker_result *handshaker_result;+     unsigned char *handshake_buffer;+     size_t handshake_buffer_size;+     ...+   } security_handshaker;++   void do_handshake(security_handshaker *h, ...) {+     // Start the handshake by the calling do_handshake_next.+     do_handshake_next(h, NULL, 0);+     ...+   }++   // This method is the callback function when there are data received from",when data is received from the peer.,
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/10427,110789897,2017-04-11T00:01:41Z,setup.py,"@@ -195,6 +195,7 @@ def cython_extensions_and_necessity():   extensions = [       _extension.Extension(           name=module_name,+          language='c++',","@kpayson64 I'm slightly worried this would actually ask Python to link using g++ instead of gcc, which would drag in libstdc++ automatically, and would thus cause breakage of pre-compiled binaries being shipped on other distributions.Can we run a sanity check on that using the distribution build test ? We should still be able to load the resulting python extension on older distributions that is. Or more directly, the resulting .so file (or whatever name that has) shouldn't have any reference to libstdc++.You can tell using `ldd`. For example:```$ ldd protoc        linux-vdso.so.1 (0x00007fff2a60e000)        libpthread.so.0 => /lib/x86_64-linux-gnu/libpthread.so.0 (0x00007f858ac76000)        libz.so.1 => /lib/x86_64-linux-gnu/libz.so.1 (0x00007f858aa5c000)        libstdc++.so.6 => /usr/lib/x86_64-linux-gnu/libstdc++.so.6 (0x00007f858a6da000)        libm.so.6 => /lib/x86_64-linux-gnu/libm.so.6 (0x00007f858a3d6000)        libgcc_s.so.1 => /lib/x86_64-linux-gnu/libgcc_s.so.1 (0x00007f858a1bf000)        libc.so.6 => /lib/x86_64-linux-gnu/libc.so.6 (0x00007f8589e1f000)        /lib64/ld-linux-x86-64.so.2 (0x000055fad2c0b000)```Here we can clearly see the libstdc++.so.6 dependency.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/10563,110985247,2017-04-11T18:53:19Z,src/node/ext/server.cc,"@@ -147,6 +175,13 @@ bool Server::HasInstance(Local<Value> val) {   return Nan::New(fun_tpl)->HasInstance(val); } +void Server::DestroyWrappedServer() {","related to below comment, the shutdown is wrapped in the null check in the callback but isn't in `TryShutdown`?mostly wondering if `TryShutdown` can be more similar with `ForceShutdown`",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/10473,111182219,2017-04-12T15:26:31Z,test/core/transport/chttp2/hpack_encoder_test.c,"@@ -103,8 +103,14 @@ static void verify(grpc_exec_ctx *exec_ctx, size_t window_available, int eof,    grpc_transport_one_way_stats stats;   memset(&stats, 0, sizeof(stats));-  grpc_chttp2_encode_header(exec_ctx, &g_compressor, 0xdeadbeef, &b, eof, 16384,-                            &stats, &output);+  grpc_encode_header_options hopt = {+      .stream_id = 0xdeadbeef,+      .is_eof = eof,+      .use_true_binary_metadata = false,","Shouldn't this be set to `use_true_binary_metadata`?Also, doesn't look like we actually have a test where this is set to true, which explains why this is currently working. :)",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/10613,111278947,2017-04-12T22:57:47Z,src/core/lib/slice/slice.c,"@@ -227,35 +227,42 @@ static const grpc_slice_refcount_vtable malloc_vtable = {     malloc_ref, malloc_unref, grpc_slice_default_eq_impl,     grpc_slice_default_hash_impl}; +grpc_slice grpc_slice_malloc_large(size_t length) {+  grpc_slice slice;++  /* Memory layout used by the slice created here:++     +-----------+----------------------------------------------------------++     | refcount  | bytes                                                    |+     +-----------+----------------------------------------------------------+++     refcount is a malloc_refcount+     bytes is an array of bytes of the requested length+     Both parts are placed in the same allocation returned from gpr_malloc */+  malloc_refcount *rc = gpr_malloc(sizeof(malloc_refcount) + length);++  /* Initial refcount on rc is 1 - and it's up to the caller to release+     this reference. */+  gpr_ref_init(&rc->refs, 1);++  rc->base.vtable = &malloc_vtable;+  rc->base.sub_refcount = &rc->base;++  /* Build up the slice to be returned. */+  /* The slices refcount points back to the allocated block. */+  slice.refcount = &rc->base;+  /* The data bytes are placed immediately after the refcount struct */+  slice.data.refcounted.bytes = (uint8_t *)(rc + 1);+  /* And the length of the block is set to the requested length */+  slice.data.refcounted.length = length;+  return slice;+}+ grpc_slice grpc_slice_malloc(size_t length) {   grpc_slice slice;    if (length > sizeof(slice.data.inlined.bytes)) {-    /* Memory layout used by the slice created here:--       +-----------+----------------------------------------------------------+-       | refcount  | bytes                                                    |-       +-----------+----------------------------------------------------------+--       refcount is a malloc_refcount-       bytes is an array of bytes of the requested length-       Both parts are placed in the same allocation returned from gpr_malloc */-    malloc_refcount *rc = gpr_malloc(sizeof(malloc_refcount) + length);--    /* Initial refcount on rc is 1 - and it's up to the caller to release-       this reference. */-    gpr_ref_init(&rc->refs, 1);--    rc->base.vtable = &malloc_vtable;-    rc->base.sub_refcount = &rc->base;--    /* Build up the slice to be returned. */-    /* The slices refcount points back to the allocated block. */-    slice.refcount = &rc->base;-    /* The data bytes are placed immediately after the refcount struct */-    slice.data.refcounted.bytes = (uint8_t *)(rc + 1);-    /* And the length of the block is set to the requested length */-    slice.data.refcounted.length = length;+    return grpc_slice_malloc_large(length);   } else {     /* small slice: just inline the data */     slice.refcount = NULL;","This recreates the logic of the new macro, GRPC_SLICE_MALLOC. Would it make sense to only use that from now on? Then we could get rid of this function, and the macro would do the inlining or call grpc_slice_malloc_large.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/10613,111279916,2017-04-12T23:04:42Z,src/core/lib/slice/slice.c,"@@ -341,6 +348,40 @@ grpc_slice grpc_slice_split_tail(grpc_slice *source, size_t split) {   return tail; } +grpc_slice grpc_slice_split_tail_no_ref(grpc_slice *source, size_t split) {+  grpc_slice tail;++  if (source->refcount == NULL) {+    /* inlined data, copy it out */+    GPR_ASSERT(source->data.inlined.length >= split);+    tail.refcount = NULL;+    tail.data.inlined.length = (uint8_t)(source->data.inlined.length - split);+    memcpy(tail.data.inlined.bytes, source->data.inlined.bytes + split,+           tail.data.inlined.length);+    source->data.inlined.length = (uint8_t)split;+  } else {+    size_t tail_length = source->data.refcounted.length - split;+    GPR_ASSERT(source->data.refcounted.length >= split);+    if (tail_length < sizeof(tail.data.inlined.bytes)) {+      /* Copy out the bytes - it'll be cheaper than refcounting */+      tail.refcount = NULL;+      tail.data.inlined.length = (uint8_t)tail_length;+      memcpy(tail.data.inlined.bytes, source->data.refcounted.bytes + split,+             tail_length);+    } else {","This else block is the only segment in which the logic differs from grpc_slice_split_tail. Would rather see some structure that duplicates less code. Some ideas;* an internal version that takes the refcount to assign to tail.refcount* grpc_slice_split_tail takes in a bool, defaulted to true, which dictates if it will alter the refcounts.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/10613,111280339,2017-04-12T23:08:06Z,src/core/lib/slice/slice_buffer.c,"@@ -273,7 +306,8 @@ void grpc_slice_buffer_move_first(grpc_slice_buffer *src, size_t n,       grpc_slice_buffer_add(dst, slice);       break;     } else { /* n < slice_len */-      grpc_slice_buffer_undo_take_first(src, grpc_slice_split_tail(&slice, n));+      grpc_slice_buffer_undo_take_first(+          src, grpc_slice_split_tail_no_ref(&slice, n));","Same comment as above that this duplicates too much code. given this use, I think adding a bool parameter that determines if refcounts will be altered is the cleanest fix, then it can simply be passed to grpc_slice_split_tail with not more changes needed.",
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/10621,111287165,2017-04-13T00:07:22Z,bazel/grpc_build_system.bzl,"@@ -69,3 +69,22 @@ def grpc_proto_library(name, srcs = [], deps = [], well_known_protos = None,     use_external = use_external,   ) +def grpc_cc_test(name, srcs = [], deps = [], external_deps = [], args = [], data = []):",Can we live with plain cc_library for tests?,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/10488,111436411,2017-04-13T16:54:45Z,include/grpc/impl/codegen/grpc_types.h,"@@ -495,13 +489,10 @@ typedef struct grpc_op {        */       grpc_slice *status_details;     } send_status_from_server;-    /** ownership of the array is with the caller, but ownership of the elements-        stays with the call object (ie key, value members are owned by the call-        object, recv_initial_metadata->array is owned by the caller).-        After the operation completes, call grpc_metadata_array_destroy on this-        value, or reuse it in a future op. */     struct {-      grpc_metadata_array *recv_initial_metadata;+      /** Ownership of all metadata and the array stays with the grpc_call */+      grpc_metadata **initial_metadata;",nit: inconsistent naming initial_metadata & count  vs  trailing_metadata & trailing_metadata_count?,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/10488,111441984,2017-04-13T17:22:55Z,include/grpc/grpc.h,"@@ -374,7 +371,7 @@ GRPCAPI void grpc_call_destroy(grpc_call *call);     \a grpc_server_register_completion_queue. */ GRPCAPI grpc_call_error grpc_server_request_call(     grpc_server *server, grpc_call **call, grpc_call_details *details,-    grpc_metadata_array *request_metadata,+    grpc_metadata **request_metadata, size_t *request_metadata_count,",I assume the resulting request_metadata is owned by the call. Maybe add that to the doc. Also below.,
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/10588,111453007,2017-04-13T18:15:00Z,src/core/lib/channel/http_server_filter.c,"@@ -238,14 +240,12 @@ static grpc_error *server_filter_incoming_metadata(grpc_exec_ctx *exec_ctx,        /* decode payload from query and add to the slice buffer to be returned */       const int k_url_safe = 1;-      grpc_slice_buffer_add(-          &calld->read_slice_buffer,-          grpc_base64_decode(exec_ctx,-                             (const char *)GRPC_SLICE_START_PTR(query_slice),-                             k_url_safe));+      grpc_slice_buffer_add(&calld->read_slice_buffer,+                            grpc_base64_decode(exec_ctx, b64_data, k_url_safe));",I think you want to get rid of b64_data and just use grpc_base64_decode_with_len. See #10618.,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/10650,111519220,2017-04-14T02:04:14Z,build.yaml,"@@ -14,7 +14,7 @@ settings:   '#10': See the expand_version.py for all the quirks here   core_version: 3.0.0-dev   g_stands_for: gentle","Yes, we were wondering. As well as https://github.com/grpc/grpc/blob/master/doc/g_stands_for.md I presume. Suggestions?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/10645,111579247,2017-04-14T14:20:32Z,src/core/ext/filters/client_channel/client_channel.c,"@@ -346,6 +351,37 @@ static void parse_retry_throttle_params(const grpc_json *field, void *arg) {   } } +// Wrap a closure associated with \a lb_policy. The associated callback (\a+// wrapped_on_pick_closure_cb) is responsible for unref'ing \a lb_policy after+// scheduling \a wrapped_closure.+typedef struct wrapped_on_pick_closure_arg {+  /* the closure instance using this struct as argument */+  grpc_closure wrapper_closure;++  /* the original closure. Usually a on_complete/notify cb for pick() and ping()+   * calls against the internal RR instance, respectively. */+  grpc_closure *wrapped_closure;++  /* The policy instance related to the closure */+  grpc_lb_policy *lb_policy;++  /* heap memory to be freed upon closure execution. Usually this arg. */+  void *free_when_done;","Given that we're always setting this to the `wrapped_on_pick_closure_arg` struct, we probably don't need it.  Instead, we can just have the callback unconditionally free the arg.",
17325098,makdharma,https://api.github.com/repos/grpc/grpc/pulls/10609,111637715,2017-04-14T21:18:07Z,tools/run_tests/run_interop_tests.py,"@@ -371,6 +371,39 @@ def unimplemented_test_cases_server(self):   def __str__(self):     return 'php7' +class ObjcLanguage:++  def __init__(self):+    self.client_cwd = 'src/objective-c/tests'+    self.safename = str(self)++  def client_cmd(self, args):+    # from args, extract the server port and craft xcodebuild command out of it+    for arg in args:+      port = re.search('--server_port=(\d+)', arg)+      if port:+        portnum = port.group(1)+        cmdline = 'pod install && xcodebuild -workspace Tests.xcworkspace -scheme InteropTestsLocalSSL -destination name=""iPhone 6"" HOST_PORT_LOCALSSL=localhost:%s test'%portnum+        return [cmdline]++  def cloud_to_prod_env(self):+    return {}++  def global_env(self):+    return {}++  def unimplemented_test_cases(self):+    # ObjC test runs all cases with the same command. It ignores the testcase+    # cmdline argument. Here we return all but one test cases as unimplemented,+    # and depend upon ObjC test's behavior that it runs all cases even when+    # we tell it to run just one.+    return _TEST_CASES[1:]",I am skipping every test case except 'large_unary'. This is because there is no way to pass a specific test case name to the client executable at runtime. So all test names are hardcoded and they all run every time you run the client exe. Hence 'large_unary' actually invokes all test cases.,
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/10391,111643740,2017-04-14T22:13:21Z,tools/codegen/core/gen_static_metadata.py,"@@ -159,6 +160,7 @@     'user-agent',     'host',     'lb-token',+    'lb-cost-bin',","Can this be multivalued? If yes, it doesn't belong here.",
17325098,makdharma,https://api.github.com/repos/grpc/grpc/pulls/10505,111829093,2017-04-17T21:44:57Z,src/objective-c/tests/InteropTests.m,"@@ -457,4 +457,99 @@ - (void)testRPCAfterClosingOpenConnections {   [self waitForExpectationsWithTimeout:TEST_TIMEOUT handler:nil]; } +- (void)testAlternateDispatchQueue {+  XCTAssertNotNil(self.class.host);+  __weak XCTestExpectation *expectation1 = [self expectationWithDescription:@""AlternateDispatchQueue1""];++  NSArray *requests = @[@27182, @8, @1828, @45904];+  NSArray *responses = @[@31415, @9, @2653, @58979];++  // Set the default dispatch queue+  NSString *queue1_label = @""test.queue1"";+  NSString *queue2_label = @""test.queue2"";+  dispatch_queue_t queue1 = dispatch_queue_create([queue1_label UTF8String], DISPATCH_QUEUE_SERIAL);+  dispatch_queue_t queue2 = dispatch_queue_create([queue2_label UTF8String], DISPATCH_QUEUE_SERIAL);+  [_service setDefaultResponseDispatchQueue:queue1];",There are two ways to set the queue on which protobuf is decoded. I'd suggest to remove this way (setDefaultResponseDispatchQueue) and only give one canonical way to setting the queue. THis will reduce possible combinations and debugging complexity.,
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/10662,112000889,2017-04-18T16:28:27Z,src/core/lib/surface/completion_queue.c,"@@ -60,26 +60,51 @@ typedef struct {   void *tag; } plucker; +/* Queue that holds the cq_completion_events. This internally uses gpr_mpscq+ * queue (a lockfree multiproducer single consumer queue). However this queue+ * supports multiple consumers too. As such, it uses the queue_mu to serialize+ * consumer access (but no locks for producer access).+ *+ * Currently this is only used in completion queues whose completion_type is+ * GRPC_CQ_NEXT */+typedef struct grpc_cq_event_queue {+  /* Mutex to serialize consumers i.e pop() operations */+  gpr_mu queue_mu;++  gpr_mpscq queue;++  /* A lazy counter indicating the number of items in the queue. This is NOT+     atomically incremented/decrements along with push/pop operations and hence+     only eventually consistent */+  gpr_atm num_queue_items;+} grpc_cq_event_queue;+ /* Completion queue structure */ struct grpc_completion_queue {",Can we go ahead and add a vtable for the top half... suggest something like:```cstruct grpc_cq_vtable {  size_t size;  void (*begin_op)(...);  void (*end_op)(...);  void (*pluck)(...);  void (*next)(...);};```and remove data structure bits from grpc_completion_queue (maybe into something like `struct cq_data`),
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/10708,112052967,2017-04-18T20:16:35Z,test/cpp/interop/BUILD,"@@ -0,0 +1,89 @@+# Copyright 2017, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.++licenses([""notice""])  # 3-clause BSD++cc_library(+    name = ""server_helper_lib"",+    srcs = [+        ""server_helper.cc"",+    ],+    hdrs = [+        ""server_helper.h"",+    ],+    deps = [+        ""//test/cpp/util:test_util"",",What I was trying to say is that you may need //external:gflags in the deps list of some of the targets here. It is also pulled in transitively from other target such as test_config.,
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/10662,112071010,2017-04-18T21:39:16Z,src/core/lib/surface/completion_queue.h,"@@ -49,6 +49,8 @@ extern int grpc_trace_pending_tags; #endif  typedef struct grpc_cq_completion {+  gpr_mpscq_node node;",Yes. It can be but we still need extra storage to store success..so something like ``` C  typedef struct grpc_cq_completion {    union {      gpr_mpscq_node node;      unitptr_t next;      bool is_success;    } list_data;   }```Did you have something else in mind ?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/10706,112464258,2017-04-20T14:15:45Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.c,"@@ -242,6 +243,46 @@ void grpc_resolve_address_ares_impl(grpc_exec_ctx *exec_ctx, const char *name,   r->success = false;   r->error = GRPC_ERROR_NONE;   ares_channel *channel = grpc_ares_ev_driver_get_channel(r->ev_driver);++  // If dns_server is specified, use it.+  if (dns_server != NULL) {+    gpr_log(GPR_INFO, ""Using DNS server %s"", dns_server);+    struct sockaddr_storage sockaddr;+    if (grpc_parse_ipv4_hostport(dns_server, (struct sockaddr_in *)&sockaddr,+                                 false /* log_errors */)) {+      r->dns_server_addr.family = AF_INET;+      struct sockaddr_in *in = (struct sockaddr_in *)&sockaddr;+      memcpy(&r->dns_server_addr.addr.addr4, &in->sin_addr,+             sizeof(struct in_addr));+      r->dns_server_addr.tcp_port = ntohs(in->sin_port);+      r->dns_server_addr.udp_port = ntohs(in->sin_port);+    } else if (grpc_parse_ipv6_hostport(dns_server,+                                        (struct sockaddr_in6 *)&sockaddr,+                                        false /* log_errors */)) {+      r->dns_server_addr.family = AF_INET6;+      struct sockaddr_in6 *in6 = (struct sockaddr_in6 *)&sockaddr;+      memcpy(&r->dns_server_addr.addr.addr6, &in6->sin6_addr,+             sizeof(struct in6_addr));+      r->dns_server_addr.tcp_port = ntohs(in6->sin6_port);+      r->dns_server_addr.udp_port = ntohs(in6->sin6_port);+    } else {+      error = grpc_error_set_str(+          GRPC_ERROR_CREATE_FROM_STATIC_STRING(""cannot parse authority""),+          GRPC_ERROR_STR_TARGET_ADDRESS, grpc_slice_from_copied_string(name));+      goto error_cleanup;+    }+    int status = ares_set_servers_ports(*channel, &r->dns_server_addr);","Any suggestions on how to fix this?  We need this function in order to support using a local DNS server, so I think this PR would be useless without it.  Is there some cpp macro I can use to make this code conditional on the right version of c-ares, or perhaps just when not building with node?",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/10720,112737136,2017-04-21T17:20:18Z,src/core/ext/transport/chttp2/transport/writing.c,"@@ -206,9 +203,20 @@ bool grpc_chttp2_begin_write(grpc_exec_ctx *exec_ctx,     }   } +  bool partial_write = false;+   /* for each grpc_chttp2_stream that's become writable, frame it's data      (according to available window sizes) and add to the output buffer */-  while (grpc_chttp2_list_pop_writable_stream(t, &s)) {+  while (true) {+    if (t->outbuf.length > 1024 * 1024) {","Since this will eventually be a tuned parameter, how about at least making it a #define or something now so that it's identifiable in the future?",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/10776,112740750,2017-04-21T17:39:43Z,README.md,"@@ -37,8 +37,9 @@ Libraries in different languages may be in different states of development. We a | Objective-C             | [src/objective-c](src/objective-c)  | 1.0     |  <small>-Java source code is in the [grpc-java](http://github.com/grpc/grpc-java) repository.-Go source code is in the [grpc-go](http://github.com/grpc/grpc-go) repository.+Java source code is in the <a href=""//github.com/grpc/grpc-java"">grpc-java</a>","Go big or go home! ok no, don't put a `<big>` either",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/10522,113037747,2017-04-24T19:40:37Z,src/core/tsi/transport_security_adapter.h,"@@ -0,0 +1,62 @@+/*+ *+ * Copyright 2017, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#ifndef GRPC_CORE_TSI_TRANSPORT_SECURITY_ADAPTER_H+#define GRPC_CORE_TSI_TRANSPORT_SECURITY_ADAPTER_H++#include ""src/core/tsi/transport_security_interface.h""++#ifdef __cplusplus+extern ""C"" {+#endif++/* Create a tsi handshaker that takes an implementation of old interface and+   converts into an implementation of new interface. In the old interface,+   there are get_bytes_to_send_to_peer, process_bytes_from_peer, get_result,+   extract_peer, and create_frame_protector. In the new interface, only next+   method is needed. See transport_security_interface.h for details. Note that+   this tsi adapter handshaker is temporary. It will be removed once TSI has+   been fully migrated to the new interface.+   Ownership of input tsi_handshaker is transferred to this new adapter.  */","Thanks jboeuf for review! Do we expect to remove the old APIs (process_bytes_from_peer, get_bytes_to_send_to_peer, etc.) eventually? If so, this wrapper is no longer useful once old APIs get removed. ",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/10822,113052292,2017-04-24T20:48:07Z,tools/run_tests/python_utils/port_server.py,"@@ -33,18 +33,20 @@ from __future__ import print_function  import argparse-from six.moves import BaseHTTPServer+from BaseHTTPServer import HTTPServer, BaseHTTPRequestHandler","If I implemented this server in Go, would you be asking for me to write preprocessor macros so I could also compile it in Fortran?We get to choose the language we use for our infrastructure, and I see no point in trying to make each program run under more than one language. Doing so just adds complexity for no real value.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/10427,113246361,2017-04-25T16:33:23Z,include/grpc/impl/codegen/compression_types.h,"@@ -101,15 +100,15 @@ typedef struct grpc_compression_options {    * precedence over \a default_algorithm.    * TODO(dgq): currently only available for server channels. */   struct {-    bool is_set;+    int is_set;","Did this C89 violation ever make it into a release branch? If so, should it be backported?",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/10849,113341375,2017-04-26T00:15:58Z,src/core/ext/filters/workarounds/workaround_cronet_compression_filter.c,"@@ -0,0 +1,149 @@+//+// Copyright 2017, Google Inc.+// All rights reserved.+//+// Redistribution and use in source and binary forms, with or without+// modification, are permitted provided that the following conditions are+// met:+//+//     * Redistributions of source code must retain the above copyright+// notice, this list of conditions and the following disclaimer.+//     * Redistributions in binary form must reproduce the above+// copyright notice, this list of conditions and the following disclaimer+// in the documentation and/or other materials provided with the+// distribution.+//     * Neither the name of Google Inc. nor the names of its+// contributors may be used to endorse or promote products derived from+// this software without specific prior written permission.+//+// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+//++#include ""src/core/ext/filters/workarounds/workaround_cronet_compression_filter.h""++#include <string.h>++#include ""src/core/lib/surface/channel_init.h""+#include ""src/core/lib/channel/channel_stack_builder.h""+/*+#include <grpc/impl/codegen/grpc_types.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>++#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/support/string.h""+#include ""src/core/lib/transport/service_config.h""+*/++#define GRPC_WORKAROUND_PRIORITY_HIGH 9999++typedef struct call_data {+  // Receive closures are chained: we inject this closure as the+  // recv_initial_metadata_ready up-call on transport_stream_op, and remember to+  // call our next_recv_initial_metadata_ready member after handling it.+  grpc_closure recv_initial_metadata_ready;+  // Used by recv_initial_metadata_ready.+  grpc_metadata_batch *recv_initial_metadata;+  // Original recv_initial_metadata_ready callback, invoked after our own.+  grpc_closure* next_recv_initial_metadata_ready;+} call_data;++typedef struct channel_data {+} channel_data;++// Callback invoked when we receive an initial metadata.+static void recv_initial_metadata_ready(grpc_exec_ctx* exec_ctx, void* user_data,+                                        grpc_error* error) {+  grpc_call_element* elem = user_data;+  call_data* calld = elem->call_data;++  ++  // Invoke the next callback.+  grpc_closure_run(exec_ctx, calld->next_recv_initial_metadata_ready, GRPC_ERROR_REF(error));+}++// Start transport stream op.+static void start_transport_stream_op_batch(+    grpc_exec_ctx* exec_ctx, grpc_call_element* elem,+    grpc_transport_stream_op_batch* op) {+  call_data* calld = elem->call_data;++  // Inject callback for receiving initial metadata+  if (op->recv_initial_metadata) {+    calld->next_recv_initial_metadata_ready =+        op->payload->recv_initial_metadata.recv_initial_metadata_ready;+    op->payload->recv_initial_metadata.recv_initial_metadata_ready = &calld->recv_initial_metadata_ready;+    calld->recv_initial_metadata = op->payload->recv_initial_metadata.recv_initial_metadata;+  }++  // Chain to the next filter.+  grpc_call_next_op(exec_ctx, elem, op);+}++// Constructor for call_data.+static grpc_error* init_call_elem(grpc_exec_ctx* exec_ctx,+                                  grpc_call_element* elem,+                                  const grpc_call_element_args* args) {+  call_data* calld = elem->call_data;+  calld->next_recv_initial_metadata_ready = NULL;+  grpc_closure_init(&calld->recv_initial_metadata_ready, recv_initial_metadata_ready, elem,+                    grpc_schedule_on_exec_ctx);+  return GRPC_ERROR_NONE;+}++// Destructor for call_data.+static void destroy_call_elem(grpc_exec_ctx* exec_ctx, grpc_call_element* elem,+                              const grpc_call_final_info* final_info,+                              grpc_closure* ignored) {}++// Constructor for channel_data.+static grpc_error* init_channel_elem(grpc_exec_ctx* exec_ctx,+                                     grpc_channel_element* elem,+                                     grpc_channel_element_args* args) {+  return GRPC_ERROR_NONE;+}++// Destructor for channel_data.+static void destroy_channel_elem(grpc_exec_ctx* exec_ctx,+                                 grpc_channel_element* elem) {}++const grpc_channel_filter grpc_workaround_cronet_compression_filter = {+    start_transport_stream_op_batch,+    grpc_channel_next_op,+    sizeof(call_data),+    init_call_elem,+    grpc_call_stack_ignore_set_pollset_or_pollset_set,+    destroy_call_elem,+    sizeof(channel_data),+    init_channel_elem,+    destroy_channel_elem,+    grpc_call_next_get_peer,+    grpc_channel_next_get_info,+    ""workaround_cronet_compression""};++static bool register_workaround_cronet_compression(grpc_exec_ctx* exec_ctx,+                                                   grpc_channel_stack_builder* builder,+                                                   void* arg) {+  return grpc_channel_stack_builder_prepend_filter(","This needs to depend on some parameter (likely a channel arg, accessed from builder)",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/10427,113574888,2017-04-26T22:08:20Z,include/grpc/impl/codegen/port_platform.h,"@@ -290,6 +290,12 @@ #endif #endif /* GPR_NO_AUTODETECT_PLATFORM */ +#if defined(__has_include)","It's valid C89, it's something we've avoided stylistically",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/10874,113641948,2017-04-27T08:33:31Z,tools/gce/linux_performance_worker_init.sh,"@@ -117,18 +122,25 @@ sudo apt-get update sudo apt-get install -y mono-devel nuget  # C# .NET Core dependencies (https://www.microsoft.com/net/core#ubuntu)-sudo sh -c 'echo ""deb [arch=amd64] https://apt-mo.trafficmanager.net/repos/dotnet-release/ xenial main"" > /etc/apt/sources.list.d/dotnetdev.list'+sudo sh -c 'echo ""deb [arch=amd64] https://apt-mo.trafficmanager.net/repos/dotnet-release/ yakkety main"" > /etc/apt/sources.list.d/dotnetdev.list' sudo apt-key adv --keyserver apt-mo.trafficmanager.net --recv-keys 417A0893 sudo apt-get update-sudo apt-get install -y dotnet-dev-1.0.0-preview2-003131+sudo apt-get install -y dotnet-dev-1.0.0-preview2.1-003155","That is problematic because whenever sdk version is set in global.json,  the SDK version needs to match exactly.Since we migrated to the new .csproj projects recently, we are not using global.json in upstream/master or v1.3.x (so that's fine), but global.json is still in use in v1.2.x: https://github.com/grpc/grpc/blob/v1.2.x/src/csharp/global.jsonUpdating the workers would mean breaking the performance benchmarks for v1.2.x (our performance_released dashboard), since C# won't build.  On the other hand, we are hopefully a few days away from releasing v1.3.x and when that happens, we will also bump performance_release dashboard to v1.3.x and unbreak it. ",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/10821,113732874,2017-04-27T15:48:00Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb_client_stats.c,"@@ -0,0 +1,133 @@+/*+ *+ * Copyright 2017, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#include ""src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb_client_stats.h""++#include <grpc/support/alloc.h>+#include <grpc/support/atm.h>+#include <grpc/support/sync.h>+#include <grpc/support/useful.h>++#include ""src/core/lib/channel/channel_args.h""++#define GRPC_ARG_GRPCLB_CLIENT_STATS ""grpc.grpclb_client_stats""++struct grpc_grpclb_client_stats {+  gpr_refcount refs;+  gpr_atm num_calls_started;+  gpr_atm num_calls_finished;+  gpr_atm num_calls_finished_with_drop_for_rate_limiting;+  gpr_atm num_calls_finished_with_drop_for_load_balancing;+  gpr_atm num_calls_finished_with_client_failed_to_send;+  gpr_atm num_calls_finished_known_received;+};++grpc_grpclb_client_stats* grpc_grpclb_client_stats_create() {+  grpc_grpclb_client_stats* client_stats = gpr_zalloc(sizeof(*client_stats));+  gpr_ref_init(&client_stats->refs, 1);+  return client_stats;+}++grpc_grpclb_client_stats* grpc_grpclb_client_stats_ref(+    grpc_grpclb_client_stats* client_stats) {+  gpr_ref(&client_stats->refs);+  return client_stats;+}++void grpc_grpclb_client_stats_unref(grpc_grpclb_client_stats* client_stats) {+  if (gpr_unref(&client_stats->refs)) {+    gpr_free(client_stats);+  }+}++void grpc_grpclb_client_stats_add_call_started(+    grpc_grpclb_client_stats* client_stats) {+  gpr_atm_full_fetch_add(&client_stats->num_calls_started, (gpr_atm)1);+}++void grpc_grpclb_client_stats_add_call_finished(+    bool finished_with_drop_for_rate_limiting,+    bool finished_with_drop_for_load_balancing,+    bool finished_with_client_failed_to_send, bool finished_known_received,+    grpc_grpclb_client_stats* client_stats) {+  gpr_atm_full_fetch_add(&client_stats->num_calls_finished, (gpr_atm)1);+  if (finished_with_drop_for_rate_limiting) {+    gpr_atm_full_fetch_add(+        &client_stats->num_calls_finished_with_drop_for_rate_limiting,+        (gpr_atm)1);+  }+  if (finished_with_drop_for_load_balancing) {+    gpr_atm_full_fetch_add(+        &client_stats->num_calls_finished_with_drop_for_load_balancing,+        (gpr_atm)1);+  }+  if (finished_with_client_failed_to_send) {+    gpr_atm_full_fetch_add(+        &client_stats->num_calls_finished_with_client_failed_to_send,+        (gpr_atm)1);+  }+  if (finished_known_received) {+    gpr_atm_full_fetch_add(&client_stats->num_calls_finished_known_received,+                           (gpr_atm)1);+  }+}++static void atomic_get_and_reset_counter(int64_t* value, gpr_atm* counter) {+  *value = (int64_t)gpr_atm_acq_load(counter);+  gpr_atm_full_fetch_add(counter, (gpr_atm)(-*value));","Because other calls may be incrementing the counter at the same time.  We want to subtract the amount that we're reporting now but not overwrite whatever excess amount has accumulated, since we want that data to be included in the next load report.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/10821,113733932,2017-04-27T15:51:54Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -202,6 +217,12 @@ static void wrapped_rr_closure(grpc_exec_ctx *exec_ctx, void *arg,                 (void *)*wc_arg->target, (void *)wc_arg->rr_policy);         abort();       }+      // Pass on client stats via context. Passes ownership of the reference.","Is there any real value in this consistency?  I don't know of any style rule that says that we have to use the same style comments throughout a given file.  I personally prefer C++-style comments for full-line or end-of-line comments, although I do use C-style comments for in-line comments (e.g., to document the name of each parameter for a function call with many parameters).  I don't really see a problem with mixing the two in the same file.",
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/10864,113822350,2017-04-27T23:09:02Z,src/core/lib/surface/server.c,"@@ -547,15 +523,15 @@ static void publish_new_rpc(grpc_exec_ctx *exec_ctx, void *arg,    for (size_t i = 0; i < server->cq_count; i++) {     size_t cq_idx = (chand->cq_idx + i) % server->cq_count;-    int request_id = gpr_stack_lockfree_pop(rm->requests_per_cq[cq_idx]);-    if (request_id == -1) {+    requested_call *rc =+        (requested_call *)gpr_locked_mpscq_pop(&rm->requests_per_cq[cq_idx]);",This makes it a bit more likely to queue requests in slow-list (especially if there are fewer server cqs).  Not easy to solve though. Perhaps add a log line before adding a request to slow list  (or keeping a count of the number of pending calls and log an error message when that count increases some threshold - say 500).,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/9376,113930934,2017-04-28T13:34:08Z,test/cpp/util/BUILD,"@@ -104,5 +104,29 @@ cc_test(     ], ) --+cc_binary(+    name = ""grpc_cli"",+    srcs = [+        ""cli_call.cc"",+        ""cli_call.h"",",https://github.com/grpc/grpc/blob/master/build.yaml#L1320and https://github.com/grpc/grpc/blob/master/build.yaml#L3702,
477596,ivucica,https://api.github.com/repos/grpc/grpc/pulls/9376,113942334,2017-04-28T14:26:21Z,test/cpp/util/BUILD,"@@ -104,5 +104,29 @@ cc_test(     ], ) --+cc_binary(+    name = ""grpc_cli"",+    srcs = [+        ""cli_call.cc"",+        ""cli_call.h"",","As discussed on hangouts: `cc_binary()` has no `hdrs`, and even in `cc_library()` it's valid to list in `srcs` various `.h` files that are not intended to be consumed by other rules.I am doing some work on reorganizing this anyway, for possible testability and reuse. I may send it as a new PR.",
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/10906,114148996,2017-05-01T16:21:51Z,include/grpc++/impl/codegen/call.h,"@@ -560,12 +562,21 @@ class CallOpClientRecvStatus {    void FinishOp(bool* status) {     if (recv_status_ == nullptr) return;-    metadata_map_->FillMap();+    trailing_metadata_map_->FillMap();+    // In the case where we receive a Trailers-Only response, the+    // metadata will be returned as initial metadata instead of trailing+    // metadata, so we need to check both.     grpc::string binary_error_details;-    auto iter = metadata_map_->map()->find(kBinaryErrorDetailsKey);-    if (iter != metadata_map_->map()->end()) {+    auto iter = trailing_metadata_map_->map()->find(kBinaryErrorDetailsKey);+    if (iter != trailing_metadata_map_->map()->end()) {",Now that you are here. Could you erase the pair from the trailing/initial metadata map? I think this is an oversight from the previous implementation and now that it can appear in either trailing or initial metadata would make it more confusing. Thanks.,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/10931,114186254,2017-05-01T19:44:18Z,src/python/grpcio/grpc/beta/implementations.py,"@@ -26,7 +26,7 @@ # THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT # (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE # OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.-""""""Entry points into the Beta API of gRPC Python.""""""","I don't think that ""Deprecated"" is enough here; I think what should be done instead should be additional prose in an explanatory paragraph. [In Python doc strings, these look like](https://google.github.io/styleguide/pyguide.html?showone=Comments#Comments)```py""""""Entry points in the (deprecated) Beta API of gRPC Python.This module is deprecated; it remains only for backwards compatibilitywith pre-1.0 code. Introduce no new uses of these code elements.""""""```.",
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/10925,114470866,2017-05-03T04:29:11Z,src/core/lib/security/transport/security_handshaker.c,"@@ -199,34 +213,80 @@ static grpc_error *check_peer_locked(grpc_exec_ctx *exec_ctx,   return GRPC_ERROR_NONE; } -static grpc_error *send_handshake_bytes_to_peer_locked(grpc_exec_ctx *exec_ctx,-                                                       security_handshaker *h) {-  // Get data to send.-  tsi_result result = TSI_OK;-  size_t offset = 0;-  do {-    size_t to_send_size = h->handshake_buffer_size - offset;-    result = tsi_handshaker_get_bytes_to_send_to_peer(-        h->handshaker, h->handshake_buffer + offset, &to_send_size);-    offset += to_send_size;-    if (result == TSI_INCOMPLETE_DATA) {-      h->handshake_buffer_size *= 2;-      h->handshake_buffer =-          gpr_realloc(h->handshake_buffer, h->handshake_buffer_size);-    }-  } while (result == TSI_INCOMPLETE_DATA);+static grpc_error *on_handshake_next_done_locked(+    grpc_exec_ctx *exec_ctx, security_handshaker *h, tsi_result result,+    const unsigned char *bytes_to_send, size_t bytes_to_send_size,+    tsi_handshaker_result *handshaker_result) {+  grpc_error *error = GRPC_ERROR_NONE;+  // Read more if we need to.+  if (result == TSI_INCOMPLETE_DATA) {+    GPR_ASSERT(bytes_to_send_size == 0);+    grpc_endpoint_read(exec_ctx, h->args->endpoint, h->args->read_buffer,+                       &h->on_handshake_data_received_from_peer);+    return error;+  }   if (result != TSI_OK) {     return grpc_set_tsi_error_result(         GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Handshake failed""), result);   }-  // Send data.-  grpc_slice to_send =-      grpc_slice_from_copied_buffer((const char *)h->handshake_buffer, offset);-  grpc_slice_buffer_reset_and_unref_internal(exec_ctx, &h->outgoing);++  // Send data to peer.+  grpc_slice to_send = grpc_slice_from_copied_buffer(+      (const char *)bytes_to_send, bytes_to_send_size);+  grpc_slice_buffer_reset_and_unref(&h->outgoing);   grpc_slice_buffer_add(&h->outgoing, to_send);   grpc_endpoint_write(exec_ctx, h->args->endpoint, &h->outgoing,                       &h->on_handshake_data_sent_to_peer);-  return GRPC_ERROR_NONE;++  // If handshake has completed, check peer and so on.+  if (handshaker_result != NULL) {+    h->handshaker_result = handshaker_result;",Do we want to assert that there is no previous result here or destroy the previous result unconditionally?,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/10915,114600466,2017-05-03T17:11:10Z,tools/run_tests/dockerize/build_interop_image.sh,"@@ -37,6 +37,7 @@ set -x #  INTEROP_IMAGE - name of tag of the final interop image #  BASE_NAME - base name used to locate the base Dockerfile and build script #  TTY_FLAG - optional -t flag to make docker allocate tty+#  RUNTIME - runtime setting. If specified, Dockerfile-$RUNTIME will be used.","Yes, I am suggesting to flatten the configurations into what you call ""languages"" - but it's just different dockerfiles.   What is a ""language"" and ""runtime"" is basically something that go/grpc-matrix can determine according to your needs.  It just need to know that what is under ""Java"" and ""OpenJDK 8""  corresponds to docker image ""grpc_interop_java_openjdk8"".  Not a big deal, and you don't need to propagate these concepts all the way to the level of run_interop_tests.py (or at least not to the level of build_interop_image shell scripts).",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/10993,114897699,2017-05-04T21:59:32Z,src/python/grpcio/grpc/__init__.py,"@@ -753,6 +753,41 @@ def peer(self):         raise NotImplementedError()      @abc.abstractmethod+    def peer_identity(self):+        """"""Gets the peer identity(s).++      Equivalent to ctx.auth_context().get(ctx.peer_identity_key())","Fun fact: these doc strings are kind of messed up because `yapf` didn't quite understand how to lay them out.I've been meaning to clean them up, but in the meantime let's not compound the problem. This, and the `Returns:` below, should be aligned with the opening of the triple-quote on the first line.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/10993,114899177,2017-05-04T22:08:52Z,src/python/grpcio/grpc/_server.py,"@@ -255,6 +256,27 @@ def invocation_metadata(self):     def peer(self):         return _common.decode(self._rpc_event.operation_call.peer()) +    def peer_identity(self):+        ids = cygrpc.peer_identity(self._rpc_event.operation_call)+        if not ids:+            return None+        else:+            return ids++    def peer_identity_key(self):+        id_key = cygrpc.peer_identity_key(self._rpc_event.operation_call)+        if id_key is None:",`return <conditional expression>`.,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/10993,114899308,2017-05-04T22:09:40Z,src/python/grpcio_tests/tests/unit/_auth_context_test.py,"@@ -0,0 +1,157 @@+# Copyright 2017, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+""""""Tests exposure of SSL auth context""""""++import pickle+import unittest++import grpc+from grpc import _channel+from grpc.framework.foundation import logging_pool++from tests.unit import test_common+from tests.unit.framework.common import test_constants+from tests.unit import resources++_REQUEST = b'\x00\x00\x00'+_RESPONSE = b'\x00\x00\x00'++_UNARY_UNARY = '/test/UnaryUnary'++_SERVER_HOST_OVERRIDE = 'foo.test.google.fr'+_CLIENT_IDS = [","Never write a list literal where a tuple literal will do, especially for the value of a constant.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/10993,114899355,2017-05-04T22:10:01Z,src/python/grpcio_tests/tests/unit/_auth_context_test.py,"@@ -0,0 +1,157 @@+# Copyright 2017, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+""""""Tests exposure of SSL auth context""""""++import pickle+import unittest++import grpc+from grpc import _channel+from grpc.framework.foundation import logging_pool++from tests.unit import test_common+from tests.unit.framework.common import test_constants+from tests.unit import resources++_REQUEST = b'\x00\x00\x00'+_RESPONSE = b'\x00\x00\x00'++_UNARY_UNARY = '/test/UnaryUnary'++_SERVER_HOST_OVERRIDE = 'foo.test.google.fr'+_CLIENT_IDS = [+    b'*.test.google.fr', b'waterzooi.test.google.be', b'*.test.youtube.com',","One line per element in multi-line data structure literals, please.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/10993,114899418,2017-05-04T22:10:30Z,src/python/grpcio_tests/tests/unit/_auth_context_test.py,"@@ -0,0 +1,157 @@+# Copyright 2017, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+""""""Tests exposure of SSL auth context""""""++import pickle+import unittest++import grpc+from grpc import _channel+from grpc.framework.foundation import logging_pool++from tests.unit import test_common+from tests.unit.framework.common import test_constants+from tests.unit import resources++_REQUEST = b'\x00\x00\x00'+_RESPONSE = b'\x00\x00\x00'++_UNARY_UNARY = '/test/UnaryUnary'++_SERVER_HOST_OVERRIDE = 'foo.test.google.fr'+_CLIENT_IDS = [+    b'*.test.google.fr', b'waterzooi.test.google.be', b'*.test.youtube.com',+    b'192.168.1.3'",Include the trailing comma after the last element in multi-line data structure literals.,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/10993,114900531,2017-05-04T22:18:22Z,src/python/grpcio_tests/tests/unit/_auth_context_test.py,"@@ -0,0 +1,157 @@+# Copyright 2017, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+""""""Tests exposure of SSL auth context""""""++import pickle+import unittest++import grpc+from grpc import _channel+from grpc.framework.foundation import logging_pool++from tests.unit import test_common+from tests.unit.framework.common import test_constants+from tests.unit import resources++_REQUEST = b'\x00\x00\x00'+_RESPONSE = b'\x00\x00\x00'++_UNARY_UNARY = '/test/UnaryUnary'++_SERVER_HOST_OVERRIDE = 'foo.test.google.fr'+_CLIENT_IDS = [+    b'*.test.google.fr', b'waterzooi.test.google.be', b'*.test.youtube.com',+    b'192.168.1.3'+]+_ID = 'id'+_ID_KEY = 'id_key'+_AUTH_CTX = 'auth_ctx'+++def handle_unary_unary(request, servicer_context):+    return pickle.dumps({+        _ID: servicer_context.peer_identity(),+        _ID_KEY: servicer_context.peer_identity_key(),+        _AUTH_CTX: servicer_context.auth_context()+    })+++class AuthContextTest(unittest.TestCase):++    def setUp(self):+        self._server = None++    def tearDown(self):+        if self._server is not None:+            self._server.stop(0)++    def testInsecure(self):+        self._server_pool = logging_pool.pool(test_constants.THREAD_CONCURRENCY)+        handler = grpc.method_handlers_generic_handler('test', {+            'UnaryUnary':+            grpc.unary_unary_rpc_method_handler(handle_unary_unary)+        })+        self._server = grpc.server(+            self._server_pool,+            handlers=(handler,),+            maximum_concurrent_rpcs=test_constants.THREAD_CONCURRENCY)+        port = self._server.add_insecure_port('[::]:0')+        self._server.start()+        self._channel = grpc.insecure_channel('localhost:%d' % port)+        response = self._channel.unary_unary(_UNARY_UNARY)(_REQUEST)++        auth_data = pickle.loads(response)+        self.assertIsNone(None, auth_data[_ID])","`None` is always `None`; this looks like it started life as a `self.assertEqual(None, auth_data[_ID])` and didn't make it all the way to `assertNone`.(Here and several other places.)",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/10993,114900720,2017-05-04T22:19:30Z,src/python/grpcio_tests/tests/unit/_auth_context_test.py,"@@ -0,0 +1,157 @@+# Copyright 2017, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+""""""Tests exposure of SSL auth context""""""++import pickle+import unittest++import grpc+from grpc import _channel+from grpc.framework.foundation import logging_pool++from tests.unit import test_common+from tests.unit.framework.common import test_constants+from tests.unit import resources++_REQUEST = b'\x00\x00\x00'+_RESPONSE = b'\x00\x00\x00'++_UNARY_UNARY = '/test/UnaryUnary'++_SERVER_HOST_OVERRIDE = 'foo.test.google.fr'+_CLIENT_IDS = [+    b'*.test.google.fr', b'waterzooi.test.google.be', b'*.test.youtube.com',+    b'192.168.1.3'+]+_ID = 'id'+_ID_KEY = 'id_key'+_AUTH_CTX = 'auth_ctx'+++def handle_unary_unary(request, servicer_context):+    return pickle.dumps({+        _ID: servicer_context.peer_identity(),+        _ID_KEY: servicer_context.peer_identity_key(),+        _AUTH_CTX: servicer_context.auth_context()+    })+++class AuthContextTest(unittest.TestCase):++    def setUp(self):+        self._server = None++    def tearDown(self):+        if self._server is not None:+            self._server.stop(0)++    def testInsecure(self):+        self._server_pool = logging_pool.pool(test_constants.THREAD_CONCURRENCY)+        handler = grpc.method_handlers_generic_handler('test', {+            'UnaryUnary':+            grpc.unary_unary_rpc_method_handler(handle_unary_unary)+        })+        self._server = grpc.server(+            self._server_pool,+            handlers=(handler,),+            maximum_concurrent_rpcs=test_constants.THREAD_CONCURRENCY)+        port = self._server.add_insecure_port('[::]:0')+        self._server.start()+        self._channel = grpc.insecure_channel('localhost:%d' % port)+        response = self._channel.unary_unary(_UNARY_UNARY)(_REQUEST)++        auth_data = pickle.loads(response)+        self.assertIsNone(None, auth_data[_ID])+        self.assertIsNone(None, auth_data[_ID_KEY])+        self.assertEqual({}, auth_data[_AUTH_CTX])++    def testSecureNoCert(self):+        self._server_pool = logging_pool.pool(test_constants.THREAD_CONCURRENCY)+        handler = grpc.method_handlers_generic_handler('test', {+            'UnaryUnary':+            grpc.unary_unary_rpc_method_handler(handle_unary_unary)+        })+        self._server = grpc.server(+            self._server_pool,+            handlers=(handler,),+            maximum_concurrent_rpcs=test_constants.THREAD_CONCURRENCY)+        port = self._server.add_secure_port(+            '[::]:0',+            grpc.ssl_server_credentials(+                [(resources.private_key(), resources.certificate_chain())]))",Never write a list literal where a tuple literal will do. (Can the value on this line be a module-scope constant?),
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/11021,115305951,2017-05-08T17:32:29Z,src/csharp/Grpc.Core/Channel.cs,"@@ -299,6 +304,40 @@ private ChannelState GetConnectivityState(bool tryToConnect)             }         } +        /// <summary>+        /// Constantly Watches channel connectivity status to work around https://github.com/GoogleCloudPlatform/google-cloud-dotnet/issues/822+        /// </summary>+        private async Task RunConnectivityWatcherAsync()+        {+            try+            {+                var lastState = State;+                while (lastState != ChannelState.Shutdown)+                {+                    lock (myLock)+                    {+                        if (shutdownRequested)+                        {+                            break;+                        }+                    }++                    try+                    {+                        await WaitForStateChangedAsync(lastState, DateTime.UtcNow.AddSeconds(1)).ConfigureAwait(false);","I left out an important note: constantly using a timeout on watch connectivity state calls like this could lead to steady memory accumulation over  the lifetimes of long-lived channel objects.(right now for every timeout on that call, there's a malloc that won't get free'd until the channel is later destroyed).see https://github.com/grpc/grpc/pull/10813 for a PR that mentions the issue and tries to fix it.That PR is held up on an unresolved test flake that it seems to be causing; currently I'm revising the ruby state watches to use infinite timeouts, with `grpc_destroy_channel` ending ops by causing state change to `shutdown`, when process is shutdown.That said I'll work more on getting https://github.com/grpc/grpc/pull/10813 in, but I'm not sure how quickly that can happen.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/11026,115361104,2017-05-08T21:45:09Z,src/core/ext/filters/client_channel/lb_policy.h,"@@ -149,7 +149,9 @@ void grpc_lb_policy_init(grpc_lb_policy *policy,  /** Finds an appropriate subchannel for a call, based on \a pick_args. -    \a target will be set to the selected subchannel, or NULL on failure.+    \a target will be set to the selected subchannel, or NULL on failure+    or when the LB policy decides to drop the call.",I wonder if we'd want to have a different way to signal dropping the call. Using `NULL` for both cases makes it ambiguous.,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/11026,115364509,2017-05-08T22:01:24Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -586,42 +597,87 @@ static bool update_lb_connectivity_status_locked(   return true; } -/* perform a pick over \a rr_policy. Given that a pick can return immediately- * (ignoring its completion callback) we need to perform the cleanups this- * callback would be otherwise resposible for */+/* Perform a pick over \a glb_policy->rr_policy. Given that a pick can return+ * immediately (ignoring its completion callback), we need to perform the+ * cleanups this callback would otherwise be resposible for. */ static bool pick_from_internal_rr_locked(-    grpc_exec_ctx *exec_ctx, grpc_lb_policy *rr_policy,+    grpc_exec_ctx *exec_ctx, glb_lb_policy *glb_policy,     const grpc_lb_policy_pick_args *pick_args,     grpc_connected_subchannel **target, wrapped_rr_closure_arg *wc_arg) {-  GPR_ASSERT(rr_policy != NULL);-  const bool pick_done = grpc_lb_policy_pick_locked(-      exec_ctx, rr_policy, pick_args, target, wc_arg->context,-      (void **)&wc_arg->lb_token, &wc_arg->wrapper_closure);-  if (pick_done) {-    /* synchronous grpc_lb_policy_pick call. Unref the RR policy. */-    if (grpc_lb_glb_trace) {-      gpr_log(GPR_INFO, ""Unreffing RR (0x%"" PRIxPTR "")"",-              (intptr_t)wc_arg->rr_policy);+  // Reset counters if we've reached the values specified by the serverlist.+  if (glb_policy->num_calls_picked == glb_policy->serverlist->num_servers &&","this `if` would be more readable if we created `bool`s with names describing the predicate. For example:```const bool a = glb_policy->num_calls_picked == glb_policy->serverlist->num_servers;const bool b = glb_policy->num_calls_dropped_for_rate_limiting == glb_policy->serverlist->num_drop_for_rate_limiting;const bool c = glb_policy->num_calls_dropped_for_load_balancing == glb_policy->serverlist->num_drop_for_load_balancing;if (a && b && c) { ... }```with suitable names for `a`, `b`, `c`.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11026,115516846,2017-05-09T15:15:17Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -586,42 +597,87 @@ static bool update_lb_connectivity_status_locked(   return true; } -/* perform a pick over \a rr_policy. Given that a pick can return immediately- * (ignoring its completion callback) we need to perform the cleanups this- * callback would be otherwise resposible for */+/* Perform a pick over \a glb_policy->rr_policy. Given that a pick can return+ * immediately (ignoring its completion callback), we need to perform the+ * cleanups this callback would otherwise be resposible for. */ static bool pick_from_internal_rr_locked(-    grpc_exec_ctx *exec_ctx, grpc_lb_policy *rr_policy,+    grpc_exec_ctx *exec_ctx, glb_lb_policy *glb_policy,     const grpc_lb_policy_pick_args *pick_args,     grpc_connected_subchannel **target, wrapped_rr_closure_arg *wc_arg) {-  GPR_ASSERT(rr_policy != NULL);-  const bool pick_done = grpc_lb_policy_pick_locked(-      exec_ctx, rr_policy, pick_args, target, wc_arg->context,-      (void **)&wc_arg->lb_token, &wc_arg->wrapper_closure);-  if (pick_done) {-    /* synchronous grpc_lb_policy_pick call. Unref the RR policy. */-    if (grpc_lb_glb_trace) {-      gpr_log(GPR_INFO, ""Unreffing RR (0x%"" PRIxPTR "")"",-              (intptr_t)wc_arg->rr_policy);+  // Reset counters if we've reached the values specified by the serverlist.+  if (glb_policy->num_calls_picked == glb_policy->serverlist->num_servers &&","I don't think this would really make anything more readable in this case, since we're just doing bounds-checking.  These aren't really hard-to-understand conditionals.",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/10993,115607331,2017-05-09T21:29:05Z,src/python/grpcio/grpc/_server.py,"@@ -255,6 +256,27 @@ def invocation_metadata(self):     def peer(self):         return _common.decode(self._rpc_event.operation_call.peer()) +    def peer_identity(self):+        ids = cygrpc.peer_identity(self._rpc_event.operation_call)+        if not ids:","It was the empty list, but I've moved that logic to _cygrpc/security.pyx.pxi",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/10849,115629479,2017-05-09T23:59:41Z,test/core/end2end/tests/compressed_payload.c,"@@ -329,6 +330,18 @@ static void request_with_payload_template(   server_args = grpc_channel_args_set_compression_algorithm(       NULL, default_server_channel_compression_algorithm); +  if (user_agent_override) {",Doesn't this belong in a fixture,
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/10743,115761579,2017-05-10T14:48:52Z,include/grpc++/impl/codegen/proto_utils.h,"@@ -175,64 +175,87 @@ class GrpcBufferReader final     return byte_count_ - backup_count_;   } - private:+ protected:   int64_t byte_count_;   int64_t backup_count_;   grpc_byte_buffer_reader reader_;   grpc_slice slice_;   Status status_; };++// BufferWriter must be a subclass of io::ZeroCopyOutputStream.","static_assert(std::is_base_of(BufferWriter, io::ZeroCopyOutputStream), ""BufferWriter must be a subclass of io::ZeroCopyOutputStream"");",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/11081,115954793,2017-05-11T10:24:05Z,tools/internal_ci/helper_scripts/pre_build_linux.sh,"@@ -0,0 +1,40 @@+#!/bin/bash+# Copyright 2017, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.++set -ex++# Enable IPv6 in Docker+sudo sed -i s/DOCKER_OPTS=/DOCKER_OPTS=\""--ipv6\""/g /etc/init.d/docker+sudo /etc/init.d/docker restart++# Download Docker images from DockerHub+export DOCKERHUB_ORGANIZATION=grpctesting",One option is to source this file (perhaps after renaming it to sth like `pre_build_linux_rc`)  https://superuser.com/questions/46139/what-does-source-do,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/11108,116273820,2017-05-12T16:41:07Z,tools/run_tests/artifacts/artifact_targets.py,"@@ -332,6 +347,10 @@ def targets():            PythonArtifact('linux', 'x86', 'cp34-cp34m'),            PythonArtifact('linux', 'x86', 'cp35-cp35m'),            PythonArtifact('linux', 'x86', 'cp36-cp36m'),+           PythonArtifact('linux', 'arm', '2.7'),",can we have some tags so we can easily filter this out of the 'linux' build (`task_runner.py -f linux artifact`) once https://github.com/grpc/grpc/pull/11115 is merged?perhaps we could use something like 'linux_extra' or 'linux_longrunning' instead of 'linux'?,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/10919,116361681,2017-05-13T16:20:55Z,doc/threading_model.md,"@@ -0,0 +1,31 @@+﻿# gRPC Threading Model++## Introduction+This document serves as a basic intro for the gRPC threading model. gRPC generates service code in two fashions - synchronous and asynchronous API. These two closely correlate to the threading model in play. ++## Synchronous API Threading model+This is the easiest model to start with and could be a satisfactory model for a large number of services. As such, the implementation is efficient (and is not a ‘toy’ implementation). In this model, gRPC takes care of the threading completely and the application code need to worry only about handling of the actual rpc call.+* When the server starts up, a thread pool is created to handle incoming rpc requests. The default implementation of this thread pool is called DynamicThreadPool. It creates threads equal to number of processors in the system and all of them are in waiting state.+* DynamicThreadPool has in­built scaling mechanism to create additional threads on demand. For integrators interested in having a little more control on the behavior of the thread pool, they can define GRPC_CUSTOM_DEFAULT_THREAD_POOL and provide the implementation of the thread pool interface (which is literally just 1 function that adds work to the pool).","So the last two paragraphs are outdated since the the grpc++ server has been using ThreadManager since v1.1, not DynamicThreadPool (DynamicThreadPool is only used now for security credential management, not for actual RPCs). The operation of ThreadManager is similar but more efficient. I think it's ok to include these paragraphs for now on the grounds that this is the way at works at 1.0 , but we should immediately followup with a 2-paragraph fix explaining ThreadManager instead. Suggest comments from @sreecha ",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/10919,116361759,2017-05-13T16:24:36Z,doc/threading_model.md,"@@ -0,0 +1,31 @@+﻿# gRPC Threading Model++## Introduction+This document serves as a basic intro for the gRPC threading model. gRPC generates service code in two fashions - synchronous and asynchronous API. These two closely correlate to the threading model in play. ++## Synchronous API Threading model+This is the easiest model to start with and could be a satisfactory model for a large number of services. As such, the implementation is efficient (and is not a ‘toy’ implementation). In this model, gRPC takes care of the threading completely and the application code need to worry only about handling of the actual rpc call.+* When the server starts up, a thread pool is created to handle incoming rpc requests. The default implementation of this thread pool is called DynamicThreadPool. It creates threads equal to number of processors in the system and all of them are in waiting state.+* DynamicThreadPool has in­built scaling mechanism to create additional threads on demand. For integrators interested in having a little more control on the behavior of the thread pool, they can define GRPC_CUSTOM_DEFAULT_THREAD_POOL and provide the implementation of the thread pool interface (which is literally just 1 function that adds work to the pool).+* As soon as enough data is available to process a complete rpc, the worker thread moves ahead with handling the rpc.+* **Pros**+	* Simple to use and get going.+	* Efficiency would be fine for most applications. Some might gain more efficiency with a more suitable implementation of the thread pool.+* **Cons**+	* The application code could be called concurrently from multiple threads - for the same client or different clients.+	* An entire worker thread is occupied until the rpc finishes. This may lead to scaling problems based on the use case.+	* If you have long running streaming rpcs, a thread would be occupied for it (multiplied by number of clients if applicable).","""for it"" -> ""for it until it finishes, even if there are long gaps with no streaming messages""",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/11115,116371351,2017-05-14T03:05:22Z,tools/run_tests/artifacts/artifact_targets.py,"@@ -162,20 +176,11 @@ def pre_build_jobspecs(self):     return []    def build_jobspec(self):-    if self.platform == 'windows':","nit, optional as fine submitting without: can we keep the exception on `windows` here? My thinking is ruby windows artifact still shouldn't be attempted, since the windows builds are just happening under the linux target",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/11142,116699117,2017-05-16T09:47:35Z,tools/internal_ci/macos/grpc_interop.cfg,"@@ -0,0 +1,40 @@+# Copyright 2017, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.++# Config file for the internal CI (in protobuf text format)++# Location of the continuous shell script in repository.+build_file: ""grpc/tools/internal_ci/macos/grpc_interop.sh""+timeout_mins: 240+action {+  define_artifacts {+    regex: ""**/*sponge_log.xml"",+    regex: ""reports/**""",nit:   I think this needs to be github/grpc/reports/** for it to work. I just checked https://github.com/grpc/grpc/blob/master/tools/internal_ci/linux/grpc_build_artifacts.cfg#L38 and that works well.,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/11142,116700536,2017-05-16T09:53:23Z,tools/internal_ci/linux/grpc_interop_badserver_java.sh,"@@ -36,6 +36,7 @@ export LANG=en_US.UTF-8 cd $(dirname $0)/../../..  source tools/internal_ci/helper_scripts/prepare_build_linux_rc+source tools/internal_ci/helper_scripts/prepare_build_interop_rc  tools/run_tests/run_interop_tests.py -l java --use_docker --http2_server_interop $@",why are  badserver_java and badserver_python separate? it's probably fine for now but we'll want to stop job proliferation.,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/11142,116702396,2017-05-16T10:01:54Z,tools/internal_ci/linux/grpc_interop_tocloud.sh,"@@ -36,5 +36,6 @@ export LANG=en_US.UTF-8 cd $(dirname $0)/../../..  source tools/internal_ci/helper_scripts/prepare_build_linux_rc+source tools/internal_ci/helper_scripts/prepare_build_interop_rc  tools/run_tests/run_interop_tests.py -l all -s all --use_docker --http2_interop -t -j 12 $@","In order to get interop tests building in a reasonable amount of time, you'll probably need to implement the DOCKERHUB_ORGANIZATION trick here:https://github.com/grpc/grpc/blob/master/tools/run_tests/dockerize/build_interop_image.sh#L83(and upload the interop base images to dockerhub).",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/11141,116781071,2017-05-16T15:44:23Z,src/node/src/client.js,"@@ -119,8 +125,10 @@ function _write(chunk, encoding, callback) {   batch[grpc.opType.SEND_MESSAGE] = message;   this.call.startBatch(batch, function(err, event) {     if (err) {-      // Something has gone wrong. Stop writing by failing to call callback-      return;+      /* Assume that the call is complete and that writing failed because a+         status was received. In that case, set a flag to discard all future+         writes */+      self.writeFailed = true;",should writeFailed also be set after `cancelWithStatus` in the exception above?,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11154,116811934,2017-05-16T17:50:57Z,src/python/grpcio_tests/tests/unit/_reconnect_test.py,"@@ -0,0 +1,73 @@+# Copyright 2017, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+""""""Tests that a channel will reconnect if a connection is dropped""""""++import unittest++import grpc+from grpc.framework.foundation import logging_pool++from tests.unit.framework.common import test_constants++_REQUEST = b'\x00\x00\x00'+_RESPONSE = b'\x00\x00\x00'++_UNARY_UNARY = '/test/UnaryUnary'++def handle_unary_unary(unused_request, unused_servicer_context):+    return _RESPONSE++class ReconnectTest(unittest.TestCase):++    def setUp(self):+        self._server_pool = logging_pool.pool(test_constants.THREAD_CONCURRENCY)+        self._handler = grpc.method_handlers_generic_handler('test', {+            'UnaryUnary':+            grpc.unary_unary_rpc_method_handler(handle_unary_unary)+        })+        self._server = grpc.server(self._server_pool, (self._handler,))+        self._port = self._server.add_insecure_port('[::]:0')+        self._server.start()+        self._channel = grpc.insecure_channel(+            'localhost:%d' % self._port)++    def tearDown(self):+        self._server.stop(None)++    def testReconnect(self):+        multi_callable = self._channel.unary_unary(_UNARY_UNARY)+        self.assertEquals(_RESPONSE, multi_callable(_REQUEST))+        self._server.stop(None)","""Rebalance"" the statements in this test so that nothing in the test method ""undoes"" what was done in `setUp` and also so that nothing in the test method ""does"" what will later be undone in `tearDown`. (I think this will mean that what will be left in your test will be only instantiating the thread pool, at which point you may choose to simply not bother with having a separate `setUp`/`tearDown`.)A unit test with a `setUp`/`tearDown` and also only a single test method is particularly susceptible to [premature generalization](http://lesswrong.com/lw/dr/generalizing_from_one_example/).",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11154,116812096,2017-05-16T17:51:42Z,src/python/grpcio_tests/tests/unit/_reconnect_test.py,"@@ -0,0 +1,73 @@+# Copyright 2017, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+""""""Tests that a channel will reconnect if a connection is dropped""""""++import unittest++import grpc+from grpc.framework.foundation import logging_pool++from tests.unit.framework.common import test_constants++_REQUEST = b'\x00\x00\x00'+_RESPONSE = b'\x00\x00\x00'++_UNARY_UNARY = '/test/UnaryUnary'++def handle_unary_unary(unused_request, unused_servicer_context):+    return _RESPONSE++class ReconnectTest(unittest.TestCase):++    def setUp(self):+        self._server_pool = logging_pool.pool(test_constants.THREAD_CONCURRENCY)+        self._handler = grpc.method_handlers_generic_handler('test', {+            'UnaryUnary':+            grpc.unary_unary_rpc_method_handler(handle_unary_unary)+        })+        self._server = grpc.server(self._server_pool, (self._handler,))+        self._port = self._server.add_insecure_port('[::]:0')+        self._server.start()+        self._channel = grpc.insecure_channel(+            'localhost:%d' % self._port)++    def tearDown(self):+        self._server.stop(None)++    def testReconnect(self):","We haven't been good about this in the past but it's on my list of things to clean up (and in the meantime, to avoid digging deeper): use the PEP8-style name `test_reconnect`.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11154,116829910,2017-05-16T19:03:47Z,src/python/grpcio/grpc/_channel.py,"@@ -926,6 +926,11 @@ def __init__(self, target, options, credentials):         self._call_state = _ChannelCallState(self._channel)         self._connectivity_state = _ChannelConnectivityState(self._channel) +        # Temporary work around UNAVAILABLE issues","I don't think this change is sufficient to close #11043 because #11043 is a wrapped-languages issue and this is a Python-only change.#9884 might be the right issue for scoping the temporary-ness of this workaround; I think I'm a little thrown by the way it's being called ""retries"" and being described as a feature when I keep encountering it as ""not trying hard enough the first time"" and thinking of it as a bug.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11196,117254814,2017-05-18T13:58:36Z,test/core/end2end/fixtures/http_proxy_fixture.c,"@@ -400,19 +403,19 @@ static void on_accept(grpc_exec_ctx* exec_ctx, void* arg,   grpc_pollset_set_add_pollset(exec_ctx, conn->pollset_set, proxy->pollset);   grpc_endpoint_add_to_pollset_set(exec_ctx, endpoint, conn->pollset_set);   grpc_closure_init(&conn->on_read_request_done, on_read_request_done, conn,-                    grpc_schedule_on_exec_ctx);+                    grpc_combiner_scheduler(conn->proxy->combiner, false));","What race condition is happening here, and how does using a combiner fix it?",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/11145,117547955,2017-05-19T18:38:11Z,src/core/ext/transport/inproc/inproc_transport.c,"@@ -0,0 +1,938 @@+/*+ *+ * Copyright 2017, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#include ""src/core/ext/transport/inproc/inproc_transport.h""+#include <grpc/support/alloc.h>+#include <grpc/support/string_util.h>+#include <grpc/support/sync.h>+#include <grpc/support/time.h>+#include <string.h>+#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/slice/slice_internal.h""+#include ""src/core/lib/surface/api_trace.h""+#include ""src/core/lib/surface/channel.h""+#include ""src/core/lib/surface/channel_stack_type.h""+#include ""src/core/lib/surface/server.h""+#include ""src/core/lib/transport/connectivity_state.h""+#include ""src/core/lib/transport/error_utils.h""+#include ""src/core/lib/transport/transport_impl.h""++static const grpc_transport_vtable inproc_vtable;+static grpc_slice g_empty_slice;++typedef struct {+  gpr_mu mu;+  gpr_refcount refs;+} shared_mu;++typedef struct inproc_transport {+  grpc_transport base;+  shared_mu *mu;+  gpr_refcount refs;+  bool is_client;+  grpc_connectivity_state_tracker connectivity;+  void (*accept_stream_cb)(grpc_exec_ctx *exec_ctx, void *user_data,+                           grpc_transport *transport, const void *server_data);+  void *accept_stream_data;+  bool is_closed;+  struct inproc_transport *other_side;+} inproc_transport;++// Specialize grpc_byte_stream for the single-slice case that we use here+typedef struct {+  grpc_byte_stream base;+  grpc_slice slice;+} inproc_slice_byte_stream;++typedef struct inproc_stream {+  inproc_transport *t;+  grpc_slice to_read_initial_md;+  grpc_slice_buffer to_read_message;+  grpc_slice to_read_trailing_md;+  bool read_closure_needed;+  grpc_closure read_closure;+  // Write buffer used only during gap at init time when client-side+  // stream is set up but server side stream is not yet set up+  grpc_slice write_buffer_initial_md;+  gpr_timespec write_buffer_deadline;+  grpc_slice_buffer write_buffer_message;+  grpc_slice write_buffer_trailing_md;+  grpc_error *write_buffer_cancel_error;++  struct inproc_stream *other_side;+  gpr_refcount refs;+  grpc_closure *closure_at_destroy;++  grpc_transport_stream_op_batch *recv_initial_md_op;+  grpc_transport_stream_op_batch *recv_message_op;+  grpc_transport_stream_op_batch *recv_trailing_md_op;++  size_t num_linked_mds;+  size_t space_linked_mds;+  grpc_linked_mdelem **linked_md_array;++  inproc_slice_byte_stream recv_message_stream;++  bool initial_md_sent;+  bool trailing_md_sent;+  bool initial_md_recvd;+  bool trailing_md_recvd;++  grpc_error *cancel_error;++  gpr_timespec deadline;+} inproc_stream;++static bool inproc_slice_byte_stream_next(grpc_exec_ctx *exec_ctx,+                                          grpc_byte_stream *bs, size_t max,+                                          grpc_closure *on_complete) {+  return true;+}++static grpc_error *inproc_slice_byte_stream_pull(grpc_exec_ctx *exec_ctx,+                                                 grpc_byte_stream *bs,+                                                 grpc_slice *slice) {+  inproc_slice_byte_stream *stream = (inproc_slice_byte_stream *)bs;+  *slice = grpc_slice_ref_internal(stream->slice);+  return GRPC_ERROR_NONE;+}++static void inproc_slice_byte_stream_destroy(grpc_exec_ctx *exec_ctx,+                                             grpc_byte_stream *bs) {+  inproc_slice_byte_stream *stream = (inproc_slice_byte_stream *)bs;+  grpc_slice_unref_internal(exec_ctx, stream->slice);+}++void inproc_slice_byte_stream_init(inproc_slice_byte_stream *s,+                                   grpc_slice slice) {+  s->base.length = (uint32_t)GRPC_SLICE_LENGTH(slice);+  s->base.flags = 0;+  s->base.next = inproc_slice_byte_stream_next;+  s->base.pull = inproc_slice_byte_stream_pull;+  s->base.destroy = inproc_slice_byte_stream_destroy;+  grpc_slice_ref_internal(slice);+  s->slice = slice;+}++static void ref_transport(inproc_transport *t) {+  gpr_log(GPR_DEBUG, ""ref_transport %p"", t);+  gpr_ref(&t->refs);+}++static void really_destroy_transport(inproc_transport *t) {+  gpr_log(GPR_DEBUG, ""really_destroy_transport %p"", t);+  grpc_exec_ctx exec_ctx = GRPC_EXEC_CTX_INIT;+  grpc_connectivity_state_destroy(&exec_ctx, &t->connectivity);+  if (gpr_unref(&t->mu->refs)) {+    gpr_free(t->mu);+  }+  gpr_free(t);+  grpc_exec_ctx_finish(&exec_ctx);+}++static void unref_transport(inproc_transport *t) {+  gpr_log(GPR_DEBUG, ""unref_transport %p"", t);+  if (gpr_unref(&t->refs)) {+    really_destroy_transport(t);+  }+}++static void ref_stream(inproc_stream *s) {+  gpr_log(GPR_DEBUG, ""ref_stream %p"", s);+  gpr_ref(&s->refs);+}++static void really_destroy_stream(grpc_exec_ctx *exec_ctx, inproc_stream *s) {+  gpr_log(GPR_DEBUG, ""really_destroy_stream %p"", s);+  grpc_slice_unref_internal(exec_ctx, s->to_read_initial_md);+  grpc_slice_buffer_destroy_internal(exec_ctx, &s->to_read_message);+  grpc_slice_unref_internal(exec_ctx, s->to_read_trailing_md);+  grpc_slice_unref_internal(exec_ctx, s->write_buffer_initial_md);+  grpc_slice_buffer_destroy_internal(exec_ctx, &s->write_buffer_message);+  grpc_slice_unref_internal(exec_ctx, s->write_buffer_trailing_md);+  GRPC_ERROR_UNREF(s->write_buffer_cancel_error);+  gpr_unref(&s->t->refs);+  if (s->closure_at_destroy) {+    grpc_closure_sched(exec_ctx, s->closure_at_destroy, GRPC_ERROR_NONE);+  }++  // Free up the linked metadata elements contents+  for (size_t i = 0; i < s->num_linked_mds; i++) {+    grpc_linked_mdelem *elem = s->linked_md_array[i];+    // The keys and values have already been taken??+    gpr_free(elem);+  }+  gpr_free(s->linked_md_array);+}++static void unref_stream(grpc_exec_ctx *exec_ctx, inproc_stream *s) {+  gpr_log(GPR_DEBUG, ""unref_stream %p"", s);+  if (gpr_unref(&s->refs)) {+    really_destroy_stream(exec_ctx, s);+  }+}++static void read_state_machine(grpc_exec_ctx *exec_ctx, void *arg,+                               grpc_error *error);++static int init_stream(grpc_exec_ctx *exec_ctx, grpc_transport *gt,+                       grpc_stream *gs, grpc_stream_refcount *refcount,+                       const void *server_data, gpr_arena *arena) {+  gpr_log(GPR_DEBUG, ""init_stream %p %p %p"", gt, gs, server_data);+  inproc_transport *t = (inproc_transport *)gt;+  inproc_stream *s = (inproc_stream *)gs;+  gpr_ref_init(&s->refs, 1);+  s->to_read_initial_md = grpc_slice_ref(g_empty_slice);+  s->to_read_trailing_md = grpc_slice_ref(g_empty_slice);+  s->write_buffer_initial_md = grpc_slice_ref(g_empty_slice);+  s->write_buffer_trailing_md = grpc_slice_ref(g_empty_slice);+  grpc_slice_buffer_init(&s->to_read_message);+  grpc_slice_buffer_init(&s->write_buffer_message);+  s->read_closure_needed = false;+  grpc_closure_init(&s->read_closure, read_state_machine, s,+                    grpc_schedule_on_exec_ctx);+  s->t = t;+  s->closure_at_destroy = NULL;+  s->num_linked_mds = 0;+  s->space_linked_mds = 0;+  s->linked_md_array = NULL; /* grow this when relevant */++  s->initial_md_sent = s->trailing_md_sent = s->initial_md_recvd =+      s->trailing_md_recvd = false;++  s->cancel_error = GRPC_ERROR_NONE;+  s->write_buffer_cancel_error = GRPC_ERROR_NONE;+  s->deadline = gpr_inf_future(GPR_CLOCK_MONOTONIC);+  s->write_buffer_deadline = gpr_inf_future(GPR_CLOCK_MONOTONIC);++  if (!server_data) {+    ref_transport(t);+    inproc_transport *st = t->other_side;+    ref_transport(st);+    s->other_side = NULL;  // will get filled in soon+    // Pass the client-side stream address to the server-side for a ref+    ref_stream(s);  // ref it now on behalf of server side to avoid destruction+    gpr_log(GPR_DEBUG, ""calling accept stream cb %p %p"", st->accept_stream_cb,+            st->accept_stream_data);+    (*st->accept_stream_cb)(exec_ctx, st->accept_stream_data, &st->base,+                            (void *)s);+  } else {+    // This is the server-side and is being called through accept_stream_cb+    inproc_stream *cs = (inproc_stream *)server_data;+    s->other_side = cs;+    // Ref the server-side stream on behalf of the client now+    ref_stream(s);++    // Now we are about to affect the other side, so lock the transport+    gpr_mu_lock(&s->t->mu->mu);+    cs->other_side = s;+    // Now transfer from the other side's write_buffer if any to the to_read+    // buffer+    if (GRPC_SLICE_START_PTR(cs->write_buffer_initial_md) != NULL) {+      grpc_slice_unref_internal(exec_ctx, s->to_read_initial_md);+      s->to_read_initial_md = grpc_slice_ref(cs->write_buffer_initial_md);+      grpc_slice_unref_internal(exec_ctx, cs->write_buffer_initial_md);+      s->deadline = gpr_time_min(s->deadline, cs->write_buffer_deadline);+    }+    if (cs->write_buffer_message.length > 0) {+      grpc_slice_buffer_swap(&cs->write_buffer_message, &s->to_read_message);+      GPR_ASSERT(cs->write_buffer_message.count == 0);+    }+    if (GRPC_SLICE_START_PTR(cs->write_buffer_trailing_md) != NULL) {+      grpc_slice_unref_internal(exec_ctx, s->to_read_trailing_md);+      s->to_read_trailing_md = grpc_slice_ref(cs->write_buffer_trailing_md);+      grpc_slice_unref_internal(exec_ctx, cs->write_buffer_trailing_md);+    }+    if (cs->write_buffer_cancel_error != GRPC_ERROR_NONE) {+      s->cancel_error = GRPC_ERROR_REF(cs->write_buffer_cancel_error);+    }++    gpr_mu_unlock(&s->t->mu->mu);+  }+  return 0;  // return value is not important+}++static grpc_slice fill_in_metadata(const grpc_metadata_batch *metadata,+                                   uint32_t flags) {+  // Calculate the size needed to store the entire metadata block, including","Any reason we're serializing at all here?Why not just populate a metadata batch...```cstatic void send_metadata(const grpc_metadata_batch *src, grpc_metadata_batch *dst) {  for (grpc_linked_mdelem *elem = src->list.head; elem != NULL;        elem = elem->next) {     grpc_metadata_batch_add_tail(..., elem->md);   }}```",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/11155,117611215,2017-05-20T15:02:49Z,src/csharp/Grpc.IntegrationTesting/Histogram.cs,"@@ -84,15 +84,27 @@ public void AddObservation(double value)             }         } -","out of scope of this PR, but looks like `this.multiplier` here above is unused.",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/10925,117614784,2017-05-20T18:11:07Z,src/core/lib/security/transport/security_handshaker.c,"@@ -199,34 +210,81 @@ static grpc_error *check_peer_locked(grpc_exec_ctx *exec_ctx,   return GRPC_ERROR_NONE; } -static grpc_error *send_handshake_bytes_to_peer_locked(grpc_exec_ctx *exec_ctx,-                                                       security_handshaker *h) {-  // Get data to send.-  tsi_result result = TSI_OK;-  size_t offset = 0;-  do {-    size_t to_send_size = h->handshake_buffer_size - offset;-    result = tsi_handshaker_get_bytes_to_send_to_peer(-        h->handshaker, h->handshake_buffer + offset, &to_send_size);-    offset += to_send_size;-    if (result == TSI_INCOMPLETE_DATA) {-      h->handshake_buffer_size *= 2;-      h->handshake_buffer =-          gpr_realloc(h->handshake_buffer, h->handshake_buffer_size);-    }-  } while (result == TSI_INCOMPLETE_DATA);+static grpc_error *on_handshake_next_done_locked(+    grpc_exec_ctx *exec_ctx, security_handshaker *h, tsi_result result,+    const unsigned char *bytes_to_send, size_t bytes_to_send_size,+    tsi_handshaker_result *handshaker_result) {+  grpc_error *error = GRPC_ERROR_NONE;+  // Read more if we need to.+  if (result == TSI_INCOMPLETE_DATA) {+    GPR_ASSERT(bytes_to_send_size == 0);+    grpc_endpoint_read(exec_ctx, h->args->endpoint, h->args->read_buffer,+                       &h->on_handshake_data_received_from_peer);+    return error;+  }   if (result != TSI_OK) {     return grpc_set_tsi_error_result(         GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Handshake failed""), result);   }-  // Send data.-  grpc_slice to_send =-      grpc_slice_from_copied_buffer((const char *)h->handshake_buffer, offset);++  // Send data to peer.+  grpc_slice to_send = grpc_slice_from_copied_buffer(","In fact, if this block executes only if bytes_to_send_size > 0, the code will break.Take start server handshake as example, it may have nothing to send to peer, but need to execute callback on_handshake_data_sent_to_peer, where there is grpc_endpoint_read (i.e., read from peer).Alternative we can check if bytes_to_send_size == 0, if so, directly runs callback. It is probably easier to skip the if check.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/11155,117722402,2017-05-22T11:29:31Z,src/csharp/Grpc.IntegrationTesting/Histogram.cs,"@@ -84,15 +84,27 @@ public void AddObservation(double value)             }         } -","We should do some cleanup in the code at some point (fix warning, formatting, remove unused ""using"" statements etc.). Hopefully I'll get to get in near future.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/10925,117778102,2017-05-22T15:40:36Z,src/core/lib/security/transport/security_handshaker.c,"@@ -150,25 +150,31 @@ static void on_peer_checked(grpc_exec_ctx *exec_ctx, void *arg,     security_handshake_failed_locked(exec_ctx, h, GRPC_ERROR_REF(error));     goto done;   }-  // Get frame protector.+  // Create frame protector.   tsi_frame_protector *protector;-  tsi_result result =-      tsi_handshaker_create_frame_protector(h->handshaker, NULL, &protector);+  tsi_result result = tsi_handshaker_result_create_frame_protector(+      h->handshaker_result, NULL, &protector);   if (result != TSI_OK) {     error = grpc_set_tsi_error_result(         GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Frame protector creation failed""),         result);     security_handshake_failed_locked(exec_ctx, h, error);     goto done;   }-  // Success.+  // Get unused bytes.+  unsigned char *unused_bytes = NULL;+  size_t unused_bytes_size = 0;+  result = tsi_handshaker_result_get_unused_bytes(+      h->handshaker_result, &unused_bytes, &unused_bytes_size);+  grpc_slice leftover_slice =+      grpc_slice_from_copied_buffer((char *)unused_bytes, unused_bytes_size);   // Create secure endpoint.   h->args->endpoint = grpc_secure_endpoint_create(-      protector, h->args->endpoint, h->left_overs.slices, h->left_overs.count);-  h->left_overs.count = 0;-  h->left_overs.length = 0;-  // Clear out the read buffer before it gets passed to the transport,-  // since any excess bytes were already copied to h->left_overs.+      protector, h->args->endpoint, &leftover_slice, 1);","If unused_bytes_size is 0, shouldn't we pass NULL and 0 for the last two parameters?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11267,117796788,2017-05-22T17:05:04Z,src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.c,"@@ -165,20 +165,20 @@ static size_t get_next_ready_subchannel_index_locked(   if (GRPC_TRACER_ON(grpc_lb_round_robin_trace)) {     gpr_log(GPR_INFO,             ""[RR: %p] getting next ready subchannel, ""-            ""last_ready_subchannel_index=%zu"",-            p, p->last_ready_subchannel_index);+            ""last_ready_subchannel_index=%d"",+            p, (int)p->last_ready_subchannel_index);","I think `int` is too small on some platforms.  If you need to cast it, then I suggest casting to an `unsigned long long` and using `%llu`.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/11267,117815426,2017-05-22T18:34:00Z,src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.c,"@@ -165,20 +165,20 @@ static size_t get_next_ready_subchannel_index_locked(   if (GRPC_TRACER_ON(grpc_lb_round_robin_trace)) {     gpr_log(GPR_INFO,             ""[RR: %p] getting next ready subchannel, ""-            ""last_ready_subchannel_index=%zu"",-            p, p->last_ready_subchannel_index);+            ""last_ready_subchannel_index=%d"",+            p, (int)p->last_ready_subchannel_index);","ahh, it looks like `%llu` isn't supported either. (it failed to compile, found some confirmation in https://stackoverflow.com/questions/13590735/printf-long-long-int-in-c-with-gcc).The `%lu` format specified appears to be ok though...",
775012,kskalski,https://api.github.com/repos/grpc/grpc/pulls/9717,117837242,2017-05-22T20:25:34Z,templates/CMakeLists.txt.template,"@@ -196,18 +196,24 @@         message(WARNING ""gRPC_PROTOBUF_PROVIDER is \""module\"" but PROTOBUF_ROOT_DIR is wrong"")     endif()   elseif(""<%text>${gRPC_PROTOBUF_PROVIDER}</%text>"" STREQUAL ""package"")-    find_package(protobuf CONFIG)-    if(protobuf_FOUND)+    find_package(Protobuf)","hm, looks like I got warnings when doing that:CMake Warning at CMakeLists.txt:187 (find_package):  By not providing ""FindPROTOBUF.cmake"" in CMAKE_MODULE_PATH this project has  asked CMake to find a package configuration file provided by ""PROTOBUF"",  but CMake did not find one.  Could not find a package configuration file provided by ""PROTOBUF"" with any  of the following names:    PROTOBUFConfig.cmake    protobuf-config.cmakeI think the proper name of the package is Protobuf, this is also what Konstantin mentioned in his comments",
10503072,a-veitch,https://api.github.com/repos/grpc/grpc/pulls/10920,118035707,2017-05-23T16:07:21Z,src/core/ext/census/intrusive_hash_map.h,"@@ -0,0 +1,169 @@+/*+ * Copyright 2017 Google Inc.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *    http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ */++#ifndef GRPC_CORE_EXT_CENSUS_INTRUSIVE_HASH_MAP_H+#define GRPC_CORE_EXT_CENSUS_INTRUSIVE_HASH_MAP_H++#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/useful.h>+#include <stdbool.h>++/* intrusive_hash_map is a fast chained hash table. It is almost always faster+ * than STL hash_map, since this hash map avoids malloc and free during insert+ * and erase. This hash map is faster than a dense hash map when the application+ * calls insert and erase more often than find. When the workload is dominated+ * by find() a dense hash map may be faster.+ *+ * intrusive_hash_map uses an intrusive header placed within a user defined+ * struct. IHM_key MUST be set to a valid value before insertion into the hash+ * map or undefined behavior may occur.  IHM_hash_link needs to be set to NULL+ * initially.+ *+ * EXAMPLE USAGE:+ *+ *  typedef struct string_item {+ *    INTRUSIVE_HASH_MAP_HEADER;+ *    // User data.+ *    char *str_buf;+ *    uint16_t len;+ *  } string_item;+ *+ *  static string_item *make_string_item(uint64_t key, const char *buf,+ *                                       uint16_t len) {+ *    string_item *item = (string_item *)gpr_malloc(sizeof(string_item));+ *    item->IHM_key = key;+ *    item->IHM_hash_link = NULL;+ *    item->len = len;+ *    item->str_buf = (char *)malloc(len);+ *    memcpy(item->str_buf, buf, len);+ *    return item;+ *  }+ *+ *  string_item *new_item1 = make_string_item(10, ""test1"", 5);+ *  bool ok = intrusive_hash_map_insert(&hash_map, (hm_item *)new_item1);+ *+ *  string_item *item1 =+ *    (string_item *)intrusive_hash_map_find(&hash_map, 10);+ */++/* Hash map item. Stores key and a pointer to the actual object. A user defined+ * version of this can be passed in as long as the first 2 entries (key and+ * hash_link) are the same. Pointer to struct will need to be cast as+ * (hm_item *) when passed to hash map. This allows it to be intrusive. */+typedef struct hm_item {+  uint64_t key;+  struct hm_item *hash_link;+  /* Optional user defined data after this. */+} hm_item;++/* Macro provided for ease of use.  This must be first in the user defined+ * struct. */+#define INTRUSIVE_HASH_MAP_HEADER \+  uint64_t IHM_key;               \+  struct hm_item *IHM_hash_link++/* The chunked vector is a data structure that allocates buckets for use in the+ * hash map. ChunkedVector is logically equivalent to T*[N] (cast void* as+ * T*). It's internally implemented as an array of 1MB arrays to avoid+ * allocating large consecutive memory chunks. This is an internal data","Could this (and other internal data structures) be moved into the implementation? Or put in a separate header to ""hide"" them?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/10925,118037585,2017-05-23T16:15:29Z,src/core/lib/security/transport/security_handshaker.c,"@@ -223,17 +228,23 @@ static grpc_error *on_handshake_next_done_locked(         GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Handshake failed""), result);   }   // Send data to peer.-  grpc_slice to_send = grpc_slice_from_copied_buffer(-      (const char *)bytes_to_send, bytes_to_send_size);-  grpc_slice_buffer_reset_and_unref_internal(exec_ctx, &h->outgoing);-  grpc_slice_buffer_add(&h->outgoing, to_send);-  grpc_endpoint_write(exec_ctx, h->args->endpoint, &h->outgoing,-                      &h->on_handshake_data_sent_to_peer);-  // If handshake has completed, check peer and so on.+  if (bytes_to_send_size > 0) {+    grpc_slice to_send = grpc_slice_from_copied_buffer(+        (const char *)bytes_to_send, bytes_to_send_size);+    grpc_slice_buffer_reset_and_unref_internal(exec_ctx, &h->outgoing);+    grpc_slice_buffer_add(&h->outgoing, to_send);+    grpc_endpoint_write(exec_ctx, h->args->endpoint, &h->outgoing,+                        &h->on_handshake_data_sent_to_peer);+  }+  // If handshake has completed, check peer and so on. Otherwise, need to read+  // more data from the peer.   if (handshaker_result != NULL) {     GPR_ASSERT(h->handshaker_result == NULL);     h->handshaker_result = handshaker_result;     error = check_peer_locked(exec_ctx, h);+  } else {+    grpc_endpoint_read(exec_ctx, h->args->endpoint, h->args->read_buffer,","Thinking about this further, I'm not sure it's a good idea to have both a read and a write outstanding at the same time.  The problem is that this requires more complex error-handling code.  For example, let's say that we're doing a write to the peer and expecting to read a response back.  If the write fails, then we still have a pending callback from the read, and we need to avoid destroying the handshaker until both callbacks have been invoked.  We could probably make that work with some refcounting changes, but it would be fairly complex, and I think we can avoid it by making this simpler.I think we need to make two changes:1. Put an `else` at the start of line 241 above, so that the three possible actions here (write, read, and handshake done) are mutually exclusive -- we can only choose one of them in any given call to this function.2. Restore the write code in `on_handshake_data_sent_to_peer()`, and make it unconditional (i.e., it should not depend on whether `h->handshaker_result` is set).",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/10925,118052177,2017-05-23T17:17:55Z,src/core/lib/security/transport/security_handshaker.c,"@@ -223,17 +228,23 @@ static grpc_error *on_handshake_next_done_locked(         GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Handshake failed""), result);   }   // Send data to peer.-  grpc_slice to_send = grpc_slice_from_copied_buffer(-      (const char *)bytes_to_send, bytes_to_send_size);-  grpc_slice_buffer_reset_and_unref_internal(exec_ctx, &h->outgoing);-  grpc_slice_buffer_add(&h->outgoing, to_send);-  grpc_endpoint_write(exec_ctx, h->args->endpoint, &h->outgoing,-                      &h->on_handshake_data_sent_to_peer);-  // If handshake has completed, check peer and so on.+  if (bytes_to_send_size > 0) {+    grpc_slice to_send = grpc_slice_from_copied_buffer(+        (const char *)bytes_to_send, bytes_to_send_size);+    grpc_slice_buffer_reset_and_unref_internal(exec_ctx, &h->outgoing);+    grpc_slice_buffer_add(&h->outgoing, to_send);+    grpc_endpoint_write(exec_ctx, h->args->endpoint, &h->outgoing,+                        &h->on_handshake_data_sent_to_peer);+  }+  // If handshake has completed, check peer and so on. Otherwise, need to read+  // more data from the peer.   if (handshaker_result != NULL) {     GPR_ASSERT(h->handshaker_result == NULL);     h->handshaker_result = handshaker_result;     error = check_peer_locked(exec_ctx, h);+  } else {+    grpc_endpoint_read(exec_ctx, h->args->endpoint, h->args->read_buffer,","I agree doing both read and write at the same time is not good (although code is cleaner).What you propose is problematic. There is a situation where handshake completes (handshake_result is not NULL) and there are some final bytes to send to peer . If we make line 241 mutually exclusive, we send the bytes (without setting the h->handshaker_result). In `on_handshake_data_send_to_peer()`, we need to wait for grpc read, but we will never get any data back. Also, if remove condition in `on_handshake_data_send_to_peer()` and always do read. The read could be blocked, because handshake finished and there is nothing to read.Basically, there are two corner cases security handshaker need to handle1. There is nothing to send to peer, but need to read from peer2. There are some bytes (i.e., finishing bytes) to send to peer, but no need to read from peer.I am thinking about two possibilities here:A. rollback last commit of this pull request, it should work fine. Doing a grpc_endpoint_write on an empty buffer is OK, as security handshaker already did it today.B. In `on_handshake_data_sent_to_peer()`, do a conditional read. In `on_handshake_next_done_locked`, have ```if (bytes_to_send_size > 0) {  // there are something to send  ... do write ...} else if (handshaker_result == NULL) {  // nothing to send, but need to read  ... do read ...}// handshake completes is regardless of write. There could be final write and handshake completesif (handshaker_result != NULL) {  check_peer_locked();} ```",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/10925,118055123,2017-05-23T17:29:57Z,src/core/lib/security/transport/security_handshaker.c,"@@ -223,17 +228,23 @@ static grpc_error *on_handshake_next_done_locked(         GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Handshake failed""), result);   }   // Send data to peer.-  grpc_slice to_send = grpc_slice_from_copied_buffer(-      (const char *)bytes_to_send, bytes_to_send_size);-  grpc_slice_buffer_reset_and_unref_internal(exec_ctx, &h->outgoing);-  grpc_slice_buffer_add(&h->outgoing, to_send);-  grpc_endpoint_write(exec_ctx, h->args->endpoint, &h->outgoing,-                      &h->on_handshake_data_sent_to_peer);-  // If handshake has completed, check peer and so on.+  if (bytes_to_send_size > 0) {+    grpc_slice to_send = grpc_slice_from_copied_buffer(+        (const char *)bytes_to_send, bytes_to_send_size);+    grpc_slice_buffer_reset_and_unref_internal(exec_ctx, &h->outgoing);+    grpc_slice_buffer_add(&h->outgoing, to_send);+    grpc_endpoint_write(exec_ctx, h->args->endpoint, &h->outgoing,+                        &h->on_handshake_data_sent_to_peer);+  }+  // If handshake has completed, check peer and so on. Otherwise, need to read+  // more data from the peer.   if (handshaker_result != NULL) {     GPR_ASSERT(h->handshaker_result == NULL);     h->handshaker_result = handshaker_result;     error = check_peer_locked(exec_ctx, h);+  } else {+    grpc_endpoint_read(exec_ctx, h->args->endpoint, h->args->read_buffer,","I was not aware of the edge case where the handshake is complete but we still have bytes to send to the peer.  Given that, I think that even without the read code-path, we still have the same problem with multiple pending callbacks, because both the check-peer and write callbacks will both be pending at the same time.I would strongly prefer to have only a single pending callback at any one time, because it greatly simplifies the error-handling logic.  If you can't find a way to do that, then we will need to discuss taking an additional ref to the handshaker and changing the error-handling logic to handle that additional ref somehow, and I would really prefer to avoid that complexity.@ctiller has confirmed for me that calling `grpc_endpoint_write()` with a 0-length buffer is very inefficient and not really intended to work.  So we should continue to avoid that if possible.",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/10925,118058747,2017-05-23T17:44:18Z,src/core/lib/security/transport/security_handshaker.c,"@@ -223,17 +228,23 @@ static grpc_error *on_handshake_next_done_locked(         GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Handshake failed""), result);   }   // Send data to peer.-  grpc_slice to_send = grpc_slice_from_copied_buffer(-      (const char *)bytes_to_send, bytes_to_send_size);-  grpc_slice_buffer_reset_and_unref_internal(exec_ctx, &h->outgoing);-  grpc_slice_buffer_add(&h->outgoing, to_send);-  grpc_endpoint_write(exec_ctx, h->args->endpoint, &h->outgoing,-                      &h->on_handshake_data_sent_to_peer);-  // If handshake has completed, check peer and so on.+  if (bytes_to_send_size > 0) {+    grpc_slice to_send = grpc_slice_from_copied_buffer(+        (const char *)bytes_to_send, bytes_to_send_size);+    grpc_slice_buffer_reset_and_unref_internal(exec_ctx, &h->outgoing);+    grpc_slice_buffer_add(&h->outgoing, to_send);+    grpc_endpoint_write(exec_ctx, h->args->endpoint, &h->outgoing,+                        &h->on_handshake_data_sent_to_peer);+  }+  // If handshake has completed, check peer and so on. Otherwise, need to read+  // more data from the peer.   if (handshaker_result != NULL) {     GPR_ASSERT(h->handshaker_result == NULL);     h->handshaker_result = handshaker_result;     error = check_peer_locked(exec_ctx, h);+  } else {+    grpc_endpoint_read(exec_ctx, h->args->endpoint, h->args->read_buffer,","Got it. We need to make callback once a time, and we can. Basically, in `on_handshake_next_done_locked`, we need to make write, read, check_peer mutually exclusive. In addition, in `on_handshake_data_send_to_peer`, do either read or check_peer mutual exclusively. I will revise shortly.",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/10925,118082627,2017-05-23T19:20:56Z,src/core/lib/security/transport/security_handshaker.c,"@@ -227,24 +227,26 @@ static grpc_error *on_handshake_next_done_locked(     return grpc_set_tsi_error_result(         GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Handshake failed""), result);   }-  // Send data to peer.+  // Update handshaker result.+  if (handshaker_result != NULL) {","The reason is that `if (bytes_to_send_size > 0)` and handshake completes, the check peer is done inside `on_handshake_data_sent_to_peer`, in this case, we need to set handshaker_result to the struct of security_handshaker, so that check peer can be executed correctly.",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/11269,118102407,2017-05-23T20:47:12Z,test/cpp/microbenchmarks/bm_fullstack_trickle.cc,"@@ -320,8 +320,8 @@ static void BM_PumpStreamServerToClient_Trickle(benchmark::State& state) { }  static void StreamingTrickleArgs(benchmark::internal::Benchmark* b) {-  for (int i = 1; i <= 128 * 1024 * 1024; i *= 8) {-    for (int j = 64; j <= 128 * 1024 * 1024; j *= 8) {+  for (int i = 1; i <= 128 * 1024 * 1024; i *= 16) {","Not needed right now, since we're not really graphing these... but this will cause a data discontinuity. It may be possible to just explicitly call out the values that we're using.",
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/10919,118732703,2017-05-26T15:50:25Z,doc/threading_model.md,"@@ -0,0 +1,31 @@+﻿# gRPC Threading Model++## Introduction+This document serves as a basic intro for the gRPC threading model. gRPC generates service code in two fashions - synchronous and asynchronous API. These two closely correlate to the threading model in play. ++## Synchronous API Threading model+This is the easiest model to start with and could be a satisfactory model for a large number of services. As such, the implementation is efficient (and is not a ‘toy’ implementation). In this model, gRPC takes care of the threading completely and the application code need to worry only about handling of the actual rpc call.+* When the server starts up, a thread pool is created to handle incoming rpc requests. The default implementation of this thread pool is called DynamicThreadPool. It creates threads equal to number of processors in the system and all of them are in waiting state.+* DynamicThreadPool has in­built scaling mechanism to create additional threads on demand. For integrators interested in having a little more control on the behavior of the thread pool, they can define GRPC_CUSTOM_DEFAULT_THREAD_POOL and provide the implementation of the thread pool interface (which is literally just 1 function that adds work to the pool).","`DynamicThreadPool` is no longer used for handling requests. Instead we use the `ThreadManager`. A `ThreadManager` internally maintains a thread pool and can be configured with a min and max number of polling threads.  This ensures that there are threads that are always waiting for incoming requests and also increases parallelism.By default a sync server automatically creates as many server completion queues  (i.e completion queues used for notify about incoming RPC requests) as the number of cores on the machine it runs and one `ThreadManager` per completion queue.#### Here are some pointers to the code:-  [ThreadManager](https://github.com/grpc/grpc/tree/0a94f3c8ab55dfd12c14058d57f33121c8d6c411/src/cpp/thread_manager)  : Do read `thread_manager.h` interface. It has good comments. Note that `PollForWork` and `DoWork` are virtual functions. The implementation is in the [`SyncRequestThreadManager`](https://github.com/grpc/grpc/blob/0a94f3c8ab55dfd12c14058d57f33121c8d6c411/src/cpp/server/server_cc.cc#L260) class in `server_cc.cc` .- Some relevant code in `ServerBuilder` (where defaults are set):   [1](https://github.com/grpc/grpc/blob/34011f19ed40503fa658234742b3a4b85476af1a/include/grpc%2B%2B/server_builder.h#L212),  [2](https://github.com/grpc/grpc/blob/0a94f3c8ab55dfd12c14058d57f33121c8d6c411/src/cpp/server/server_builder.cc#L59),  [3](https://github.com/grpc/grpc/blob/0a94f3c8ab55dfd12c14058d57f33121c8d6c411/src/cpp/server/server_builder.cc#L273) and  [4](https://github.com/grpc/grpc/blob/0a94f3c8ab55dfd12c14058d57f33121c8d6c411/src/cpp/server/server_builder.cc#L273)- Relevant code in `Server` : [1](https://github.com/grpc/grpc/blob/0a94f3c8ab55dfd12c14058d57f33121c8d6c411/src/cpp/server/server_cc.cc#L368), [2](https://github.com/grpc/grpc/blob/0a94f3c8ab55dfd12c14058d57f33121c8d6c411/src/cpp/server/server_cc.cc#L389) and [3](https://github.com/grpc/grpc/blob/0a94f3c8ab55dfd12c14058d57f33121c8d6c411/src/cpp/server/server_cc.cc#L260)Hope this helps.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/11272,118778775,2017-05-26T19:57:06Z,src/csharp/Grpc.Core/Internal/CallSafeHandle.cs,"@@ -218,5 +218,16 @@ private static uint GetFlags(bool buffered)         {             return buffered ? 0 : GRPC_WRITE_BUFFER_HINT;         }++        /// <summary>+        /// Only for testing.+        /// </summary>+        public static CallSafeHandle CreateFake(IntPtr ptr, CompletionQueueSafeHandle cq)+        {+            var call = new CallSafeHandle();+            call.SetHandle(ptr);",is the `0xdead` handle used here? is the `SetHandle` needed?,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/11272,118811490,2017-05-27T02:37:05Z,src/csharp/Grpc.Microbenchmarks/SendMessageBenchmark.cs,"@@ -0,0 +1,106 @@+﻿#region Copyright notice and license++// Copyright 2015, Google Inc.+// All rights reserved.+//+// Redistribution and use in source and binary forms, with or without+// modification, are permitted provided that the following conditions are+// met:+//+//     * Redistributions of source code must retain the above copyright+// notice, this list of conditions and the following disclaimer.+//     * Redistributions in binary form must reproduce the above+// copyright notice, this list of conditions and the following disclaimer+// in the documentation and/or other materials provided with the+// distribution.+//     * Neither the name of Google Inc. nor the names of its+// contributors may be used to endorse or promote products derived from+// this software without specific prior written permission.+//+// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.++#endregion++using System;+using System.Threading;+using Grpc.Core;+using Grpc.Core.Internal;+using System.Collections.Generic;+using System.Diagnostics;++namespace Grpc.Microbenchmarks+{+    public class SendMessageBenchmark+    {+        static readonly NativeMethods Native = NativeMethods.Get();++        GrpcEnvironment environment;++        public void Init()+        {+            Native.grpcsharp_test_override_method(""grpcsharp_call_start_batch"", ""nop"");+            environment = GrpcEnvironment.AddRef();+        }++        public void Cleanup()+        {+            GrpcEnvironment.ReleaseAsync().Wait();+            // TODO(jtattermusch): track GC stats+        }++        public void Run(int threadCount, int iterations, int payloadSize)+        {+            Console.WriteLine(string.Format(""SendMessageBenchmark: threads={0}, iterations={1}, payloadSize={2}"", threadCount, iterations, payloadSize));+            var threadedBenchmark = new ThreadedBenchmark(threadCount, () => ThreadBody(iterations, payloadSize));+            threadedBenchmark.Run();+        }++        private void ThreadBody(int iterations, int payloadSize)+        {+            // TODO(jtattermusch): parametrize by number of pending completions.+            // TODO(jtattermusch): parametrize by cached/non-cached BatchContextSafeHandle++            var completionRegistry = new CompletionRegistry(environment);+            var cq = CompletionQueueSafeHandle.CreateAsync(completionRegistry);+            var call = CreateFakeCall(cq);++            var sendCompletionHandler = new SendCompletionHandler((success) => { });+            var payload = new byte[payloadSize];+            var writeFlags = default(WriteFlags);++            var stopwatch = Stopwatch.StartNew();+            for (int i = 0; i < iterations; i++)+            {+                call.StartSendMessage(sendCompletionHandler, payload, writeFlags, false);","Yes, that's right. I have code that will add thread-local pooling of batchcontextsafehandle objects and I expect the benchmarks will show big improvements with it.",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/11317,119499525,2017-05-31T23:31:50Z,src/core/lib/surface/completion_queue.c,"@@ -559,44 +559,45 @@ static void cq_end_op_for_next(grpc_exec_ctx *exec_ctx,        error != GRPC_ERROR_NONE)) {     const char *errmsg = grpc_error_string(error);     GRPC_API_TRACE(-        ""cq_end_op_for_next(exec_ctx=%p, cc=%p, tag=%p, error=%s, ""+        ""cq_end_op_for_next(exec_ctx=%p, cq=%p, tag=%p, error=%s, ""         ""done=%p, done_arg=%p, storage=%p)"",-        7, (exec_ctx, cc, tag, errmsg, done, done_arg, storage));+        7, (exec_ctx, cq, tag, errmsg, done, done_arg, storage));     if (GRPC_TRACER_ON(grpc_trace_operation_failures) &&         error != GRPC_ERROR_NONE) {       gpr_log(GPR_ERROR, ""Operation failed: tag=%p, error=%s"", tag, errmsg);     }   } -  cq_data *cqd = &cc->data;+  cq_data *cqd = &cq->data;   int is_success = (error == GRPC_ERROR_NONE);    storage->tag = tag;   storage->done = done;   storage->done_arg = done_arg;   storage->next = (uintptr_t)(is_success); -  cq_check_tag(cc, tag, true); /* Used in debug builds only */+  cq_check_tag(cq, tag, true); /* Used in debug builds only */    /* Add the completion to the queue */-  cq_event_queue_push(&cqd->queue, storage);+  bool is_first = cq_event_queue_push(&cqd->queue, storage);   gpr_atm_no_barrier_fetch_add(&cqd->things_queued_ever, 1);+  bool shutdown = gpr_unref(&cqd->pending_events);","Ok... so a better fix is to probably merge (shutdown, pending_events, shutdown_called) into a single atomic that we can update independently.",
10605667,chwarr,https://api.github.com/repos/grpc/grpc/pulls/11353,119516226,2017-06-01T02:20:48Z,src/csharp/Grpc.Core/Server.cs,"@@ -316,6 +319,20 @@ private void AllowOneRpc(CompletionQueueSafeHandle cq)             }         } +        /// <summary>+        /// Checks that all ports have been bound successfully.+        /// </summary>+        private void CheckPortsBoundSuccessfully()+        {+            lock (myLock)+            {+                if (!ports.All((port) => port.BoundPort != 0))+                {+                    throw new IOException(""Failed to bind some of ports exposed by the server."");","If the unbound ports (or at least one of them) were included in the exception message, that would make it more actionable. Though, I'm not sure whether having custom messages in exceptions is OK in this code base. (Some people like to keep all their exception messages static to help with localization, for example.)Something like this?```var unboundPort = ports.FirstOrDefault(port => port.BoundPort == 0);if (unboundPort != null){    // may need to pass a culture: don't know this code base's style    throw new IOException(        string.Format(""Failed to bind port \""{0}:{1}\"""", unboundPort.Host, unboundPort.Port));}```",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11369,119712716,2017-06-01T19:52:49Z,tools/distrib/pylint_code.sh,"@@ -33,7 +33,7 @@ set -ex # change to root directory cd $(dirname $0)/../.. -DIRS=src/python/grpcio/grpc+DIRS=""src/python/grpcio/grpc src/python/grpcio_reflection/grpc_reflection src/python/grpcio_health_checking/grpc_health""","Is this the ""right"" way to do a sequence of strings in `sh`? Since it's now a list of things that will grow at least a little bit more, can it be changed to be a one-element-per-line style ""constant sequence of strings""?However this is done it should pass `shellcheck`. Does what's currently drafted pass `shellcheck`?",
2230985,connor4312,https://api.github.com/repos/grpc/grpc/pulls/11020,119988445,2017-06-03T15:18:14Z,src/node/index.d.ts,"@@ -0,0 +1,526 @@+declare module 'grpc' {+  import { ReflectionObject, Service } from 'protobufjs'++  /**+   * Default options for loading proto files into gRPC+   */+  export interface ILoadOptions {+    /**+     * Load this file with field names in camel case instead of their original case. Defaults to `false`.+     */+    convertFieldsToCamelCase: boolean;++    /**+     * Deserialize bytes values as base64 strings instead of buffers. Defaults to `false`.+     */+    binaryAsBase64: boolean;++    /**+     * Deserialize long values as strings instead of objects. Defaults to `true`.+     */+    longsAsStrings: boolean;++    /**+     * Deserialize enum values as strings instead of numbers. Defaults to `true`.+     */+    enumsAsStrings: boolean;+  }++  export interface ILoadProtobufOptions extends ILoadOptions {+    /**+     * Indicate that an object from the corresponding version of+     * ProtoBuf.js is provided in the value argument. If the option is 'detect',+     * gRPC will guess what the version is based on the structure of the value.+     * Defaults to 'detect'.+     */+    protobufjsVersion: 5 | 6 | 'detect';+  }++  /**+   * Load a gRPC object from a `.proto` file.+   * @param filename The file to load+   * @param format The file format to expect. Defaults to 'proto'.+   * @param options Options to apply to the loaded file.+   * @return The resulting gRPC object.+   */+  export function load(filename: string, format?: 'proto' | 'json', options?: ILoadOptions): IProtobufDefinition;++  /**+   * Map from `.proto` file.+   * - Namespaces become maps from the names of their direct members to those member objects+   * - Service definitions become client constructors for clients for that service. They also have a service member that can be used for constructing servers.+   * - Message definitions become Message constructors like those that ProtoBuf.js would create+   * - Enum definitions become Enum objects like those that ProtoBuf.js would create+   * - Anything else becomes the relevant reflection object that ProtoBuf.js would create+   */+  export interface IProtobufDefinition {+    [key: string]: any;",You can probably tighten this a bit. [This](https://github.com/mixer/etcd3/blob/password-auth/src/types/grpc.d.ts#L121) is what worked for me,
2230985,connor4312,https://api.github.com/repos/grpc/grpc/pulls/11020,119988476,2017-06-03T15:19:52Z,src/node/index.d.ts,"@@ -0,0 +1,526 @@+declare module 'grpc' {+  import { ReflectionObject, Service } from 'protobufjs'++  /**+   * Default options for loading proto files into gRPC+   */+  export interface ILoadOptions {+    /**+     * Load this file with field names in camel case instead of their original case. Defaults to `false`.+     */+    convertFieldsToCamelCase: boolean;++    /**+     * Deserialize bytes values as base64 strings instead of buffers. Defaults to `false`.+     */+    binaryAsBase64: boolean;++    /**+     * Deserialize long values as strings instead of objects. Defaults to `true`.+     */+    longsAsStrings: boolean;++    /**+     * Deserialize enum values as strings instead of numbers. Defaults to `true`.+     */+    enumsAsStrings: boolean;+  }++  export interface ILoadProtobufOptions extends ILoadOptions {+    /**+     * Indicate that an object from the corresponding version of+     * ProtoBuf.js is provided in the value argument. If the option is 'detect',+     * gRPC will guess what the version is based on the structure of the value.+     * Defaults to 'detect'.+     */+    protobufjsVersion: 5 | 6 | 'detect';+  }++  /**+   * Load a gRPC object from a `.proto` file.+   * @param filename The file to load+   * @param format The file format to expect. Defaults to 'proto'.+   * @param options Options to apply to the loaded file.+   * @return The resulting gRPC object.+   */+  export function load(filename: string, format?: 'proto' | 'json', options?: ILoadOptions): IProtobufDefinition;++  /**+   * Map from `.proto` file.+   * - Namespaces become maps from the names of their direct members to those member objects+   * - Service definitions become client constructors for clients for that service. They also have a service member that can be used for constructing servers.+   * - Message definitions become Message constructors like those that ProtoBuf.js would create+   * - Enum definitions become Enum objects like those that ProtoBuf.js would create+   * - Anything else becomes the relevant reflection object that ProtoBuf.js would create+   */+  export interface IProtobufDefinition {+    [key: string]: any;+  }++  /**+   * Load a ProtoBuf.js object as a gRPC object.+   * - protobufjsVersion: Available values are 5, 6, and 'detect'. 5 and 6+   *   respectively indicate that an object from the corresponding version of+   *   ProtoBuf.js is provided in the value argument. If the option is 'detect',+   *   gRPC will guess what the version is based on the structure of the value.+   *   Defaults to 'detect'.+   * @param {Object} value The ProtoBuf.js reflection object to load+   * @param {Object=} options Options to apply to the loaded file+   * @return {Object<string, *>} The resulting gRPC object+   */+  export function loadObject(replectionObject: ReflectionObject, options?: ILoadProtobufOptions): IProtobufDefinition;++  /**+   * Serer object that stores request handlers and delegates incoming requests to those handlers+   */+  export class Server {+    /**+     * Constructs a server object+     * @param options Options that should be passed to the internal server implementation+     */+    constructor(options?: IServerOptions);++    /**+     * Start the server and begin handling requests+     */+    start(): void;++    /**+     * Gracefully shuts down the server. The server will stop receiving new calls,+     * and any pending calls will complete. The callback will be called when all+     * pending calls have completed and the server is fully shut down. This method+     * is idempotent with itself and forceShutdown.+     * @param callback The shutdown complete callback+     */+    tryShutdown(callback: () => void): void;++    /**+     * Forcibly shuts down the server. The server will stop receiving new calls+     * and cancel all pending calls. When it returns, the server has shut down.+     * This method is idempotent with itself and tryShutdown, and it will trigger+     * any outstanding tryShutdown callbacks.+     */+    forceShutdown(): void;++    /**+     * Registers a handler to handle the named method. Fails if there already is+     * a handler for the given method. Returns true on success+     * @param name The name of the method that the provided function should handle/respond to.+     * @param handler Function that takes a stream of request values and returns a stream of response values+     * @param serialize Serialization function for responses+     * @param deserialize Deserialization function for requests+     * @param type The streaming type of method that this handles+     * @return True if the handler was set. False if a handler was already set for that name.+     */+    register(name: string, handler: () => void, serialize: (obj: any) => Buffer, deserialize: (buffer: Buffer) => any, type: string): boolean;++    /**+     * Add a service to the server, with a corresponding implementation. If you are+     * generating this from a proto file, you should instead use `addProtoService`.+     * @param service The service descriptor, as `getProtobufServiceAttrs` returns+     * @param implementation Map of method names to method implementation for the provided service.+     */+    addService(service: { [index: string]: any }, implementation: { [index: string]: () => void }): void;++    /**+     * Add a proto service to the server, with a corresponding implementation+     * @deprecated Use grpc.load and Server#addService instead+     * @param service The proto service descriptor+     * @param implementation Map of method names to method implementation for the provided service.+     */+    addProtoService(service: Service, implementation: any): void;++    /**+     * Binds the server to the given port, with SSL enabled if creds is given+     * @param port The port that the server should bind on, in the format ""address:port""+     * @param creds Server credential object to be used for SSL. Pass an insecure credentials object for an insecure port.+     */+    bind(port: string, creds: ServerCredentials): any;+  }++  export interface IServerOptions {++  }++  export interface IError {+    code: string;+    message: string;+  }++  /**+   * Credentials factories+   */+  export const credentials: {+    /**+     * Create an SSL Credentials object. If using a client-side certificate, both+     * the second and third arguments must be passed.+     * @param rootCerts The root certificate data+     * @param privateKey The client certificate private key, if applicable+     * @param certChain The client certificate cert chain, if applicable+     * @return The SSL Credentials object+     */+    createSsl(rootCerts: Buffer, privateKey?: Buffer, certChain?: Buffer): ChannelCredentials;++    /**+     * Create a gRPC credentials object from a metadata generation function. This+     * function gets the service URL and a callback as parameters. The error+     * passed to the callback can optionally have a 'code' value attached to it,+     * which corresponds to a status code that this library uses.+     * @param metadataGenerator The function that generates metadata+     * @return The credentials object+     */+    createFromMetadataGenerator(metadataGenerator: (s: string, callback: (error: Error, metadata: Metadata) => void) => void): CallCredentials;","The metadata generator function actually takes a `{ service_url: string }` as its first argument <sup>[ref](https://github.com/grpc/grpc/blob/master/src/node/src/credentials.js#L136)</sup>. Also, the callback should be typed as `error: Error | null, metadata?: Metadata` to avoid compilation errors when using strict null checks 😄 ",
22083734,matt-kwong,https://api.github.com/repos/grpc/grpc/pulls/11367,120724527,2017-06-07T19:36:55Z,tools/profiling/microbenchmarks/bm_diff/bm_diff.py,"@@ -0,0 +1,207 @@+#!/usr/bin/env python2.7+# Copyright 2017, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+"""""" Computes the diff between two bm runs and outputs significant results """"""++import bm_constants+import bm_speedup++import sys+import os++sys.path.append(os.path.join(os.path.dirname(sys.argv[0]), '..'))+import bm_json++import json+import tabulate+import argparse+import collections+import subprocess++verbose = False+++def _median(ary):",Do we need to check if `ary` is a non-empty list?,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/11356,121314954,2017-06-12T06:03:04Z,src/csharp/Grpc.Core/Internal/SimpleObjectPool.cs,"@@ -0,0 +1,103 @@+#region Copyright notice and license++// Copyright 2015, Google Inc.+// All rights reserved.+// +// Redistribution and use in source and binary forms, with or without+// modification, are permitted provided that the following conditions are+// met:+// +//     * Redistributions of source code must retain the above copyright+// notice, this list of conditions and the following disclaimer.+//     * Redistributions in binary form must reproduce the above+// copyright notice, this list of conditions and the following disclaimer+// in the documentation and/or other materials provided with the+// distribution.+//     * Neither the name of Google Inc. nor the names of its+// contributors may be used to endorse or promote products derived from+// this software without specific prior written permission.+// +// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+// ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+// A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+// OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+// SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+// LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+// DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+// THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.++#endregion++using System;+using System.Threading;+using System.Collections.Generic;+using Grpc.Core.Utils;++namespace Grpc.Core.Internal+{+    /// <summary>+    /// Simple queue-based pool of objects. Methods are NOT threadsafe!+    /// </summary>+    internal class SimpleObjectPool<T> where T : IDisposable+    {+        readonly Thread thread;+        readonly Func<T> itemFactory;+        readonly Queue<T> queue;+        readonly int capacity;+        bool disposed;++        public SimpleObjectPool(Thread thread, Func<T> itemFactory, int capacity)+        {+            this.thread = thread;+            this.itemFactory = itemFactory;+            this.queue = new Queue<T>(capacity);+            this.capacity = capacity;+        }++        public Thread Thread+        {+            get { return thread; }+        }++        public T Lease()+        {+            GrpcPreconditions.CheckState(!disposed);++            if (queue.Count > 0)","Maybe we wouldn't want to check it in, but I wonder if it would be interesting to track the success-rate of this in one way or another in the larger benchmarks too.",
676565,augustoroman,https://api.github.com/repos/grpc/grpc/pulls/10529,122056730,2017-06-14T20:33:02Z,examples/ruby/mutual_auth/client.rb,"@@ -0,0 +1,83 @@+#!/usr/bin/env ruby++# Copyright 2015, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.++# Sample app that connects to a Greeter service with mutual client/server+# authentication.+#+# Usage: $ path/to/client.rb++this_dir = File.expand_path(File.dirname(__FILE__))+lib_dir = File.join(File.dirname(this_dir), 'lib')+$LOAD_PATH.unshift(lib_dir) unless $LOAD_PATH.include?(lib_dir)++require 'grpc'+require 'optparse'++require 'helloworld_services_pb'++# Loads the certificates used to access the test server securely.+def load_test_certs+  this_dir = File.expand_path(File.dirname(__FILE__))+  cert_dir = File.join(this_dir, 'client_certs')+  files = ['trusted_server_roots.pem', 'client.key', 'client.crt']+  files.map { |f| File.open(File.join(cert_dir, f)).read }+end++def test_client_creds+  certs = load_test_certs+  GRPC::Core::ChannelCredentials.new(certs[0], certs[1], certs[2])","this is a great example, thanks.  I wish I had found this yesterday.  Can you be more explicit here?```root_ca_crt, client_key, client_crt = load_test_certsGRPC::Core::ChannelCredentials.new(root_ca_crt, client_key, client_crt)```The [ruby auth documentation](http://www.grpc.io/docs/guides/auth.html#ruby) doesn't document what the parameters can be and I couldn't find actual documentation on the ChannelCredentials constructor options.The [ruby tests for ChannelCredentials](https://github.com/grpc/grpc/blob/master/src/ruby/spec/channel_credentials_spec.rb#L23) actually provide the arguments in the _wrong_ order (notice the highlighted line is `ca-cert, client-cert, client-key` instead of `ca-cert, client-key, client-cert`). It wasn't until I found the [source code for ChannelCredentials](https://github.com/grpc/grpc/blob/master/src/ruby/ext/grpc/rb_channel_credentials.c#L127..L140) that I finally realized that I had the order wrong.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/10529,122083947,2017-06-14T22:51:43Z,examples/ruby/mutual_auth/client_certs/trusted_server_roots.pem,"@@ -0,0 +1,15 @@+-----BEGIN CERTIFICATE-----","Can we please use either this file or the `ca.pem` file. I don't want to duplicate this roots file, perhaps we can put this in the shared parent directory?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/10529,122087408,2017-06-14T23:16:32Z,examples/ruby/mutual_auth/server.rb,"@@ -0,0 +1,96 @@+#!/usr/bin/env ruby++# Copyright 2015, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.++# Sample gRPC server that implements the Greeter::Helloworld service and+# enforces mutual authentication.+#+# Usage: $ path/to/server.rb++this_dir = File.expand_path(File.dirname(__FILE__))+lib_dir = File.join(File.dirname(this_dir), 'lib')+$LOAD_PATH.unshift(lib_dir) unless $LOAD_PATH.include?(lib_dir)++require 'grpc'+require 'openssl'++require 'helloworld_services_pb'++# Additional peer certificate validation that checks for a specific CN in the+# subject name.+def check_peer_cert(call)+  valid_cert = false+  certificate = OpenSSL::X509::Certificate.new call.peer_cert+  certificate.subject().to_a().each do |name_entry|+    if (name_entry[0] == ""CN"") && (name_entry[1] == ""testclient"")+      valid_cert = true+    end+  end+  unless valid_cert+    fail GRPC::BadStatus.new(GRPC::Core::StatusCodes::UNAUTHENTICATED,+                             ""Client cert has invalid CN"")+  end+end+++# GreeterServer is simple server that implements the Helloworld Greeter server.+class GreeterServer < Helloworld::Greeter::Service+  # say_hello implements the SayHello rpc method.+  def say_hello(hello_req, call)+    check_peer_cert(call)+    Helloworld::HelloReply.new(message: ""Hello #{hello_req.name}"")+  end+end++# loads the certificates for the test server.+def load_test_certs+  this_dir = File.expand_path(File.dirname(__FILE__))+  cert_dir = File.join(this_dir, 'server_certs')+  files = ['trusted_client_roots.pem', 'server1.key', 'server1.pem']+  files.map { |f| File.open(File.join(cert_dir, f)).read }+end++# creates ServerCredentials from the test certificates.+def test_server_creds+  certs = load_test_certs+  GRPC::Core::ServerCredentials.new(+      certs[0], [{private_key: certs[1], cert_chain: certs[2]}], true)",can we add a comment here to indicate that the `true` parameter of this constructor is forcing the request/verification of the client's certificate?,
676565,augustoroman,https://api.github.com/repos/grpc/grpc/pulls/10529,122113296,2017-06-15T03:32:03Z,examples/ruby/mutual_auth/client.rb,"@@ -0,0 +1,83 @@+#!/usr/bin/env ruby++# Copyright 2015, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.++# Sample app that connects to a Greeter service with mutual client/server+# authentication.+#+# Usage: $ path/to/client.rb++this_dir = File.expand_path(File.dirname(__FILE__))+lib_dir = File.join(File.dirname(this_dir), 'lib')+$LOAD_PATH.unshift(lib_dir) unless $LOAD_PATH.include?(lib_dir)++require 'grpc'+require 'optparse'++require 'helloworld_services_pb'++# Loads the certificates used to access the test server securely.+def load_test_certs+  this_dir = File.expand_path(File.dirname(__FILE__))+  cert_dir = File.join(this_dir, 'client_certs')+  files = ['trusted_server_roots.pem', 'client.key', 'client.crt']+  files.map { |f| File.open(File.join(cert_dir, f)).read }+end++def test_client_creds+  certs = load_test_certs+  GRPC::Core::ChannelCredentials.new(certs[0], certs[1], certs[2])+end++def main+  host_override = 'foo.test.google.fr'+  OptionParser.new do |opts|+    opts.on('--server_host_override HOST_OVERRIDE',+	    'override the SSL target host name.') do |v|+      host_override = v+    end+  end.parse!++  # NEVER override the target hostname in a production environment. In+  # production, the FQDN of the server and the name in the certificate have to+  # match.","In our use case, we generate certs using a self-signed root CA and derived certs for a target machine that is automatically scaled up and down in a cluster, so we typically don't have DNS for each machine and we don't have IPs assigned ahead of time.  Instead, we create the derived certs with a non-fully-qualified name (e.g. myserver) and use this option to override the name for the randomly-assigned IP.  Thus, we get secure communication using the SSL certs and verification that the certs are derived from our custom root CA, but the name verification provides no additional security -- it works only as long as we keep our private certs secret.  Am I correct in believing this is a reasonable approach in this situation?",
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/10529,122180225,2017-06-15T11:23:17Z,examples/ruby/mutual_auth/client.rb,"@@ -0,0 +1,83 @@+#!/usr/bin/env ruby++# Copyright 2015, Google Inc.+# All rights reserved.+#+# Redistribution and use in source and binary forms, with or without+# modification, are permitted provided that the following conditions are+# met:+#+#     * Redistributions of source code must retain the above copyright+# notice, this list of conditions and the following disclaimer.+#     * Redistributions in binary form must reproduce the above+# copyright notice, this list of conditions and the following disclaimer+# in the documentation and/or other materials provided with the+# distribution.+#     * Neither the name of Google Inc. nor the names of its+# contributors may be used to endorse or promote products derived from+# this software without specific prior written permission.+#+# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+# ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+# A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+# OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+# SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+# LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+# DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+# THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+# OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.++# Sample app that connects to a Greeter service with mutual client/server+# authentication.+#+# Usage: $ path/to/client.rb++this_dir = File.expand_path(File.dirname(__FILE__))+lib_dir = File.join(File.dirname(this_dir), 'lib')+$LOAD_PATH.unshift(lib_dir) unless $LOAD_PATH.include?(lib_dir)++require 'grpc'+require 'optparse'++require 'helloworld_services_pb'++# Loads the certificates used to access the test server securely.+def load_test_certs+  this_dir = File.expand_path(File.dirname(__FILE__))+  cert_dir = File.join(this_dir, 'client_certs')+  files = ['trusted_server_roots.pem', 'client.key', 'client.crt']+  files.map { |f| File.open(File.join(cert_dir, f)).read }+end++def test_client_creds+  certs = load_test_certs+  GRPC::Core::ChannelCredentials.new(certs[0], certs[1], certs[2])+end++def main+  host_override = 'foo.test.google.fr'+  OptionParser.new do |opts|+    opts.on('--server_host_override HOST_OVERRIDE',+	    'override the SSL target host name.') do |v|+      host_override = v+    end+  end.parse!++  # NEVER override the target hostname in a production environment. In+  # production, the FQDN of the server and the name in the certificate have to+  # match."," Just to make sure. In your case case, it looks like the client knows which identity is expected on the server side and uses the override to check it, right?If that's the case indeed, I have an issue not so much with the trust model which looks fine, but with the semantics of the certificate: DNS names in SANs are expected to be backed by the DNS system and have HTTPS semantics (server host authentication). This is not quite the case here and the clean way to go about that is to use some other type of SAN entry such as a URI SAN (https://en.wikipedia.org/wiki/Subject_Alternative_Name). This is the approach that (at least some flavor of) https://github.com/spiffe is taking. We don't have this support in gRPC yet since the current SSL/TLS stack is currently very much locked into an HTTPS model but we will probably extend the model to something like spiffe soon.",
17325098,makdharma,https://api.github.com/repos/grpc/grpc/pulls/11145,122767510,2017-06-19T17:13:14Z,src/core/ext/transport/inproc/inproc_transport.c,"@@ -0,0 +1,1159 @@+/*+ *+ * Copyright 2017, Google Inc.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions are+ * met:+ *+ *     * Redistributions of source code must retain the above copyright+ * notice, this list of conditions and the following disclaimer.+ *     * Redistributions in binary form must reproduce the above+ * copyright notice, this list of conditions and the following disclaimer+ * in the documentation and/or other materials provided with the+ * distribution.+ *     * Neither the name of Google Inc. nor the names of its+ * contributors may be used to endorse or promote products derived from+ * this software without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS+ * ""AS IS"" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.+ *+ */++#include ""src/core/ext/transport/inproc/inproc_transport.h""+#include <grpc/support/alloc.h>+#include <grpc/support/string_util.h>+#include <grpc/support/sync.h>+#include <grpc/support/time.h>+#include <string.h>+#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/slice/slice_internal.h""+#include ""src/core/lib/surface/api_trace.h""+#include ""src/core/lib/surface/channel.h""+#include ""src/core/lib/surface/channel_stack_type.h""+#include ""src/core/lib/surface/server.h""+#include ""src/core/lib/transport/connectivity_state.h""+#include ""src/core/lib/transport/error_utils.h""+#include ""src/core/lib/transport/transport_impl.h""++#define INPROC_LOG(...)                                          \+  do {                                                           \+    if (GRPC_TRACER_ON(grpc_inproc_trace)) gpr_log(__VA_ARGS__); \+  } while (0)++static const grpc_transport_vtable inproc_vtable;+static grpc_slice g_empty_slice;++typedef struct {+  gpr_mu mu;+  gpr_refcount refs;+} shared_mu;++typedef struct inproc_transport {+  grpc_transport base;+  shared_mu *mu;+  gpr_refcount refs;+  bool is_client;+  grpc_connectivity_state_tracker connectivity;+  void (*accept_stream_cb)(grpc_exec_ctx *exec_ctx, void *user_data,+                           grpc_transport *transport, const void *server_data);+  void *accept_stream_data;+  bool is_closed;+  struct inproc_transport *other_side;+  struct inproc_stream *stream_list;+} inproc_transport;++typedef struct sb_list_entry {+  grpc_slice_buffer sb;+  struct sb_list_entry *next;+} sb_list_entry;++// Specialize grpc_byte_stream for our use case+typedef struct {+  grpc_byte_stream base;+  sb_list_entry *le;+} inproc_slice_byte_stream;++typedef struct {+  // TODO (vjpai): Add some inlined elements to avoid alloc in simple cases+  sb_list_entry *head;+  sb_list_entry *tail;+} slice_buffer_list;","slice_buffer_list sounds like a useful generic data structure. How about creating separate slice_buffer_list.{h,c} and adding to src/core/lib/slice ?",
22083734,matt-kwong,https://api.github.com/repos/grpc/grpc/pulls/11504,122860106,2017-06-20T01:03:51Z,test/cpp/qps/qps_diff.py,"@@ -0,0 +1,164 @@+#!/usr/bin/env python2.7+#+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+"""""" Computes the diff between two qps runs and outputs significant results """"""++import shutil+import subprocess+import os+import multiprocessing+import json+import sys+import tabulate+import argparse++sys.path.append(+  os.path.join(+    os.path.dirname(sys.argv[0]), '..', '..', '..', 'tools', 'profiling', 'microbenchmarks', 'bm_diff'))+import bm_speedup++sys.path.append(+  os.path.join(+    os.path.dirname(sys.argv[0]), '..', '..', '..', 'tools', 'run_tests', 'python_utils'))+import comment_on_pr++_SCENARIOS = {",It might be worth it to format this or keep this in a separate JSON file if this list is expected to grow.,
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/11504,122872660,2017-06-20T03:15:46Z,test/cpp/qps/qps_diff.py,"@@ -0,0 +1,164 @@+#!/usr/bin/env python2.7+#+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+"""""" Computes the diff between two qps runs and outputs significant results """"""++import shutil+import subprocess+import os+import multiprocessing+import json+import sys+import tabulate+import argparse++sys.path.append(+  os.path.join(+    os.path.dirname(sys.argv[0]), '..', '..', '..', 'tools', 'profiling', 'microbenchmarks', 'bm_diff'))+import bm_speedup++sys.path.append(+  os.path.join(+    os.path.dirname(sys.argv[0]), '..', '..', '..', 'tools', 'run_tests', 'python_utils'))+import comment_on_pr++_SCENARIOS = {+  'large-message-throughput': '{""scenarios"":[{""name"":""large-message-throughput"", ""spawn_local_worker_count"": -2, ""warmup_seconds"": 30, ""benchmark_seconds"": 270, ""num_servers"": 1, ""server_config"": {""async_server_threads"": 1, ""security_params"": null, ""server_type"": ""ASYNC_SERVER""}, ""num_clients"": 1, ""client_config"": {""client_type"": ""ASYNC_CLIENT"", ""security_params"": null, ""payload_config"": {""simple_params"": {""resp_size"": 1048576, ""req_size"": 1048576}}, ""client_channels"": 1, ""async_client_threads"": 1, ""outstanding_rpcs_per_channel"": 1, ""rpc_type"": ""UNARY"", ""load_params"": {""closed_loop"": {}}, ""histogram_params"": {""max_possible"": 60000000000.0, ""resolution"": 0.01}}}]}',+  'multi-channel-64-KiB': '{""scenarios"":[{""name"":""multi-channel-64-KiB"", ""spawn_local_worker_count"": -3, ""warmup_seconds"": 30, ""benchmark_seconds"": 270, ""num_servers"": 1, ""server_config"": {""async_server_threads"": 31, ""security_params"": null, ""server_type"": ""ASYNC_SERVER""}, ""num_clients"": 2, ""client_config"": {""client_type"": ""ASYNC_CLIENT"", ""security_params"": null, ""payload_config"": {""simple_params"": {""resp_size"": 65536, ""req_size"": 65536}}, ""client_channels"": 32, ""async_client_threads"": 31, ""outstanding_rpcs_per_channel"": 100, ""rpc_type"": ""UNARY"", ""load_params"": {""closed_loop"": {}}, ""histogram_params"": {""max_possible"": 60000000000.0, ""resolution"": 0.01}}}]}'+}++def _args():+  argp = argparse.ArgumentParser(+    description='Perform diff on QPS Driver')+  argp.add_argument(+    '-d',+    '--diff_base',+    type=str,+    help='Commit or branch to compare the current one to')+  argp.add_argument(+    '-l',+    '--loops',+    type=int,+    default=4,+    help='Number of times to loops the benchmarks. More loops cuts down on noise'+  )+  argp.add_argument(+    '-j',+    '--jobs',+    type=int,+    default=multiprocessing.cpu_count(),+    help='Number of CPUs to use')+  args = argp.parse_args()+  assert args.diff_base, ""diff_base must be set""+  return args++def _make_cmd(jobs):+  return ['make', '-j', '%d' % jobs, 'qps_json_driver', 'qps_worker',]++def build(name, jobs):+  shutil.rmtree('qps_diff_%s' % name, ignore_errors=True)+  subprocess.check_call(['git', 'submodule', 'update'])+  try:+    subprocess.check_call(_make_cmd(jobs))+  except subprocess.CalledProcessError, e:+    subprocess.check_call(['make', 'clean'])+    subprocess.check_call(_make_cmd(jobs))+  os.rename('bins', 'qps_diff_%s' % name)++def _run_cmd(name, scenario, fname):+  return ['qps_diff_%s/opt/qps_json_driver' % name, '--scenarios_json', scenario, '--json_file_out', fname]++def run(name, scenarios, loops):+  for sn in scenarios:+    for i in range(0, loops):+      fname = ""%s.%s.%d.json"" % (sn, name, i)+      subprocess.check_call(_run_cmd(name, scenarios[sn], fname))++def _load_qps(fname):+  try:+    with open(fname) as f:+      return json.loads(f.read())['qps']+  except IOError, e:+    print(""IOError occurred reading file: %s"" % fname)+    return None+  except ValueError, e:+    print(""ValueError occurred reading file: %s"" % fname)+    return None++def _median(ary):+  assert (len(ary))+  ary = sorted(ary)+  n = len(ary)+  if n % 2 == 0:+    return (ary[(n - 1) / 2] + ary[(n - 1) / 2 + 1]) / 2.0+  else:+    return ary[n / 2]++def diff(scenarios, loops, old, new):+  old_data = {}+  new_data = {}++  # collect data+  for sn in scenarios:+    old_data[sn] = []+    new_data[sn] = []+    for i in range(0, loops):+      old_data[sn].append(_load_qps(""%s.%s.%d.json"" % (sn, old, i)))+      new_data[sn].append(_load_qps(""%s.%s.%d.json"" % (sn, new, i)))++  # crunch data+  headers = ['Benchmark', 'qps']+  rows = []+  for sn in scenarios:+    mdn_diff = abs(_median(new_data[sn]) - _median(old_data[sn]))+    print('%s: %s=%r %s=%r mdn_diff=%r' % (sn, new, new_data[sn], old, old_data[sn], mdn_diff))+    s = bm_speedup.speedup(new_data[sn], old_data[sn], 10e-5)+    if abs(s) > 3 and mdn_diff > 0.5:+      rows.append([sn, '%+d%%' % s])++  if rows:+    return tabulate.tabulate(rows, headers=headers, floatfmt='+.2f')+  else:+    return None++def main(args):++  build('new', args.jobs)++  if args.diff_base:+    where_am_i = subprocess.check_output(+      ['git', 'rev-parse', '--abbrev-ref', 'HEAD']).strip()+    subprocess.check_call(['git', 'checkout', args.diff_base])+    try:+      build('old', args.jobs)+    finally:+      subprocess.check_call(['git', 'checkout', where_am_i])+      subprocess.check_call(['git', 'submodule', 'update'])++  run('new', _SCENARIOS, args.loops)+  run('old', _SCENARIOS, args.loops)++  diff_output = diff(_SCENARIOS, args.loops, 'old', 'new')++  if diff_output:+    text = '[qps] Performance differences noted:\n%s' % diff_output+  else:+    text = '[qps] No significant performance differences'+  print('%s' % text)+  comment_on_pr.comment_on_pr('```\n%s\n```' % text)++if __name__ == '__main__':+  args = _args()+  main(args);",too much c in my brain... done,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11552,123037783,2017-06-20T17:11:13Z,src/core/ext/transport/chttp2/transport/chttp2_transport.c,"@@ -518,7 +520,7 @@ static void init_transport(grpc_exec_ctx *exec_ctx, grpc_chttp2_transport *t,                   &channel_args->args[i], settings_map[j].integer_options);               if (value >= 0) {                 push_setting(exec_ctx, t, settings_map[j].setting_id,-                             (uint32_t)value);+                             (uint32_t)value, true);","Is it necessary to set `force_write` to true here, given that we unconditionally call `grpc_chttp2_initiate_write()` on line 554 below?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11552,123053592,2017-06-20T18:12:14Z,src/core/ext/transport/chttp2/transport/chttp2_transport.c,"@@ -518,7 +520,7 @@ static void init_transport(grpc_exec_ctx *exec_ctx, grpc_chttp2_transport *t,                   &channel_args->args[i], settings_map[j].integer_options);               if (value >= 0) {                 push_setting(exec_ctx, t, settings_map[j].setting_id,-                             (uint32_t)value);+                             (uint32_t)value, true);","It looks like we are now setting this parameter to false in all callers.  Given that, why not remove the parameter?  I think this entire PR could boil down to a 1-line change of simply removing the call to `grpc_chttp2_initiate_write()` from inside of `push_settings()`.",
17460127,y-zeng,https://api.github.com/repos/grpc/grpc/pulls/11499,123368907,2017-06-21T21:19:49Z,src/core/ext/transport/chttp2/transport/parsing.c,"@@ -681,9 +681,19 @@ static grpc_error *init_header_frame_parser(grpc_exec_ctx *exec_ctx,   t->parser_data = &t->hpack_parser;   switch (s->header_frames_received) {     case 0:-      t->hpack_parser.on_header = on_initial_header;+      if (t->is_client && t->header_eof) {+        GRPC_CHTTP2_IF_TRACING(gpr_log(GPR_INFO, ""parsing Trailers-Only""));+        if (s->trailing_metadata_available != NULL) {","Looks like `trailing_metadata_available` is not used in this PR, is this reserved for future use?",
17325098,makdharma,https://api.github.com/repos/grpc/grpc/pulls/11584,123845604,2017-06-23T21:13:05Z,src/core/ext/transport/cronet/transport/cronet_transport.c,"@@ -766,20 +766,47 @@ static bool op_can_be_run(grpc_transport_stream_op_batch *curr_op,   bool is_canceled_or_failed = stream_state->state_op_done[OP_CANCEL_ERROR] ||                                stream_state->state_callback_received[OP_FAILED];   if (is_canceled_or_failed) {-    if (op_id == OP_SEND_INITIAL_METADATA) result = false;-    if (op_id == OP_SEND_MESSAGE) result = false;-    if (op_id == OP_SEND_TRAILING_METADATA) result = false;-    if (op_id == OP_CANCEL_ERROR) result = false;+    if (op_id == OP_SEND_INITIAL_METADATA) {+      CRONET_LOG(GPR_DEBUG, ""Because"");+      result = false;+    }+    if (op_id == OP_SEND_MESSAGE) {+      CRONET_LOG(GPR_DEBUG, ""Because"");+      result = false;+    }+    if (op_id == OP_SEND_TRAILING_METADATA) {+      CRONET_LOG(GPR_DEBUG, ""Because"");+      result = false;+    }+    if (op_id == OP_CANCEL_ERROR) {+      CRONET_LOG(GPR_DEBUG, ""Because"");+      result = false;+    }     /* already executed */     if (op_id == OP_RECV_INITIAL_METADATA &&-        stream_state->state_op_done[OP_RECV_INITIAL_METADATA])+        stream_state->state_op_done[OP_RECV_INITIAL_METADATA]) {+      CRONET_LOG(GPR_DEBUG, ""Because"");       result = false;+    }     if (op_id == OP_RECV_MESSAGE &&-        stream_state->state_op_done[OP_RECV_MESSAGE])+        stream_state->state_op_done[OP_RECV_MESSAGE]) {+      CRONET_LOG(GPR_DEBUG, ""Because"");       result = false;+    }     if (op_id == OP_RECV_TRAILING_METADATA &&-        stream_state->state_op_done[OP_RECV_TRAILING_METADATA])+        stream_state->state_op_done[OP_RECV_TRAILING_METADATA]) {+      CRONET_LOG(GPR_DEBUG, ""Because"");       result = false;+    }+    /* If cancelled, we need to wait for the cancel callback (if call is already+     * started) */+    if (op_id == OP_ON_COMPLETE &&+        !(stream_state->state_callback_received[OP_FAILED] ||",Add a line describing the rationale behind each condition.,
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/11583,123853290,2017-06-23T22:06:56Z,src/python/grpcio_tests/tests/testing/_application_testing_common.py,"@@ -0,0 +1,35 @@+# Copyright 2017 The gRPC Authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import grpc_testing++from tests.testing.proto import requests_pb2+from tests.testing.proto import services_pb2++_FIRST_SERVICE_UNUN = grpc_testing.method('UnUn', requests_pb2.Up,","This feels like a really uncomfortable way of testing Protobuf based services/clients.I imagine the first class use case of the testing framework will be:""I have a protobuf stub, and I want to mock server responses""I think a nicer user experience is more along the lines ofchannel = MockChannel()stub = helloworld_pb2_grpc.GreeterStub(channel),and then from there I can call functions on my MockChannel to set next reply/errors ext.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11595,123890391,2017-06-25T04:45:41Z,tools/distrib/pylint_code.sh,"@@ -19,15 +19,16 @@ set -ex cd ""$(dirname ""$0"")/../..""  DIRS=(-  'src/python/grpcio/grpc'-  'src/python/grpcio_reflection/grpc_reflection'-  'src/python/grpcio_health_checking/grpc_health'+    'src/python/grpcio/grpc'+    'src/python/grpcio_health_checking/grpc_health'+    'src/python/grpcio_reflection/grpc_reflection' )  VIRTUALENV=python_pylint_venv  virtualenv $VIRTUALENV PYTHON=$(realpath $VIRTUALENV/bin/python)+$PYTHON -m pip install --upgrade pip","Not a bad idea - but if we do that, we should do it for all our virtual environments throughout the codebase. Let's defer for a separate change?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11591,124022681,2017-06-26T14:23:41Z,src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.c,"@@ -421,16 +425,15 @@ static grpc_connectivity_state update_lb_connectivity_status_locked(                                 GRPC_CHANNEL_CONNECTING, GRPC_ERROR_NONE,                                 ""rr_connecting"");     return GRPC_CHANNEL_CONNECTING;-  } else if (p->num_subchannels == 0) { /* 3) SHUTDOWN */+  } else if (p->num_shutdown == p->num_subchannels) { /* 3) SHUTDOWN */     grpc_connectivity_state_set(exec_ctx, &p->state_tracker,-                                GRPC_CHANNEL_SHUTDOWN, GRPC_ERROR_REF(error),",Why are we no longer reffing the error for these two calls?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11454,124037038,2017-06-26T15:14:38Z,include/grpc++/impl/codegen/server_interface.h,"@@ -174,22 +174,49 @@ class ServerInterface : public CallHook {                         ServerCompletionQueue* notification_cq, void* tag,                         Message* request)         : RegisteredAsyncRequest(server, context, stream, call_cq, tag),+          registered_method_(registered_method),+          server_(server),+          context_(context),+          stream_(stream),+          call_cq_(call_cq),+          notification_cq_(notification_cq),+          tag_(tag),           request_(request) {       IssueRequest(registered_method, &payload_, notification_cq);     }      bool FinalizeResult(void** tag, bool* status) override {-      bool serialization_status =-          *status && payload_ &&-          SerializationTraits<Message>::Deserialize(payload_, request_).ok();-      bool ret = RegisteredAsyncRequest::FinalizeResult(tag, status);-      *status = serialization_status && *status;-      return ret;+      if (*status) {+        if (payload_ == nullptr ||+            !SerializationTraits<Message>::Deserialize(payload_, request_)+                 .ok()) {+          // If deserialization fails, we cancel the call and instantiate+          // a new instance of ourselves to request another call.  We then+          // return false, which prevents the call from being returned to+          // the application.+          g_core_codegen_interface->grpc_call_cancel_with_status(+              call_, GRPC_STATUS_INTERNAL, ""Unable to parse request"", nullptr);","I agree that INVALID_ARGUMENT would make sense, but https://github.com/grpc/grpc/blob/master/doc/statuscodes.md dictates that gRPC is not allowed to return that code itself, only applications can do so.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11454,124037617,2017-06-26T15:16:34Z,test/cpp/server/server_request_call_test.cc,"@@ -0,0 +1,158 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <thread>++#include <grpc++/impl/codegen/config.h>+#include <gtest/gtest.h>++#include <grpc++/server.h>+#include <grpc++/server_builder.h>++#include <grpc++/create_channel.h>+#include <grpc++/security/credentials.h>++#include <grpc/support/log.h>++#include ""src/proto/grpc/testing/echo.grpc.pb.h""+#include ""test/core/util/port.h""++namespace grpc {+namespace {++TEST(ServerRequestCallTest, ShortDeadlineDoesNotCauseOkayFalse) {+  std::mutex mu;+  bool shutting_down = false;++  // grpc server config.+  std::ostringstream s;+  int p = grpc_pick_unused_port_or_die();+  s << ""[::1]:"" << p;+  const string address = s.str();+  testing::EchoTestService::AsyncService service;+  ServerBuilder builder;+  builder.AddListeningPort(address, InsecureServerCredentials());+  auto cq = builder.AddCompletionQueue();+  builder.RegisterService(&service);+  auto server = builder.BuildAndStart();++  // server thread.+  std::thread t([address, &service, &cq, &mu, &shutting_down] {+    for (int n = 0; true; n++) {+      ServerContext ctx;+      testing::EchoRequest req;+      ServerAsyncResponseWriter<testing::EchoResponse> responder(&ctx);++      // if shutting down, don't enqueue a new request.+      {+        std::lock_guard<std::mutex> lock(mu);+        if (!shutting_down) {+          service.RequestEcho(&ctx, &req, &responder, cq.get(), cq.get(),+                              (void*)1);+        }+      }++      bool ok;+      void* tag;+      bool result = cq->Next(&tag, &ok);+      if (!result) {+        break;+      }++      EXPECT_EQ((void*)1, tag);++      // If not shutting down, ok must be true for new requests.+      {+        std::lock_guard<std::mutex> lock(mu);+        if (!shutting_down && !ok) {+          gpr_log(GPR_INFO, ""!ok on request %d"", n);+          abort();+        }++        if (shutting_down && !ok) {+          // Failed connection due to shutdown, continue flushing the CQ.+          continue;+        }+      }++      // Send a simple response after a small delay that would ensure the client+      // deadline is exceeded.+      gpr_log(GPR_INFO, ""Got request %d"", n);+      testing::EchoResponse response;+      response.set_message(""foobar"");+      // A bit of sleep to make sure the deadline elapses.+      gpr_sleep_until(gpr_time_add(gpr_now(GPR_CLOCK_MONOTONIC),+                                   gpr_time_from_millis(50, GPR_TIMESPAN)));+      gpr_log(GPR_INFO, ""Finishing request %d"", n);+      responder.Finish(response, grpc::Status::OK, (void*)2);+      result = cq->Next(&tag, &ok);+      EXPECT_EQ((void*)2, tag);+    }+  });++  auto stub = testing::EchoTestService::NewStub(+      CreateChannel(address, InsecureChannelCredentials()));++  for (int i = 0; i < 100; i++) {+    gpr_log(GPR_INFO, ""Sending %d."", i);+    testing::EchoRequest request;++    /////////+    // Comment out the following line to get ok=false due to invalid request.+    // Otherwise, ok=false due to deadline being exceeded.+    /////////+    request.set_message(""foobar"");++    // A simple request with a short deadline. The server will always exceed the+    // deadline, whether due to the sleep or because the server was unable to+    // even fetch the request from the CQ before the deadline elapsed.+    testing::EchoResponse response;+    ::grpc::ClientContext ctx;+    ctx.set_fail_fast(false);+    ctx.set_deadline(std::chrono::system_clock::now() ++                     std::chrono::milliseconds(1));+    grpc::Status status = stub->Echo(&ctx, request, &response);+    EXPECT_EQ(DEADLINE_EXCEEDED, status.error_code());","I've seen the OK status being returned sporadically in the tests, but I don't fully understand why it's happening.  Even if the server sees the most recent request first, it will always sleep for longer than the deadline before sending the response, so it's not clear to me how we're getting OK here.  Could there be some other bug here?I can certainly change this to accept an OK status as well, but I'd like to understand why it's happening first.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/11591,124052738,2017-06-26T16:12:41Z,src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.c,"@@ -421,16 +425,15 @@ static grpc_connectivity_state update_lb_connectivity_status_locked(                                 GRPC_CHANNEL_CONNECTING, GRPC_ERROR_NONE,                                 ""rr_connecting"");     return GRPC_CHANNEL_CONNECTING;-  } else if (p->num_subchannels == 0) { /* 3) SHUTDOWN */+  } else if (p->num_shutdown == p->num_subchannels) { /* 3) SHUTDOWN */     grpc_connectivity_state_set(exec_ctx, &p->state_tracker,-                                GRPC_CHANNEL_SHUTDOWN, GRPC_ERROR_REF(error),",That was a leak. The ref is already incremented [here](https://github.com/dgquintas/grpc/blob/bc6bc090f471ac60c28a00152c637522e3bc72aa/src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.c#L471). This codepath wasn't hit prior to this PR.,
29667874,griffithjames,https://api.github.com/repos/grpc/grpc/pulls/11583,124074038,2017-06-26T17:45:49Z,src/python/grpcio_testing/grpc_testing/_channel.py,"@@ -0,0 +1,753 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Channel fixtures.""""""++import collections+import logging+import threading++import grpc+import grpc_testing+from grpc_testing import _common++_NOT_YET_OBSERVED = object()+++class _RpcState(object):++    def __init__(self, invocation_metadata, requests, requests_closed):+        self.condition = threading.Condition()+        self.invocation_metadata = invocation_metadata+        self.requests = requests+        self.requests_closed = requests_closed+        self.initial_metadata = None+        self.responses = []+        self.trailing_metadata = None+        self.code = None+        self.details = None+++def _state_add_request(state, request):+    with state.condition:+        if state.code is None and not state.requests_closed:+            state.requests.append(request)+            state.condition.notify_all()+            return True+        else:+            return False+++def _state_no_more_requests(state):+    with state.condition:+        if state.code is None and not state.requests_closed:+            state.requests_closed = True+            state.condition.notify_all()+++def _state_take_response(state):+    with state.condition:+        while True:+            if state.code is grpc.StatusCode.OK:+                if state.responses:+                    response = state.responses.pop(0)+                    return _common.ChannelRpcRead(response, None, None, None)+                else:+                    return _common.ChannelRpcRead(None, state.trailing_metadata,+                                                  grpc.StatusCode.OK,+                                                  state.details)+            elif state.code is None:+                if state.responses:+                    response = state.responses.pop(0)+                    return _common.ChannelRpcRead(response, None, None, None)+                else:+                    state.condition.wait()+            else:+                return _common.ChannelRpcRead(None, state.trailing_metadata,+                                              state.code, state.details)+++def _state_cancel(state, code, details):+    with state.condition:+        if state.code is None:+            if state.initial_metadata is None:+                state.initial_metadata = _common.FUSSED_EMPTY_METADATA+            state.trailing_metadata = _common.FUSSED_EMPTY_METADATA+            state.code = code+            state.details = details+            state.condition.notify_all()+            return True+        else:+            return False+++def _state_terminate(state):+    with state.condition:+        while True:","Could be:```    while state.code is None:        state.condition.wait()    return state.trailing_metadata, state.code, state.details```",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/11583,124092973,2017-06-26T19:03:18Z,src/python/grpcio_testing/grpc_testing/__init__.py,"@@ -0,0 +1,441 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Fixtures for use in testing gRPC Python-using application code.""""""++import abc+import collections++import grpc+import six+++class ChannelRpc(six.with_metaclass(abc.ABCMeta)):",I think we should have 2 separate classes for each RPC carnality.,
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/11583,124093602,2017-06-26T19:06:07Z,src/python/grpcio_testing/grpc_testing/__init__.py,"@@ -0,0 +1,441 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Fixtures for use in testing gRPC Python-using application code.""""""++import abc+import collections++import grpc+import six+++class ChannelRpc(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for an in-progress RPC invoked by a system under test.++    Enables users to ""play a server"" for such RPCs by reading requests,+    supplying responses, and supplying status.+    """"""++    @abc.abstractmethod+    def invocation_metadata(self):+        """"""Accesses the metadata passed by the system under test.++        Returns:+          The invocation metadata supplied by the system under test at+            RPC-invocation-time.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def initial_metadata(self, initial_metadata):+        """"""Accepts the initial metadata to be passed to the system under test.++        Args:+          initial_metadata: The RPC's initial metadata to be passed to the+            system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_request_as_message(self):",What do you think of renaming this ```get_next_request()```,
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/11583,124095118,2017-06-26T19:12:32Z,src/python/grpcio_testing/grpc_testing/__init__.py,"@@ -0,0 +1,441 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Fixtures for use in testing gRPC Python-using application code.""""""++import abc+import collections++import grpc+import six+++class ChannelRpc(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for an in-progress RPC invoked by a system under test.++    Enables users to ""play a server"" for such RPCs by reading requests,+    supplying responses, and supplying status.+    """"""++    @abc.abstractmethod+    def invocation_metadata(self):+        """"""Accesses the metadata passed by the system under test.++        Returns:+          The invocation metadata supplied by the system under test at+            RPC-invocation-time.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def initial_metadata(self, initial_metadata):+        """"""Accepts the initial metadata to be passed to the system under test.++        Args:+          initial_metadata: The RPC's initial metadata to be passed to the+            system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_request_as_message(self):+        """"""Draws one of the requests added to the RPC by the system under test.++        Successive calls to this method return requests in the same order in+        which the system under test added them to the RPC.++        Returns:+          A deserialized request message added to the RPC by the system under+            test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def add_responses_as_messages(self, responses):+        """"""Accepts responses to be passed to the system under test.++        Args:+          responses: An iterable of deserialized response messages to be passed+            to the system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def no_more_requests(self):","What do you think of removing this method, and changing it to ```get_trailing_metadata()```.   Client trailing metadata is set on RPC termination, and lets a tester isolate trailing metadata validation from the ```terminate()``` funciton.",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/11583,124095550,2017-06-26T19:14:36Z,src/python/grpcio_testing/grpc_testing/__init__.py,"@@ -0,0 +1,441 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Fixtures for use in testing gRPC Python-using application code.""""""++import abc+import collections++import grpc+import six+++class ChannelRpc(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for an in-progress RPC invoked by a system under test.++    Enables users to ""play a server"" for such RPCs by reading requests,+    supplying responses, and supplying status.+    """"""++    @abc.abstractmethod+    def invocation_metadata(self):+        """"""Accesses the metadata passed by the system under test.++        Returns:+          The invocation metadata supplied by the system under test at+            RPC-invocation-time.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def initial_metadata(self, initial_metadata):","What do you think of changing this to ```set_inital_metadata()``` and changing the description to ""sets the server's initial metadata to be returned to the client""?",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/11583,124096932,2017-06-26T19:21:01Z,src/python/grpcio_testing/grpc_testing/__init__.py,"@@ -0,0 +1,441 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Fixtures for use in testing gRPC Python-using application code.""""""++import abc+import collections++import grpc+import six+++class ChannelRpc(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for an in-progress RPC invoked by a system under test.++    Enables users to ""play a server"" for such RPCs by reading requests,+    supplying responses, and supplying status.+    """"""++    @abc.abstractmethod+    def invocation_metadata(self):+        """"""Accesses the metadata passed by the system under test.++        Returns:+          The invocation metadata supplied by the system under test at+            RPC-invocation-time.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def initial_metadata(self, initial_metadata):+        """"""Accepts the initial metadata to be passed to the system under test.++        Args:+          initial_metadata: The RPC's initial metadata to be passed to the+            system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_request_as_message(self):+        """"""Draws one of the requests added to the RPC by the system under test.++        Successive calls to this method return requests in the same order in+        which the system under test added them to the RPC.++        Returns:+          A deserialized request message added to the RPC by the system under+            test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def add_responses_as_messages(self, responses):+        """"""Accepts responses to be passed to the system under test.++        Args:+          responses: An iterable of deserialized response messages to be passed+            to the system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def no_more_requests(self):+        """"""Blocks until the system under test has closed the request stream.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def cancelled(self):+        """"""Blocks until the system under test has cancelled the RPC.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def terminate(self, trailing_metadata, code, details):+        """"""Accepts the RPC's trailing metadata, status code, and status details.++        This method implicitly closes the RPC's response stream and, from the+        perspective of the test code that is ""playing server"", terminates the+        RPC.+        """"""+        raise NotImplementedError()+++class ChannelFixture(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for a channel on which a system under test invokes RPCs.""""""++    @abc.abstractmethod+    def channel(self):+        """"""Accesses the grpc.Channel on which the system under test makes RPCs.++        Returns:+          The grpc.Channel on which the system under test should make RPCs.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_rpc_by_service_and_method_names(self, service_name, method_name):+        """"""Draws an RPC currently being made by the system under test.++        If no RPC with the given names is currently being made by the system+        under test, this method blocks until such an RPC is made by the system+        under test.++        This method is mutative; for each RPC made by the system under test+        exactly one ChannelRpc will be returned from this method. If two calls+        to this method are made by test code but only one RPC is invoked by the+        system under test, the second call to this method will block+        indefinitely.++        Args:+          service_name: An RPC service name (such as ""my_package.MyService"").+          method_name: An RPC method name (such as ""MyMethod"").++        Returns:+          A ChannelRpc that allows test code to ""play server"" and interact with+            the system under test.+        """"""+        raise NotImplementedError()+++class ServerRpc(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for an in-progress RPC serviced by a system under test.++    Enables users to ""play a client"" for such RPCs by supplying requests,+    reading responses, and cancelling.+    """"""++    @abc.abstractmethod+    def initial_metadata(self):+        """"""Accesses the initial metadata emitted by the system under test.++        This method blocks until the system under test has added initial+        metadata to the RPC (or has provided one or more response messages or+        has terminated the RPC, either of which will cause gRPC Python to+        synthesize initial metadata for the RPC).++        Returns:+          The initial metadata for the RPC.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def add_requests_as_messages(self, requests):+        """"""Accepts requests to be passed to the system under test.++        Args:+          requests: An iterable of deserialized request messages to be passed+            to the system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_response_as_message(self):+        """"""Draws one of the responses added to the RPC by the system under test.++        Successive calls to this method return responses in the same order in+        which the system under test added them to the RPC.++        Returns:+          A deserialized response message added to the RPC by the system under+            test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def no_more_requests(self):+        """"""Indicates the end of the RPC's request stream.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def cancel(self):+        """"""Cancel's the RPC.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def terminate(self):",Change to get result/get trailing metadata?  I don't see another way to validate a Servers returned status code or trailing metadata,
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/11583,124097528,2017-06-26T19:23:55Z,src/python/grpcio_testing/grpc_testing/__init__.py,"@@ -0,0 +1,441 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Fixtures for use in testing gRPC Python-using application code.""""""++import abc+import collections++import grpc+import six+++class ChannelRpc(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for an in-progress RPC invoked by a system under test.++    Enables users to ""play a server"" for such RPCs by reading requests,+    supplying responses, and supplying status.+    """"""++    @abc.abstractmethod+    def invocation_metadata(self):+        """"""Accesses the metadata passed by the system under test.++        Returns:+          The invocation metadata supplied by the system under test at+            RPC-invocation-time.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def initial_metadata(self, initial_metadata):+        """"""Accepts the initial metadata to be passed to the system under test.++        Args:+          initial_metadata: The RPC's initial metadata to be passed to the+            system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_request_as_message(self):+        """"""Draws one of the requests added to the RPC by the system under test.++        Successive calls to this method return requests in the same order in+        which the system under test added them to the RPC.++        Returns:+          A deserialized request message added to the RPC by the system under+            test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def add_responses_as_messages(self, responses):+        """"""Accepts responses to be passed to the system under test.++        Args:+          responses: An iterable of deserialized response messages to be passed+            to the system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def no_more_requests(self):+        """"""Blocks until the system under test has closed the request stream.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def cancelled(self):+        """"""Blocks until the system under test has cancelled the RPC.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def terminate(self, trailing_metadata, code, details):+        """"""Accepts the RPC's trailing metadata, status code, and status details.++        This method implicitly closes the RPC's response stream and, from the+        perspective of the test code that is ""playing server"", terminates the+        RPC.+        """"""+        raise NotImplementedError()+++class ChannelFixture(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for a channel on which a system under test invokes RPCs.""""""++    @abc.abstractmethod+    def channel(self):+        """"""Accesses the grpc.Channel on which the system under test makes RPCs.++        Returns:+          The grpc.Channel on which the system under test should make RPCs.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_rpc_by_service_and_method_names(self, service_name, method_name):+        """"""Draws an RPC currently being made by the system under test.++        If no RPC with the given names is currently being made by the system+        under test, this method blocks until such an RPC is made by the system+        under test.++        This method is mutative; for each RPC made by the system under test+        exactly one ChannelRpc will be returned from this method. If two calls+        to this method are made by test code but only one RPC is invoked by the+        system under test, the second call to this method will block+        indefinitely.++        Args:+          service_name: An RPC service name (such as ""my_package.MyService"").+          method_name: An RPC method name (such as ""MyMethod"").++        Returns:+          A ChannelRpc that allows test code to ""play server"" and interact with+            the system under test.+        """"""+        raise NotImplementedError()+++class ServerRpc(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for an in-progress RPC serviced by a system under test.++    Enables users to ""play a client"" for such RPCs by supplying requests,+    reading responses, and cancelling.+    """"""++    @abc.abstractmethod+    def initial_metadata(self):+        """"""Accesses the initial metadata emitted by the system under test.++        This method blocks until the system under test has added initial+        metadata to the RPC (or has provided one or more response messages or+        has terminated the RPC, either of which will cause gRPC Python to+        synthesize initial metadata for the RPC).++        Returns:+          The initial metadata for the RPC.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def add_requests_as_messages(self, requests):+        """"""Accepts requests to be passed to the system under test.++        Args:+          requests: An iterable of deserialized request messages to be passed+            to the system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_response_as_message(self):+        """"""Draws one of the responses added to the RPC by the system under test.++        Successive calls to this method return responses in the same order in+        which the system under test added them to the RPC.++        Returns:+          A deserialized response message added to the RPC by the system under+            test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def no_more_requests(self):+        """"""Indicates the end of the RPC's request stream.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def cancel(self):+        """"""Cancel's the RPC.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def terminate(self):+        """"""Blocks until the system under test has terminated the RPC.""""""+        raise NotImplementedError()+++class ServerFixture(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for a server in which a system under test services RPCs.""""""++    @abc.abstractmethod+    def invoke_rpc_by_service_and_method_names(self, service_name, method_name,+                                               invocation_metadata, requests,+                                               no_more_requests, timeout):+        """"""Invokes an RPC to be serviced by the system under test.++        Args:+          service_name: An RPC service name (such as ""my_package.MyService"").+          method_name: An RPC method name (such as ""MyMethod"").+          invocation_metadata: The metadata supplied at RPC-invocation-time by+            the invoker of the RPC.+          requests: An iterable of request messages with which to start the RPC.+            These are just a start; they need not be all requests that will ever+            be added to the RPC.+          no_more_requests: True if all requests are known and passed in this+            call and the RPC's request stream should be closed; False if test+            code may add more requests later or wishes to hold the request+            stream open until a later time.+          timeout: A duration of time in seconds for the RPC.+        """"""+        raise NotImplementedError()+++class Connection(six.with_metaclass(abc.ABCMeta)):",What is the benefit to testing a system that is both a server and a client?  Should we encourage users to test server and client components in isolation?,
29667874,griffithjames,https://api.github.com/repos/grpc/grpc/pulls/11583,124115477,2017-06-26T20:41:38Z,src/python/grpcio_testing/grpc_testing/__init__.py,"@@ -0,0 +1,441 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Fixtures for use in testing gRPC Python-using application code.""""""++import abc+import collections++import grpc+import six+++class ChannelRpc(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for an in-progress RPC invoked by a system under test.++    Enables users to ""play a server"" for such RPCs by reading requests,+    supplying responses, and supplying status.+    """"""++    @abc.abstractmethod+    def invocation_metadata(self):+        """"""Accesses the metadata passed by the system under test.++        Returns:+          The invocation metadata supplied by the system under test at+            RPC-invocation-time.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def initial_metadata(self, initial_metadata):+        """"""Accepts the initial metadata to be passed to the system under test.++        Args:+          initial_metadata: The RPC's initial metadata to be passed to the+            system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_request_as_message(self):+        """"""Draws one of the requests added to the RPC by the system under test.++        Successive calls to this method return requests in the same order in+        which the system under test added them to the RPC.++        Returns:+          A deserialized request message added to the RPC by the system under+            test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def add_responses_as_messages(self, responses):+        """"""Accepts responses to be passed to the system under test.++        Args:+          responses: An iterable of deserialized response messages to be passed+            to the system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def no_more_requests(self):+        """"""Blocks until the system under test has closed the request stream.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def cancelled(self):+        """"""Blocks until the system under test has cancelled the RPC.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def terminate(self, trailing_metadata, code, details):+        """"""Accepts the RPC's trailing metadata, status code, and status details.++        This method implicitly closes the RPC's response stream and, from the+        perspective of the test code that is ""playing server"", terminates the+        RPC.+        """"""+        raise NotImplementedError()+++class ChannelFixture(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for a channel on which a system under test invokes RPCs.""""""++    @abc.abstractmethod+    def channel(self):+        """"""Accesses the grpc.Channel on which the system under test makes RPCs.++        Returns:+          The grpc.Channel on which the system under test should make RPCs.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_rpc_by_service_and_method_names(self, service_name, method_name):+        """"""Draws an RPC currently being made by the system under test.++        If no RPC with the given names is currently being made by the system+        under test, this method blocks until such an RPC is made by the system+        under test.++        This method is mutative; for each RPC made by the system under test+        exactly one ChannelRpc will be returned from this method. If two calls+        to this method are made by test code but only one RPC is invoked by the+        system under test, the second call to this method will block+        indefinitely.++        Args:+          service_name: An RPC service name (such as ""my_package.MyService"").+          method_name: An RPC method name (such as ""MyMethod"").++        Returns:+          A ChannelRpc that allows test code to ""play server"" and interact with+            the system under test.+        """"""+        raise NotImplementedError()+++class ServerRpc(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for an in-progress RPC serviced by a system under test.++    Enables users to ""play a client"" for such RPCs by supplying requests,+    reading responses, and cancelling.+    """"""++    @abc.abstractmethod+    def initial_metadata(self):+        """"""Accesses the initial metadata emitted by the system under test.++        This method blocks until the system under test has added initial+        metadata to the RPC (or has provided one or more response messages or+        has terminated the RPC, either of which will cause gRPC Python to+        synthesize initial metadata for the RPC).++        Returns:+          The initial metadata for the RPC.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def add_requests_as_messages(self, requests):+        """"""Accepts requests to be passed to the system under test.++        Args:+          requests: An iterable of deserialized request messages to be passed+            to the system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_response_as_message(self):+        """"""Draws one of the responses added to the RPC by the system under test.++        Successive calls to this method return responses in the same order in+        which the system under test added them to the RPC.++        Returns:+          A deserialized response message added to the RPC by the system under+            test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def no_more_requests(self):+        """"""Indicates the end of the RPC's request stream.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def cancel(self):+        """"""Cancel's the RPC.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def terminate(self):+        """"""Blocks until the system under test has terminated the RPC.""""""+        raise NotImplementedError()+++class ServerFixture(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for a server in which a system under test services RPCs.""""""++    @abc.abstractmethod+    def invoke_rpc_by_service_and_method_names(self, service_name, method_name,+                                               invocation_metadata, requests,+                                               no_more_requests, timeout):+        """"""Invokes an RPC to be serviced by the system under test.++        Args:+          service_name: An RPC service name (such as ""my_package.MyService"").+          method_name: An RPC method name (such as ""MyMethod"").+          invocation_metadata: The metadata supplied at RPC-invocation-time by+            the invoker of the RPC.+          requests: An iterable of request messages with which to start the RPC.+            These are just a start; they need not be all requests that will ever+            be added to the RPC.+          no_more_requests: True if all requests are known and passed in this+            call and the RPC's request stream should be closed; False if test+            code may add more requests later or wishes to hold the request+            stream open until a later time.+          timeout: A duration of time in seconds for the RPC.+        """"""+        raise NotImplementedError()+++class Connection(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for testing a system that is both a client and a server.""""""++    @abc.abstractmethod+    def channel(self):+        """"""Accesses the grpc.Channel on which the system under test makes RPCs.++        Returns:+          The grpc.Channel on which the system under test should make RPCs.+        """"""+        raise NotImplementedError()+++class Time(six.with_metaclass(abc.ABCMeta)):+    """"""A simulation of time.++    Implementations needn't be connected with real time as provided by the+    Python interpreter, but as long as systems under test use+    RpcContext.is_active and RpcContext.time_remaining for querying RPC liveness+    implementations may be used to change passage of time in tests.+    """"""++    @abc.abstractmethod+    def time(self):+        """"""Accesses the current test time.++        Returns:+          The current test time (over which this object has authority).+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def call_in(self, behavior, delay):+        """"""Adds a behavior to be called after some time.++        Args:+          behavior: A behavior to be called with no arguments.+          delay: A duration of time in seconds after which to call the behavior.++        Returns:+          A grpc.Future with which the call of the behavior may be cancelled+            before it is executed.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def call_at(self, behavior, time):+        """"""Adds a behavior to be called at a specific time.++        Args:+          behavior: A behavior to be called with no arguments.+          time: The test time at which to call the behavior.++        Returns:+          A grpc.Future with which the call of the behavior may be cancelled+            before it is executed.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def sleep_for(self, duration):+        """"""Blocks for some length of test time.++        Args:+          duration: A duration of test time in seconds for which to block.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def sleep_until(self, time):+        """"""Blocks until some test time.++        Args:+          time: The test time until which to block.+        """"""+        raise NotImplementedError()+++# TODO(google/protobuf/3167, google/protobuf/3168): Eliminate this and+# use Descriptor objects instead.+class Method(six.with_metaclass(abc.ABCMeta)):+    """"""A description of an RPC method.++    Attributes:+      name: The method name.+      request_class: The class of the method's requests.+      response_class: The class of the method's responses.+      request_unary: True if the method requires exactly one request+        message being sent per RPC; False otherwise.+      response_unary: True if the method requires exactly one response+        message being sent per RPC; False otherwise.+    """"""+++# TODO(google/protobuf 3167, google/protobuf 3168): Eliminate this and+# use Descriptor objects instead.+class Service(six.with_metaclass(abc.ABCMeta)):+    """"""A description of an RPC service.++    Attributes:+      name: The service name.+      methods: A sequence of Methods describing the service's methods.+    """"""+++class _Method(Method,+              collections.namedtuple('_Method',+                                     ('name', 'request_class', 'response_class',+                                      'request_unary', 'response_unary',))):+    pass+++class _Service(Service, collections.namedtuple('_Service',+                                               ('name', 'methods',))):+    pass+++def real_time():+    """"""Creates a Time backed by the Python interpreter's time.++    Returns:+      A Time backed by the ""system"" (Python interpreter's) time.+    """"""+    from grpc_testing import _time+    return _time.RealTime()+++def fake_time(now):+    """"""Creates a Time that can be manipulated by test code.++    The returned instance maintains an internal representation of time+    independent of real time. This internal representation only advances+    when user code calls the instance's sleep_for and sleep_until methods.++    Returns:+      A Time that simulates the passage of time.+    """"""+    from grpc_testing import _time+    return _time.FakeTime(now)+++def method(name, request_class, response_class, request_unary, response_unary):+    """"""Creates a Method from the given parameters.++    Args:+      name: The method name.+      request_class: The class of the method's requests.+      response_class: The class of the method's responses.+      request_unary: True if the method requires exactly one request",Isn't this data known from the proto file?,
29667874,griffithjames,https://api.github.com/repos/grpc/grpc/pulls/11583,124122863,2017-06-26T21:09:10Z,src/python/grpcio_tests/tests/testing/_server_application.py,"@@ -0,0 +1,67 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""An example gRPC Python-using server-side application.""""""++import grpc++# requests_pb2 is a semantic dependency of this module.+from tests.testing.proto import requests_pb2  # pylint: disable=unused-import+from tests.testing.proto import services_pb2+from tests.testing.proto import services_pb2_grpc++from tests.testing import _application_common+++class FirstServiceServicer(services_pb2_grpc.FirstServiceServicer):","It'd be nice if users of this framework didn't have to instantiate the services they're mocking, and the framework did it for them. ",
29667874,griffithjames,https://api.github.com/repos/grpc/grpc/pulls/11583,124126724,2017-06-26T21:27:20Z,src/python/grpcio_tests/tests/testing/_client_application.py,"@@ -0,0 +1,237 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""An example gRPC Python-using client-side application.""""""++import collections+import enum+import threading++import grpc+from tests.unit.framework.common import test_constants++from tests.testing.proto import services_pb2_grpc++from tests.testing import _application_common+++@enum.unique+class Scenario(enum.Enum):+    UNARY_UNARY = 'unary unary'+    UNARY_STREAM = 'unary stream'+    STREAM_UNARY = 'stream unary'+    STREAM_STREAM = 'stream stream'+    CONCURRENT_STREAM_UNARY = 'concurrent stream unary'+    CONCURRENT_STREAM_STREAM = 'concurrent stream stream'+    CANCEL_UNARY_UNARY = 'cancel unary unary'+    CANCEL_UNARY_STREAM = 'cancel unary stream'+    INFINITE_REQUEST_STREAM = 'infinite request stream'+++class Outcome(collections.namedtuple('Outcome', ('kind', 'code', 'details'))):+    """"""Outcome of a client application scenario.++    Attributes:+      kind: A Kind value describing the overall kind of scenario execution.+      code: A grpc.StatusCode value. Only valid if kind is Kind.RPC_ERROR.+      details: A status details string. Only valid if kind is Kind.RPC_ERROR.+    """"""++    @enum.unique+    class Kind(enum.Enum):+        SATISFACTORY = 'satisfactory'+        UNSATISFACTORY = 'unsatisfactory'+        RPC_ERROR = 'rpc error'+++_SATISFACTORY_OUTCOME = Outcome(Outcome.Kind.SATISFACTORY, None, None)+_UNSATISFACTORY_OUTCOME = Outcome(Outcome.Kind.UNSATISFACTORY, None, None)+++class _Pipe(object):++    def __init__(self):+        self._condition = threading.Condition()+        self._values = []+        self._open = True++    def __iter__(self):+        return self++    def _next(self):+        with self._condition:+            while True:+                if self._values:+                    return self._values.pop(0)+                elif not self._open:+                    raise StopIteration()+                else:+                    self._condition.wait()++    def __next__(self):  # (Python 3 Iterator Protocol)+        return self._next()++    def next(self):  # (Python 2 Iterator Protocol)+        return self._next()++    def add(self, value):+        with self._condition:++            self._values.append(value)+            self._condition.notify_all()++    def close(self):+        with self._condition:+            self._open = False+            self._condition.notify_all()+++def _run_unary_unary(stub):+    response = stub.UnUn(_application_common.UNARY_UNARY_REQUEST)+    if _application_common.UNARY_UNARY_RESPONSE == response:+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def _run_unary_stream(stub):+    response_iterator = stub.UnStre(_application_common.UNARY_STREAM_REQUEST)+    try:+        next(response_iterator)+    except StopIteration:+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def _run_stream_unary(stub):+    response, call = stub.StreUn.with_call(+        iter((_application_common.STREAM_UNARY_REQUEST,) * 3))+    if (_application_common.STREAM_UNARY_RESPONSE == response and+            call.code() is grpc.StatusCode.OK):+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def _run_stream_stream(stub):+    request_pipe = _Pipe()+    response_iterator = stub.StreStre(iter(request_pipe))+    request_pipe.add(_application_common.STREAM_STREAM_REQUEST)+    first_responses = next(response_iterator), next(response_iterator),+    request_pipe.add(_application_common.STREAM_STREAM_REQUEST)+    second_responses = next(response_iterator), next(response_iterator),+    request_pipe.close()+    try:+        next(response_iterator)+    except StopIteration:+        unexpected_extra_response = False+    else:+        unexpected_extra_response = True+    if (first_responses == _application_common.TWO_STREAM_STREAM_RESPONSES and+            second_responses == _application_common.TWO_STREAM_STREAM_RESPONSES+            and not unexpected_extra_response):+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def _run_concurrent_stream_unary(stub):+    future_calls = tuple(+        stub.StreUn.future(+            iter((_application_common.STREAM_UNARY_REQUEST,) * 3))+        for _ in range(test_constants.THREAD_CONCURRENCY))+    for future_call in future_calls:+        if future_call.code() is grpc.StatusCode.OK:+            response = future_call.result()+            if _application_common.STREAM_UNARY_RESPONSE != response:+                return _UNSATISFACTORY_OUTCOME+        else:+            return _UNSATISFACTORY_OUTCOME+    else:+        return _SATISFACTORY_OUTCOME+++def _run_concurrent_stream_stream(stub):+    condition = threading.Condition()+    outcomes = [None] * test_constants.RPC_CONCURRENCY++    def run_stream_stream(index):+        outcome = _run_stream_stream(stub)+        with condition:+            outcomes[index] = outcome+            condition.notify()++    for index in range(test_constants.RPC_CONCURRENCY):+        thread = threading.Thread(target=run_stream_stream, args=(index,))+        thread.start()+    with condition:+        while True:+            if all(outcomes):+                for outcome in outcomes:+                    if outcome.kind is not Outcome.Kind.SATISFACTORY:+                        return _UNSATISFACTORY_OUTCOME+                else:+                    return _SATISFACTORY_OUTCOME+            else:+                condition.wait()+++def _run_cancel_unary_unary(stub):+    response_future_call = stub.UnUn.future(+        _application_common.UNARY_UNARY_REQUEST)+    initial_metadata = response_future_call.initial_metadata()+    cancelled = response_future_call.cancel()+    if initial_metadata is not None and cancelled:+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def _run_infinite_request_stream(stub):++    def infinite_request_iterator():+        while True:+            yield _application_common.STREAM_UNARY_REQUEST++    response_future_call = stub.StreUn.future(+        infinite_request_iterator(),+        timeout=_application_common.INFINITE_REQUEST_STREAM_TIMEOUT)+    if response_future_call.code() is grpc.StatusCode.DEADLINE_EXCEEDED:+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def run(scenario, channel):+    stub = services_pb2_grpc.FirstServiceStub(channel)+    try:+        if scenario is Scenario.UNARY_UNARY:","Personally, I think this pattern is cleaner as an enum->function dictionary.",
29667874,griffithjames,https://api.github.com/repos/grpc/grpc/pulls/11583,124127828,2017-06-26T21:33:01Z,src/python/grpcio_tests/tests/testing/_client_application.py,"@@ -0,0 +1,237 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""An example gRPC Python-using client-side application.""""""++import collections+import enum+import threading++import grpc+from tests.unit.framework.common import test_constants++from tests.testing.proto import services_pb2_grpc++from tests.testing import _application_common+++@enum.unique+class Scenario(enum.Enum):+    UNARY_UNARY = 'unary unary'+    UNARY_STREAM = 'unary stream'+    STREAM_UNARY = 'stream unary'+    STREAM_STREAM = 'stream stream'+    CONCURRENT_STREAM_UNARY = 'concurrent stream unary'+    CONCURRENT_STREAM_STREAM = 'concurrent stream stream'+    CANCEL_UNARY_UNARY = 'cancel unary unary'+    CANCEL_UNARY_STREAM = 'cancel unary stream'+    INFINITE_REQUEST_STREAM = 'infinite request stream'+++class Outcome(collections.namedtuple('Outcome', ('kind', 'code', 'details'))):+    """"""Outcome of a client application scenario.++    Attributes:+      kind: A Kind value describing the overall kind of scenario execution.+      code: A grpc.StatusCode value. Only valid if kind is Kind.RPC_ERROR.+      details: A status details string. Only valid if kind is Kind.RPC_ERROR.+    """"""++    @enum.unique+    class Kind(enum.Enum):+        SATISFACTORY = 'satisfactory'+        UNSATISFACTORY = 'unsatisfactory'+        RPC_ERROR = 'rpc error'+++_SATISFACTORY_OUTCOME = Outcome(Outcome.Kind.SATISFACTORY, None, None)+_UNSATISFACTORY_OUTCOME = Outcome(Outcome.Kind.UNSATISFACTORY, None, None)+++class _Pipe(object):++    def __init__(self):+        self._condition = threading.Condition()+        self._values = []+        self._open = True++    def __iter__(self):+        return self++    def _next(self):+        with self._condition:+            while True:","Consider:```    while not self._values:        if not self._open:            raise StopIteration()        self._condition.wait()    return self._values.pop(0)```I don't totally love it, but it is (slightly) more compact.",
29667874,griffithjames,https://api.github.com/repos/grpc/grpc/pulls/11583,124129358,2017-06-26T21:40:53Z,src/python/grpcio_tests/tests/testing/_client_application.py,"@@ -0,0 +1,237 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""An example gRPC Python-using client-side application.""""""++import collections+import enum+import threading++import grpc+from tests.unit.framework.common import test_constants++from tests.testing.proto import services_pb2_grpc++from tests.testing import _application_common+++@enum.unique+class Scenario(enum.Enum):+    UNARY_UNARY = 'unary unary'+    UNARY_STREAM = 'unary stream'+    STREAM_UNARY = 'stream unary'+    STREAM_STREAM = 'stream stream'+    CONCURRENT_STREAM_UNARY = 'concurrent stream unary'+    CONCURRENT_STREAM_STREAM = 'concurrent stream stream'+    CANCEL_UNARY_UNARY = 'cancel unary unary'+    CANCEL_UNARY_STREAM = 'cancel unary stream'+    INFINITE_REQUEST_STREAM = 'infinite request stream'+++class Outcome(collections.namedtuple('Outcome', ('kind', 'code', 'details'))):+    """"""Outcome of a client application scenario.++    Attributes:+      kind: A Kind value describing the overall kind of scenario execution.+      code: A grpc.StatusCode value. Only valid if kind is Kind.RPC_ERROR.+      details: A status details string. Only valid if kind is Kind.RPC_ERROR.+    """"""++    @enum.unique+    class Kind(enum.Enum):+        SATISFACTORY = 'satisfactory'+        UNSATISFACTORY = 'unsatisfactory'+        RPC_ERROR = 'rpc error'+++_SATISFACTORY_OUTCOME = Outcome(Outcome.Kind.SATISFACTORY, None, None)+_UNSATISFACTORY_OUTCOME = Outcome(Outcome.Kind.UNSATISFACTORY, None, None)+++class _Pipe(object):++    def __init__(self):+        self._condition = threading.Condition()+        self._values = []+        self._open = True++    def __iter__(self):+        return self++    def _next(self):+        with self._condition:+            while True:+                if self._values:+                    return self._values.pop(0)+                elif not self._open:+                    raise StopIteration()+                else:+                    self._condition.wait()++    def __next__(self):  # (Python 3 Iterator Protocol)+        return self._next()++    def next(self):  # (Python 2 Iterator Protocol)+        return self._next()++    def add(self, value):+        with self._condition:++            self._values.append(value)+            self._condition.notify_all()++    def close(self):+        with self._condition:+            self._open = False+            self._condition.notify_all()+++def _run_unary_unary(stub):+    response = stub.UnUn(_application_common.UNARY_UNARY_REQUEST)+    if _application_common.UNARY_UNARY_RESPONSE == response:+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def _run_unary_stream(stub):+    response_iterator = stub.UnStre(_application_common.UNARY_STREAM_REQUEST)+    try:+        next(response_iterator)+    except StopIteration:+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def _run_stream_unary(stub):+    response, call = stub.StreUn.with_call(+        iter((_application_common.STREAM_UNARY_REQUEST,) * 3))+    if (_application_common.STREAM_UNARY_RESPONSE == response and+            call.code() is grpc.StatusCode.OK):+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def _run_stream_stream(stub):+    request_pipe = _Pipe()+    response_iterator = stub.StreStre(iter(request_pipe))+    request_pipe.add(_application_common.STREAM_STREAM_REQUEST)+    first_responses = next(response_iterator), next(response_iterator),+    request_pipe.add(_application_common.STREAM_STREAM_REQUEST)+    second_responses = next(response_iterator), next(response_iterator),+    request_pipe.close()+    try:+        next(response_iterator)+    except StopIteration:+        unexpected_extra_response = False+    else:+        unexpected_extra_response = True+    if (first_responses == _application_common.TWO_STREAM_STREAM_RESPONSES and+            second_responses == _application_common.TWO_STREAM_STREAM_RESPONSES+            and not unexpected_extra_response):+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def _run_concurrent_stream_unary(stub):+    future_calls = tuple(+        stub.StreUn.future(+            iter((_application_common.STREAM_UNARY_REQUEST,) * 3))+        for _ in range(test_constants.THREAD_CONCURRENCY))+    for future_call in future_calls:+        if future_call.code() is grpc.StatusCode.OK:+            response = future_call.result()+            if _application_common.STREAM_UNARY_RESPONSE != response:+                return _UNSATISFACTORY_OUTCOME+        else:+            return _UNSATISFACTORY_OUTCOME+    else:+        return _SATISFACTORY_OUTCOME+++def _run_concurrent_stream_stream(stub):+    condition = threading.Condition()+    outcomes = [None] * test_constants.RPC_CONCURRENCY++    def run_stream_stream(index):+        outcome = _run_stream_stream(stub)+        with condition:+            outcomes[index] = outcome+            condition.notify()++    for index in range(test_constants.RPC_CONCURRENCY):+        thread = threading.Thread(target=run_stream_stream, args=(index,))+        thread.start()+    with condition:+        while True:+            if all(outcomes):+                for outcome in outcomes:+                    if outcome.kind is not Outcome.Kind.SATISFACTORY:+                        return _UNSATISFACTORY_OUTCOME+                else:+                    return _SATISFACTORY_OUTCOME+            else:+                condition.wait()+++def _run_cancel_unary_unary(stub):+    response_future_call = stub.UnUn.future(+        _application_common.UNARY_UNARY_REQUEST)+    initial_metadata = response_future_call.initial_metadata()+    cancelled = response_future_call.cancel()+    if initial_metadata is not None and cancelled:+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def _run_infinite_request_stream(stub):++    def infinite_request_iterator():+        while True:+            yield _application_common.STREAM_UNARY_REQUEST++    response_future_call = stub.StreUn.future(+        infinite_request_iterator(),+        timeout=_application_common.INFINITE_REQUEST_STREAM_TIMEOUT)+    if response_future_call.code() is grpc.StatusCode.DEADLINE_EXCEEDED:+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def run(scenario, channel):+    stub = services_pb2_grpc.FirstServiceStub(channel)","It'd be nice if the framework could provide stubs in a generic way, without referring to the class again, like this:`stub = my_service.stub()`It's a not a big deal, but it'd be nice to have.",
29667874,griffithjames,https://api.github.com/repos/grpc/grpc/pulls/11583,124134599,2017-06-26T22:08:53Z,src/python/grpcio_testing/grpc_testing/_time.py,"@@ -0,0 +1,223 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Test times.""""""++import collections+import logging+import threading+import time as _time++import grpc+import grpc_testing+++def _call(behaviors):+    for behavior in behaviors:+        try:+            behavior()+        except Exception:  # pylint: disable=broad-except+            logging.exception('Exception calling behavior?')+++def _call_in_thread(behaviors):+    calling = threading.Thread(target=_call, args=(behaviors,))+    calling.start()+    calling.join()+++class _State(object):++    def __init__(self):+        self.condition = threading.Condition()+        self.times_to_behaviors = collections.defaultdict(list)+        self.behaviors_to_times = {}+++class _Delta(+        collections.namedtuple('_Delta',+                               ('mature_behaviors', 'earliest_mature_time',+                                'earliest_immature_time',))):+    pass+++def _process(state, now):+    mature_behaviors = []+    earliest_mature_time = None+    while state.times_to_behaviors:+        earliest_time = min(state.times_to_behaviors)+        if earliest_time <= now:+            if earliest_mature_time is None:+                earliest_mature_time = earliest_time+            earliest_mature_behaviors = state.times_to_behaviors.pop(+                earliest_time)+            for mature_behavior in earliest_mature_behaviors:+                state.behaviors_to_times.pop(mature_behavior)+            mature_behaviors.extend(earliest_mature_behaviors)+        else:+            earliest_immature_time = earliest_time+            break+    else:+        earliest_immature_time = None+    return _Delta(mature_behaviors, earliest_mature_time,+                  earliest_immature_time)+++class _Future(grpc.Future):++    def __init__(self, state, behavior):+        self._state = state+        self._behavior = behavior+        self._cancelled = False++    def cancel(self):+        with self._state.condition:+            time = self._state.behaviors_to_times.pop(self._behavior, None)+            if time is None:+                return False+            else:+                self._state.times_to_behaviors[time].remove(self._behavior)+                if not self._state.times_to_behaviors[time]:+                    self._state.times_to_behaviors.pop(time)+                    self._state.condition.notify_all()+                self._cancelled = True+                return True++    def cancelled(self):+        with self._state.condition:+            return self._cancelled++    def running(self):+        raise NotImplementedError()++    def done(self):+        raise NotImplementedError()++    def result(self, timeout=None):+        raise NotImplementedError()++    def exception(self, timeout=None):+        raise NotImplementedError()++    def traceback(self, timeout=None):+        raise NotImplementedError()++    def add_done_callback(self, fn):+        raise NotImplementedError()+++class RealTime(grpc_testing.Time):",Could this class be simpler by using a timer interrupt and a sorted list of event times?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11607,124299395,2017-06-27T14:56:49Z,src/core/tsi/transport_security.c,"@@ -330,3 +331,50 @@ tsi_result tsi_construct_peer(size_t property_count, tsi_peer *peer) {   }   return TSI_OK; }++/* --- tsi_plugin_func implementation --- */++typedef struct tsi_plugin_func_list tsi_plugin_func_list;++static tsi_plugin_func_list *tsi_destroy_list = NULL;+static gpr_once tsi_once_var = GPR_ONCE_INIT;+static gpr_mu tsi_mu;++typedef struct tsi_plugin_func_node {+  void (*func)(void);+  struct tsi_plugin_func_node *next;+} tsi_plugin_func_node;++struct tsi_plugin_func_list {+  tsi_plugin_func_node *head;+};++void tsi_register_destroy_plugin(void (*destroy)(void)) {+  gpr_mu_lock(&tsi_mu);+  if (tsi_destroy_list == NULL) {+    tsi_destroy_list = gpr_zalloc(sizeof(*tsi_destroy_list));+  }+  /* Create a tsi_plugin_func_node instance and add to tsi_destroy_list. */+  tsi_plugin_func_node *node = gpr_zalloc(sizeof(*node));+  node->func = destroy;+  node->next = tsi_destroy_list->head;+  tsi_destroy_list->head = node;+  gpr_mu_unlock(&tsi_mu);+}++/* --- tsi_init/tsi_destroy implementation --- */++static void init_mu() { gpr_mu_init(&tsi_mu); }++void tsi_init() { gpr_once_init(&tsi_once_var, init_mu); }++void tsi_destroy() {+  if (tsi_destroy_list == NULL) {+    return;+  }+  tsi_plugin_func_node *node = tsi_destroy_list->head;",Could write this a bit more compactly as a for loop:```for (tsi_plugin_func_node *node = tsi_destroy_list->head; node != NULL;     node = node->next) {  node->func();}```,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11607,124300736,2017-06-27T15:01:01Z,src/core/tsi/transport_security.c,"@@ -330,3 +331,50 @@ tsi_result tsi_construct_peer(size_t property_count, tsi_peer *peer) {   }   return TSI_OK; }++/* --- tsi_plugin_func implementation --- */++typedef struct tsi_plugin_func_list tsi_plugin_func_list;++static tsi_plugin_func_list *tsi_destroy_list = NULL;+static gpr_once tsi_once_var = GPR_ONCE_INIT;+static gpr_mu tsi_mu;","Same here -- as long as we require that `tsi_register_destroy_plugin()` is only invoked at initialization time, there should be no need for locking.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11607,124301272,2017-06-27T15:02:58Z,src/core/tsi/gts_transport_security.c,"@@ -0,0 +1,35 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/core/tsi/gts_transport_security.h""+#include <grpc/support/alloc.h>++static gts_shared_resource* gts_resource = NULL;","Who's going to set this pointer, and when will that happen?If we really want a single global object here, why not just have this be the struct itself, instead of a pointer that has to be set later?  The initialization hook can initialize the data members.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11607,124302584,2017-06-27T15:07:13Z,src/core/tsi/transport_security.h,"@@ -111,6 +111,9 @@ tsi_result tsi_construct_allocated_string_peer_property( tsi_result tsi_construct_string_peer_property_from_cstring(     const char *name, const char *value, tsi_peer_property *property); +/* Destroy plugin registration funcion. */+void tsi_register_destroy_plugin(void (*destroy)(void));","Design question: Why are we creating a new registration system for TSI implementations, rather than using the existing gRPC plugin system?  In other words, can't we just have each TSI implementation be its own gRPC plugin, in which case there's no need for this duplicate machinery?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11607,124323609,2017-06-27T16:17:26Z,src/core/tsi/transport_security.h,"@@ -111,6 +111,9 @@ tsi_result tsi_construct_allocated_string_peer_property( tsi_result tsi_construct_string_peer_property_from_cstring(     const char *name, const char *value, tsi_peer_property *property); +/* Destroy plugin registration funcion. */+void tsi_register_destroy_plugin(void (*destroy)(void));","I'm not necessarily opposed to having a separate mechanism for TSI implementations; we do something similar for (e.g.) resolver and LB policy implementations.  But if we're going to do that, then I think we should provide a complete interface, which provides hooks for both initialization and destruction.  For example:```void tsi_register_implementation(void (*init)(), void (*destroy)());```This way, implementations like GTS can have their own one-time global initialization and destruction code.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/11454,124328915,2017-06-27T16:37:33Z,test/cpp/server/server_request_call_test.cc,"@@ -0,0 +1,158 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <thread>++#include <grpc++/impl/codegen/config.h>+#include <gtest/gtest.h>++#include <grpc++/server.h>+#include <grpc++/server_builder.h>++#include <grpc++/create_channel.h>+#include <grpc++/security/credentials.h>++#include <grpc/support/log.h>++#include ""src/proto/grpc/testing/echo.grpc.pb.h""+#include ""test/core/util/port.h""++namespace grpc {+namespace {++TEST(ServerRequestCallTest, ShortDeadlineDoesNotCauseOkayFalse) {+  std::mutex mu;+  bool shutting_down = false;++  // grpc server config.+  std::ostringstream s;+  int p = grpc_pick_unused_port_or_die();+  s << ""[::1]:"" << p;+  const string address = s.str();+  testing::EchoTestService::AsyncService service;+  ServerBuilder builder;+  builder.AddListeningPort(address, InsecureServerCredentials());+  auto cq = builder.AddCompletionQueue();+  builder.RegisterService(&service);+  auto server = builder.BuildAndStart();++  // server thread.+  std::thread t([address, &service, &cq, &mu, &shutting_down] {+    for (int n = 0; true; n++) {+      ServerContext ctx;+      testing::EchoRequest req;+      ServerAsyncResponseWriter<testing::EchoResponse> responder(&ctx);++      // if shutting down, don't enqueue a new request.+      {+        std::lock_guard<std::mutex> lock(mu);+        if (!shutting_down) {+          service.RequestEcho(&ctx, &req, &responder, cq.get(), cq.get(),+                              (void*)1);+        }+      }++      bool ok;+      void* tag;+      bool result = cq->Next(&tag, &ok);+      if (!result) {+        break;+      }++      EXPECT_EQ((void*)1, tag);++      // If not shutting down, ok must be true for new requests.+      {+        std::lock_guard<std::mutex> lock(mu);+        if (!shutting_down && !ok) {+          gpr_log(GPR_INFO, ""!ok on request %d"", n);+          abort();+        }++        if (shutting_down && !ok) {+          // Failed connection due to shutdown, continue flushing the CQ.+          continue;+        }+      }++      // Send a simple response after a small delay that would ensure the client+      // deadline is exceeded.+      gpr_log(GPR_INFO, ""Got request %d"", n);+      testing::EchoResponse response;+      response.set_message(""foobar"");+      // A bit of sleep to make sure the deadline elapses.+      gpr_sleep_until(gpr_time_add(gpr_now(GPR_CLOCK_MONOTONIC),+                                   gpr_time_from_millis(50, GPR_TIMESPAN)));+      gpr_log(GPR_INFO, ""Finishing request %d"", n);+      responder.Finish(response, grpc::Status::OK, (void*)2);+      result = cq->Next(&tag, &ok);+      EXPECT_EQ((void*)2, tag);+    }+  });++  auto stub = testing::EchoTestService::NewStub(+      CreateChannel(address, InsecureChannelCredentials()));++  for (int i = 0; i < 100; i++) {+    gpr_log(GPR_INFO, ""Sending %d."", i);+    testing::EchoRequest request;++    /////////+    // Comment out the following line to get ok=false due to invalid request.+    // Otherwise, ok=false due to deadline being exceeded.+    /////////+    request.set_message(""foobar"");++    // A simple request with a short deadline. The server will always exceed the+    // deadline, whether due to the sleep or because the server was unable to+    // even fetch the request from the CQ before the deadline elapsed.+    testing::EchoResponse response;+    ::grpc::ClientContext ctx;+    ctx.set_fail_fast(false);+    ctx.set_deadline(std::chrono::system_clock::now() ++                     std::chrono::milliseconds(1));+    grpc::Status status = stub->Echo(&ctx, request, &response);+    EXPECT_EQ(DEADLINE_EXCEEDED, status.error_code());+    gpr_log(GPR_INFO, ""Success."");+  }+  gpr_log(GPR_INFO, ""Done sending RPCs."");++  // Wait for all requests to complete. Hacky but it works.+  gpr_sleep_until(gpr_time_add(gpr_now(GPR_CLOCK_MONOTONIC),+                               gpr_time_from_millis(10, GPR_TIMESPAN)));++  // Shut down everything properly.+  gpr_log(GPR_INFO, ""Shutting down."");+  {+    std::lock_guard<std::mutex> lock(mu);+    shutting_down = true;+  }+  server->Shutdown();+  cq->Shutdown();","I don't mean to comment on this PR, but rather just on the last comment. There is a reason why it is part of the contract that no messages get sent to a CQ after its shutdown has been called. The application is capable of tracking this, since the application was what called shutdown after all. Having a gentler failure mode (rather than just asserting or crashing) might be nice, but doing that correctly, requires additional locking inside grpc, rather than having the application just consider its own shutdown state (which it might be able to do more efficiently than with a general lock). As a matter of course, we do grab a lock on the CQ struct during grpc_cq_begin_op and grpc_completion_queue_shutdown as we manipulate the list of tags associated with this CQ. In the case of begin_op, though, the lock would need to be held for longer for this to work out: not just while inserting into the tag list but during the entire duration of setting up the part of the operation that could lead to a CQ-related effect, since that's the window of vulnerability for another thread invoking shutdown. This is an example of a TOCTTOU vulnerability otherwise.",
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/11454,124331236,2017-06-27T16:46:39Z,test/cpp/server/server_request_call_test.cc,"@@ -0,0 +1,158 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <thread>++#include <grpc++/impl/codegen/config.h>+#include <gtest/gtest.h>++#include <grpc++/server.h>+#include <grpc++/server_builder.h>++#include <grpc++/create_channel.h>+#include <grpc++/security/credentials.h>++#include <grpc/support/log.h>++#include ""src/proto/grpc/testing/echo.grpc.pb.h""+#include ""test/core/util/port.h""++namespace grpc {+namespace {++TEST(ServerRequestCallTest, ShortDeadlineDoesNotCauseOkayFalse) {+  std::mutex mu;+  bool shutting_down = false;++  // grpc server config.+  std::ostringstream s;+  int p = grpc_pick_unused_port_or_die();+  s << ""[::1]:"" << p;+  const string address = s.str();+  testing::EchoTestService::AsyncService service;+  ServerBuilder builder;+  builder.AddListeningPort(address, InsecureServerCredentials());+  auto cq = builder.AddCompletionQueue();+  builder.RegisterService(&service);+  auto server = builder.BuildAndStart();++  // server thread.+  std::thread t([address, &service, &cq, &mu, &shutting_down] {+    for (int n = 0; true; n++) {+      ServerContext ctx;+      testing::EchoRequest req;+      ServerAsyncResponseWriter<testing::EchoResponse> responder(&ctx);++      // if shutting down, don't enqueue a new request.+      {+        std::lock_guard<std::mutex> lock(mu);+        if (!shutting_down) {+          service.RequestEcho(&ctx, &req, &responder, cq.get(), cq.get(),+                              (void*)1);+        }+      }++      bool ok;+      void* tag;+      bool result = cq->Next(&tag, &ok);+      if (!result) {+        break;+      }++      EXPECT_EQ((void*)1, tag);++      // If not shutting down, ok must be true for new requests.+      {+        std::lock_guard<std::mutex> lock(mu);+        if (!shutting_down && !ok) {+          gpr_log(GPR_INFO, ""!ok on request %d"", n);+          abort();+        }++        if (shutting_down && !ok) {+          // Failed connection due to shutdown, continue flushing the CQ.+          continue;+        }+      }++      // Send a simple response after a small delay that would ensure the client+      // deadline is exceeded.+      gpr_log(GPR_INFO, ""Got request %d"", n);+      testing::EchoResponse response;+      response.set_message(""foobar"");+      // A bit of sleep to make sure the deadline elapses.+      gpr_sleep_until(gpr_time_add(gpr_now(GPR_CLOCK_MONOTONIC),+                                   gpr_time_from_millis(50, GPR_TIMESPAN)));+      gpr_log(GPR_INFO, ""Finishing request %d"", n);+      responder.Finish(response, grpc::Status::OK, (void*)2);+      result = cq->Next(&tag, &ok);+      EXPECT_EQ((void*)2, tag);+    }+  });++  auto stub = testing::EchoTestService::NewStub(+      CreateChannel(address, InsecureChannelCredentials()));++  for (int i = 0; i < 100; i++) {+    gpr_log(GPR_INFO, ""Sending %d."", i);+    testing::EchoRequest request;++    /////////+    // Comment out the following line to get ok=false due to invalid request.+    // Otherwise, ok=false due to deadline being exceeded.+    /////////+    request.set_message(""foobar"");++    // A simple request with a short deadline. The server will always exceed the+    // deadline, whether due to the sleep or because the server was unable to+    // even fetch the request from the CQ before the deadline elapsed.+    testing::EchoResponse response;+    ::grpc::ClientContext ctx;+    ctx.set_fail_fast(false);+    ctx.set_deadline(std::chrono::system_clock::now() ++                     std::chrono::milliseconds(1));+    grpc::Status status = stub->Echo(&ctx, request, &response);+    EXPECT_EQ(DEADLINE_EXCEEDED, status.error_code());+    gpr_log(GPR_INFO, ""Success."");+  }+  gpr_log(GPR_INFO, ""Done sending RPCs."");++  // Wait for all requests to complete. Hacky but it works.+  gpr_sleep_until(gpr_time_add(gpr_now(GPR_CLOCK_MONOTONIC),+                               gpr_time_from_millis(10, GPR_TIMESPAN)));++  // Shut down everything properly.+  gpr_log(GPR_INFO, ""Shutting down."");+  {+    std::lock_guard<std::mutex> lock(mu);+    shutting_down = true;+  }+  server->Shutdown();+  cq->Shutdown();","I might have caused confusion in my previous comment. What I was trying to say is that while we ask the users to not inject new events to a cq after shutdown is called, in this PR a new event (request_call) is created internally in C++ server when the previous request comes back. And by this time we do not know whether the cq shutdown has been called. If this is possible, that means user can do everything right but we violates our contract internally.I think if we want to proceed like this, we will need to tell users only to shutdown the server cq when all the requested calls *come back*, which sounds like a reasonable requirement.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11583,124341756,2017-06-27T17:28:14Z,src/python/grpcio_tests/tests/testing/_application_testing_common.py,"@@ -0,0 +1,35 @@+# Copyright 2017 The gRPC Authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import grpc_testing++from tests.testing.proto import requests_pb2+from tests.testing.proto import services_pb2++_FIRST_SERVICE_UNUN = grpc_testing.method('UnUn', requests_pb2.Up,","I agree too, but [Protocol Buffers Python is currently missing support for service descriptors adequately describing services](https://github.com/google/protobuf/issues/3168). (This is why the double creation function is named `channel_fixture_from_descriptions` rather than just `channel_fixture`; it leaves room for the much better `channel_fixture_from_descriptors` in the future.)To dig into the example: the application and its author don't ""have a protobuf stub""; they have a protobuf stub _class_, and instantiation of that class requires a `grpc.Channel`, and if they ""want to mock server responses"" at the _message_ level, not the level of serialized messages, that means that the test infrastructure has to be told at `grpc.Channel`-instantiation-time about which methods have which cardinality and which request and response classes. Until the feature is complete in Protocol Buffers Python and ""the methods _[can]_ come from the service protos"", I think this is the best way.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11583,124342567,2017-06-27T17:31:04Z,src/python/grpcio_testing/grpc_testing/__init__.py,"@@ -0,0 +1,441 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Fixtures for use in testing gRPC Python-using application code.""""""++import abc+import collections++import grpc+import six+++class ChannelRpc(six.with_metaclass(abc.ABCMeta)):","Mmm, carnality... wait, we can't talk about that in the workplace! :-PDo you mean one class for each of the four cardinalities, for a total of four classes? `UnaryUnaryChannelRpc`, `UnaryStreamChannelRpc`, and so forth? I agree that each would present a better, safer, and more helpful API than that presented by the one all-cardinalities `ChannelRpc` right now.Is there something that would allow two classes that I'm not seeing?",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11583,124343030,2017-06-27T17:32:55Z,src/python/grpcio_testing/grpc_testing/__init__.py,"@@ -0,0 +1,441 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Fixtures for use in testing gRPC Python-using application code.""""""++import abc+import collections++import grpc+import six+++class ChannelRpc(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for an in-progress RPC invoked by a system under test.++    Enables users to ""play a server"" for such RPCs by reading requests,+    supplying responses, and supplying status.+    """"""++    @abc.abstractmethod+    def invocation_metadata(self):+        """"""Accesses the metadata passed by the system under test.++        Returns:+          The invocation metadata supplied by the system under test at+            RPC-invocation-time.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def initial_metadata(self, initial_metadata):","`send_initial_metadata` to better indicate that this would be a transmission-to-the-system-under-test, but sure.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11583,124344888,2017-06-27T17:39:40Z,src/python/grpcio_testing/grpc_testing/__init__.py,"@@ -0,0 +1,441 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Fixtures for use in testing gRPC Python-using application code.""""""++import abc+import collections++import grpc+import six+++class ChannelRpc(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for an in-progress RPC invoked by a system under test.++    Enables users to ""play a server"" for such RPCs by reading requests,+    supplying responses, and supplying status.+    """"""++    @abc.abstractmethod+    def invocation_metadata(self):+        """"""Accesses the metadata passed by the system under test.++        Returns:+          The invocation metadata supplied by the system under test at+            RPC-invocation-time.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def initial_metadata(self, initial_metadata):+        """"""Accepts the initial metadata to be passed to the system under test.++        Args:+          initial_metadata: The RPC's initial metadata to be passed to the+            system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_request_as_message(self):+        """"""Draws one of the requests added to the RPC by the system under test.++        Successive calls to this method return requests in the same order in+        which the system under test added them to the RPC.++        Returns:+          A deserialized request message added to the RPC by the system under+            test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def add_responses_as_messages(self, responses):+        """"""Accepts responses to be passed to the system under test.++        Args:+          responses: An iterable of deserialized response messages to be passed+            to the system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def no_more_requests(self):",Client trailing metadata is not a thing that exists.,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11583,124346438,2017-06-27T17:45:20Z,src/python/grpcio_testing/grpc_testing/__init__.py,"@@ -0,0 +1,441 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Fixtures for use in testing gRPC Python-using application code.""""""++import abc+import collections++import grpc+import six+++class ChannelRpc(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for an in-progress RPC invoked by a system under test.++    Enables users to ""play a server"" for such RPCs by reading requests,+    supplying responses, and supplying status.+    """"""++    @abc.abstractmethod+    def invocation_metadata(self):+        """"""Accesses the metadata passed by the system under test.++        Returns:+          The invocation metadata supplied by the system under test at+            RPC-invocation-time.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def initial_metadata(self, initial_metadata):+        """"""Accepts the initial metadata to be passed to the system under test.++        Args:+          initial_metadata: The RPC's initial metadata to be passed to the+            system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_request_as_message(self):+        """"""Draws one of the requests added to the RPC by the system under test.++        Successive calls to this method return requests in the same order in+        which the system under test added them to the RPC.++        Returns:+          A deserialized request message added to the RPC by the system under+            test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def add_responses_as_messages(self, responses):+        """"""Accepts responses to be passed to the system under test.++        Args:+          responses: An iterable of deserialized response messages to be passed+            to the system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def no_more_requests(self):+        """"""Blocks until the system under test has closed the request stream.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def cancelled(self):+        """"""Blocks until the system under test has cancelled the RPC.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def terminate(self, trailing_metadata, code, details):+        """"""Accepts the RPC's trailing metadata, status code, and status details.++        This method implicitly closes the RPC's response stream and, from the+        perspective of the test code that is ""playing server"", terminates the+        RPC.+        """"""+        raise NotImplementedError()+++class ChannelFixture(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for a channel on which a system under test invokes RPCs.""""""++    @abc.abstractmethod+    def channel(self):+        """"""Accesses the grpc.Channel on which the system under test makes RPCs.++        Returns:+          The grpc.Channel on which the system under test should make RPCs.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_rpc_by_service_and_method_names(self, service_name, method_name):","I think it worsens the use case of a system that makes five (or two, or twenty) concurrent RPCs of five (or two, or twenty) different RPC methods?To be fair: if a system under test makes twenty concurrent RPCs of the _same_ RPC method, the test infrastructure doesn't afford a way for them to be distinguished (as in real gRPC any such distinction would have to be in-band). But for different RPC methods, which have different message classes and cardinalities, I think this method makes more sense as ""pass to me any in-flight RPC of this RPC method"" rather than ""pass to me any in-flight RPC"".",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11583,124346958,2017-06-27T17:47:23Z,src/python/grpcio_testing/grpc_testing/__init__.py,"@@ -0,0 +1,441 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Fixtures for use in testing gRPC Python-using application code.""""""++import abc+import collections++import grpc+import six+++class ChannelRpc(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for an in-progress RPC invoked by a system under test.++    Enables users to ""play a server"" for such RPCs by reading requests,+    supplying responses, and supplying status.+    """"""++    @abc.abstractmethod+    def invocation_metadata(self):+        """"""Accesses the metadata passed by the system under test.++        Returns:+          The invocation metadata supplied by the system under test at+            RPC-invocation-time.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def initial_metadata(self, initial_metadata):+        """"""Accepts the initial metadata to be passed to the system under test.++        Args:+          initial_metadata: The RPC's initial metadata to be passed to the+            system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_request_as_message(self):+        """"""Draws one of the requests added to the RPC by the system under test.++        Successive calls to this method return requests in the same order in+        which the system under test added them to the RPC.++        Returns:+          A deserialized request message added to the RPC by the system under+            test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def add_responses_as_messages(self, responses):+        """"""Accepts responses to be passed to the system under test.++        Args:+          responses: An iterable of deserialized response messages to be passed+            to the system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def no_more_requests(self):+        """"""Blocks until the system under test has closed the request stream.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def cancelled(self):+        """"""Blocks until the system under test has cancelled the RPC.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def terminate(self, trailing_metadata, code, details):+        """"""Accepts the RPC's trailing metadata, status code, and status details.++        This method implicitly closes the RPC's response stream and, from the+        perspective of the test code that is ""playing server"", terminates the+        RPC.+        """"""+        raise NotImplementedError()+++class ChannelFixture(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for a channel on which a system under test invokes RPCs.""""""++    @abc.abstractmethod+    def channel(self):+        """"""Accesses the grpc.Channel on which the system under test makes RPCs.++        Returns:+          The grpc.Channel on which the system under test should make RPCs.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_rpc_by_service_and_method_names(self, service_name, method_name):+        """"""Draws an RPC currently being made by the system under test.++        If no RPC with the given names is currently being made by the system+        under test, this method blocks until such an RPC is made by the system+        under test.++        This method is mutative; for each RPC made by the system under test+        exactly one ChannelRpc will be returned from this method. If two calls+        to this method are made by test code but only one RPC is invoked by the+        system under test, the second call to this method will block+        indefinitely.++        Args:+          service_name: An RPC service name (such as ""my_package.MyService"").+          method_name: An RPC method name (such as ""MyMethod"").++        Returns:+          A ChannelRpc that allows test code to ""play server"" and interact with+            the system under test.+        """"""+        raise NotImplementedError()+++class ServerRpc(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for an in-progress RPC serviced by a system under test.++    Enables users to ""play a client"" for such RPCs by supplying requests,+    reading responses, and cancelling.+    """"""++    @abc.abstractmethod+    def initial_metadata(self):+        """"""Accesses the initial metadata emitted by the system under test.++        This method blocks until the system under test has added initial+        metadata to the RPC (or has provided one or more response messages or+        has terminated the RPC, either of which will cause gRPC Python to+        synthesize initial metadata for the RPC).++        Returns:+          The initial metadata for the RPC.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def add_requests_as_messages(self, requests):+        """"""Accepts requests to be passed to the system under test.++        Args:+          requests: An iterable of deserialized request messages to be passed+            to the system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_response_as_message(self):+        """"""Draws one of the responses added to the RPC by the system under test.++        Successive calls to this method return responses in the same order in+        which the system under test added them to the RPC.++        Returns:+          A deserialized response message added to the RPC by the system under+            test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def no_more_requests(self):+        """"""Indicates the end of the RPC's request stream.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def cancel(self):+        """"""Cancel's the RPC.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def terminate(self):",Doc string error; this method _does_ return the RPC's trailing metadata and status. Will fix in next revision.,
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/11607,124349520,2017-06-27T17:56:57Z,src/core/tsi/gts_transport_security.c,"@@ -0,0 +1,35 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/core/tsi/gts_transport_security.h""+#include <grpc/support/alloc.h>++static gts_shared_resource* gts_resource = NULL;","The pointer will be set during the time gts tsi handshaker is created (in a lazy manner), and I think the main reason is to save resources i.e., if there is no handshake performed, we will not create any shared resources including tsi thread, cq and so on.  How do you think? ",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11583,124350933,2017-06-27T18:02:05Z,src/python/grpcio_testing/grpc_testing/_channel.py,"@@ -0,0 +1,753 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Channel fixtures.""""""++import collections+import logging+import threading++import grpc+import grpc_testing+from grpc_testing import _common++_NOT_YET_OBSERVED = object()+++class _RpcState(object):++    def __init__(self, invocation_metadata, requests, requests_closed):+        self.condition = threading.Condition()+        self.invocation_metadata = invocation_metadata+        self.requests = requests+        self.requests_closed = requests_closed+        self.initial_metadata = None+        self.responses = []+        self.trailing_metadata = None+        self.code = None+        self.details = None+++def _state_add_request(state, request):+    with state.condition:+        if state.code is None and not state.requests_closed:+            state.requests.append(request)+            state.condition.notify_all()+            return True+        else:+            return False+++def _state_no_more_requests(state):+    with state.condition:+        if state.code is None and not state.requests_closed:+            state.requests_closed = True+            state.condition.notify_all()+++def _state_take_response(state):+    with state.condition:+        while True:+            if state.code is grpc.StatusCode.OK:+                if state.responses:+                    response = state.responses.pop(0)+                    return _common.ChannelRpcRead(response, None, None, None)+                else:+                    return _common.ChannelRpcRead(None, state.trailing_metadata,+                                                  grpc.StatusCode.OK,+                                                  state.details)+            elif state.code is None:+                if state.responses:+                    response = state.responses.pop(0)+                    return _common.ChannelRpcRead(response, None, None, None)+                else:+                    state.condition.wait()+            else:+                return _common.ChannelRpcRead(None, state.trailing_metadata,+                                              state.code, state.details)+++def _state_cancel(state, code, details):+    with state.condition:+        if state.code is None:+            if state.initial_metadata is None:+                state.initial_metadata = _common.FUSSED_EMPTY_METADATA+            state.trailing_metadata = _common.FUSSED_EMPTY_METADATA+            state.code = code+            state.details = details+            state.condition.notify_all()+            return True+        else:+            return False+++def _state_terminate(state):+    with state.condition:+        while True:+            if state.code is None:+                state.condition.wait()+            else:+                return state.trailing_metadata, state.code, state.details+++def _state_is_active(state):+    with state.condition:+        return state.code is None+++def _state_time_remaining(unused_state):+    raise NotImplementedError()+++def _state_add_callback(unused_state, unused_callback):+    raise NotImplementedError()+++def _state_initial_metadata(state):+    with state.condition:+        while True:+            if state.initial_metadata is None:+                if state.code is None:+                    state.condition.wait()+                else:+                    return _common.FUSSED_EMPTY_METADATA+            else:+                return state.initial_metadata+++def _state_trailing_metadata(state):+    with state.condition:+        while state.trailing_metadata is None:+            state.condition.wait()+        return state.trailing_metadata+++def _state_code(state):+    with state.condition:+        while state.code is None:+            state.condition.wait()+        return state.code+++def _state_details(state):+    with state.condition:+        while state.details is None:+            state.condition.wait()+        return state.details+++def _handler_cancel(handler):+    return handler.cancel(grpc.StatusCode.CANCELLED, 'Locally cancelled!')+++def _handler_is_active(handler):+    return handler.is_active()+++def _handler_time_remaining(unused_handler):+    raise NotImplementedError()+++def _handler_add_callback(handler, callback):+    return handler.add_callback(callback)+++def _handler_initial_metadata(handler):+    return handler.initial_metadata()+++def _handler_trailing_metadata(handler):+    trailing_metadata, unused_code, unused_details = handler.terminate()+    return trailing_metadata+++def _handler_code(handler):+    unused_trailing_metadata, code, unused_details = handler.terminate()+    return code+++def _handler_details(handler):+    unused_trailing_metadata, unused_code, details = handler.terminate()+    return details+++class _Call(grpc.Call):++    def __init__(self, handler):+        self._handler = handler++    def cancel(self):+        _handler_cancel(self._handler)++    def is_active(self):+        return _handler_is_active(self._handler)","There's kind of a long story here that @kpayson64 already knows, and it starts with [the _Rendezvous class in the current gRPC Python](https://github.com/grpc/grpc/blob/71a78e92cb9f6af405e6f80c9a31c408c4025095/src/python/grpcio/grpc/_channel.py#L238). That's a class that implements a bunch of interfaces, but at each point where an instance of the class is passed from gRPC Python to the application the instance that is passed is only valid for use according to some subset of those interfaces. Authors have introspected the instance, seen a lot of methods that look legitimate, and dug themselves into holes trying crazy things. The motivation in this module for pulling all the behavior out into module-scope functions is so that we can have these several classes that each only implement the combinations of interfaces that are needed to be passed, and the indirection is so that exactly all logic is done in shared module-scope functions. It's only a little indirection, so that's not an issue, and it's a lot of text on the page, but it's module-private implementation inside package-private module, so the code golfing of using dynamic magic to shrink it down textually can wait until later.I guess the short answer is ""this prototypes something I've been wanting to try in the non-test codebase for a while"".",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11607,124355543,2017-06-27T18:19:22Z,src/core/tsi/transport_security.h,"@@ -111,6 +111,9 @@ tsi_result tsi_construct_allocated_string_peer_property( tsi_result tsi_construct_string_peer_property_from_cstring(     const char *name, const char *value, tsi_peer_property *property); +/* Destroy plugin registration funcion. */+void tsi_register_destroy_plugin(void (*destroy)(void));","I don't think the dependency issue is a problem, since any given TSI implementation would only be used if it is actually registered, in which case we will depend on it anyway.Stepping back a bit, I think there are two basic choices here:1. We use the existing gRPC plugin mechanism for TSI implementations.2. We add a new registration mechanism for TSI implementations.As I mentioned earlier, we do have a number of cases where we have gone with option 2, such as our existing resolver and LB policy APIs.  However, the reason that we added a new mechanism in those cases is that they are designed to register an implementation by name such that it can be selected by name at run-time, so there is factory machinery involved.  I don't think that's the case for the TSI implementation -- correct me if I'm wrong, but my understanding is that the TSI implementation is essentially chosen by the credentials, which are passed into gRPC via the API.  In that case, all we really need for TSI implementations is a hook to do global initialization and destruction, so I think the gRPC plugin mechanism will work fine.If we do support a separate registration mechanism for TSI implementations, then the idea would be that the application would need to call `tsi_register_implementation()` before calling `grpc_init()`.  Then `grpc_init()` would call the init function of every TSI implementation that was registered, and `grpc_shutdown()` would call the destroy function of every TSI implementation that was registered.  But as I said above, this is functionally equivalent to just calling the init and destroy functions as a gRPC plugin.Given the above, I think we should just use the existing gRPC plugin mechanism instead of creating a new one.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11583,124355765,2017-06-27T18:20:06Z,src/python/grpcio_testing/grpc_testing/_time.py,"@@ -0,0 +1,223 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Test times.""""""++import collections+import logging+import threading+import time as _time++import grpc+import grpc_testing+++def _call(behaviors):+    for behavior in behaviors:+        try:+            behavior()+        except Exception:  # pylint: disable=broad-except+            logging.exception('Exception calling behavior?')+++def _call_in_thread(behaviors):+    calling = threading.Thread(target=_call, args=(behaviors,))+    calling.start()+    calling.join()+++class _State(object):++    def __init__(self):+        self.condition = threading.Condition()+        self.times_to_behaviors = collections.defaultdict(list)+        self.behaviors_to_times = {}+++class _Delta(+        collections.namedtuple('_Delta',+                               ('mature_behaviors', 'earliest_mature_time',+                                'earliest_immature_time',))):+    pass+++def _process(state, now):+    mature_behaviors = []+    earliest_mature_time = None+    while state.times_to_behaviors:+        earliest_time = min(state.times_to_behaviors)+        if earliest_time <= now:+            if earliest_mature_time is None:+                earliest_mature_time = earliest_time+            earliest_mature_behaviors = state.times_to_behaviors.pop(+                earliest_time)+            for mature_behavior in earliest_mature_behaviors:+                state.behaviors_to_times.pop(mature_behavior)+            mature_behaviors.extend(earliest_mature_behaviors)+        else:+            earliest_immature_time = earliest_time+            break+    else:+        earliest_immature_time = None+    return _Delta(mature_behaviors, earliest_mature_time,+                  earliest_immature_time)+++class _Future(grpc.Future):++    def __init__(self, state, behavior):+        self._state = state+        self._behavior = behavior+        self._cancelled = False++    def cancel(self):+        with self._state.condition:+            time = self._state.behaviors_to_times.pop(self._behavior, None)+            if time is None:+                return False+            else:+                self._state.times_to_behaviors[time].remove(self._behavior)+                if not self._state.times_to_behaviors[time]:+                    self._state.times_to_behaviors.pop(time)+                    self._state.condition.notify_all()+                self._cancelled = True+                return True++    def cancelled(self):+        with self._state.condition:+            return self._cancelled++    def running(self):+        raise NotImplementedError()++    def done(self):+        raise NotImplementedError()++    def result(self, timeout=None):+        raise NotImplementedError()++    def exception(self, timeout=None):+        raise NotImplementedError()++    def traceback(self, timeout=None):+        raise NotImplementedError()++    def add_done_callback(self, fn):+        raise NotImplementedError()+++class RealTime(grpc_testing.Time):","Adding a sorted list would make it more complex behaviorally but more performant under huge workloads (or acceptably performant for huge workloads for which this implementation's performance would be unacceptable). I don't know of any huge workloads forecast for this unit test framework, but I'm open to seeing that happen in the future?(In all fairness: if Python's standard library had [a sort-maintaining dictionary](https://docs.oracle.com/javase/8/docs/api/java/util/TreeMap.html), I'd have used it. :-P)As for an interrupt: I've never made much use of signals so there's a lack-of-familiarity dimension to their not being used here, but... wouldn't they count as ""global"" (process-wide) state that might interfere with process-wide state used by the system under test? Implementing a unit test library, shouldn't I refrain from using process-wide state when I have the capacity to do so?",
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/11607,124355934,2017-06-27T18:20:44Z,src/core/tsi/transport_security.h,"@@ -111,6 +111,9 @@ tsi_result tsi_construct_allocated_string_peer_property( tsi_result tsi_construct_string_peer_property_from_cstring(     const char *name, const char *value, tsi_peer_property *property); +/* Destroy plugin registration funcion. */+void tsi_register_destroy_plugin(void (*destroy)(void));","Let me be more specific on the second part of my comment. If we want to support lazy registration  i.e., register or initialize tsi implementation-specific (e.g., gts-specific) global resources if and only if the corresponding implementation is used in the user's code, the information will not be available at the time grpc_init() is called, and therefore, can not invoked correctly. ",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11607,124358225,2017-06-27T18:29:03Z,src/core/tsi/transport_security.h,"@@ -111,6 +111,9 @@ tsi_result tsi_construct_allocated_string_peer_property( tsi_result tsi_construct_string_peer_property_from_cstring(     const char *name, const char *value, tsi_peer_property *property); +/* Destroy plugin registration funcion. */+void tsi_register_destroy_plugin(void (*destroy)(void));","I understand that.  There will be some things that need to be initialized preemptively at initialization time and others that need to be initialized lazily, and that's fine.  If a particular implementation does not have anything that needs to be initialized preemptively, then the preemptive initialization can be a no-op.  But we should still offer a preemptive initialization hook for the cases where it is needed.In this case, I suspect that you will need both preemptive and lazy initialization.  As per my comment above, I think you will need to initialize the mutex preemptively, and you can then use that mutex to initialize the channel and CQ lazily.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11583,124359329,2017-06-27T18:32:58Z,src/python/grpcio_tests/tests/testing/_client_application.py,"@@ -0,0 +1,237 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""An example gRPC Python-using client-side application.""""""++import collections+import enum+import threading++import grpc+from tests.unit.framework.common import test_constants++from tests.testing.proto import services_pb2_grpc++from tests.testing import _application_common+++@enum.unique+class Scenario(enum.Enum):+    UNARY_UNARY = 'unary unary'+    UNARY_STREAM = 'unary stream'+    STREAM_UNARY = 'stream unary'+    STREAM_STREAM = 'stream stream'+    CONCURRENT_STREAM_UNARY = 'concurrent stream unary'+    CONCURRENT_STREAM_STREAM = 'concurrent stream stream'+    CANCEL_UNARY_UNARY = 'cancel unary unary'+    CANCEL_UNARY_STREAM = 'cancel unary stream'+    INFINITE_REQUEST_STREAM = 'infinite request stream'+++class Outcome(collections.namedtuple('Outcome', ('kind', 'code', 'details'))):+    """"""Outcome of a client application scenario.++    Attributes:+      kind: A Kind value describing the overall kind of scenario execution.+      code: A grpc.StatusCode value. Only valid if kind is Kind.RPC_ERROR.+      details: A status details string. Only valid if kind is Kind.RPC_ERROR.+    """"""++    @enum.unique+    class Kind(enum.Enum):+        SATISFACTORY = 'satisfactory'+        UNSATISFACTORY = 'unsatisfactory'+        RPC_ERROR = 'rpc error'+++_SATISFACTORY_OUTCOME = Outcome(Outcome.Kind.SATISFACTORY, None, None)+_UNSATISFACTORY_OUTCOME = Outcome(Outcome.Kind.UNSATISFACTORY, None, None)+++class _Pipe(object):++    def __init__(self):+        self._condition = threading.Condition()+        self._values = []+        self._open = True++    def __iter__(self):+        return self++    def _next(self):+        with self._condition:+            while True:",When inside the loop there are only two branches I'm a little equivocal but for three or more I definitely like this implementation better.With the exception of combinatorially explosive boilerplate I'm mostly blind to textual-length-of-code-on-the-page (and so much happier for it!).,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11583,124360743,2017-06-27T18:38:52Z,src/python/grpcio_tests/tests/testing/_client_application.py,"@@ -0,0 +1,237 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""An example gRPC Python-using client-side application.""""""++import collections+import enum+import threading++import grpc+from tests.unit.framework.common import test_constants++from tests.testing.proto import services_pb2_grpc++from tests.testing import _application_common+++@enum.unique+class Scenario(enum.Enum):+    UNARY_UNARY = 'unary unary'+    UNARY_STREAM = 'unary stream'+    STREAM_UNARY = 'stream unary'+    STREAM_STREAM = 'stream stream'+    CONCURRENT_STREAM_UNARY = 'concurrent stream unary'+    CONCURRENT_STREAM_STREAM = 'concurrent stream stream'+    CANCEL_UNARY_UNARY = 'cancel unary unary'+    CANCEL_UNARY_STREAM = 'cancel unary stream'+    INFINITE_REQUEST_STREAM = 'infinite request stream'+++class Outcome(collections.namedtuple('Outcome', ('kind', 'code', 'details'))):+    """"""Outcome of a client application scenario.++    Attributes:+      kind: A Kind value describing the overall kind of scenario execution.+      code: A grpc.StatusCode value. Only valid if kind is Kind.RPC_ERROR.+      details: A status details string. Only valid if kind is Kind.RPC_ERROR.+    """"""++    @enum.unique+    class Kind(enum.Enum):+        SATISFACTORY = 'satisfactory'+        UNSATISFACTORY = 'unsatisfactory'+        RPC_ERROR = 'rpc error'+++_SATISFACTORY_OUTCOME = Outcome(Outcome.Kind.SATISFACTORY, None, None)+_UNSATISFACTORY_OUTCOME = Outcome(Outcome.Kind.UNSATISFACTORY, None, None)+++class _Pipe(object):++    def __init__(self):+        self._condition = threading.Condition()+        self._values = []+        self._open = True++    def __iter__(self):+        return self++    def _next(self):+        with self._condition:+            while True:+                if self._values:+                    return self._values.pop(0)+                elif not self._open:+                    raise StopIteration()+                else:+                    self._condition.wait()++    def __next__(self):  # (Python 3 Iterator Protocol)+        return self._next()++    def next(self):  # (Python 2 Iterator Protocol)+        return self._next()++    def add(self, value):+        with self._condition:++            self._values.append(value)+            self._condition.notify_all()++    def close(self):+        with self._condition:+            self._open = False+            self._condition.notify_all()+++def _run_unary_unary(stub):+    response = stub.UnUn(_application_common.UNARY_UNARY_REQUEST)+    if _application_common.UNARY_UNARY_RESPONSE == response:+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def _run_unary_stream(stub):+    response_iterator = stub.UnStre(_application_common.UNARY_STREAM_REQUEST)+    try:+        next(response_iterator)+    except StopIteration:+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def _run_stream_unary(stub):+    response, call = stub.StreUn.with_call(+        iter((_application_common.STREAM_UNARY_REQUEST,) * 3))+    if (_application_common.STREAM_UNARY_RESPONSE == response and+            call.code() is grpc.StatusCode.OK):+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def _run_stream_stream(stub):+    request_pipe = _Pipe()+    response_iterator = stub.StreStre(iter(request_pipe))+    request_pipe.add(_application_common.STREAM_STREAM_REQUEST)+    first_responses = next(response_iterator), next(response_iterator),+    request_pipe.add(_application_common.STREAM_STREAM_REQUEST)+    second_responses = next(response_iterator), next(response_iterator),+    request_pipe.close()+    try:+        next(response_iterator)+    except StopIteration:+        unexpected_extra_response = False+    else:+        unexpected_extra_response = True+    if (first_responses == _application_common.TWO_STREAM_STREAM_RESPONSES and+            second_responses == _application_common.TWO_STREAM_STREAM_RESPONSES+            and not unexpected_extra_response):+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def _run_concurrent_stream_unary(stub):+    future_calls = tuple(+        stub.StreUn.future(+            iter((_application_common.STREAM_UNARY_REQUEST,) * 3))+        for _ in range(test_constants.THREAD_CONCURRENCY))+    for future_call in future_calls:+        if future_call.code() is grpc.StatusCode.OK:+            response = future_call.result()+            if _application_common.STREAM_UNARY_RESPONSE != response:+                return _UNSATISFACTORY_OUTCOME+        else:+            return _UNSATISFACTORY_OUTCOME+    else:+        return _SATISFACTORY_OUTCOME+++def _run_concurrent_stream_stream(stub):+    condition = threading.Condition()+    outcomes = [None] * test_constants.RPC_CONCURRENCY++    def run_stream_stream(index):+        outcome = _run_stream_stream(stub)+        with condition:+            outcomes[index] = outcome+            condition.notify()++    for index in range(test_constants.RPC_CONCURRENCY):+        thread = threading.Thread(target=run_stream_stream, args=(index,))+        thread.start()+    with condition:+        while True:+            if all(outcomes):+                for outcome in outcomes:+                    if outcome.kind is not Outcome.Kind.SATISFACTORY:+                        return _UNSATISFACTORY_OUTCOME+                else:+                    return _SATISFACTORY_OUTCOME+            else:+                condition.wait()+++def _run_cancel_unary_unary(stub):+    response_future_call = stub.UnUn.future(+        _application_common.UNARY_UNARY_REQUEST)+    initial_metadata = response_future_call.initial_metadata()+    cancelled = response_future_call.cancel()+    if initial_metadata is not None and cancelled:+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def _run_infinite_request_stream(stub):++    def infinite_request_iterator():+        while True:+            yield _application_common.STREAM_UNARY_REQUEST++    response_future_call = stub.StreUn.future(+        infinite_request_iterator(),+        timeout=_application_common.INFINITE_REQUEST_STREAM_TIMEOUT)+    if response_future_call.code() is grpc.StatusCode.DEADLINE_EXCEEDED:+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def run(scenario, channel):+    stub = services_pb2_grpc.FirstServiceStub(channel)","I think that this is a big deal to avoid having: opinions differ about whether the generated `_pb2_grpc` module is a part of gRPC Python or a part of the application, but it is definitely part of the code run during ""production"" and [I'm biased towards including it rather than excluding it](https://www.youtube.com/watch?v=Xu5EhKVZdV8).But... I'm not even seeing what you're suggesting here. What is the `my_service` in `stub = my_service.stub()`? How is it created, and is it created in the application under test, the application's tests, or somewhere else?",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11583,124362569,2017-06-27T18:46:05Z,src/python/grpcio_tests/tests/testing/_connection_test.py,"@@ -0,0 +1,104 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import time+import unittest++from grpc.framework.foundation import logging_pool+import grpc_testing++from tests.testing import _application_testing_common+from tests.testing import _client_application+from tests.testing import _server_application+++class ConnectionTest(unittest.TestCase):++    def setUp(self):+        self._application_thread_pool = logging_pool.pool(1)+        self._fake_time = grpc_testing.fake_time(time.time())+        self._real_time = grpc_testing.real_time()+        self._fake_time_connection = (grpc_testing.connection_from_descriptions(+            {","Although the `FirstServiceServicer` class (an instance of which is part of the system under test here) takes no construction parameters and could be a module-scope constant singleton within the Python interpreter; I'd like to retain construction here because I think it's important to exemplify constructing the entire system-under-test within the test's `setUp` method.Not just important, but correct-with-respect-to-testing-orthodoxy too. :-)Is that worth putting in a comment?",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11583,124363241,2017-06-27T18:48:47Z,src/python/grpcio_tests/tests/testing/_connection_test.py,"@@ -0,0 +1,104 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import time+import unittest++from grpc.framework.foundation import logging_pool+import grpc_testing++from tests.testing import _application_testing_common+from tests.testing import _client_application+from tests.testing import _server_application+++class ConnectionTest(unittest.TestCase):++    def setUp(self):+        self._application_thread_pool = logging_pool.pool(1)+        self._fake_time = grpc_testing.fake_time(time.time())+        self._real_time = grpc_testing.real_time()+        self._fake_time_connection = (grpc_testing.connection_from_descriptions(+            {+                _server_application.FirstServiceServicer():+                _application_testing_common.FIRST_SERVICE+            }, self._fake_time))+        self._real_time_connection = (grpc_testing.connection_from_descriptions(+            {+                _server_application.FirstServiceServicer():+                _application_testing_common.FIRST_SERVICE+            }, self._real_time))++    def tearDown(self):+        self._application_thread_pool.shutdown(wait=True)++    def test_successful_unary_unary(self):+        application_future = self._application_thread_pool.submit(+            _client_application.run, _client_application.Scenario.UNARY_UNARY,+            self._fake_time_connection.channel())+        application_return_value = application_future.result()","[Testing orthodoxy](http://wiki.c2.com/?ArrangeActAssert): accessing the application future's result is part of the test action (because it's not just a simple getter but rather something that blocks until the system under test has returned and raises an exception if the system under test raised an exception).Once the value has been obtained, the test action is over and the test assertions happen after the blank line.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11583,124363929,2017-06-27T18:51:33Z,src/python/grpcio_tests/tests/testing/_server_application.py,"@@ -0,0 +1,67 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""An example gRPC Python-using server-side application.""""""++import grpc++# requests_pb2 is a semantic dependency of this module.+from tests.testing.proto import requests_pb2  # pylint: disable=unused-import+from tests.testing.proto import services_pb2+from tests.testing.proto import services_pb2_grpc++from tests.testing import _application_common+++class FirstServiceServicer(services_pb2_grpc.FirstServiceServicer):","It'd be a little textual convenience and a radical departure from the way the system under test is expected to be used in non-test production circumstances.While this example illustrates a servicer implementation that takes no construction parameters, real servicer implementations are expected to take application-determined, application-semantic construction parameters at least some of the time. Presumably the testing framework wouldn't be able to infer how to instantiate the servicer class then?",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11583,124366455,2017-06-27T19:01:40Z,src/python/grpcio_tests/tests/testing/_time_test.py,"@@ -0,0 +1,111 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import threading+import time+import random+import unittest++import grpc_testing++_QUANTUM = 0.3+_MANY = 10000+++class TimeTest(object):++    def test_sleep_for(self):+        start_time = self._time.time()+        self._time.sleep_for(_QUANTUM)+        end_time = self._time.time()++        self.assertLessEqual(start_time + _QUANTUM, end_time)++    def test_sleep_until(self):+        start_time = self._time.time()+        self._time.sleep_until(start_time + _QUANTUM)+        end_time = self._time.time()++        self.assertLessEqual(start_time + _QUANTUM, end_time)++    def test_call_in(self):+        event = threading.Event()++        self._time.call_in(event.set, _QUANTUM)+        self._time.sleep_for(_QUANTUM * 2)++        self.assertTrue(event.is_set())++    def test_call_at(self):+        event = threading.Event()++        self._time.call_at(event.set, self._time.time() + _QUANTUM)+        self._time.sleep_for(_QUANTUM * 2)++        self.assertTrue(event.is_set())++    def test_cancel(self):+        event = threading.Event()++        future = self._time.call_in(event.set, _QUANTUM * 2)+        self._time.sleep_for(_QUANTUM)+        cancelled = future.cancel()+        self._time.sleep_for(_QUANTUM * 2)++        if cancelled:+            self.assertFalse(event.is_set())+            self.assertTrue(future.cancelled())+        else:+            self.assertTrue(event.is_set())++    def test_many(self):+        test_events = tuple(threading.Event() for _ in range(_MANY))+        test_futures = {}+        other_futures = []++        for test_event in test_events:+            test_futures[test_event] = self._time.call_in(+                test_event.set, _QUANTUM * (2 + random.random()))+        for _ in range(_MANY):+            other_futures.append(+                self._time.call_in(threading.Event().set, _QUANTUM * 1000 *+                                   random.random()))+        self._time.sleep_for(_QUANTUM)+        cancelled = set()+        for test_event, test_future in test_futures.items():+            if bool(random.randint(0, 1)) and test_future.cancel():",A pathological scheduler may not get arround to evaluating the cancel call until long after the event has been set. (Right?),
29667874,griffithjames,https://api.github.com/repos/grpc/grpc/pulls/11583,124376260,2017-06-27T19:45:19Z,src/python/grpcio_testing/grpc_testing/_channel.py,"@@ -0,0 +1,753 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Channel fixtures.""""""++import collections+import logging+import threading++import grpc+import grpc_testing+from grpc_testing import _common++_NOT_YET_OBSERVED = object()+++class _RpcState(object):++    def __init__(self, invocation_metadata, requests, requests_closed):+        self.condition = threading.Condition()+        self.invocation_metadata = invocation_metadata+        self.requests = requests+        self.requests_closed = requests_closed+        self.initial_metadata = None+        self.responses = []+        self.trailing_metadata = None+        self.code = None+        self.details = None+++def _state_add_request(state, request):+    with state.condition:+        if state.code is None and not state.requests_closed:+            state.requests.append(request)+            state.condition.notify_all()+            return True+        else:+            return False+++def _state_no_more_requests(state):+    with state.condition:+        if state.code is None and not state.requests_closed:+            state.requests_closed = True+            state.condition.notify_all()+++def _state_take_response(state):+    with state.condition:+        while True:+            if state.code is grpc.StatusCode.OK:+                if state.responses:+                    response = state.responses.pop(0)+                    return _common.ChannelRpcRead(response, None, None, None)+                else:+                    return _common.ChannelRpcRead(None, state.trailing_metadata,+                                                  grpc.StatusCode.OK,+                                                  state.details)+            elif state.code is None:+                if state.responses:+                    response = state.responses.pop(0)+                    return _common.ChannelRpcRead(response, None, None, None)+                else:+                    state.condition.wait()+            else:+                return _common.ChannelRpcRead(None, state.trailing_metadata,+                                              state.code, state.details)+++def _state_cancel(state, code, details):+    with state.condition:+        if state.code is None:+            if state.initial_metadata is None:+                state.initial_metadata = _common.FUSSED_EMPTY_METADATA+            state.trailing_metadata = _common.FUSSED_EMPTY_METADATA+            state.code = code+            state.details = details+            state.condition.notify_all()+            return True+        else:+            return False+++def _state_terminate(state):+    with state.condition:+        while True:","I don't have a strong feeling either way. My impulse is that if there's only way to leave the loop, might as well make it the loop condition.I do like the brevity, I will confess.",
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/11607,124385670,2017-06-27T20:24:36Z,src/core/tsi/transport_security.h,"@@ -111,6 +111,9 @@ tsi_result tsi_construct_allocated_string_peer_property( tsi_result tsi_construct_string_peer_property_from_cstring(     const char *name, const char *value, tsi_peer_property *property); +/* Destroy plugin registration funcion. */+void tsi_register_destroy_plugin(void (*destroy)(void));","Regarding the first issue, if you think dependency is not a problem, I think I will use the existing grpc plugin mechanisms instead of creating a new registration mechanism. I will also remove tsi_init and tsi_destroy from TSI since corresponding TSI implementation APIs will be registered to grpc directly, instead of going through TSI. ",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/11583,124394304,2017-06-27T21:00:02Z,src/python/grpcio_testing/grpc_testing/_channel.py,"@@ -0,0 +1,753 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Channel fixtures.""""""++import collections+import logging+import threading++import grpc+import grpc_testing+from grpc_testing import _common++_NOT_YET_OBSERVED = object()+++class _RpcState(object):++    def __init__(self, invocation_metadata, requests, requests_closed):+        self.condition = threading.Condition()+        self.invocation_metadata = invocation_metadata+        self.requests = requests+        self.requests_closed = requests_closed+        self.initial_metadata = None+        self.responses = []+        self.trailing_metadata = None+        self.code = None+        self.details = None+++def _state_add_request(state, request):+    with state.condition:+        if state.code is None and not state.requests_closed:+            state.requests.append(request)+            state.condition.notify_all()+            return True+        else:+            return False+++def _state_no_more_requests(state):+    with state.condition:+        if state.code is None and not state.requests_closed:+            state.requests_closed = True+            state.condition.notify_all()+++def _state_take_response(state):+    with state.condition:+        while True:+            if state.code is grpc.StatusCode.OK:+                if state.responses:+                    response = state.responses.pop(0)+                    return _common.ChannelRpcRead(response, None, None, None)+                else:+                    return _common.ChannelRpcRead(None, state.trailing_metadata,+                                                  grpc.StatusCode.OK,+                                                  state.details)+            elif state.code is None:+                if state.responses:+                    response = state.responses.pop(0)+                    return _common.ChannelRpcRead(response, None, None, None)+                else:+                    state.condition.wait()+            else:+                return _common.ChannelRpcRead(None, state.trailing_metadata,+                                              state.code, state.details)+++def _state_cancel(state, code, details):+    with state.condition:+        if state.code is None:+            if state.initial_metadata is None:+                state.initial_metadata = _common.FUSSED_EMPTY_METADATA+            state.trailing_metadata = _common.FUSSED_EMPTY_METADATA+            state.code = code+            state.details = details+            state.condition.notify_all()+            return True+        else:+            return False+++def _state_terminate(state):+    with state.condition:+        while True:","I am in favor of @griffithjames's version, as I think it's making the loop exit invariant clear (and in the English readability sense). Frankly, I feel an argument against this is an argument against conditional `while` loops in general.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11621,124407445,2017-06-27T21:59:00Z,src/core/lib/iomgr/closure.h,"@@ -42,7 +42,9 @@ typedef struct grpc_closure_list {  *  * \param arg Arbitrary input.  * \param error GRPC_ERROR_NONE if no error occurred, otherwise some grpc_error- *              describing what went wrong */+ *              describing what went wrong.+ *              Error contract: it is not the cb's job to unref this error;","FWIW, note that this is already documented here:https://github.com/grpc/grpc/blob/master/doc/core/grpc-error.md",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/11621,124414346,2017-06-27T22:38:30Z,src/core/lib/transport/transport.h,"@@ -198,6 +198,8 @@ struct grpc_transport_stream_op_batch_payload {         grpc_chttp2_grpc_status_to_http2_error. Send a RST_STREAM with this         error. */   struct {+    // Error contract: the recipient of cancel_error must cause cancel_error","That was my original thought, but this particular one can also go to `grpc_transport_stream_op_finish_batch_with_failure` (which, for what it's worth, can be sung to the tune of Supercalifragilisticexpialidocious). In that case, it never makes it down to the `ext/transport` . But I guess a `lib/transport` is still part of the transport so it's still legitimate. I can change that.",
29667874,griffithjames,https://api.github.com/repos/grpc/grpc/pulls/11583,124417081,2017-06-27T22:56:40Z,src/python/grpcio_testing/grpc_testing/_time.py,"@@ -0,0 +1,223 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Test times.""""""++import collections+import logging+import threading+import time as _time++import grpc+import grpc_testing+++def _call(behaviors):+    for behavior in behaviors:+        try:+            behavior()+        except Exception:  # pylint: disable=broad-except+            logging.exception('Exception calling behavior?')+++def _call_in_thread(behaviors):+    calling = threading.Thread(target=_call, args=(behaviors,))+    calling.start()+    calling.join()+++class _State(object):++    def __init__(self):+        self.condition = threading.Condition()+        self.times_to_behaviors = collections.defaultdict(list)+        self.behaviors_to_times = {}+++class _Delta(+        collections.namedtuple('_Delta',+                               ('mature_behaviors', 'earliest_mature_time',+                                'earliest_immature_time',))):+    pass+++def _process(state, now):+    mature_behaviors = []+    earliest_mature_time = None+    while state.times_to_behaviors:+        earliest_time = min(state.times_to_behaviors)+        if earliest_time <= now:+            if earliest_mature_time is None:+                earliest_mature_time = earliest_time+            earliest_mature_behaviors = state.times_to_behaviors.pop(+                earliest_time)+            for mature_behavior in earliest_mature_behaviors:+                state.behaviors_to_times.pop(mature_behavior)+            mature_behaviors.extend(earliest_mature_behaviors)+        else:+            earliest_immature_time = earliest_time+            break+    else:+        earliest_immature_time = None+    return _Delta(mature_behaviors, earliest_mature_time,+                  earliest_immature_time)+++class _Future(grpc.Future):++    def __init__(self, state, behavior):+        self._state = state+        self._behavior = behavior+        self._cancelled = False++    def cancel(self):+        with self._state.condition:+            time = self._state.behaviors_to_times.pop(self._behavior, None)+            if time is None:+                return False+            else:+                self._state.times_to_behaviors[time].remove(self._behavior)+                if not self._state.times_to_behaviors[time]:+                    self._state.times_to_behaviors.pop(time)+                    self._state.condition.notify_all()+                self._cancelled = True+                return True++    def cancelled(self):+        with self._state.condition:+            return self._cancelled++    def running(self):+        raise NotImplementedError()++    def done(self):+        raise NotImplementedError()++    def result(self, timeout=None):+        raise NotImplementedError()++    def exception(self, timeout=None):+        raise NotImplementedError()++    def traceback(self, timeout=None):+        raise NotImplementedError()++    def add_done_callback(self, fn):+        raise NotImplementedError()+++class RealTime(grpc_testing.Time):","To my mind, it'd be simpler. When adding an item, you check if it's first, and if so, update the interrupt time. When the interrupt went off, you could pop items until time had expired, then update the next interrupt time. It feels like a lot clearer to me.I don't know a polite way to use the signaling system. Usually it's not a problem, because it's rarely used, you're right that it'd be a bad idea in this case. So much for that idea.",
29667874,griffithjames,https://api.github.com/repos/grpc/grpc/pulls/11583,124418978,2017-06-27T23:10:28Z,src/python/grpcio_tests/tests/testing/_client_application.py,"@@ -0,0 +1,237 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""An example gRPC Python-using client-side application.""""""++import collections+import enum+import threading++import grpc+from tests.unit.framework.common import test_constants++from tests.testing.proto import services_pb2_grpc++from tests.testing import _application_common+++@enum.unique+class Scenario(enum.Enum):+    UNARY_UNARY = 'unary unary'+    UNARY_STREAM = 'unary stream'+    STREAM_UNARY = 'stream unary'+    STREAM_STREAM = 'stream stream'+    CONCURRENT_STREAM_UNARY = 'concurrent stream unary'+    CONCURRENT_STREAM_STREAM = 'concurrent stream stream'+    CANCEL_UNARY_UNARY = 'cancel unary unary'+    CANCEL_UNARY_STREAM = 'cancel unary stream'+    INFINITE_REQUEST_STREAM = 'infinite request stream'+++class Outcome(collections.namedtuple('Outcome', ('kind', 'code', 'details'))):+    """"""Outcome of a client application scenario.++    Attributes:+      kind: A Kind value describing the overall kind of scenario execution.+      code: A grpc.StatusCode value. Only valid if kind is Kind.RPC_ERROR.+      details: A status details string. Only valid if kind is Kind.RPC_ERROR.+    """"""++    @enum.unique+    class Kind(enum.Enum):+        SATISFACTORY = 'satisfactory'+        UNSATISFACTORY = 'unsatisfactory'+        RPC_ERROR = 'rpc error'+++_SATISFACTORY_OUTCOME = Outcome(Outcome.Kind.SATISFACTORY, None, None)+_UNSATISFACTORY_OUTCOME = Outcome(Outcome.Kind.UNSATISFACTORY, None, None)+++class _Pipe(object):++    def __init__(self):+        self._condition = threading.Condition()+        self._values = []+        self._open = True++    def __iter__(self):+        return self++    def _next(self):+        with self._condition:+            while True:+                if self._values:+                    return self._values.pop(0)+                elif not self._open:+                    raise StopIteration()+                else:+                    self._condition.wait()++    def __next__(self):  # (Python 3 Iterator Protocol)+        return self._next()++    def next(self):  # (Python 2 Iterator Protocol)+        return self._next()++    def add(self, value):+        with self._condition:++            self._values.append(value)+            self._condition.notify_all()++    def close(self):+        with self._condition:+            self._open = False+            self._condition.notify_all()+++def _run_unary_unary(stub):+    response = stub.UnUn(_application_common.UNARY_UNARY_REQUEST)+    if _application_common.UNARY_UNARY_RESPONSE == response:+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def _run_unary_stream(stub):+    response_iterator = stub.UnStre(_application_common.UNARY_STREAM_REQUEST)+    try:+        next(response_iterator)+    except StopIteration:+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def _run_stream_unary(stub):+    response, call = stub.StreUn.with_call(+        iter((_application_common.STREAM_UNARY_REQUEST,) * 3))+    if (_application_common.STREAM_UNARY_RESPONSE == response and+            call.code() is grpc.StatusCode.OK):+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def _run_stream_stream(stub):+    request_pipe = _Pipe()+    response_iterator = stub.StreStre(iter(request_pipe))+    request_pipe.add(_application_common.STREAM_STREAM_REQUEST)+    first_responses = next(response_iterator), next(response_iterator),+    request_pipe.add(_application_common.STREAM_STREAM_REQUEST)+    second_responses = next(response_iterator), next(response_iterator),+    request_pipe.close()+    try:+        next(response_iterator)+    except StopIteration:+        unexpected_extra_response = False+    else:+        unexpected_extra_response = True+    if (first_responses == _application_common.TWO_STREAM_STREAM_RESPONSES and+            second_responses == _application_common.TWO_STREAM_STREAM_RESPONSES+            and not unexpected_extra_response):+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def _run_concurrent_stream_unary(stub):+    future_calls = tuple(+        stub.StreUn.future(+            iter((_application_common.STREAM_UNARY_REQUEST,) * 3))+        for _ in range(test_constants.THREAD_CONCURRENCY))+    for future_call in future_calls:+        if future_call.code() is grpc.StatusCode.OK:+            response = future_call.result()+            if _application_common.STREAM_UNARY_RESPONSE != response:+                return _UNSATISFACTORY_OUTCOME+        else:+            return _UNSATISFACTORY_OUTCOME+    else:+        return _SATISFACTORY_OUTCOME+++def _run_concurrent_stream_stream(stub):+    condition = threading.Condition()+    outcomes = [None] * test_constants.RPC_CONCURRENCY++    def run_stream_stream(index):+        outcome = _run_stream_stream(stub)+        with condition:+            outcomes[index] = outcome+            condition.notify()++    for index in range(test_constants.RPC_CONCURRENCY):+        thread = threading.Thread(target=run_stream_stream, args=(index,))+        thread.start()+    with condition:+        while True:+            if all(outcomes):+                for outcome in outcomes:+                    if outcome.kind is not Outcome.Kind.SATISFACTORY:+                        return _UNSATISFACTORY_OUTCOME+                else:+                    return _SATISFACTORY_OUTCOME+            else:+                condition.wait()+++def _run_cancel_unary_unary(stub):+    response_future_call = stub.UnUn.future(+        _application_common.UNARY_UNARY_REQUEST)+    initial_metadata = response_future_call.initial_metadata()+    cancelled = response_future_call.cancel()+    if initial_metadata is not None and cancelled:+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def _run_infinite_request_stream(stub):++    def infinite_request_iterator():+        while True:+            yield _application_common.STREAM_UNARY_REQUEST++    response_future_call = stub.StreUn.future(+        infinite_request_iterator(),+        timeout=_application_common.INFINITE_REQUEST_STREAM_TIMEOUT)+    if response_future_call.code() is grpc.StatusCode.DEADLINE_EXCEEDED:+        return _SATISFACTORY_OUTCOME+    else:+        return _UNSATISFACTORY_OUTCOME+++def run(scenario, channel):+    stub = services_pb2_grpc.FirstServiceStub(channel)","Here's what I'd love:```my_service = make_a_mockery(services_pb2_grpc, 'FirstService')my_stub = my_service.stub()my_service.UnUn.add_exchange( _application_common.UNARY_UNARY_REQUEST, _application_common.STREAM_UNARY_RESPONSE)response = my_stub.UnUn( _application_common.UNARY_UNARY_REQUEST)if response == _application_common.STREAM_UNARY_RESPONSE and my_stub.done():    return _SATISFACTORY_OUTCOMEelse:    return _UNSATISFACTORY_OUTCOME```In a non-toy case, I'd create the service in a module's test, and then use dependency injection to give the module the stub.",
29667874,griffithjames,https://api.github.com/repos/grpc/grpc/pulls/11583,124421822,2017-06-27T23:30:49Z,src/python/grpcio_tests/tests/testing/_client_test.py,"@@ -0,0 +1,316 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import time+import unittest++import grpc+from grpc.framework.foundation import logging_pool+from tests.unit.framework.common import test_constants+import grpc_testing++from tests.testing import _application_common+from tests.testing import _application_testing_common+from tests.testing import _client_application+++class ClientTest(unittest.TestCase):++    def setUp(self):+        self._application_thread_pool = logging_pool.pool(1)","Interesting. My default design in this situation is to have the client-side run in the foreground, with the mock server behavior happening in the background. Now everything makes sense.Maybe `client_execution_thread_pool`?Maybe a comment that the server is running in the foreground here? I'm prepared to believe I'm the exception vis-a-vis where mocks run.",
29667874,griffithjames,https://api.github.com/repos/grpc/grpc/pulls/11583,124422781,2017-06-27T23:38:32Z,src/python/grpcio_tests/tests/testing/_server_application.py,"@@ -0,0 +1,67 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""An example gRPC Python-using server-side application.""""""++import grpc++# requests_pb2 is a semantic dependency of this module.+from tests.testing.proto import requests_pb2  # pylint: disable=unused-import+from tests.testing.proto import services_pb2+from tests.testing.proto import services_pb2_grpc++from tests.testing import _application_common+++class FirstServiceServicer(services_pb2_grpc.FirstServiceServicer):","I was reading this class as a mechanism to test the client. That is incorrect.To test the service, I agree you need to implement the service.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/11608,124618901,2017-06-28T18:25:36Z,tools/run_tests/python_utils/report_utils.py,"@@ -43,11 +43,11 @@ def _filter_msg(msg, output_format):     return msg  -def render_junit_xml_report(resultset, xml_report, suite_package='grpc',-                            suite_name='tests'):+def render_junit_xml_report(resultset, xml_report=None, suite_package='grpc',","if you really need to obtain xml tree, it looks like introduce a new function for it (and making render_junit_xml_report a thin wrapper around it) is a cleaner solutions than defining new semantics for an existing and widely used function (and the new semantics are rather odd to be honest).",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11607,124645355,2017-06-28T20:17:31Z,src/core/ext/transport/chttp2/transport/frame_rst_stream.c,"@@ -93,7 +93,7 @@ grpc_error *grpc_chttp2_rst_stream_parser_parse(grpc_exec_ctx *exec_ctx,                       (((uint32_t)p->reason_bytes[2]) << 8) |                       (((uint32_t)p->reason_bytes[3]));     grpc_error *error = GRPC_ERROR_NONE;-    if (reason != GRPC_HTTP2_NO_ERROR || s->header_frames_received < 2) {+    if (reason != GRPC_HTTP2_NO_ERROR || s->metadata_buffer[1].size == 0) {",There are a bunch of changes here that actually came from a PR that I merged last week.  I suspect that you did a bad merge somehow.,
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/11606,124690358,2017-06-29T00:43:40Z,src/objective-c/GRPCClient/private/GRPCWrappedCall.h,"@@ -75,6 +75,7 @@ @interface GRPCWrappedCall : NSObject  - (instancetype)initWithHost:(NSString *)host+                  serverName:(nullable NSString *)serverName","Specifying nullability for only partial parameters here seems to break compile in Xcode 8.x. Since it is internal interface, I think it is probably ok to just remove the `nullable` specifier. Same for `grpchost.{h,m}`",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/11619,124811056,2017-06-29T14:13:40Z,src/csharp/Grpc.IntegrationTesting/CustomErrorDetailsTest.cs,"@@ -0,0 +1,112 @@+#region Copyright notice and license++// Copyright 2015-2016 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Generic;+using System.IO;+using System.Linq;+using System.Threading;+using System.Threading.Tasks;+using Google.Protobuf;+using Grpc.Core;+using Grpc.Core.Utils;+using Grpc.Testing;+using NUnit.Framework;++namespace Grpc.IntegrationTesting+{+    /// <summary>+    /// Shows how to attach custom error details as a binary trailer.+    /// </summary>+    public class CustomErrorDetailsTest+    {+        const string DebugInfoTrailerName = ""debug-info-bin"";+        const string ExceptionDetail = ""Exception thrown on purpose."";+        const string Host = ""localhost"";+        Server server;+        Channel channel;+        TestService.TestServiceClient client;++        [TestFixtureSetUp]+        public void Init()+        {+            // Disable SO_REUSEPORT to prevent https://github.com/grpc/grpc/issues/10755+            server = new Server(new[] { new ChannelOption(ChannelOptions.SoReuseport, 0) })+            {+                Services = { TestService.BindService(new CustomErrorDetailsTestServiceImpl()) },+                Ports = { { Host, ServerPort.PickUnused, ServerCredentials.Insecure } }+            };+            server.Start();++            channel = new Channel(Host, server.Ports.Single().BoundPort, ChannelCredentials.Insecure);+            client = new TestService.TestServiceClient(channel);+        }++        [TestFixtureTearDown]+        public void Cleanup()+        {+            channel.ShutdownAsync().Wait();+            server.ShutdownAsync().Wait();+        }++        [Test]+        public async Task UnaryCall()+        {+            var call = client.UnaryCallAsync(new SimpleRequest { ResponseSize = 10 });++            try+            {+                await call.ResponseAsync;+                Assert.Fail();+            }+            catch (RpcException e)+            {+                Assert.AreEqual(StatusCode.Internal, e.Status.StatusCode);+                var debugInfo = GetDebugInfo(call.GetTrailers());+                Assert.AreEqual(debugInfo.Detail, ExceptionDetail);+                Assert.IsNotEmpty(debugInfo.StackEntries);+            }+        }++        private DebugInfo GetDebugInfo(Metadata trailers)+        {+            var entry = trailers.First((e) => e.Key == DebugInfoTrailerName);+            return DebugInfo.Parser.ParseFrom(entry.ValueBytes);+        }++        private class CustomErrorDetailsTestServiceImpl : TestService.TestServiceBase+        {+            public override async Task<SimpleResponse> UnaryCall(SimpleRequest request, ServerCallContext context)+            {+                try+                {+                    throw new ArgumentException(ExceptionDetail);+                }+                catch (Exception e)+                {+                    // Fill debug info with some structured details about the failure.+                    var debugInfo = new DebugInfo();+                    debugInfo.Detail = e.Message;+                    debugInfo.StackEntries.AddRange(e.StackTrace.Split(new[] { Environment.NewLine }, StringSplitOptions.None)); +                    context.ResponseTrailers.Add(DebugInfoTrailerName, debugInfo.ToByteArray());+                    throw new RpcException(new Status(StatusCode.Internal, ""The handler threw exception.""));","There's a standard error code to use when the server side handler threw an exception and it's `Unknown` (my bad, I mixed it up with Internal). I'll change the status code to Unknown.https://github.com/grpc/grpc/blob/a410632b570a8717eb5f3c1f43eb84bf80e0aca9/src/csharp/Grpc.Core.Tests/ClientServerTest.cs#L71",
24657604,wcevans,https://api.github.com/repos/grpc/grpc/pulls/11145,125072184,2017-06-30T15:53:41Z,test/cpp/end2end/end2end_test.cc,"@@ -1633,51 +1650,56 @@ TEST_P(ResourceQuotaEnd2endTest, SimpleRequest) {  std::vector<TestScenario> CreateTestScenarios(bool use_proxy,                                               bool test_insecure,-                                              bool test_secure) {+                                              bool test_secure,+                                              bool test_inproc) {   std::vector<TestScenario> scenarios;   std::vector<grpc::string> credentials_types;   if (test_secure) {     credentials_types =         GetCredentialsProvider()->GetSecureCredentialsTypeList();   }-  if (test_insecure) {-    // Only add insecure credentials type when it is registered with the+  auto insec_ok = []() {",nit: You can omit the parentheses if the argument list is empty.,
24657604,wcevans,https://api.github.com/repos/grpc/grpc/pulls/11145,125072313,2017-06-30T15:54:18Z,test/cpp/end2end/async_end2end_test.cc,"@@ -1732,8 +1739,14 @@ std::vector<TestScenario> CreateTestScenarios(bool test_disable_blocking,   std::vector<grpc::string> credentials_types;   std::vector<grpc::string> messages; -  if (GetCredentialsProvider()->GetChannelCredentials(kInsecureCredentialsType,-                                                      nullptr) != nullptr) {+  auto insec_ok = []() {",nit: You can omit the parentheses if the argument list is empty.,
24657604,wcevans,https://api.github.com/repos/grpc/grpc/pulls/11145,125096734,2017-06-30T18:00:50Z,src/core/ext/transport/inproc/inproc_transport.c,"@@ -0,0 +1,1183 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/core/ext/transport/inproc/inproc_transport.h""+#include <grpc/support/alloc.h>+#include <grpc/support/string_util.h>+#include <grpc/support/sync.h>+#include <grpc/support/time.h>+#include <string.h>+#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/slice/slice_internal.h""+#include ""src/core/lib/surface/api_trace.h""+#include ""src/core/lib/surface/channel.h""+#include ""src/core/lib/surface/channel_stack_type.h""+#include ""src/core/lib/surface/server.h""+#include ""src/core/lib/transport/connectivity_state.h""+#include ""src/core/lib/transport/error_utils.h""+#include ""src/core/lib/transport/transport_impl.h""++#define INPROC_LOG(...)                                          \+  do {                                                           \+    if (GRPC_TRACER_ON(grpc_inproc_trace)) gpr_log(__VA_ARGS__); \+  } while (0)++static const grpc_transport_vtable inproc_vtable;+static grpc_slice g_empty_slice;+static grpc_slice g_fake_path_key;+static grpc_slice g_fake_path_value;+static grpc_slice g_fake_auth_key;+static grpc_slice g_fake_auth_value;++typedef struct {+  gpr_mu mu;+  gpr_refcount refs;+} shared_mu;++typedef struct inproc_transport {+  grpc_transport base;+  shared_mu *mu;+  gpr_refcount refs;+  bool is_client;+  grpc_connectivity_state_tracker connectivity;+  void (*accept_stream_cb)(grpc_exec_ctx *exec_ctx, void *user_data,+                           grpc_transport *transport, const void *server_data);+  void *accept_stream_data;+  bool is_closed;+  struct inproc_transport *other_side;+  struct inproc_stream *stream_list;+} inproc_transport;++typedef struct sb_list_entry {+  grpc_slice_buffer sb;+  struct sb_list_entry *next;+} sb_list_entry;++// Specialize grpc_byte_stream for our use case+typedef struct {+  grpc_byte_stream base;+  sb_list_entry *le;+} inproc_slice_byte_stream;++typedef struct {+  // TODO (vjpai): Add some inlined elements to avoid alloc in simple cases+  sb_list_entry *head;+  sb_list_entry *tail;+} slice_buffer_list;++static void slice_buffer_list_init(slice_buffer_list *l) {+  l->head = NULL;+  l->tail = NULL;+}++static void sb_list_entry_destroy(grpc_exec_ctx *exec_ctx, sb_list_entry *le) {+  grpc_slice_buffer_destroy_internal(exec_ctx, &le->sb);+  gpr_free(le);+}++static void slice_buffer_list_destroy(grpc_exec_ctx *exec_ctx,+                                      slice_buffer_list *l) {+  sb_list_entry *curr = l->head;+  while (curr != NULL) {+    sb_list_entry *le = curr;+    curr = curr->next;+    sb_list_entry_destroy(exec_ctx, le);+  }+  l->head = NULL;+  l->tail = NULL;+}++static bool slice_buffer_list_empty(slice_buffer_list *l) {+  return l->head == NULL;+}++static void slice_buffer_list_append_entry(slice_buffer_list *l,+                                           sb_list_entry *next) {+  next->next = NULL;+  if (l->tail) {+    l->tail->next = next;+    l->tail = next;+  } else {+    l->head = next;+    l->tail = next;+  }+}++static grpc_slice_buffer *slice_buffer_list_append(slice_buffer_list *l) {+  sb_list_entry *next = gpr_malloc(sizeof(*next));+  grpc_slice_buffer_init(&next->sb);+  slice_buffer_list_append_entry(l, next);+  return &next->sb;+}++static sb_list_entry *slice_buffer_list_pophead(slice_buffer_list *l) {+  sb_list_entry *ret = l->head;+  l->head = l->head->next;+  if (l->head == NULL) {+    l->tail = NULL;+  }+  return ret;+}++typedef struct inproc_stream {+  inproc_transport *t;+  grpc_metadata_batch to_read_initial_md;+  uint32_t to_read_initial_md_flags;+  bool to_read_initial_md_filled;+  slice_buffer_list to_read_message;+  grpc_metadata_batch to_read_trailing_md;+  bool to_read_trailing_md_filled;+  bool read_closure_needed;+  grpc_closure read_closure;+  // Write buffer used only during gap at init time when client-side+  // stream is set up but server side stream is not yet set up+  grpc_metadata_batch write_buffer_initial_md;+  bool write_buffer_initial_md_filled;+  uint32_t write_buffer_initial_md_flags;+  gpr_timespec write_buffer_deadline;+  slice_buffer_list write_buffer_message;+  grpc_metadata_batch write_buffer_trailing_md;+  bool write_buffer_trailing_md_filled;+  grpc_error *write_buffer_cancel_error;++  struct inproc_stream *other_side;+  gpr_refcount refs;+  grpc_closure *closure_at_destroy;++  gpr_arena *arena;++  grpc_transport_stream_op_batch *recv_initial_md_op;+  grpc_transport_stream_op_batch *recv_message_op;+  grpc_transport_stream_op_batch *recv_trailing_md_op;++  inproc_slice_byte_stream recv_message_stream;++  bool initial_md_sent;+  bool trailing_md_sent;+  bool initial_md_recvd;+  bool trailing_md_recvd;++  grpc_error *cancel_self_error;+  grpc_error *cancel_other_error;++  gpr_timespec deadline;++  struct inproc_stream *stream_list_prev;+  struct inproc_stream *stream_list_next;+} inproc_stream;++static bool inproc_slice_byte_stream_next(grpc_exec_ctx *exec_ctx,+                                          grpc_byte_stream *bs, size_t max,+                                          grpc_closure *on_complete) {+  inproc_slice_byte_stream *stream = (inproc_slice_byte_stream *)bs;+  return (stream->le->sb.count != 0);+}++static grpc_error *inproc_slice_byte_stream_pull(grpc_exec_ctx *exec_ctx,+                                                 grpc_byte_stream *bs,+                                                 grpc_slice *slice) {+  inproc_slice_byte_stream *stream = (inproc_slice_byte_stream *)bs;+  *slice = grpc_slice_buffer_take_first(&stream->le->sb);+  return GRPC_ERROR_NONE;+}++static void inproc_slice_byte_stream_destroy(grpc_exec_ctx *exec_ctx,+                                             grpc_byte_stream *bs) {+  inproc_slice_byte_stream *stream = (inproc_slice_byte_stream *)bs;+  sb_list_entry_destroy(exec_ctx, stream->le);+}++void inproc_slice_byte_stream_init(inproc_slice_byte_stream *s,+                                   sb_list_entry *le) {+  s->base.length = (uint32_t)le->sb.length;+  s->base.flags = 0;+  s->base.next = inproc_slice_byte_stream_next;+  s->base.pull = inproc_slice_byte_stream_pull;+  s->base.destroy = inproc_slice_byte_stream_destroy;+  s->le = le;+}++static void ref_transport(inproc_transport *t) {+  INPROC_LOG(GPR_DEBUG, ""ref_transport %p"", t);+  gpr_ref(&t->refs);+}++static void really_destroy_transport(grpc_exec_ctx *exec_ctx,+                                     inproc_transport *t) {+  INPROC_LOG(GPR_DEBUG, ""really_destroy_transport %p"", t);+  grpc_connectivity_state_destroy(exec_ctx, &t->connectivity);+  if (gpr_unref(&t->mu->refs)) {+    gpr_free(t->mu);+  }+  gpr_free(t);+}++static void unref_transport(grpc_exec_ctx *exec_ctx, inproc_transport *t) {+  INPROC_LOG(GPR_DEBUG, ""unref_transport %p"", t);+  if (gpr_unref(&t->refs)) {+    really_destroy_transport(exec_ctx, t);+  }+}++static void ref_stream(inproc_stream *s) {+  INPROC_LOG(GPR_DEBUG, ""ref_stream %p"", s);+  gpr_ref(&s->refs);+}++static void really_destroy_stream(grpc_exec_ctx *exec_ctx, inproc_stream *s) {+  INPROC_LOG(GPR_DEBUG, ""really_destroy_stream %p"", s);+  // Remove the stream contents and remove from the transport's linked list+  gpr_mu_lock(&s->t->mu->mu);++  grpc_metadata_batch_destroy(exec_ctx, &s->to_read_initial_md);+  slice_buffer_list_destroy(exec_ctx, &s->to_read_message);+  grpc_metadata_batch_destroy(exec_ctx, &s->to_read_trailing_md);+  grpc_metadata_batch_destroy(exec_ctx, &s->write_buffer_initial_md);+  slice_buffer_list_destroy(exec_ctx, &s->write_buffer_message);+  grpc_metadata_batch_destroy(exec_ctx, &s->write_buffer_trailing_md);+  GRPC_ERROR_UNREF(s->write_buffer_cancel_error);+  GRPC_ERROR_UNREF(s->cancel_self_error);+  GRPC_ERROR_UNREF(s->cancel_other_error);++  inproc_stream *p = s->stream_list_prev;+  inproc_stream *n = s->stream_list_next;+  if (p) {+    p->stream_list_next = n;+  } else {+    s->t->stream_list = n;+  }+  if (n) {+    n->stream_list_prev = p;+  }+  gpr_mu_unlock(&s->t->mu->mu);++  unref_transport(exec_ctx, s->t);++  if (s->closure_at_destroy) {+    GRPC_CLOSURE_SCHED(exec_ctx, s->closure_at_destroy, GRPC_ERROR_NONE);+  }+}++static void unref_stream(grpc_exec_ctx *exec_ctx, inproc_stream *s) {+  INPROC_LOG(GPR_DEBUG, ""unref_stream %p"", s);+  if (gpr_unref(&s->refs)) {+    really_destroy_stream(exec_ctx, s);+  }+}++static void read_state_machine(grpc_exec_ctx *exec_ctx, void *arg,+                               grpc_error *error);++static void log_metadata(const grpc_metadata_batch *md_batch, bool is_client,+                         bool is_initial) {+  for (grpc_linked_mdelem *md = md_batch->list.head; md != NULL;+       md = md->next) {+    char *key = grpc_slice_to_c_string(GRPC_MDKEY(md->md));+    char *value = grpc_slice_to_c_string(GRPC_MDVALUE(md->md));+    gpr_log(GPR_INFO, ""INPROC:%s:%s: %s: %s"", is_initial ? ""HDR"" : ""TRL"",+            is_client ? ""CLI"" : ""SVR"", key, value);+    gpr_free(key);+    gpr_free(value);+  }+}++static grpc_error *fill_in_metadata(grpc_exec_ctx *exec_ctx, inproc_stream *s,+                                    const grpc_metadata_batch *metadata,+                                    uint32_t flags, grpc_metadata_batch *out_md,+                                    uint32_t *outflags, bool *markfilled) {+  if (outflags != NULL) {+    *outflags = flags;+  }+  if (markfilled != NULL) {+    *markfilled = true;+  }+  grpc_error *error = GRPC_ERROR_NONE;+  for (grpc_linked_mdelem *elem = metadata->list.head;+       (elem != NULL) && (error == GRPC_ERROR_NONE); elem = elem->next) {+    grpc_linked_mdelem *nelem = gpr_arena_alloc(s->arena, sizeof(*nelem));+    nelem->md = grpc_mdelem_from_slices(+        exec_ctx, grpc_slice_intern(GRPC_MDKEY(elem->md)),+        grpc_slice_intern(GRPC_MDVALUE(elem->md)));++    error = grpc_metadata_batch_link_tail(exec_ctx, out_md, nelem);+  }+  return error;+}++static int init_stream(grpc_exec_ctx *exec_ctx, grpc_transport *gt,+                       grpc_stream *gs, grpc_stream_refcount *refcount,+                       const void *server_data, gpr_arena *arena) {+  INPROC_LOG(GPR_DEBUG, ""init_stream %p %p %p"", gt, gs, server_data);+  inproc_transport *t = (inproc_transport *)gt;+  inproc_stream *s = (inproc_stream *)gs;+  s->arena = arena;+  gpr_ref_init(&s->refs, 1);  // don't count the transport stream list+  grpc_metadata_batch_init(&s->to_read_initial_md);+  s->to_read_initial_md_flags = 0;+  s->to_read_initial_md_filled = false;+  grpc_metadata_batch_init(&s->to_read_trailing_md);+  s->to_read_trailing_md_filled = false;+  grpc_metadata_batch_init(&s->write_buffer_initial_md);+  s->write_buffer_initial_md_flags = 0;+  s->write_buffer_initial_md_filled = false;+  grpc_metadata_batch_init(&s->write_buffer_trailing_md);+  s->write_buffer_trailing_md_filled = false;+  slice_buffer_list_init(&s->to_read_message);+  slice_buffer_list_init(&s->write_buffer_message);+  s->read_closure_needed = false;+  GRPC_CLOSURE_INIT(&s->read_closure, read_state_machine, s,+                    grpc_schedule_on_exec_ctx);+  s->t = t;+  s->closure_at_destroy = NULL;++  s->initial_md_sent = s->trailing_md_sent = s->initial_md_recvd =+      s->trailing_md_recvd = false;++  s->cancel_self_error = GRPC_ERROR_NONE;+  s->cancel_other_error = GRPC_ERROR_NONE;+  s->write_buffer_cancel_error = GRPC_ERROR_NONE;+  s->deadline = gpr_inf_future(GPR_CLOCK_MONOTONIC);+  s->write_buffer_deadline = gpr_inf_future(GPR_CLOCK_MONOTONIC);++  s->stream_list_prev = NULL;+  gpr_mu_lock(&t->mu->mu);+  s->stream_list_next = t->stream_list;+  if (t->stream_list) {+    t->stream_list->stream_list_prev = s;+  }+  t->stream_list = s;+  gpr_mu_unlock(&t->mu->mu);++  if (!server_data) {+    ref_transport(t);+    inproc_transport *st = t->other_side;+    ref_transport(st);+    s->other_side = NULL;  // will get filled in soon+    // Pass the client-side stream address to the server-side for a ref+    ref_stream(s);  // ref it now on behalf of server side to avoid destruction+    INPROC_LOG(GPR_DEBUG, ""calling accept stream cb %p %p"",+               st->accept_stream_cb, st->accept_stream_data);+    (*st->accept_stream_cb)(exec_ctx, st->accept_stream_data, &st->base,+                            (void *)s);+  } else {+    // This is the server-side and is being called through accept_stream_cb+    inproc_stream *cs = (inproc_stream *)server_data;+    s->other_side = cs;+    // Ref the server-side stream on behalf of the client now+    ref_stream(s);++    // Now we are about to affect the other side, so lock the transport+    gpr_mu_lock(&s->t->mu->mu);+    cs->other_side = s;+    // Now transfer from the other side's write_buffer if any to the to_read+    // buffer+    if (cs->write_buffer_initial_md_filled) {+      fill_in_metadata(exec_ctx, s, &cs->write_buffer_initial_md,+                       cs->write_buffer_initial_md_flags,+                       &s->to_read_initial_md, &s->to_read_initial_md_flags,+                       &s->to_read_initial_md_filled);+      s->deadline = gpr_time_min(s->deadline, cs->write_buffer_deadline);+      grpc_metadata_batch_clear(exec_ctx, &cs->write_buffer_initial_md);+      cs->write_buffer_initial_md_filled = false;+    }+    while (!slice_buffer_list_empty(&cs->write_buffer_message)) {+      slice_buffer_list_append_entry(+          &s->to_read_message,+          slice_buffer_list_pophead(&cs->write_buffer_message));+    }+    if (cs->write_buffer_trailing_md_filled) {+      fill_in_metadata(exec_ctx, s, &cs->write_buffer_trailing_md, 0,+                       &s->to_read_trailing_md, NULL,+                       &s->to_read_trailing_md_filled);+      grpc_metadata_batch_clear(exec_ctx, &cs->write_buffer_trailing_md);+      cs->write_buffer_trailing_md_filled = false;+    }+    if (cs->write_buffer_cancel_error != GRPC_ERROR_NONE) {+      s->cancel_other_error = cs->write_buffer_cancel_error;+      cs->write_buffer_cancel_error = GRPC_ERROR_NONE;+    }++    gpr_mu_unlock(&s->t->mu->mu);+  }+  return 0;  // return value is not important+}++static void fail_helper_locked(grpc_exec_ctx *exec_ctx, inproc_stream *s,+                               grpc_error *error) {+  INPROC_LOG(GPR_DEBUG, ""read_state_machine %p fail_helper"", s);+  // If we're failing this side, we need to make sure that+  // we also send or have already sent trailing metadata+  if (!s->trailing_md_sent) {+    // Send trailing md to the other side indicating cancellation+    s->trailing_md_sent = true;++    grpc_metadata_batch fake_md;+    grpc_metadata_batch_init(&fake_md);++    inproc_stream *other = s->other_side;+    grpc_metadata_batch *dest = (other == NULL) ? &s->write_buffer_trailing_md+                                                : &other->to_read_trailing_md;+    bool *destfilled = (other == NULL) ? &s->write_buffer_trailing_md_filled+                                       : &other->to_read_trailing_md_filled;+    fill_in_metadata(exec_ctx, s, &fake_md, 0, dest, NULL, destfilled);+    grpc_metadata_batch_destroy(exec_ctx, &fake_md);++    if (other != NULL) {+      if (other->cancel_other_error == GRPC_ERROR_NONE) {+        other->cancel_other_error = GRPC_ERROR_REF(error);+      }+      if (other->read_closure_needed) {+        GRPC_CLOSURE_SCHED(exec_ctx, &other->read_closure,+                           GRPC_ERROR_REF(error));+        other->read_closure_needed = false;+      }+    } else if (s->write_buffer_cancel_error == GRPC_ERROR_NONE) {+      s->write_buffer_cancel_error = GRPC_ERROR_REF(error);+    }+  }+  if (s->recv_initial_md_op) {+    grpc_error *err;+    if (!s->t->is_client) {+      // If this is a server, provide initial metadata with a path and authority+      // since it expects that as well as no error yet+      grpc_metadata_batch fake_md;+      grpc_metadata_batch_init(&fake_md);+      grpc_linked_mdelem *path_md = gpr_arena_alloc(s->arena, sizeof(*path_md));+      path_md->md =+          grpc_mdelem_from_slices(exec_ctx, g_fake_path_key, g_fake_path_value);+      GPR_ASSERT(grpc_metadata_batch_link_tail(exec_ctx, &fake_md, path_md) ==+                 GRPC_ERROR_NONE);+      grpc_linked_mdelem *auth_md = gpr_arena_alloc(s->arena, sizeof(*auth_md));+      auth_md->md =+          grpc_mdelem_from_slices(exec_ctx, g_fake_auth_key, g_fake_auth_value);+      GPR_ASSERT(grpc_metadata_batch_link_tail(exec_ctx, &fake_md, auth_md) ==+                 GRPC_ERROR_NONE);++      fill_in_metadata(+          exec_ctx, s, &fake_md, 0,+          s->recv_initial_md_op->payload->recv_initial_metadata+              .recv_initial_metadata,+          s->recv_initial_md_op->payload->recv_initial_metadata.recv_flags,+          NULL);+      grpc_metadata_batch_destroy(exec_ctx, &fake_md);+      err = GRPC_ERROR_NONE;+    } else {+      err = GRPC_ERROR_REF(error);+    }+    INPROC_LOG(GPR_DEBUG,+               ""fail_helper %p scheduling initial-metadata-ready %p %p"", s,+               error, err);+    GRPC_CLOSURE_SCHED(exec_ctx,+                       s->recv_initial_md_op->payload->recv_initial_metadata+                           .recv_initial_metadata_ready,+                       err);+    // Last use of err so no need to REF and then UNREF it++    if ((s->recv_initial_md_op != s->recv_message_op) &&+        (s->recv_initial_md_op != s->recv_trailing_md_op)) {+      INPROC_LOG(GPR_DEBUG,+                 ""fail_helper %p scheduling initial-metadata-on-complete %p"",+                 error, s);+      GRPC_CLOSURE_SCHED(exec_ctx, s->recv_initial_md_op->on_complete,+                         GRPC_ERROR_REF(error));+    }+    s->recv_initial_md_op = NULL;+  }+  if (s->recv_message_op) {+    INPROC_LOG(GPR_DEBUG, ""fail_helper %p scheduling message-ready %p"", s,+               error);+    GRPC_CLOSURE_SCHED(+        exec_ctx, s->recv_message_op->payload->recv_message.recv_message_ready,+        GRPC_ERROR_REF(error));+    if (s->recv_message_op != s->recv_trailing_md_op) {+      INPROC_LOG(GPR_DEBUG, ""fail_helper %p scheduling message-on-complete %p"",+                 s, error);+      GRPC_CLOSURE_SCHED(exec_ctx, s->recv_message_op->on_complete,+                         GRPC_ERROR_REF(error));+    }+    s->recv_message_op = NULL;+  }+  if (s->recv_trailing_md_op) {  // Use on_complete here+    INPROC_LOG(GPR_DEBUG,+               ""fail_helper %p scheduling trailing-md-on-complete %p"", s,+               error);+    GRPC_CLOSURE_SCHED(exec_ctx, s->recv_trailing_md_op->on_complete,+                       GRPC_ERROR_REF(error));+    s->recv_trailing_md_op = NULL;+  }+  GRPC_ERROR_UNREF(error);+}++static void read_state_machine(grpc_exec_ctx *exec_ctx, void *arg,+                               grpc_error *error) {+  // This function gets called when we have contents in the unprocessed reads+  // Get what we want based on our ops wanted+  // Schedule our appropriate closures+  // and then return to read_closure_needed state if still needed++  // Since this is a closure directly invoked by the combiner, it should not+  // unref the error explicitly. That will be done implicitly by the combiner+  grpc_error *new_err = GRPC_ERROR_NONE;++  INPROC_LOG(GPR_DEBUG, ""read_state_machine %p"", arg);+  inproc_stream *s = (inproc_stream *)arg;+  gpr_mu_lock(&s->t->mu->mu);+  // cancellation takes precedence+  if (s->cancel_self_error != GRPC_ERROR_NONE) {+    fail_helper_locked(exec_ctx, s, GRPC_ERROR_REF(s->cancel_self_error));+    goto done;+  } else if (s->cancel_other_error != GRPC_ERROR_NONE) {+    fail_helper_locked(exec_ctx, s, GRPC_ERROR_REF(s->cancel_other_error));+    goto done;+  } else if (error != GRPC_ERROR_NONE) {+    fail_helper_locked(exec_ctx, s, GRPC_ERROR_REF(error));+    goto done;+  }++  if (s->recv_initial_md_op) {+    if (!s->to_read_initial_md_filled) {+      // We entered the state machine on some other kind of read even though+      // we still haven't satisfied initial md . That's an error.+      new_err =+          GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Unexpected frame sequencing"");+      INPROC_LOG(GPR_DEBUG,+                 ""read_state_machine %p scheduling on_complete errors for no ""+                 ""initial md %p"",+                 s, new_err);+      fail_helper_locked(exec_ctx, s, new_err);+      goto done;+    } else if (s->initial_md_recvd) {+      new_err =+          GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Already recvd initial md"");+      INPROC_LOG(+          GPR_DEBUG,+          ""read_state_machine %p scheduling on_complete errors for already ""+          ""recvd initial md %p"",+          s, new_err);+      fail_helper_locked(exec_ctx, s, new_err);+      goto done;+    }++    s->initial_md_recvd = true;+    new_err = fill_in_metadata(+        exec_ctx, s, &s->to_read_initial_md, s->to_read_initial_md_flags,+        s->recv_initial_md_op->payload->recv_initial_metadata+            .recv_initial_metadata,+        s->recv_initial_md_op->payload->recv_initial_metadata.recv_flags, NULL);+    s->recv_initial_md_op->payload->recv_initial_metadata.recv_initial_metadata+        ->deadline = s->deadline;+    grpc_metadata_batch_clear(exec_ctx, &s->to_read_initial_md);+    s->to_read_initial_md_filled = false;+    INPROC_LOG(GPR_DEBUG,+               ""read_state_machine %p scheduling initial-metadata-ready %p"", s,+               new_err);+    GRPC_CLOSURE_SCHED(exec_ctx,+                       s->recv_initial_md_op->payload->recv_initial_metadata+                           .recv_initial_metadata_ready,+                       GRPC_ERROR_REF(new_err));+    if ((s->recv_initial_md_op != s->recv_message_op) &&+        (s->recv_initial_md_op != s->recv_trailing_md_op)) {+      INPROC_LOG(+          GPR_DEBUG,+          ""read_state_machine %p scheduling initial-metadata-on-complete %p"", s,+          new_err);+      GRPC_CLOSURE_SCHED(exec_ctx, s->recv_initial_md_op->on_complete,+                         GRPC_ERROR_REF(new_err));+    }+    s->recv_initial_md_op = NULL;++    if (new_err != GRPC_ERROR_NONE) {+      INPROC_LOG(GPR_DEBUG,+                 ""read_state_machine %p scheduling on_complete errors2 %p"", s,+                 new_err);+      fail_helper_locked(exec_ctx, s, GRPC_ERROR_REF(new_err));+      goto done;+    }+  }+  if (s->to_read_initial_md_filled) {+    new_err = GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Unexpected recv frame"");+    fail_helper_locked(exec_ctx, s, GRPC_ERROR_REF(new_err));+    goto done;+  }+  if (!slice_buffer_list_empty(&s->to_read_message) && s->recv_message_op) {+    inproc_slice_byte_stream_init(+        &s->recv_message_stream,+        slice_buffer_list_pophead(&s->to_read_message));+    *s->recv_message_op->payload->recv_message.recv_message =+        &s->recv_message_stream.base;+    INPROC_LOG(GPR_DEBUG, ""read_state_machine %p scheduling message-ready"", s);+    GRPC_CLOSURE_SCHED(+        exec_ctx, s->recv_message_op->payload->recv_message.recv_message_ready,+        GRPC_ERROR_NONE);+    if (s->recv_message_op != s->recv_trailing_md_op) {+      INPROC_LOG(GPR_DEBUG,+                 ""read_state_machine %p scheduling message-on-complete %p"", s,+                 new_err);+      GRPC_CLOSURE_SCHED(exec_ctx, s->recv_message_op->on_complete,+                         GRPC_ERROR_REF(new_err));+    }+    s->recv_message_op = NULL;+  }+  if (s->to_read_trailing_md_filled) {+    if (s->trailing_md_recvd) {+      new_err =+          GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Already recvd trailing md"");+      INPROC_LOG(+          GPR_DEBUG,+          ""read_state_machine %p scheduling on_complete errors for already ""+          ""recvd trailing md %p"",+          s, new_err);+      fail_helper_locked(exec_ctx, s, GRPC_ERROR_REF(new_err));+      goto done;+    }+    if (s->recv_message_op != NULL) {+      // This message needs to be wrapped up because it will never be+      // satisfied+      INPROC_LOG(GPR_DEBUG, ""read_state_machine %p scheduling message-ready"",+                 s);+      GRPC_CLOSURE_SCHED(+          exec_ctx,+          s->recv_message_op->payload->recv_message.recv_message_ready,+          GRPC_ERROR_NONE);+      if (s->recv_message_op != s->recv_trailing_md_op) {+        INPROC_LOG(GPR_DEBUG,+                   ""read_state_machine %p scheduling message-on-complete %p"", s,+                   new_err);+        GRPC_CLOSURE_SCHED(exec_ctx, s->recv_message_op->on_complete,+                           GRPC_ERROR_REF(new_err));+      }+      s->recv_message_op = NULL;+    }+    if (s->recv_trailing_md_op != NULL) {+      // We wanted trailing metadata and we got it+      s->trailing_md_recvd = true;+      new_err =+          fill_in_metadata(exec_ctx, s, &s->to_read_trailing_md, 0,+                           s->recv_trailing_md_op->payload+                               ->recv_trailing_metadata.recv_trailing_metadata,+                           NULL, NULL);+      grpc_metadata_batch_clear(exec_ctx, &s->to_read_trailing_md);+      s->to_read_trailing_md_filled = false;++      // We should schedule the recv_trailing_md_op completion if+      // 1. this stream is the client-side+      // 2. this stream is the server-side AND has already sent its trailing md+      //    (If the server hasn't already sent its trailing md, it doesn't have+      //     a final status, so don't mark this op complete)+      if (s->t->is_client || s->trailing_md_sent) {+        INPROC_LOG(+            GPR_DEBUG,+            ""read_state_machine %p scheduling trailing-md-on-complete %p"", s,+            new_err);+        GRPC_CLOSURE_SCHED(exec_ctx, s->recv_trailing_md_op->on_complete,+                           GRPC_ERROR_REF(new_err));+        s->recv_trailing_md_op = NULL;+      } else {+        INPROC_LOG(GPR_DEBUG,+                   ""read_state_machine %p server needs to delay handling ""+                   ""trailing-md-on-complete %p"",+                   s, new_err);+      }+    } else {+      INPROC_LOG(+          GPR_DEBUG,+          ""read_state_machine %p has trailing md but not yet waiting for it"",+          s);+    }+  }+  if (s->trailing_md_recvd && s->recv_message_op) {+    // No further message will come on this stream, so finish off the+    // recv_message_op+    INPROC_LOG(GPR_DEBUG, ""read_state_machine %p scheduling message-ready"", s);+    GRPC_CLOSURE_SCHED(+        exec_ctx, s->recv_message_op->payload->recv_message.recv_message_ready,+        GRPC_ERROR_NONE);+    if (s->recv_message_op != s->recv_trailing_md_op) {+      INPROC_LOG(GPR_DEBUG,+                 ""read_state_machine %p scheduling message-on-complete %p"", s,+                 new_err);+      GRPC_CLOSURE_SCHED(exec_ctx, s->recv_message_op->on_complete,+                         GRPC_ERROR_REF(new_err));+    }+    s->recv_message_op = NULL;+  }+  if (s->recv_message_op || s->recv_trailing_md_op) {+    // Didn't get the item we wanted so we still need to get+    // rescheduled+    INPROC_LOG(GPR_DEBUG, ""read_state_machine %p still needs closure %p %p"", s,+               s->recv_message_op, s->recv_trailing_md_op);+    s->read_closure_needed = true;+  }+done:+  gpr_mu_unlock(&s->t->mu->mu);+  GRPC_ERROR_UNREF(new_err);+}++static grpc_closure do_nothing_closure;++static bool cancel_stream(grpc_exec_ctx *exec_ctx, inproc_stream *s,",Suggest renaming to cancel_stream_locked,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/11608,125236324,2017-07-03T08:41:47Z,tools/run_tests/python_utils/report_utils.py,"@@ -46,8 +46,22 @@ def _filter_msg(msg, output_format): def render_junit_xml_report(resultset, xml_report, suite_package='grpc',                             suite_name='tests'):   """"""Generate JUnit-like XML report.""""""-  root = ET.Element('testsuites')-  testsuite = ET.SubElement(root, 'testsuite', id='1', package=suite_package,+  tree = add_junit_xml_results(resultset, suite_package, suite_name, '1')+  create_xml_report_file(xml_report, tree)++def create_xml_report_file(xml_report, tree):+  """"""Generate JUnit-like report file from xml tree .""""""+  # ensure the report directory exists+  report_dir = os.path.dirname(os.path.abspath(xml_report))+  if not os.path.exists(report_dir):+    os.makedirs(report_dir)+  tree.write(xml_report, encoding='UTF-8')++def add_junit_xml_results(resultset, suite_package, suite_name, id,","I think this method is a bit ill-defined. If ""old_tree"" is set (not the best name of the param IMHO), the parameters ""suite_package"", ""suite_name"" and ""id"" are ignored.Having said that and taking into account that both kokoro and jenkins have no problem processing multiple XML reports in  single run, how about reverting changes to report_utils.py and just generating an XML report for each configuration?",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/11145,125529590,2017-07-04T21:05:17Z,test/cpp/end2end/thread_stress_test.cc,"@@ -151,80 +151,99 @@ class TestServiceImpl : public ::grpc::testing::EchoTestService::Service {   std::mutex mu_; }; -class TestServiceImplDupPkg-    : public ::grpc::testing::duplicate::EchoTestService::Service {- public:-  Status Echo(ServerContext* context, const EchoRequest* request,-              EchoResponse* response) override {-    response->set_message(""no package"");-    return Status::OK;-  }-};- template <class Service> class CommonStressTest {  public:   CommonStressTest() : kMaxMessageSize_(8192) {}   virtual ~CommonStressTest() {}   virtual void SetUp() = 0;   virtual void TearDown() = 0;-  void ResetStub() {-    std::shared_ptr<Channel> channel =-        CreateChannel(server_address_.str(), InsecureChannelCredentials());-    stub_ = grpc::testing::EchoTestService::NewStub(channel);-  }+  virtual void ResetStub() = 0;   grpc::testing::EchoTestService::Stub* GetStub() { return stub_.get(); }   protected:-  void SetUpStart(ServerBuilder* builder, Service* service) {-    int port = grpc_pick_unused_port_or_die();-    server_address_ << ""localhost:"" << port;-    // Setup server-    builder->AddListeningPort(server_address_.str(),-                              InsecureServerCredentials());+  std::unique_ptr<grpc::testing::EchoTestService::Stub> stub_;+  std::unique_ptr<Server> server_;++  virtual void SetUpStart(ServerBuilder* builder, Service* service) = 0;+  void SetUpStartCommon(ServerBuilder* builder, Service* service) {     builder->RegisterService(service);     builder->SetMaxMessageSize(         kMaxMessageSize_);  // For testing max message size.-    builder->RegisterService(&dup_pkg_service_);   }   void SetUpEnd(ServerBuilder* builder) { server_ = builder->BuildAndStart(); }   void TearDownStart() { server_->Shutdown(); }   void TearDownEnd() {}   private:-  std::unique_ptr<grpc::testing::EchoTestService::Stub> stub_;-  std::unique_ptr<Server> server_;-  std::ostringstream server_address_;   const int kMaxMessageSize_;-  TestServiceImplDupPkg dup_pkg_service_; }; -class CommonStressTestSyncServer : public CommonStressTest<TestServiceImpl> {+template <class Service>+class CommonStressTestInsecure : public CommonStressTest<Service> {+ public:+  void ResetStub() override {+    std::shared_ptr<Channel> channel =+        CreateChannel(server_address_.str(), InsecureChannelCredentials());+    this->stub_ = grpc::testing::EchoTestService::NewStub(channel);+  }++ protected:+  void SetUpStart(ServerBuilder* builder, Service* service) override {+    int port = grpc_pick_unused_port_or_die();+    this->server_address_ << ""localhost:"" << port;+    // Setup server+    builder->AddListeningPort(server_address_.str(),+                              InsecureServerCredentials());+    this->SetUpStartCommon(builder, service);+  }++ private:+  std::ostringstream server_address_;+};++template <class Service>+class CommonStressTestInproc : public CommonStressTest<Service> {+ public:+  void ResetStub() override {+    ChannelArguments args;+    std::shared_ptr<Channel> channel = this->server_->InProcessChannel(args);+    this->stub_ = grpc::testing::EchoTestService::NewStub(channel);+  }++ protected:+  void SetUpStart(ServerBuilder* builder, Service* service) override {+    this->SetUpStartCommon(builder, service);+  }+};++template <class BaseClass>+class CommonStressTestSyncServer : public BaseClass {  public:   void SetUp() override {     ServerBuilder builder;-    SetUpStart(&builder, &service_);-    SetUpEnd(&builder);+    this->SetUpStart(&builder, &service_);","Yup! This is because it was changed from a regular base class to a templated base class. Template resolution is late, and leaving it out confuses the compiler. [Ref](https://stackoverflow.com/questions/4643074/why-do-i-have-to-access-template-base-class-members-through-the-this-pointer)",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/11145,125655371,2017-07-05T14:17:46Z,src/core/ext/transport/inproc/inproc_transport.c,"@@ -0,0 +1,1183 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/core/ext/transport/inproc/inproc_transport.h""+#include <grpc/support/alloc.h>+#include <grpc/support/string_util.h>+#include <grpc/support/sync.h>+#include <grpc/support/time.h>+#include <string.h>+#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/slice/slice_internal.h""+#include ""src/core/lib/surface/api_trace.h""+#include ""src/core/lib/surface/channel.h""+#include ""src/core/lib/surface/channel_stack_type.h""+#include ""src/core/lib/surface/server.h""+#include ""src/core/lib/transport/connectivity_state.h""+#include ""src/core/lib/transport/error_utils.h""+#include ""src/core/lib/transport/transport_impl.h""++#define INPROC_LOG(...)                                          \+  do {                                                           \+    if (GRPC_TRACER_ON(grpc_inproc_trace)) gpr_log(__VA_ARGS__); \+  } while (0)++static const grpc_transport_vtable inproc_vtable;+static grpc_slice g_empty_slice;+static grpc_slice g_fake_path_key;+static grpc_slice g_fake_path_value;+static grpc_slice g_fake_auth_key;+static grpc_slice g_fake_auth_value;++typedef struct {+  gpr_mu mu;+  gpr_refcount refs;+} shared_mu;++typedef struct inproc_transport {+  grpc_transport base;+  shared_mu *mu;+  gpr_refcount refs;+  bool is_client;+  grpc_connectivity_state_tracker connectivity;+  void (*accept_stream_cb)(grpc_exec_ctx *exec_ctx, void *user_data,+                           grpc_transport *transport, const void *server_data);+  void *accept_stream_data;+  bool is_closed;+  struct inproc_transport *other_side;+  struct inproc_stream *stream_list;+} inproc_transport;++typedef struct sb_list_entry {+  grpc_slice_buffer sb;+  struct sb_list_entry *next;+} sb_list_entry;++// Specialize grpc_byte_stream for our use case+typedef struct {+  grpc_byte_stream base;+  sb_list_entry *le;+} inproc_slice_byte_stream;++typedef struct {+  // TODO (vjpai): Add some inlined elements to avoid alloc in simple cases+  sb_list_entry *head;+  sb_list_entry *tail;+} slice_buffer_list;++static void slice_buffer_list_init(slice_buffer_list *l) {+  l->head = NULL;+  l->tail = NULL;+}++static void sb_list_entry_destroy(grpc_exec_ctx *exec_ctx, sb_list_entry *le) {+  grpc_slice_buffer_destroy_internal(exec_ctx, &le->sb);+  gpr_free(le);+}++static void slice_buffer_list_destroy(grpc_exec_ctx *exec_ctx,+                                      slice_buffer_list *l) {+  sb_list_entry *curr = l->head;+  while (curr != NULL) {+    sb_list_entry *le = curr;+    curr = curr->next;+    sb_list_entry_destroy(exec_ctx, le);+  }+  l->head = NULL;+  l->tail = NULL;+}++static bool slice_buffer_list_empty(slice_buffer_list *l) {+  return l->head == NULL;+}++static void slice_buffer_list_append_entry(slice_buffer_list *l,+                                           sb_list_entry *next) {+  next->next = NULL;+  if (l->tail) {+    l->tail->next = next;+    l->tail = next;+  } else {+    l->head = next;+    l->tail = next;+  }+}++static grpc_slice_buffer *slice_buffer_list_append(slice_buffer_list *l) {+  sb_list_entry *next = gpr_malloc(sizeof(*next));+  grpc_slice_buffer_init(&next->sb);+  slice_buffer_list_append_entry(l, next);+  return &next->sb;+}++static sb_list_entry *slice_buffer_list_pophead(slice_buffer_list *l) {+  sb_list_entry *ret = l->head;+  l->head = l->head->next;+  if (l->head == NULL) {+    l->tail = NULL;+  }+  return ret;+}++typedef struct inproc_stream {+  inproc_transport *t;+  grpc_metadata_batch to_read_initial_md;+  uint32_t to_read_initial_md_flags;+  bool to_read_initial_md_filled;+  slice_buffer_list to_read_message;+  grpc_metadata_batch to_read_trailing_md;+  bool to_read_trailing_md_filled;+  bool read_closure_needed;+  grpc_closure read_closure;+  // Write buffer used only during gap at init time when client-side+  // stream is set up but server side stream is not yet set up+  grpc_metadata_batch write_buffer_initial_md;+  bool write_buffer_initial_md_filled;+  uint32_t write_buffer_initial_md_flags;+  gpr_timespec write_buffer_deadline;+  slice_buffer_list write_buffer_message;+  grpc_metadata_batch write_buffer_trailing_md;+  bool write_buffer_trailing_md_filled;+  grpc_error *write_buffer_cancel_error;++  struct inproc_stream *other_side;+  gpr_refcount refs;+  grpc_closure *closure_at_destroy;++  gpr_arena *arena;++  grpc_transport_stream_op_batch *recv_initial_md_op;+  grpc_transport_stream_op_batch *recv_message_op;+  grpc_transport_stream_op_batch *recv_trailing_md_op;++  inproc_slice_byte_stream recv_message_stream;++  bool initial_md_sent;+  bool trailing_md_sent;+  bool initial_md_recvd;+  bool trailing_md_recvd;++  grpc_error *cancel_self_error;+  grpc_error *cancel_other_error;++  gpr_timespec deadline;++  struct inproc_stream *stream_list_prev;+  struct inproc_stream *stream_list_next;+} inproc_stream;++static bool inproc_slice_byte_stream_next(grpc_exec_ctx *exec_ctx,+                                          grpc_byte_stream *bs, size_t max,+                                          grpc_closure *on_complete) {+  inproc_slice_byte_stream *stream = (inproc_slice_byte_stream *)bs;+  return (stream->le->sb.count != 0);+}++static grpc_error *inproc_slice_byte_stream_pull(grpc_exec_ctx *exec_ctx,+                                                 grpc_byte_stream *bs,+                                                 grpc_slice *slice) {+  inproc_slice_byte_stream *stream = (inproc_slice_byte_stream *)bs;+  *slice = grpc_slice_buffer_take_first(&stream->le->sb);+  return GRPC_ERROR_NONE;+}++static void inproc_slice_byte_stream_destroy(grpc_exec_ctx *exec_ctx,+                                             grpc_byte_stream *bs) {+  inproc_slice_byte_stream *stream = (inproc_slice_byte_stream *)bs;+  sb_list_entry_destroy(exec_ctx, stream->le);+}++void inproc_slice_byte_stream_init(inproc_slice_byte_stream *s,+                                   sb_list_entry *le) {+  s->base.length = (uint32_t)le->sb.length;+  s->base.flags = 0;+  s->base.next = inproc_slice_byte_stream_next;+  s->base.pull = inproc_slice_byte_stream_pull;+  s->base.destroy = inproc_slice_byte_stream_destroy;+  s->le = le;+}++static void ref_transport(inproc_transport *t) {+  INPROC_LOG(GPR_DEBUG, ""ref_transport %p"", t);+  gpr_ref(&t->refs);+}++static void really_destroy_transport(grpc_exec_ctx *exec_ctx,+                                     inproc_transport *t) {+  INPROC_LOG(GPR_DEBUG, ""really_destroy_transport %p"", t);+  grpc_connectivity_state_destroy(exec_ctx, &t->connectivity);+  if (gpr_unref(&t->mu->refs)) {+    gpr_free(t->mu);+  }+  gpr_free(t);+}++static void unref_transport(grpc_exec_ctx *exec_ctx, inproc_transport *t) {+  INPROC_LOG(GPR_DEBUG, ""unref_transport %p"", t);+  if (gpr_unref(&t->refs)) {+    really_destroy_transport(exec_ctx, t);+  }+}++static void ref_stream(inproc_stream *s) {+  INPROC_LOG(GPR_DEBUG, ""ref_stream %p"", s);+  gpr_ref(&s->refs);+}++static void really_destroy_stream(grpc_exec_ctx *exec_ctx, inproc_stream *s) {+  INPROC_LOG(GPR_DEBUG, ""really_destroy_stream %p"", s);+  // Remove the stream contents and remove from the transport's linked list+  gpr_mu_lock(&s->t->mu->mu);++  grpc_metadata_batch_destroy(exec_ctx, &s->to_read_initial_md);+  slice_buffer_list_destroy(exec_ctx, &s->to_read_message);+  grpc_metadata_batch_destroy(exec_ctx, &s->to_read_trailing_md);+  grpc_metadata_batch_destroy(exec_ctx, &s->write_buffer_initial_md);+  slice_buffer_list_destroy(exec_ctx, &s->write_buffer_message);+  grpc_metadata_batch_destroy(exec_ctx, &s->write_buffer_trailing_md);+  GRPC_ERROR_UNREF(s->write_buffer_cancel_error);+  GRPC_ERROR_UNREF(s->cancel_self_error);+  GRPC_ERROR_UNREF(s->cancel_other_error);++  inproc_stream *p = s->stream_list_prev;+  inproc_stream *n = s->stream_list_next;+  if (p) {+    p->stream_list_next = n;+  } else {+    s->t->stream_list = n;+  }+  if (n) {+    n->stream_list_prev = p;+  }+  gpr_mu_unlock(&s->t->mu->mu);++  unref_transport(exec_ctx, s->t);++  if (s->closure_at_destroy) {+    GRPC_CLOSURE_SCHED(exec_ctx, s->closure_at_destroy, GRPC_ERROR_NONE);+  }+}++static void unref_stream(grpc_exec_ctx *exec_ctx, inproc_stream *s) {+  INPROC_LOG(GPR_DEBUG, ""unref_stream %p"", s);+  if (gpr_unref(&s->refs)) {+    really_destroy_stream(exec_ctx, s);+  }+}++static void read_state_machine(grpc_exec_ctx *exec_ctx, void *arg,+                               grpc_error *error);++static void log_metadata(const grpc_metadata_batch *md_batch, bool is_client,+                         bool is_initial) {+  for (grpc_linked_mdelem *md = md_batch->list.head; md != NULL;+       md = md->next) {+    char *key = grpc_slice_to_c_string(GRPC_MDKEY(md->md));+    char *value = grpc_slice_to_c_string(GRPC_MDVALUE(md->md));+    gpr_log(GPR_INFO, ""INPROC:%s:%s: %s: %s"", is_initial ? ""HDR"" : ""TRL"",+            is_client ? ""CLI"" : ""SVR"", key, value);+    gpr_free(key);+    gpr_free(value);+  }+}++static grpc_error *fill_in_metadata(grpc_exec_ctx *exec_ctx, inproc_stream *s,+                                    const grpc_metadata_batch *metadata,+                                    uint32_t flags, grpc_metadata_batch *out_md,+                                    uint32_t *outflags, bool *markfilled) {+  if (outflags != NULL) {+    *outflags = flags;+  }+  if (markfilled != NULL) {+    *markfilled = true;+  }+  grpc_error *error = GRPC_ERROR_NONE;+  for (grpc_linked_mdelem *elem = metadata->list.head;+       (elem != NULL) && (error == GRPC_ERROR_NONE); elem = elem->next) {+    grpc_linked_mdelem *nelem = gpr_arena_alloc(s->arena, sizeof(*nelem));+    nelem->md = grpc_mdelem_from_slices(+        exec_ctx, grpc_slice_intern(GRPC_MDKEY(elem->md)),+        grpc_slice_intern(GRPC_MDVALUE(elem->md)));++    error = grpc_metadata_batch_link_tail(exec_ctx, out_md, nelem);+  }+  return error;+}++static int init_stream(grpc_exec_ctx *exec_ctx, grpc_transport *gt,+                       grpc_stream *gs, grpc_stream_refcount *refcount,+                       const void *server_data, gpr_arena *arena) {+  INPROC_LOG(GPR_DEBUG, ""init_stream %p %p %p"", gt, gs, server_data);+  inproc_transport *t = (inproc_transport *)gt;+  inproc_stream *s = (inproc_stream *)gs;+  s->arena = arena;+  gpr_ref_init(&s->refs, 1);  // don't count the transport stream list+  grpc_metadata_batch_init(&s->to_read_initial_md);+  s->to_read_initial_md_flags = 0;+  s->to_read_initial_md_filled = false;+  grpc_metadata_batch_init(&s->to_read_trailing_md);+  s->to_read_trailing_md_filled = false;+  grpc_metadata_batch_init(&s->write_buffer_initial_md);+  s->write_buffer_initial_md_flags = 0;+  s->write_buffer_initial_md_filled = false;+  grpc_metadata_batch_init(&s->write_buffer_trailing_md);+  s->write_buffer_trailing_md_filled = false;+  slice_buffer_list_init(&s->to_read_message);+  slice_buffer_list_init(&s->write_buffer_message);+  s->read_closure_needed = false;+  GRPC_CLOSURE_INIT(&s->read_closure, read_state_machine, s,+                    grpc_schedule_on_exec_ctx);+  s->t = t;+  s->closure_at_destroy = NULL;++  s->initial_md_sent = s->trailing_md_sent = s->initial_md_recvd =+      s->trailing_md_recvd = false;++  s->cancel_self_error = GRPC_ERROR_NONE;+  s->cancel_other_error = GRPC_ERROR_NONE;+  s->write_buffer_cancel_error = GRPC_ERROR_NONE;+  s->deadline = gpr_inf_future(GPR_CLOCK_MONOTONIC);+  s->write_buffer_deadline = gpr_inf_future(GPR_CLOCK_MONOTONIC);++  s->stream_list_prev = NULL;+  gpr_mu_lock(&t->mu->mu);+  s->stream_list_next = t->stream_list;+  if (t->stream_list) {+    t->stream_list->stream_list_prev = s;+  }+  t->stream_list = s;+  gpr_mu_unlock(&t->mu->mu);++  if (!server_data) {+    ref_transport(t);+    inproc_transport *st = t->other_side;+    ref_transport(st);+    s->other_side = NULL;  // will get filled in soon+    // Pass the client-side stream address to the server-side for a ref+    ref_stream(s);  // ref it now on behalf of server side to avoid destruction+    INPROC_LOG(GPR_DEBUG, ""calling accept stream cb %p %p"",+               st->accept_stream_cb, st->accept_stream_data);+    (*st->accept_stream_cb)(exec_ctx, st->accept_stream_data, &st->base,+                            (void *)s);+  } else {+    // This is the server-side and is being called through accept_stream_cb+    inproc_stream *cs = (inproc_stream *)server_data;+    s->other_side = cs;+    // Ref the server-side stream on behalf of the client now+    ref_stream(s);++    // Now we are about to affect the other side, so lock the transport","Yup, that's it. I'm changing the comment. Note that locking throughout the inproc transport is probably over-conservative as I'm just always locking out both sides of the transport to avoid the chance that the transport gets shutdown while we're in the middle of an op. This should be improved (of course, paying attention to the fact that more locks might mean more chances for deadlock down the road.)",
25518558,yongni,https://api.github.com/repos/grpc/grpc/pulls/11608,125721112,2017-07-05T18:23:15Z,tools/run_tests/python_utils/report_utils.py,"@@ -46,8 +46,22 @@ def _filter_msg(msg, output_format): def render_junit_xml_report(resultset, xml_report, suite_package='grpc',                             suite_name='tests'):   """"""Generate JUnit-like XML report.""""""-  root = ET.Element('testsuites')-  testsuite = ET.SubElement(root, 'testsuite', id='1', package=suite_package,+  tree = add_junit_xml_results(resultset, suite_package, suite_name, '1')+  create_xml_report_file(xml_report, tree)++def create_xml_report_file(xml_report, tree):+  """"""Generate JUnit-like report file from xml tree .""""""+  # ensure the report directory exists+  report_dir = os.path.dirname(os.path.abspath(xml_report))+  if not os.path.exists(report_dir):+    os.makedirs(report_dir)+  tree.write(xml_report, encoding='UTF-8')++def add_junit_xml_results(resultset, suite_package, suite_name, id,","Just to clarify, ""suite_package"", ""suite_name"" and ""id"" are not ignored.  They become the attribute of the new testsuite element under the old_tree of ""testsuites"".See below for example:```<testsuites><testsuite errors=""0"" failures=""0"" id=""6474f42c-25ae-4de9-a580-e2300cbeb8f6"" name=""go__go1.7:master"" package=""grpc_interop_matrix"" timestamp=""2017-07-05T11:16:12.256313""><testcase name=""cancel_after_first_response"" time=""16.6104240417""/><testcase name=""ping_pong"" time=""17.6899580956""/><testcase name=""client_streaming"" time=""18.3408219814""/><testcase name=""server_streaming"" time=""18.156867981""/><testcase name=""empty_stream"" time=""13.1786220074""/><testcase name=""timeout_on_sleeping_server"" time=""16.0977790356""/><testcase name=""empty_unary"" time=""13.9597160816""/><testcase name=""cancel_after_begin"" time=""14.9083271027""/><testcase name=""large_unary"" time=""17.2520859241""/></testsuite><testsuite errors=""0"" failures=""0"" id=""4cb8d3b8-56db-4375-a056-3a955175d16b"" name=""go__go1.8:master"" package=""grpc_interop_matrix"" timestamp=""2017-07-05T11:16:30.792714""><testcase name=""cancel_after_first_response"" time=""18.0730729103""/><testcase name=""ping_pong"" time=""14.6083629131""/><testcase name=""client_streaming"" time=""18.5181870461""/><testcase name=""server_streaming"" time=""17.1722960472""/><testcase name=""empty_stream"" time=""15.1755671501""/><testcase name=""timeout_on_sleeping_server"" time=""18.3323328495""/><testcase name=""empty_unary"" time=""16.8497140408""/><testcase name=""cancel_after_begin"" time=""16.2281429768""/><testcase name=""large_unary"" time=""17.6928610802""/></testsuite></testsuites>```Honest, I found it is easier to have a single file to look at for results rather than a bunch of files.  I have made some change to the API hopefully to address your other concerns.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11671,125762344,2017-07-05T21:29:47Z,src/core/ext/filters/client_channel/client_channel.c,"@@ -241,6 +243,10 @@ static void set_channel_connectivity_state_locked(grpc_exec_ctx *exec_ctx,                                          GRPC_ERROR_REF(error));     }   }+  if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    gpr_log(GPR_DEBUG, ""setting connectivity state to %s"",",Added the address of the channel data to all messages.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11696,125917825,2017-07-06T14:34:29Z,src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.c,"@@ -511,13 +529,23 @@ static void rr_connectivity_changed_locked(grpc_exec_ctx *exec_ctx, void *arg,                                            grpc_error *error) {   subchannel_data *sd = arg;   round_robin_lb_policy *p = sd->subchannel_list->policy;+  if (GRPC_TRACER_ON(grpc_lb_round_robin_trace)) {+    gpr_log(+        GPR_DEBUG,+        ""[RR %p] connectivity changed for subchannel %p, subchannel_list %p: ""+        ""prev_state=%d new_state=%d p->shutdown=%d ""+        ""sd->subchannel_list->shutting_down=%d error=%s"",+        (void *)p, (void *)sd->subchannel_list, (void *)sd->subchannel,+        sd->prev_connectivity_state, sd->curr_connectivity_state, p->shutdown,+        sd->subchannel_list->shutting_down, grpc_error_string(error));+  }   // If the policy is shutting down, unref and return.   if (p->shutdown) {     rr_subchannel_list_unref(exec_ctx, sd->subchannel_list, ""pol_shutdown"");     GRPC_LB_POLICY_WEAK_UNREF(exec_ctx, &p->base, ""pol_shutdown"");     return;   }-  if (sd->subchannel_list->shutting_down) {+  if (sd->subchannel_list->shutting_down && error == GRPC_ERROR_CANCELLED) {     // the subchannel list associated with sd has been discarded. This callback     // corresponds to the unsubscription.     GPR_ASSERT(error == GRPC_ERROR_CANCELLED);","This assert is probably no longer needed, since we won't enter this block if it's not true.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11696,125918782,2017-07-06T14:37:27Z,src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.c,"@@ -511,13 +529,23 @@ static void rr_connectivity_changed_locked(grpc_exec_ctx *exec_ctx, void *arg,                                            grpc_error *error) {   subchannel_data *sd = arg;   round_robin_lb_policy *p = sd->subchannel_list->policy;+  if (GRPC_TRACER_ON(grpc_lb_round_robin_trace)) {+    gpr_log(+        GPR_DEBUG,+        ""[RR %p] connectivity changed for subchannel %p, subchannel_list %p: ""+        ""prev_state=%d new_state=%d p->shutdown=%d ""+        ""sd->subchannel_list->shutting_down=%d error=%s"",+        (void *)p, (void *)sd->subchannel_list, (void *)sd->subchannel,","The subchannel and subchannel_list arguments are in the wrong order, relative to the format string.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11696,125919585,2017-07-06T14:40:02Z,src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.c,"@@ -195,11 +195,29 @@ static void rr_subchannel_list_unref(grpc_exec_ctx *exec_ctx, static void rr_subchannel_list_shutdown(grpc_exec_ctx *exec_ctx,                                         rr_subchannel_list *subchannel_list,                                         const char *reason) {+  if (subchannel_list->shutting_down) {+    if (GRPC_TRACER_ON(grpc_lb_round_robin_trace)) {+      gpr_log(GPR_DEBUG, ""Subchannel list %p already shutting down"",+              (void *)subchannel_list);+    }+    return;",Are there actually cases where we were calling shutdown twice on the same subchannel list?,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/11696,125982514,2017-07-06T18:41:13Z,src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.c,"@@ -195,11 +195,29 @@ static void rr_subchannel_list_unref(grpc_exec_ctx *exec_ctx, static void rr_subchannel_list_shutdown(grpc_exec_ctx *exec_ctx,                                         rr_subchannel_list *subchannel_list,                                         const char *reason) {+  if (subchannel_list->shutting_down) {+    if (GRPC_TRACER_ON(grpc_lb_round_robin_trace)) {+      gpr_log(GPR_DEBUG, ""Subchannel list %p already shutting down"",+              (void *)subchannel_list);+    }+    return;","Yes, and they are very common. Consider: four `sd`s that share/belong to a given subchannel_list. When this subchannel list is outdated, it'll be shutdown (line 556). But because the connectivity callback works at the `sd` level, this will happen for all `sd`s that share/belong to that subchannel list. See the following log for an example:```round_robin.c:527] [RR 0x7fa87d6d0e80] connectivity changed for sl 0x7fa87d55c9c0, subchannel 0x7fa87d5d0d40: prev_state=1 new_state=1 p->shutdown=0 sd->subchannel_list->shutting_down=0 error=""No Error""round_robin.c:557] about to shutdown OUTDATED Subchannel list 0x7fa87d55c9c0round_robin.c:205] Shutting down subchannel_list 0x7fa87d55c9c0round_robin.c:214] Unsubscribing from subchannel 0x7fa87d76a3e0 as part of shutting down subchannel_list 0x7fa87d55c9c0round_robin.c:214] Unsubscribing from subchannel 0x7fa87d5d0d40 as part of shutting down subchannel_list 0x7fa87d55c9c0round_robin.c:214] Unsubscribing from subchannel 0x7fa87d5d03e0 as part of shutting down subchannel_list 0x7fa87d55c9c0round_robin.c:214] Unsubscribing from subchannel 0x7fa87d5d0b60 as part of shutting down subchannel_list 0x7fa87d55c9c0round_robin.c:182] [RR 0x7fa87d6d0e80] subchannel_list 0x7fa87d55c9c0 UNREF 5->4round_robin.c:527] [RR 0x7fa87d6d0e80] connectivity changed for sl 0x7fa87d55c9c0, subchannel 0x7fa87d76a3e0: prev_state=1 new_state=1 p->shutdown=0 sd->subchannel_list->shutting_down=1 error=""No Error""round_robin.c:557] about to shutdown OUTDATED Subchannel list 0x7fa87d55c9c0round_robin.c:198] Subchannel list 0x7fa87d55c9c0 already shutting downround_robin.c:527] [RR 0x7fa87d6d0e80] connectivity changed for sl 0x7fa87d55c9c0, subchannel 0x7fa87d5d03e0: prev_state=1 new_state=1 p->shutdown=0 sd->subchannel_list->shutting_down=1 error=""No Error""round_robin.c:557] about to shutdown OUTDATED Subchannel list 0x7fa87d55c9c0round_robin.c:198] Subchannel list 0x7fa87d55c9c0 already shutting downround_robin.c:527] [RR 0x7fa87d6d0e80] connectivity changed for sl 0x7fa87d55c9c0, subchannel 0x7fa87d5d0b60: prev_state=1 new_state=1 p->shutdown=0 sd->subchannel_list->shutting_down=1 error=""No Error""round_robin.c:557] about to shutdown OUTDATED Subchannel list 0x7fa87d55c9c0round_robin.c:198] Subchannel list 0x7fa87d55c9c0 already shutting down```",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/11696,125985957,2017-07-06T18:54:43Z,src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.c,"@@ -511,13 +529,23 @@ static void rr_connectivity_changed_locked(grpc_exec_ctx *exec_ctx, void *arg,                                            grpc_error *error) {   subchannel_data *sd = arg;   round_robin_lb_policy *p = sd->subchannel_list->policy;+  if (GRPC_TRACER_ON(grpc_lb_round_robin_trace)) {+    gpr_log(+        GPR_DEBUG,+        ""[RR %p] connectivity changed for subchannel %p, subchannel_list %p: ""+        ""prev_state=%d new_state=%d p->shutdown=%d ""+        ""sd->subchannel_list->shutting_down=%d error=%s"",+        (void *)p, (void *)sd->subchannel_list, (void *)sd->subchannel,+        sd->prev_connectivity_state, sd->curr_connectivity_state, p->shutdown,+        sd->subchannel_list->shutting_down, grpc_error_string(error));+  }   // If the policy is shutting down, unref and return.   if (p->shutdown) {     rr_subchannel_list_unref(exec_ctx, sd->subchannel_list, ""pol_shutdown"");     GRPC_LB_POLICY_WEAK_UNREF(exec_ctx, &p->base, ""pol_shutdown"");     return;   }-  if (sd->subchannel_list->shutting_down) {+  if (sd->subchannel_list->shutting_down && error == GRPC_ERROR_CANCELLED) {","Yes. Again, concurrent updates. Consider:1. Subchannel list X=[a,b,c] is created as part of an update.2. Subchannels a, b, c have state INIT.3. An update comes, subchannel list Y=[a, x, y]. Outdated subchannel list X is shutdown, we unsubscribe from connectivity updates for subchannels a, b, c.4. rr_connectivity callback is called for ""a"". However, ""a"" is referenced by two separate `sd`s, one corresponding to X, another one to Y. In the context of the outdated list X, we only want to go inside this `if` when the rr_connectivity callback corresponds to the subchannel unsubscription from step 3. That is indicated by `error` being CANCELLED. The connectivity callback will be invoked for the ""a"" in Y with an `error == NONE` as it transitions from INIT to CONNECTING, for example.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/11719,126228300,2017-07-07T19:35:20Z,test/core/bad_client/tests/large_metadata.c,"@@ -166,34 +167,41 @@ static void server_verifier_sends_too_much_metadata(grpc_server *server,   cq_verifier_destroy(cqv); } -static void client_validator(grpc_slice_buffer *incoming) {+static bool client_validator(grpc_slice_buffer *incoming) {+  for (size_t i = 0; i < incoming->count; ++i) {+    const char* s = (const char*)GRPC_SLICE_START_PTR(incoming->slices[i]);+    char *hex = gpr_dump(s, GRPC_SLICE_LENGTH(incoming->slices[i]),+                         GPR_DUMP_HEX | GPR_DUMP_ASCII);+    gpr_log(GPR_INFO, ""RESPONSE SLICE %zu: %s"", i, hex);","no `%zu` on windows, need to use `%lu` and cast `i` to unsigned long.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/11189,126251489,2017-07-07T21:42:40Z,test/core/compression/stream_compression_test.c,"@@ -0,0 +1,291 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <string.h>++#include <grpc/grpc.h>+#include <grpc/slice_buffer.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>++#include ""src/core/lib/compression/stream_compression.h""++static void generate_random_payload(char *payload, size_t size) {+  size_t i;+  static const char chars[] = ""abcdefghijklmnopqrstuvwxyz1234567890"";+  for (i = 0; i < size - 1; ++i) {+    payload[i] = chars[rand() % (int)(sizeof(chars) - 1)];+  }+  payload[size - 1] = '\0';+}++static bool slice_buffer_equals_string(grpc_slice_buffer *buf,+                                       const char *str) {+  size_t i;+  if (buf->length != strlen(str)) {+    return false;+  }+  size_t pointer = 0;+  for (i = 0; i < buf->count; i++) {+    size_t slice_len = GRPC_SLICE_LENGTH(buf->slices[i]);+    if (0 != strncmp(str + pointer,+                     (char *)GRPC_SLICE_START_PTR(buf->slices[i]), slice_len)) {+      return false;+    }+    pointer += slice_len;+  }+  return true;+}++static void test_stream_compression_simple_compress_decompress() {+  const char test_str[] = ""aaaaaaabbbbbbbccccccctesttesttest"";+  grpc_slice_buffer source, relay, sink;+  grpc_slice_buffer_init(&source);+  grpc_slice_buffer_init(&relay);+  grpc_slice_buffer_init(&sink);+  grpc_stream_compression_context *compress_ctx =+      grpc_stream_compression_context_create(GRPC_STREAM_COMPRESSION_COMPRESS);+  grpc_stream_compression_context *decompress_ctx =+      grpc_stream_compression_context_create(+          GRPC_STREAM_COMPRESSION_DECOMPRESS);+  grpc_slice slice = grpc_slice_from_static_string(test_str);+  grpc_slice_buffer_add(&source, slice);+  GPR_ASSERT(grpc_stream_compress(compress_ctx, &source, &relay, NULL,+                                  ~(size_t)0,+                                  GRPC_STREAM_COMPRESSION_FLUSH_FINISH));+  bool end_of_context;+  size_t output_size;+  GPR_ASSERT(grpc_stream_decompress(decompress_ctx, &relay, &sink, &output_size,+                                    ~(size_t)0, &end_of_context));+  GPR_ASSERT(output_size = sizeof(test_str) - 1);","is this supposed to be a ==? You are assigning, so this assert will pass as long as test_str != 1",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/11752,126817434,2017-07-11T21:49:42Z,tools/internal_ci/linux/grpc_interop_toprod.cfg,"@@ -0,0 +1,26 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++# Config file for the internal CI (in protobuf text format)++# Location of the continuous shell script in repository.+build_file: ""grpc/tools/internal_ci/linux/grpc_interop_toprod.sh""+# grpc_interop tests can take 6+ hours to complete.+timeout_mins: 480+action {+  define_artifacts {+    regex: ""**/report.xml""","regex: ""**/*sponge_log.xml""https://github.com/grpc/grpc/blob/72cdf6f08242251810edae2df0b3f261afc73c2e/tools/internal_ci/macos/grpc_master.cfg#L22",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/11720,126821762,2017-07-11T22:12:31Z,src/core/ext/transport/chttp2/transport/internal.h,"@@ -270,7 +270,6 @@ struct grpc_chttp2_transport {   grpc_slice_buffer outbuf;","I can do this change. The main reason I switched away from this solution (which I used in the previous attempts) was the tracing story and because I need read access to t->settings.To get around this I could duplicate that data, pass it into the api separately, or maybe even have the flow_control* structs hold const pointers back to their transports or streams? Which of those seems cleanest?",
14932100,adelez,https://api.github.com/repos/grpc/grpc/pulls/11752,126823499,2017-07-11T22:22:29Z,tools/internal_ci/linux/grpc_interop_toprod.cfg,"@@ -0,0 +1,26 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++# Config file for the internal CI (in protobuf text format)++# Location of the continuous shell script in repository.+build_file: ""grpc/tools/internal_ci/linux/grpc_interop_toprod.sh""+# grpc_interop tests can take 6+ hours to complete.+timeout_mins: 480+action {+  define_artifacts {+    regex: ""**/report.xml""","Done. I'm just naming the interop result to sponge_log.xml, because there's only one xml file.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11761,126964752,2017-07-12T14:10:56Z,src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.c,"@@ -543,7 +545,12 @@ static void rr_connectivity_changed_locked(grpc_exec_ctx *exec_ctx, void *arg,   }   // If the policy is shutting down, unref and return.   if (p->shutdown) {+    const bool needs_shutdown = !sd->subchannel_list->shutting_down;     rr_subchannel_list_unref(exec_ctx, sd->subchannel_list, ""pol_shutdown"");+    if (needs_shutdown) {+      rr_subchannel_list_shutdown(exec_ctx, sd->subchannel_list,",Is it safe to call shutdown after calling unref?  What if unref causes the subchannel list to be destroyed?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11761,127237265,2017-07-13T14:44:24Z,src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.c,"@@ -743,6 +756,17 @@ static void rr_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,       gpr_zalloc(sizeof(subchannel_data) * num_addrs);   subchannel_list->num_subchannels = num_addrs;   gpr_ref_init(&subchannel_list->refcount, 1);+  if (p->latest_pending_subchannel_list != NULL && p->started_picking) {+    if (GRPC_TRACER_ON(grpc_lb_round_robin_trace)) {+      gpr_log(GPR_DEBUG,+              ""Shutting down latest pending subchannel list %p, about to be ""+              ""replaced by newer latest %p"",+              (void *)p->latest_pending_subchannel_list,+              (void *)subchannel_list);+    }+    rr_subchannel_list_shutdown(exec_ctx, p->latest_pending_subchannel_list,","How is it safe to call this if we're not holding a ref on `p->latest_pending_subchannel_list`?I think we need to hold a ref to both `p->subchannel_list` and `p->latest_pending_subchannel_list`.  Consequences of this:- When promoting `p->latest_pending_subchannel_list` to `p->subchannel_list`, we should shutdown and unref `p->subchannel_list` and then simply reassign; there's no need to add a new ref to `p->latest_pending_subchannel_list` at that point.- Any time we shut down a subchannel list, we should unref immediately after shutting down.  Given that, we might want to call `rr_subchannel_list_unref()` directly from `rr_subchannel_list_shutdown()` (and perhaps rename it to `rr_subchannel_list_shutdown_and_unref()`).",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/11587,127267464,2017-07-13T16:35:41Z,src/core/ext/transport/chttp2/transport/chttp2_transport.c,"@@ -2398,6 +2418,36 @@ void grpc_chttp2_config_default_keepalive_args(grpc_channel_args *args,                 &args->args[i],                 (grpc_integer_options){g_default_keepalive_permit_without_calls,                                        0, 1});+      } else if (0 ==+                 strcmp(args->args[i].key, GRPC_ARG_HTTP2_MAX_PING_STRIKES)) {+        g_default_max_ping_strikes = grpc_channel_arg_get_integer(","Setting global state from transport construction is the wrong thing to do:1. it's not thread safe (what if I create transports from two threads)2. it's order dependent (max_ping_strikes now depends on the construction order of transports, which might change even due to network latency - meaning this could become a random number)Better would be to hold these values as properties of the transport (preferably as some sub-struct... grpc_chttp2_ping_enforcement_args?)",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11755,127294025,2017-07-13T18:24:44Z,src/core/ext/filters/client_channel/http_proxy.c,"@@ -80,6 +81,39 @@ static bool proxy_mapper_map_name(grpc_exec_ctx* exec_ctx,     grpc_uri_destroy(uri);     return false;   }+  char* no_proxy_str = gpr_getenv(""no_proxy"");+  if (no_proxy_str != NULL) {+    char *server_host;+    char *server_port;+    if (!gpr_split_host_port(uri->path[0] == '/' ? uri->path + 1 : uri->path, &server_host, &server_port)) {+      gpr_log(GPR_INFO, ""unable to split host and port, not checking no_proxy list for host '%s'"", server_uri);+    } else {+      size_t uri_len = strlen(server_host);+      size_t i = 0;+      size_t marker = 0;+      while (no_proxy_str[i] != 0) {","I suggest using `gpr_string_split()` to split up the entries in the environment variable value.  Then we can just iterate through the array, comparing `server_host` against each element in turn.https://github.com/grpc/grpc/blob/master/src/core/lib/support/string.h#L84",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/11761,127326843,2017-07-13T20:48:26Z,src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.c,"@@ -743,6 +756,17 @@ static void rr_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,       gpr_zalloc(sizeof(subchannel_data) * num_addrs);   subchannel_list->num_subchannels = num_addrs;   gpr_ref_init(&subchannel_list->refcount, 1);+  if (p->latest_pending_subchannel_list != NULL && p->started_picking) {+    if (GRPC_TRACER_ON(grpc_lb_round_robin_trace)) {+      gpr_log(GPR_DEBUG,+              ""Shutting down latest pending subchannel list %p, about to be ""+              ""replaced by newer latest %p"",+              (void *)p->latest_pending_subchannel_list,+              (void *)subchannel_list);+    }+    rr_subchannel_list_shutdown(exec_ctx, p->latest_pending_subchannel_list,","Done. I've changed the ""reasons"" for the unrefs to be more descriptive. There are two types of references:1. Those taken once. Namely, the one intrinsic to the creation of the list, and the one when the new subchannel list is made pending (which all lists are, even if for the first list we immediately turn around and make it the current one), ""make_pending"".2. References taken on account of the connectivity callback, reason ""started_picking"".Correspondingly, all unrefs inside the `rr_connectivity_changed_locked` callback correspond to ""started_picking"" refs, and the ""reason"" for those unrefs has the ""+started_picking"" suffix. All other unrefs -those happening outside the callback- have the ""+make_pending"" suffix **except** for the _already present_ unref in `rr_subchannel_list_shutdown`, which pairs up with the reference created when the subchannel list is minted (in the new `rr_subchannel_list_create` function).All shutdowns are now followed by an unref, yes, but given that `rr_subchannel_list_shutdown` already has an unref inside, I wonder if it isn't cleaner to leave the other unrefs outside. But I don't feel too strongly about it.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11761,127343678,2017-07-13T22:02:27Z,src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.c,"@@ -743,6 +756,17 @@ static void rr_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,       gpr_zalloc(sizeof(subchannel_data) * num_addrs);   subchannel_list->num_subchannels = num_addrs;   gpr_ref_init(&subchannel_list->refcount, 1);+  if (p->latest_pending_subchannel_list != NULL && p->started_picking) {+    if (GRPC_TRACER_ON(grpc_lb_round_robin_trace)) {+      gpr_log(GPR_DEBUG,+              ""Shutting down latest pending subchannel list %p, about to be ""+              ""replaced by newer latest %p"",+              (void *)p->latest_pending_subchannel_list,+              (void *)subchannel_list);+    }+    rr_subchannel_list_shutdown(exec_ctx, p->latest_pending_subchannel_list,","As per our discussion, I think there are duplicate refs here for the ones you identified as type 1.  I think the subchannel list does not need to hold a reference to itself -- the one returned from `rr_subchannel_list_create()` is the one that should be held by the RR policy, so there's no need for an additional ref on line 791 below.  And then there is also no need for an additional unref every time we shut down a subchannel list.  So we can rename `rr_subchannel_list_shutdown()` to `rr_subchannel_list_shutdown_and_unref()`.",
17460127,y-zeng,https://api.github.com/repos/grpc/grpc/pulls/11587,127344087,2017-07-13T22:04:53Z,src/core/ext/transport/chttp2/transport/chttp2_transport.c,"@@ -2398,6 +2418,36 @@ void grpc_chttp2_config_default_keepalive_args(grpc_channel_args *args,                 &args->args[i],                 (grpc_integer_options){g_default_keepalive_permit_without_calls,                                        0, 1});+      } else if (0 ==+                 strcmp(args->args[i].key, GRPC_ARG_HTTP2_MAX_PING_STRIKES)) {+        g_default_max_ping_strikes = grpc_channel_arg_get_integer(","Thanks for the review!These global values are not set from transport construction, they are set in `grpc_chttp2_config_default_keepalive_args()`. It's an internal interface, and must only be called at the initialization stage, as stated [here](https://github.com/grpc/grpc/blob/master/src/core/ext/transport/chttp2/transport/internal.h#L853).The transport struct has corresponding properties in `grpc_chttp2_repeated_ping_policy`. When constructing a transport, we will use `g_default_max_ping_strikes` as the default value of `grpc_chttp2_transport.ping_policy.max_ping_strikes`.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/11785,127441425,2017-07-14T11:58:05Z,tools/run_tests/dockerize/build_interop_image.sh,"@@ -75,6 +75,22 @@ git branch -f jenkins-docker  CONTAINER_NAME=""build_${BASE_NAME}_$(uuidgen)"" +# build_interop.sh could be missing from old git tree and we will have issue unless we find the proper+# build_interop.sh to use in such case.+if ! [ -e $GRPC_ROOT/tools/dockerfile/interoptest/$BASE_NAME/build_interop.sh ]; then","I get that but that's an inconsistency. if you are using grpc_interop_cxx_debian8/Dockerfile  from head, you should also use grpc_interop_cxx_debian8/build_interop.sh from HEAD. Or you should use Dockerfile and build_interop.sh from the old revision. But combining one of them from head seems as a hack.Can we adding unnessary complexity to build_interop_image.sh? Interop test building is already complicated enough. If you really need to override the build_interop.sh file location, can you do that in some other way? (e.g. env variable set by the matrix script or sth in that sense)",
25518558,yongni,https://api.github.com/repos/grpc/grpc/pulls/11785,127482487,2017-07-14T15:24:53Z,tools/run_tests/dockerize/build_interop_image.sh,"@@ -75,6 +75,22 @@ git branch -f jenkins-docker  CONTAINER_NAME=""build_${BASE_NAME}_$(uuidgen)"" +# build_interop.sh could be missing from old git tree and we will have issue unless we find the proper+# build_interop.sh to use in such case.+if ! [ -e $GRPC_ROOT/tools/dockerfile/interoptest/$BASE_NAME/build_interop.sh ]; then","We need to build an older client and we have a) code to compile; b) Dockerfile; 3) build_interop.sh.  Given that we introduced a runtime variation, b and c don't exist on the old tree.  We have two options:A) Use b and c from head for lang_runtime;B) Use b from head and c from old tree.I first tried Option A, but ran into problem because build_interop.sh has changed over time and no longer works as-is against old tree.  We could add logic to fix build_interop.sh or find an alternative from old tree which is Option B.In Option B, we don't have the lang_runtime/build_image.sh, so the closest we can find is lang/build_image.sh.  This is not ideal, but it guaranteed to work.If we go with Option A, we need to either fix build_image.sh from head by bringing version specific build_image.sh logic to head.What do you prefer among all these no optimal solutions?",
6765840,bsyk,https://api.github.com/repos/grpc/grpc/pulls/11755,127489858,2017-07-14T15:59:09Z,src/core/ext/filters/client_channel/http_proxy.c,"@@ -83,35 +84,47 @@ static bool proxy_mapper_map_name(grpc_exec_ctx* exec_ctx,   }   char* no_proxy_str = gpr_getenv(""no_proxy"");   if (no_proxy_str != NULL) {-    char *server_host;-    char *server_port;-    if (!gpr_split_host_port(uri->path[0] == '/' ? uri->path + 1 : uri->path, &server_host, &server_port)) {-      gpr_log(GPR_INFO, ""unable to split host and port, not checking no_proxy list for host '%s'"", server_uri);+    static const char* NO_PROXY_SEPARATOR = "","";+    bool use_proxy = true;+    char* server_host;+    char* server_port;+    if (!gpr_split_host_port(uri->path[0] == '/' ? uri->path + 1 : uri->path,+                             &server_host, &server_port)) {+      gpr_log(GPR_INFO,+              ""unable to split host and port, not checking no_proxy list for ""+              ""host '%s'"",+              server_uri);     } else {       size_t uri_len = strlen(server_host);-      size_t i = 0;-      size_t marker = 0;-      while (no_proxy_str[i] != 0) {-        if (no_proxy_str[i] == ',' || no_proxy_str[i] == ' ') {-          size_t no_proxy_len = i - marker;-          if (no_proxy_len <= uri_len) {-            if (strncmp(&no_proxy_str[marker], &server_host[uri_len - no_proxy_len], no_proxy_len) == 0) {-              gpr_log(GPR_INFO, ""not using proxy for host in no_proxy list '%s'"",-                      server_uri);-              grpc_uri_destroy(uri);-              gpr_free(*name_to_resolve);-              gpr_free(server_host);-              gpr_free(server_port);-              *name_to_resolve = NULL;-              return false;-            }-          }-          marker = i + 1;+      char** no_proxy_hosts;+      size_t num_no_proxy_hosts;+      gpr_string_split(no_proxy_str, NO_PROXY_SEPARATOR, &no_proxy_hosts,+                       &num_no_proxy_hosts);+      for (size_t i = 0; i < num_no_proxy_hosts; i++) {+        char* no_proxy_entry = no_proxy_hosts[i];+        size_t no_proxy_len = strlen(no_proxy_entry);+        if (no_proxy_len <= uri_len &&+            gpr_stricmp(no_proxy_entry, &server_host[uri_len - no_proxy_len]) ==+                0) {+          gpr_log(GPR_INFO, ""not using proxy for host in no_proxy list '%s'"",+                  server_uri);+          use_proxy = false;",Added check to for-loop exit condition,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11583,127759300,2017-07-17T16:42:44Z,src/python/grpcio_testing/grpc_testing/_channel.py,"@@ -0,0 +1,753 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Channel fixtures.""""""++import collections+import logging+import threading++import grpc+import grpc_testing+from grpc_testing import _common++_NOT_YET_OBSERVED = object()+++class _RpcState(object):++    def __init__(self, invocation_metadata, requests, requests_closed):+        self.condition = threading.Condition()+        self.invocation_metadata = invocation_metadata+        self.requests = requests+        self.requests_closed = requests_closed+        self.initial_metadata = None+        self.responses = []+        self.trailing_metadata = None+        self.code = None+        self.details = None+++def _state_add_request(state, request):+    with state.condition:+        if state.code is None and not state.requests_closed:+            state.requests.append(request)+            state.condition.notify_all()+            return True+        else:+            return False+++def _state_no_more_requests(state):+    with state.condition:+        if state.code is None and not state.requests_closed:+            state.requests_closed = True+            state.condition.notify_all()+++def _state_take_response(state):+    with state.condition:+        while True:+            if state.code is grpc.StatusCode.OK:+                if state.responses:+                    response = state.responses.pop(0)+                    return _common.ChannelRpcRead(response, None, None, None)+                else:+                    return _common.ChannelRpcRead(None, state.trailing_metadata,+                                                  grpc.StatusCode.OK,+                                                  state.details)+            elif state.code is None:+                if state.responses:+                    response = state.responses.pop(0)+                    return _common.ChannelRpcRead(response, None, None, None)+                else:+                    state.condition.wait()+            else:+                return _common.ChannelRpcRead(None, state.trailing_metadata,+                                              state.code, state.details)+++def _state_cancel(state, code, details):+    with state.condition:+        if state.code is None:+            if state.initial_metadata is None:+                state.initial_metadata = _common.FUSSED_EMPTY_METADATA+            state.trailing_metadata = _common.FUSSED_EMPTY_METADATA+            state.code = code+            state.details = details+            state.condition.notify_all()+            return True+        else:+            return False+++def _state_terminate(state):+    with state.condition:+        while True:","It took me a while to work through why I like the `while True:` form but I think I can articulate it (and I hope I'm not fooling myself with a post hoc rationalization). Consider```pythonwith my_condition:  while not my_first_thing and not my_second_thing:    my_condition.wait()if my_first_thing:  return respond_to_my_first_thing()else:  return respond_to_my_second_thing()```. That's bad because it unnecessarily double-tests the wait condition (first to determine whether or not to remain in the loop and again to determine why it got out of the loop). In that case```pythonwith my_condition:  while True:    if my_first_thing:      return respond_to_my_first_thing()    elif my_second_thing:      return respond_to_my_second_thing()    else:      my_condition.wait()```is clearly better because it only does the minimum number of tests. What's attractive to me about the `while True:` for the single-condition cases, then, is that it's just a simpler case of the appropriate solution for the multiple-condition cases.",
5120183,jcanizales,https://api.github.com/repos/grpc/grpc/pulls/11832,127834265,2017-07-17T21:44:26Z,src/objective-c/GRPCClient/GRPCCall.m,"@@ -422,33 +430,55 @@ - (void)startWithWriteable:(id<GRXWriteable>)writeable {   // that the life of the instance is determined by this retain cycle.   _retainSelf = self; -  _responseWriteable = [[GRXConcurrentWriteable alloc] initWithWriteable:writeable-                                                           dispatchQueue:_responseQueue];--  _wrappedCall = [[GRPCWrappedCall alloc] initWithHost:_host serverName:_serverName path:_path];-  NSAssert(_wrappedCall, @""Error allocating RPC objects. Low memory?"");--  [self sendHeaders:_requestHeaders];-  [self invokeCall];--  // TODO(jcanizales): Extract this logic somewhere common.-  NSString *host = [NSURL URLWithString:[@""https://"" stringByAppendingString:_host]].host;-  if (!host) {-    // TODO(jcanizales): Check this on init.-    [NSException raise:NSInvalidArgumentException format:@""host of %@ is nil"", _host];-  }   __weak typeof(self) weakSelf = self;-  _connectivityMonitor = [GRPCConnectivityMonitor monitorWithHost:host];-  void (^handler)() = ^{+  void (^performCall)() = ^{     typeof(self) strongSelf = weakSelf;     if (strongSelf) {-      [strongSelf finishWithError:[NSError errorWithDomain:kGRPCErrorDomain-                                                      code:GRPCErrorCodeUnavailable-                                                  userInfo:@{ NSLocalizedDescriptionKey : @""Connectivity lost."" }]];+      strongSelf->_responseWriteable = [[GRXConcurrentWriteable alloc] initWithWriteable:writeable+                                                                           dispatchQueue:strongSelf->_responseQueue];++      strongSelf->_wrappedCall = [[GRPCWrappedCall alloc] initWithHost:strongSelf->_host+                                                            serverName:strongSelf->_serverName+                                                                  path:strongSelf->_path];+      NSAssert(_wrappedCall, @""Error allocating RPC objects. Low memory?"");++      [strongSelf sendHeaders:_requestHeaders];+      [strongSelf invokeCall];++      // TODO(jcanizales): Extract this logic somewhere common.+      NSString *host = [NSURL URLWithString:[@""https://"" stringByAppendingString:strongSelf->_host]].host;+      if (!host) {+        // TODO(jcanizales): Check this on init.+        [NSException raise:NSInvalidArgumentException format:@""host of %@ is nil"", strongSelf->_host];+      }+      strongSelf->_connectivityMonitor = [GRPCConnectivityMonitor monitorWithHost:host];+      void (^handler)() = ^{+        typeof(self) strongSelf = weakSelf;","You're hiding `strongSelf` here with another `strongSelf`. It might be clearer to put all of this in a method, and on line 437 do:```obj-cif (strongSelf) {  [strongSelf someMethod];}```Then you can use `self` inside that method, and refer to ivars normally (`_myIvar` instead of `strongSelf->_myIvar`).",
5120183,jcanizales,https://api.github.com/repos/grpc/grpc/pulls/11833,127836721,2017-07-17T21:56:21Z,examples/objective-c/auth_sample/MakeRPCViewController.m,"@@ -72,8 +83,7 @@ - (void)viewWillAppear:(BOOL)animated {       }];    // Set the access token to be used.-  NSString *accessToken = GIDSignIn.sharedInstance.currentUser.authentication.accessToken;-  call.requestHeaders[@""Authorization""] = [@""Bearer "" stringByAppendingString:accessToken];+  call.oauthToken = [[OAuthAuthenticator alloc] init];","It'd be nice to have a gRPC+GID category in an optional subspec, so that people using this don't have to write the `OAuthAuthenticator` class above; they'll just call something like `call.useGIDToken` or whatever; just one line of code.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11865,127988255,2017-07-18T14:18:05Z,src/core/lib/support/avl.c,"@@ -32,22 +32,23 @@ gpr_avl gpr_avl_create(const gpr_avl_vtable *vtable) {   return out; } -static gpr_avl_node *ref_node(gpr_avl_node *node) {+static gpr_avl_node *ref_node(gpr_avl_node *node, void *user_data) {",Why add the `user_data` param here if it's not used for anything?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11755,127997626,2017-07-18T14:48:18Z,src/core/ext/filters/client_channel/http_proxy.c,"@@ -83,35 +84,47 @@ static bool proxy_mapper_map_name(grpc_exec_ctx* exec_ctx,   }   char* no_proxy_str = gpr_getenv(""no_proxy"");   if (no_proxy_str != NULL) {-    char *server_host;-    char *server_port;-    if (!gpr_split_host_port(uri->path[0] == '/' ? uri->path + 1 : uri->path, &server_host, &server_port)) {-      gpr_log(GPR_INFO, ""unable to split host and port, not checking no_proxy list for host '%s'"", server_uri);+    static const char* NO_PROXY_SEPARATOR = "","";+    bool use_proxy = true;+    char* server_host;+    char* server_port;+    if (!gpr_split_host_port(uri->path[0] == '/' ? uri->path + 1 : uri->path,+                             &server_host, &server_port)) {+      gpr_log(GPR_INFO,+              ""unable to split host and port, not checking no_proxy list for ""+              ""host '%s'"",+              server_uri);     } else {       size_t uri_len = strlen(server_host);-      size_t i = 0;-      size_t marker = 0;-      while (no_proxy_str[i] != 0) {-        if (no_proxy_str[i] == ',' || no_proxy_str[i] == ' ') {-          size_t no_proxy_len = i - marker;-          if (no_proxy_len <= uri_len) {-            if (strncmp(&no_proxy_str[marker], &server_host[uri_len - no_proxy_len], no_proxy_len) == 0) {-              gpr_log(GPR_INFO, ""not using proxy for host in no_proxy list '%s'"",-                      server_uri);-              grpc_uri_destroy(uri);-              gpr_free(*name_to_resolve);-              gpr_free(server_host);-              gpr_free(server_port);-              *name_to_resolve = NULL;-              return false;-            }-          }-          marker = i + 1;+      char** no_proxy_hosts;+      size_t num_no_proxy_hosts;+      gpr_string_split(no_proxy_str, NO_PROXY_SEPARATOR, &no_proxy_hosts,+                       &num_no_proxy_hosts);+      for (size_t i = 0; i < num_no_proxy_hosts; i++) {+        char* no_proxy_entry = no_proxy_hosts[i];+        size_t no_proxy_len = strlen(no_proxy_entry);+        if (no_proxy_len <= uri_len &&+            gpr_stricmp(no_proxy_entry, &server_host[uri_len - no_proxy_len]) ==+                0) {+          gpr_log(GPR_INFO, ""not using proxy for host in no_proxy list '%s'"",+                  server_uri);+          use_proxy = false;","Oh, sorry, I see -- you added it to the for loop condition instead of just adding a break here.I think using break makes the code more readable than doing it in the for loop condition (and it's every so slightly more efficient, since you don't need to reevaluate the bool each time).  Would you mind changing it?  Thanks!",
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/11733,128043450,2017-07-18T17:35:19Z,src/core/lib/security/credentials/credentials.h,"@@ -138,48 +138,39 @@ grpc_channel_credentials *grpc_channel_credentials_from_arg( grpc_channel_credentials *grpc_channel_credentials_find_in_args(     const grpc_channel_args *args); -/* --- grpc_credentials_md. --- */+/* --- grpc_credentials_mdelem_list. --- */  typedef struct {-  grpc_slice key;-  grpc_slice value;-} grpc_credentials_md;+  grpc_mdelem *md;+  size_t size;+} grpc_credentials_mdelem_list;","I would prefer `_array` than `_list` but if we're already the list suffix for other things in the code which are not linked list, I am fine with that.",
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/11733,128044733,2017-07-18T17:40:10Z,src/core/lib/security/credentials/credentials_metadata.c,"@@ -24,65 +24,34 @@  #include ""src/core/lib/slice/slice_internal.h"" -static void store_ensure_capacity(grpc_credentials_md_store *store) {-  if (store->num_entries == store->allocated) {-    store->allocated = (store->allocated == 0) ? 1 : store->allocated * 2;-    store->entries = gpr_realloc(-        store->entries, store->allocated * sizeof(grpc_credentials_md));+static void mdelem_list_ensure_capacity(grpc_credentials_mdelem_list *list,+                                        size_t space_needed) {+  size_t target_size = list->size + space_needed;",Not sure I understand why `target_size != space_needed` here.Don't you want to exit early without realloc if `list->size > space_needed`?,
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/11733,128053167,2017-07-18T18:11:33Z,src/core/lib/security/credentials/oauth2/oauth2_credentials.c,"@@ -205,63 +206,122 @@ grpc_oauth2_token_fetcher_credentials_parse_server_response( static void on_oauth2_token_fetcher_http_response(grpc_exec_ctx *exec_ctx,                                                   void *user_data,                                                   grpc_error *error) {+  GRPC_LOG_IF_ERROR(""oauth_fetch"", GRPC_ERROR_REF(error));   grpc_credentials_metadata_request *r =       (grpc_credentials_metadata_request *)user_data;   grpc_oauth2_token_fetcher_credentials *c =       (grpc_oauth2_token_fetcher_credentials *)r->creds;+  grpc_mdelem access_token_md = GRPC_MDNULL;   gpr_timespec token_lifetime;-  grpc_credentials_status status;--  GRPC_LOG_IF_ERROR(""oauth_fetch"", GRPC_ERROR_REF(error));-+  grpc_credentials_status status =+      grpc_oauth2_token_fetcher_credentials_parse_server_response(+          exec_ctx, &r->response, &access_token_md, &token_lifetime);+  // Update cache and grab list of pending requests.   gpr_mu_lock(&c->mu);-  status = grpc_oauth2_token_fetcher_credentials_parse_server_response(-      exec_ctx, &r->response, &c->access_token_md, &token_lifetime);-  if (status == GRPC_CREDENTIALS_OK) {-    c->token_expiration =-        gpr_time_add(gpr_now(GPR_CLOCK_REALTIME), token_lifetime);-    r->cb(exec_ctx, r->user_data, c->access_token_md->entries,-          c->access_token_md->num_entries, GRPC_CREDENTIALS_OK, NULL);-  } else {-    c->token_expiration = gpr_inf_past(GPR_CLOCK_REALTIME);-    r->cb(exec_ctx, r->user_data, NULL, 0, status,-          ""Error occured when fetching oauth2 token."");-  }+  c->token_fetch_pending = false;+  c->access_token_md = GRPC_MDELEM_REF(access_token_md);+  c->token_expiration =+      status == GRPC_CREDENTIALS_OK+          ? gpr_time_add(gpr_now(GPR_CLOCK_REALTIME), token_lifetime)+          : gpr_inf_past(GPR_CLOCK_REALTIME);+  grpc_oauth2_pending_get_request_metadata *pending_request =+      c->pending_requests;+  c->pending_requests = NULL;   gpr_mu_unlock(&c->mu);+  // Invoke callbacks for all pending requests.+  while (pending_request != NULL) {+    if (status == GRPC_CREDENTIALS_OK) {+      grpc_credentials_mdelem_list_add(pending_request->md_list,+                                       access_token_md);+    } else {+      error = GRPC_ERROR_CREATE_REFERENCING_FROM_STATIC_STRING(+          ""Error occured when fetching oauth2 token."", &error, 1);+    }+    GRPC_CLOSURE_SCHED(exec_ctx, pending_request->on_request_metadata, error);+    grpc_oauth2_pending_get_request_metadata *prev = pending_request;+    pending_request = pending_request->next;+    gpr_free(prev);+  }+  GRPC_MDELEM_UNREF(exec_ctx, access_token_md);+  grpc_call_credentials_unref(exec_ctx, r->creds);   grpc_credentials_metadata_request_destroy(exec_ctx, r); } -static void oauth2_token_fetcher_get_request_metadata(+static bool oauth2_token_fetcher_get_request_metadata(     grpc_exec_ctx *exec_ctx, grpc_call_credentials *creds,     grpc_polling_entity *pollent, grpc_auth_metadata_context context,-    grpc_credentials_metadata_cb cb, void *user_data) {+    grpc_credentials_mdelem_list *md_list, grpc_closure *on_request_metadata,+    grpc_error **error) {   grpc_oauth2_token_fetcher_credentials *c =       (grpc_oauth2_token_fetcher_credentials *)creds;+  // Check if we can use the cached token.   gpr_timespec refresh_threshold = gpr_time_from_seconds(       GRPC_SECURE_TOKEN_REFRESH_THRESHOLD_SECS, GPR_TIMESPAN);-  grpc_credentials_md_store *cached_access_token_md = NULL;-  {-    gpr_mu_lock(&c->mu);-    if (c->access_token_md != NULL &&-        (gpr_time_cmp(-             gpr_time_sub(c->token_expiration, gpr_now(GPR_CLOCK_REALTIME)),-             refresh_threshold) > 0)) {-      cached_access_token_md =-          grpc_credentials_md_store_ref(c->access_token_md);-    }+  grpc_mdelem cached_access_token_md = GRPC_MDNULL;+  gpr_mu_lock(&c->mu);+  if (!GRPC_MDISNULL(c->access_token_md) &&+      (gpr_time_cmp(+           gpr_time_sub(c->token_expiration, gpr_now(GPR_CLOCK_REALTIME)),+           refresh_threshold) > 0)) {+    cached_access_token_md = GRPC_MDELEM_REF(c->access_token_md);+  }+  if (!GRPC_MDISNULL(cached_access_token_md)) {     gpr_mu_unlock(&c->mu);+    grpc_credentials_mdelem_list_add(md_list, cached_access_token_md);+    GRPC_MDELEM_UNREF(exec_ctx, cached_access_token_md);+    return true;   }-  if (cached_access_token_md != NULL) {-    cb(exec_ctx, user_data, cached_access_token_md->entries,-       cached_access_token_md->num_entries, GRPC_CREDENTIALS_OK, NULL);-    grpc_credentials_md_store_unref(exec_ctx, cached_access_token_md);-  } else {-    c->fetch_func(-        exec_ctx,-        grpc_credentials_metadata_request_create(creds, cb, user_data),-        &c->httpcli_context, pollent, on_oauth2_token_fetcher_http_response,-        gpr_time_add(gpr_now(GPR_CLOCK_REALTIME), refresh_threshold));+  // Couldn't get the token from the cache.+  // Add request to c->pending_requests and start a new fetch if needed.+  grpc_oauth2_pending_get_request_metadata *pending_request =+      (grpc_oauth2_pending_get_request_metadata *)gpr_malloc(+          sizeof(*pending_request));+  pending_request->md_list = md_list;+  pending_request->on_request_metadata = on_request_metadata;+  pending_request->next = c->pending_requests;+  c->pending_requests = pending_request;+  bool start_fetch = false;+  if (!c->token_fetch_pending) {+    c->token_fetch_pending = true;+    start_fetch = true;+  }+  gpr_mu_unlock(&c->mu);+  if (start_fetch) {+    grpc_call_credentials_ref(creds);+    c->fetch_func(exec_ctx, grpc_credentials_metadata_request_create(creds),+                  &c->httpcli_context, pollent,+                  on_oauth2_token_fetcher_http_response,+                  gpr_time_add(gpr_now(GPR_CLOCK_REALTIME), refresh_threshold));   }+  return false;+}++static void oauth2_token_fetcher_cancel_get_request_metadata(+    grpc_exec_ctx *exec_ctx, grpc_call_credentials *creds,+    grpc_credentials_mdelem_list *md_list, grpc_error *error) {+  grpc_oauth2_token_fetcher_credentials *c =+      (grpc_oauth2_token_fetcher_credentials *)creds;+  gpr_mu_lock(&c->mu);+  grpc_oauth2_pending_get_request_metadata *prev = NULL;+  grpc_oauth2_pending_get_request_metadata *pending_request =+      c->pending_requests;+  while (pending_request != NULL) {+    if (pending_request->md_list == md_list) {+      if (prev != NULL) {",Please add a comment here: `// Remove matching pending request from the list.`,
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/11733,128055602,2017-07-18T18:21:07Z,src/core/lib/security/credentials/plugin/plugin_credentials.h,"@@ -21,10 +21,22 @@  #include ""src/core/lib/security/credentials/credentials.h"" -typedef struct {+struct grpc_plugin_credentials;++typedef struct grpc_plugin_credentials_pending_request {+  bool cancelled;+  struct grpc_plugin_credentials *creds;+  grpc_credentials_mdelem_list *md_list;+  grpc_closure *on_request_metadata;+  struct grpc_plugin_credentials_pending_request *prev;",Are you sure that you need a double-linked list here? It seems to add some complexity for not much gain but maybe I'm missing something.,
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/11583,128095430,2017-07-18T21:06:03Z,src/python/grpcio_testing/grpc_testing/__init__.py,"@@ -0,0 +1,683 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Fixtures for use in testing gRPC Python-using application code.""""""++import abc+import collections++from google.protobuf import descriptor++import grpc+import six+++class UnaryUnaryChannelRpc(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for a unary-unary RPC invoked by a system under test.++    Enables users to ""play server"" for the RPC.+    """"""++    @abc.abstractmethod+    def send_initial_metadata(self, initial_metadata):+        """"""Sends the RPC's initial metadata to the system under test.++        Args:+          initial_metadata: The RPC's initial metadata to be ""sent"" to+            the system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def cancelled(self):+        """"""Blocks until the system under test has cancelled the RPC.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def terminate(self, response, trailing_metadata, code, details):+        """"""Terminates the RPC.++        Args:+          response: The response for the RPC.+          trailing_metadata: The RPC's trailing metadata.+          code: The RPC's status code.+          details: The RPC's status details.+        """"""+        raise NotImplementedError()+++class UnaryStreamChannelRpc(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for a unary-stream RPC invoked by a system under test.++    Enables users to ""play server"" for the RPC.+    """"""++    @abc.abstractmethod+    def send_initial_metadata(self, initial_metadata):+        """"""Sends the RPC's initial metadata to the system under test.++        Args:+          initial_metadata: The RPC's initial metadata to be ""sent"" to+            the system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def send_response(self, response):+        """"""Sends a response to the system under test.++        Args:+          response: A response message to be ""sent"" to the system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def cancelled(self):+        """"""Blocks until the system under test has cancelled the RPC.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def terminate(self, trailing_metadata, code, details):+        """"""Terminates the RPC.++        Args:+          trailing_metadata: The RPC's trailing metadata.+          code: The RPC's status code.+          details: The RPC's status details.+        """"""+        raise NotImplementedError()+++class StreamUnaryChannelRpc(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for a stream-unary RPC invoked by a system under test.++    Enables users to ""play server"" for the RPC.+    """"""++    @abc.abstractmethod+    def send_initial_metadata(self, initial_metadata):+        """"""Sends the RPC's initial metadata to the system under test.++        Args:+          initial_metadata: The RPC's initial metadata to be ""sent"" to+            the system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_request(self):+        """"""Draws one of the requests added to the RPC by the system under test.++        Successive calls to this method return requests in the same order in+        which the system under test added them to the RPC.++        Returns:+          A request message added to the RPC by the system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def no_more_requests(self):+        """"""Blocks until the system under test has closed the request stream.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def cancelled(self):+        """"""Blocks until the system under test has cancelled the RPC.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def terminate(self, response, trailing_metadata, code, details):+        """"""Terminates the RPC.++        Args:+          response: The response for the RPC.+          trailing_metadata: The RPC's trailing metadata.+          code: The RPC's status code.+          details: The RPC's status details.+        """"""+        raise NotImplementedError()+++class StreamStreamChannelRpc(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for a stream-stream RPC invoked by a system under test.++    Enables users to ""play server"" for the RPC.+    """"""++    @abc.abstractmethod+    def send_initial_metadata(self, initial_metadata):+        """"""Sends the RPC's initial metadata to the system under test.++        Args:+          initial_metadata: The RPC's initial metadata to be ""sent"" to the+            system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_request(self):+        """"""Draws one of the requests added to the RPC by the system under test.++        Successive calls to this method return requests in the same order in+        which the system under test added them to the RPC.++        Returns:+          A request message added to the RPC by the system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def send_response(self, response):+        """"""Sends a response to the system under test.++        Args:+          response: A response messages to be ""sent"" to the system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def no_more_requests(self):+        """"""Blocks until the system under test has closed the request stream.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def cancelled(self):+        """"""Blocks until the system under test has cancelled the RPC.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def terminate(self, trailing_metadata, code, details):+        """"""Terminates the RPC.++        Args:+          trailing_metadata: The RPC's trailing metadata.+          code: The RPC's status code.+          details: The RPC's status details.+        """"""+        raise NotImplementedError()+++class Channel(six.with_metaclass(abc.ABCMeta), grpc.Channel):+    """"""A grpc.Channel double with which to test a system that invokes RPCs.""""""++    @abc.abstractmethod+    def take_unary_unary(self, descriptor):+        """"""Draws an RPC currently being made by the system under test.++        If the given descriptor does not identify any RPC currently being made+        by the system under test, this method blocks until the system under+        test invokes such an RPC.++        Args:+          descriptor: A descriptor.MethodDescriptor describing a unary-unary+            RPC method.++        Returns:+          A (invocation_metadata, request, unary_unary_channel_rpc) tuple of+            the RPC's invocation metadata, its request, and a+            UnaryUnaryChannelRpc with which to ""play server"" for the RPC.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_unary_stream(self, descriptor):+        """"""Draws an RPC currently being made by the system under test.++        If the given descriptor does not identify any RPC currently being made+        by the system under test, this method blocks until the system under+        test invokes such an RPC.++        Args:+          descriptor: A descriptor.MethodDescriptor describing a unary-stream+            RPC method.++        Returns:+          A (invocation_metadata, request, unary_stream_channel_rpc) tuple of+            the RPC's invocation metadata, its request, and a+            UnaryStreamChannelRpc with which to ""play server"" for the RPC.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_stream_unary(self, descriptor):+        """"""Draws an RPC currently being made by the system under test.++        If the given descriptor does not identify any RPC currently being made+        by the system under test, this method blocks until the system under+        test invokes such an RPC.++        Args:+          descriptor: A descriptor.MethodDescriptor describing a stream-unary+            RPC method.++        Returns:+          A (invocation_metadata, stream_unary_channel_rpc) tuple of the RPC's+            invocation metadata and a StreamUnaryChannelRpc with which to ""play+            server"" for the RPC.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_stream_stream(self, descriptor):+        """"""Draws an RPC currently being made by the system under test.++        If the given descriptor does not identify any RPC currently being made+        by the system under test, this method blocks until the system under+        test invokes such an RPC.++        Args:+          descriptor: A descriptor.MethodDescriptor describing a stream-stream+            RPC method.++        Returns:+          A (invocation_metadata, stream_stream_channel_rpc) tuple of the RPC's+            invocation metadata and a StreamStreamChannelRpc with which to+            ""play server"" for the RPC.+        """"""+        raise NotImplementedError()+++class UnaryUnaryServerRpc(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for a unary-unary RPC serviced by a system under test.++    Enables users to ""play client"" for the RPC.+    """"""++    @abc.abstractmethod+    def get_initial_metadata(self):+        """"""Accesses the initial metadata emitted by the system under test.++        This method blocks until the system under test has added initial+        metadata to the RPC (or has provided one or more response messages or+        has terminated the RPC, either of which will cause gRPC Python to+        synthesize initial metadata for the RPC).++        Returns:+          The initial metadata for the RPC.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def cancel(self):+        """"""Cancels the RPC.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def terminate(self):+        """"""Blocks until the system under test has terminated the RPC.++        Returns:+          A (response, trailing_metadata, code, details) tuple with the RPC's+            response, trailing metadata, code, and details.+        """"""+        raise NotImplementedError()+++class UnaryStreamServerRpc(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for a unary-stream RPC serviced by a system under test.++    Enables users to ""play client"" for the RPC.+    """"""++    @abc.abstractmethod+    def get_initial_metadata(self):+        """"""Accesses the initial metadata emitted by the system under test.++        This method blocks until the system under test has added initial+        metadata to the RPC (or has provided one or more response messages or+        has terminated the RPC, either of which will cause gRPC Python to+        synthesize initial metadata for the RPC).++        Returns:+          The initial metadata for the RPC.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_response(self):+        """"""Draws one of the responses added to the RPC by the system under test.++        Successive calls to this method return responses in the same order in+        which the system under test added them to the RPC.++        Returns:+          A response message added to the RPC by the system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def cancel(self):+        """"""Cancels the RPC.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def terminate(self):+        """"""Blocks until the system under test has terminated the RPC.++        Returns:+          A (trailing_metadata, code, details) tuple with the RPC's trailing+            metadata, code, and details.+        """"""+        raise NotImplementedError()+++class StreamUnaryServerRpc(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for a stream-unary RPC serviced by a system under test.++    Enables users to ""play client"" for the RPC.+    """"""++    @abc.abstractmethod+    def get_initial_metadata(self):+        """"""Accesses the initial metadata emitted by the system under test.++        This method blocks until the system under test has added initial+        metadata to the RPC (or has provided one or more response messages or+        has terminated the RPC, either of which will cause gRPC Python to+        synthesize initial metadata for the RPC).++        Returns:+          The initial metadata for the RPC.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def send_request(self, request):+        """"""Sends a request to the system under test.++        Args:+          request: A request message for the RPC to be ""sent"" to the system+            under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def no_more_requests(self):+        """"""Indicates the end of the RPC's request stream.""""""+        raise NotImplementedError()+    +    @abc.abstractmethod+    def cancel(self):+        """"""Cancels the RPC.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def terminate(self):+        """"""Blocks until the system under test has terminated the RPC.++        Returns:+          A (response, trailing_metadata, code, details) tuple with the RPC's+            response, trailing metadata, code, and details.+        """"""+        raise NotImplementedError()+++class StreamStreamServerRpc(six.with_metaclass(abc.ABCMeta)):+    """"""Fixture for a stream-stream RPC serviced by a system under test.++    Enables users to ""play client"" for the RPC.+    """"""++    @abc.abstractmethod+    def get_initial_metadata(self):+        """"""Accesses the initial metadata emitted by the system under test.++        This method blocks until the system under test has added initial+        metadata to the RPC (or has provided one or more response messages or+        has terminated the RPC, either of which will cause gRPC Python to+        synthesize initial metadata for the RPC).++        Returns:+          The initial metadata for the RPC.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def send_request(self, request):+        """"""Sends a request to the system under test.++        Args:+          request: A request message for the RPC to be ""sent"" to the system+            under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def no_more_requests(self):+        """"""Indicates the end of the RPC's request stream.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def take_response(self):+        """"""Draws one of the responses added to the RPC by the system under test.++        Successive calls to this method return responses in the same order in+        which the system under test added them to the RPC.++        Returns:+          A response message added to the RPC by the system under test.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def cancel(self):+        """"""Cancels the RPC.""""""+        raise NotImplementedError()++    @abc.abstractmethod+    def terminate(self):+        """"""Blocks until the system under test has terminated the RPC.++        Returns:+          A (trailing_metadata, code, details) tuple with the RPC's trailing+            metadata, code, and details.+        """"""+        raise NotImplementedError()+++class Server(six.with_metaclass(abc.ABCMeta)):+    """"""A server with which to test a system that services RPCs.""""""++    @abc.abstracmethod+    def invoke_unary_unary(+            self, descriptor, invocation_metadata, request, timeout):+        """"""Invokes an RPC to be serviced by the system under test.++        Args:+          descriptor: A descriptor.MethodDescriptor describing a unary-unary+            RPC method.+          invocation_metadata: The RPC's invocation metadata.+          request: The RPC's request.+          timeout: A duration of time in seconds for the RPC or None to+            indicate that the RPC has no time limit.++        Returns:+          A UnaryUnaryServerRpc with which to ""play client"" for the RPC.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def invoke_unary_stream(+            self, descriptor, invocation_metadata, request, timeout):+        """"""Invokes an RPC to be serviced by the system under test.++        Args:+          descriptor: A descriptor.MethodDescriptor describing a unary-stream+            RPC method.+          invocation_metadata: The RPC's invocation metadata.+          request: The RPC's request.+          timeout: A duration of time in seconds for the RPC or None to+            indicate that the RPC has no time limit.++        Returns:+          A UnaryStreamServerRpc with which to ""play client"" for the RPC.+        """"""+        raise NotImplementedError()++    @abc.abstracmethod+    def invoke_stream_unary(self, descriptor, invocation_metadata, timeout):+        """"""Invokes an RPC to be serviced by the system under test.++        Args:+          descriptor: A descriptor.MethodDescriptor describing a stream-unary+            RPC method.+          invocation_metadata: The RPC's invocation metadata.+          timeout: A duration of time in seconds for the RPC or None to+            indicate that the RPC has no time limit.++        Returns:+          A StreamUnaryServerRpc with which to ""play client"" for the RPC.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def invoke_stream_stream(self, descriptor, invocation_metadata, timeout):+        """"""Invokes an RPC to be serviced by the system under test.++        Args:+          descriptor: A descriptor.MethodDescriptor describing a stream-stream+            RPC method.+          invocation_metadata: The RPC's invocation metadata.+          timeout: A duration of time in seconds for the RPC or None to+            indicate that the RPC has no time limit.++        Returns:+          A StreamStreamServerRpc with which to ""play client"" for the RPC.+        """"""+        raise NotImplementedError()+++class Time(six.with_metaclass(abc.ABCMeta)):+    """"""A simulation of time.++    Implementations needn't be connected with real time as provided by the+    Python interpreter, but as long as systems under test use+    RpcContext.is_active and RpcContext.time_remaining for querying RPC liveness+    implementations may be used to change passage of time in tests.+    """"""++    @abc.abstractmethod+    def time(self):+        """"""Accesses the current test time.++        Returns:+          The current test time (over which this object has authority).+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def call_in(self, behavior, delay):+        """"""Adds a behavior to be called after some time.++        Args:+          behavior: A behavior to be called with no arguments.+          delay: A duration of time in seconds after which to call the behavior.++        Returns:+          A grpc.Future with which the call of the behavior may be cancelled+            before it is executed.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def call_at(self, behavior, time):+        """"""Adds a behavior to be called at a specific time.++        Args:+          behavior: A behavior to be called with no arguments.+          time: The test time at which to call the behavior.++        Returns:+          A grpc.Future with which the call of the behavior may be cancelled+            before it is executed.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def sleep_for(self, duration):+        """"""Blocks for some length of test time.++        Args:+          duration: A duration of test time in seconds for which to block.+        """"""+        raise NotImplementedError()++    @abc.abstractmethod+    def sleep_until(self, time):+        """"""Blocks until some test time.++        Args:+          time: The test time until which to block.+        """"""+        raise NotImplementedError()+++def real_time():+    """"""Creates a Time backed by the Python interpreter's time.++    Returns:+      A Time backed by the ""system"" (Python interpreter's) time.+    """"""+    from grpc_testing import _time+    return _time.RealTime()+++def fake_time(now):+    """"""Creates a Time that can be manipulated by test code.++    The returned instance maintains an internal representation of time+    independent of real time. This internal representation only advances+    when user code calls the instance's sleep_for and sleep_until methods.++    Returns:+      A Time that simulates the passage of time.+    """"""+    from grpc_testing import _time+    return _time.FakeTime(now)+++def channel(descriptors, time):","What do you think of naming this ```channel_from_descriptors()```?  This leaves us open to the possibility of having a similar method ```channel_from_stub()``` once Protobuf exports the cardinality, which would make this library even easier to use.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11733,128107815,2017-07-18T22:01:51Z,src/core/lib/security/credentials/credentials_metadata.c,"@@ -24,65 +24,34 @@  #include ""src/core/lib/slice/slice_internal.h"" -static void store_ensure_capacity(grpc_credentials_md_store *store) {-  if (store->num_entries == store->allocated) {-    store->allocated = (store->allocated == 0) ? 1 : store->allocated * 2;-    store->entries = gpr_realloc(-        store->entries, store->allocated * sizeof(grpc_credentials_md));+static void mdelem_list_ensure_capacity(grpc_credentials_mdelem_list *list,+                                        size_t space_needed) {+  size_t target_size = list->size + space_needed;","Yeah, looks like the code wasn't quite right here.  The intent here is to keep the allocated space at the next power of two greater than the used space (i.e., every time we need more space, we double the allocated space).The `size` field indicates the used space, not the allocated size.  The `space_needed` parameter is not the total space needed, but rather the additional space needed on top of the existing used space.  So the total space needed is the sum of the two.So what we're doing here is to compute the next power of two greater than the new amount of space needed.  We then call `gpr_realloc()` to get that amount of space.Note that it may be the case that the next power of two greater than the currently used space is the same as the next power of two greater than the new total space needed.  In this case, the call the `gpr_realloc()` will be a no-op.I've tweaked the code to work the way I've described here and to make it a bit more readable.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11733,128109842,2017-07-18T22:12:13Z,src/core/lib/security/credentials/plugin/plugin_credentials.h,"@@ -21,10 +21,22 @@  #include ""src/core/lib/security/credentials/credentials.h"" -typedef struct {+struct grpc_plugin_credentials;++typedef struct grpc_plugin_credentials_pending_request {+  bool cancelled;+  struct grpc_plugin_credentials *creds;+  grpc_credentials_mdelem_list *md_list;+  grpc_closure *on_request_metadata;+  struct grpc_plugin_credentials_pending_request *prev;","Making it a double-linked list makes it more efficient to remove the pending request from the list when it is successfully completed, which is the common case (see plugin_credentials.c lines 70-72 -- if this wasn't a double-linked list, we would need to iterate through the list in order to remove an element).  I think it's particularly important to make this case fast, because the work has to be done while holding the credential's mutex.  So if there are multiple calls in flight at once (which should be common), then we will be blocking progress on all other calls while we're removing one call from the pending request list.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11733,128111710,2017-07-18T22:23:31Z,src/core/lib/security/transport/client_auth_filter.c,"@@ -61,6 +68,40 @@ typedef struct {   grpc_auth_context *auth_context; } channel_data; +static void decode_cancel_state(gpr_atm cancel_state, grpc_closure **func,+                                grpc_error **error) {+  if (cancel_state & 1) {+    *error = (grpc_error *)(cancel_state & ~(gpr_atm)1);","BTW, it's also worth noting that this ugly atomic code is only temporary.  I'll be eliminating it as part of the call combiner work, which was my impetus for this PR in the first place.  If you want an early look, see this file in #11566 (which is built on top of this PR).",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11866,128278257,2017-07-19T15:17:12Z,src/core/lib/iomgr/exec_ctx.c,"@@ -108,9 +108,46 @@ static void exec_ctx_sched(grpc_exec_ctx *exec_ctx, grpc_closure *closure,   grpc_closure_list_append(&exec_ctx->closure_list, closure, error); } -void grpc_exec_ctx_global_init(void) {}+static gpr_timespec g_start_time;++void grpc_exec_ctx_global_init(void) {+  g_start_time = gpr_now(GPR_CLOCK_MONOTONIC);+}+ void grpc_exec_ctx_global_shutdown(void) {} +static gpr_atm timespec_to_atm_round_down(gpr_timespec ts) {","Are we concerned about the loss of precision here?  Presumably, this means that deadline timers will fire some number of nanoseconds earlier than they would have before.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11866,128280053,2017-07-19T15:23:07Z,src/core/lib/iomgr/timer_manager.c,"@@ -168,30 +166,29 @@ static bool wait_until(gpr_timespec next) {        unless their 'next' is earlier than the current timed-waiter's deadline        (in which case the thread with earlier 'next' takes over as the new timed        waiter) */-    if (gpr_time_cmp(next, inf_future) != 0) {-      if (!g_has_timed_waiter ||-          (gpr_time_cmp(next, g_timed_waiter_deadline) < 0)) {+    if (next != GRPC_MILLIS_INF_FUTURE) {+      if (!g_has_timed_waiter || (next < g_timed_waiter_deadline)) {         my_timed_waiter_generation = ++g_timed_waiter_generation;         g_has_timed_waiter = true;         g_timed_waiter_deadline = next;          if (GRPC_TRACER_ON(grpc_timer_check_trace)) {-          gpr_timespec wait_time =-              gpr_time_sub(next, gpr_now(GPR_CLOCK_MONOTONIC));-          gpr_log(GPR_DEBUG, ""sleep for a %"" PRId64 "".%09d seconds"",-                  wait_time.tv_sec, wait_time.tv_nsec);+          grpc_millis wait_time = next - grpc_exec_ctx_now(exec_ctx);+          gpr_log(GPR_DEBUG, ""sleep for a %"" PRIdPTR "" milliseconds"",+                  wait_time);         }       } else {  // g_timed_waiter == true && next >= g_timed_waiter_deadline-        next = inf_future;+        next = GRPC_MILLIS_INF_FUTURE;       }     }      if (GRPC_TRACER_ON(grpc_timer_check_trace) &&-        gpr_time_cmp(next, inf_future) == 0) {+        next == GRPC_MILLIS_INF_FUTURE) {       gpr_log(GPR_DEBUG, ""sleep until kicked"");     } -    gpr_cv_wait(&g_cv_wait, &g_mu, next);+    gpr_cv_wait(&g_cv_wait, &g_mu,",Would it make sense to change `gpr_cv_wait()` to use `grpc_millis` as well?  (I realize that this would require renaming it to `gpr_millis`.),
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11866,128281003,2017-07-19T15:26:26Z,src/core/lib/support/block_annotate.h,"@@ -26,8 +26,12 @@ #define GRPC_SCHEDULING_START_BLOCKING_REGION \   do {                                        \   } while (0)-#define GRPC_SCHEDULING_END_BLOCKING_REGION \-  do {                                      \+#define GRPC_SCHEDULING_END_BLOCKING_REGION_NO_EXEC_CTX \","It seems a bit messy to put code that references exec_ctx into gpr.  I realize that this is just a macro, so there's no link-time dependency, but it still seems sub-optimal.  Do we have any reasonable alternative?",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/11876,128314888,2017-07-19T17:36:17Z,tools/run_tests/run_interop_tests.py,"@@ -1042,6 +1042,7 @@ def aggregate_http2_results(stdout): # Start interop servers. server_jobs = {} server_addresses = {}+num_failures = 0","to be honest, I am not a big fan of having such a large scope for num_failures variable. I'll need to take another look.Btw, in the past, I think we had the ""exit 1"" behavior (it was removed because jenkins recognizes failures from the junit report). Perhaps looking at history of this file will reveal a better way to achieve this?",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/11876,128315218,2017-07-19T17:37:37Z,tools/run_tests/run_interop_tests.py,"@@ -1247,3 +1248,8 @@ def aggregate_http2_results(stdout):       dockerjob.remove_image(image)     else:       print('Preserving docker image: %s' % image)++if num_failures:",I am thinking maybe throwing an exception somewhere would be a cleaner approach. Also see the comment above.,
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/11866,128359018,2017-07-19T20:32:57Z,src/core/lib/surface/completion_queue.c,"@@ -1111,19 +1105,17 @@ static grpc_event cq_pluck(grpc_completion_queue *cq, void *tag,       dump_pending_tags(cq);       break;     }-    now = gpr_now(GPR_CLOCK_MONOTONIC);-    if (!is_finished_arg.first_loop && gpr_time_cmp(now, deadline) >= 0) {+    if (!is_finished_arg.first_loop &&+        grpc_exec_ctx_now(&exec_ctx) >= deadline_millis) {       del_plucker(cq, tag, &worker);       gpr_mu_unlock(cq->mu);       memset(&ret, 0, sizeof(ret));       ret.type = GRPC_QUEUE_TIMEOUT;       dump_pending_tags(cq);       break;     }--    cq->num_polls++;",Yeah not intentional at all (suspect merge error... I started this change a long long time ago),
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/11865,128363267,2017-07-19T20:49:57Z,include/grpc/support/avl.h,"@@ -57,25 +62,27 @@ typedef struct gpr_avl { GPRAPI gpr_avl gpr_avl_create(const gpr_avl_vtable *vtable); /** add a reference to an existing tree - returns",We should update the docstring for all the modified functions that now take `user_data`,
14932100,adelez,https://api.github.com/repos/grpc/grpc/pulls/11876,128363777,2017-07-19T20:52:03Z,tools/run_tests/run_interop_tests.py,"@@ -1042,6 +1042,7 @@ def aggregate_http2_results(stdout): # Start interop servers. server_jobs = {} server_addresses = {}+num_failures = 0",This is because of the large scope of the try block. I'll take another look.,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/11884,128365815,2017-07-19T21:00:28Z,src/core/ext/filters/client_channel/http_proxy.c,"@@ -47,15 +50,18 @@ static char* grpc_get_http_proxy_server(grpc_exec_ctx* exec_ctx) {     gpr_log(GPR_ERROR, ""'%s' scheme not supported in proxy URI"", uri->scheme);     goto done;   }-  if (strchr(uri->authority, '@') != NULL) {-    gpr_log(GPR_ERROR, ""userinfo not supported in proxy URI"");-    goto done;+  char *user_cred_end = strchr(uri->authority, '@');+  if (user_cred_end != NULL) {+    *name_to_resolve = gpr_strdup(user_cred_end + 1);+    *user_cred_end = '\0';+    *user_cred = gpr_strdup(uri->authority);+    gpr_log(GPR_INFO, ""userinfo found in proxy URI"");","nit: it usually helps to print the data in question, unless it's sensitive and/or too long to print.",
14932100,adelez,https://api.github.com/repos/grpc/grpc/pulls/11876,128367979,2017-07-19T21:09:59Z,tools/run_tests/run_interop_tests.py,"@@ -1247,3 +1248,8 @@ def aggregate_http2_results(stdout):       dockerjob.remove_image(image)     else:       print('Preserving docker image: %s' % image)++if num_failures:",I don't feel throwing exception is cleaner. sys.exit(1) is used when other types of jobs fail such as building docker image. This is consistent.,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/11866,128372864,2017-07-19T21:31:01Z,src/core/ext/filters/client_channel/lb_policy/grpclb/load_balancer_api.c,"@@ -258,13 +258,10 @@ int grpc_grpclb_duration_compare(const grpc_grpclb_duration *lhs,   return 0; } -gpr_timespec grpc_grpclb_duration_to_timespec(-    grpc_grpclb_duration *duration_pb) {-  gpr_timespec duration;-  duration.tv_sec = duration_pb->has_seconds ? duration_pb->seconds : 0;-  duration.tv_nsec = duration_pb->has_nanos ? duration_pb->nanos : 0;-  duration.clock_type = GPR_TIMESPAN;-  return duration;+grpc_millis grpc_grpclb_duration_to_millis(grpc_grpclb_duration *duration_pb) {+  return (duration_pb->has_seconds ? duration_pb->seconds : 0) *+             GPR_MS_PER_SEC ++         (duration_pb->has_nanos ? duration_pb->nanos : 0) / GPR_NS_PER_MS;","This is a nit, but let's round down: `duration` represents how long a serverlist is valid. Rounding down is slightly more conservative.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11866,128527935,2017-07-20T14:18:35Z,src/core/ext/filters/client_channel/client_channel.c,"@@ -814,7 +816,7 @@ typedef struct client_channel_call_data {    grpc_slice path;  // Request path.   gpr_timespec call_start_time;",Could change this to `grpc_millis` as well.Same thing for the `start_time` field in `grpc_call_element_args`:https://github.com/grpc/grpc/blob/master/src/core/lib/channel/channel_stack.h#L71,
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/11886,128561732,2017-07-20T16:13:31Z,tools/run_tests/sanity/check_submodules.sh,"@@ -31,7 +31,7 @@ cat << EOF | awk '{ print $1 }' | sort > $want_submodules  886e7d75368e3f4fab3f4d0d3584e4abfc557755 third_party/boringssl-with-bazel (version_for_cocoapods_7.0-857-g886e7d7)  30dbc81fb5ffdc98ea9b14b1918bfe4e8779b26e third_party/gflags (v2.2.0)  ec44c6c1675c25b9827aacd08c02433cccde7780 third_party/googletest (release-1.8.0)- a6189acd18b00611c1dc7042299ad75486f08a1a third_party/protobuf (v3.3.0)+ 942a29cecd36f2a4b22fdd2179635cd548e6bd27 third_party/protobuf (3.4.x)",Any idea when the 3.4.0 release is happening?  I know I got some push back when I tried to move the dependency to a non-release protobuf version.,
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/11886,128573548,2017-07-20T17:02:47Z,src/compiler/php_plugin.cc,"@@ -40,12 +41,25 @@ class PHPGrpcGenerator : public grpc::protobuf::compiler::CodeGenerator {       return true;     } +    std::vector<std::pair<grpc::string, grpc::string> > options;+    ParseGeneratorParameter(parameter, &options);++    grpc::string class_suffix;+    for (size_t i = 0; i < options.size(); ++i) {+      if (options[i].first == ""class_suffix"") {",The PR #11773 handling the `parameter` has *just* been merged to `master` yesterday. So no one is using it yet. I want to make changes on top of that to make sure it's more flexible when this does get released.,
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/11886,128574074,2017-07-20T17:05:06Z,src/compiler/php_plugin.cc,"@@ -40,12 +41,25 @@ class PHPGrpcGenerator : public grpc::protobuf::compiler::CodeGenerator {       return true;     } +    std::vector<std::pair<grpc::string, grpc::string> > options;+    ParseGeneratorParameter(parameter, &options);++    grpc::string class_suffix;+    for (size_t i = 0; i < options.size(); ++i) {+      if (options[i].first == ""class_suffix"") {",C# is also doing something [similar](https://github.com/grpc/grpc/blob/5253c8f9a899450397a5e46e4923d01ac9a66a27/src/compiler/csharp_plugin.cc#L37),
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/11583,128691655,2017-07-21T06:21:50Z,src/python/grpcio_testing/grpc_testing/_channel.py,"@@ -0,0 +1,753 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Channel fixtures.""""""++import collections+import logging+import threading++import grpc+import grpc_testing+from grpc_testing import _common++_NOT_YET_OBSERVED = object()+++class _RpcState(object):++    def __init__(self, invocation_metadata, requests, requests_closed):+        self.condition = threading.Condition()+        self.invocation_metadata = invocation_metadata+        self.requests = requests+        self.requests_closed = requests_closed+        self.initial_metadata = None+        self.responses = []+        self.trailing_metadata = None+        self.code = None+        self.details = None+++def _state_add_request(state, request):+    with state.condition:+        if state.code is None and not state.requests_closed:+            state.requests.append(request)+            state.condition.notify_all()+            return True+        else:+            return False+++def _state_no_more_requests(state):+    with state.condition:+        if state.code is None and not state.requests_closed:+            state.requests_closed = True+            state.condition.notify_all()+++def _state_take_response(state):+    with state.condition:+        while True:+            if state.code is grpc.StatusCode.OK:+                if state.responses:+                    response = state.responses.pop(0)+                    return _common.ChannelRpcRead(response, None, None, None)+                else:+                    return _common.ChannelRpcRead(None, state.trailing_metadata,+                                                  grpc.StatusCode.OK,+                                                  state.details)+            elif state.code is None:+                if state.responses:+                    response = state.responses.pop(0)+                    return _common.ChannelRpcRead(response, None, None, None)+                else:+                    state.condition.wait()+            else:+                return _common.ChannelRpcRead(None, state.trailing_metadata,+                                              state.code, state.details)+++def _state_cancel(state, code, details):+    with state.condition:+        if state.code is None:+            if state.initial_metadata is None:+                state.initial_metadata = _common.FUSSED_EMPTY_METADATA+            state.trailing_metadata = _common.FUSSED_EMPTY_METADATA+            state.code = code+            state.details = details+            state.condition.notify_all()+            return True+        else:+            return False+++def _state_terminate(state):+    with state.condition:+        while True:","(*obviously either way is not material, so this is mostly for the sake of its philosophical value*)I remain unconvinced. I don't have much disagreement there, though I would question the ""clearly better"" part even there, but I think we might be arguing a straw-man here, since the original code in question were much simpler with no branches within the loop (side note: the two code snippets above are actually not semantically equivalent (due to the presence of the `with` clause), but that's besides the point).I think my critical question is under what circumstances would we ever want to prefer `while condition:` over `while True:`? It's hard for me to imagine a `while` loop getting much simpler than @griffithjames's version.It would remain an acceptable and internally consistent conclusion if we agree that `while condition` is a universally bad idea; do you think that's the case though? If not, what's the principle that is preventing us from using `while True:` everywhere?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11884,128774168,2017-07-21T14:24:26Z,test/core/end2end/fixtures/http_proxy_fixture.c,"@@ -395,23 +377,21 @@ static void on_read_request_done(grpc_exec_ctx* exec_ctx, void* arg,     return;   }   // If proxy auth is being used, check if the header is present and as expected-  if(grpc_channel_args_find(-      conn->proxy->channel_args,-      GRPC_END2END_HTTP_PROXY_TEST_CONNECT_AUTH_PRESENT) != NULL) {+  const grpc_arg* proxy_auth = grpc_channel_args_find(+      conn->proxy->channel_args, GRPC_ARG_HTTP_PROXY_AUTH_CREDS);+  if (proxy_auth != NULL) {     bool auth_header_found = false;",Suggest renaming this `client_authenticated`.,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11583,128804074,2017-07-21T16:26:06Z,src/python/grpcio_testing/grpc_testing/_channel.py,"@@ -0,0 +1,753 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Channel fixtures.""""""++import collections+import logging+import threading++import grpc+import grpc_testing+from grpc_testing import _common++_NOT_YET_OBSERVED = object()+++class _RpcState(object):++    def __init__(self, invocation_metadata, requests, requests_closed):+        self.condition = threading.Condition()+        self.invocation_metadata = invocation_metadata+        self.requests = requests+        self.requests_closed = requests_closed+        self.initial_metadata = None+        self.responses = []+        self.trailing_metadata = None+        self.code = None+        self.details = None+++def _state_add_request(state, request):+    with state.condition:+        if state.code is None and not state.requests_closed:+            state.requests.append(request)+            state.condition.notify_all()+            return True+        else:+            return False+++def _state_no_more_requests(state):+    with state.condition:+        if state.code is None and not state.requests_closed:+            state.requests_closed = True+            state.condition.notify_all()+++def _state_take_response(state):+    with state.condition:+        while True:+            if state.code is grpc.StatusCode.OK:+                if state.responses:+                    response = state.responses.pop(0)+                    return _common.ChannelRpcRead(response, None, None, None)+                else:+                    return _common.ChannelRpcRead(None, state.trailing_metadata,+                                                  grpc.StatusCode.OK,+                                                  state.details)+            elif state.code is None:+                if state.responses:+                    response = state.responses.pop(0)+                    return _common.ChannelRpcRead(response, None, None, None)+                else:+                    state.condition.wait()+            else:+                return _common.ChannelRpcRead(None, state.trailing_metadata,+                                              state.code, state.details)+++def _state_cancel(state, code, details):+    with state.condition:+        if state.code is None:+            if state.initial_metadata is None:+                state.initial_metadata = _common.FUSSED_EMPTY_METADATA+            state.trailing_metadata = _common.FUSSED_EMPTY_METADATA+            state.code = code+            state.details = details+            state.condition.notify_all()+            return True+        else:+            return False+++def _state_terminate(state):+    with state.condition:+        while True:","_(Right. And I also enjoy these kinds of explorations of ostensibly trivial concerns.)_Let's not get too far ahead of ourselves. While [I do enjoy telling other folks how to code](https://www.youtube.com/watch?v=aOEfIrC07XA), this is only the first time I've thought through this question, so any results may be shaky and certainly won't have time and experience behind them. So I'm trying to guide myself but I'm a long way from saying others should follow.What's attractive to me about `while True:` everywhere is that (1) it's one form that applies generally rather than one general form plus a different form in a special case and (2) it's one statement rather than two.But it would be a huge leap to go from ""`while True:` is more attractive to @nathanielmanistaatgoogle, today, for reasons he's only just recently bothered thinking about"" to ""`while <condition>:` is bad and should be avoided"".I agree that it's hard to imagine the logic getting _textually shorter_ than```while <condition>:  <single simple statement>return <simple expression>```. For some folks textual brevity _is_ simplicity, but I (for the time being, at least) prefer```while True:  <parse tree node>```to```while <condition>:  <parse tree node><parse tree node>```, even if my `<parse tree node>` isn't a _leaf_ node. I'll try to meditate on why, certainly before I start making recommendations and rules that would apply to others. It's probably got something to do with why [I prefer `for`/`else` even with loop bodies that `return` and do not `break`](https://github.com/grpc/grpc/blob/37e06cfc4d7e6473b000d4b64c7305da8e98e456/.pylintrc#L67-L69).Certainly nothing prevents us from using `while True:` everywhere (at least as I understand the scope of this conversation). In subsequent drafts of this pull request I've tried to use `while True:` consistently throughout. (No need at this time to go mucking about the extant codebase.)",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/11886,128804850,2017-07-21T16:29:56Z,src/compiler/php_plugin.cc,"@@ -40,12 +41,25 @@ class PHPGrpcGenerator : public grpc::protobuf::compiler::CodeGenerator {       return true;     } +    std::vector<std::pair<grpc::string, grpc::string> > options;+    ParseGeneratorParameter(parameter, &options);++    grpc::string class_suffix;+    for (size_t i = 0; i < options.size(); ++i) {+      if (options[i].first == ""class_suffix"") {","If this is a new feature and we have some flexibility, is there any way we can have some kind of protobuf ```grpc_args``` parameter?  It feels really awkward to jam arguments into the ```grpc_out``` parameter.Might be out of scope for this PR, but just my 2-cents.",
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/11886,128839989,2017-07-21T19:10:10Z,src/compiler/php_plugin.cc,"@@ -40,12 +41,25 @@ class PHPGrpcGenerator : public grpc::protobuf::compiler::CodeGenerator {       return true;     } +    std::vector<std::pair<grpc::string, grpc::string> > options;+    ParseGeneratorParameter(parameter, &options);++    grpc::string class_suffix;+    for (size_t i = 0; i < options.size(); ++i) {+      if (options[i].first == ""class_suffix"") {","My understanding is that this is the preferred way (by way of how `protoc` works) of passing command line parameters to a protoc plugin. The `parameter` parameter is already there in the `Generate` method in the plugin already supplied by the main `protoc`. So we did not introduce that parameter per se. It's already passed to the plugin if you do specify something before the `:` in `--grpc_out`. This is just to formalize that, if you do pass something before the `:`, it should be in the format of `param1:var1,param2:var2`",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/11905,128841492,2017-07-21T19:18:12Z,src/core/ext/transport/inproc/inproc_transport.c,"@@ -201,24 +202,39 @@ static grpc_error *inproc_slice_byte_stream_pull(grpc_exec_ctx *exec_ctx,                                                  grpc_byte_stream *bs,                                                  grpc_slice *slice) {   inproc_slice_byte_stream *stream = (inproc_slice_byte_stream *)bs;+  if (stream->shutdown_error != GRPC_ERROR_NONE) {+    return GRPC_ERROR_REF(stream->shutdown_error);+  }   *slice = grpc_slice_buffer_take_first(&stream->le->sb);   return GRPC_ERROR_NONE; } +static void inproc_slice_byte_stream_shutdown(grpc_exec_ctx *exec_ctx,+                                              grpc_byte_stream *bs,+                                              grpc_error *error) {+  inproc_slice_byte_stream *stream = (inproc_slice_byte_stream *)bs;+  GRPC_ERROR_UNREF(stream->shutdown_error);+  stream->shutdown_error = error;+}+ static void inproc_slice_byte_stream_destroy(grpc_exec_ctx *exec_ctx,                                              grpc_byte_stream *bs) {   inproc_slice_byte_stream *stream = (inproc_slice_byte_stream *)bs;   sb_list_entry_destroy(exec_ctx, stream->le);+  GRPC_ERROR_UNREF(stream->shutdown_error); } +static const grpc_byte_stream_vtable inproc_slice_byte_stream_vtable = {+    inproc_slice_byte_stream_next, inproc_slice_byte_stream_pull,+    inproc_slice_byte_stream_shutdown, inproc_slice_byte_stream_destroy};+ void inproc_slice_byte_stream_init(inproc_slice_byte_stream *s,                                    sb_list_entry *le) {   s->base.length = (uint32_t)le->sb.length;   s->base.flags = 0;-  s->base.next = inproc_slice_byte_stream_next;-  s->base.pull = inproc_slice_byte_stream_pull;-  s->base.destroy = inproc_slice_byte_stream_destroy;+  s->base.vtable = &inproc_slice_byte_stream_vtable;",This saves space (1 pointer instead of 3) but increases the dependence length. It was `load->jump` but is now `load->load->jump` (this applies to all of the byte_stream classes that use the vtable). Are there really enough active instances that the memory savings is important?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11905,128849478,2017-07-21T20:00:37Z,src/core/ext/transport/inproc/inproc_transport.c,"@@ -201,24 +202,39 @@ static grpc_error *inproc_slice_byte_stream_pull(grpc_exec_ctx *exec_ctx,                                                  grpc_byte_stream *bs,                                                  grpc_slice *slice) {   inproc_slice_byte_stream *stream = (inproc_slice_byte_stream *)bs;+  if (stream->shutdown_error != GRPC_ERROR_NONE) {+    return GRPC_ERROR_REF(stream->shutdown_error);+  }   *slice = grpc_slice_buffer_take_first(&stream->le->sb);   return GRPC_ERROR_NONE; } +static void inproc_slice_byte_stream_shutdown(grpc_exec_ctx *exec_ctx,+                                              grpc_byte_stream *bs,+                                              grpc_error *error) {+  inproc_slice_byte_stream *stream = (inproc_slice_byte_stream *)bs;+  GRPC_ERROR_UNREF(stream->shutdown_error);+  stream->shutdown_error = error;+}+ static void inproc_slice_byte_stream_destroy(grpc_exec_ctx *exec_ctx,                                              grpc_byte_stream *bs) {   inproc_slice_byte_stream *stream = (inproc_slice_byte_stream *)bs;   sb_list_entry_destroy(exec_ctx, stream->le);+  GRPC_ERROR_UNREF(stream->shutdown_error); } +static const grpc_byte_stream_vtable inproc_slice_byte_stream_vtable = {+    inproc_slice_byte_stream_next, inproc_slice_byte_stream_pull,+    inproc_slice_byte_stream_shutdown, inproc_slice_byte_stream_destroy};+ void inproc_slice_byte_stream_init(inproc_slice_byte_stream *s,                                    sb_list_entry *le) {   s->base.length = (uint32_t)le->sb.length;   s->base.flags = 0;-  s->base.next = inproc_slice_byte_stream_next;-  s->base.pull = inproc_slice_byte_stream_pull;-  s->base.destroy = inproc_slice_byte_stream_destroy;+  s->base.vtable = &inproc_slice_byte_stream_vtable;","I haven't taken any measurements or anything, but I'd say yes: there will be at least one `grpc_byte_stream` instance for each sent and received message.  In fact, sometimes there will be more than one byte stream for a given sent or received message -- for example, in a case like the new `grpc_cached_byte_stream` class, where one byte stream wraps another one.Also, note that with the addition of the new shutdown method, it's actually 4-to-1, not 3-to-1.If there's compelling evidence that this is going to be a performance problem, we can certainly revert it.  But I think it actually makes the code cleaner.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/11905,128878321,2017-07-21T23:15:40Z,src/core/lib/transport/byte_stream.c,"@@ -56,25 +64,123 @@ static grpc_error *slice_buffer_stream_pull(grpc_exec_ctx *exec_ctx,                                             grpc_byte_stream *byte_stream,                                             grpc_slice *slice) {   grpc_slice_buffer_stream *stream = (grpc_slice_buffer_stream *)byte_stream;+  if (stream->shutdown_error != GRPC_ERROR_NONE) {+    return GRPC_ERROR_REF(stream->shutdown_error);+  }   GPR_ASSERT(stream->cursor < stream->backing_buffer->count);   *slice =       grpc_slice_ref_internal(stream->backing_buffer->slices[stream->cursor]);   stream->cursor++;   return GRPC_ERROR_NONE; } +static void slice_buffer_stream_shutdown(grpc_exec_ctx *exec_ctx,+                                         grpc_byte_stream *byte_stream,+                                         grpc_error *error) {+  grpc_slice_buffer_stream *stream = (grpc_slice_buffer_stream *)byte_stream;+  GRPC_ERROR_UNREF(stream->shutdown_error);+  stream->shutdown_error = error;+}+ static void slice_buffer_stream_destroy(grpc_exec_ctx *exec_ctx,-                                        grpc_byte_stream *byte_stream) {}+                                        grpc_byte_stream *byte_stream) {+  grpc_slice_buffer_stream *stream = (grpc_slice_buffer_stream *)byte_stream;+  GRPC_ERROR_UNREF(stream->shutdown_error);+}++static const grpc_byte_stream_vtable slice_buffer_stream_vtable = {+    slice_buffer_stream_next, slice_buffer_stream_pull,+    slice_buffer_stream_shutdown, slice_buffer_stream_destroy};  void grpc_slice_buffer_stream_init(grpc_slice_buffer_stream *stream,                                    grpc_slice_buffer *slice_buffer,                                    uint32_t flags) {   GPR_ASSERT(slice_buffer->length <= UINT32_MAX);   stream->base.length = (uint32_t)slice_buffer->length;   stream->base.flags = flags;-  stream->base.next = slice_buffer_stream_next;-  stream->base.pull = slice_buffer_stream_pull;-  stream->base.destroy = slice_buffer_stream_destroy;+  stream->base.vtable = &slice_buffer_stream_vtable;   stream->backing_buffer = slice_buffer;   stream->cursor = 0;+  stream->shutdown_error = GRPC_ERROR_NONE;+}++// grpc_caching_byte_stream++void grpc_byte_stream_cache_init(grpc_byte_stream_cache *cache,+                                 grpc_byte_stream *underlying_stream) {+  cache->underlying_stream = underlying_stream;+  grpc_slice_buffer_init(&cache->cache_buffer);+}++void grpc_byte_stream_cache_destroy(grpc_exec_ctx *exec_ctx,+                                    grpc_byte_stream_cache *cache) {+  grpc_byte_stream_destroy(exec_ctx, cache->underlying_stream);+  grpc_slice_buffer_destroy_internal(exec_ctx, &cache->cache_buffer);+}++static bool caching_byte_stream_next(grpc_exec_ctx *exec_ctx,+                                     grpc_byte_stream *byte_stream,+                                     size_t max_size_hint,+                                     grpc_closure *on_complete) {+  grpc_caching_byte_stream *stream = (grpc_caching_byte_stream *)byte_stream;+  if (stream->shutdown_error != GRPC_ERROR_NONE) return true;+  if (stream->cursor < stream->cache->cache_buffer.count) return true;+  stream->cursor = SIZE_MAX;+  return grpc_byte_stream_next(exec_ctx, stream->cache->underlying_stream,+                               max_size_hint, on_complete);+}++static grpc_error *caching_byte_stream_pull(grpc_exec_ctx *exec_ctx,+                                            grpc_byte_stream *byte_stream,+                                            grpc_slice *slice) {+  grpc_caching_byte_stream *stream = (grpc_caching_byte_stream *)byte_stream;+  if (stream->shutdown_error != GRPC_ERROR_NONE) {+    return GRPC_ERROR_REF(stream->shutdown_error);+  }+  if (stream->cursor < stream->cache->cache_buffer.count) {+    *slice = grpc_slice_ref_internal(+        stream->cache->cache_buffer.slices[stream->cursor]);+    ++stream->cursor;+    return GRPC_ERROR_NONE;+  }+  grpc_error *error =+      grpc_byte_stream_pull(exec_ctx, stream->cache->underlying_stream, slice);+  if (error == GRPC_ERROR_NONE) {+    grpc_slice_buffer_add(&stream->cache->cache_buffer,","I am a little confused by this. We are caching it in the cache buffer, but also passing it pack up to the original caller? In what situations would the cache grow large enough that calls to this pull would only draw from the cache and not the underlying byte stream?",
1353258,ax3l,https://api.github.com/repos/grpc/grpc/pulls/11903,128924413,2017-07-23T16:59:48Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.c,"@@ -358,7 +357,7 @@ static grpc_ares_request *grpc_dns_lookup_ares_impl(     grpc_ares_request_ref(r);     char *service_name;     gpr_asprintf(&service_name, ""_grpclb._tcp.%s"", host);-    ares_query(*channel, service_name, ns_c_in, ns_t_srv, on_srv_query_done_cb,+    ares_query(*channel, service_name, 1 /*ns_c_in*/, 33 /*ns_t_srv*/, on_srv_query_done_cb,","@y-zeng They should not be OS dependent - [`ares_query`](https://linux.die.net/man/3/ares_query) is a DNS request:- `dnsclass`: `ns_c_in == 1` means ""internet"" ([RFC 1035, section *3.2.4. CLASS values*](https://www.ietf.org/rfc/rfc1035.txt)) and- `type`: `ns_t_srv == 33` means ""server selection"" ([SRV Record](https://en.wikipedia.org/wiki/SRV_record), [RFC 2782](https://tools.ietf.org/html/rfc2782))Shall I add a simple comment in the line above or the whole `nameser.h` file? (it's not really ""from c-ares"" but all-over the web in all kinds of DNS based libs and apps; can't track the origin; both numbers are well-defined and [IANA controlled](https://www.iana.org/assignments/dns-parameters/dns-parameters.xhtml)). Update: updated as described.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/11876,129017674,2017-07-24T12:05:43Z,tools/run_tests/run_interop_tests.py,"@@ -1230,6 +1230,11 @@ def aggregate_http2_results(stdout):       _HTTP2_TEST_CASES, http2_server_test_cases, resultset, num_failures,       args.cloud_to_prod_auth or args.cloud_to_prod, args.prod_servers,       args.http2_interop)+  +  if num_failures:",Does this actually work? According to the manual sys.exit() throws SystemExit exception which seems to be eaten in except Exception as e:,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11915,129055659,2017-07-24T14:42:57Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -788,10 +791,9 @@ static void rr_handover_locked(grpc_exec_ctx *exec_ctx,                                glb_lb_policy *glb_policy) {   GPR_ASSERT(glb_policy->serverlist != NULL &&              glb_policy->serverlist->num_servers > 0);-   if (glb_policy->shutting_down) return;-   grpc_lb_policy_args *args = lb_policy_args_create(exec_ctx, glb_policy);+  if (args == NULL) return;","Simply returning here seems wrong.  Consider the case where we first get an update containing at least one non-drop address, and we then get an update containing only drop addresses.  In this case, I think we should update the RR policy with an empty list, so that it does not continue to maintain a connection to the original non-drop address.We will still drop all calls regardless, because the code in `pick_from_internal_rr_locked()` checks whether the serverlist entries are drop entries before asking the RR policy to do the pick.  But it seems cleaner to update the RR policy appropriately, so that we don't maintain a subchannel that we don't need.I think a better fix would be to change `process_serverlist_locked()` to return an empty list of addresses instead of returning NULL.  We can then use that empty list just as we would use any other list, without any special checks for NULL.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/11905,129086902,2017-07-24T16:32:37Z,src/core/ext/filters/http/client/http_client_filter.c,"@@ -171,25 +161,131 @@ static void hc_on_recv_trailing_metadata(grpc_exec_ctx *exec_ctx,   } else {     GRPC_ERROR_REF(error);   }-  GRPC_CLOSURE_RUN(exec_ctx, calld->on_done_recv_trailing_metadata, error);+  GRPC_CLOSURE_RUN(exec_ctx, calld->original_recv_trailing_metadata_on_complete,+                   error); } -static void hc_on_complete(grpc_exec_ctx *exec_ctx, void *user_data,-                           grpc_error *error) {-  grpc_call_element *elem = user_data;-  call_data *calld = elem->call_data;-  if (calld->payload_bytes) {-    gpr_free(calld->payload_bytes);-    calld->payload_bytes = NULL;+static void send_message_on_complete(grpc_exec_ctx *exec_ctx, void *arg,+                                     grpc_error *error) {+  grpc_call_element *elem = (grpc_call_element *)arg;+  call_data *calld = (call_data *)elem->call_data;+  grpc_byte_stream_cache_destroy(exec_ctx, &calld->send_message_cache);+  GRPC_CLOSURE_RUN(exec_ctx, calld->original_send_message_on_complete,+                   GRPC_ERROR_REF(error));+}++// Pulls a slice from the send_message byte stream, updating+// calld->send_message_bytes_read.+static grpc_error *pull_slice_from_send_message(grpc_exec_ctx *exec_ctx,+                                                call_data *calld) {+  grpc_slice incoming_slice;+  grpc_error *error = grpc_byte_stream_pull(+      exec_ctx, &calld->send_message_caching_stream.base, &incoming_slice);+  if (error == GRPC_ERROR_NONE) {+    calld->send_message_bytes_read += GRPC_SLICE_LENGTH(incoming_slice);+    grpc_slice_unref_internal(exec_ctx, incoming_slice);   }-  calld->on_complete->cb(exec_ctx, calld->on_complete->cb_arg, error);+  return error; } -static void send_done(grpc_exec_ctx *exec_ctx, void *elemp, grpc_error *error) {-  grpc_call_element *elem = elemp;-  call_data *calld = elem->call_data;-  grpc_slice_buffer_reset_and_unref_internal(exec_ctx, &calld->slices);-  calld->post_send->cb(exec_ctx, calld->post_send->cb_arg, error);+// Reads as many slices as possible from the send_message byte stream.+// Upon successful return, if calld->send_message_bytes_read ==+// calld->send_message_caching_stream.base.length, then we have completed+// reading from the byte stream; otherwise, an async read has been dispatched+// and on_send_message_next_done() will be invoked when it is complete.+static grpc_error *read_all_available_send_message_data(grpc_exec_ctx *exec_ctx,+                                                        call_data *calld) {+  while (grpc_byte_stream_next(exec_ctx,+                               &calld->send_message_caching_stream.base,+                               ~(size_t)0, &calld->on_send_message_next_done)) {+    grpc_error *error = pull_slice_from_send_message(exec_ctx, calld);+    if (error != GRPC_ERROR_NONE) return error;+    if (calld->send_message_bytes_read ==+        calld->send_message_caching_stream.base.length) {+      break;+    }+  }+  return GRPC_ERROR_NONE;+}++// Async callback for grpc_byte_stream_next().+static void on_send_message_next_done(grpc_exec_ctx *exec_ctx, void *arg,+                                      grpc_error *error) {+  grpc_call_element *elem = (grpc_call_element *)arg;+  call_data *calld = (call_data *)elem->call_data;+  if (error != GRPC_ERROR_NONE) {+    grpc_transport_stream_op_batch_finish_with_failure(+        exec_ctx, calld->send_message_batch, error);+    return;+  }+  error = pull_slice_from_send_message(exec_ctx, calld);+  if (error != GRPC_ERROR_NONE) {+    grpc_transport_stream_op_batch_finish_with_failure(+        exec_ctx, calld->send_message_batch, error);+    return;+  }+  // There may or may not be more to read, but we don't care.  If we got+  // here, then we know that all of the data was not available+  // synchronously, so we were not able to do a cached call.  Instead,+  // we just reset the byte stream and then send down the batch as-is.+  grpc_caching_byte_stream_reset(&calld->send_message_caching_stream);+  grpc_call_next_op(exec_ctx, elem, calld->send_message_batch);+}++static char *slice_buffer_to_string(grpc_slice_buffer *slice_buffer) {",This seems like a function that belongs in a util file,
29667874,griffithjames,https://api.github.com/repos/grpc/grpc/pulls/11901,129089020,2017-07-24T16:41:03Z,src/python/grpcio_testing/grpc_testing/_time.py,"@@ -0,0 +1,222 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Test times.""""""++import collections+import logging+import threading+import time as _time++import grpc+import grpc_testing+++def _call(behaviors):+    for behavior in behaviors:+        try:+            behavior()+        except Exception:  # pylint: disable=broad-except+            logging.exception('Exception calling behavior?')+++def _call_in_thread(behaviors):+    calling = threading.Thread(target=_call, args=(behaviors,))+    calling.start()+    calling.join()+++class _State(object):++    def __init__(self):+        self.condition = threading.Condition()+        self.times_to_behaviors = collections.defaultdict(list)+++class _Delta(+        collections.namedtuple('_Delta',+                               ('mature_behaviors', 'earliest_mature_time',+                                'earliest_immature_time',))):+    pass+++def _process(state, now):+    mature_behaviors = []+    earliest_mature_time = None+    while state.times_to_behaviors:+        earliest_time = min(state.times_to_behaviors)+        if earliest_time <= now:",Consider flipping this conditional and then have no else:    if earliest_time > now:        earliest_immature_time = earliest_time        break    if earliest_mature_time is None:        earliest_mature_time = earliest_time    earliest_mature_behaviors = state.times_to_behaviors.pop(earliest_time)    mature_behaviors.extend(earliest_mature_behaviors),
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11901,129147092,2017-07-24T20:38:21Z,src/python/grpcio_testing/grpc_testing/_time.py,"@@ -0,0 +1,222 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Test times.""""""++import collections+import logging+import threading+import time as _time++import grpc+import grpc_testing+++def _call(behaviors):+    for behavior in behaviors:+        try:+            behavior()+        except Exception:  # pylint: disable=broad-except+            logging.exception('Exception calling behavior?')+++def _call_in_thread(behaviors):+    calling = threading.Thread(target=_call, args=(behaviors,))+    calling.start()+    calling.join()+++class _State(object):++    def __init__(self):+        self.condition = threading.Condition()+        self.times_to_behaviors = collections.defaultdict(list)+++class _Delta(+        collections.namedtuple('_Delta',+                               ('mature_behaviors', 'earliest_mature_time',+                                'earliest_immature_time',))):+    pass+++def _process(state, now):+    mature_behaviors = []+    earliest_mature_time = None+    while state.times_to_behaviors:+        earliest_time = min(state.times_to_behaviors)+        if earliest_time <= now:",The structure here is deliberate - it's more important (to me) that the mutual exclusivity of the groups of statements be more readily apparent visually and geometrically. I don't like having code that looks like```if <condition>:  <some statements><other statements>```but that also has no code paths between `<some statements>` and `<other statements>`.,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11901,129148399,2017-07-24T20:43:54Z,src/python/grpcio_tests/tests/testing/_time_test.py,"@@ -0,0 +1,164 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import random+import threading+import time+import unittest++import grpc_testing++_QUANTUM = 0.3+_MANY = 10000+# Tests that run in real time can either wait for the scheduler to+# eventually run what needs to be run (and risk timing out) or declare+# that the scheduler didn't schedule work reasonably fast enough. We+# choose the latter for this test.+_PATHOLOGICAL_SCHEDULING = 'pathological thread scheduling!'+++class _TimeNoter(object):++    def __init__(self, time):+        self._condition = threading.Condition()+        self._time = time+        self._call_times = []++    def __call__(self):+        with self._condition:+            self._call_times.append(self._time.time())++    def call_times(self):+        with self._condition:+            return tuple(self._call_times)+++class TimeTest(object):++    def test_sleep_for(self):+        start_time = self._time.time()+        self._time.sleep_for(_QUANTUM)+        end_time = self._time.time()++        self.assertLessEqual(start_time + _QUANTUM, end_time)++    def test_sleep_until(self):+        start_time = self._time.time()+        self._time.sleep_until(start_time + _QUANTUM)+        end_time = self._time.time()++        self.assertLessEqual(start_time + _QUANTUM, end_time)++    def test_call_in(self):+        time_noter = _TimeNoter(self._time)++        start_time = self._time.time()+        self._time.call_in(time_noter, _QUANTUM)+        self._time.sleep_for(_QUANTUM * 2)+        call_times = time_noter.call_times()++        self.assertTrue(call_times, msg=_PATHOLOGICAL_SCHEDULING)+        self.assertLessEqual(start_time + _QUANTUM, call_times[0])++    def test_call_at(self):+        time_noter = _TimeNoter(self._time)++        start_time = self._time.time()+        self._time.call_at(time_noter, self._time.time() + _QUANTUM)+        self._time.sleep_for(_QUANTUM * 2)+        call_times = time_noter.call_times()++        self.assertTrue(call_times, msg=_PATHOLOGICAL_SCHEDULING)+        self.assertLessEqual(start_time + _QUANTUM, call_times[0])++    def test_cancel(self):+        time_noter = _TimeNoter(self._time)++        future = self._time.call_in(time_noter, _QUANTUM * 2)+        self._time.sleep_for(_QUANTUM)+        cancelled = future.cancel()+        self._time.sleep_for(_QUANTUM * 2)+        call_times = time_noter.call_times()++        self.assertFalse(call_times, msg=_PATHOLOGICAL_SCHEDULING)+        self.assertTrue(cancelled)+        self.assertTrue(future.cancelled())++    def test_many(self):+        test_events = tuple(threading.Event() for _ in range(_MANY))","The right answer would be `six.moves.range`, but I felt lazy about importing the `six` module.",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/11878,129160528,2017-07-24T21:35:28Z,src/php/ext/grpc/channel.c,"@@ -223,9 +346,50 @@ PHP_METHOD(Channel, watchConnectivityState) { PHP_METHOD(Channel, close) {   wrapped_grpc_channel *channel = Z_WRAPPED_GRPC_CHANNEL_P(getThis());   if (channel->wrapped != NULL) {-    grpc_channel_destroy(channel->wrapped);+    // this fixes a race when two shared Channel objects both call close()+    // at about the same time+    int state = grpc_channel_check_connectivity_state(channel->wrapped, 0);","This seems like a really awkward way to avoid a race condition.It seems like the same thing could be accomplished using a mutex, along with a small shared wrapper object around the ```grpc_channel*```.",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/11878,129161785,2017-07-24T21:41:36Z,src/php/ext/grpc/channel.c,"@@ -121,6 +146,10 @@ PHP_METHOD(Channel, __construct) {   grpc_channel_args args;   HashTable *array_hash;   wrapped_grpc_channel_credentials *creds = NULL;+  php_grpc_zend_resource *rsrc;+  channel_persistent_le_t *le;",Should you have a MAX LENGTH on this list to prevent leaks?,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11901,129182900,2017-07-24T23:51:02Z,src/python/grpcio_testing/grpc_testing/_time.py,"@@ -0,0 +1,222 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Test times.""""""++import collections+import logging+import threading+import time as _time++import grpc+import grpc_testing+++def _call(behaviors):+    for behavior in behaviors:+        try:+            behavior()+        except Exception:  # pylint: disable=broad-except+            logging.exception('Exception calling behavior?')+++def _call_in_thread(behaviors):+    calling = threading.Thread(target=_call, args=(behaviors,))+    calling.start()+    calling.join()+++class _State(object):++    def __init__(self):+        self.condition = threading.Condition()+        self.times_to_behaviors = collections.defaultdict(list)+++class _Delta(+        collections.namedtuple('_Delta',+                               ('mature_behaviors', 'earliest_mature_time',+                                'earliest_immature_time',))):+    pass+++def _process(state, now):+    mature_behaviors = []+    earliest_mature_time = None+    while state.times_to_behaviors:+        earliest_time = min(state.times_to_behaviors)+        if earliest_time <= now:+            if earliest_mature_time is None:+                earliest_mature_time = earliest_time+            earliest_mature_behaviors = state.times_to_behaviors.pop(+                earliest_time)+            mature_behaviors.extend(earliest_mature_behaviors)+        else:+            earliest_immature_time = earliest_time+            break+    else:+        earliest_immature_time = None+    return _Delta(mature_behaviors, earliest_mature_time,+                  earliest_immature_time)+++class _Future(grpc.Future):++    def __init__(self, state, behavior, time):+        self._state = state+        self._behavior = behavior+        self._time = time+        self._cancelled = False++    def cancel(self):+        with self._state.condition:+            if self._cancelled:+                return True+            else:+                behaviors_at_time = self._state.times_to_behaviors.get(+                    self._time)+                if behaviors_at_time is None:+                    return False+                else:+                    behaviors_at_time.remove(self._behavior)+                    if not behaviors_at_time:+                        self._state.times_to_behaviors.pop(self._time)+                        self._state.condition.notify_all()+                    self._cancelled = True+                    return True++    def cancelled(self):+        with self._state.condition:+            return self._cancelled++    def running(self):+        raise NotImplementedError()++    def done(self):+        raise NotImplementedError()++    def result(self, timeout=None):+        raise NotImplementedError()++    def exception(self, timeout=None):+        raise NotImplementedError()++    def traceback(self, timeout=None):+        raise NotImplementedError()++    def add_done_callback(self, fn):+        raise NotImplementedError()+++class RealTime(grpc_testing.Time):++    def __init__(self):+        self._state = _State()+        self._active = False+        self._calling = None++    def _activity(self):+        while True:+            with self._state.condition:+                while True:+                    now = _time.time()+                    delta = _process(self._state, now)+                    self._state.condition.notify_all()+                    if delta.mature_behaviors:+                        self._calling = delta.earliest_mature_time+                        break+                    self._calling = None+                    if delta.earliest_immature_time is None:+                        self._active = False+                        return+                    else:+                        timeout = max(0, delta.earliest_immature_time - now)+                        self._state.condition.wait(timeout=timeout)+            _call(delta.mature_behaviors)++    def _ensure_called_through(self, time):","Right. The issue is that if we don't have these ""strict"" semantics for fake time, then callbacks are only made runnable _after_ the test advances the time to _after_ the callbacks should have run. Without this strictness the fake time would be nearly unusable. I've changed the verbiage.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11915,129317701,2017-07-25T14:17:00Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -727,6 +723,7 @@ static void create_rr_locked(grpc_exec_ctx *exec_ctx, glb_lb_policy *glb_policy,   /* Connectivity state is a function of the RR policy updated/created */   update_lb_connectivity_status_locked(exec_ctx, glb_policy, rr_state,                                        rr_state_error);+  GRPC_ERROR_UNREF(rr_state_error);","This looks wrong.  I think `update_lb_connectivity_status_locked()` should take ownership of the error, as per:https://github.com/grpc/grpc/blob/master/doc/core/grpc-error.md#rule-3",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11915,129320795,2017-07-25T14:27:07Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1108,6 +1107,10 @@ static void glb_cancel_pick_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *pol,     }     pp = next;   }+  if (glb_policy->rr_policy != NULL) {+    grpc_lb_policy_cancel_pick_locked(exec_ctx, glb_policy->rr_policy, target,","When I first read this, I thought that this could cause us to invoke the pick callback twice, once from the pending picks list (in the loop immediately above) and again here.  It took me a little while to figure out why that wasn't the case.It's probably worth leaving a comment somewhere in this function explaining that we will only do one of (a) invoke the callback ourselves from the pending picks list and (b) cancel the pick on the RR policy, because `create_rr_locked()` will remove entries from `glb_policy->pending_picks` before sending them to the RR policy.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11901,129374296,2017-07-25T17:39:16Z,src/python/grpcio_testing/grpc_testing/_time.py,"@@ -0,0 +1,222 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Test times.""""""++import collections+import logging+import threading+import time as _time++import grpc+import grpc_testing+++def _call(behaviors):+    for behavior in behaviors:+        try:+            behavior()+        except Exception:  # pylint: disable=broad-except+            logging.exception('Exception calling behavior?')+++def _call_in_thread(behaviors):+    calling = threading.Thread(target=_call, args=(behaviors,))+    calling.start()",One must never call untrusted foreign code while holding a lock of one's own. Three of `_call_in_thread`'s four call sites are inside `with self._condition` blocks. (I think the tests as written right now would fail if the use of the extra thread were removed.),
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/11941,129780331,2017-07-27T08:23:54Z,tools/internal_ci/macos/grpc_master.cfg,"@@ -15,11 +15,16 @@ # Config file for the internal CI (in protobuf text format)  # Location of the continuous shell script in repository.-build_file: ""grpc/tools/internal_ci/macos/grpc_master.sh""+build_file: ""grpc/tools/internal_ci/macos/grpc_run_tests_matrix.sh"" timeout_mins: 240 action {   define_artifacts {     regex: ""**/*sponge_log.xml""     regex: ""github/grpc/reports/**""   } }++env_vars {+  key: ""RUN_TESTS_FLAGS""+  value: ""-f basictests macos --internal_ci -j 2 --inner_jobs 4""","Windows workers should have access to bigquery already, but I'm not sure if the google api client python package is installed there.Also, we'd need to make sure to differentiate between master and pull requests jobs in order to use bq_result_table.I'll look into that in a followup PR.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11948,129855299,2017-07-27T14:21:59Z,src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.c,"@@ -74,6 +74,9 @@ typedef struct round_robin_lb_policy {   bool started_picking;   /** are we shutting down? */   bool shutdown;+  /** has the policy gotten into the GRPC_CHANNEL_SHUTDOWN? No picks can be+   * service after this point, the policy will never transition out. */+  bool in_connectivity_shutdown;","Could we use the existing `shutdown` bool for this, rather than adding a new one?  Not sure whether or not this makes sense; it just seems a little odd to have two different variables for very similar purposes.",
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/11703,129901779,2017-07-27T17:12:47Z,src/core/lib/surface/completion_queue.c,"@@ -576,6 +549,42 @@ static void cq_check_tag(grpc_completion_queue *cq, void *tag, bool lock_cq) { static void cq_check_tag(grpc_completion_queue *cq, void *tag, bool lock_cq) {} #endif +static bool cq_begin_op_for_next(grpc_completion_queue *cq, void *tag) {+  cq_next_data *cqd = DATA_FROM_CQ(cq);+  while (true) {+    gpr_atm count = gpr_atm_no_barrier_load(&cqd->pending_events);+    if (count == 0) {+      cq_check_tag(cq, tag, true); /* Used in debug builds only */","ok. It was not failing because just before calling this function, we were adding the tag to `cq->outstanding_tags` (in function grpc_cq_begin_op). That is not really the correct way to do it (because we may still have race conditions) but since its only for debugging purposes, I guess its ok.. In anycase, we should remove the `cq_check_tag` here.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/11923,129904542,2017-07-27T17:23:37Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb_client_stats.c,"@@ -87,32 +80,70 @@ void grpc_grpclb_client_stats_add_call_finished(   } } +void grpc_grpclb_client_stats_add_call_dropped_locked(+    char* token, grpc_grpclb_client_stats* client_stats) {+  // Increment num_calls_started and num_calls_finished.+  gpr_atm_full_fetch_add(&client_stats->num_calls_started, (gpr_atm)1);+  gpr_atm_full_fetch_add(&client_stats->num_calls_finished, (gpr_atm)1);+  // Record the drop.+  if (client_stats->drop_token_counts == NULL) {+    client_stats->drop_token_counts =+        gpr_zalloc(sizeof(grpc_grpclb_dropped_call_counts));+  }+  grpc_grpclb_dropped_call_counts* drop_token_counts =+      client_stats->drop_token_counts;+  for (size_t i = 0; i < drop_token_counts->num_entries; ++i) {+    if (strcmp(drop_token_counts->token_counts[i].token, token) == 0) {","Given that the length of the token is bounded (https://github.com/grpc/grpc/blob/master/src/proto/grpc/lb/v1/load_balancer.proto#L154), `strncmp` looks like a safer option. See https://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c#L513 ",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11923,129936520,2017-07-27T19:26:46Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb_client_stats.c,"@@ -87,32 +80,70 @@ void grpc_grpclb_client_stats_add_call_finished(   } } +void grpc_grpclb_client_stats_add_call_dropped_locked(+    char* token, grpc_grpclb_client_stats* client_stats) {+  // Increment num_calls_started and num_calls_finished.+  gpr_atm_full_fetch_add(&client_stats->num_calls_started, (gpr_atm)1);+  gpr_atm_full_fetch_add(&client_stats->num_calls_finished, (gpr_atm)1);+  // Record the drop.+  if (client_stats->drop_token_counts == NULL) {+    client_stats->drop_token_counts =+        gpr_zalloc(sizeof(grpc_grpclb_dropped_call_counts));+  }+  grpc_grpclb_dropped_call_counts* drop_token_counts =+      client_stats->drop_token_counts;+  for (size_t i = 0; i < drop_token_counts->num_entries; ++i) {+    if (strcmp(drop_token_counts->token_counts[i].token, token) == 0) {","I'm not sure why that makes any difference.  As long as both strings are nul-terminated (which they should be), the behavior should be the same for both `strcmp()` and `strncmp()`.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/11923,129947723,2017-07-27T20:16:07Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb_client_stats.c,"@@ -87,32 +80,70 @@ void grpc_grpclb_client_stats_add_call_finished(   } } +void grpc_grpclb_client_stats_add_call_dropped_locked(+    char* token, grpc_grpclb_client_stats* client_stats) {+  // Increment num_calls_started and num_calls_finished.+  gpr_atm_full_fetch_add(&client_stats->num_calls_started, (gpr_atm)1);+  gpr_atm_full_fetch_add(&client_stats->num_calls_finished, (gpr_atm)1);+  // Record the drop.+  if (client_stats->drop_token_counts == NULL) {+    client_stats->drop_token_counts =+        gpr_zalloc(sizeof(grpc_grpclb_dropped_call_counts));+  }+  grpc_grpclb_dropped_call_counts* drop_token_counts =+      client_stats->drop_token_counts;+  for (size_t i = 0; i < drop_token_counts->num_entries; ++i) {+    if (strcmp(drop_token_counts->token_counts[i].token, token) == 0) {","Same reasons we use asserts for things that should be but not always are. If for any reason (including malicious) we have a ill-formatted string, this opens the doors to exploitable vulnerabilities (a compromised balancer can send any token it wants). Even if we currently sanitize the serverlists, if that were to stop happening, this `strcmp` would be exposed. There's no downside to using `strncmp` (given the max size of the token is bounded) and a sizable upside.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/11948,129951286,2017-07-27T20:31:27Z,src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.c,"@@ -74,6 +74,9 @@ typedef struct round_robin_lb_policy {   bool started_picking;   /** are we shutting down? */   bool shutdown;+  /** has the policy gotten into the GRPC_CHANNEL_SHUTDOWN? No picks can be+   * service after this point, the policy will never transition out. */+  bool in_connectivity_shutdown;","Woops confused this with the grpclb similar bool. Addressing this comment now, please ignore it for now, commit to follow.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11923,129951933,2017-07-27T20:34:12Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb_client_stats.c,"@@ -87,32 +80,70 @@ void grpc_grpclb_client_stats_add_call_finished(   } } +void grpc_grpclb_client_stats_add_call_dropped_locked(+    char* token, grpc_grpclb_client_stats* client_stats) {+  // Increment num_calls_started and num_calls_finished.+  gpr_atm_full_fetch_add(&client_stats->num_calls_started, (gpr_atm)1);+  gpr_atm_full_fetch_add(&client_stats->num_calls_finished, (gpr_atm)1);+  // Record the drop.+  if (client_stats->drop_token_counts == NULL) {+    client_stats->drop_token_counts =+        gpr_zalloc(sizeof(grpc_grpclb_dropped_call_counts));+  }+  grpc_grpclb_dropped_call_counts* drop_token_counts =+      client_stats->drop_token_counts;+  for (size_t i = 0; i < drop_token_counts->num_entries; ++i) {+    if (strcmp(drop_token_counts->token_counts[i].token, token) == 0) {","The token is sent in a protobuf string field.  The protobuf API will always return the deserialized value as a nul-terminated string, regardless of the contents of the field, so I don't see how it's possible to get a non-nul-terminated string here, either maliciously or by accident.  The only edge case I can see regarding nul bytes is that we could get a string with a nul byte in the middle, in which case our code will just ignore everything after that (and `strncmp()` would not protect against that anyway).Conversely, although the comment you pointed to documents that the token string will not be more than 50 characters, there is nothing (at least on the client side) enforcing this.  If we only compare the first 50 characters and then the balancer suddenly starts sending longer tokens that differ only in the last character, then we would wind up generating bogus load-reports.  I think it's better to protect against that future possibility than against the impossible-as-far-as-I-can-tell possibility of a non-nul-terminated string.",
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/11703,130158522,2017-07-28T18:40:53Z,src/core/lib/surface/completion_queue.c,"@@ -576,6 +549,42 @@ static void cq_check_tag(grpc_completion_queue *cq, void *tag, bool lock_cq) { static void cq_check_tag(grpc_completion_queue *cq, void *tag, bool lock_cq) {} #endif +static bool cq_begin_op_for_next(grpc_completion_queue *cq, void *tag) {+  cq_next_data *cqd = DATA_FROM_CQ(cq);+  while (true) {+    gpr_atm count = gpr_atm_no_barrier_load(&cqd->pending_events);+    if (count == 0) {+      cq_check_tag(cq, tag, true); /* Used in debug builds only */","Removed.The tag is added to a debug-only list in begin_op and if the tag is not removed here, our bookkeeping might go wrong when dumping the pending tags. (This may not be a huge issue as it should be around shutdown time.) Could you elaborate on the race condition?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/11934,130171372,2017-07-28T19:45:09Z,src/core/ext/transport/chttp2/transport/writing.c,"@@ -453,6 +453,7 @@ void grpc_chttp2_end_write(grpc_exec_ctx *exec_ctx, grpc_chttp2_transport *t,    while (grpc_chttp2_list_pop_writing_stream(t, &s)) {     if (s->sent_initial_metadata) {+      s->write_initial_metadata_done = true;","Is it possible for the initial metadata to be sent in multiple writes?  If so, we should probably set this when the first write finishes instead of waiting for all of the writes to finish.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/10636,130178586,2017-07-28T20:24:21Z,src/ruby/ext/grpc/rb_call.c,"@@ -179,6 +179,36 @@ static VALUE grpc_rb_call_cancel(VALUE self) {   return Qnil; } +/* Not a part of the surface API.+ * This is meant for internal usage by the ""write thread"" of grpc-ruby+ * client-side bidi calls. It provides a way for the background write-thread+ * to propogate failures to the main read-thread and give the user an error+ * message. */+static VALUE grpc_rb_call_cancel_with_bidi_write_thread_error_message(","per offline conversation. the `const char *` type for the `description` API seems to force some memory management if surfacing the `grpc_call_cancel_with_status` string directly.But looking into `grpc_call_cancel_with_status`, it looks like the error string that it stores is copied out from the `description` parameter anyways. (https://github.com/grpc/grpc/blob/4ea19235d72404c9fb56fcf155f7fbf8ea8ec37e/src/core/lib/surface/call.c#L648). I'm not sure if this is subject to change, but if not, perhaps the `const char * description` in `grpc_call_cancel_with_status` is overly restrictive.cc @nicolasnoble @ncteisen ",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/10636,130184579,2017-07-28T20:56:44Z,src/ruby/ext/grpc/rb_call.c,"@@ -179,6 +179,36 @@ static VALUE grpc_rb_call_cancel(VALUE self) {   return Qnil; } +/* Not a part of the surface API.+ * This is meant for internal usage by the ""write thread"" of grpc-ruby+ * client-side bidi calls. It provides a way for the background write-thread+ * to propogate failures to the main read-thread and give the user an error+ * message. */+static VALUE grpc_rb_call_cancel_with_bidi_write_thread_error_message(","That description is a read only string from grpc_call_cancel_with_status's point of view. That is why it is duplicated, so the error can take ownership of its life. Otherwise it's just printed. So surfacing grpc_call_cancel_with_status should be safe I think? You can pass it any char*, and it won't modify or deallocate it",
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/11977,130195188,2017-07-28T22:00:30Z,src/core/tsi/transport_security_grpc.h,"@@ -0,0 +1,73 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_TSI_TRANSPORT_SECURITY_GRPC_H+#define GRPC_CORE_TSI_TRANSPORT_SECURITY_GRPC_H++#include <grpc/slice_buffer.h>+#include ""src/core/tsi/transport_security.h""++#ifdef __cplusplus+extern ""C"" {+#endif++/* -- tsi_zero_copy_protector object --  */++/* Outputs protected frames.+   - unprotected_bytes is the unprotected data to be protected.+   - protected_output_frames is the protected output frames. One or more frames+     may be produced in this protect function.+   - This method returns TSI_OK in case of success or a specific error code in+     case of failure.  */+tsi_result tsi_zero_copy_protector_protect(+    tsi_zero_copy_protector *self, grpc_slice_buffer *unprotected_bytes,+    grpc_slice_buffer *protected_output_frames);++/* Outputs unprotected bytes.+   - protected_frames_bytes is the bytes of protected frames.+   - unproteced_bytes is the unprotected output data.+   - This method returns TSI_OK in case of success. Success includes cases where+     there is not enough data to output in which case unprotected_bytes has 0+     bytes.  */+tsi_result tsi_zero_copy_protector_unprotect(+    tsi_zero_copy_protector *self, grpc_slice_buffer *protected_frames_bytes,",Same comment about the parameter names.,
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/11964,130226652,2017-07-29T19:20:42Z,src/python/grpcio_testing/grpc_testing/_channel/_channel.py,"@@ -0,0 +1,61 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import grpc_testing+from grpc_testing._channel import _channel_rpc+from grpc_testing._channel import _multi_callable+++# All per-call credentials parameters are unused by this test infrastructure.+# pylint: disable=unused-argument+class TestingChannel(grpc_testing.Channel):++    def __init__(self, time, state):+        self._time = time",Is time unused at this point?,
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/11964,130228434,2017-07-29T21:09:19Z,src/python/grpcio_tests/tests/testing/_client_test.py,"@@ -0,0 +1,302 @@+# Copyright 2017 The gRPC Authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++from concurrent import futures+import time+import unittest++import grpc+from grpc.framework.foundation import logging_pool+from tests.unit.framework.common import test_constants+import grpc_testing++from tests.testing import _application_common+from tests.testing import _application_testing_common+from tests.testing import _client_application+from tests.testing.proto import requests_pb2+from tests.testing.proto import services_pb2+++class ClientTest(unittest.TestCase):++    def setUp(self):+        # In this test the client-side application under test executes in+        # a separate thread while we retain use of the test thread to ""play+        # server"".+        self._client_execution_thread_pool = logging_pool.pool(1)","It seems like using the testing infrastructure to test any blocking RPCs will require something like this.It might be nice if I could ```take_next_rpc``` in advance or something like that, so that I could run the client app in the main thread.  This would probably make debugging easier, especially in the case of apps with unhanded exceptions.I realize this would be a large structural change, so I'm not suggesting we implement this, but I wanted to mention it.",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/11964,130286511,2017-07-31T07:26:36Z,src/python/grpcio_testing/grpc_testing/_channel/_channel.py,"@@ -0,0 +1,61 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import grpc_testing+from grpc_testing._channel import _channel_rpc+from grpc_testing._channel import _multi_callable+++# All per-call credentials parameters are unused by this test infrastructure.",credentials parameters? (I think this may be copied and pasted from somewhere else),
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11964,130417040,2017-07-31T18:03:51Z,src/python/grpcio_testing/grpc_testing/_channel/_channel.py,"@@ -0,0 +1,61 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import grpc_testing+from grpc_testing._channel import _channel_rpc+from grpc_testing._channel import _multi_callable+++# All per-call credentials parameters are unused by this test infrastructure.","Yep, corrected to ""All serializer and deserializer parameters are not (yet) used by this test infrastructure."". Thanks for the catch.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11964,130418365,2017-07-31T18:08:50Z,src/python/grpcio_testing/grpc_testing/_channel/_rpc_state.py,"@@ -0,0 +1,193 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import threading++import grpc+from grpc_testing import _common+++class State(_common.ChannelRpcHandler):++    def __init__(self, invocation_metadata, requests, requests_closed):+        self._condition = threading.Condition()+        self._invocation_metadata = invocation_metadata+        self._requests = requests+        self._requests_closed = requests_closed+        self._initial_metadata = None+        self._responses = []+        self._trailing_metadata = None+        self._code = None+        self._details = None++    def initial_metadata(self):+        with self._condition:+            while True:+                if self._initial_metadata is None:+                    if self._code is None:+                        self._condition.wait()+                    else:+                        return _common.FUSSED_EMPTY_METADATA+                else:+                    return self._initial_metadata++    def add_request(self, request):+        with self._condition:+            if self._code is None and not self._requests_closed:+                self._requests.append(request)+                self._condition.notify_all()+                return True+            else:+                return False++    def close_requests(self):+        with self._condition:+            if self._code is None and not self._requests_closed:+                self._requests_closed = True+                self._condition.notify_all()++    def take_response(self):+        with self._condition:+            while True:+                if self._code is grpc.StatusCode.OK:+                    if self._responses:+                        response = self._responses.pop(0)+                        return _common.ChannelRpcRead(+                            response, None, None, None)+                    else:+                        return _common.ChannelRpcRead(+                            None, self._trailing_metadata,+                            grpc.StatusCode.OK, self._details)+                elif self._code is None:+                    if self._responses:+                        response = self._responses.pop(0)+                        return _common.ChannelRpcRead(+                            response, None, None, None)+                    else:+                        self._condition.wait()+                else:+                    return _common.ChannelRpcRead(+                        None, self._trailing_metadata, self._code,+                        self._details)++    def termination(self):+        with self._condition:+            while True:+                if self._code is None:+                    self._condition.wait()+                else:+                    return self._trailing_metadata, self._code, self._details++    def cancel(self, code, details):","Maybe I should have called this ""abort"" - it's more akin to ""cancel for the given reason"", kind of like [`grpc_call_cancel_with_status`](https://github.com/grpc/grpc/blob/4042e4c4d4b36891a2c220c8d5b69b9ad73a77bd/include/grpc/grpc.h#L294-L303) in the core API.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11964,130423760,2017-07-31T18:27:23Z,src/python/grpcio_tests/tests/testing/proto/__init__.py,"@@ -0,0 +1,13 @@+# Copyright 2017 gRPC authors.","Maybe not? I was just following the existing pattern in tests/protoc_plugin/protos.But when I remove the file, the test fails, so [let's keep it for now and if it can be cleaned up we'll clean it up later](https://github.com/grpc/grpc/issues/11993).",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12003,130465842,2017-07-31T21:23:54Z,src/node/test/call_test.js,"@@ -188,6 +188,91 @@ describe('call', function() {       }, TypeError);     });   });+  describe('startBatch with message', function() {+    it('should fail with non-buffer arguments', function() {+      var call = new grpc.Call(channel, 'method', getDeadline(1));+      assert.throws(function() {+        var batch = {};+        batch[grpc.opType.SEND_MESSAGE] = null;+        call.startBatch(batch, function(){});+      }, TypeError);+      assert.throws(function() {+        var batch = {};+        batch[grpc.opType.SEND_MESSAGE] = 5;+        call.startBatch(batch, function(){});+      }, TypeError);+      assert.throws(function() {+        var batch = {};+        batch[grpc.opType.SEND_MESSAGE] = 'value';+        call.startBatch(batch, function(){});+      }, TypeError);+    });+  });+  describe('startBatch with status', function() {+    it('should fail without a code', function() {+      var call = new grpc.Call(channel, 'method', getDeadline(1));+      assert.throws(function() {+        var batch = {};+        batch[grpc.opType.SEND_STATUS_FROM_SERVER] = {+          details: 'details string',+          metadata: {}+        };+        call.startBatch(batch, function(){});+      }, TypeError);+    });+    it('should fail without details', function() {+      var call = new grpc.Call(channel, 'method', getDeadline(1));+      assert.throws(function() {+        var batch = {};+        batch[grpc.opType.SEND_STATUS_FROM_SERVER] = {+          code: 0,+          metadata: {}+        };+        call.startBatch(batch, function(){});+      }, TypeError);+    });+    it('should fail without metadata', function() {+      var call = new grpc.Call(channel, 'method', getDeadline(1));",is the deadline necessary for these tests? can it be removed?,
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/11878,130513249,2017-08-01T03:34:05Z,src/php/ext/grpc/channel_credentials.c,"@@ -140,10 +144,24 @@ PHP_METHOD(ChannelCredentials, createSsl) {                          ""createSsl expects 3 optional strings"", 1 TSRMLS_CC);     return;   }++  php_grpc_int hashkey_len = root_certs_length + cert_chain_length;+  char hashkey[hashkey_len];+  if (root_certs_length > 0) {+    strcpy(hashkey, pem_root_certs);+  }+  if (cert_chain_length > 0) {+    strcpy(hashkey, pem_key_cert_pair.cert_chain);+  }++  char *hashstr = emalloc(41);",There's another small memory leak in this class. It's tricky to fix. I will add a TODO to fix it.,
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/11878,130673135,2017-08-01T17:28:57Z,src/php/ext/grpc/channel.c,"@@ -146,14 +180,93 @@ PHP_METHOD(Channel, __construct) {       php_grpc_zend_hash_del(array_hash, ""credentials"", sizeof(""credentials""));     }   }-  php_grpc_read_args_array(args_array, &args TSRMLS_CC);-  if (creds == NULL) {-    channel->wrapped = grpc_insecure_channel_create(target, &args, NULL);+  if (php_grpc_zend_hash_find(array_hash, ""force_new"", sizeof(""force_new""),+                              (void **)&force_new_obj) == SUCCESS) {+    if (PHP_GRPC_BVAL_IS_TRUE(force_new_obj)) {+      force_new = true;+    }+    php_grpc_zend_hash_del(array_hash, ""force_new"", sizeof(""force_new""));+  }++  // parse the rest of the channel args array+  if (php_grpc_read_args_array(args_array, &args TSRMLS_CC) == FAILURE) {+    return;",zend_throw_exception needed here?,
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/11954,130673635,2017-08-01T17:30:35Z,src/core/lib/iomgr/gethostname_fallback.c,"@@ -0,0 +1,29 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/core/lib/iomgr/port.h""++#if !defined(GRPC_POSIX_HOST_NAME_MAX) && !defined(GRPC_POSIX_SYSCONF)","The only small maintainability problem I see here potentially is if there's yet a new version of grpc_gethostname that gets added, this logic here is disjointed from adding a new entry (which resides in port.h).Our main way to handle this is to add for instance `GRPC_GETHOSTNAME_FALLBACK` in port.h close to the other checks where people would need to add their new implementation anyway, for example where you check for duplicated `#defines`, you can also add the fallback definition.",
961599,murgatroid99,https://api.github.com/repos/grpc/grpc/pulls/12003,130676856,2017-08-01T17:42:22Z,src/node/test/call_test.js,"@@ -188,6 +188,91 @@ describe('call', function() {       }, TypeError);     });   });+  describe('startBatch with message', function() {+    it('should fail with non-buffer arguments', function() {+      var call = new grpc.Call(channel, 'method', getDeadline(1));+      assert.throws(function() {+        var batch = {};+        batch[grpc.opType.SEND_MESSAGE] = null;+        call.startBatch(batch, function(){});+      }, TypeError);+      assert.throws(function() {+        var batch = {};+        batch[grpc.opType.SEND_MESSAGE] = 5;+        call.startBatch(batch, function(){});+      }, TypeError);+      assert.throws(function() {+        var batch = {};+        batch[grpc.opType.SEND_MESSAGE] = 'value';+        call.startBatch(batch, function(){});+      }, TypeError);+    });+  });+  describe('startBatch with status', function() {+    it('should fail without a code', function() {+      var call = new grpc.Call(channel, 'method', getDeadline(1));+      assert.throws(function() {+        var batch = {};+        batch[grpc.opType.SEND_STATUS_FROM_SERVER] = {+          details: 'details string',+          metadata: {}+        };+        call.startBatch(batch, function(){});+      }, TypeError);+    });+    it('should fail without details', function() {+      var call = new grpc.Call(channel, 'method', getDeadline(1));+      assert.throws(function() {+        var batch = {};+        batch[grpc.opType.SEND_STATUS_FROM_SERVER] = {+          code: 0,+          metadata: {}+        };+        call.startBatch(batch, function(){});+      }, TypeError);+    });+    it('should fail without metadata', function() {+      var call = new grpc.Call(channel, 'method', getDeadline(1));",Call needs some deadline. We might as well use the same deadline value used elsewhere in the file.,
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/11878,130677208,2017-08-01T17:43:41Z,src/php/ext/grpc/channel.c,"@@ -146,14 +180,93 @@ PHP_METHOD(Channel, __construct) {       php_grpc_zend_hash_del(array_hash, ""credentials"", sizeof(""credentials""));     }   }-  php_grpc_read_args_array(args_array, &args TSRMLS_CC);-  if (creds == NULL) {-    channel->wrapped = grpc_insecure_channel_create(target, &args, NULL);+  if (php_grpc_zend_hash_find(array_hash, ""force_new"", sizeof(""force_new""),+                              (void **)&force_new_obj) == SUCCESS) {+    if (PHP_GRPC_BVAL_IS_TRUE(force_new_obj)) {+      force_new = true;+    }+    php_grpc_zend_hash_del(array_hash, ""force_new"", sizeof(""force_new""));+  }++  // parse the rest of the channel args array+  if (php_grpc_read_args_array(args_array, &args TSRMLS_CC) == FAILURE) {+    return;+  }++  // Construct a hashkey for the persistent channel+  // Currently, the hashkey contains 3 parts:+  // 1. hostname+  // 2. hash value of the channel args array (excluding ""credentials""+  //    and ""force_new"")+  // 3. (optional) hash value of the ChannelCredentials object+  //+  // Note that, if the ChannelCredentials object was created by+  // ""composing"" a ChannelCredentials and CallCredentials object+  // together, the CallCredentials portion will be ignored, when+  // constructing this hashkey.+  //+  // In other words, the same ChannelCredentials object, composed","This really feels like too dangerous of an edge case to ignore.I can think of a likely use case that this change would break:Suppose a user has 2 cloud projects, and they want to access data from each in an app.  Cloud credentials are always CallCredentials, so this change will break them.  I realize there is no good way to hash a function, especially if we get passed an anonymous function.  I think a good compromise would be adding an optional id parameter when a call credentials is created from a callback, and this can be used to avoid this.  If we have a call credentials without an id, then we don't cache the channel. ",
29667874,griffithjames,https://api.github.com/repos/grpc/grpc/pulls/11964,130680662,2017-08-01T17:56:32Z,src/python/grpcio_testing/grpc_testing/_channel/_rpc_state.py,"@@ -0,0 +1,193 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import threading++import grpc+from grpc_testing import _common+++class State(_common.ChannelRpcHandler):++    def __init__(self, invocation_metadata, requests, requests_closed):+        self._condition = threading.Condition()+        self._invocation_metadata = invocation_metadata",self._invocation_metadata could be a list - it'd let you pop() it to empty it.,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/11964,130698826,2017-08-01T19:04:03Z,src/python/grpcio_testing/grpc_testing/_channel/_rpc_state.py,"@@ -0,0 +1,193 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import threading++import grpc+from grpc_testing import _common+++class State(_common.ChannelRpcHandler):++    def __init__(self, invocation_metadata, requests, requests_closed):+        self._condition = threading.Condition()+        self._invocation_metadata = invocation_metadata","It could, but there's no need for it to be. Each of the three [metadata objects](https://grpc.io/grpc/python/grpc.html#glossary) in an RPC is treated as a (probably immutable) [sequence](https://docs.python.org/2/library/stdtypes.html#sequence-types-str-unicode-list-tuple-bytearray-buffer-xrange). Metadata is accepted whole from the application on one side, delivered whole to the application on the other side, and mostly not molested by the gRPC code in between.In the particular circumstance of this instance-scope field: non-`None` indicating metadata accepted from the system under test and not yet delivered to the testing system and `None` indicating metadata having already been delivered to the testing system are exactly the semantics we want. We want semantics simpler than one usually gets with a mutable list-valued field.",
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/11878,130791843,2017-08-02T06:01:09Z,src/php/ext/grpc/channel.c,"@@ -146,14 +180,93 @@ PHP_METHOD(Channel, __construct) {       php_grpc_zend_hash_del(array_hash, ""credentials"", sizeof(""credentials""));     }   }-  php_grpc_read_args_array(args_array, &args TSRMLS_CC);-  if (creds == NULL) {-    channel->wrapped = grpc_insecure_channel_create(target, &args, NULL);+  if (php_grpc_zend_hash_find(array_hash, ""force_new"", sizeof(""force_new""),+                              (void **)&force_new_obj) == SUCCESS) {+    if (PHP_GRPC_BVAL_IS_TRUE(force_new_obj)) {+      force_new = true;+    }+    php_grpc_zend_hash_del(array_hash, ""force_new"", sizeof(""force_new""));+  }++  // parse the rest of the channel args array+  if (php_grpc_read_args_array(args_array, &args TSRMLS_CC) == FAILURE) {+    return;","No need. The exception was ""thrown"" in the inner function. Once this function returns (our C code is done), PHP will throw the exception in user-land.",
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/11878,130792026,2017-08-02T06:02:45Z,src/php/ext/grpc/channel.c,"@@ -146,14 +180,93 @@ PHP_METHOD(Channel, __construct) {       php_grpc_zend_hash_del(array_hash, ""credentials"", sizeof(""credentials""));     }   }-  php_grpc_read_args_array(args_array, &args TSRMLS_CC);-  if (creds == NULL) {-    channel->wrapped = grpc_insecure_channel_create(target, &args, NULL);+  if (php_grpc_zend_hash_find(array_hash, ""force_new"", sizeof(""force_new""),+                              (void **)&force_new_obj) == SUCCESS) {+    if (PHP_GRPC_BVAL_IS_TRUE(force_new_obj)) {+      force_new = true;+    }+    php_grpc_zend_hash_del(array_hash, ""force_new"", sizeof(""force_new""));+  }++  // parse the rest of the channel args array+  if (php_grpc_read_args_array(args_array, &args TSRMLS_CC) == FAILURE) {+    return;+  }++  // Construct a hashkey for the persistent channel+  // Currently, the hashkey contains 3 parts:+  // 1. hostname+  // 2. hash value of the channel args array (excluding ""credentials""+  //    and ""force_new"")+  // 3. (optional) hash value of the ChannelCredentials object+  //+  // Note that, if the ChannelCredentials object was created by+  // ""composing"" a ChannelCredentials and CallCredentials object+  // together, the CallCredentials portion will be ignored, when+  // constructing this hashkey.+  //+  // In other words, the same ChannelCredentials object, composed+  // with 2 different CallCredentials objects, will return the same+  // underlying grpc_channel. So proceed with caution.++  php_serialize_data_t var_hash;+  smart_str buf = {0};+  PHP_VAR_SERIALIZE_INIT(var_hash);+  PHP_GRPC_VAR_SERIALIZE(&buf, args_array, &var_hash);+  PHP_VAR_SERIALIZE_DESTROY(var_hash);++  char sha1str[41];+  generate_sha1_str(sha1str, PHP_GRPC_SERIALIZED_BUF_STR(buf),+                    PHP_GRPC_SERIALIZED_BUF_LEN(buf));++  php_grpc_int key_len = target_length + strlen(sha1str);+  if (creds != NULL && creds->hashstr != NULL) {+    key_len += strlen(creds->hashstr);+  }+  char *key = malloc(key_len + 1);+  strcpy(key, target);+  strcat(key, sha1str);+  if (creds != NULL && creds->hashstr != NULL) {+    strcat(key, creds->hashstr);+  }+  channel->wrapper = malloc(sizeof(grpc_channel_wrapper));+  channel->wrapper->key = key;+  gpr_mu_init(&channel->wrapper->mu);+  smart_str_free(&buf);++  if (force_new) {+    php_grpc_delete_persistent_list_entry(key, key_len TSRMLS_CC);+  }++  if (!(PHP_GRPC_PERSISTENT_LIST_FIND(&EG(persistent_list), key, key_len,+                                      rsrc))) {+    php_grpc_zend_resource new_rsrc;+    // this links each persistent list entry to a destructor+    new_rsrc.type = le_plink;+    le = malloc(sizeof(channel_persistent_le_t));++    if (creds == NULL) {+      channel->wrapper->wrapped = grpc_insecure_channel_create(target, &args,+                                                               NULL);+    } else {+      channel->wrapper->wrapped =+          grpc_secure_channel_create(creds->wrapped, target, &args, NULL);+    }+    efree(args.args);+    le->channel = channel->wrapper;+    new_rsrc.ptr = le;+    PHP_GRPC_PERSISTENT_LIST_UPDATE(&EG(persistent_list), key, key_len,+                                    (void *)&new_rsrc);   } else {-    channel->wrapped =-        grpc_secure_channel_create(creds->wrapped, target, &args, NULL);+    le = (channel_persistent_le_t *)rsrc->ptr;+    if (strcmp(target, grpc_channel_get_target(le->channel->wrapped)) != 0) {+      zend_throw_exception(spl_ce_RuntimeException,",Done. Added all the fields (target and hashstr) to the wrapper object. Now I am doing comparison on all the fields. Also will return the new channel (the parameters user requested) and evicted the old entry found in the persistent list.,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12026,130795579,2017-08-02T06:33:04Z,tools/internal_ci/macos/grpc_interop.sh,"@@ -18,6 +18,6 @@ set -ex # change to grpc repo root cd $(dirname $0)/../../.. -source tools/internal_ci/helper_scripts/prepare_build_interop_rc+source tools/internal_ci/helper_scripts/prepare_build_mac_interop_rc",consistency: for linux we include both standard and interop rc file:```source tools/internal_ci/helper_scripts/prepare_build_linux_rcsource tools/internal_ci/helper_scripts/prepare_build_interop_rc```https://github.com/grpc/grpc/blob/master/tools/internal_ci/linux/grpc_interop_tocloud.sh#L24That allows avoiding some duplication of the install scripts and helps maintain a more standard environment.It looks like you've copy-pasted the software installation from `tools/internal_ci/helper_scripts/prepare_build_macos_rc`,
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/11977,131006067,2017-08-02T21:49:06Z,src/core/tsi/transport_security_grpc.h,"@@ -0,0 +1,73 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_TSI_TRANSPORT_SECURITY_GRPC_H+#define GRPC_CORE_TSI_TRANSPORT_SECURITY_GRPC_H++#include <grpc/slice_buffer.h>+#include ""src/core/tsi/transport_security.h""++#ifdef __cplusplus+extern ""C"" {+#endif++/* -- tsi_zero_copy_protector object --  */++/* Outputs protected frames.+   - unprotected_bytes is the unprotected data to be protected.+   - protected_output_frames is the protected output frames. One or more frames+     may be produced in this protect function.+   - This method returns TSI_OK in case of success or a specific error code in+     case of failure.  */+tsi_result tsi_zero_copy_protector_protect(+    tsi_zero_copy_protector *self, grpc_slice_buffer *unprotected_bytes,","In general, the data in the unprotected_bytes slice buffer should be unmodified. I am not 100% certain that unprotected_bytes will not be changed. We may need to split slice of unprotected_bytes. How about we do not claim 'const' for now? If we eventually we are able to do mark it as const, we can mark it later. ",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12048,131158815,2017-08-03T14:32:33Z,tools/internal_ci/linux/grpc_build_boringssl_at_head.cfg,"@@ -0,0 +1,30 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++# Config file for the internal CI (in protobuf text format)++# Location of the continuous shell script in repository.+build_file: ""grpc/tools/internal_ci/linux/grpc_build_submodule_at_head.sh""+timeout_mins: 180+action {+  define_artifacts {+    regex: ""**/*sponge_log.xml""+    regex: ""github/grpc/reports/**""+  }+}++env_vars {+  key: ""RUN_TESTS_FLAGS""","Please add a comment ""tiny hack: we want to pass the submodule name to test script, so we are misusing the already-whitelisted env variable for that purpose.""",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/11566,131160545,2017-08-03T14:38:30Z,src/core/ext/filters/client_channel/client_channel.c,"@@ -808,90 +808,74 @@ typedef struct client_channel_call_data {   // The code in deadline_filter.c requires this to be the first field.   // TODO(roth): This is slightly sub-optimal in that grpc_deadline_state   // and this struct both independently store a pointer to the call-  // stack and each has its own mutex.  If/when we have time, find a way-  // to avoid this without breaking the grpc_deadline_state abstraction.+  // stack and the call combiner.  If/when we have time, find a way to avoid+  // this without breaking the grpc_deadline_state abstraction.   grpc_deadline_state deadline_state;    grpc_slice path;  // Request path.   gpr_timespec call_start_time;   gpr_timespec deadline;+  grpc_call_stack *owning_call;+  gpr_arena *arena;+  grpc_call_combiner *call_combiner;+   grpc_server_retry_throttle_data *retry_throttle_data;   method_parameters *method_params; -  /** either 0 for no call, a pointer to a grpc_subchannel_call (if the lowest-      bit is 0), or a pointer to an error (if the lowest bit is 1) */-  gpr_atm subchannel_call_or_error;-  gpr_arena *arena;+  grpc_subchannel_call *subchannel_call;+  grpc_error *error;    grpc_lb_policy *lb_policy;  // Holds ref while LB pick is pending.   grpc_closure lb_pick_closure;+  grpc_closure cancel_closure;    grpc_connected_subchannel *connected_subchannel;   grpc_call_context_element subchannel_call_context[GRPC_CONTEXT_COUNT];   grpc_polling_entity *pollent;    grpc_transport_stream_op_batch *waiting_for_pick_batches[MAX_WAITING_BATCHES];   size_t waiting_for_pick_batches_count;+  grpc_closure handle_pending_batch_in_call_combiner[MAX_WAITING_BATCHES]; -  grpc_transport_stream_op_batch_payload *initial_metadata_payload;--  grpc_call_stack *owning_call;+  grpc_transport_stream_op_batch *initial_metadata_batch;    grpc_linked_mdelem lb_token_mdelem;    grpc_closure on_complete;   grpc_closure *original_on_complete; } call_data; -typedef struct {-  grpc_subchannel_call *subchannel_call;-  grpc_error *error;-} call_or_error;--static call_or_error get_call_or_error(call_data *p) {-  gpr_atm c = gpr_atm_acq_load(&p->subchannel_call_or_error);-  if (c == 0)-    return (call_or_error){NULL, NULL};-  else if (c & 1)-    return (call_or_error){NULL, (grpc_error *)((c) & ~(gpr_atm)1)};-  else-    return (call_or_error){(grpc_subchannel_call *)c, NULL};+grpc_subchannel_call *grpc_client_channel_get_subchannel_call(+    grpc_call_element *elem) {+  call_data *calld = elem->call_data;+  return calld->subchannel_call; } -static bool set_call_or_error(call_data *p, call_or_error coe) {-  // this should always be under a lock-  call_or_error existing = get_call_or_error(p);-  if (existing.error != GRPC_ERROR_NONE) {-    GRPC_ERROR_UNREF(coe.error);-    return false;-  }-  GPR_ASSERT(existing.subchannel_call == NULL);-  if (coe.error != GRPC_ERROR_NONE) {-    GPR_ASSERT(coe.subchannel_call == NULL);-    gpr_atm_rel_store(&p->subchannel_call_or_error, 1 | (gpr_atm)coe.error);+static void waiting_for_pick_batches_add(+    call_data *calld, grpc_transport_stream_op_batch *batch) {+  if (batch->send_initial_metadata) {+    GPR_ASSERT(calld->initial_metadata_batch == NULL);+    calld->initial_metadata_batch = batch;   } else {-    GPR_ASSERT(coe.subchannel_call != NULL);-    gpr_atm_rel_store(&p->subchannel_call_or_error,-                      (gpr_atm)coe.subchannel_call);+    GPR_ASSERT(calld->waiting_for_pick_batches_count < MAX_WAITING_BATCHES);+    calld->waiting_for_pick_batches[calld->waiting_for_pick_batches_count++] =+        batch;   }-  return true; } -grpc_subchannel_call *grpc_client_channel_get_subchannel_call(-    grpc_call_element *call_elem) {-  return get_call_or_error(call_elem->call_data).subchannel_call;-}--static void waiting_for_pick_batches_add_locked(-    call_data *calld, grpc_transport_stream_op_batch *batch) {-  GPR_ASSERT(calld->waiting_for_pick_batches_count < MAX_WAITING_BATCHES);-  calld->waiting_for_pick_batches[calld->waiting_for_pick_batches_count++] =-      batch;+static void fail_pending_batch_in_call_combiner(grpc_exec_ctx *exec_ctx,+                                                void *arg, grpc_error *error) {+  call_data *calld = arg;+  --calld->waiting_for_pick_batches_count;+  grpc_transport_stream_op_batch_finish_with_failure(+      exec_ctx,+      calld->waiting_for_pick_batches[calld->waiting_for_pick_batches_count],+      GRPC_ERROR_REF(error), calld->call_combiner);","This is really cool. I wanted to scream data race every time I saw constructs like this, but then I remembered the invariant that batches on the same call will get serialized on the same call combiner. That said, the issue here is a lack of comments! Please introduce comments to make this maintainable in the future.",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/11878,131275445,2017-08-03T22:29:04Z,src/php/ext/grpc/channel.c,"@@ -222,10 +408,46 @@ PHP_METHOD(Channel, watchConnectivityState) {  */ PHP_METHOD(Channel, close) {   wrapped_grpc_channel *channel = Z_WRAPPED_GRPC_CHANNEL_P(getThis());-  if (channel->wrapped != NULL) {-    grpc_channel_destroy(channel->wrapped);-    channel->wrapped = NULL;+  gpr_mu_lock(&channel->wrapper->mu);+  if (channel->wrapper->wrapped != NULL) {+    grpc_channel_destroy(channel->wrapper->wrapped);+    channel->wrapper->wrapped = NULL;+  }+  gpr_mu_unlock(&channel->wrapper->mu);++  php_grpc_delete_persistent_list_entry(channel->wrapper->key,+                                        strlen(channel->wrapper->key)+                                        TSRMLS_CC);+}++// Delete an entry from the persistent list+// Note: this does not destroy or close the underlying grpc_channel+void php_grpc_delete_persistent_list_entry(char *key, php_grpc_int key_len+                                           TSRMLS_DC) {+  php_grpc_zend_resource *rsrc;+  if (PHP_GRPC_PERSISTENT_LIST_FIND(&EG(persistent_list), key,","You might want another mutex around this global list, it could be accessed by multiple threads and I'm guessing its not threadsafe.",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/11878,131285446,2017-08-03T23:46:10Z,src/php/ext/grpc/channel.c,"@@ -303,6 +304,7 @@ PHP_METHOD(Channel, __construct) {       channel->wrapper = le->channel;     }   }+  gpr_mu_unlock(&channel->wrapper->mu);","Sorry, I should clarify.  I think you need a separate mutex specifically for ```persistent_list```.  The linked list is not threadsafe, so any time we access it we need to acquire a global mutex around it (separate from the channel mutex).",
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/11878,131289746,2017-08-04T00:26:19Z,src/php/ext/grpc/channel.c,"@@ -303,6 +304,7 @@ PHP_METHOD(Channel, __construct) {       channel->wrapper = le->channel;     }   }+  gpr_mu_unlock(&channel->wrapper->mu);",Done. Added a `global_persistent_list_mu`,
22083734,matt-kwong,https://api.github.com/repos/grpc/grpc/pulls/12053,131422573,2017-08-04T15:49:53Z,tools/flakes/detect_flakes.py,"@@ -0,0 +1,83 @@+# -*- coding: utf-8 -*-+from __future__ import absolute_import+from __future__ import division+from __future__ import print_function++import os+import sys+import logging+logging.basicConfig(format='%(asctime)s %(message)s')++gcp_utils_dir = os.path.abspath(+    os.path.join(os.path.dirname(__file__), '../gcp/utils'))+sys.path.append(gcp_utils_dir)++import big_query_utils+++def get_flaky_tests(period, limit=None):+  """""" period is one of ""WEEK"", ""DAY"", etc.+  (see https://cloud.google.com/bigquery/docs/reference/standard-sql/functions-and-operators#date_add). """"""++  bq = big_query_utils.create_big_query()+  query = """"""+SELECT+  filtered_test_name,+  FIRST(timestamp),+  FIRST(build_url),+FROM (+  SELECT+    REGEXP_REPLACE(test_name, r'/\d+', '') AS filtered_test_name,+    result,+    build_url,+    timestamp+  FROM+    [grpc-testing:jenkins_test_results.aggregate_results]+  WHERE+    timestamp >= DATE_ADD(CURRENT_DATE(), -1, ""{period}"")+    AND NOT REGEXP_MATCH(job_name, '.*portability.*'))+GROUP BY+  filtered_test_name,+  timestamp,+  build_url+HAVING+  SUM(result != 'PASSED'+    AND result != 'SKIPPED') > 0+ORDER BY+  timestamp DESC+"""""".format(period=period)+  if limit:+    query += '\n LIMIT {}'.format(limit)+  query_job = big_query_utils.sync_query_job(bq, 'grpc-testing', query)+  page = bq.jobs().getQueryResults(+      pageToken=None, **query_job['jobReference']).execute(num_retries=3)+  testname_to_ts_url_pair = {row['f'][0]['v']: (row['f'][1]['v'], row['f'][2]['v']) for row in page['rows']}","With `ORDER BY timestamp ASC`, wouldn't the latest failures be at the end of the list? This would mean that the latest failures overwrite earlier failures of the same name in the dict.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12076,131449477,2017-08-04T17:58:15Z,src/ruby/lib/grpc/generic/service.rb,"@@ -167,22 +167,22 @@ def initialize(host, creds, **kw)             if desc.request_response?               define_method(mth_name) do |req, metadata = {}|                 GRPC.logger.debug(""calling #{@host}:#{route}"")-                request_response(route, req, marshal, unmarshal, metadata)",I think I see the issue - renaming the metadata variable here to `client_stub_opts` would be more clear?,
8314021,benwulfe,https://api.github.com/repos/grpc/grpc/pulls/12099,131694053,2017-08-07T15:59:14Z,src/csharp/Grpc.Core/GrpcEnvironment.cs,"@@ -311,13 +328,16 @@ internal static void GrpcNativeShutdown()         /// </summary>         private async Task ShutdownAsync()         {-            if (isClosed)+            if (isShutdown)","this is technically not thread safe either, but I'm not sure how important it really is if multiple threads dont call shutdown.A switch to interlocked.exchange and inspect the result would fix.",
17011,jskeet,https://api.github.com/repos/grpc/grpc/pulls/12120,131942872,2017-08-08T15:15:27Z,src/csharp/Grpc.Core/RpcException.cs,"@@ -56,5 +71,18 @@ public Status Status                 return status;             }         }++        /// <summary>+        /// Gets the call trailing metadata.+        /// Trailers only have meaningful content for client-side calls (in which case they represent the trailing metadata sent by the server when closing the call).+        /// Instances of <c>RpcException</c> thrown by the server-side part of the stack will have trailers always set to empty.+        /// </summary>+        public Metadata Trailers",I'd just use `public Metadata Trailers { get; }` and assign directly to this in the constructor - and to the same with `Status` - unless you particularly need to be pre-C#-6 friendly.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12104,131945809,2017-08-08T15:25:05Z,src/core/lib/channel/channel_stack_builder.c,"@@ -158,9 +176,43 @@ const grpc_channel_args *grpc_channel_stack_builder_get_channel_arguments(   return builder->args; } +// Returns true if (an equivalent of) \a filter has been found and properly+// processed. Only replaces if \a filter's priority value is lower than the+// potentially already present equally named filter.+static bool search_and_maybe_replace(+    grpc_channel_stack_builder *builder, const grpc_channel_filter *filter,+    grpc_post_filter_create_init_func post_init_func, void *user_data) {+  grpc_channel_stack_builder_iterator *it =+      grpc_channel_stack_builder_iterator_find(builder, filter->name);+  if (it == NULL) {+    return false;+  }+  if (filter->priority < it->node->filter->priority) {+    // If the new filter has a lesser priority value (ie, it's more prioritary)+    // than the present one, replace.+    filter_node *new_node = gpr_malloc(sizeof(*new_node));",Couldn't this entire block just be replaced with the following?```it->node->filter = filter;it->node->init = post_init_func;it->node->init_arg = user_data;```,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12104,131946340,2017-08-08T15:26:43Z,src/cpp/common/channel_filter.h,"@@ -386,7 +388,7 @@ void RegisterChannelFilter(        FilterType::SetPollsetOrPollsetSet, FilterType::DestroyCallElement,        FilterType::channel_data_size, FilterType::InitChannelElement,        FilterType::DestroyChannelElement, FilterType::GetPeer,-       FilterType::GetChannelInfo, name}};+       FilterType::GetChannelInfo, name, INT_MAX}};","Instead of hard-coding this, let's add a new parameter to `RegisterChannelFilter()`.  Otherwise, there's no way for someone internally to define a C++ filter that overrides one of the OSS filters.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/12104,131987542,2017-08-08T18:01:21Z,src/core/lib/channel/channel_stack.h,"@@ -159,6 +159,11 @@ typedef struct {    /* The name of this filter */   const char *name;++  /* For filter with the same \a name, determines which one is kept in the+   * channel stack. Stringly lesser values take precedence (UNIX priority","I have no idea where that word came from. It's the result of a race condition in my brain. It should be **Strictly**, but I think my muscle memory is more used to writing ""string"" when a word begins with ""stri"".",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/11566,132032598,2017-08-08T21:07:49Z,src/core/ext/filters/http/message_compress/message_compress_filter.c,"@@ -237,196 +255,171 @@ static grpc_error *pull_slice_from_send_message(grpc_exec_ctx *exec_ctx, // If all data has been read, invokes finish_send_message().  Otherwise, // an async call to grpc_byte_stream_next() has been started, which will // eventually result in calling on_send_message_next_done().-static grpc_error *continue_reading_send_message(grpc_exec_ctx *exec_ctx,-                                                 grpc_call_element *elem) {+static void continue_reading_send_message(grpc_exec_ctx *exec_ctx,+                                          grpc_call_element *elem) {   call_data *calld = (call_data *)elem->call_data;   while (grpc_byte_stream_next(       exec_ctx, calld->send_message_batch->payload->send_message.send_message,       ~(size_t)0, &calld->on_send_message_next_done)) {     grpc_error *error = pull_slice_from_send_message(exec_ctx, calld);-    if (error != GRPC_ERROR_NONE) return error;+    if (error != GRPC_ERROR_NONE) {+      // Closure callback; does not take ownership of error.+      fail_send_message_batch_in_call_combiner(exec_ctx, calld, error);+      GRPC_ERROR_UNREF(error);+      return;+    }     if (calld->slices.length ==         calld->send_message_batch->payload->send_message.send_message->length) {       finish_send_message(exec_ctx, elem);       break;     }   }-  return GRPC_ERROR_NONE; }  // Async callback for grpc_byte_stream_next(). static void on_send_message_next_done(grpc_exec_ctx *exec_ctx, void *arg,                                       grpc_error *error) {   grpc_call_element *elem = (grpc_call_element *)arg;   call_data *calld = (call_data *)elem->call_data;-  if (error != GRPC_ERROR_NONE) goto fail;+  if (error != GRPC_ERROR_NONE) {+    // Closure callback; does not take ownership of error.+    fail_send_message_batch_in_call_combiner(exec_ctx, calld, error);+    return;+  }   error = pull_slice_from_send_message(exec_ctx, calld);-  if (error != GRPC_ERROR_NONE) goto fail;+  if (error != GRPC_ERROR_NONE) {+    // Closure callback; does not take ownership of error.+    fail_send_message_batch_in_call_combiner(exec_ctx, calld, error);+    GRPC_ERROR_UNREF(error);","We shouldn't be unreffing inside a callback (last paragraph of [Rule 2](https://github.com/grpc/grpc/blob/a461f0d46ccf03bc8e107a7038296e237089d179/doc/core/grpc-error.md#rule-2)), we don't own `error`.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/11566,132035811,2017-08-08T21:21:09Z,src/core/lib/channel/connected_channel.c,"@@ -36,7 +36,52 @@ typedef struct connected_channel_channel_data {   grpc_transport *transport; } channel_data; -typedef struct connected_channel_call_data { void *unused; } call_data;+typedef struct {+  grpc_closure closure;+  grpc_closure *original_closure;+  grpc_call_combiner *call_combiner;+  const char *reason;+  bool free_when_done;+} callback_state;++typedef struct connected_channel_call_data {+  grpc_call_combiner *call_combiner;+  // Closures used for returning results on the call combiner.+  callback_state on_complete[6];  // Max number of pending batches.+  callback_state recv_initial_metadata_ready;+  callback_state recv_message_ready;+} call_data;++static void run_in_call_combiner(grpc_exec_ctx *exec_ctx, void *arg,+                                 grpc_error *error) {+  callback_state *state = (callback_state *)arg;+  GRPC_CALL_COMBINER_START(exec_ctx, state->call_combiner,+                           state->original_closure, GRPC_ERROR_REF(error),+                           state->reason);+  if (state->free_when_done) gpr_free(state);+}++static void intercept_callback(call_data *calld, callback_state *state,+                               bool free_when_done, const char *reason,+                               grpc_closure **original_closure) {+  state->original_closure = *original_closure;+  state->call_combiner = calld->call_combiner;+  state->reason = reason;+  state->free_when_done = free_when_done;+  *original_closure = GRPC_CLOSURE_INIT(&state->closure, run_in_call_combiner,+                                        state, grpc_schedule_on_exec_ctx);+}++static callback_state *get_state_for_batch(+    call_data *calld, grpc_transport_stream_op_batch *batch) {+  if (batch->send_initial_metadata) return &calld->on_complete[0];","using numerical indices here seems fragile. I suggest having an enum along the lines of```enum batch_op_callback_index {  CB_IDX_SEND_INITIAL_METADATA = 0,  CB_IDX_SEND_MESSAGE = 1,...}```This makes the code more readable, having `if (batch->send_initial_metadata) return &calld->on_complete[CB_IDX_SEND_INITIAL_METADATA];` instead, which also makes it easier to visually validate that the index used matches what the `if` is filtering for.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12100,132085898,2017-08-09T03:57:28Z,src/ruby/lib/grpc/generic/rpc_desc.rb,"@@ -72,18 +72,20 @@ def handle_bidi_streamer(active_call, mth)       send_status(active_call, OK, 'OK', active_call.output_metadata)     end -    def run_server_method(active_call, mth)-      # While a server method is running, it might be cancelled, its deadline-      # might be reached, the handler could throw an unknown error, or a-      # well-behaved handler could throw a StatusError.-      if request_response?-        handle_request_response(active_call, mth)-      elsif client_streamer?-        handle_client_streamer(active_call, mth)-      elsif server_streamer?-        handle_server_streamer(active_call, mth)-      else  # is a bidi_stream-        handle_bidi_streamer(active_call, mth)+    def run_server_method(active_call, mth, interceptors = [])+      intercept(interceptors, active_call, mth) do","I'm not sure about this, but I'm wondering if it would make sense to treat interceptors as simple decorators around the the server-side handlers, and pass them the same parameters that normal server-call-handlers get (e.g. interceptors for `client streaming` and `bidi` RPCs receive the request `Enumerable` stream, and interceptors for `server streaming` and `unary` RPCs receive the single request message - all along with the same ""view"" of the active call that the handlers get.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12100,132086150,2017-08-09T04:00:27Z,src/ruby/lib/grpc/generic/rpc_desc.rb,"@@ -72,18 +72,20 @@ def handle_bidi_streamer(active_call, mth)       send_status(active_call, OK, 'OK', active_call.output_metadata)     end -    def run_server_method(active_call, mth)-      # While a server method is running, it might be cancelled, its deadline-      # might be reached, the handler could throw an unknown error, or a-      # well-behaved handler could throw a StatusError.-      if request_response?-        handle_request_response(active_call, mth)-      elsif client_streamer?-        handle_client_streamer(active_call, mth)-      elsif server_streamer?-        handle_server_streamer(active_call, mth)-      else  # is a bidi_stream-        handle_bidi_streamer(active_call, mth)+    def run_server_method(active_call, mth, interceptors = [])+      intercept(interceptors, active_call, mth) do",I agree that the interceptor should be here - especially for the exception handlers for cleanup/finishing of calls,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12120,132113127,2017-08-09T07:53:14Z,src/csharp/Grpc.Core/RpcException.cs,"@@ -44,6 +47,18 @@ public RpcException(Status status) : base(status.ToString())         public RpcException(Status status, string message) : base(message)         {             this.status = status;+            this.trailers = Metadata.Empty;+        }++        /// <summary>+        /// Creates a new <c>RpcException</c> associated with given status and trailing response metadata.+        /// </summary>+        /// <param name=""status"">Resulting status of a call.</param>+        /// <param name=""trailers"">Response trailing metadata.</param> +        public RpcException(Status status, Metadata trailers) : base(status.ToString())","One thing that might keep the server-side simpler:What if the `public RpcException(Status status, Metadata trailers)` constructor for `RpcException` was kept private, and only used within grpc library on client-side calls?Then for server-side calls, the existing way of setting trailers could remain the only way.- might lose consistency, but I think server-side changes here might not be needed",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12120,132120017,2017-08-09T08:28:24Z,src/csharp/Grpc.Core/Internal/ServerCallHandler.cs,"@@ -292,11 +292,20 @@ public Task HandleCall(ServerRpcNew newRpc, CompletionQueueSafeHandle cq)      internal static class HandlerUtils     {-        public static Status StatusFromException(Exception e)+        public static Status StatusFromException(Exception e, Metadata callContextResponseTrailers)         {             var rpcException = e as RpcException;             if (rpcException != null)             {+                // There are two sources of metadata entries on the server-side:+                // 1. serverCallContext.ResponseTrailers+                // 2. trailers in RpcException thrown by user code in server side handler.+                // As metadata allows duplicate keys, the logical thing to do is+                // to just merge trailers from RpcException into serverCallContext.ResponseTrailers.+                foreach (var entry in rpcException.Trailers)",I think that would just lead to duplication of the casting logic? I don't see much value in that.,
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/12024,132287663,2017-08-09T19:49:12Z,test/core/tsi/transport_security_test_lib.h,"@@ -0,0 +1,152 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_TEST_CORE_TSI_TRANSPORT_SECURITY_TEST_LIB_H_+#define GRPC_TEST_CORE_TSI_TRANSPORT_SECURITY_TEST_LIB_H_++#include ""src/core/tsi/transport_security_interface.h""++#define TSI_TEST_TINY_HANDSHAKE_BUFFER_SIZE 64+#define TSI_TEST_SMALL_HANDSHAKE_BUFFER_SIZE 128+#define TSI_TEST_SMALL_READ_BUFFER_ALLOCATED_SIZE 41+#define TSI_TEST_SMALL_PROTECTED_BUFFER_SIZE 37+#define TSI_TEST_SMALL_MESSAGE_BUFFER_ALLOCATED_SIZE 42+#define TSI_TEST_SMALL_CLIENT_MAX_OUTPUT_PROTECTED_FRAME_SIZE 39+#define TSI_TEST_SMALL_SERVER_MAX_OUTPUT_PROTECTED_FRAME_SIZE 43+#define TSI_TEST_DEFAULT_BUFFER_SIZE 4096+#define TSI_TEST_DEFAULT_PROTECTED_BUFFER_SIZE 16384+#define TSI_TEST_DEFAULT_CHANNEL_SIZE 32768+#define TSI_TEST_BIG_MESSAGE_SIZE 17000+#define TSI_TEST_SMALL_MESSAGE_SIZE 10+#define TSI_TEST_NUM_OF_ARGUMENTS 8+#define TSI_TEST_NUM_OF_COMBINATIONS 256++/* ---  tsi_test_fixture object ---++  This object wraps all information that will be used to test correctness of TSI+  handshakes and frame protect/unprotect operations with respect to TSI+  implementations. The tests for specific TSI implementations should create+  their+  own custom ""subclass"" of this fixture. */+typedef struct tsi_test_fixture tsi_test_fixture;++/* ---  tsi_test_frame_protector_config object ---++  This object is used to configure different parameters of TSI frame protector+  APIs. */+typedef struct tsi_test_frame_protector_config tsi_test_frame_protector_config;++/* V-table for tsi_test_fixture operations that are implemented differently in+   different TSI implementations. */+typedef struct tsi_test_fixture_vtable {+  void (*setup_handshakers)(tsi_test_fixture *fixture);+  void (*check_handshake_results)(tsi_test_fixture *fixture);+  void (*destruct)(tsi_test_fixture *fixture);+} tranport_security_test_vtable;++struct tsi_test_fixture {+  const struct tsi_test_fixture_vtable *vtable;+  /* client/server TSI handshaker used to perform TSI handshakes, and will get+     instantiated during the call to setup_handshakers. */+  tsi_handshaker *client_handshaker;+  tsi_handshaker *server_handshaker;+  /* client/server TSI handshaker results used to store the result of TSI+     handshake, and will get validated during the call to+     check_handshake_results. If the handshake fails, the result will store NULL+     upon finishing the handshake. */+  tsi_handshaker_result *client_result;+  tsi_handshaker_result *server_result;+  /* size of buffer used to store data received from the peer. */+  size_t handshake_buffer_size;+  /* simulated channels between client and server. If the server (client)+     wants to send data to the client (server), he will write data to+     client_channel (server_channel), which will be read by client (server). */+  uint8_t *client_channel;+  uint8_t *server_channel;+  /* size of data written to the client/server channel. */+  size_t bytes_written_to_client_channel;+  size_t bytes_written_to_server_channel;+  /* size of data read from the client/server channel */+  size_t bytes_read_from_client_channel;+  size_t bytes_read_from_server_channel;+  /* tsi_test_frame_protector_config instance */+  tsi_test_frame_protector_config *config;+};++struct tsi_test_frame_protector_config {+  /* size of buffer used to store protected frames to be unprotected. */+  size_t read_buffer_allocated_size;+  /* size of buffer used to store bytes resulted from unprotect operations. */+  size_t message_buffer_allocated_size;+  /* size of buffer used to store frames resulted from protect operations. */+  size_t protected_buffer_size;+  /* size of client/server maximum frame size. */+  size_t client_max_output_protected_frame_size;+  size_t server_max_output_protected_frame_size;+  /* pointer that points to client/server message to be protected. */+  uint8_t *client_message;+  uint8_t *server_message;+  /* size of client/server message. */+  size_t client_message_size;+  size_t server_message_size;+};++/* This method creates a tsi_test_frame_protector_config instance. Each+   parameter of this function is a boolean value indicating whether to set the+   corresponding parameter with a default value or not. If it's false, it will+   be set with a specific value which is usually much smaller than the default.+   Both values are defined with #define directive. */+tsi_test_frame_protector_config *tsi_test_frame_protector_config_create(+    bool use_default_read_buffer_allocated_size,+    bool use_default_message_buffer_allocated_size,+    bool use_default_protected_buffer_size, bool use_default_client_message,+    bool use_default_server_message,+    bool use_default_client_max_output_protected_frame_size,+    bool use_default_server_max_output_protected_frame_size,+    bool use_default_handshake_buffer_size);++/* This method sets different buffer and frame sizes of a+   tsi_test_frame_protector_config instance with user provided values. */+void tsi_test_frame_protector_config_set_buffer_size(+    tsi_test_frame_protector_config *config, size_t read_buffer_allocated_size,+    size_t message_buffer_allocated_size, size_t protected_buffer_size,+    size_t client_max_output_protected_frame_size,+    size_t server_max_output_protected_frame_size);++/* This method destroys a tsi_test_frame_protector_config instance. */+void tsi_test_frame_protector_config_destroy(+    tsi_test_frame_protector_config *config);++/* This method initializes members of tsi_test_fixture instance. */+void tsi_test_fixture_init(tsi_test_fixture *fixture);++/* This method destroys a tsi_test_fixture instance. Notice that the+   fixture intance must be dynamically allocated and will be freed by+   this functoin. */+void tsi_test_fixture_destroy(tsi_test_fixture *fixture);++/* This method performs a full TSI handshake between a client and a server. */",Add a comment that this test library only tests handshake using new TSI handshaker API.,
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/12024,132299420,2017-08-09T20:36:09Z,test/core/tsi/transport_security_test_lib.c,"@@ -0,0 +1,513 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <stdio.h>+#include <stdlib.h>+#include <string.h>++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include ""src/core/lib/security/transport/tsi_error.h""+#include ""test/core/tsi/transport_security_test_lib.h""++typedef struct handshaker_args {+  tsi_test_fixture *fixture;+  unsigned char *handshake_buffer;+  size_t handshake_buffer_size;+  bool is_client;+  bool transferred_data;+  grpc_error *error;+} handshaker_args;++static handshaker_args *handshaker_args_create(tsi_test_fixture *fixture,+                                               bool is_client) {+  GPR_ASSERT(fixture != NULL);+  GPR_ASSERT(fixture->config != NULL);+  handshaker_args *args = gpr_zalloc(sizeof(*args));+  args->fixture = fixture;+  args->handshake_buffer_size = fixture->handshake_buffer_size;+  args->handshake_buffer = gpr_zalloc(args->handshake_buffer_size);+  args->is_client = is_client;+  args->error = GRPC_ERROR_NONE;+  return args;+}++static void handshaker_args_destroy(handshaker_args *args) {+  gpr_free(args->handshake_buffer);+  GRPC_ERROR_UNREF(args->error);+  gpr_free(args);+}++static void do_handshaker_next_locked(handshaker_args *args);++static void setup_handshakers(tsi_test_fixture *fixture) {+  GPR_ASSERT(fixture != NULL);+  GPR_ASSERT(fixture->vtable != NULL);+  GPR_ASSERT(fixture->vtable->setup_handshakers != NULL);+  fixture->vtable->setup_handshakers(fixture);+}++static void check_handshake_results(tsi_test_fixture *fixture) {+  GPR_ASSERT(fixture != NULL);+  GPR_ASSERT(fixture->vtable != NULL);+  GPR_ASSERT(fixture->vtable->check_handshake_results != NULL);+  fixture->vtable->check_handshake_results(fixture);","tsi_handshaker_result_get_unused_bytes() is not tested in this PR. I think we can test in the following way: When client/server finds handshake finishes and needs to send the final message back to peer, we cam concatenate a pre-defined string to the message. Later, when we verify the handshake result, we can call get_unused_bytes and compare with the predefined string.",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/12024,132300548,2017-08-09T20:40:46Z,test/core/tsi/transport_security_test_lib.h,"@@ -0,0 +1,152 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_TEST_CORE_TSI_TRANSPORT_SECURITY_TEST_LIB_H_+#define GRPC_TEST_CORE_TSI_TRANSPORT_SECURITY_TEST_LIB_H_++#include ""src/core/tsi/transport_security_interface.h""++#define TSI_TEST_TINY_HANDSHAKE_BUFFER_SIZE 64+#define TSI_TEST_SMALL_HANDSHAKE_BUFFER_SIZE 128+#define TSI_TEST_SMALL_READ_BUFFER_ALLOCATED_SIZE 41+#define TSI_TEST_SMALL_PROTECTED_BUFFER_SIZE 37+#define TSI_TEST_SMALL_MESSAGE_BUFFER_ALLOCATED_SIZE 42+#define TSI_TEST_SMALL_CLIENT_MAX_OUTPUT_PROTECTED_FRAME_SIZE 39+#define TSI_TEST_SMALL_SERVER_MAX_OUTPUT_PROTECTED_FRAME_SIZE 43+#define TSI_TEST_DEFAULT_BUFFER_SIZE 4096+#define TSI_TEST_DEFAULT_PROTECTED_BUFFER_SIZE 16384+#define TSI_TEST_DEFAULT_CHANNEL_SIZE 32768+#define TSI_TEST_BIG_MESSAGE_SIZE 17000+#define TSI_TEST_SMALL_MESSAGE_SIZE 10+#define TSI_TEST_NUM_OF_ARGUMENTS 8+#define TSI_TEST_NUM_OF_COMBINATIONS 256++/* ---  tsi_test_fixture object ---++  This object wraps all information that will be used to test correctness of TSI+  handshakes and frame protect/unprotect operations with respect to TSI+  implementations. The tests for specific TSI implementations should create+  their+  own custom ""subclass"" of this fixture. */+typedef struct tsi_test_fixture tsi_test_fixture;++/* ---  tsi_test_frame_protector_config object ---++  This object is used to configure different parameters of TSI frame protector+  APIs. */+typedef struct tsi_test_frame_protector_config tsi_test_frame_protector_config;++/* V-table for tsi_test_fixture operations that are implemented differently in+   different TSI implementations. */+typedef struct tsi_test_fixture_vtable {+  void (*setup_handshakers)(tsi_test_fixture *fixture);+  void (*check_handshake_results)(tsi_test_fixture *fixture);","Maybe call check_handshaker_peers? There are 3 functions from handshaker_result: extract_peer, create_frame_protector, get_unused_bytes. frame protector is tested separately. You actually only test extract_peer.",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/12024,132300841,2017-08-09T20:41:53Z,test/core/tsi/transport_security_test_lib.c,"@@ -0,0 +1,513 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <stdio.h>+#include <stdlib.h>+#include <string.h>++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include ""src/core/lib/security/transport/tsi_error.h""+#include ""test/core/tsi/transport_security_test_lib.h""++typedef struct handshaker_args {+  tsi_test_fixture *fixture;+  unsigned char *handshake_buffer;+  size_t handshake_buffer_size;+  bool is_client;+  bool transferred_data;+  grpc_error *error;+} handshaker_args;++static handshaker_args *handshaker_args_create(tsi_test_fixture *fixture,+                                               bool is_client) {+  GPR_ASSERT(fixture != NULL);+  GPR_ASSERT(fixture->config != NULL);+  handshaker_args *args = gpr_zalloc(sizeof(*args));+  args->fixture = fixture;+  args->handshake_buffer_size = fixture->handshake_buffer_size;+  args->handshake_buffer = gpr_zalloc(args->handshake_buffer_size);+  args->is_client = is_client;+  args->error = GRPC_ERROR_NONE;+  return args;+}++static void handshaker_args_destroy(handshaker_args *args) {+  gpr_free(args->handshake_buffer);+  GRPC_ERROR_UNREF(args->error);+  gpr_free(args);+}++static void do_handshaker_next_locked(handshaker_args *args);++static void setup_handshakers(tsi_test_fixture *fixture) {+  GPR_ASSERT(fixture != NULL);+  GPR_ASSERT(fixture->vtable != NULL);+  GPR_ASSERT(fixture->vtable->setup_handshakers != NULL);+  fixture->vtable->setup_handshakers(fixture);+}++static void check_handshake_results(tsi_test_fixture *fixture) {",You can still name check_handshake_results here. You do two things here1. check_unused_bytes (this is common for all tsi implementation)2. check_handshaker_peers (you can call vtable for each tsi implementation).,
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/12024,132310527,2017-08-09T21:22:50Z,test/core/tsi/transport_security_test_lib.c,"@@ -0,0 +1,513 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <stdio.h>+#include <stdlib.h>+#include <string.h>++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include ""src/core/lib/security/transport/tsi_error.h""+#include ""test/core/tsi/transport_security_test_lib.h""++typedef struct handshaker_args {+  tsi_test_fixture *fixture;+  unsigned char *handshake_buffer;+  size_t handshake_buffer_size;+  bool is_client;+  bool transferred_data;+  grpc_error *error;+} handshaker_args;++static handshaker_args *handshaker_args_create(tsi_test_fixture *fixture,+                                               bool is_client) {+  GPR_ASSERT(fixture != NULL);+  GPR_ASSERT(fixture->config != NULL);+  handshaker_args *args = gpr_zalloc(sizeof(*args));+  args->fixture = fixture;+  args->handshake_buffer_size = fixture->handshake_buffer_size;+  args->handshake_buffer = gpr_zalloc(args->handshake_buffer_size);+  args->is_client = is_client;+  args->error = GRPC_ERROR_NONE;+  return args;+}++static void handshaker_args_destroy(handshaker_args *args) {+  gpr_free(args->handshake_buffer);+  GRPC_ERROR_UNREF(args->error);+  gpr_free(args);+}++static void do_handshaker_next_locked(handshaker_args *args);++static void setup_handshakers(tsi_test_fixture *fixture) {+  GPR_ASSERT(fixture != NULL);+  GPR_ASSERT(fixture->vtable != NULL);+  GPR_ASSERT(fixture->vtable->setup_handshakers != NULL);+  fixture->vtable->setup_handshakers(fixture);+}++static void check_handshake_results(tsi_test_fixture *fixture) {+  GPR_ASSERT(fixture != NULL);+  GPR_ASSERT(fixture->vtable != NULL);+  GPR_ASSERT(fixture->vtable->check_handshake_results != NULL);+  fixture->vtable->check_handshake_results(fixture);+}++static void send_bytes_to_peer(tsi_test_fixture *fixture,+                               const unsigned char *buf, size_t buf_size,+                               bool is_client) {+  GPR_ASSERT(fixture != NULL);+  GPR_ASSERT(buf != NULL);+  uint8_t *channel =+      is_client ? fixture->server_channel : fixture->client_channel;+  GPR_ASSERT(channel != NULL);+  size_t *bytes_written = is_client ? &fixture->bytes_written_to_server_channel+                                    : &fixture->bytes_written_to_client_channel;+  GPR_ASSERT(bytes_written != NULL);+  GPR_ASSERT(*bytes_written + buf_size <= TSI_TEST_DEFAULT_CHANNEL_SIZE);+  /* Write data to channel. */+  memcpy(channel + *bytes_written, buf, buf_size);+  *bytes_written += buf_size;+}++static void receive_bytes_from_peer(tsi_test_fixture *fixture,+                                    unsigned char **buf, size_t *buf_size,+                                    bool is_client) {+  GPR_ASSERT(fixture != NULL);+  GPR_ASSERT(*buf != NULL);+  GPR_ASSERT(buf_size != NULL);+  uint8_t *channel =+      is_client ? fixture->client_channel : fixture->server_channel;+  GPR_ASSERT(channel != NULL);+  size_t *bytes_read = is_client ? &fixture->bytes_read_from_client_channel+                                 : &fixture->bytes_read_from_server_channel;+  size_t *bytes_written = is_client ? &fixture->bytes_written_to_client_channel+                                    : &fixture->bytes_written_to_server_channel;+  GPR_ASSERT(bytes_read != NULL);+  GPR_ASSERT(bytes_written != NULL);+  size_t to_read = *buf_size < *bytes_written - *bytes_read+                       ? *buf_size+                       : *bytes_written - *bytes_read;+  /* Read data from channel. */+  memcpy(*buf, channel + *bytes_read, to_read);+  *buf_size = to_read;+  *bytes_read += to_read;+}++static void send_message_to_peer(tsi_test_fixture *fixture,+                                 tsi_frame_protector *protector,+                                 bool is_client) {+  /* Initialization. */+  GPR_ASSERT(fixture != NULL);+  GPR_ASSERT(fixture->config != NULL);+  GPR_ASSERT(protector != NULL);+  tsi_test_frame_protector_config *config = fixture->config;+  unsigned char *protected_buffer = gpr_zalloc(config->protected_buffer_size);+  size_t message_size =+      is_client ? config->client_message_size : config->server_message_size;+  uint8_t *message =+      is_client ? config->client_message : config->server_message;+  GPR_ASSERT(message != NULL);+  const unsigned char *message_bytes = (const unsigned char *)message;+  tsi_result result = TSI_OK;++  /* Do protect and send protected data to peer. */+  while (message_size > 0 && result == TSI_OK) {+    size_t protected_buffer_size_to_send = config->protected_buffer_size;+    size_t processed_message_size = message_size;+    /* Do protect. */+    result = tsi_frame_protector_protect(+        protector, message_bytes, &processed_message_size, protected_buffer,+        &protected_buffer_size_to_send);+    GPR_ASSERT(result == TSI_OK);+    /* Send protected data to peer. */+    send_bytes_to_peer(fixture, protected_buffer, protected_buffer_size_to_send,+                       is_client);+    message_bytes += processed_message_size;+    message_size -= processed_message_size;+    /* Flush if we're done. */+    if (message_size == 0) {+      size_t still_pending_size;+      do {+        protected_buffer_size_to_send = config->protected_buffer_size;+        result = tsi_frame_protector_protect_flush(+            protector, protected_buffer, &protected_buffer_size_to_send,+            &still_pending_size);+        GPR_ASSERT(result == TSI_OK);+        send_bytes_to_peer(fixture, protected_buffer,+                           protected_buffer_size_to_send, is_client);+      } while (still_pending_size > 0 && result == TSI_OK);+      GPR_ASSERT(result == TSI_OK);+    }+  }+  GPR_ASSERT(result == TSI_OK);+  gpr_free(protected_buffer);+}++static void receive_message_from_peer(tsi_test_fixture *fixture,+                                      tsi_frame_protector *protector,+                                      unsigned char *message,+                                      size_t *bytes_received, bool is_client) {+  /* Initialization. */+  GPR_ASSERT(fixture != NULL);+  GPR_ASSERT(protector != NULL);+  GPR_ASSERT(message != NULL);+  GPR_ASSERT(bytes_received != NULL);+  GPR_ASSERT(fixture->config != NULL);+  tsi_test_frame_protector_config *config = fixture->config;+  size_t read_offset = 0;+  size_t message_offset = 0;+  size_t read_from_peer_size = 0;+  tsi_result result = TSI_OK;+  bool done = false;+  unsigned char *read_buffer = gpr_zalloc(config->read_buffer_allocated_size);+  unsigned char *message_buffer =+      gpr_zalloc(config->message_buffer_allocated_size);++  /* Do unprotect on data received from peer. */+  while (!done && result == TSI_OK) {+    /* Receive data from peer. */+    if (read_from_peer_size == 0) {+      read_from_peer_size = config->read_buffer_allocated_size;+      receive_bytes_from_peer(fixture, &read_buffer, &read_from_peer_size,+                              is_client);+      read_offset = 0;+    }+    if (read_from_peer_size == 0) {+      done = true;+    }+    /* Do unprotect. */+    size_t message_buffer_size;+    do {+      message_buffer_size = config->message_buffer_allocated_size;+      size_t processed_size = read_from_peer_size;+      result = tsi_frame_protector_unprotect(+          protector, read_buffer + read_offset, &processed_size, message_buffer,+          &message_buffer_size);+      GPR_ASSERT(result == TSI_OK);+      if (message_buffer_size > 0) {+        memcpy(message + message_offset, message_buffer, message_buffer_size);+        message_offset += message_buffer_size;+      }+      read_offset += processed_size;+      read_from_peer_size -= processed_size;+    } while ((read_from_peer_size > 0 || message_buffer_size > 0) &&+             result == TSI_OK);+    GPR_ASSERT(result == TSI_OK);+  }+  GPR_ASSERT(result == TSI_OK);+  *bytes_received = message_offset;+  gpr_free(read_buffer);+  gpr_free(message_buffer);+}++grpc_error *on_handshake_next_done_locked(",rename to on_handshake_next_done()There is no lock in this test library.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12137,132473497,2017-08-10T14:43:20Z,src/core/lib/surface/call.c,"@@ -1384,12 +1383,28 @@ static void receiving_initial_metadata_ready(grpc_exec_ctx *exec_ctx,     }   } -  call->has_initial_md_been_received = true;-  if (call->saved_receiving_stream_ready_bctlp != NULL) {-    grpc_closure *saved_rsr_closure = GRPC_CLOSURE_CREATE(-        receiving_stream_ready, call->saved_receiving_stream_ready_bctlp,-        grpc_schedule_on_exec_ctx);-    call->saved_receiving_stream_ready_bctlp = NULL;+  grpc_closure *saved_rsr_closure = NULL;+  while (true) {","Would this code be simpler if we kept `saved_receiving_stream_ready_bctlp` as a separate non-atomic pointer, and used the atomic value only for an enum indicating the state?  I'm thinking of an enum like this:```typedef enum {  RECV_NONE,  RECV_INITIAL_METADATA_FIRST,  RECV_MESSAGE_FIRST,} recv_state;```Then the fields of `grpc_call` are:```gpr_atm recv_state;  // a recv_state enumvoid *saved_receiving_stream_ready_bctlp;```Then the code in `receiving_stream_ready()` becomes:```call->saved_receiving_stream_ready_bctlp = bctlp;if (error != GRPC_ERROR_NONE || call->receiving_stream == NULL ||    !gpr_atm_full_cas(&call->recv_state, RECV_NONE, RECV_MESSAGE_FIRST)) {  call->saved_receiving_stream_ready_bctlp = NULL;  process_data_after_md(exec_ctx, bctlp);}```And the code here becomes:```if (!gpr_atm_full_cas(&call->recv_state, RECV_NONE, RECV_INITIAL_METADATA_FIRST)) {  grpc_closure *saved_rsr_closure = GRPC_CLOSURE_CREATE(      receiving_stream_ready, call->saved_receiving_stream_ready_bctlp,      grpc_schedule_on_exec_ctx);  call->saved_receiving_stream_ready_bctlp = NULL;  GRPC_CLOSURE_RUN(exec_ctx, saved_rsr_closure, GRPC_ERROR_REF(error));}```What do you think?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12137,132474479,2017-08-10T14:46:19Z,src/core/lib/surface/call.c,"@@ -1290,11 +1290,10 @@ static void receiving_stream_ready(grpc_exec_ctx *exec_ctx, void *bctlp,     cancel_with_error(exec_ctx, call, STATUS_FROM_SURFACE,                       GRPC_ERROR_REF(error));   }-  if (call->has_initial_md_been_received || error != GRPC_ERROR_NONE ||-      call->receiving_stream == NULL) {+  if (error != GRPC_ERROR_NONE || call->receiving_stream == NULL ||+      !gpr_atm_rel_cas(&call->saved_receiving_stream_ready_bctlp, 0,+                       (gpr_atm)bctlp)) {     process_data_after_md(exec_ctx, bctlp);","It looks like there may an unrelated bug here, which is that if the recv_initial_metadata and recv_message ops were in different batches, we will use the wrong batch_control structure in this call.  I think that just as we save the recv_message batch_control struct to be used in recv_initial_metadata_ready, we also need to save the recv_initial_metadata batch_control struct to be used in recv_message_ready.",
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/10919,132524793,2017-08-10T17:58:31Z,doc/threading_model.md,"@@ -0,0 +1,31 @@+﻿# gRPC Threading Model++## Introduction+This document serves as a basic intro for the gRPC threading model. gRPC generates service code in two fashions - synchronous and asynchronous API. These two closely correlate to the threading model in play. ++## Synchronous API Threading model+This is the easiest model to start with and could be a satisfactory model for a large number of services. As such, the implementation is efficient (and is not a ‘toy’ implementation). In this model, gRPC takes care of the threading completely and the application code need to worry only about handling of the actual rpc call.+* When the server starts up, a thread pool is created to handle incoming rpc requests. The default implementation of this thread pool is called DynamicThreadPool. It creates threads equal to number of processors in the system and all of them are in waiting state.+* DynamicThreadPool has in­built scaling mechanism to create additional threads on demand. For integrators interested in having a little more control on the behavior of the thread pool, they can define GRPC_CUSTOM_DEFAULT_THREAD_POOL and provide the implementation of the thread pool interface (which is literally just 1 function that adds work to the pool).","The handling of streaming RPCs is similar to that of Unary RPCs... i.e we ensure a certain number of threads (between min_pollers_ and max_pollers_) are polling for new incoming RPCs and in case of streaming RPCs, a thread is dedicated until the streaming RPC finishes.  Yes, this does have the same issue that you mentioned with DynamicThreadPool (but should be mitigated once https://github.com/grpc/grpc/issues/12147 is fixed)",
20803483,fengli79,https://api.github.com/repos/grpc/grpc/pulls/11878,132536358,2017-08-10T18:45:09Z,src/php/ext/grpc/channel.c,"@@ -146,14 +232,82 @@ PHP_METHOD(Channel, __construct) {       php_grpc_zend_hash_del(array_hash, ""credentials"", sizeof(""credentials""));     }   }-  php_grpc_read_args_array(args_array, &args TSRMLS_CC);-  if (creds == NULL) {-    channel->wrapped = grpc_insecure_channel_create(target, &args, NULL);+  if (php_grpc_zend_hash_find(array_hash, ""force_new"", sizeof(""force_new""),+                              (void **)&force_new_obj) == SUCCESS) {+    if (PHP_GRPC_BVAL_IS_TRUE(force_new_obj)) {+      force_new = true;+    }+    php_grpc_zend_hash_del(array_hash, ""force_new"", sizeof(""force_new""));+  }++  // parse the rest of the channel args array+  if (php_grpc_read_args_array(args_array, &args TSRMLS_CC) == FAILURE) {+    return;+  }++  // Construct a hashkey for the persistent channel+  // Currently, the hashkey contains 3 parts:+  // 1. hostname+  // 2. hash value of the channel args array (excluding ""credentials""+  //    and ""force_new"")+  // 3. (optional) hash value of the ChannelCredentials object+  php_serialize_data_t var_hash;+  smart_str buf = {0};+  PHP_VAR_SERIALIZE_INIT(var_hash);+  PHP_GRPC_VAR_SERIALIZE(&buf, args_array, &var_hash);+  PHP_VAR_SERIALIZE_DESTROY(var_hash);++  char sha1str[41];+  generate_sha1_str(sha1str, PHP_GRPC_SERIALIZED_BUF_STR(buf),+                    PHP_GRPC_SERIALIZED_BUF_LEN(buf));++  php_grpc_int key_len = target_length + strlen(sha1str);+  if (creds != NULL && creds->hashstr != NULL) {+    key_len += strlen(creds->hashstr);+  }+  char *key = malloc(key_len + 1);+  strcpy(key, target);+  strcat(key, sha1str);+  if (creds != NULL && creds->hashstr != NULL) {+    strcat(key, creds->hashstr);+  }+  channel->wrapper = malloc(sizeof(grpc_channel_wrapper));+  channel->wrapper->key = key;+  channel->wrapper->target = target;+  channel->wrapper->args_hashstr = sha1str;+  if (creds != NULL && creds->hashstr != NULL) {+    channel->wrapper->creds_hashstr = creds->hashstr;+  }+  gpr_mu_init(&channel->wrapper->mu);+  smart_str_free(&buf);++  if (force_new) {","If an existed channel get removed from the shared list, then further call will get a new channel unexpectedly.Consider this sequence:1. create shared channel A.2. grap channel A for request 13. grap channel A for request 24. request 3 want to get a non-persistent channel and it eject channel A from the pool.5. request 4 want to get a persistent channel and it has to recreate channel A as it has been ejected from the pool, this is unexpected.",
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/11878,132542263,2017-08-10T19:11:04Z,src/php/ext/grpc/channel.c,"@@ -146,14 +232,82 @@ PHP_METHOD(Channel, __construct) {       php_grpc_zend_hash_del(array_hash, ""credentials"", sizeof(""credentials""));     }   }-  php_grpc_read_args_array(args_array, &args TSRMLS_CC);-  if (creds == NULL) {-    channel->wrapped = grpc_insecure_channel_create(target, &args, NULL);+  if (php_grpc_zend_hash_find(array_hash, ""force_new"", sizeof(""force_new""),+                              (void **)&force_new_obj) == SUCCESS) {+    if (PHP_GRPC_BVAL_IS_TRUE(force_new_obj)) {+      force_new = true;+    }+    php_grpc_zend_hash_del(array_hash, ""force_new"", sizeof(""force_new""));+  }++  // parse the rest of the channel args array+  if (php_grpc_read_args_array(args_array, &args TSRMLS_CC) == FAILURE) {+    return;+  }++  // Construct a hashkey for the persistent channel+  // Currently, the hashkey contains 3 parts:+  // 1. hostname+  // 2. hash value of the channel args array (excluding ""credentials""+  //    and ""force_new"")+  // 3. (optional) hash value of the ChannelCredentials object+  php_serialize_data_t var_hash;+  smart_str buf = {0};+  PHP_VAR_SERIALIZE_INIT(var_hash);+  PHP_GRPC_VAR_SERIALIZE(&buf, args_array, &var_hash);+  PHP_VAR_SERIALIZE_DESTROY(var_hash);++  char sha1str[41];+  generate_sha1_str(sha1str, PHP_GRPC_SERIALIZED_BUF_STR(buf),+                    PHP_GRPC_SERIALIZED_BUF_LEN(buf));++  php_grpc_int key_len = target_length + strlen(sha1str);+  if (creds != NULL && creds->hashstr != NULL) {+    key_len += strlen(creds->hashstr);+  }+  char *key = malloc(key_len + 1);+  strcpy(key, target);+  strcat(key, sha1str);+  if (creds != NULL && creds->hashstr != NULL) {+    strcat(key, creds->hashstr);+  }+  channel->wrapper = malloc(sizeof(grpc_channel_wrapper));+  channel->wrapper->key = key;+  channel->wrapper->target = target;+  channel->wrapper->args_hashstr = sha1str;+  if (creds != NULL && creds->hashstr != NULL) {+    channel->wrapper->creds_hashstr = creds->hashstr;+  }+  gpr_mu_init(&channel->wrapper->mu);+  smart_str_free(&buf);++  if (force_new) {+    php_grpc_delete_persistent_list_entry(key, key_len TSRMLS_CC);+  }++  if (creds != NULL && creds->has_call_creds) {+    // If the ChannelCredentials object was composed with a CallCredentials+    // object, there is no way we can tell them apart. Do NOT persist+    // them. They should be individually destroyed.+    create_channel(channel, target, args, creds);","CallCredentials is a wrapper over a callback function. At the right time, i.e. when C core asks for the actual auth token, this callback function is called, and a token is fetched (from some other mechanism, or using some other auth library). We cannot persist the channel if a CallCredentials object was involved in creating the channel. Consider this:1. Create a channel with CallCredentials callback func 1.2. Create a channel with CallCredentials callback func 2.If we had persisted the underlying channel, 2. would return the same underlying channel and that will be wrong.",
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/11878,132542768,2017-08-10T19:13:26Z,src/php/ext/grpc/channel.c,"@@ -146,14 +232,82 @@ PHP_METHOD(Channel, __construct) {       php_grpc_zend_hash_del(array_hash, ""credentials"", sizeof(""credentials""));     }   }-  php_grpc_read_args_array(args_array, &args TSRMLS_CC);-  if (creds == NULL) {-    channel->wrapped = grpc_insecure_channel_create(target, &args, NULL);+  if (php_grpc_zend_hash_find(array_hash, ""force_new"", sizeof(""force_new""),+                              (void **)&force_new_obj) == SUCCESS) {+    if (PHP_GRPC_BVAL_IS_TRUE(force_new_obj)) {+      force_new = true;+    }+    php_grpc_zend_hash_del(array_hash, ""force_new"", sizeof(""force_new""));+  }++  // parse the rest of the channel args array+  if (php_grpc_read_args_array(args_array, &args TSRMLS_CC) == FAILURE) {+    return;+  }++  // Construct a hashkey for the persistent channel+  // Currently, the hashkey contains 3 parts:+  // 1. hostname+  // 2. hash value of the channel args array (excluding ""credentials""+  //    and ""force_new"")+  // 3. (optional) hash value of the ChannelCredentials object+  php_serialize_data_t var_hash;+  smart_str buf = {0};+  PHP_VAR_SERIALIZE_INIT(var_hash);+  PHP_GRPC_VAR_SERIALIZE(&buf, args_array, &var_hash);+  PHP_VAR_SERIALIZE_DESTROY(var_hash);++  char sha1str[41];+  generate_sha1_str(sha1str, PHP_GRPC_SERIALIZED_BUF_STR(buf),+                    PHP_GRPC_SERIALIZED_BUF_LEN(buf));++  php_grpc_int key_len = target_length + strlen(sha1str);+  if (creds != NULL && creds->hashstr != NULL) {+    key_len += strlen(creds->hashstr);+  }+  char *key = malloc(key_len + 1);+  strcpy(key, target);+  strcat(key, sha1str);+  if (creds != NULL && creds->hashstr != NULL) {+    strcat(key, creds->hashstr);+  }+  channel->wrapper = malloc(sizeof(grpc_channel_wrapper));+  channel->wrapper->key = key;+  channel->wrapper->target = target;+  channel->wrapper->args_hashstr = sha1str;+  if (creds != NULL && creds->hashstr != NULL) {+    channel->wrapper->creds_hashstr = creds->hashstr;+  }+  gpr_mu_init(&channel->wrapper->mu);+  smart_str_free(&buf);++  if (force_new) {","At step 4, there is no concept of ""non-persistent channel"" (except when CallCredentials is involved but that's not what we are talking about here). By using ""force_new"", you eject channel A from the list, but the newly created channel *is* persisted. Step 5 will get the same persistent channel. ",
17460127,y-zeng,https://api.github.com/repos/grpc/grpc/pulls/12137,132616616,2017-08-11T04:54:41Z,src/core/lib/surface/call.c,"@@ -1290,11 +1290,10 @@ static void receiving_stream_ready(grpc_exec_ctx *exec_ctx, void *bctlp,     cancel_with_error(exec_ctx, call, STATUS_FROM_SURFACE,                       GRPC_ERROR_REF(error));   }-  if (call->has_initial_md_been_received || error != GRPC_ERROR_NONE ||-      call->receiving_stream == NULL) {+  if (error != GRPC_ERROR_NONE || call->receiving_stream == NULL ||+      !gpr_atm_rel_cas(&call->saved_receiving_stream_ready_bctlp, 0,+                       (gpr_atm)bctlp)) {     process_data_after_md(exec_ctx, bctlp);",It looks like we should always use the batch_control structure from the batch that includes the recv_message op in  `process_data_after_md()`. It might not be necessary to save the recv_initial_metadata batch_control struct.,
17460127,y-zeng,https://api.github.com/repos/grpc/grpc/pulls/12137,132616634,2017-08-11T04:54:59Z,src/core/lib/surface/call.c,"@@ -1384,12 +1383,28 @@ static void receiving_initial_metadata_ready(grpc_exec_ctx *exec_ctx,     }   } -  call->has_initial_md_been_received = true;-  if (call->saved_receiving_stream_ready_bctlp != NULL) {-    grpc_closure *saved_rsr_closure = GRPC_CLOSURE_CREATE(-        receiving_stream_ready, call->saved_receiving_stream_ready_bctlp,-        grpc_schedule_on_exec_ctx);-    call->saved_receiving_stream_ready_bctlp = NULL;+  grpc_closure *saved_rsr_closure = NULL;+  while (true) {+    gpr_atm rsr_bctlp =+        gpr_atm_acq_load(&call->saved_receiving_stream_ready_bctlp);+    /* Should only receive initial metadata once */+    GPR_ASSERT(rsr_bctlp != 1);+    if (rsr_bctlp == 0) {+      /* Not received initial metadata and messages */+      if (gpr_atm_no_barrier_cas(&call->saved_receiving_stream_ready_bctlp, 0,","`no_barrier` should be enough for the previous implementation. As `receiving_initial_metadata_ready()` won't access the batch_control object from `receiving_stream_ready()` before and after the `cas` if the initial metadata is received first.The `cas` in `receiving_stream_ready()`  is `rel`, as `receiving_initial_metadata_ready()` won't access the batch_control object before the `acq_load`.In the new implementation, `receiving_initial_metadata_ready()` is using `acq_cas`, as it will only access the stored batch_control object after the `cas`. And its corresponding `cas` in ` receiving_stream_ready()` should be `rel`.@sreecha I'm not very confident about the semantics used here. Could you please take a look? ",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12152,132682783,2017-08-11T13:17:05Z,tools/run_tests/run_tests_matrix.py,"@@ -411,6 +411,8 @@ def _runs_per_test_type(arg_str):     extra_args.append('--bq_result_table')     extra_args.append('%s' % args.bq_result_table)     extra_args.append('--measure_cpu_costs')+    extra_args.append('--auto_set_flakes')","This itself looks good, but it also looks like it's impossible to disable the --auto_set_flakes because of python args library wierdness (try --auto_set_flakes False, --auto_set_flakes=false - none of them works).https://stackoverflow.com/questions/15008758/parsing-boolean-values-with-argparseSo we need to change the way --auto_set_flakes gets registered in run_tests.py and only then fix here.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12152,132683288,2017-08-11T13:19:36Z,tools/run_tests/run_tests_matrix.py,"@@ -411,6 +411,8 @@ def _runs_per_test_type(arg_str):     extra_args.append('--bq_result_table')     extra_args.append('%s' % args.bq_result_table)     extra_args.append('--measure_cpu_costs')+    extra_args.append('--auto_set_flakes')",Here's what I tried:```tools/run_tests/run_tests.py -l csharp --auto_set_flakes=False...Setting csharp.Grpc.IntegrationTesting.CustomErrorDetailsTest to flakySetting csharp.Grpc.IntegrationTesting.GeneratedServiceBaseTest to flakySetting csharp.Grpc.IntegrationTesting.MetadataCredentialsTest to flaky...```,
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/12168,132792713,2017-08-11T22:09:13Z,src/php/ext/grpc/channel_credentials.c,"@@ -116,8 +116,13 @@ PHP_METHOD(ChannelCredentials, setDefaultRootsPem) {                          ""setDefaultRootsPem expects 1 string"", 1 TSRMLS_CC);     return;   }-  default_pem_root_certs = gpr_malloc((pem_roots_length + 1) * sizeof(char));-  memcpy(default_pem_root_certs, pem_roots, pem_roots_length + 1);+  char *default_certs = php_grpc_get_default_pem_root_certs(TSRMLS_C);+  if (default_certs == NULL) {","Need to fix this, in case the incoming parameter is different from what we saved",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/12168,132795489,2017-08-11T22:31:30Z,src/php/ext/grpc/channel.c,"@@ -431,6 +434,7 @@ PHP_METHOD(Channel, close) {   gpr_mu_lock(&channel->wrapper->mu);   if (channel->wrapper->wrapped != NULL) {     grpc_channel_destroy(channel->wrapper->wrapped);+    free(channel->wrapper->target);","I think you don't want to destroy this until it is removed from the list, the ```target``` gets checked when you search through the list right?",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/11782,132800125,2017-08-11T23:19:22Z,src/core/ext/filters/http/message_compress/message_compress_filter.c,"@@ -171,17 +200,14 @@ static grpc_error *process_send_initial_metadata(   error = grpc_metadata_batch_add_tail(       exec_ctx, initial_metadata, &calld->accept_encoding_storage,       GRPC_MDELEM_ACCEPT_ENCODING_FOR_ALGORITHMS(-          channeld->supported_compression_algorithms &-          GRPC_MESSAGE_COMPRESSION_ALGORITHM_MASK));",Because the bits for stream compression algorithms is no longer being captured by `channeld->supported_compression_algorithms`. They are now in `channeld->supported_stream_compression_algorithms`. So right now we don't need mask any of them.,
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/12168,132813261,2017-08-12T08:19:28Z,src/php/ext/grpc/channel.c,"@@ -431,6 +434,7 @@ PHP_METHOD(Channel, close) {   gpr_mu_lock(&channel->wrapper->mu);   if (channel->wrapper->wrapped != NULL) {     grpc_channel_destroy(channel->wrapper->wrapped);+    free(channel->wrapper->target);","The `key` is used to search through the list, not the `target`, which is part of the `key`",
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/12168,132813273,2017-08-12T08:19:53Z,src/php/ext/grpc/php_grpc.h,"@@ -91,8 +92,13 @@ ZEND_END_MODULE_GLOBALS(grpc) #define GRPC_G(v) (grpc_globals.v) #endif +ZEND_DECLARE_MODULE_GLOBALS(grpc)","Undid this, as I no longer used this `globals` mechanism.",
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/12168,132813484,2017-08-12T08:26:06Z,src/php/ext/grpc/channel_credentials.c,"@@ -116,8 +116,13 @@ PHP_METHOD(ChannelCredentials, setDefaultRootsPem) {                          ""setDefaultRootsPem expects 1 string"", 1 TSRMLS_CC);     return;   }-  default_pem_root_certs = gpr_malloc((pem_roots_length + 1) * sizeof(char));-  memcpy(default_pem_root_certs, pem_roots, pem_roots_length + 1);+  char *default_certs = php_grpc_get_default_pem_root_certs(TSRMLS_C);+  if (default_certs == NULL) {","This has been done in a different way now. The certs string is stored in the ""persistent list"", similarly to persistent channel. Everytime we call `setDefaultRootPem`, we check the persistent list. If it exists, we retrieve it and compare it to the incoming parameter. If they are different, I update the persistent list. Previously we just store the char pointer in a variable and apparently PHP will somehow corrupt the pointer once in a while so I cannot use a simple variable.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12143,132871987,2017-08-14T04:33:14Z,src/csharp/Grpc.Core/ClientBase.cs,"@@ -156,9 +156,24 @@ internal ClientBaseConfiguration(CallInvoker undecoratedCallInvoker, string host                 this.host = host;             } +            class SetHostInterceptor : InterceptorBase","nit: ""SetHostInterceptor is an odd name (but I agree that doesn't really matter in this stage as it's a private class anyway).",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12143,132873314,2017-08-14T04:47:51Z,src/csharp/Grpc.Core/Channel.cs,"@@ -128,6 +137,36 @@ public ChannelState State         }          /// <summary>+        /// Gets the canonical CallInvoker for the current channel.+        /// </summary>+        /// <returns>An instance of DefaultCallInvoker if no interceptor is registered. Otherwise, returns an InterceptingCallInvoker.</returns>+        internal CallInvoker CallInvoker { get; private set; }++        /// <summary>+        /// Intercepts the channel via the specified interceptor.+        /// </summary>+        /// <param name=""interceptor"">The interceptor instance to intercept the calls passing through the channel.</param>+        /// <returns>A new channel instance whose calls will be intercepted.</returns>+        public Channel Intercept(IInterceptor interceptor)","not sure if decorating a channel like this is intuitive. There should probably be a section in the design for ""Applying interceptor to a channel"" (as opposed to actually intercepting a call of given arity), showing some possible ways how to do it (and commenting on which approach seems the best and why).Btw, there is already a concept of CallInvoker and callInvokers can be stacked on top of each other (even though the order of them being applied might not be intuitive).One can create a stub with arbitrary call invoker by using https://github.com/grpc/grpc/blob/master/src/csharp/Grpc.Examples/MathGrpc.cs#L137. Why is a method on a channel superior to that approach?",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12143,132873755,2017-08-14T04:55:26Z,src/csharp/Grpc.Core/InterceptorBase.cs,"@@ -0,0 +1,69 @@+#region Copyright notice and license++// Copyright 2017 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;++namespace Grpc.Core+{+    public abstract class InterceptorBase : IInterceptor","does the interceptor provide access to all of call metadata (request headers, response headers, response trailers)? can the metadata be modified or just inspected?",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/12168,133013444,2017-08-14T17:40:31Z,src/php/ext/grpc/channel_credentials.c,"@@ -100,6 +113,27 @@ zval *grpc_php_wrap_channel_credentials(grpc_channel_credentials *wrapped,   return credentials_object; } +void update_root_certs_persistent_list(char *pem_roots,+                                       php_grpc_int pem_roots_length+                                       TSRMLS_DC) {++  php_grpc_zend_resource new_rsrc;+  channel_credentials_persistent_le_t *le;+  php_grpc_int key_len = strlen(persistent_list_key);+  new_rsrc.type = le_cc_plink;+  le = malloc(sizeof(channel_credentials_persistent_le_t));++  char *tmp = malloc(pem_roots_length+1);","Nit:  tmp seems uneeded here, you should be able to put the data directly into ```le->default_root_certs```",
233334,splittingred,https://api.github.com/repos/grpc/grpc/pulls/12100,133054618,2017-08-14T20:36:56Z,src/ruby/lib/grpc/generic/client_stub.rb,"@@ -149,16 +153,29 @@ def request_response(method, req, marshal, unmarshal,                           deadline: deadline,                           parent: parent,                           credentials: credentials)-      return c.request_response(req, metadata: metadata) unless return_op--      # return the operation view of the active_call; define #execute as a-      # new method for this instance that invokes #request_response.-      c.merge_metadata_to_send(metadata)-      op = c.operation-      op.define_singleton_method(:execute) do-        c.request_response(req, metadata: metadata)+      interception_context = InterceptionContext.new(interceptors.all)+      intercept_args = {+        method: method,+        request: req,+        call: c,+        metadata: metadata","One thing on this (and other request types) was how much information we wanted to pass to client interceptors. For example, do we care about passing the deadline, parent, and credentials options? Should that be encapsulated in a `call_options` hash that gets passed to the Interception Context? Looking for thoughts here.",
233334,splittingred,https://api.github.com/repos/grpc/grpc/pulls/12100,133055300,2017-08-14T20:39:45Z,src/ruby/lib/grpc/generic/interceptors.rb,"@@ -0,0 +1,167 @@+# Copyright 2015 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+require_relative 'interceptor_registry'++# GRPC contains the General RPC module.+module GRPC+  ##+  # Base class for interception in GRPC+  #+  class Interceptor+    ##+    # @param [Hash] options A hash of options that will be used+    #   by the interceptor+    #+    def initialize(options = {})+      @options = options || {}+    end+  end++  ##+  # ClientInterceptor allows for wrapping outbound gRPC client stub requests+  #+  class ClientInterceptor < Interceptor+    ##+    # Intercept a unary request response call+    #+    # @param [Object] request+    # @param [GRPC::ActiveCall] call+    # @param [Method] method+    # @param [Hash] metadata+    #+    def request_response(*)","I'd love to explicitly define the args here, but there are a few upstream problems with Rubocop that causes build failures:- The gRPC Rubocop version is pretty old (0.30) compared to latest (0.49), and the newer versions have a IgnoreUnusedKeywordArguments flag we could use, as well as inline ignore statements- Upgrading Rubocop is a pretty large change (last I tried on master it was around 120 Rubocop errors or so) and I didn't want to inflate this already larger PR further",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12100,133089209,2017-08-14T23:45:32Z,src/ruby/lib/grpc/generic/client_stub.rb,"@@ -149,16 +153,29 @@ def request_response(method, req, marshal, unmarshal,                           deadline: deadline,                           parent: parent,                           credentials: credentials)-      return c.request_response(req, metadata: metadata) unless return_op--      # return the operation view of the active_call; define #execute as a-      # new method for this instance that invokes #request_response.-      c.merge_metadata_to_send(metadata)-      op = c.operation-      op.define_singleton_method(:execute) do-        c.request_response(req, metadata: metadata)+      interception_context = InterceptionContext.new(interceptors.all)+      intercept_args = {+        method: method,+        request: req,+        call: c,+        metadata: metadata","For consistency with the API of the `ActiveCall` object that's exposed for `operation views` of client calls, I think it would make sense to expose only the `OperationView`'s of the of the `call` parameters to `interceptor_args`, but without the `execute` method, and probably without the the `start_call` method as well.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12100,133093734,2017-08-15T00:19:52Z,src/ruby/lib/grpc/generic/interceptors.rb,"@@ -0,0 +1,167 @@+# Copyright 2015 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+require_relative 'interceptor_registry'++# GRPC contains the General RPC module.+module GRPC+  ##+  # Base class for interception in GRPC+  #+  class Interceptor+    ##+    # @param [Hash] options A hash of options that will be used+    #   by the interceptor+    #+    def initialize(options = {})+      @options = options || {}+    end+  end++  ##+  # ClientInterceptor allows for wrapping outbound gRPC client stub requests+  #+  class ClientInterceptor < Interceptor+    ##+    # Intercept a unary request response call+    #+    # @param [Object] request+    # @param [GRPC::ActiveCall] call+    # @param [Method] method+    # @param [Hash] metadata+    #+    def request_response(*)","I agree that upgrading RuboCop in this PR would make the scope too large.I'd be ok with logging the arguments, as a hack for now.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/12187,133103765,2017-08-15T02:00:32Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -775,8 +787,10 @@ static void create_rr_locked(grpc_exec_ctx *exec_ctx, glb_lb_policy *glb_policy, /* glb_policy->rr_policy may be NULL (initial handover) */ static void rr_handover_locked(grpc_exec_ctx *exec_ctx,                                glb_lb_policy *glb_policy) {-  GPR_ASSERT(glb_policy->serverlist != NULL &&-             glb_policy->serverlist->num_servers > 0);+  GPR_ASSERT((glb_policy->fallback && glb_policy->fallback_addresses != NULL &&","This assert is now too long. If it fails, which clause is the invalid one? This could have been argued even for the previous contents, but at least then they were both about `glb_policy->serverlist`. In general, not just for asserts, I find that overly composed conditions are difficult to read. I usually create const bools with descriptive variable names that, if I really have to, then compose. That way at least I can read it as if it were natural language. But again, in this case, the main issue is that the assert granularity is too coarse. ",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,133214776,2017-08-15T15:08:33Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -668,8 +675,13 @@ static bool pick_from_internal_rr_locked(  static grpc_lb_policy_args *lb_policy_args_create(grpc_exec_ctx *exec_ctx,                                                   glb_lb_policy *glb_policy) {-  grpc_lb_addresses *addresses =-      process_serverlist_locked(exec_ctx, glb_policy->serverlist);+  grpc_lb_addresses *addresses;+  if (glb_policy->fallback) {+    addresses = glb_policy->fallback_addresses;","It's not clear from the code what the ownership semantics are for `glb_policy->fallback_addresses`.  Here we are giving the value to the local variable `addresses`, whose value will be freed before this function returns.  That will leave us in a state where `glb_policy->fallback_addresses` points to a value that has already been freed.If we intend it to be freed at this point, then let's reset `glb_policy->fallback_addresses` to NULL right after this line, so that it's clear that nothing should try accessing it later.If we do *not* intend it to be freed at this point, then we should change line 696 to only free the value if we are not using the fallback.  In that case, we should make sure to free the value in `glb_destroy()`.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,133215721,2017-08-15T15:12:06Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -967,6 +981,20 @@ static grpc_lb_policy *glb_create(grpc_exec_ctx *exec_ctx,   glb_policy->args = grpc_channel_args_copy_and_add_and_remove(       args->args, args_to_remove, GPR_ARRAY_SIZE(args_to_remove), &new_arg, 1); +  /* Fallback is off */+  glb_policy->fallback = false;++  /* Copy the backend server addresses from the resolver for fallback */","We also need to do something similar in `glb_update()`, since we may get updated backend addresses from the resolver while we are still trying to contact the balancer.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,133230803,2017-08-15T16:07:56Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -775,8 +787,10 @@ static void create_rr_locked(grpc_exec_ctx *exec_ctx, glb_lb_policy *glb_policy, /* glb_policy->rr_policy may be NULL (initial handover) */ static void rr_handover_locked(grpc_exec_ctx *exec_ctx,                                glb_lb_policy *glb_policy) {-  GPR_ASSERT(glb_policy->serverlist != NULL &&-             glb_policy->serverlist->num_servers > 0);+  GPR_ASSERT((glb_policy->fallback && glb_policy->fallback_addresses != NULL &&","I agree that simpler conditions are better, at least for asserts.But I haven't found a better way to separate the conditions when failure happens in this case. I think using two const bools to group the conditions is more readable and I will do that. But finally both bools will sit in the same assert. If the assert fails, we still can't tell which condition fails (can we?).Do you think I should add two logs, each of which prints the failed condition?",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/12187,133234116,2017-08-15T16:21:23Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -775,8 +787,10 @@ static void create_rr_locked(grpc_exec_ctx *exec_ctx, glb_lb_policy *glb_policy, /* glb_policy->rr_policy may be NULL (initial handover) */ static void rr_handover_locked(grpc_exec_ctx *exec_ctx,                                glb_lb_policy *glb_policy) {-  GPR_ASSERT(glb_policy->serverlist != NULL &&-             glb_policy->serverlist->num_servers > 0);+  GPR_ASSERT((glb_policy->fallback && glb_policy->fallback_addresses != NULL &&","At the very least, we can separate the OR-ed clauses:```GPR_ASSERT(glb_policy->fallback &c& glb_policy->fallback_addresses != NULL && glb_policy->fallback_addresses->num_addresses > 0);GPR_ASSERT(glb_policy->serverlist != NULL && glb_policy->serverlist->num_servers > 0);```Moreover, it you take Mark's suggestion to get rid of the boolean in favor of using `glb_policy->fallback_addresses != NULL` as the check, the first assert is further simplified and looks very much like the second. ",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,133236893,2017-08-15T16:32:32Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -967,6 +981,20 @@ static grpc_lb_policy *glb_create(grpc_exec_ctx *exec_ctx,   glb_policy->args = grpc_channel_args_copy_and_add_and_remove(       args->args, args_to_remove, GPR_ARRAY_SIZE(args_to_remove), &new_arg, 1); +  /* Fallback is off */+  glb_policy->fallback = false;++  /* Copy the backend server addresses from the resolver for fallback */+  grpc_lb_addresses *backends = grpc_lb_addresses_create(+      addresses->num_addresses - num_grpclb_addrs, NULL);+  for (size_t addr_copied = 0, i = 0; i < addresses->num_addresses; ++i) {","I chose to use another loop because:- I need `num_grpclb_addrs` before copying backends, and `num_grpclb_addrs` is a result of the existing for loop. There is a dependency. - These two loops have different goals. The old one is for validation; the new one is for data movement. (Maybe moving the new loop to under the old one can help compiler optimization like loop fusion?) ",
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/12137,133240777,2017-08-15T16:49:31Z,src/core/lib/surface/call.c,"@@ -1290,11 +1303,11 @@ static void receiving_stream_ready(grpc_exec_ctx *exec_ctx, void *bctlp,     cancel_with_error(exec_ctx, call, STATUS_FROM_SURFACE,                       GRPC_ERROR_REF(error));   }-  if (call->has_initial_md_been_received || error != GRPC_ERROR_NONE ||-      call->receiving_stream == NULL) {+  call->saved_receiving_stream_ready_bctlp = bctlp;",We talked offline about this yesterday but putting it here again for the record.   This change to `saved_receiving_stream_ready_bctlp` may not be visible after the `gpr_atm_acq_cas` you are doing in `receiving_initial_metadata_ready` function. (please see my comment there),
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/12137,133241527,2017-08-15T16:52:23Z,src/core/lib/surface/call.c,"@@ -1384,8 +1397,8 @@ static void receiving_initial_metadata_ready(grpc_exec_ctx *exec_ctx,     }   } -  call->has_initial_md_been_received = true;-  if (call->saved_receiving_stream_ready_bctlp != NULL) {+  if (!gpr_atm_acq_cas(&call->recv_state, RECV_NONE,","This uses `__ATOMIC_ACQUIRE` semantics only in case of success and `__ATOMIC_RELAXED`  semantics in case of failure.  Since we are accessing `saved_receiving_stream_ready_bctlp` only in case `gpr_atm_acq_cas` fails, we are using `__ATOMIC_RELAXED` and hence no guarantee that we are getting the updated value of `saved_receiving_stream_ready_bctlp`",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,133245279,2017-08-15T17:07:55Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -775,8 +787,10 @@ static void create_rr_locked(grpc_exec_ctx *exec_ctx, glb_lb_policy *glb_policy, /* glb_policy->rr_policy may be NULL (initial handover) */ static void rr_handover_locked(grpc_exec_ctx *exec_ctx,                                glb_lb_policy *glb_policy) {-  GPR_ASSERT(glb_policy->serverlist != NULL &&-             glb_policy->serverlist->num_servers > 0);+  GPR_ASSERT((glb_policy->fallback && glb_policy->fallback_addresses != NULL &&","Must these two asserts both hold?- We can just have valid fallback, if we don't have a valid server list because we can't reach any balancer.- We can just have valid server list, because fallback is unnecessary then.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/12187,133245635,2017-08-15T17:09:20Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -967,6 +981,20 @@ static grpc_lb_policy *glb_create(grpc_exec_ctx *exec_ctx,   glb_policy->args = grpc_channel_args_copy_and_add_and_remove(       args->args, args_to_remove, GPR_ARRAY_SIZE(args_to_remove), &new_arg, 1); +  /* Fallback is off */+  glb_policy->fallback = false;++  /* Copy the backend server addresses from the resolver for fallback */+  grpc_lb_addresses *backends = grpc_lb_addresses_create(+      addresses->num_addresses - num_grpclb_addrs, NULL);+  for (size_t addr_copied = 0, i = 0; i < addresses->num_addresses; ++i) {+    if (!addresses->addresses[i].is_balancer) {+      memcpy(backends->addresses + addr_copied++, addresses->addresses + i, ","Yes, true, it'd need the `&`. In this case however it doesn't matter because we need to use `grpc_lb_addresses_set_address`. But if it did, the `&...[i]` for would still be (weakly) preferred for consistency reasons with the rest of the codebase. Ultimately [the compiler doesn't care](https://godbolt.org/g/YsMdUr)",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/12187,133246486,2017-08-15T17:12:47Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -775,8 +787,10 @@ static void create_rr_locked(grpc_exec_ctx *exec_ctx, glb_lb_policy *glb_policy, /* glb_policy->rr_policy may be NULL (initial handover) */ static void rr_handover_locked(grpc_exec_ctx *exec_ctx,                                glb_lb_policy *glb_policy) {-  GPR_ASSERT(glb_policy->serverlist != NULL &&-             glb_policy->serverlist->num_servers > 0);+  GPR_ASSERT((glb_policy->fallback && glb_policy->fallback_addresses != NULL &&","Sorry, I wasn't suggesting having both one after the other: I'd move the assert relative to the fallback to the part of the code that's act upon `glb_policy->fallback_addresses`.Basically, you need to branch depending on whether we are using the serverlist or the fallback addresses. Each branch would have its corresponding version of the assert.",
17460127,y-zeng,https://api.github.com/repos/grpc/grpc/pulls/12137,133257441,2017-08-15T17:55:07Z,src/core/lib/surface/call.c,"@@ -1384,8 +1397,8 @@ static void receiving_initial_metadata_ready(grpc_exec_ctx *exec_ctx,     }   } -  call->has_initial_md_been_received = true;-  if (call->saved_receiving_stream_ready_bctlp != NULL) {+  if (!gpr_atm_acq_cas(&call->recv_state, RECV_NONE,",Thanks @sreecha! I didn't consider the `__ATOMIC_RELAXED` semantics in case of failure. The problem is `full_cas` also has this issue. We may need to find another solution if the semantics in failed comparison cannot be changed to `__ATOMIC_ACQUIRE`.,
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/12137,133259067,2017-08-15T18:01:49Z,src/core/lib/surface/call.c,"@@ -1384,8 +1397,8 @@ static void receiving_initial_metadata_ready(grpc_exec_ctx *exec_ctx,     }   } -  call->has_initial_md_been_received = true;-  if (call->saved_receiving_stream_ready_bctlp != NULL) {+  if (!gpr_atm_acq_cas(&call->recv_state, RECV_NONE,","Unfortunately, all our [`gpr_atm_xxx_cas()`](https://github.com/grpc/grpc/blob/master/include/grpc/impl/codegen/atm_gcc_atomic.h#L64) APIs  use `__ATOMIC_RELAXED` memory order in case of failure.    i.e they all are designed for cases like:```if (gpr_atm_xxx_cas(...)) {     // Do something }```but not for the opposite. i.e```if ( ! gpr_atm_xxx_cas(...)) {     // Do something }```I think this is the case for adding new variants to our gpr_atm_xxx_cas APIs (where we can specify __ATOMIC_ACQUIRE mem order for failure case)cc/ @dklempner @ctiller @vjpai  to add any comments here.",
17460127,y-zeng,https://api.github.com/repos/grpc/grpc/pulls/12137,133263996,2017-08-15T18:21:34Z,src/core/lib/surface/call.c,"@@ -1384,8 +1397,8 @@ static void receiving_initial_metadata_ready(grpc_exec_ctx *exec_ctx,     }   } -  call->has_initial_md_been_received = true;-  if (call->saved_receiving_stream_ready_bctlp != NULL) {+  if (!gpr_atm_acq_cas(&call->recv_state, RECV_NONE,","I've checked the previous implementation in 873bb70, it should not have the issue with `__ATOMIC_RELAXED` semantics in failed `cas`. It's a little more complicated but does not require new `gpr_atm_xxx_cas` APIs.  ",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12176,133279762,2017-08-15T19:24:18Z,src/csharp/Grpc.Core/Internal/GrpcThreadPool.cs,"@@ -187,6 +193,16 @@ private void RunHandlerLoop(CompletionQueueSafeHandle cq, IProfiler optionalProf                 }             }             while (ev.type != CompletionQueueEvent.CompletionType.Shutdown);++            // Continuations are running on default threadpool that consists of background threads.+            // GrpcThreadPool thread (a foreground thread) will not exit unless all queued work had+            // been finished to prevent terminating the continuations queued prematurely.+            while (queuedContinuationCounter.Count != 0)+            {+                // Only happens on shutdown and having pending continuations shouldn't very common,+                // so sleeping here for a little bit is fine.+                Thread.Sleep(FinishContinuationsSleepMillis);","A little worried about the infinite wait here, maybe max out at something like a 10 second deadline?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12104,133305691,2017-08-15T21:15:06Z,src/core/lib/channel/channel_stack_builder.h,"@@ -95,6 +95,11 @@ bool grpc_channel_stack_builder_move_next( bool grpc_channel_stack_builder_move_prev(     grpc_channel_stack_builder_iterator *iterator); +/// Return an iterator at \a filter_name, or at the end of the iterator if not",s/end of the iterator/end of the list/,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12104,133308518,2017-08-15T21:27:28Z,test/core/channel/channel_stack_builder_test.c,"@@ -0,0 +1,155 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/core/lib/channel/channel_stack_builder.h""++#include <limits.h>+#include <string.h>++#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>++#include ""src/core/lib/slice/slice_internal.h""+#include ""src/core/lib/surface/channel_init.h""+#include ""test/core/util/test_config.h""++static grpc_error *channel_init_func(grpc_exec_ctx *exec_ctx,+                                     grpc_channel_element *elem,+                                     grpc_channel_element_args *args) {+  return GRPC_ERROR_NONE;+}++static grpc_error *call_init_func(grpc_exec_ctx *exec_ctx,+                                  grpc_call_element *elem,+                                  const grpc_call_element_args *args) {+  return GRPC_ERROR_NONE;+}++static void channel_destroy_func(grpc_exec_ctx *exec_ctx,+                                 grpc_channel_element *elem) {}++static void call_destroy_func(grpc_exec_ctx *exec_ctx, grpc_call_element *elem,+                              const grpc_call_final_info *final_info,+                              grpc_closure *ignored) {}++static void call_func(grpc_exec_ctx *exec_ctx, grpc_call_element *elem,+                      grpc_transport_stream_op_batch *op) {}++static void channel_func(grpc_exec_ctx *exec_ctx, grpc_channel_element *elem,+                         grpc_transport_op *op) {+  if (op->disconnect_with_error != GRPC_ERROR_NONE) {+    GRPC_ERROR_UNREF(op->disconnect_with_error);+  }+  GRPC_CLOSURE_SCHED(exec_ctx, op->on_consumed, GRPC_ERROR_NONE);+}++static char *get_peer(grpc_exec_ctx *exec_ctx, grpc_call_element *elem) {+  return gpr_strdup(""peer"");+}++unsigned long g_high_prio_arg = 0;","Couldn't this just be a bool, similar to what you're doing for the original filter?",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/12104,133318047,2017-08-15T22:16:30Z,src/core/lib/channel/channel_stack_builder.c,"@@ -124,6 +124,24 @@ bool grpc_channel_stack_builder_move_prev(   return true; } +grpc_channel_stack_builder_iterator *grpc_channel_stack_builder_iterator_find(+    grpc_channel_stack_builder *builder, const char *filter_name) {+  GPR_ASSERT(filter_name != NULL);+  grpc_channel_stack_builder_iterator *it =+      grpc_channel_stack_builder_create_iterator_at_first(builder);+  if (grpc_channel_stack_builder_iterator_is_end(it)) return it;+  do {+    const char *filter_name_at_it =+        grpc_channel_stack_builder_iterator_filter_name(it);+    if (filter_name_at_it != NULL &&","In fact it'll always be NULL the first iteration. The first element of the list `it` iterates over (ie, `builder->begin`) is a market node with its filter field always set to NULL. We could in fact do a `next(it)` after calling `grpc_channel_stack_builder_create_iterator_at_first(builder)` but it looks ugly.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/12187,133329871,2017-08-15T23:35:14Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -967,6 +981,20 @@ static grpc_lb_policy *glb_create(grpc_exec_ctx *exec_ctx,   glb_policy->args = grpc_channel_args_copy_and_add_and_remove(       args->args, args_to_remove, GPR_ARRAY_SIZE(args_to_remove), &new_arg, 1); +  /* Fallback is off */+  glb_policy->fallback = false;++  /* Copy the backend server addresses from the resolver for fallback */+  grpc_lb_addresses *backends = grpc_lb_addresses_create(+      addresses->num_addresses - num_grpclb_addrs, NULL);+  for (size_t addr_copied = 0, i = 0; i < addresses->num_addresses; ++i) {+    if (!addresses->addresses[i].is_balancer) {+      memcpy(backends->addresses + addr_copied++, addresses->addresses + i, ","In general, it's better to use the API to modify instances, because they encapsulate the full contract. They also allow us to change behavior in the future by only modifying the API function body.More importantly, in this case, `memcpy`ing here is shallow: data pointed by pointers in `addresses->addresses[i]` won't be copied, and there's currently one field whose contents -not just the pointer- needs to be copied ([balancer_name](https://github.com/grpc/grpc/blob/e60c0f82b55310efae040534541f5a6acec28aba/src/core/ext/filters/client_channel/lb_policy_factory.c#L67)). Not doing so will result in a use-after-free the moment `addresses->addresses` (which we don't own) is freed.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,133336191,2017-08-16T00:30:10Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -967,6 +981,20 @@ static grpc_lb_policy *glb_create(grpc_exec_ctx *exec_ctx,   glb_policy->args = grpc_channel_args_copy_and_add_and_remove(       args->args, args_to_remove, GPR_ARRAY_SIZE(args_to_remove), &new_arg, 1); +  /* Fallback is off */+  glb_policy->fallback = false;++  /* Copy the backend server addresses from the resolver for fallback */+  grpc_lb_addresses *backends = grpc_lb_addresses_create(+      addresses->num_addresses - num_grpclb_addrs, NULL);+  for (size_t addr_copied = 0, i = 0; i < addresses->num_addresses; ++i) {+    if (!addresses->addresses[i].is_balancer) {+      memcpy(backends->addresses + addr_copied++, addresses->addresses + i, ","Understood. In this case, should I do something similar to [`grpc_lb_addresses_copy`](https://github.com/grpc/grpc/blob/e60c0f82b55310efae040534541f5a6acec28aba/src/core/ext/filters/client_channel/lb_policy_factory.c#L39) (i.e., `memcpy` each address and do necessary deep copy)? BTW, what is backend address's `balancer_name` like? ",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,133475212,2017-08-16T14:59:01Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -967,6 +981,20 @@ static grpc_lb_policy *glb_create(grpc_exec_ctx *exec_ctx,   glb_policy->args = grpc_channel_args_copy_and_add_and_remove(       args->args, args_to_remove, GPR_ARRAY_SIZE(args_to_remove), &new_arg, 1); +  /* Fallback is off */+  glb_policy->fallback = false;++  /* Copy the backend server addresses from the resolver for fallback */+  grpc_lb_addresses *backends = grpc_lb_addresses_create(+      addresses->num_addresses - num_grpclb_addrs, NULL);+  for (size_t addr_copied = 0, i = 0; i < addresses->num_addresses; ++i) {+    if (!addresses->addresses[i].is_balancer) {+      memcpy(backends->addresses + addr_copied++, addresses->addresses + i, ","I suggest refactoring `grpc_lb_addresses_copy()` such that there is a separate function called `grpc_lb_address_copy()` that copies an individual address, and then modifying `grpc_lb_addresses_copy()` to be a loop that calls `grpc_lb_address_copy()` for each address in the list.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,133543756,2017-08-16T19:26:17Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -967,6 +981,20 @@ static grpc_lb_policy *glb_create(grpc_exec_ctx *exec_ctx,   glb_policy->args = grpc_channel_args_copy_and_add_and_remove(       args->args, args_to_remove, GPR_ARRAY_SIZE(args_to_remove), &new_arg, 1); +  /* Fallback is off */+  glb_policy->fallback = false;++  /* Copy the backend server addresses from the resolver for fallback */+  grpc_lb_addresses *backends = grpc_lb_addresses_create(+      addresses->num_addresses - num_grpclb_addrs, NULL);+  for (size_t addr_copied = 0, i = 0; i < addresses->num_addresses; ++i) {+    if (!addresses->addresses[i].is_balancer) {+      memcpy(backends->addresses + addr_copied++, addresses->addresses + i, ","I think we are talking about the same functionality, but using different names.If populate means fill, I think we should avoid using `..._copy()`? Because the existing `grpc_lb_addresses_copy()` returns a new object, which looks reasonable. (So does `user_data_vtable->copy()`.) `..._set()` may be a confusing name. Ah, naming is so difficult...",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12210,133736549,2017-08-17T14:53:52Z,tools/run_tests/name_resolution/resolver_test_record_groups.yaml,"@@ -0,0 +1,94 @@+naming_end2end_tests_common_zone_name: test-2.grpctestingexp.+naming_end2end_tests:+- expected_addrs: ['1.2.3.4:1234']+  expected_config_index: null+  record_to_resolve: srv-ipv4-single-target+  records:+    _grpclb._tcp.srv-ipv4-single-target:+    - {TTL: '2100', data: 0 0 1234 ipv4-single-target, type: SRV}+    ipv4-single-target:+    - {TTL: '2100', data: 1.2.3.4, type: A}+- expected_addrs: ['1.2.3.5:1234', '1.2.3.6:1234', '1.2.3.7:1234']+  expected_config_index: null+  record_to_resolve: srv-ipv4-multi-target+  records:+    _grpclb._tcp.srv-ipv4-multi-target:+    - {TTL: '2100', data: 0 0 1234 ipv4-multi-target, type: SRV}+    ipv4-multi-target:+    - {TTL: '2100', data: 1.2.3.5, type: A}+    - {TTL: '2100', data: 1.2.3.6, type: A}+    - {TTL: '2100', data: 1.2.3.7, type: A}+- expected_addrs: ['[2607:f8b0:400a:801::1001]:1234']+  expected_config_index: null+  record_to_resolve: srv-ipv6-single-target+  records:+    _grpclb._tcp.srv-ipv6-single-target:+    - {TTL: '2100', data: 0 0 1234 ipv6-single-target, type: SRV}+    ipv6-single-target:+    - {TTL: '2100', data: '2607:f8b0:400a:801::1001', type: AAAA}+- expected_addrs: ['[2607:f8b0:400a:801::1002]:1234', '[2607:f8b0:400a:801::1003]:1234',+    '[2607:f8b0:400a:801::1004]:1234']+  expected_config_index: null+  record_to_resolve: srv-ipv6-multi-target+  records:+    _grpclb._tcp.srv-ipv6-multi-target:+    - {TTL: '2100', data: 0 0 1234 ipv6-multi-target, type: SRV}+    ipv6-multi-target:+    - {TTL: '2100', data: '2607:f8b0:400a:801::1002', type: AAAA}+    - {TTL: '2100', data: '2607:f8b0:400a:801::1003', type: AAAA}+    - {TTL: '2100', data: '2607:f8b0:400a:801::1004', type: AAAA}+- expected_addrs: ['1.2.3.4:1234']+  expected_config_index: 0+  record_to_resolve: srv-ipv4-simple-service-config+  records:+    _grpclb._tcp.srv-ipv4-simple-service-config:+    - {TTL: '2100', data: 0 0 1234 ipv4-simple-service-config,+      type: SRV}+    ipv4-simple-service-config:+    - {TTL: '2100', data: 1.2.3.4, type: A}+    srv-ipv4-simple-service-config:+    - {TTL: '2100', data: 'grpc_config=[{""serviceConfig"":{""loadBalancingPolicy"":""round_robin"",""methodConfig"":[{""name"":[{""method"":""Foo"",""service"":""SimpleService"",""waitForReady"":true}]}]}}]',+      type: TXT}+- expected_addrs: ['1.2.3.4:443']+  expected_config_index: 0+  record_to_resolve: ipv4-no-srv-simple-service-config+  records:+    ipv4-no-srv-simple-service-config:+    - {TTL: '2100', data: 1.2.3.4, type: A}+    - {TTL: '2100', data: 'grpc_config=[{""serviceConfig"":{""loadBalancingPolicy"":""round_robin"",""methodConfig"":[{""name"":[{""method"":""Foo"",""service"":""NoSrvSimpleService"",""waitForReady"":true}]}]}}]',+      type: TXT}+- expected_addrs: ['1.2.3.4:443']+  expected_config_index: null+  record_to_resolve: ipv4-no-config-for-cpp+  records:+    ipv4-no-config-for-cpp:+    - {TTL: '2100', data: 1.2.3.4, type: A}+    - {TTL: '2100', data: 'grpc_config=[{""clientLanguage"":[""python""],""serviceConfig"":{""loadBalancingPolicy"":""round_robin"",""methodConfig"":[{""name"":[{""method"":""Foo"",""service"":""PythonService"",""waitForReady"":true}]}]}}]',+      type: TXT}+- expected_addrs: ['1.2.3.4:443']+  expected_config_index: null+  record_to_resolve: ipv4-cpp-config-has-zero-percentage+  records:+    ipv4-cpp-config-has-zero-percentage:+    - {TTL: '2100', data: 1.2.3.4, type: A}+    - {TTL: '2100', data: 'grpc_config=[{""percentage"":0,""serviceConfig"":{""loadBalancingPolicy"":""round_robin"",""methodConfig"":[{""name"":[{""method"":""Foo"",""service"":""CppService"",""waitForReady"":true}]}]}}]',+      type: TXT}++naming_end2end_tests_TODO:+- ""TODO: enable these large-txt-record tests once working. (these are txt-records are larger than 255 characters)""","DNS doesn't allow individual TXT records larger than 255 characters, but it does allow you to split up a TXT record into multiple strings.  For example:```foo.com. IN TXT ""grpc_config=[{\""serviceConfig\"":{"" ""\""loadBalancingPolicy\"":\""round_robin\""}}]""```I don't know the protocol details, but I do know that DNS can somehow represent the difference between multiple independent TXT records and a single split-up TXT record.  For example, if I add a second TXT record to the zone file in addition to the above, dig shows the following:```roth@segfault:~/grpc> dig @127.0.0.1 -p 1234 foo.com. txt; <<>> DiG 9.9.5-3ubuntu0.15-Ubuntu <<>> @127.0.0.1 -p 1234 foo.com. txt; (1 server found);; global options: +cmd;; Got answer:;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 60627;; flags: qr aa rd ra; QUERY: 1, ANSWER: 2, AUTHORITY: 1, ADDITIONAL: 2;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 4096;; QUESTION SECTION:;foo.com.                       IN      TXT;; ANSWER SECTION:foo.com.                3600    IN      TXT     ""a=1234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890""foo.com.                3600    IN      TXT     ""grpc_config=[{\""serviceConfig\"":{"" ""\""loadBalancingPolicy\"":\""round_robin\""}}]"";; AUTHORITY SECTION:foo.com.                3600    IN      NS      ns.foo.com.;; ADDITIONAL SECTION:ns.foo.com.             3600    IN      A       127.0.0.1;; Query time: 0 msec;; SERVER: 127.0.0.1#1234(127.0.0.1);; WHEN: Thu Aug 17 08:09:58 PDT 2017;; MSG SIZE  rcvd: 417```Note that the two parts of the service config string are shown as a single split-up entry, but the other TXT record is shown as an independent record.Note that because the split-up record appears differently at the protocol level, the c-ares code has special handling for this case.  So we do need to find a way to test this.From a quick glance at the dnslib code, I'm not sure it can handle this right now.  If not, perhaps we can fix it to do that?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12210,133737110,2017-08-17T14:55:19Z,tools/run_tests/name_resolution/resolver_test_record_groups.yaml,"@@ -0,0 +1,94 @@+naming_end2end_tests_common_zone_name: test-2.grpctestingexp.+naming_end2end_tests:+- expected_addrs: ['1.2.3.4:1234']+  expected_config_index: null+  record_to_resolve: srv-ipv4-single-target+  records:+    _grpclb._tcp.srv-ipv4-single-target:+    - {TTL: '2100', data: 0 0 1234 ipv4-single-target, type: SRV}+    ipv4-single-target:+    - {TTL: '2100', data: 1.2.3.4, type: A}+- expected_addrs: ['1.2.3.5:1234', '1.2.3.6:1234', '1.2.3.7:1234']+  expected_config_index: null+  record_to_resolve: srv-ipv4-multi-target+  records:+    _grpclb._tcp.srv-ipv4-multi-target:+    - {TTL: '2100', data: 0 0 1234 ipv4-multi-target, type: SRV}+    ipv4-multi-target:+    - {TTL: '2100', data: 1.2.3.5, type: A}+    - {TTL: '2100', data: 1.2.3.6, type: A}+    - {TTL: '2100', data: 1.2.3.7, type: A}+- expected_addrs: ['[2607:f8b0:400a:801::1001]:1234']+  expected_config_index: null+  record_to_resolve: srv-ipv6-single-target+  records:+    _grpclb._tcp.srv-ipv6-single-target:+    - {TTL: '2100', data: 0 0 1234 ipv6-single-target, type: SRV}+    ipv6-single-target:+    - {TTL: '2100', data: '2607:f8b0:400a:801::1001', type: AAAA}+- expected_addrs: ['[2607:f8b0:400a:801::1002]:1234', '[2607:f8b0:400a:801::1003]:1234',+    '[2607:f8b0:400a:801::1004]:1234']+  expected_config_index: null+  record_to_resolve: srv-ipv6-multi-target+  records:+    _grpclb._tcp.srv-ipv6-multi-target:+    - {TTL: '2100', data: 0 0 1234 ipv6-multi-target, type: SRV}+    ipv6-multi-target:+    - {TTL: '2100', data: '2607:f8b0:400a:801::1002', type: AAAA}+    - {TTL: '2100', data: '2607:f8b0:400a:801::1003', type: AAAA}+    - {TTL: '2100', data: '2607:f8b0:400a:801::1004', type: AAAA}+- expected_addrs: ['1.2.3.4:1234']+  expected_config_index: 0+  record_to_resolve: srv-ipv4-simple-service-config+  records:+    _grpclb._tcp.srv-ipv4-simple-service-config:+    - {TTL: '2100', data: 0 0 1234 ipv4-simple-service-config,+      type: SRV}+    ipv4-simple-service-config:+    - {TTL: '2100', data: 1.2.3.4, type: A}+    srv-ipv4-simple-service-config:+    - {TTL: '2100', data: 'grpc_config=[{""serviceConfig"":{""loadBalancingPolicy"":""round_robin"",""methodConfig"":[{""name"":[{""method"":""Foo"",""service"":""SimpleService"",""waitForReady"":true}]}]}}]',+      type: TXT}+- expected_addrs: ['1.2.3.4:443']+  expected_config_index: 0+  record_to_resolve: ipv4-no-srv-simple-service-config+  records:+    ipv4-no-srv-simple-service-config:+    - {TTL: '2100', data: 1.2.3.4, type: A}+    - {TTL: '2100', data: 'grpc_config=[{""serviceConfig"":{""loadBalancingPolicy"":""round_robin"",""methodConfig"":[{""name"":[{""method"":""Foo"",""service"":""NoSrvSimpleService"",""waitForReady"":true}]}]}}]',+      type: TXT}+- expected_addrs: ['1.2.3.4:443']+  expected_config_index: null+  record_to_resolve: ipv4-no-config-for-cpp+  records:+    ipv4-no-config-for-cpp:+    - {TTL: '2100', data: 1.2.3.4, type: A}+    - {TTL: '2100', data: 'grpc_config=[{""clientLanguage"":[""python""],""serviceConfig"":{""loadBalancingPolicy"":""round_robin"",""methodConfig"":[{""name"":[{""method"":""Foo"",""service"":""PythonService"",""waitForReady"":true}]}]}}]',+      type: TXT}+- expected_addrs: ['1.2.3.4:443']+  expected_config_index: null+  record_to_resolve: ipv4-cpp-config-has-zero-percentage+  records:+    ipv4-cpp-config-has-zero-percentage:+    - {TTL: '2100', data: 1.2.3.4, type: A}+    - {TTL: '2100', data: 'grpc_config=[{""percentage"":0,""serviceConfig"":{""loadBalancingPolicy"":""round_robin"",""methodConfig"":[{""name"":[{""method"":""Foo"",""service"":""CppService"",""waitForReady"":true}]}]}}]',+      type: TXT}++naming_end2end_tests_TODO:+- ""TODO: enable these large-txt-record tests once working. (these are txt-records are larger than 255 characters)""","We should also make sure to test the case where the sum total of the TXT records is larger than 512 bytes, because that will cause DNS to fall back from UDP to TCP.  (I was having some problems testing this with the service config code, so this may not work right yet.)",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12210,133750433,2017-08-17T15:39:34Z,test/cpp/naming/naming_end2end_test.cc,"@@ -0,0 +1,297 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/host_port.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>+#include <grpc/support/time.h>+#include <string.h>++#include <gflags/gflags.h>+#include <vector>++#include ""test/cpp/util/test_config.h""++extern ""C"" {+#include ""src/core/ext/filters/client_channel/client_channel.h""+#include ""src/core/ext/filters/client_channel/resolver.h""+#include ""src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.h""+#include ""src/core/ext/filters/client_channel/resolver_registry.h""+#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/iomgr/combiner.h""+#include ""src/core/lib/iomgr/executor.h""+#include ""src/core/lib/iomgr/iomgr.h""+#include ""src/core/lib/iomgr/resolve_address.h""+#include ""src/core/lib/iomgr/sockaddr_utils.h""+#include ""src/core/lib/support/env.h""+#include ""src/core/lib/support/string.h""+#include ""test/core/util/test_config.h""+}++using std::vector;++DEFINE_string(target_name, """", """");+DEFINE_bool(expect_target_is_balancer, true, """");+DEFINE_string(expected_addrs, """", """");+DEFINE_string(expected_chosen_service_config, """", """");+DEFINE_string(local_dns_server_address, """", """");++namespace grpc {+namespace testing {++static vector<std::string> parse_expected_addrs(const char *expected_addrs) {+  std::vector<std::string> out;++  char *p = (char *)expected_addrs;++  if (strlen(p) != 0) {+    for (;;) {+      char *comma = strchr(p, ',');+      if (comma) {+        out.emplace_back(p, comma);+        p = comma + 1;+      } else {+        out.emplace_back(p);+        break;+      }+    }+  }+  if (out.size() == 0) {+    gpr_log(GPR_ERROR,+            ""expected_addrs arg should be a comma-separated list of ip-ports"");+  }+  return out;+}++static gpr_timespec test_deadline(void) {+  return grpc_timeout_seconds_to_deadline(100);+}++typedef struct args_struct {+  gpr_event ev;+  gpr_atm done_atm;+  gpr_mu *mu;+  grpc_pollset *pollset;+  grpc_pollset_set *pollset_set;+  grpc_combiner *lock;+  grpc_channel_args *channel_args;+  bool expect_is_balancer;+  const char *target_name;+  vector<std::string> expected_addrs;+  const char *expected_service_config_string;+} args_struct;++int matches_any(vector<std::string> expected_addrs, const char *addr) {+  for (auto it = expected_addrs.begin(); it != expected_addrs.end(); it++) {+    if (it->compare(addr) == 0) {+      gpr_log(GPR_INFO, ""found a match for expected addresss: %s"", addr);+      return 1;+    } else {+      gpr_log(GPR_INFO, ""expected addresss: %s didn't match found address: %s"",+              it->c_str(), addr);+    }+  }+  gpr_log(GPR_ERROR, ""no match found for found address: %s"", addr);+  return 0;+}++static void do_nothing(grpc_exec_ctx *exec_ctx, void *arg, grpc_error *error) {}++void args_init(grpc_exec_ctx *exec_ctx, args_struct *args) {+  gpr_event_init(&args->ev);+  args->pollset = (grpc_pollset *)gpr_zalloc(grpc_pollset_size());+  grpc_pollset_init(args->pollset, &args->mu);+  args->pollset_set = grpc_pollset_set_create();+  grpc_pollset_set_add_pollset(exec_ctx, args->pollset_set, args->pollset);+  args->lock = grpc_combiner_create();+  gpr_atm_rel_store(&args->done_atm, 0);+  args->channel_args = NULL;+}++void args_finish(grpc_exec_ctx *exec_ctx, args_struct *args) {+  GPR_ASSERT(gpr_event_wait(&args->ev, test_deadline()));+  grpc_pollset_set_del_pollset(exec_ctx, args->pollset_set, args->pollset);+  grpc_pollset_set_destroy(exec_ctx, args->pollset_set);+  grpc_closure do_nothing_cb;+  GRPC_CLOSURE_INIT(&do_nothing_cb, do_nothing, NULL,+                    grpc_schedule_on_exec_ctx);+  grpc_pollset_shutdown(exec_ctx, args->pollset, &do_nothing_cb);+  // exec_ctx needs to be flushed before calling grpc_pollset_destroy()+  grpc_channel_args_destroy(exec_ctx, args->channel_args);+  grpc_exec_ctx_flush(exec_ctx);+  grpc_pollset_destroy(exec_ctx, args->pollset);+  gpr_free(args->pollset);+  GRPC_COMBINER_UNREF(exec_ctx, args->lock, NULL);+}++static gpr_timespec n_sec_deadline(int seconds) {+  return gpr_time_add(gpr_now(GPR_CLOCK_REALTIME),+                      gpr_time_from_seconds(seconds, GPR_TIMESPAN));+}++static void poll_pollset_until_request_done(args_struct *args) {+  gpr_timespec deadline = n_sec_deadline(10);+  while (true) {+    bool done = gpr_atm_acq_load(&args->done_atm) != 0;+    if (done) {+      break;+    }+    gpr_timespec time_left =+        gpr_time_sub(deadline, gpr_now(GPR_CLOCK_REALTIME));+    gpr_log(GPR_DEBUG, ""done=%d, time_left=%"" PRId64 "".%09d"", done,+            time_left.tv_sec, time_left.tv_nsec);+    GPR_ASSERT(gpr_time_cmp(time_left, gpr_time_0(GPR_TIMESPAN)) >= 0);+    grpc_pollset_worker *worker = NULL;+    grpc_exec_ctx exec_ctx = GRPC_EXEC_CTX_INIT;+    gpr_mu_lock(args->mu);+    GRPC_LOG_IF_ERROR(+        ""pollset_work"",+        grpc_pollset_work(&exec_ctx, args->pollset, &worker,+                          gpr_now(GPR_CLOCK_REALTIME), n_sec_deadline(1)));+    gpr_mu_unlock(args->mu);+    grpc_exec_ctx_finish(&exec_ctx);+  }+  gpr_event_set(&args->ev, (void *)1);+}++static void check_service_config_result_locked(grpc_channel_args *channel_args,+                                               args_struct *args) {+  const grpc_arg *service_config_arg =+      grpc_channel_args_find(channel_args, GRPC_ARG_SERVICE_CONFIG);+  if (args->expected_service_config_string != NULL &&+      strlen(args->expected_service_config_string) > 0) {+    GPR_ASSERT(service_config_arg != NULL);+    GPR_ASSERT(service_config_arg->type == GRPC_ARG_STRING);+    char *service_config_string = service_config_arg->value.string;+    if (gpr_stricmp(service_config_string,+                    args->expected_service_config_string) != 0) {+      gpr_log(GPR_ERROR, ""expected service config string: |%s|"",+              args->expected_service_config_string);+      gpr_log(GPR_ERROR, ""got service config string: |%s|"",+              service_config_string);+      GPR_ASSERT(0);+    }+  } else {+    GPR_ASSERT(service_config_arg == NULL);+  }+}++static void check_channel_arg_srv_result_locked(grpc_exec_ctx *exec_ctx,+                                                void *argsp, grpc_error *err) {+  args_struct *args = (args_struct *)argsp;+  grpc_channel_args *channel_args = args->channel_args;+  const grpc_arg *channel_arg =+      grpc_channel_args_find(channel_args, GRPC_ARG_LB_ADDRESSES);+  GPR_ASSERT(channel_arg != NULL);+  GPR_ASSERT(channel_arg->type == GRPC_ARG_POINTER);+  grpc_lb_addresses *addresses =+      (grpc_lb_addresses *)channel_arg->value.pointer.p;+  gpr_log(GPR_INFO, ""num addrs found: %d. expected %"" PRIdPTR,+          (int)addresses->num_addresses, args->expected_addrs.size());++  GPR_ASSERT(addresses->num_addresses == args->expected_addrs.size());+  for (size_t i = 0; i < addresses->num_addresses; i++) {+    grpc_lb_address addr = addresses->addresses[i];+    char *str;+    grpc_sockaddr_to_string(&str, &addr.address, 1 /* normalize */);+    gpr_log(GPR_INFO, ""%s"", str);+    GPR_ASSERT(addr.is_balancer == args->expect_is_balancer);+    GPR_ASSERT(matches_any(args->expected_addrs, str));+    gpr_free(str);+  }++  check_service_config_result_locked(channel_args, args);++  gpr_atm_rel_store(&args->done_atm, 1);+  gpr_mu_lock(args->mu);+  GRPC_LOG_IF_ERROR(""pollset_kick"", grpc_pollset_kick(args->pollset, NULL));+  gpr_mu_unlock(args->mu);+}++static void test_resolves(grpc_exec_ctx *exec_ctx, args_struct *args) {+  char *whole_uri = NULL;+  const char *authority = FLAGS_local_dns_server_address.c_str();+  if (authority != NULL && strlen(authority) > 0) {+    gpr_log(GPR_INFO, ""Specifying authority in uris to: %s"", authority);+  } else {+    authority = """";+  }++  GPR_ASSERT(asprintf(&whole_uri, ""dns://%s/%s"", authority,+                      (char *)args->target_name));+  args->channel_args = NULL;","Please move this into `naming_end2end_test_resolution()`, where the rest of the args struct is initialized.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12210,133751500,2017-08-17T15:43:18Z,test/cpp/naming/naming_end2end_test.cc,"@@ -0,0 +1,297 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/host_port.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>+#include <grpc/support/time.h>+#include <string.h>++#include <gflags/gflags.h>+#include <vector>++#include ""test/cpp/util/test_config.h""++extern ""C"" {+#include ""src/core/ext/filters/client_channel/client_channel.h""+#include ""src/core/ext/filters/client_channel/resolver.h""+#include ""src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.h""+#include ""src/core/ext/filters/client_channel/resolver_registry.h""+#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/iomgr/combiner.h""+#include ""src/core/lib/iomgr/executor.h""+#include ""src/core/lib/iomgr/iomgr.h""+#include ""src/core/lib/iomgr/resolve_address.h""+#include ""src/core/lib/iomgr/sockaddr_utils.h""+#include ""src/core/lib/support/env.h""+#include ""src/core/lib/support/string.h""+#include ""test/core/util/test_config.h""+}++using std::vector;++DEFINE_string(target_name, """", """");+DEFINE_bool(expect_target_is_balancer, true, """");+DEFINE_string(expected_addrs, """", """");+DEFINE_string(expected_chosen_service_config, """", """");+DEFINE_string(local_dns_server_address, """", """");++namespace grpc {+namespace testing {++static vector<std::string> parse_expected_addrs(const char *expected_addrs) {+  std::vector<std::string> out;++  char *p = (char *)expected_addrs;++  if (strlen(p) != 0) {+    for (;;) {+      char *comma = strchr(p, ',');+      if (comma) {+        out.emplace_back(p, comma);+        p = comma + 1;+      } else {+        out.emplace_back(p);+        break;+      }+    }+  }+  if (out.size() == 0) {+    gpr_log(GPR_ERROR,+            ""expected_addrs arg should be a comma-separated list of ip-ports"");+  }+  return out;+}++static gpr_timespec test_deadline(void) {+  return grpc_timeout_seconds_to_deadline(100);+}++typedef struct args_struct {+  gpr_event ev;+  gpr_atm done_atm;+  gpr_mu *mu;+  grpc_pollset *pollset;+  grpc_pollset_set *pollset_set;+  grpc_combiner *lock;+  grpc_channel_args *channel_args;+  bool expect_is_balancer;+  const char *target_name;+  vector<std::string> expected_addrs;+  const char *expected_service_config_string;+} args_struct;++int matches_any(vector<std::string> expected_addrs, const char *addr) {+  for (auto it = expected_addrs.begin(); it != expected_addrs.end(); it++) {+    if (it->compare(addr) == 0) {+      gpr_log(GPR_INFO, ""found a match for expected addresss: %s"", addr);+      return 1;+    } else {+      gpr_log(GPR_INFO, ""expected addresss: %s didn't match found address: %s"",+              it->c_str(), addr);+    }+  }+  gpr_log(GPR_ERROR, ""no match found for found address: %s"", addr);+  return 0;+}++static void do_nothing(grpc_exec_ctx *exec_ctx, void *arg, grpc_error *error) {}++void args_init(grpc_exec_ctx *exec_ctx, args_struct *args) {+  gpr_event_init(&args->ev);+  args->pollset = (grpc_pollset *)gpr_zalloc(grpc_pollset_size());+  grpc_pollset_init(args->pollset, &args->mu);+  args->pollset_set = grpc_pollset_set_create();+  grpc_pollset_set_add_pollset(exec_ctx, args->pollset_set, args->pollset);+  args->lock = grpc_combiner_create();+  gpr_atm_rel_store(&args->done_atm, 0);+  args->channel_args = NULL;+}++void args_finish(grpc_exec_ctx *exec_ctx, args_struct *args) {+  GPR_ASSERT(gpr_event_wait(&args->ev, test_deadline()));+  grpc_pollset_set_del_pollset(exec_ctx, args->pollset_set, args->pollset);+  grpc_pollset_set_destroy(exec_ctx, args->pollset_set);+  grpc_closure do_nothing_cb;+  GRPC_CLOSURE_INIT(&do_nothing_cb, do_nothing, NULL,+                    grpc_schedule_on_exec_ctx);+  grpc_pollset_shutdown(exec_ctx, args->pollset, &do_nothing_cb);+  // exec_ctx needs to be flushed before calling grpc_pollset_destroy()+  grpc_channel_args_destroy(exec_ctx, args->channel_args);+  grpc_exec_ctx_flush(exec_ctx);+  grpc_pollset_destroy(exec_ctx, args->pollset);+  gpr_free(args->pollset);+  GRPC_COMBINER_UNREF(exec_ctx, args->lock, NULL);+}++static gpr_timespec n_sec_deadline(int seconds) {+  return gpr_time_add(gpr_now(GPR_CLOCK_REALTIME),+                      gpr_time_from_seconds(seconds, GPR_TIMESPAN));+}++static void poll_pollset_until_request_done(args_struct *args) {+  gpr_timespec deadline = n_sec_deadline(10);+  while (true) {+    bool done = gpr_atm_acq_load(&args->done_atm) != 0;+    if (done) {+      break;+    }+    gpr_timespec time_left =+        gpr_time_sub(deadline, gpr_now(GPR_CLOCK_REALTIME));+    gpr_log(GPR_DEBUG, ""done=%d, time_left=%"" PRId64 "".%09d"", done,+            time_left.tv_sec, time_left.tv_nsec);+    GPR_ASSERT(gpr_time_cmp(time_left, gpr_time_0(GPR_TIMESPAN)) >= 0);+    grpc_pollset_worker *worker = NULL;+    grpc_exec_ctx exec_ctx = GRPC_EXEC_CTX_INIT;+    gpr_mu_lock(args->mu);+    GRPC_LOG_IF_ERROR(+        ""pollset_work"",+        grpc_pollset_work(&exec_ctx, args->pollset, &worker,+                          gpr_now(GPR_CLOCK_REALTIME), n_sec_deadline(1)));+    gpr_mu_unlock(args->mu);+    grpc_exec_ctx_finish(&exec_ctx);+  }+  gpr_event_set(&args->ev, (void *)1);+}++static void check_service_config_result_locked(grpc_channel_args *channel_args,+                                               args_struct *args) {+  const grpc_arg *service_config_arg =+      grpc_channel_args_find(channel_args, GRPC_ARG_SERVICE_CONFIG);+  if (args->expected_service_config_string != NULL &&+      strlen(args->expected_service_config_string) > 0) {+    GPR_ASSERT(service_config_arg != NULL);+    GPR_ASSERT(service_config_arg->type == GRPC_ARG_STRING);+    char *service_config_string = service_config_arg->value.string;+    if (gpr_stricmp(service_config_string,+                    args->expected_service_config_string) != 0) {+      gpr_log(GPR_ERROR, ""expected service config string: |%s|"",+              args->expected_service_config_string);+      gpr_log(GPR_ERROR, ""got service config string: |%s|"",+              service_config_string);+      GPR_ASSERT(0);+    }+  } else {+    GPR_ASSERT(service_config_arg == NULL);+  }+}++static void check_channel_arg_srv_result_locked(grpc_exec_ctx *exec_ctx,+                                                void *argsp, grpc_error *err) {+  args_struct *args = (args_struct *)argsp;+  grpc_channel_args *channel_args = args->channel_args;+  const grpc_arg *channel_arg =+      grpc_channel_args_find(channel_args, GRPC_ARG_LB_ADDRESSES);+  GPR_ASSERT(channel_arg != NULL);+  GPR_ASSERT(channel_arg->type == GRPC_ARG_POINTER);+  grpc_lb_addresses *addresses =+      (grpc_lb_addresses *)channel_arg->value.pointer.p;+  gpr_log(GPR_INFO, ""num addrs found: %d. expected %"" PRIdPTR,+          (int)addresses->num_addresses, args->expected_addrs.size());++  GPR_ASSERT(addresses->num_addresses == args->expected_addrs.size());+  for (size_t i = 0; i < addresses->num_addresses; i++) {+    grpc_lb_address addr = addresses->addresses[i];+    char *str;+    grpc_sockaddr_to_string(&str, &addr.address, 1 /* normalize */);+    gpr_log(GPR_INFO, ""%s"", str);+    GPR_ASSERT(addr.is_balancer == args->expect_is_balancer);","I think we need the ability to set `expect_is_balancer` on a per-address basis.  In particular, we should test the case where the resolver returns both balancer and backend addresses for a given name, as described here:https://github.com/grpc/proposal/blob/master/A5-grpclb-in-dns.md#future-work-providing-both-server-and-balancer-results",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12210,133755203,2017-08-17T15:56:53Z,test/cpp/naming/naming_end2end_test.cc,"@@ -0,0 +1,297 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/host_port.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>+#include <grpc/support/time.h>+#include <string.h>++#include <gflags/gflags.h>+#include <vector>++#include ""test/cpp/util/test_config.h""++extern ""C"" {+#include ""src/core/ext/filters/client_channel/client_channel.h""+#include ""src/core/ext/filters/client_channel/resolver.h""+#include ""src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.h""+#include ""src/core/ext/filters/client_channel/resolver_registry.h""+#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/iomgr/combiner.h""+#include ""src/core/lib/iomgr/executor.h""+#include ""src/core/lib/iomgr/iomgr.h""+#include ""src/core/lib/iomgr/resolve_address.h""+#include ""src/core/lib/iomgr/sockaddr_utils.h""+#include ""src/core/lib/support/env.h""+#include ""src/core/lib/support/string.h""+#include ""test/core/util/test_config.h""+}++using std::vector;++DEFINE_string(target_name, """", """");+DEFINE_bool(expect_target_is_balancer, true, """");+DEFINE_string(expected_addrs, """", """");+DEFINE_string(expected_chosen_service_config, """", """");+DEFINE_string(local_dns_server_address, """", """");++namespace grpc {+namespace testing {++static vector<std::string> parse_expected_addrs(const char *expected_addrs) {+  std::vector<std::string> out;++  char *p = (char *)expected_addrs;++  if (strlen(p) != 0) {+    for (;;) {+      char *comma = strchr(p, ',');+      if (comma) {+        out.emplace_back(p, comma);+        p = comma + 1;+      } else {+        out.emplace_back(p);+        break;+      }+    }+  }+  if (out.size() == 0) {+    gpr_log(GPR_ERROR,+            ""expected_addrs arg should be a comma-separated list of ip-ports"");+  }+  return out;+}++static gpr_timespec test_deadline(void) {+  return grpc_timeout_seconds_to_deadline(100);+}++typedef struct args_struct {+  gpr_event ev;+  gpr_atm done_atm;+  gpr_mu *mu;+  grpc_pollset *pollset;+  grpc_pollset_set *pollset_set;+  grpc_combiner *lock;+  grpc_channel_args *channel_args;+  bool expect_is_balancer;+  const char *target_name;+  vector<std::string> expected_addrs;+  const char *expected_service_config_string;+} args_struct;++int matches_any(vector<std::string> expected_addrs, const char *addr) {+  for (auto it = expected_addrs.begin(); it != expected_addrs.end(); it++) {+    if (it->compare(addr) == 0) {+      gpr_log(GPR_INFO, ""found a match for expected addresss: %s"", addr);+      return 1;+    } else {+      gpr_log(GPR_INFO, ""expected addresss: %s didn't match found address: %s"",+              it->c_str(), addr);+    }+  }+  gpr_log(GPR_ERROR, ""no match found for found address: %s"", addr);+  return 0;+}++static void do_nothing(grpc_exec_ctx *exec_ctx, void *arg, grpc_error *error) {}++void args_init(grpc_exec_ctx *exec_ctx, args_struct *args) {+  gpr_event_init(&args->ev);+  args->pollset = (grpc_pollset *)gpr_zalloc(grpc_pollset_size());+  grpc_pollset_init(args->pollset, &args->mu);+  args->pollset_set = grpc_pollset_set_create();+  grpc_pollset_set_add_pollset(exec_ctx, args->pollset_set, args->pollset);+  args->lock = grpc_combiner_create();+  gpr_atm_rel_store(&args->done_atm, 0);+  args->channel_args = NULL;+}++void args_finish(grpc_exec_ctx *exec_ctx, args_struct *args) {+  GPR_ASSERT(gpr_event_wait(&args->ev, test_deadline()));+  grpc_pollset_set_del_pollset(exec_ctx, args->pollset_set, args->pollset);+  grpc_pollset_set_destroy(exec_ctx, args->pollset_set);+  grpc_closure do_nothing_cb;+  GRPC_CLOSURE_INIT(&do_nothing_cb, do_nothing, NULL,+                    grpc_schedule_on_exec_ctx);+  grpc_pollset_shutdown(exec_ctx, args->pollset, &do_nothing_cb);+  // exec_ctx needs to be flushed before calling grpc_pollset_destroy()+  grpc_channel_args_destroy(exec_ctx, args->channel_args);+  grpc_exec_ctx_flush(exec_ctx);+  grpc_pollset_destroy(exec_ctx, args->pollset);+  gpr_free(args->pollset);+  GRPC_COMBINER_UNREF(exec_ctx, args->lock, NULL);+}++static gpr_timespec n_sec_deadline(int seconds) {+  return gpr_time_add(gpr_now(GPR_CLOCK_REALTIME),+                      gpr_time_from_seconds(seconds, GPR_TIMESPAN));+}++static void poll_pollset_until_request_done(args_struct *args) {+  gpr_timespec deadline = n_sec_deadline(10);+  while (true) {+    bool done = gpr_atm_acq_load(&args->done_atm) != 0;+    if (done) {+      break;+    }+    gpr_timespec time_left =+        gpr_time_sub(deadline, gpr_now(GPR_CLOCK_REALTIME));+    gpr_log(GPR_DEBUG, ""done=%d, time_left=%"" PRId64 "".%09d"", done,+            time_left.tv_sec, time_left.tv_nsec);+    GPR_ASSERT(gpr_time_cmp(time_left, gpr_time_0(GPR_TIMESPAN)) >= 0);+    grpc_pollset_worker *worker = NULL;+    grpc_exec_ctx exec_ctx = GRPC_EXEC_CTX_INIT;+    gpr_mu_lock(args->mu);+    GRPC_LOG_IF_ERROR(+        ""pollset_work"",+        grpc_pollset_work(&exec_ctx, args->pollset, &worker,+                          gpr_now(GPR_CLOCK_REALTIME), n_sec_deadline(1)));+    gpr_mu_unlock(args->mu);+    grpc_exec_ctx_finish(&exec_ctx);+  }+  gpr_event_set(&args->ev, (void *)1);+}++static void check_service_config_result_locked(grpc_channel_args *channel_args,+                                               args_struct *args) {+  const grpc_arg *service_config_arg =+      grpc_channel_args_find(channel_args, GRPC_ARG_SERVICE_CONFIG);+  if (args->expected_service_config_string != NULL &&+      strlen(args->expected_service_config_string) > 0) {+    GPR_ASSERT(service_config_arg != NULL);+    GPR_ASSERT(service_config_arg->type == GRPC_ARG_STRING);+    char *service_config_string = service_config_arg->value.string;+    if (gpr_stricmp(service_config_string,",I don't think we want case-insensitive comparison here -- the JSON data is compared in a case-sensitive way.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,133764537,2017-08-17T16:33:20Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -668,9 +684,23 @@ static bool pick_from_internal_rr_locked(  static grpc_lb_policy_args *lb_policy_args_create(grpc_exec_ctx *exec_ctx,                                                   glb_lb_policy *glb_policy) {-  grpc_lb_addresses *addresses =-      process_serverlist_locked(exec_ctx, glb_policy->serverlist);+  GPR_ASSERT(glb_policy->serverlist != NULL || +             glb_policy->fallback_backend_addresses != NULL);+  grpc_lb_addresses *addresses;+  if (glb_policy->serverlist != NULL) {+    GPR_ASSERT(glb_policy->serverlist->num_servers > 0);+    addresses = process_serverlist_locked(exec_ctx, glb_policy->serverlist);+  } else if (glb_policy->fallback_backend_addresses != NULL) {","Can probably remove the `if` here -- if we get here and do not have a response from the balancer, then we should unconditionally use the addresses returned by the resolver.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/12104,133809469,2017-08-17T19:40:27Z,src/core/ext/filters/load_reporting/load_reporting.c,"@@ -42,9 +42,13 @@ static bool maybe_add_load_reporting_filter(grpc_exec_ctx *exec_ctx,                                             void *arg) {   const grpc_channel_args *args =       grpc_channel_stack_builder_get_channel_arguments(builder);-  if (is_load_reporting_enabled(args)) {-    return grpc_channel_stack_builder_prepend_filter(-        builder, (const grpc_channel_filter *)arg, NULL, NULL);+  const grpc_channel_filter *filter = arg;+  grpc_channel_stack_builder_iterator *it = grpc_channel_stack_builder_iterator_find(builder, filter->name);+  const bool already_has_load_reporting_filter = !grpc_channel_stack_builder_iterator_is_end(it);+  grpc_channel_stack_builder_iterator_destroy(it);+  if (is_load_reporting_enabled(args) && !already_has_load_reporting_filter) {","The test's initial call to `::testing::InitGoogleTest()` will trigger all (internal) module initializers. One of them is `InitGRPC()`, which will register the internal version of the load reporting plugin.The OSS version, from `grpc_init()` is, in this case, initialized later as part of instantiating `ServerCompletionQueue` because [`CompletionQueue` inherits from `GrpcLibraryCodegen`](https://github.com/grpc/grpc/blob/f4af6eb2f44e7a9fa08e5e427a5e5f9d1ba2acd2/include/grpc%2B%2B/impl/codegen/completion_queue.h#L86), whose job is precisely to [call `grpc_init()`](https://github.com/grpc/grpc/blob/5253c8f9a899450397a5e46e4923d01ac9a66a27/include/grpc%2B%2B/impl/codegen/grpc_library.h#L44). `ServerCompletionQueue` is not instantiated until the test needs to create a server instance.Basically, internal happens first because the (internal) testing framework initializes internal modules first. ",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/11566,133810539,2017-08-17T19:45:32Z,src/core/lib/iomgr/call_combiner.h,"@@ -0,0 +1,104 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_IOMGR_CALL_COMBINER_H+#define GRPC_CORE_LIB_IOMGR_CALL_COMBINER_H++#include <stddef.h>++#include <grpc/support/atm.h>++#include ""src/core/lib/iomgr/closure.h""+#include ""src/core/lib/iomgr/exec_ctx.h""+#include ""src/core/lib/support/mpscq.h""++// A simple, lock-free mechanism for serializing activity related to a+// single call.  This is similar to a combiner but is more lightweight.+//+// It requires the callback (or, in the common case where the callback+// actually kicks off a chain of callbacks, the last callback in that+// chain) to explicitly indicate (by calling GRPC_CALL_COMBINER_STOP())+// when it is done with the action that was kicked off by the original+// callback.++extern grpc_tracer_flag grpc_call_combiner_trace;++typedef struct {+  gpr_atm size;  // size_t, num closures in queue or currently executing+  gpr_mpscq queue;+  // Either 0 (if not cancelled and no cancellation closure set),+  // a grpc_closure* (if the lowest bit is 0),+  // or a grpc_error* (if the lowest bit is 1).+  gpr_atm cancel_state;+} grpc_call_combiner;++// Assumes memory was initialized to zero.+void grpc_call_combiner_init(grpc_call_combiner* call_combiner);++void grpc_call_combiner_destroy(grpc_call_combiner* call_combiner);++#ifndef NDEBUG+#define GRPC_CALL_COMBINER_START(exec_ctx, call_combiner, closure, error,   \+                                 reason)                                    \+  grpc_call_combiner_start((exec_ctx), (call_combiner), (closure), (error), \+                           __FILE__, __LINE__, (reason))+#define GRPC_CALL_COMBINER_STOP(exec_ctx, call_combiner, reason)           \+  grpc_call_combiner_stop((exec_ctx), (call_combiner), __FILE__, __LINE__, \+                          (reason))+/// Starts processing \a closure on \a call_combiner.+void grpc_call_combiner_start(grpc_exec_ctx* exec_ctx,+                              grpc_call_combiner* call_combiner,+                              grpc_closure* closure, grpc_error* error,+                              const char* file, int line, const char* reason);+/// Yields the call combiner to the next closure in the queue, if any.+void grpc_call_combiner_stop(grpc_exec_ctx* exec_ctx,+                             grpc_call_combiner* call_combiner,+                             const char* file, int line, const char* reason);+#else+#define GRPC_CALL_COMBINER_START(exec_ctx, call_combiner, closure, error,   \+                                 reason)                                    \+  grpc_call_combiner_start((exec_ctx), (call_combiner), (closure), (error), \+                           (reason))+#define GRPC_CALL_COMBINER_STOP(exec_ctx, call_combiner, reason) \+  grpc_call_combiner_stop((exec_ctx), (call_combiner), (reason))+/// Starts processing \a closure on \a call_combiner.+void grpc_call_combiner_start(grpc_exec_ctx* exec_ctx,+                              grpc_call_combiner* call_combiner,+                              grpc_closure* closure, grpc_error* error,+                              const char* reason);+/// Yields the call combiner to the next closure in the queue, if any.+void grpc_call_combiner_stop(grpc_exec_ctx* exec_ctx,+                             grpc_call_combiner* call_combiner,+                             const char* reason);+#endif",Is there a strong reason why the function declarations should be different for NDEBUG or debug? I can understand not using those parameters in the NDEBUG case but removing them makes the function type different in the two cases which can have an impact on their usability if we ever need them for templates or function pointers.,
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/11566,133811842,2017-08-17T19:52:02Z,src/core/lib/iomgr/call_combiner.h,"@@ -0,0 +1,104 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_IOMGR_CALL_COMBINER_H+#define GRPC_CORE_LIB_IOMGR_CALL_COMBINER_H++#include <stddef.h>++#include <grpc/support/atm.h>++#include ""src/core/lib/iomgr/closure.h""+#include ""src/core/lib/iomgr/exec_ctx.h""+#include ""src/core/lib/support/mpscq.h""++// A simple, lock-free mechanism for serializing activity related to a+// single call.  This is similar to a combiner but is more lightweight.+//+// It requires the callback (or, in the common case where the callback+// actually kicks off a chain of callbacks, the last callback in that+// chain) to explicitly indicate (by calling GRPC_CALL_COMBINER_STOP())+// when it is done with the action that was kicked off by the original+// callback.++extern grpc_tracer_flag grpc_call_combiner_trace;++typedef struct {+  gpr_atm size;  // size_t, num closures in queue or currently executing+  gpr_mpscq queue;+  // Either 0 (if not cancelled and no cancellation closure set),+  // a grpc_closure* (if the lowest bit is 0),+  // or a grpc_error* (if the lowest bit is 1).+  gpr_atm cancel_state;+} grpc_call_combiner;++// Assumes memory was initialized to zero.+void grpc_call_combiner_init(grpc_call_combiner* call_combiner);++void grpc_call_combiner_destroy(grpc_call_combiner* call_combiner);++#ifndef NDEBUG+#define GRPC_CALL_COMBINER_START(exec_ctx, call_combiner, closure, error,   \+                                 reason)                                    \+  grpc_call_combiner_start((exec_ctx), (call_combiner), (closure), (error), \+                           __FILE__, __LINE__, (reason))+#define GRPC_CALL_COMBINER_STOP(exec_ctx, call_combiner, reason)           \+  grpc_call_combiner_stop((exec_ctx), (call_combiner), __FILE__, __LINE__, \+                          (reason))+/// Starts processing \a closure on \a call_combiner.+void grpc_call_combiner_start(grpc_exec_ctx* exec_ctx,+                              grpc_call_combiner* call_combiner,+                              grpc_closure* closure, grpc_error* error,+                              const char* file, int line, const char* reason);+/// Yields the call combiner to the next closure in the queue, if any.+void grpc_call_combiner_stop(grpc_exec_ctx* exec_ctx,+                             grpc_call_combiner* call_combiner,+                             const char* file, int line, const char* reason);+#else+#define GRPC_CALL_COMBINER_START(exec_ctx, call_combiner, closure, error,   \+                                 reason)                                    \+  grpc_call_combiner_start((exec_ctx), (call_combiner), (closure), (error), \+                           (reason))+#define GRPC_CALL_COMBINER_STOP(exec_ctx, call_combiner, reason) \+  grpc_call_combiner_stop((exec_ctx), (call_combiner), (reason))+/// Starts processing \a closure on \a call_combiner.+void grpc_call_combiner_start(grpc_exec_ctx* exec_ctx,+                              grpc_call_combiner* call_combiner,+                              grpc_closure* closure, grpc_error* error,+                              const char* reason);+/// Yields the call combiner to the next closure in the queue, if any.+void grpc_call_combiner_stop(grpc_exec_ctx* exec_ctx,+                             grpc_call_combiner* call_combiner,+                             const char* reason);+#endif","Drive by comment: we do this a lot, so if we should stop, this would not be the best place to fix it- https://github.com/grpc/grpc/blob/master/src/core/lib/iomgr/error.h#L158- https://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/lb_policy.h#L106- there are a lot more",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,133811941,2017-08-17T19:52:26Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1783,6 +1861,19 @@ static void glb_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,         &glb_policy->lb_channel_connectivity,         &glb_policy->lb_channel_on_connectivity_changed, NULL);   }++  // Propagate update to fallback_backend_addresses if we haven't heard from +  // the balancer.+  if (glb_policy->serverlist == NULL) {+    grpc_lb_addresses *backends = grpc_lb_addresses_extract_backends(addresses);","Okay.  But similar to my comment on line 693, we should still not have to check to check for the fallback addresses being NULL here -- we should make sure that never happens.  Otherwise, we need more logic here to *remove* addresses from the RR policy -- for example, consider the case where the previous fallback list had one or more backends, but this new list does not have any backends.  In that case, we would need to remove the old backends from the RR policy.  But if we can just pass in an empty list, everything should work fine.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,133812562,2017-08-17T19:55:27Z,src/core/ext/filters/client_channel/lb_policy_factory.h,"@@ -66,9 +66,18 @@ typedef struct grpc_lb_addresses { grpc_lb_addresses *grpc_lb_addresses_create(     size_t num_addresses, const grpc_lb_user_data_vtable *user_data_vtable); +/** Deep copy the address from \a src to \a dest. */+void grpc_lb_address_copy(grpc_lb_address* dest, const grpc_lb_address* src,  ","It seems a bit ugly that we need to pass the user_data_vtable into this function, since it's not really part of the object being copied.  This suggests that this function is operating at a granularity that should not be exposed beyond this module.Since this isn't being used anywhere outside of this module, I suggest just making this a static function and not exposing it.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,133817601,2017-08-17T20:16:58Z,src/core/ext/filters/client_channel/lb_policy_factory.c,"@@ -36,24 +36,50 @@ grpc_lb_addresses* grpc_lb_addresses_create(   return addresses; } +void grpc_lb_address_copy(grpc_lb_address* dest, const grpc_lb_address* src,  +                          const grpc_lb_user_data_vtable* user_data_vtable) {+  if (src->user_data != NULL) GPR_ASSERT(user_data_vtable != NULL);+  memcpy(dest, src, sizeof(grpc_lb_address));+  if (src->balancer_name != NULL) {+    dest->balancer_name = gpr_strdup(src->balancer_name);+  }+  if (src->user_data != NULL) {+    dest->user_data = user_data_vtable->copy(src->user_data);+  }+}+ grpc_lb_addresses* grpc_lb_addresses_copy(const grpc_lb_addresses* addresses) {   grpc_lb_addresses* new_addresses = grpc_lb_addresses_create(       addresses->num_addresses, addresses->user_data_vtable);-  memcpy(new_addresses->addresses, addresses->addresses,-         sizeof(grpc_lb_address) * addresses->num_addresses);   for (size_t i = 0; i < addresses->num_addresses; ++i) {-    if (new_addresses->addresses[i].balancer_name != NULL) {-      new_addresses->addresses[i].balancer_name =-          gpr_strdup(new_addresses->addresses[i].balancer_name);-    }-    if (new_addresses->addresses[i].user_data != NULL) {-      new_addresses->addresses[i].user_data = addresses->user_data_vtable->copy(-          new_addresses->addresses[i].user_data);-    }+    grpc_lb_address_copy(&new_addresses->addresses[i], &addresses->addresses[i], +                         addresses->user_data_vtable);   }   return new_addresses; } +grpc_lb_addresses* grpc_lb_addresses_extract_backends(+    const grpc_lb_addresses* addresses) {+  // First run: get the number of backends.+  size_t num_backend_addrs = 0;+  for (size_t i = 0; i < addresses->num_addresses; ++i) {+    if (!addresses->addresses[i].is_balancer) ++num_backend_addrs;+  }+  if (num_backend_addrs == 0) return NULL;+  +  // Second run: copy the backends.+  grpc_lb_addresses *backends = grpc_lb_addresses_create(num_backend_addrs, +                                                         NULL);",Need to pass `addresses->user_data_vtable` here.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,133817758,2017-08-17T20:17:49Z,src/core/ext/filters/client_channel/lb_policy_factory.h,"@@ -66,9 +66,18 @@ typedef struct grpc_lb_addresses { grpc_lb_addresses *grpc_lb_addresses_create(     size_t num_addresses, const grpc_lb_user_data_vtable *user_data_vtable); +/** Deep copy the address from \a src to \a dest. */+void grpc_lb_address_copy(grpc_lb_address* dest, const grpc_lb_address* src,  +                          const grpc_lb_user_data_vtable* user_data_vtable);+ /** Creates a copy of \a addresses. */ grpc_lb_addresses *grpc_lb_addresses_copy(const grpc_lb_addresses *addresses); +/** Extract the backend addresses and return them in a new \a +    grpc_lb_addresses. */+grpc_lb_addresses *grpc_lb_addresses_extract_backends(","Suggest calling this `grpc_lb_addresses_copy_backends()`.Alternatively, instead of creating a new method for this, we could just add a parameter to `grpc_lb_addresses_copy()` that says whether to copy only backend addresses.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,133817939,2017-08-17T20:18:35Z,src/core/ext/filters/client_channel/lb_policy_factory.c,"@@ -36,24 +36,50 @@ grpc_lb_addresses* grpc_lb_addresses_create(   return addresses; } +void grpc_lb_address_copy(grpc_lb_address* dest, const grpc_lb_address* src,  +                          const grpc_lb_user_data_vtable* user_data_vtable) {+  if (src->user_data != NULL) GPR_ASSERT(user_data_vtable != NULL);+  memcpy(dest, src, sizeof(grpc_lb_address));+  if (src->balancer_name != NULL) {+    dest->balancer_name = gpr_strdup(src->balancer_name);+  }+  if (src->user_data != NULL) {+    dest->user_data = user_data_vtable->copy(src->user_data);+  }+}+ grpc_lb_addresses* grpc_lb_addresses_copy(const grpc_lb_addresses* addresses) {   grpc_lb_addresses* new_addresses = grpc_lb_addresses_create(       addresses->num_addresses, addresses->user_data_vtable);-  memcpy(new_addresses->addresses, addresses->addresses,-         sizeof(grpc_lb_address) * addresses->num_addresses);   for (size_t i = 0; i < addresses->num_addresses; ++i) {-    if (new_addresses->addresses[i].balancer_name != NULL) {-      new_addresses->addresses[i].balancer_name =-          gpr_strdup(new_addresses->addresses[i].balancer_name);-    }-    if (new_addresses->addresses[i].user_data != NULL) {-      new_addresses->addresses[i].user_data = addresses->user_data_vtable->copy(-          new_addresses->addresses[i].user_data);-    }+    grpc_lb_address_copy(&new_addresses->addresses[i], &addresses->addresses[i], +                         addresses->user_data_vtable);   }   return new_addresses; } +grpc_lb_addresses* grpc_lb_addresses_extract_backends(+    const grpc_lb_addresses* addresses) {+  // First run: get the number of backends.+  size_t num_backend_addrs = 0;+  for (size_t i = 0; i < addresses->num_addresses; ++i) {+    if (!addresses->addresses[i].is_balancer) ++num_backend_addrs;+  }+  if (num_backend_addrs == 0) return NULL;","In this case, let's return an empty list instead of returning NULL.I think if we just remove this line, it will do the right thing.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,133834103,2017-08-17T21:29:24Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -668,9 +684,23 @@ static bool pick_from_internal_rr_locked(  static grpc_lb_policy_args *lb_policy_args_create(grpc_exec_ctx *exec_ctx,                                                   glb_lb_policy *glb_policy) {-  grpc_lb_addresses *addresses =-      process_serverlist_locked(exec_ctx, glb_policy->serverlist);+  GPR_ASSERT(glb_policy->serverlist != NULL || +             glb_policy->fallback_backend_addresses != NULL);+  grpc_lb_addresses *addresses;+  if (glb_policy->serverlist != NULL) {+    GPR_ASSERT(glb_policy->serverlist->num_servers > 0);+    addresses = process_serverlist_locked(exec_ctx, glb_policy->serverlist);+  } else if (glb_policy->fallback_backend_addresses != NULL) {","I see. I thought that if even the fallback can't work, we would trigger some assertion to give up. But it seems that we prefer waiting than terminating when things can't be done right away. RR can handle empty address list by keeping the requested picks pending, so it's fair enough to pass an empty list to it when we don't have any backends in the resolution. ",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,133838317,2017-08-17T21:51:05Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1783,6 +1861,19 @@ static void glb_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,         &glb_policy->lb_channel_connectivity,         &glb_policy->lb_channel_on_connectivity_changed, NULL);   }++  // Propagate update to fallback_backend_addresses if we haven't heard from +  // the balancer.+  if (glb_policy->serverlist == NULL) {+    grpc_lb_addresses *backends = grpc_lb_addresses_extract_backends(addresses);","I see.Maybe a relative question: an empty address list is totally different from a [missing GRPC_ARG_LB_ADDRESSES](https://github.com/grpc/grpc/blob/106d175c8c4e038960a9f3304fdfe36450fdf784/src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c#L1754), right?",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,133842235,2017-08-17T22:12:16Z,src/core/ext/filters/client_channel/lb_policy_factory.h,"@@ -66,9 +66,18 @@ typedef struct grpc_lb_addresses { grpc_lb_addresses *grpc_lb_addresses_create(     size_t num_addresses, const grpc_lb_user_data_vtable *user_data_vtable); +/** Deep copy the address from \a src to \a dest. */+void grpc_lb_address_copy(grpc_lb_address* dest, const grpc_lb_address* src,  +                          const grpc_lb_user_data_vtable* user_data_vtable);+ /** Creates a copy of \a addresses. */ grpc_lb_addresses *grpc_lb_addresses_copy(const grpc_lb_addresses *addresses); +/** Extract the backend addresses and return them in a new \a +    grpc_lb_addresses. */+grpc_lb_addresses *grpc_lb_addresses_extract_backends(",I prefer adding a parameter to `grpc_lb_addresses_copy()`. I didn't do this because it changes the existing interface. Will such a change affect others?,
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,133843629,2017-08-17T22:21:14Z,src/core/ext/filters/client_channel/lb_policy_factory.c,"@@ -36,24 +36,50 @@ grpc_lb_addresses* grpc_lb_addresses_create(   return addresses; } +void grpc_lb_address_copy(grpc_lb_address* dest, const grpc_lb_address* src,  +                          const grpc_lb_user_data_vtable* user_data_vtable) {+  if (src->user_data != NULL) GPR_ASSERT(user_data_vtable != NULL);+  memcpy(dest, src, sizeof(grpc_lb_address));+  if (src->balancer_name != NULL) {+    dest->balancer_name = gpr_strdup(src->balancer_name);+  }+  if (src->user_data != NULL) {+    dest->user_data = user_data_vtable->copy(src->user_data);+  }+}+ grpc_lb_addresses* grpc_lb_addresses_copy(const grpc_lb_addresses* addresses) {   grpc_lb_addresses* new_addresses = grpc_lb_addresses_create(       addresses->num_addresses, addresses->user_data_vtable);-  memcpy(new_addresses->addresses, addresses->addresses,-         sizeof(grpc_lb_address) * addresses->num_addresses);   for (size_t i = 0; i < addresses->num_addresses; ++i) {-    if (new_addresses->addresses[i].balancer_name != NULL) {-      new_addresses->addresses[i].balancer_name =-          gpr_strdup(new_addresses->addresses[i].balancer_name);-    }-    if (new_addresses->addresses[i].user_data != NULL) {-      new_addresses->addresses[i].user_data = addresses->user_data_vtable->copy(-          new_addresses->addresses[i].user_data);-    }+    grpc_lb_address_copy(&new_addresses->addresses[i], &addresses->addresses[i], +                         addresses->user_data_vtable);   }   return new_addresses; } +grpc_lb_addresses* grpc_lb_addresses_extract_backends(+    const grpc_lb_addresses* addresses) {+  // First run: get the number of backends.+  size_t num_backend_addrs = 0;+  for (size_t i = 0; i < addresses->num_addresses; ++i) {+    if (!addresses->addresses[i].is_balancer) ++num_backend_addrs;+  }+  if (num_backend_addrs == 0) return NULL;+  +  // Second run: copy the backends.+  grpc_lb_addresses *backends = grpc_lb_addresses_create(num_backend_addrs, +                                                         NULL);","AFAIK, `user_data` is only meaningful when the addresses are returned by the balancer(?). How will the addresses from the resolver use `user_data` or `user_data_vtable`? When can `user_data` and `user_data_vtable` be NULL?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,133847650,2017-08-17T22:48:39Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -668,9 +684,23 @@ static bool pick_from_internal_rr_locked(  static grpc_lb_policy_args *lb_policy_args_create(grpc_exec_ctx *exec_ctx,                                                   glb_lb_policy *glb_policy) {-  grpc_lb_addresses *addresses =-      process_serverlist_locked(exec_ctx, glb_policy->serverlist);+  GPR_ASSERT(glb_policy->serverlist != NULL || +             glb_policy->fallback_backend_addresses != NULL);+  grpc_lb_addresses *addresses;+  if (glb_policy->serverlist != NULL) {+    GPR_ASSERT(glb_policy->serverlist->num_servers > 0);+    addresses = process_serverlist_locked(exec_ctx, glb_policy->serverlist);+  } else if (glb_policy->fallback_backend_addresses != NULL) {","We *never* want to trigger an assertion, because an assertion will cause the process to crash immediately.  That's very bad behavior on the part of a library, because it doesn't give the application any opportunity to clean up or handle the error or anything else -- it just causes the program to crash immediately.  Assertions should only be used for things that we think are true invariants (i.e., things that should actually be impossible).  The idea is that if something ""impossible"" does happen, then we're going to crash anyway, so we'd rather trigger an assertion telling us about the real problem than having some indirect corruption later that's harder to track down (e.g., dereferencing a NULL pointer).",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,133849109,2017-08-17T22:59:51Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1783,6 +1861,19 @@ static void glb_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,         &glb_policy->lb_channel_connectivity,         &glb_policy->lb_channel_on_connectivity_changed, NULL);   }++  // Propagate update to fallback_backend_addresses if we haven't heard from +  // the balancer.+  if (glb_policy->serverlist == NULL) {+    grpc_lb_addresses *backends = grpc_lb_addresses_extract_backends(addresses);","The check you pointed at is a great example of something that used to be an assertion, but we changed it to handle the case differently because our fuzzer tests showed us that it was a possible issue.  In practice, the resolver is responsible for always returning this argument, so we were originally treating it like an invariant.  However, even though we don't expect this to happen in the real world, someone could potentially plug in a poorly written resolver that does fail to return that arg, so the LB policy code needs to handle that.An empty address list may or may not be the same sort of case, depending on the context.If you are looking at the raw list returned by the resolver, then it's the same case.  In practice, the resolver should never return an empty list either; it should not return at all if the name does not resolve.  But, of course, a poorly written resolver could do the wrong thing here, too, so it's basically the same case as the arg being missing.In contrast, if you are looking at the code in this PR, where we are extracting only the backend addresses from the list, then it's totally expected for the list to be empty.  It's totally legal for a resolver to return a list that contains only balancer addresses, so we need to be prepared to handle that case.To be clear, while we should not crash in either case, the distinction I'm drawing here is that the first case is simply us being defensive to protect against people plugging in poorly written resolver implementations, whereas the second case is us handling a perfectly normal, expected situation.  The second case is therefore much more important to get right.  We ideally don't want to crash in the first case either, but if we did, it would basically be the fault of whoever wrote the bad resolver implementation, so it wouldn't be the end of the world.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,133849513,2017-08-17T23:03:05Z,src/core/ext/filters/client_channel/lb_policy_factory.h,"@@ -66,9 +66,18 @@ typedef struct grpc_lb_addresses { grpc_lb_addresses *grpc_lb_addresses_create(     size_t num_addresses, const grpc_lb_user_data_vtable *user_data_vtable); +/** Deep copy the address from \a src to \a dest. */+void grpc_lb_address_copy(grpc_lb_address* dest, const grpc_lb_address* src,  ","That's fine.  (If you were going to have a separate function for copying only the backend addresses, I would say to keep the helper function, to avoid duplication between the two ""public"" methods.  But if you're just going to add a parameter to `grpc_lb_addresses_copy()`, then there's no need for that.)",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,133850117,2017-08-17T23:07:15Z,src/core/ext/filters/client_channel/lb_policy_factory.c,"@@ -36,24 +36,50 @@ grpc_lb_addresses* grpc_lb_addresses_create(   return addresses; } +void grpc_lb_address_copy(grpc_lb_address* dest, const grpc_lb_address* src,  +                          const grpc_lb_user_data_vtable* user_data_vtable) {+  if (src->user_data != NULL) GPR_ASSERT(user_data_vtable != NULL);+  memcpy(dest, src, sizeof(grpc_lb_address));+  if (src->balancer_name != NULL) {+    dest->balancer_name = gpr_strdup(src->balancer_name);+  }+  if (src->user_data != NULL) {+    dest->user_data = user_data_vtable->copy(src->user_data);+  }+}+ grpc_lb_addresses* grpc_lb_addresses_copy(const grpc_lb_addresses* addresses) {   grpc_lb_addresses* new_addresses = grpc_lb_addresses_create(       addresses->num_addresses, addresses->user_data_vtable);-  memcpy(new_addresses->addresses, addresses->addresses,-         sizeof(grpc_lb_address) * addresses->num_addresses);   for (size_t i = 0; i < addresses->num_addresses; ++i) {-    if (new_addresses->addresses[i].balancer_name != NULL) {-      new_addresses->addresses[i].balancer_name =-          gpr_strdup(new_addresses->addresses[i].balancer_name);-    }-    if (new_addresses->addresses[i].user_data != NULL) {-      new_addresses->addresses[i].user_data = addresses->user_data_vtable->copy(-          new_addresses->addresses[i].user_data);-    }+    grpc_lb_address_copy(&new_addresses->addresses[i], &addresses->addresses[i], +                         addresses->user_data_vtable);   }   return new_addresses; } +grpc_lb_addresses* grpc_lb_addresses_extract_backends(+    const grpc_lb_addresses* addresses) {+  // First run: get the number of backends.+  size_t num_backend_addrs = 0;+  for (size_t i = 0; i < addresses->num_addresses; ++i) {+    if (!addresses->addresses[i].is_balancer) ++num_backend_addrs;+  }+  if (num_backend_addrs == 0) return NULL;+  +  // Second run: copy the backends.+  grpc_lb_addresses *backends = grpc_lb_addresses_create(num_backend_addrs, +                                                         NULL);","From the perspective of the `grpc_lb_addresses` interface, it shouldn't matter which caller sets `user_data` and which caller doesn't.  What matters is the guarantee that this interface provides, which is that any caller can set `user_data`, as long as they provide a vtable.  And the functions should work for that case.Another way to think of this is that, while it may be true that no current caller depends on this, new callers may be created in the future.  If a new caller started using this and set user_data that did not get propagated, they would be very surprised by that.  Interfaces should always try to provide the least surprising guarantees.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,134041277,2017-08-18T19:47:20Z,src/core/ext/filters/client_channel/lb_policy_factory.h,"@@ -66,9 +66,18 @@ typedef struct grpc_lb_addresses { grpc_lb_addresses *grpc_lb_addresses_create(     size_t num_addresses, const grpc_lb_user_data_vtable *user_data_vtable); +/** Deep copy the address from \a src to \a dest. */+void grpc_lb_address_copy(grpc_lb_address* dest, const grpc_lb_address* src,  +                          const grpc_lb_user_data_vtable* user_data_vtable);+ /** Creates a copy of \a addresses. */ grpc_lb_addresses *grpc_lb_addresses_copy(const grpc_lb_addresses *addresses); +/** Extract the backend addresses and return them in a new \a +    grpc_lb_addresses. */+grpc_lb_addresses *grpc_lb_addresses_extract_backends(",The problem of changing the existing function is that `[grpc_arg_pointer_vtable]`https://github.com/grpc/grpc/blob/b48f0946a145893cb28117ef4f162c0a5050e577/include/grpc/impl/codegen/grpc_types.h#L87 should also change. It looks like I shouldn't force the siblings of `lb_addresses_arg_vtable` to take this change. Should I roll back (this rollback)?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,134046405,2017-08-18T20:15:12Z,src/core/ext/filters/client_channel/lb_policy_factory.h,"@@ -66,9 +66,18 @@ typedef struct grpc_lb_addresses { grpc_lb_addresses *grpc_lb_addresses_create(     size_t num_addresses, const grpc_lb_user_data_vtable *user_data_vtable); +/** Deep copy the address from \a src to \a dest. */+void grpc_lb_address_copy(grpc_lb_address* dest, const grpc_lb_address* src,  +                          const grpc_lb_user_data_vtable* user_data_vtable);+ /** Creates a copy of \a addresses. */ grpc_lb_addresses *grpc_lb_addresses_copy(const grpc_lb_addresses *addresses); +/** Extract the backend addresses and return them in a new \a +    grpc_lb_addresses. */+grpc_lb_addresses *grpc_lb_addresses_extract_backends(","You should definitely not change `grpc_arg_pointer_vtable`.  But you should not need to do so.The goal of the channel arg pointer vtable is to provide hooks for copying an arbitrary object encoded in a channel arg as a pointer.  If we're copying a channel arg, we don't want to change its value; we just want to copy it as-is.  So I think you can just change the copy function that we're using for this particular channel arg to pass in the parameter that causes us to copy all addresses, not just the backend addresses.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12228,134239972,2017-08-21T14:13:08Z,src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.c,"@@ -630,13 +640,57 @@ static void rr_connectivity_changed_locked(grpc_exec_ctx *exec_ctx, void *arg,         GRPC_CLOSURE_SCHED(exec_ctx, pp->on_complete, GRPC_ERROR_NONE);         gpr_free(pp);       }+      rr_subchannel_list_unref(exec_ctx, sd->subchannel_list,+                               ""sd_shutdown+started_picking"");+      // unref the ""rr_connectivity_update"" weak ref from start_picking.+      GRPC_LB_POLICY_WEAK_UNREF(exec_ctx, &p->base,+                                ""rr_connectivity_sd_shutdown"");+    } else {+      // Policy isn't shutting down but the subchannel has going into shutdown.+      // Try to reconnect by recreating the subchannel.+      grpc_subchannel_args sc_args;+      memset(&sc_args, 0, sizeof(grpc_subchannel_args));+      sc_args.args = sd->channel_args_for_subchannel;+      sd->subchannel = grpc_client_channel_factory_create_subchannel(+          exec_ctx, p->client_channel_factory, &sc_args);++      if (GRPC_TRACER_ON(grpc_lb_round_robin_trace)) {+        gpr_log(GPR_DEBUG,+                ""[RR %p]: Created (retry) subchannel %p for address uri %s ""+                ""into subchannel_list %p"",+                (void *)p, (void *)sd->subchannel, sd->address_uri,+                (void *)sd->subchannel_list);+      }+      sd->prev_connectivity_state = GRPC_CHANNEL_INIT;+      sd->curr_connectivity_state = GRPC_CHANNEL_IDLE;","If we're changing this, don't we need to update the subchannel list's `num_shutdown` field?Conversely, if we do update that list, won't this prevent us from ever shutting down the RR policy when all subchannels go bad, thus preventing us from ever re-resolving the server name?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12228,134240217,2017-08-21T14:14:14Z,src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.c,"@@ -630,13 +640,57 @@ static void rr_connectivity_changed_locked(grpc_exec_ctx *exec_ctx, void *arg,         GRPC_CLOSURE_SCHED(exec_ctx, pp->on_complete, GRPC_ERROR_NONE);         gpr_free(pp);       }+      rr_subchannel_list_unref(exec_ctx, sd->subchannel_list,+                               ""sd_shutdown+started_picking"");+      // unref the ""rr_connectivity_update"" weak ref from start_picking.+      GRPC_LB_POLICY_WEAK_UNREF(exec_ctx, &p->base,+                                ""rr_connectivity_sd_shutdown"");+    } else {+      // Policy isn't shutting down but the subchannel has going into shutdown.+      // Try to reconnect by recreating the subchannel.+      grpc_subchannel_args sc_args;",This code seems very similar to the code in `rr_update_locked()`.  Consider refactoring into a helper function?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,134501120,2017-08-22T14:38:30Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -668,9 +684,21 @@ static bool pick_from_internal_rr_locked(  static grpc_lb_policy_args *lb_policy_args_create(grpc_exec_ctx *exec_ctx,                                                   glb_lb_policy *glb_policy) {-  grpc_lb_addresses *addresses =-      process_serverlist_locked(exec_ctx, glb_policy->serverlist);+  GPR_ASSERT(glb_policy->serverlist != NULL || ",I think it would be simpler to just put `GPR_ASSERT(glb_policy->fallback_backend_addresses != NULL)` in the `else` block.  That's both easier to read and avoids checking the value of `glb_policy->serverlist` twice.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,134503238,2017-08-22T14:45:10Z,src/core/ext/filters/client_channel/lb_policy_factory.c,"@@ -125,7 +140,7 @@ void grpc_lb_addresses_destroy(grpc_exec_ctx* exec_ctx, }  static void* lb_addresses_copy(void* addresses) {-  return grpc_lb_addresses_copy(addresses);+  return grpc_lb_addresses_copy(addresses, false);","Suggest adding `/* only_backends */` after `false`, so it's clear to a reader what the parameter indicates.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,134503353,2017-08-22T14:45:29Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -967,6 +997,10 @@ static grpc_lb_policy *glb_create(grpc_exec_ctx *exec_ctx,   glb_policy->args = grpc_channel_args_copy_and_add_and_remove(       args->args, args_to_remove, GPR_ARRAY_SIZE(args_to_remove), &new_arg, 1); +  /* Copy the backend addresses (may be empty) from the resolver for fallback */+  glb_policy->fallback_backend_addresses = +      grpc_lb_addresses_copy(addresses, true);","Suggest adding `/* only_backends */` after `true`, so it's clear to a reader what the parameter indicates.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,134504857,2017-08-22T14:50:15Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1783,6 +1859,18 @@ static void glb_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,         &glb_policy->lb_channel_connectivity,         &glb_policy->lb_channel_on_connectivity_changed, NULL);   }++  // Propagate update to fallback_backend_addresses if we haven't heard from +  // the balancer.+  if (glb_policy->serverlist == NULL) {+    if (glb_policy->fallback_backend_addresses != NULL) {",Won't `fallback_backend_addresses` always be non-NULL at this point?  I think that should always be true up until the point that we set `serverlist`.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,134505041,2017-08-22T14:50:50Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1783,6 +1859,18 @@ static void glb_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,         &glb_policy->lb_channel_connectivity,         &glb_policy->lb_channel_on_connectivity_changed, NULL);   }++  // Propagate update to fallback_backend_addresses if we haven't heard from +  // the balancer.+  if (glb_policy->serverlist == NULL) {+    if (glb_policy->fallback_backend_addresses != NULL) {+      grpc_lb_addresses_destroy(exec_ctx, glb_policy->fallback_backend_addresses);+    }+    glb_policy->fallback_backend_addresses = grpc_lb_addresses_copy(addresses, true);","Suggest adding `/* only_backends */` after `true`, so it's clear to a reader what the parameter indicates.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,134505984,2017-08-22T14:54:03Z,test/cpp/end2end/grpclb_end2end_test.cc,"@@ -593,6 +594,89 @@ TEST_F(SingleBalancerTest, InitiallyEmptyServerlist) {   EXPECT_EQ(""grpclb"", channel_->GetLoadBalancingPolicyName()); } +TEST_F(SingleBalancerTest, Fallback) {+  const int kFallbackTimeoutMs = 200 * grpc_test_slowdown_factor();+  const int kServerlistDelayMs = 500 * grpc_test_slowdown_factor();+  const int kCallDeadlineMs = 1000 * grpc_test_slowdown_factor();++  ResetStub(kFallbackTimeoutMs);+  std::vector<AddressData> addresses;+  addresses.emplace_back(AddressData{balancer_servers_[0].port_, true, """"});+  addresses.emplace_back(AddressData{balancer_servers_[1].port_, true, """"});+  addresses.emplace_back(AddressData{balancer_servers_[2].port_, false, """"});","If we're trying to include a backend address in the data returned by the resolver, then let's use `backend_servers_[0]` instead of `balancer_servers_[2]` here.  The balancer does not provide the right RPC service to answer the RPC that the client is sending.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,134510369,2017-08-22T15:07:41Z,test/cpp/end2end/grpclb_end2end_test.cc,"@@ -593,6 +594,89 @@ TEST_F(SingleBalancerTest, InitiallyEmptyServerlist) {   EXPECT_EQ(""grpclb"", channel_->GetLoadBalancingPolicyName()); } +TEST_F(SingleBalancerTest, Fallback) {+  const int kFallbackTimeoutMs = 200 * grpc_test_slowdown_factor();+  const int kServerlistDelayMs = 500 * grpc_test_slowdown_factor();+  const int kCallDeadlineMs = 1000 * grpc_test_slowdown_factor();++  ResetStub(kFallbackTimeoutMs);+  std::vector<AddressData> addresses;+  addresses.emplace_back(AddressData{balancer_servers_[0].port_, true, """"});+  addresses.emplace_back(AddressData{balancer_servers_[1].port_, true, """"});+  addresses.emplace_back(AddressData{balancer_servers_[2].port_, false, """"});+  SetNextResolution(addresses);++  // First response is an empty serverlist, sent right away.+  ScheduleResponseForBalancer(0, LoadBalanceResponse(), 0);+  // Send non-empty serverlist only after kServerlistDelayMs+  ScheduleResponseForBalancer(+      0, BalancerServiceImpl::BuildResponseForBackends(GetBackendPorts(), {}),+      kServerlistDelayMs);++  const gpr_timespec second_call_time = gpr_time_add(+      gpr_now(GPR_CLOCK_REALTIME), +      gpr_time_from_millis(kServerlistDelayMs * 1.1, GPR_TIMESPAN));++  const auto t0 = system_clock::now();+  // The first request. The client will block while it's still trying to +  // contact the balancer.+  const auto& statuses_and_responses =+      SendRpc(kMessage_, num_backends_);+  const auto ellapsed_ms =+      std::chrono::duration_cast<std::chrono::milliseconds>(+          system_clock::now() - t0);++  // After fallback is in use, the call succeeds even though it's before +  // the serverlist is available.+  EXPECT_GT(ellapsed_ms.count(), kFallbackTimeoutMs);+  EXPECT_LT(ellapsed_ms.count(), kServerlistDelayMs);++  // Each backend should have gotten 1 request.","I don't think this is correct.  If the first RPC is sent before the serverlist is returned, it should be sent only to the backend address returned by the resolver.If this test is currently passing, then I suspect there is a bug somewhere in either the code or the test.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,134544251,2017-08-22T17:12:15Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1550,6 +1604,13 @@ static void lb_on_response_received_locked(grpc_exec_ctx *exec_ctx, void *arg,     if (!glb_policy->seen_initial_response &&         (response = grpc_grpclb_initial_response_parse(response_slice)) !=             NULL) {+      /* Don't use fallback any more. */","Should I actually move this block of code under line 1657 (`if (serverlist->num_servers > 0)`)? Because if the initial response is empty, the `serverlist` will remain NULL, and fallback is still useful.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,134545534,2017-08-22T17:17:30Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -959,6 +985,10 @@ static grpc_lb_policy *glb_create(grpc_exec_ctx *exec_ctx,   glb_policy->lb_call_timeout_ms =       grpc_channel_arg_get_integer(arg, (grpc_integer_options){0, 0, INT_MAX}); +  arg = grpc_channel_args_find(args->args, GRPC_ARG_GRPCLB_FALLBACK_TIMEOUT_MS);+  glb_policy->lb_fallback_timeout_ms = +      grpc_channel_arg_get_integer(arg, (grpc_integer_options){0, 0, INT_MAX});","Added. If fallback is enabled by default, some tests (e.g., `InitiallyEmptyServerlist`) may need modification.",
17460127,y-zeng,https://api.github.com/repos/grpc/grpc/pulls/12080,134550258,2017-08-22T17:34:57Z,src/cpp/client/channel_cc.cc,"@@ -35,17 +35,80 @@ #include <grpc/slice.h> #include <grpc/support/alloc.h> #include <grpc/support/log.h>+#include <grpc/support/thd.h> #include ""src/core/lib/profiling/timers.h""  namespace grpc { +namespace {+const int kWaitForStateChangeTimeoutMsec = 100;+void WatchStateChange(void* arg);+}  // namespace++// Constantly watches channel connectivity status to reconnect a transiently+// disconnected channel. This is a temporary work-around before we have retry+// support.+class ChannelConnectivityWatcher {+ public:+  ChannelConnectivityWatcher(Channel* channel)+      : channel_(channel), thd_id_(0), being_destroyed_(0) {}++  void WatchStateChangeImpl() {+    grpc_connectivity_state state = GRPC_CHANNEL_IDLE;+    while (state != GRPC_CHANNEL_SHUTDOWN) {+      if (gpr_atm_no_barrier_load(&being_destroyed_) == 1) {+        break;+      }+      channel_->WaitForStateChange(+          state,+          gpr_time_add(gpr_now(GPR_CLOCK_REALTIME),+                       gpr_time_from_millis(kWaitForStateChangeTimeoutMsec,+                                            GPR_TIMESPAN)));+      state = channel_->GetState(false);+    }+  }+  void StartWatching() {+    gpr_thd_options options = gpr_thd_options_default();+    gpr_thd_options_set_joinable(&options);+    gpr_thd_new(&thd_id_, &WatchStateChange, this, &options);+  }++  void Destroy() {+    if (thd_id_ != 0) {+      gpr_atm_no_barrier_store(&being_destroyed_, 1);+      gpr_thd_join(thd_id_);+    }+  }++ private:+  Channel* channel_;+  gpr_thd_id thd_id_;+  gpr_atm being_destroyed_;+};++namespace {+void WatchStateChange(void* arg) {",It seems `gpr_thd_new` is not willing to take a static member function as its parameter.,
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,134565440,2017-08-22T18:31:35Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1550,6 +1604,13 @@ static void lb_on_response_received_locked(grpc_exec_ctx *exec_ctx, void *arg,     if (!glb_policy->seen_initial_response &&         (response = grpc_grpclb_initial_response_parse(response_slice)) !=             NULL) {+      /* Don't use fallback any more. */",Why isn't `serverlist` parsed from the initial response? Is initial response only for setup work?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,134597179,2017-08-22T20:46:51Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1550,6 +1604,13 @@ static void lb_on_response_received_locked(grpc_exec_ctx *exec_ctx, void *arg,     if (!glb_policy->seen_initial_response &&         (response = grpc_grpclb_initial_response_parse(response_slice)) !=             NULL) {+      /* Don't use fallback any more. */","Yes, good catch -- this should definitely be moved.  I would put it on line 1675, right after setting `glb_policy->serverlist` but before calling `rr_handover_locked()`.The serverlist not being included in the initial response is just how the load balancer protocol is defined.  The initial response message contains different information than subsequent messages, as you can see here:https://github.com/grpc/grpc/blob/master/src/proto/grpc/lb/v1/load_balancer.proto#L105",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12100,134654378,2017-08-23T04:22:08Z,src/ruby/lib/grpc/generic/active_call.rb,"@@ -657,5 +666,11 @@ def initialize(wrapped)     Operation = view_class(:cancel, :cancelled?, :deadline, :execute,                            :metadata, :status, :start_call, :wait, :write_flag,                            :write_flag=, :trailing_metadata)++    # InterceptableView further limits access to an ActiveCall's methods+    # for use in interceptors on the client+    InterceptableView = view_class(:cancel, :cancelled?, :deadline,","Sorry from these methods, asking a to get rid of a few more:(though still open to arguments for keeping them)* `cancel`  - I'd like to hide this accessor for the same reasons as hiding the ""metadata-sending"" and ""call-starting"" calls.* `cancelled?` - IMO this API wouldn't give intuituve results, I can't think of a valid use* `wait` - wait's until the call has finished executing; I can't see a valid use* `write_flag=` - being a potential performance optimization, I don't think interceptors should need access to it.* `trailing_metadata` - not filled in until the call has finished* `status` - not filled in until the call has finished",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12210,134657647,2017-08-23T05:03:12Z,test/cpp/naming/naming_end2end_test.cc,"@@ -0,0 +1,297 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/host_port.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>+#include <grpc/support/time.h>+#include <string.h>++#include <gflags/gflags.h>+#include <vector>++#include ""test/cpp/util/test_config.h""++extern ""C"" {+#include ""src/core/ext/filters/client_channel/client_channel.h""+#include ""src/core/ext/filters/client_channel/resolver.h""+#include ""src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.h""+#include ""src/core/ext/filters/client_channel/resolver_registry.h""+#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/iomgr/combiner.h""+#include ""src/core/lib/iomgr/executor.h""+#include ""src/core/lib/iomgr/iomgr.h""+#include ""src/core/lib/iomgr/resolve_address.h""+#include ""src/core/lib/iomgr/sockaddr_utils.h""+#include ""src/core/lib/support/env.h""+#include ""src/core/lib/support/string.h""+#include ""test/core/util/test_config.h""+}++using std::vector;++DEFINE_string(target_name, """", """");+DEFINE_bool(expect_target_is_balancer, true, """");+DEFINE_string(expected_addrs, """", """");+DEFINE_string(expected_chosen_service_config, """", """");+DEFINE_string(local_dns_server_address, """", """");++namespace grpc {+namespace testing {++static vector<std::string> parse_expected_addrs(const char *expected_addrs) {+  std::vector<std::string> out;++  char *p = (char *)expected_addrs;++  if (strlen(p) != 0) {+    for (;;) {+      char *comma = strchr(p, ',');+      if (comma) {+        out.emplace_back(p, comma);+        p = comma + 1;+      } else {+        out.emplace_back(p);+        break;+      }+    }+  }+  if (out.size() == 0) {+    gpr_log(GPR_ERROR,+            ""expected_addrs arg should be a comma-separated list of ip-ports"");+  }+  return out;+}++static gpr_timespec test_deadline(void) {+  return grpc_timeout_seconds_to_deadline(100);+}++typedef struct args_struct {+  gpr_event ev;+  gpr_atm done_atm;+  gpr_mu *mu;+  grpc_pollset *pollset;+  grpc_pollset_set *pollset_set;+  grpc_combiner *lock;+  grpc_channel_args *channel_args;+  bool expect_is_balancer;+  const char *target_name;+  vector<std::string> expected_addrs;+  const char *expected_service_config_string;+} args_struct;++int matches_any(vector<std::string> expected_addrs, const char *addr) {+  for (auto it = expected_addrs.begin(); it != expected_addrs.end(); it++) {+    if (it->compare(addr) == 0) {+      gpr_log(GPR_INFO, ""found a match for expected addresss: %s"", addr);+      return 1;+    } else {+      gpr_log(GPR_INFO, ""expected addresss: %s didn't match found address: %s"",+              it->c_str(), addr);+    }+  }+  gpr_log(GPR_ERROR, ""no match found for found address: %s"", addr);+  return 0;+}++static void do_nothing(grpc_exec_ctx *exec_ctx, void *arg, grpc_error *error) {}++void args_init(grpc_exec_ctx *exec_ctx, args_struct *args) {+  gpr_event_init(&args->ev);+  args->pollset = (grpc_pollset *)gpr_zalloc(grpc_pollset_size());+  grpc_pollset_init(args->pollset, &args->mu);+  args->pollset_set = grpc_pollset_set_create();+  grpc_pollset_set_add_pollset(exec_ctx, args->pollset_set, args->pollset);+  args->lock = grpc_combiner_create();+  gpr_atm_rel_store(&args->done_atm, 0);+  args->channel_args = NULL;+}++void args_finish(grpc_exec_ctx *exec_ctx, args_struct *args) {+  GPR_ASSERT(gpr_event_wait(&args->ev, test_deadline()));+  grpc_pollset_set_del_pollset(exec_ctx, args->pollset_set, args->pollset);+  grpc_pollset_set_destroy(exec_ctx, args->pollset_set);+  grpc_closure do_nothing_cb;+  GRPC_CLOSURE_INIT(&do_nothing_cb, do_nothing, NULL,+                    grpc_schedule_on_exec_ctx);+  grpc_pollset_shutdown(exec_ctx, args->pollset, &do_nothing_cb);+  // exec_ctx needs to be flushed before calling grpc_pollset_destroy()+  grpc_channel_args_destroy(exec_ctx, args->channel_args);+  grpc_exec_ctx_flush(exec_ctx);+  grpc_pollset_destroy(exec_ctx, args->pollset);+  gpr_free(args->pollset);+  GRPC_COMBINER_UNREF(exec_ctx, args->lock, NULL);+}++static gpr_timespec n_sec_deadline(int seconds) {+  return gpr_time_add(gpr_now(GPR_CLOCK_REALTIME),+                      gpr_time_from_seconds(seconds, GPR_TIMESPAN));+}++static void poll_pollset_until_request_done(args_struct *args) {+  gpr_timespec deadline = n_sec_deadline(10);+  while (true) {+    bool done = gpr_atm_acq_load(&args->done_atm) != 0;+    if (done) {+      break;+    }+    gpr_timespec time_left =+        gpr_time_sub(deadline, gpr_now(GPR_CLOCK_REALTIME));+    gpr_log(GPR_DEBUG, ""done=%d, time_left=%"" PRId64 "".%09d"", done,+            time_left.tv_sec, time_left.tv_nsec);+    GPR_ASSERT(gpr_time_cmp(time_left, gpr_time_0(GPR_TIMESPAN)) >= 0);+    grpc_pollset_worker *worker = NULL;+    grpc_exec_ctx exec_ctx = GRPC_EXEC_CTX_INIT;+    gpr_mu_lock(args->mu);+    GRPC_LOG_IF_ERROR(+        ""pollset_work"",+        grpc_pollset_work(&exec_ctx, args->pollset, &worker,+                          gpr_now(GPR_CLOCK_REALTIME), n_sec_deadline(1)));+    gpr_mu_unlock(args->mu);+    grpc_exec_ctx_finish(&exec_ctx);+  }+  gpr_event_set(&args->ev, (void *)1);+}++static void check_service_config_result_locked(grpc_channel_args *channel_args,+                                               args_struct *args) {+  const grpc_arg *service_config_arg =+      grpc_channel_args_find(channel_args, GRPC_ARG_SERVICE_CONFIG);+  if (args->expected_service_config_string != NULL &&+      strlen(args->expected_service_config_string) > 0) {+    GPR_ASSERT(service_config_arg != NULL);+    GPR_ASSERT(service_config_arg->type == GRPC_ARG_STRING);+    char *service_config_string = service_config_arg->value.string;+    if (gpr_stricmp(service_config_string,+                    args->expected_service_config_string) != 0) {+      gpr_log(GPR_ERROR, ""expected service config string: |%s|"",+              args->expected_service_config_string);+      gpr_log(GPR_ERROR, ""got service config string: |%s|"",+              service_config_string);+      GPR_ASSERT(0);+    }+  } else {+    GPR_ASSERT(service_config_arg == NULL);+  }+}++static void check_channel_arg_srv_result_locked(grpc_exec_ctx *exec_ctx,+                                                void *argsp, grpc_error *err) {+  args_struct *args = (args_struct *)argsp;+  grpc_channel_args *channel_args = args->channel_args;+  const grpc_arg *channel_arg =+      grpc_channel_args_find(channel_args, GRPC_ARG_LB_ADDRESSES);+  GPR_ASSERT(channel_arg != NULL);+  GPR_ASSERT(channel_arg->type == GRPC_ARG_POINTER);+  grpc_lb_addresses *addresses =+      (grpc_lb_addresses *)channel_arg->value.pointer.p;+  gpr_log(GPR_INFO, ""num addrs found: %d. expected %"" PRIdPTR,+          (int)addresses->num_addresses, args->expected_addrs.size());++  GPR_ASSERT(addresses->num_addresses == args->expected_addrs.size());+  for (size_t i = 0; i < addresses->num_addresses; i++) {+    grpc_lb_address addr = addresses->addresses[i];+    char *str;+    grpc_sockaddr_to_string(&str, &addr.address, 1 /* normalize */);+    gpr_log(GPR_INFO, ""%s"", str);+    GPR_ASSERT(addr.is_balancer == args->expect_is_balancer);+    GPR_ASSERT(matches_any(args->expected_addrs, str));+    gpr_free(str);+  }++  check_service_config_result_locked(channel_args, args);++  gpr_atm_rel_store(&args->done_atm, 1);+  gpr_mu_lock(args->mu);+  GRPC_LOG_IF_ERROR(""pollset_kick"", grpc_pollset_kick(args->pollset, NULL));+  gpr_mu_unlock(args->mu);+}++static void test_resolves(grpc_exec_ctx *exec_ctx, args_struct *args) {+  char *whole_uri = NULL;+  const char *authority = FLAGS_local_dns_server_address.c_str();+  if (authority != NULL && strlen(authority) > 0) {+    gpr_log(GPR_INFO, ""Specifying authority in uris to: %s"", authority);+  } else {+    authority = """";+  }++  GPR_ASSERT(asprintf(&whole_uri, ""dns://%s/%s"", authority,+                      (char *)args->target_name));+  args->channel_args = NULL;++  grpc_resolver *resolver = grpc_resolver_create(exec_ctx, whole_uri, NULL,+                                                 args->pollset_set, args->lock);+  gpr_free(whole_uri);++  grpc_closure on_resolver_result_changed;+  GRPC_CLOSURE_INIT(&on_resolver_result_changed,+                    check_channel_arg_srv_result_locked, (void *)args,+                    grpc_combiner_scheduler(args->lock));++  grpc_resolver_next_locked(exec_ctx, resolver, &args->channel_args,+                            &on_resolver_result_changed);++  grpc_exec_ctx_flush(exec_ctx);+  poll_pollset_until_request_done(args);+  GRPC_RESOLVER_UNREF(exec_ctx, resolver, NULL);+}++void naming_end2end_test_resolution(const char *name,+                                    std::vector<std::string> expected_addrs,+                                    const char *expected_service_config,+                                    bool expected_target_is_balancer) {+  grpc_init();+  gpr_log(GPR_INFO, ""e a size: %d"", (int)expected_addrs.size());+  grpc_exec_ctx exec_ctx = GRPC_EXEC_CTX_INIT;+  args_struct args;+  args_init(&exec_ctx, &args);+  args.expect_is_balancer = expected_target_is_balancer;+  args.target_name = name;+  args.expected_addrs = expected_addrs;+  args.expected_service_config_string = expected_service_config;++  test_resolves(&exec_ctx, &args);+  args_finish(&exec_ctx, &args);+  grpc_exec_ctx_finish(&exec_ctx);+  grpc_shutdown();+}++}  // namespace+}  // namespace grpc++int main(int argc, char **argv) {+  grpc::testing::InitTest(&argc, &argv, true);+  if (FLAGS_target_name == """" || FLAGS_expected_addrs == """") {+    gpr_log(GPR_ERROR,+            ""Missing target_name or expected_addrs params. Got %s and %s"",+            FLAGS_target_name.c_str(), FLAGS_expected_addrs.c_str());+    abort();+  }+  auto expected_addrs_list =+      grpc::testing::parse_expected_addrs(FLAGS_expected_addrs.c_str());++  grpc::testing::naming_end2end_test_resolution(","Renamed this to `resolver_component_test..`. I wanted make it more unique than `resolver_test`, for namespacing/regex matching purposes, but can change if we want to",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12100,134658515,2017-08-23T05:13:12Z,src/ruby/lib/grpc/generic/interceptor_registry.rb,"@@ -0,0 +1,121 @@+# Copyright 2015 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++# GRPC contains the General RPC module.+module GRPC+  ##+  # Represents a registry of added interceptors available for enumeration.+  # The registry can be used for both server and client interceptors.+  #+  class InterceptorRegistry+    ##+    # An error raised when an interceptor is attempted to be added+    # that does not extend GRPC::Interceptor+    #+    class DescendantError < StandardError; end++    ##+    # Initialize the registry with an empty interceptor list+    #+    def initialize(interceptors = {})+      @interceptors = {}+      interceptors.each do |k, i|+        self[k] = i+      end+    end++    ##+    # Add an interceptor to the registry+    #+    # @param [Symbol] name The key to identify the interceptor in the+    #   registry as+    # @param [GRPC::Interceptor] interceptor The interceptor instance+    #+    def []=(name, interceptor = nil)","It looks like the `[]=` method can potentially be bypassed, with bad types accidentally invoked.AFAICS the features of this class are also offered in `Hash`? What do you think if we shrink the `InterceptorRegistry` class here, move the type-checking logic into the `InterceporRegistry#initialize` method, and keep only the `build_context` method. The user API would then be to pass in a plain `Hash` to `#new` of this class",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,134772694,2017-08-23T14:44:24Z,test/cpp/end2end/grpclb_end2end_test.cc,"@@ -416,10 +416,10 @@ class GrpclbEnd2endTest : public ::testing::Test {     grpc_exec_ctx_finish(&exec_ctx);   } -  const std::vector<int> GetBackendPorts() const {+  const std::vector<int> GetBackendPorts(const size_t begin = 0) const {",Suggest calling this parameter `start_index`.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,134775028,2017-08-23T14:51:51Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1664,6 +1732,21 @@ static void lb_call_on_retry_timer_locked(grpc_exec_ctx *exec_ctx, void *arg,   GRPC_LB_POLICY_WEAK_UNREF(exec_ctx, &glb_policy->base, ""grpclb_retry_timer""); } +static void lb_on_fallback_timer_locked(grpc_exec_ctx *exec_ctx, void *arg,+                                        grpc_error *error) {+  glb_lb_policy *glb_policy = arg;+  glb_policy->fallback_timer_active = false;+  if (!glb_policy->shutting_down && error == GRPC_ERROR_NONE) {+    if (GRPC_TRACER_ON(grpc_lb_glb_trace)) {+      gpr_log(GPR_INFO, ""Falling back to use backends from resolver (grpclb %p)"",+              (void *)glb_policy);+    }+    GPR_ASSERT(glb_policy->fallback_backend_addresses != NULL);","I think there's a possible race condition here.  In `lb_on_response_received_locked()`, when we get the first serverlist, we cancel the timer and set `glb_policy->fallback_backend_addresses` to NULL.  However, if `lb_on_response_received_locked()` runs after the timer schedules this callback but before this callback runs, then `glb_policy->fallback_backend_addresses` will be NULL here.I suggest removing this assertion and instead adding the following on line 1738:```// If we've already gotten a serverlist from the balancer, there's nothing to do here.if (glb_policy->fallback_backend_addresses == NULL) return;```",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12210,134782373,2017-08-23T15:15:39Z,test/cpp/naming/naming_end2end_test.cc,"@@ -0,0 +1,297 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/host_port.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>+#include <grpc/support/time.h>+#include <string.h>++#include <gflags/gflags.h>+#include <vector>++#include ""test/cpp/util/test_config.h""++extern ""C"" {+#include ""src/core/ext/filters/client_channel/client_channel.h""+#include ""src/core/ext/filters/client_channel/resolver.h""+#include ""src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.h""+#include ""src/core/ext/filters/client_channel/resolver_registry.h""+#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/iomgr/combiner.h""+#include ""src/core/lib/iomgr/executor.h""+#include ""src/core/lib/iomgr/iomgr.h""+#include ""src/core/lib/iomgr/resolve_address.h""+#include ""src/core/lib/iomgr/sockaddr_utils.h""+#include ""src/core/lib/support/env.h""+#include ""src/core/lib/support/string.h""+#include ""test/core/util/test_config.h""+}++using std::vector;++DEFINE_string(target_name, """", """");+DEFINE_bool(expect_target_is_balancer, true, """");+DEFINE_string(expected_addrs, """", """");+DEFINE_string(expected_chosen_service_config, """", """");+DEFINE_string(local_dns_server_address, """", """");++namespace grpc {+namespace testing {++static vector<std::string> parse_expected_addrs(const char *expected_addrs) {+  std::vector<std::string> out;++  char *p = (char *)expected_addrs;++  if (strlen(p) != 0) {+    for (;;) {+      char *comma = strchr(p, ',');+      if (comma) {+        out.emplace_back(p, comma);+        p = comma + 1;+      } else {+        out.emplace_back(p);+        break;+      }+    }+  }+  if (out.size() == 0) {+    gpr_log(GPR_ERROR,+            ""expected_addrs arg should be a comma-separated list of ip-ports"");+  }+  return out;+}++static gpr_timespec test_deadline(void) {+  return grpc_timeout_seconds_to_deadline(100);+}++typedef struct args_struct {+  gpr_event ev;+  gpr_atm done_atm;+  gpr_mu *mu;+  grpc_pollset *pollset;+  grpc_pollset_set *pollset_set;+  grpc_combiner *lock;+  grpc_channel_args *channel_args;+  bool expect_is_balancer;+  const char *target_name;+  vector<std::string> expected_addrs;+  const char *expected_service_config_string;+} args_struct;++int matches_any(vector<std::string> expected_addrs, const char *addr) {+  for (auto it = expected_addrs.begin(); it != expected_addrs.end(); it++) {+    if (it->compare(addr) == 0) {+      gpr_log(GPR_INFO, ""found a match for expected addresss: %s"", addr);+      return 1;+    } else {+      gpr_log(GPR_INFO, ""expected addresss: %s didn't match found address: %s"",+              it->c_str(), addr);+    }+  }+  gpr_log(GPR_ERROR, ""no match found for found address: %s"", addr);+  return 0;+}++static void do_nothing(grpc_exec_ctx *exec_ctx, void *arg, grpc_error *error) {}++void args_init(grpc_exec_ctx *exec_ctx, args_struct *args) {+  gpr_event_init(&args->ev);+  args->pollset = (grpc_pollset *)gpr_zalloc(grpc_pollset_size());+  grpc_pollset_init(args->pollset, &args->mu);+  args->pollset_set = grpc_pollset_set_create();+  grpc_pollset_set_add_pollset(exec_ctx, args->pollset_set, args->pollset);+  args->lock = grpc_combiner_create();+  gpr_atm_rel_store(&args->done_atm, 0);+  args->channel_args = NULL;+}++void args_finish(grpc_exec_ctx *exec_ctx, args_struct *args) {+  GPR_ASSERT(gpr_event_wait(&args->ev, test_deadline()));+  grpc_pollset_set_del_pollset(exec_ctx, args->pollset_set, args->pollset);+  grpc_pollset_set_destroy(exec_ctx, args->pollset_set);+  grpc_closure do_nothing_cb;+  GRPC_CLOSURE_INIT(&do_nothing_cb, do_nothing, NULL,+                    grpc_schedule_on_exec_ctx);+  grpc_pollset_shutdown(exec_ctx, args->pollset, &do_nothing_cb);+  // exec_ctx needs to be flushed before calling grpc_pollset_destroy()+  grpc_channel_args_destroy(exec_ctx, args->channel_args);+  grpc_exec_ctx_flush(exec_ctx);+  grpc_pollset_destroy(exec_ctx, args->pollset);+  gpr_free(args->pollset);+  GRPC_COMBINER_UNREF(exec_ctx, args->lock, NULL);+}++static gpr_timespec n_sec_deadline(int seconds) {+  return gpr_time_add(gpr_now(GPR_CLOCK_REALTIME),+                      gpr_time_from_seconds(seconds, GPR_TIMESPAN));+}++static void poll_pollset_until_request_done(args_struct *args) {+  gpr_timespec deadline = n_sec_deadline(10);+  while (true) {+    bool done = gpr_atm_acq_load(&args->done_atm) != 0;+    if (done) {+      break;+    }+    gpr_timespec time_left =+        gpr_time_sub(deadline, gpr_now(GPR_CLOCK_REALTIME));+    gpr_log(GPR_DEBUG, ""done=%d, time_left=%"" PRId64 "".%09d"", done,+            time_left.tv_sec, time_left.tv_nsec);+    GPR_ASSERT(gpr_time_cmp(time_left, gpr_time_0(GPR_TIMESPAN)) >= 0);+    grpc_pollset_worker *worker = NULL;+    grpc_exec_ctx exec_ctx = GRPC_EXEC_CTX_INIT;+    gpr_mu_lock(args->mu);+    GRPC_LOG_IF_ERROR(+        ""pollset_work"",+        grpc_pollset_work(&exec_ctx, args->pollset, &worker,+                          gpr_now(GPR_CLOCK_REALTIME), n_sec_deadline(1)));+    gpr_mu_unlock(args->mu);+    grpc_exec_ctx_finish(&exec_ctx);+  }+  gpr_event_set(&args->ev, (void *)1);+}++static void check_service_config_result_locked(grpc_channel_args *channel_args,+                                               args_struct *args) {+  const grpc_arg *service_config_arg =+      grpc_channel_args_find(channel_args, GRPC_ARG_SERVICE_CONFIG);","That's correct.  The resolver's behavior is that it will only set `GRPC_ARG_LB_POLICY_NAME` if the service config explicitly specifies an LB policy, otherwise it is left unset.  When the resolver returns its results to the client_channel code, that's where we check whether any of the addresses are balancer addresses and if so, force the use of `grpclb` regardless of what policy (if any) was present in the service config.https://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/client_channel.c#L389",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12210,134793516,2017-08-23T15:52:50Z,test/cpp/naming/naming_end2end_test.cc,"@@ -0,0 +1,297 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/host_port.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>+#include <grpc/support/time.h>+#include <string.h>++#include <gflags/gflags.h>+#include <vector>++#include ""test/cpp/util/test_config.h""++extern ""C"" {+#include ""src/core/ext/filters/client_channel/client_channel.h""+#include ""src/core/ext/filters/client_channel/resolver.h""+#include ""src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.h""+#include ""src/core/ext/filters/client_channel/resolver_registry.h""+#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/iomgr/combiner.h""+#include ""src/core/lib/iomgr/executor.h""+#include ""src/core/lib/iomgr/iomgr.h""+#include ""src/core/lib/iomgr/resolve_address.h""+#include ""src/core/lib/iomgr/sockaddr_utils.h""+#include ""src/core/lib/support/env.h""+#include ""src/core/lib/support/string.h""+#include ""test/core/util/test_config.h""+}++using std::vector;++DEFINE_string(target_name, """", """");+DEFINE_bool(expect_target_is_balancer, true, """");+DEFINE_string(expected_addrs, """", """");+DEFINE_string(expected_chosen_service_config, """", """");+DEFINE_string(local_dns_server_address, """", """");++namespace grpc {+namespace testing {++static vector<std::string> parse_expected_addrs(const char *expected_addrs) {+  std::vector<std::string> out;++  char *p = (char *)expected_addrs;++  if (strlen(p) != 0) {+    for (;;) {+      char *comma = strchr(p, ',');+      if (comma) {+        out.emplace_back(p, comma);+        p = comma + 1;+      } else {+        out.emplace_back(p);+        break;+      }+    }+  }+  if (out.size() == 0) {+    gpr_log(GPR_ERROR,+            ""expected_addrs arg should be a comma-separated list of ip-ports"");+  }+  return out;+}++static gpr_timespec test_deadline(void) {+  return grpc_timeout_seconds_to_deadline(100);+}++typedef struct args_struct {+  gpr_event ev;+  gpr_atm done_atm;+  gpr_mu *mu;+  grpc_pollset *pollset;+  grpc_pollset_set *pollset_set;+  grpc_combiner *lock;+  grpc_channel_args *channel_args;+  bool expect_is_balancer;+  const char *target_name;+  vector<std::string> expected_addrs;+  const char *expected_service_config_string;+} args_struct;++int matches_any(vector<std::string> expected_addrs, const char *addr) {+  for (auto it = expected_addrs.begin(); it != expected_addrs.end(); it++) {+    if (it->compare(addr) == 0) {+      gpr_log(GPR_INFO, ""found a match for expected addresss: %s"", addr);+      return 1;+    } else {+      gpr_log(GPR_INFO, ""expected addresss: %s didn't match found address: %s"",+              it->c_str(), addr);+    }+  }+  gpr_log(GPR_ERROR, ""no match found for found address: %s"", addr);+  return 0;+}++static void do_nothing(grpc_exec_ctx *exec_ctx, void *arg, grpc_error *error) {}++void args_init(grpc_exec_ctx *exec_ctx, args_struct *args) {+  gpr_event_init(&args->ev);+  args->pollset = (grpc_pollset *)gpr_zalloc(grpc_pollset_size());+  grpc_pollset_init(args->pollset, &args->mu);+  args->pollset_set = grpc_pollset_set_create();+  grpc_pollset_set_add_pollset(exec_ctx, args->pollset_set, args->pollset);+  args->lock = grpc_combiner_create();+  gpr_atm_rel_store(&args->done_atm, 0);+  args->channel_args = NULL;+}++void args_finish(grpc_exec_ctx *exec_ctx, args_struct *args) {+  GPR_ASSERT(gpr_event_wait(&args->ev, test_deadline()));+  grpc_pollset_set_del_pollset(exec_ctx, args->pollset_set, args->pollset);+  grpc_pollset_set_destroy(exec_ctx, args->pollset_set);+  grpc_closure do_nothing_cb;+  GRPC_CLOSURE_INIT(&do_nothing_cb, do_nothing, NULL,+                    grpc_schedule_on_exec_ctx);+  grpc_pollset_shutdown(exec_ctx, args->pollset, &do_nothing_cb);+  // exec_ctx needs to be flushed before calling grpc_pollset_destroy()+  grpc_channel_args_destroy(exec_ctx, args->channel_args);+  grpc_exec_ctx_flush(exec_ctx);+  grpc_pollset_destroy(exec_ctx, args->pollset);+  gpr_free(args->pollset);+  GRPC_COMBINER_UNREF(exec_ctx, args->lock, NULL);+}++static gpr_timespec n_sec_deadline(int seconds) {+  return gpr_time_add(gpr_now(GPR_CLOCK_REALTIME),+                      gpr_time_from_seconds(seconds, GPR_TIMESPAN));+}++static void poll_pollset_until_request_done(args_struct *args) {+  gpr_timespec deadline = n_sec_deadline(10);+  while (true) {+    bool done = gpr_atm_acq_load(&args->done_atm) != 0;+    if (done) {+      break;+    }+    gpr_timespec time_left =+        gpr_time_sub(deadline, gpr_now(GPR_CLOCK_REALTIME));+    gpr_log(GPR_DEBUG, ""done=%d, time_left=%"" PRId64 "".%09d"", done,+            time_left.tv_sec, time_left.tv_nsec);+    GPR_ASSERT(gpr_time_cmp(time_left, gpr_time_0(GPR_TIMESPAN)) >= 0);+    grpc_pollset_worker *worker = NULL;+    grpc_exec_ctx exec_ctx = GRPC_EXEC_CTX_INIT;+    gpr_mu_lock(args->mu);+    GRPC_LOG_IF_ERROR(+        ""pollset_work"",+        grpc_pollset_work(&exec_ctx, args->pollset, &worker,+                          gpr_now(GPR_CLOCK_REALTIME), n_sec_deadline(1)));+    gpr_mu_unlock(args->mu);+    grpc_exec_ctx_finish(&exec_ctx);+  }+  gpr_event_set(&args->ev, (void *)1);+}++static void check_service_config_result_locked(grpc_channel_args *channel_args,+                                               args_struct *args) {+  const grpc_arg *service_config_arg =+      grpc_channel_args_find(channel_args, GRPC_ARG_SERVICE_CONFIG);+  if (args->expected_service_config_string != NULL &&+      strlen(args->expected_service_config_string) > 0) {+    GPR_ASSERT(service_config_arg != NULL);+    GPR_ASSERT(service_config_arg->type == GRPC_ARG_STRING);+    char *service_config_string = service_config_arg->value.string;+    if (gpr_stricmp(service_config_string,+                    args->expected_service_config_string) != 0) {+      gpr_log(GPR_ERROR, ""expected service config string: |%s|"",+              args->expected_service_config_string);+      gpr_log(GPR_ERROR, ""got service config string: |%s|"",+              service_config_string);+      GPR_ASSERT(0);+    }+  } else {+    GPR_ASSERT(service_config_arg == NULL);+  }+}++static void check_channel_arg_srv_result_locked(grpc_exec_ctx *exec_ctx,+                                                void *argsp, grpc_error *err) {+  args_struct *args = (args_struct *)argsp;+  grpc_channel_args *channel_args = args->channel_args;+  const grpc_arg *channel_arg =+      grpc_channel_args_find(channel_args, GRPC_ARG_LB_ADDRESSES);+  GPR_ASSERT(channel_arg != NULL);+  GPR_ASSERT(channel_arg->type == GRPC_ARG_POINTER);+  grpc_lb_addresses *addresses =+      (grpc_lb_addresses *)channel_arg->value.pointer.p;+  gpr_log(GPR_INFO, ""num addrs found: %d. expected %"" PRIdPTR,+          (int)addresses->num_addresses, args->expected_addrs.size());++  GPR_ASSERT(addresses->num_addresses == args->expected_addrs.size());+  for (size_t i = 0; i < addresses->num_addresses; i++) {+    grpc_lb_address addr = addresses->addresses[i];+    char *str;+    grpc_sockaddr_to_string(&str, &addr.address, 1 /* normalize */);+    gpr_log(GPR_INFO, ""%s"", str);+    GPR_ASSERT(addr.is_balancer == args->expect_is_balancer);","Looks good.  The format might be a bit less ambiguous if we used a different delimiter character for the (address,is_balancer) pairs than between the pairs.  But this is fine as-is too.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,134802011,2017-08-23T16:25:49Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1602,15 +1658,27 @@ static void lb_on_response_received_locked(grpc_exec_ctx *exec_ctx, void *arg,             }             grpc_grpclb_destroy_serverlist(serverlist);           } else { /* new serverlist */+            /* record the old status */+            /* TODO(juanlishen): this assumes that num_servers never decreases+             * to 0 once it's positive */+            bool first_serverlist = glb_policy->serverlist == NULL;","I actually deleted this boolean yesterday because I found checking `if (glb_policy->fallback_backend_addresses != NULL)` a better way to do so, but I forgot to amend and push... Even before adding the boolean, I thought putting the code on line 1668 is good because it reuses the `if` branch. But it contradicts the intuition/rule that we should throw away fallback only _after_ we have a useful `serverlist`. Putting it on line 1668 is quite close, but a little bit too early. BTW, I should delete the trailing space on line 1668.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/12234,134810587,2017-08-23T17:01:46Z,tools/internal_ci/linux/grpc_performance_profile_daily.cfg,"@@ -0,0 +1,26 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++# Config file for the internal CI (in protobuf text format)++# Location of the continuous shell script in repository.+build_file: ""grpc/tools/internal_ci/linux/grpc_performance_profile_daily.sh""+timeout_mins: 1440","Probably good to make it a bit under 24h, in case tests/benchmarks start taking > 24h. Otherwise we'll start having a slight shift in start time every time that happens. Unless ""timeout"" here doesn't mean timeout for how long we wait for the results.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,134814483,2017-08-23T17:18:18Z,include/grpc++/support/channel_arguments.h,"@@ -64,7 +64,9 @@ class ChannelArguments {   /// Set the compression algorithm for the channel.   void SetCompressionAlgorithm(grpc_compression_algorithm algorithm); -  /// Set the GRPCLB fallback timeout (in ms) for the channel.+  /// Set the grpclb fallback timeout (in ms) for the channel. Here, fallback ","I see, it's ambiguous. Will make it more explicit.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/12080,134817700,2017-08-23T17:31:16Z,src/cpp/client/channel_cc.cc,"@@ -35,17 +35,82 @@ #include <grpc/slice.h> #include <grpc/support/alloc.h> #include <grpc/support/log.h>+#include <grpc/support/thd.h> #include ""src/core/lib/profiling/timers.h""  namespace grpc { +namespace {+void WatchStateChange(void* arg);+}  // namespace++// Constantly watches channel connectivity status to reconnect a transiently+// disconnected channel. This is a temporary work-around before we have retry+// support.+class ChannelConnectivityWatcher {+ public:+  explicit ChannelConnectivityWatcher(Channel* channel)+      : channel_(channel), thd_id_(0), shutting_down_(0) {}++  void WatchStateChangeImpl() {+    grpc_connectivity_state state = GRPC_CHANNEL_IDLE;+    while (state != GRPC_CHANNEL_SHUTDOWN) {+      channel_->WaitForStateChange(state, gpr_inf_future(GPR_CLOCK_REALTIME));+      if (gpr_atm_no_barrier_load(&shutting_down_) == 1) {+        break;+      }+      state = channel_->GetState(false);+    }+  }++  void StartWatching() {+    const char* disabled_str =+        std::getenv(""GRPC_DISABLE_CHANNEL_CONNECTIVITY_WATCHER"");",Do we want to use [`gpr_getenv`](https://github.com/grpc/grpc/blob/6331bcf12f0690d7dc07de5d41515985506c5058/src/core/lib/support/env.h#L34) instead?,
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,134823877,2017-08-23T17:52:50Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1783,6 +1866,17 @@ static void glb_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,         &glb_policy->lb_channel_connectivity,         &glb_policy->lb_channel_on_connectivity_changed, NULL);   }++  // Propagate update to fallback_backend_addresses if we haven't heard any valid +  // serverlist from the balancer.+  if (glb_policy->serverlist == NULL) {","If a previous `serverlist` is destroyed and it becomes a NULL, we don't have a `fallback_backend_addresses` to destroy.Should I change the condition to `if (glb_policy->fallback_backend_addresses != NULL)`? It means directly that we want to update the `fallback_backend_addresses` if fallback is still available.  ",
22083734,matt-kwong,https://api.github.com/repos/grpc/grpc/pulls/12234,134824004,2017-08-23T17:53:12Z,tools/internal_ci/linux/grpc_performance_profile_daily.cfg,"@@ -0,0 +1,26 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++# Config file for the internal CI (in protobuf text format)++# Location of the continuous shell script in repository.+build_file: ""grpc/tools/internal_ci/linux/grpc_performance_profile_daily.sh""+timeout_mins: 1440","Timeout here just means when Kokoro cancels the build (24 hours is the limit). Historically, when this job was working, the job took ~14 hours, and the 24 hour timeout just gives room for more performance data to be collected. This job will run daily regardless of what the `timeout_mins` field is.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/11978,134847220,2017-08-23T19:24:30Z,grpc.gemspec,"@@ -289,87 +360,12 @@ Gem::Specification.new do |s|   s.files += %w( src/core/lib/transport/transport.h )   s.files += %w( src/core/lib/transport/transport_impl.h )   s.files += %w( src/core/lib/debug/trace.h )-  s.files += %w( src/core/ext/transport/chttp2/transport/bin_decoder.h )-  s.files += %w( src/core/ext/transport/chttp2/transport/bin_encoder.h )-  s.files += %w( src/core/ext/transport/chttp2/transport/chttp2_transport.h )-  s.files += %w( src/core/ext/transport/chttp2/transport/frame.h )-  s.files += %w( src/core/ext/transport/chttp2/transport/frame_data.h )-  s.files += %w( src/core/ext/transport/chttp2/transport/frame_goaway.h )-  s.files += %w( src/core/ext/transport/chttp2/transport/frame_ping.h )-  s.files += %w( src/core/ext/transport/chttp2/transport/frame_rst_stream.h )-  s.files += %w( src/core/ext/transport/chttp2/transport/frame_settings.h )-  s.files += %w( src/core/ext/transport/chttp2/transport/frame_window_update.h )-  s.files += %w( src/core/ext/transport/chttp2/transport/hpack_encoder.h )-  s.files += %w( src/core/ext/transport/chttp2/transport/hpack_parser.h )-  s.files += %w( src/core/ext/transport/chttp2/transport/hpack_table.h )-  s.files += %w( src/core/ext/transport/chttp2/transport/http2_settings.h )-  s.files += %w( src/core/ext/transport/chttp2/transport/huffsyms.h )-  s.files += %w( src/core/ext/transport/chttp2/transport/incoming_metadata.h )-  s.files += %w( src/core/ext/transport/chttp2/transport/internal.h )-  s.files += %w( src/core/ext/transport/chttp2/transport/stream_map.h )-  s.files += %w( src/core/ext/transport/chttp2/transport/varint.h )-  s.files += %w( src/core/ext/transport/chttp2/alpn/alpn.h )-  s.files += %w( src/core/ext/filters/http/client/http_client_filter.h )-  s.files += %w( src/core/ext/filters/http/message_compress/message_compress_filter.h )-  s.files += %w( src/core/ext/filters/http/server/http_server_filter.h )-  s.files += %w( src/core/lib/security/context/security_context.h )-  s.files += %w( src/core/lib/security/credentials/composite/composite_credentials.h )-  s.files += %w( src/core/lib/security/credentials/credentials.h )-  s.files += %w( src/core/lib/security/credentials/fake/fake_credentials.h )-  s.files += %w( src/core/lib/security/credentials/google_default/google_default_credentials.h )-  s.files += %w( src/core/lib/security/credentials/iam/iam_credentials.h )-  s.files += %w( src/core/lib/security/credentials/jwt/json_token.h )-  s.files += %w( src/core/lib/security/credentials/jwt/jwt_credentials.h )-  s.files += %w( src/core/lib/security/credentials/jwt/jwt_verifier.h )-  s.files += %w( src/core/lib/security/credentials/oauth2/oauth2_credentials.h )-  s.files += %w( src/core/lib/security/credentials/plugin/plugin_credentials.h )-  s.files += %w( src/core/lib/security/credentials/ssl/ssl_credentials.h )-  s.files += %w( src/core/lib/security/transport/auth_filters.h )-  s.files += %w( src/core/lib/security/transport/lb_targets_info.h )-  s.files += %w( src/core/lib/security/transport/secure_endpoint.h )-  s.files += %w( src/core/lib/security/transport/security_connector.h )-  s.files += %w( src/core/lib/security/transport/security_handshaker.h )-  s.files += %w( src/core/lib/security/transport/tsi_error.h )-  s.files += %w( src/core/lib/security/util/json_util.h )-  s.files += %w( src/core/tsi/fake_transport_security.h )-  s.files += %w( src/core/tsi/gts_transport_security.h )-  s.files += %w( src/core/tsi/ssl_transport_security.h )-  s.files += %w( src/core/tsi/ssl_types.h )-  s.files += %w( src/core/tsi/transport_security.h )-  s.files += %w( src/core/tsi/transport_security_adapter.h )-  s.files += %w( src/core/tsi/transport_security_interface.h )-  s.files += %w( src/core/ext/transport/chttp2/server/chttp2_server.h )-  s.files += %w( src/core/ext/filters/client_channel/client_channel.h )-  s.files += %w( src/core/ext/filters/client_channel/client_channel_factory.h )-  s.files += %w( src/core/ext/filters/client_channel/connector.h )-  s.files += %w( src/core/ext/filters/client_channel/http_connect_handshaker.h )-  s.files += %w( src/core/ext/filters/client_channel/http_proxy.h )-  s.files += %w( src/core/ext/filters/client_channel/lb_policy.h )-  s.files += %w( src/core/ext/filters/client_channel/lb_policy_factory.h )-  s.files += %w( src/core/ext/filters/client_channel/lb_policy_registry.h )-  s.files += %w( src/core/ext/filters/client_channel/parse_address.h )-  s.files += %w( src/core/ext/filters/client_channel/proxy_mapper.h )-  s.files += %w( src/core/ext/filters/client_channel/proxy_mapper_registry.h )-  s.files += %w( src/core/ext/filters/client_channel/resolver.h )-  s.files += %w( src/core/ext/filters/client_channel/resolver_factory.h )-  s.files += %w( src/core/ext/filters/client_channel/resolver_registry.h )-  s.files += %w( src/core/ext/filters/client_channel/retry_throttle.h )-  s.files += %w( src/core/ext/filters/client_channel/subchannel.h )-  s.files += %w( src/core/ext/filters/client_channel/subchannel_index.h )-  s.files += %w( src/core/ext/filters/client_channel/uri_parser.h )-  s.files += %w( src/core/ext/filters/deadline/deadline_filter.h )-  s.files += %w( src/core/ext/transport/chttp2/client/chttp2_connector.h )-  s.files += %w( src/core/ext/transport/inproc/inproc_transport.h )   s.files += %w( src/core/ext/filters/client_channel/lb_policy/grpclb/client_load_reporting_filter.h )   s.files += %w( src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.h )   s.files += %w( src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb_channel.h )   s.files += %w( src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb_client_stats.h )   s.files += %w( src/core/ext/filters/client_channel/lb_policy/grpclb/load_balancer_api.h )   s.files += %w( src/core/ext/filters/client_channel/lb_policy/grpclb/proto/grpc/lb/v1/load_balancer.pb.h )-  s.files += %w( third_party/nanopb/pb.h )",It was intentional to split the sources from the headers as separate targets so that some of the targets could just depend on the headers without having to also depend on the sources for building (see the comment above about the mechanics of this PR). I don't actually know the Ruby implications of this - is there a reason why the source-only gem doesn't also include the headers that are listed in filegroups for it?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,134850546,2017-08-23T19:39:43Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1602,15 +1658,27 @@ static void lb_on_response_received_locked(grpc_exec_ctx *exec_ctx, void *arg,             }             grpc_grpclb_destroy_serverlist(serverlist);           } else { /* new serverlist */+            /* record the old status */+            /* TODO(juanlishen): this assumes that num_servers never decreases+             * to 0 once it's positive */+            bool first_serverlist = glb_policy->serverlist == NULL;","This code is running under the combiner (essentially a lock), so it's fine to clear `fallback_backend_addresses` before setting `serverlist`.  The important thing is that they're both done in the same place; it doesn't matter which happens first, because they're both done while holding the lock.I think putting it in the `else` on line 1668 is fine.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,134851647,2017-08-23T19:44:52Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1783,6 +1866,17 @@ static void glb_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,         &glb_policy->lb_channel_connectivity,         &glb_policy->lb_channel_on_connectivity_changed, NULL);   }++  // Propagate update to fallback_backend_addresses if we haven't heard any valid +  // serverlist from the balancer.+  if (glb_policy->serverlist == NULL) {","I don't think this is a problem.  Once we set the serverlist, I don't think we ever unset it.  We may replace it with a new serverlist, but I don't think we ever set it to NULL.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,134852555,2017-08-23T19:48:48Z,test/cpp/end2end/grpclb_end2end_test.cc,"@@ -597,43 +597,40 @@ TEST_F(SingleBalancerTest, InitiallyEmptyServerlist) { TEST_F(SingleBalancerTest, Fallback) {   const int kFallbackTimeoutMs = 200 * grpc_test_slowdown_factor();   const int kServerlistDelayMs = 500 * grpc_test_slowdown_factor();-  const int kCallDeadlineMs = 1000 * grpc_test_slowdown_factor();+  const size_t kNumBackendInResolution = backends_.size() / 2;    ResetStub(kFallbackTimeoutMs);   std::vector<AddressData> addresses;   addresses.emplace_back(AddressData{balancer_servers_[0].port_, true, """"});-  addresses.emplace_back(AddressData{balancer_servers_[1].port_, true, """"});-  addresses.emplace_back(AddressData{balancer_servers_[2].port_, false, """"});+  for (size_t i = 0; i < kNumBackendInResolution; ++i) {+    addresses.emplace_back(AddressData{backend_servers_[i].port_, false, """"});+  }   SetNextResolution(addresses); -  // First response is an empty serverlist, sent right away.-  ScheduleResponseForBalancer(0, LoadBalanceResponse(), 0);   // Send non-empty serverlist only after kServerlistDelayMs   ScheduleResponseForBalancer(-      0, BalancerServiceImpl::BuildResponseForBackends(GetBackendPorts(), {}),+      0, +      BalancerServiceImpl::BuildResponseForBackends(+          GetBackendPorts(kNumBackendInResolution /* begin */), {}),       kServerlistDelayMs);    const gpr_timespec second_call_time = gpr_time_add(       gpr_now(GPR_CLOCK_REALTIME),        gpr_time_from_millis(kServerlistDelayMs * 1.1, GPR_TIMESPAN)); -  const auto t0 = system_clock::now();   // The first request. The client will block while it's still trying to    // contact the balancer.-  const auto& statuses_and_responses_1 =-      SendRpc(kMessage_, num_backends_);-  const auto ellapsed_ms_1 =-      std::chrono::duration_cast<std::chrono::milliseconds>(-          system_clock::now() - t0);+  const auto& statuses_and_responses_1 = SendRpc(kMessage_, ","Yeah, it looks like there are a few other places where they're being used incorrectly.  In particular, we shouldn't be using references when assigning to a temporary value (such as the return value of a function) that is not itself a reference.  (I'll send you an internal doc that explains this in more detail.)  Feel free to fix any such places where we're doing that.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/12228,134899673,2017-08-23T23:57:57Z,test/cpp/end2end/client_lb_end2end_test.cc,"@@ -517,24 +531,59 @@ TEST_F(ClientLbEnd2endTest, RoundRobinReconnect) {   // state READY in the order in which the addresses are specified,   // which is only true because the backends are all local.   for (size_t i = 0; i < servers_.size(); ++i) {-    SendRpc();+    CheckRpcSendOk();     EXPECT_EQ(1, servers_[i]->service_.request_count()) << ""for backend #"" << i;   }-  // Check LB policy name for the channel.-  EXPECT_EQ(""round_robin"", channel_->GetLoadBalancingPolicyName());-   // Kill all servers   for (size_t i = 0; i < servers_.size(); ++i) {     servers_[i]->Shutdown(false);   }   // Client request should fail.-  SendRpc(false);+  CheckRpcSendFailure();    // Bring servers back up on the same port (we aren't recreating the channel).   StartServers(kNumServers, ports);    // Client request should succeed.-  SendRpc();+  CheckRpcSendOk();+}++TEST_F(ClientLbEnd2endTest, RoundRobinSingleReconnect) {+  const int kNumServers = 2;+  StartServers(kNumServers);+  ResetStub(""round_robin"");+  std::vector<int> ports;+  for (const auto& server : servers_) {+    ports.emplace_back(server->port_);+  }+  SetNextResolution(ports);+  for (size_t i = 0; i < servers_.size(); ++i) {+    CheckRpcSendOk();+    EXPECT_EQ(1, servers_[i]->service_.request_count()) << ""for backend #"" << i;+  }+  // One request should have gone to each server.+  for (size_t i = 0; i < servers_.size(); ++i) {+    EXPECT_EQ(1, servers_[i]->service_.request_count());+  }+  // Check LB policy name for the channel.+  EXPECT_EQ(""round_robin"", channel_->GetLoadBalancingPolicyName());+  const auto pre_death = servers_[0]->service_.request_count();+  // Kill the first server.+  servers_[0]->Shutdown(true);+  // Client request still succeed. May need retrying if RR had returned a pick","That's implicitly tested by the fact that `EXPECT_EQ(pre_death, post_death)` succeeds. However, I've added an extra set of requests to drive the point home.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/12228,134902890,2017-08-24T00:27:57Z,src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.c,"@@ -630,13 +639,58 @@ static void rr_connectivity_changed_locked(grpc_exec_ctx *exec_ctx, void *arg,         GRPC_CLOSURE_SCHED(exec_ctx, pp->on_complete, GRPC_ERROR_NONE);         gpr_free(pp);       }+      rr_subchannel_list_unref(exec_ctx, sd->subchannel_list,+                               ""sd_shutdown+started_picking"");+      // unref the ""rr_connectivity_update"" weak ref from start_picking.+      GRPC_LB_POLICY_WEAK_UNREF(exec_ctx, &p->base,+                                ""rr_connectivity_sd_shutdown"");+    } else {+      // Policy isn't shutting down, we aren't in connectivity shutdown (from","The moment `num_shutdown` equals `num_subchannels`, the policy will go into shutdown. Given that initially `num_shutdown < num_subchannels`, and that `num_shutdown` is only incremented by one _before_ performing the `num_shutdown == num_subchannels` test that'd put the policy in shutdown, it's impossible for `num_shutdown` to ever be `≥ num_subchannels`. If we have a single subchannel and it reports as shutdown, that event will be captured by ` rr_connectivity_changed_locked`, which will first call `update_state_counters_locked`, making `num_shutdown` be 1. After that, `update_lb_connectivity_status_locked` will detect that `num_subchannels == num_shutdown`, which will make `p->shutdown` true and the subchannel will _not_ try to reconnect. In fact, this scenario is precisely what the `RoundRobinReresolve` (renamed it) testcase covers. Changing `kNumServers` to 1 would literally make it so, but any other value has the same effect (while adding more complexity to the dance behind the scenes). At the end of the day, `rr_connectivity_changed_locked` will be called with an initial `num_shutdown == num_subchannels - 1`, which will become an equality in the manner described above. This is independent of there being one or many subchannels in flux.<hr>All that being said, we may want to use something other than `num_subchannels` to compare against `num_shutdown` in order to put the policy in shutdown and trigger a re-resolution. For example, we may want to shutdown-and-reresolve after `num_subchannels/2` subchannels have gone into shutdown (note that this is orthogonal to reconnections, the same way subchannels currently bail out the moment they detect the policy is shutting down). This all is TBD and suitable for a separate PR.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12228,135042223,2017-08-24T15:07:56Z,src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.c,"@@ -630,13 +639,58 @@ static void rr_connectivity_changed_locked(grpc_exec_ctx *exec_ctx, void *arg,         GRPC_CLOSURE_SCHED(exec_ctx, pp->on_complete, GRPC_ERROR_NONE);         gpr_free(pp);       }+      rr_subchannel_list_unref(exec_ctx, sd->subchannel_list,+                               ""sd_shutdown+started_picking"");+      // unref the ""rr_connectivity_update"" weak ref from start_picking.+      GRPC_LB_POLICY_WEAK_UNREF(exec_ctx, &p->base,+                                ""rr_connectivity_sd_shutdown"");+    } else {+      // Policy isn't shutting down, we aren't in connectivity shutdown (from","I think I wasn't clear in expressing my concern here.  Let me try a different way.The code in `update_state_counters_locked()` updates the counters based on `prev_connectivity_state` and `curr_connectivity_state`, and it assumes that it will be called whenever the state changes.  However, in this new code, when we try to reconnect, we reset `prev_connectivity_state` and `curr_connectivity_state` without calling `update_state_counters_locked()`, which means that we're not updating the counters appropriately.In particular, the next time `update_state_counters_locked()` is called, `prev_connectivity_state` will no longer be set to `SHUTDOWN`, so `num_shutdown` will never be decremented, which means that it will grow until we have seen the same number of shutdowns as the number of subchannels.  For example, let's say that we have 3 subchannels, A, B, and C.  If we have 3 transient failures that cause us to reconnect (regardless of how those failures are distributed across the subchannels -- could be 3 failures on A, or one on A and two on B, or one failure on each), we will put the policy into shutdown, even if all of those reconnections are successful.Conversely, if the new subchannel manages to reconnect immediately, the call to `grpc_subchannel_check_connectivity()` on line 666 could return `READY` immediately, in which case we would fail to increment the `num_ready` counter.I'm not sure what the easiest way to fix this is.  My first thought was that we should simply call `update_state_counters_locked()` again right after we reset `curr_connectivity_state`.  But if we did that, then we'd never notice that all of the subchannels had gone into state `SHUTDOWN`, because they'd never stay there.  It might be that we need to explicitly track the set of subchannels that's currently trying to reconnect.Also note that we should probably not be resetting `prev_connectivity_state` until after `update_state_counters_locked()` has a look at the current value -- in fact, we might even want to have `update_state_counters_locked()` update `prev_connectivity_state` after it's done updating the counters.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12210,135044248,2017-08-24T15:14:21Z,test/cpp/naming/resolver_component_test.cc,"@@ -87,32 +97,50 @@ bool convert_string_to_bool(std::string bool_str) {   } } -vector<GrpcLBAddress> parse_expected_addrs(std::string expected_addrs) {+void ExpectTokenAndMoveForward(const char *token, std::string &expected_addrs) {",References should only be used for `const` parameters.https://google.github.io/styleguide/cppguide.html#Reference_Arguments,
108421,inkel,https://api.github.com/repos/grpc/grpc/pulls/12283,135081784,2017-08-24T17:39:17Z,src/ruby/lib/grpc/core/call.rb,"@@ -0,0 +1,20 @@+module GRPC+  module Core+    class Call+      # call-seq:+      # metadata = call.metadata+      #+      # Gets the metadata object saved the call.+      attr_reader :metadata++      # call-seq:+      # call.metadata = metadata+      #+      # Saves the metadata hash on the call.+      def metadata=(val)+        raise TypeError, ""expected Hash, got #{val.class}"" if val && !val.is_a?(::Hash)","@chad I can see that, but `nil.class == NilClass`, so checking that `val.is_a?(Hash)` will in a way check that is not `nil`.Anyway, I did a quick benchmark and `if val && !val.is_a?(Hash)` is 1.32 times faster than `unless val.is_a?(Hash)`, at least in my machine.",
3124,tenderlove,https://api.github.com/repos/grpc/grpc/pulls/12283,135085140,2017-08-24T17:52:46Z,src/ruby/lib/grpc/core/call.rb,"@@ -0,0 +1,20 @@+module GRPC+  module Core+    class Call+      # call-seq:+      # metadata = call.metadata+      #+      # Gets the metadata object saved the call.+      attr_reader :metadata++      # call-seq:+      # call.metadata = metadata+      #+      # Saves the metadata hash on the call.+      def metadata=(val)+        raise TypeError, ""expected Hash, got #{val.class}"" if val && !val.is_a?(::Hash)",@inkel changing to `unless val.is_a?(::Hash)` would not be the same logic.  The current conditional allows `nil` *or* `Hash` (and the tests specify that `nil` is an acceptable value).,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12283,135089675,2017-08-24T18:10:33Z,src/ruby/lib/grpc/core/call.rb,"@@ -0,0 +1,20 @@+module GRPC+  module Core+    class Call+      # call-seq:+      # metadata = call.metadata+      #+      # Gets the metadata object saved the call.+      attr_reader :metadata++      # call-seq:+      # call.metadata = metadata+      #+      # Saves the metadata hash on the call.+      def metadata=(val)",Is this change for readability? A little unsure of the benefit since the `metadata` setter isn't intended as a part of the surface API.,
3124,tenderlove,https://api.github.com/repos/grpc/grpc/pulls/12283,135091528,2017-08-24T18:17:34Z,src/ruby/lib/grpc/core/call.rb,"@@ -0,0 +1,20 @@+module GRPC+  module Core+    class Call+      # call-seq:+      # metadata = call.metadata+      #+      # Gets the metadata object saved the call.+      attr_reader :metadata++      # call-seq:+      # call.metadata = metadata+      #+      # Saves the metadata hash on the call.+      def metadata=(val)","This PR is just to convert C to Ruby, as pure Ruby should be a little easier to work on.  It made no changes in the API surface area.  If the intention is that the `metatdata=` method is not public API, it should probably be a private method or at the very least `nodoc`.",
775012,kskalski,https://api.github.com/repos/grpc/grpc/pulls/11891,135108720,2017-08-24T19:29:00Z,CMakeLists.txt,"@@ -339,7 +339,7 @@ function(protobuf_generate_grpc_cpp)              ""${_gRPC_PROTO_GENS_DIR}/${RELFIL_WE}_mock.grpc.pb.h""              ""${_gRPC_PROTO_GENS_DIR}/${RELFIL_WE}.pb.cc""              ""${_gRPC_PROTO_GENS_DIR}/${RELFIL_WE}.pb.h""-      COMMAND $<TARGET_FILE:${_gRPC_PROTOBUF_PROTOC}>+      COMMAND ${_gRPC_PROTOBUF_PROTOC}","When running with cmake . -DgRPC_PROTOBUF_PROVIDER=package -DgRPC_ZLIB_PROVIDER=package -DgRPC_SSL_PROVIDER=packageI getCMake Error at CMakeLists.txt:336 (add_custom_command):  Error evaluating generator expression:    $<TARGET_FILE:/usr/bin/protoc>When {_gRPC_PROTOBUF_PROTOC} point to absolute path then prefixing it with anything doesn't make sense. I'm not sure what was the original intention of using TARGET_FILE here, I guess it accidentally pointed to the same directory as PROTOBUF_ROOT_DIR",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12080,135112217,2017-08-24T19:45:11Z,doc/environment_variables.md,"@@ -113,3 +113,9 @@ some configuration as environment variables that can be set.   - native (default)- a DNS resolver based around getaddrinfo(), creates a new thread to     perform name resolution   - ares - a DNS resolver based around the c-ares library++* GRPC_DISABLE_CHANNEL_CONNECTIVITY_WATCHER+  The channel connectivity watcher uses one extra thread to check the channel",Maybe note that this is a temporary hack and will be removed in the future once we have support for automatically reestablishing failed connections?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12080,135112503,2017-08-24T19:46:26Z,src/cpp/client/channel_cc.cc,"@@ -35,17 +35,151 @@ #include <grpc/slice.h> #include <grpc/support/alloc.h> #include <grpc/support/log.h>+#include <grpc/support/sync.h>+#include <grpc/support/thd.h>+#include <grpc/support/time.h>+#include <grpc/support/useful.h> #include ""src/core/lib/profiling/timers.h""+#include ""src/core/lib/support/env.h""  namespace grpc { +namespace {+int kConnectivityCheckIntervalMsec = 500;+void WatchStateChange(void* arg);++class TagSaver final : public CompletionQueueTag {+ public:+  explicit TagSaver(void* tag) : tag_(tag) {}+  ~TagSaver() override {}+  bool FinalizeResult(void** tag, bool* status) override {+    *tag = tag_;+    delete this;+    return true;+  }++ private:+  void* tag_;+};++// Constantly watches channel connectivity status to reconnect a transiently+// disconnected channel. This is a temporary work-around before we have retry+// support.+class ChannelConnectivityWatcher {+ public:+  ChannelConnectivityWatcher() : thd_id_(0) {+    char* env = gpr_getenv(""GRPC_DISABLE_CHANNEL_CONNECTIVITY_WATCHER"");+    bool disabled = false;+    if (env != nullptr) {+      static const char* truthy[] = {""yes"",  ""Yes"",  ""YES"", ""true"",+                                     ""True"", ""TRUE"", ""1""};+      for (size_t i = 0; i < GPR_ARRAY_SIZE(truthy); i++) {+        if (0 == strcmp(env, truthy[i])) {",Could use `gpr_stricmp()` here to avoid some of the duplicate entries in `truthy`.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12080,135114138,2017-08-24T19:54:11Z,src/cpp/client/channel_cc.cc,"@@ -35,17 +35,151 @@ #include <grpc/slice.h> #include <grpc/support/alloc.h> #include <grpc/support/log.h>+#include <grpc/support/sync.h>+#include <grpc/support/thd.h>+#include <grpc/support/time.h>+#include <grpc/support/useful.h> #include ""src/core/lib/profiling/timers.h""+#include ""src/core/lib/support/env.h""  namespace grpc { +namespace {+int kConnectivityCheckIntervalMsec = 500;+void WatchStateChange(void* arg);++class TagSaver final : public CompletionQueueTag {+ public:+  explicit TagSaver(void* tag) : tag_(tag) {}+  ~TagSaver() override {}+  bool FinalizeResult(void** tag, bool* status) override {+    *tag = tag_;+    delete this;+    return true;+  }++ private:+  void* tag_;+};++// Constantly watches channel connectivity status to reconnect a transiently+// disconnected channel. This is a temporary work-around before we have retry+// support.+class ChannelConnectivityWatcher {+ public:+  ChannelConnectivityWatcher() : thd_id_(0) {+    char* env = gpr_getenv(""GRPC_DISABLE_CHANNEL_CONNECTIVITY_WATCHER"");+    bool disabled = false;+    if (env != nullptr) {+      static const char* truthy[] = {""yes"",  ""Yes"",  ""YES"", ""true"",+                                     ""True"", ""TRUE"", ""1""};+      for (size_t i = 0; i < GPR_ARRAY_SIZE(truthy); i++) {+        if (0 == strcmp(env, truthy[i])) {+          disabled = true;+          break;+        }+      }+    }+    gpr_free(env);+    if (!disabled) {+      gpr_thd_options options = gpr_thd_options_default();+      gpr_thd_options_set_joinable(&options);+      gpr_thd_new(&thd_id_, &WatchStateChange, this, &options);+    }+  }++  ~ChannelConnectivityWatcher() {+    cq_.Shutdown();+    if (thd_id_ != 0) {+      gpr_thd_join(thd_id_);+    }+  }++  void WatchStateChangeImpl() {+    bool ok = false;+    void* tag = NULL;+    CompletionQueue::NextStatus status = CompletionQueue::GOT_EVENT;+    while (status != CompletionQueue::SHUTDOWN) {+      status = cq_.AsyncNext(&tag, &ok, gpr_inf_past(GPR_CLOCK_REALTIME));+      // Make sure we've seen 2 TIMEOUTs before going to sleep+      if (status == CompletionQueue::TIMEOUT) {+        status = cq_.AsyncNext(&tag, &ok, gpr_inf_past(GPR_CLOCK_REALTIME));+      }+      if (status == CompletionQueue::TIMEOUT) {","Minor nit: Maybe move this inside of the preceding `if` block, so that we don't have to evaluate the condition twice if `status` is not `TIMEOUT`?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12080,135114231,2017-08-24T19:54:43Z,src/cpp/client/channel_cc.cc,"@@ -35,17 +35,151 @@ #include <grpc/slice.h> #include <grpc/support/alloc.h> #include <grpc/support/log.h>+#include <grpc/support/sync.h>+#include <grpc/support/thd.h>+#include <grpc/support/time.h>+#include <grpc/support/useful.h> #include ""src/core/lib/profiling/timers.h""+#include ""src/core/lib/support/env.h""  namespace grpc { +namespace {+int kConnectivityCheckIntervalMsec = 500;+void WatchStateChange(void* arg);++class TagSaver final : public CompletionQueueTag {+ public:+  explicit TagSaver(void* tag) : tag_(tag) {}+  ~TagSaver() override {}+  bool FinalizeResult(void** tag, bool* status) override {+    *tag = tag_;+    delete this;+    return true;+  }++ private:+  void* tag_;+};++// Constantly watches channel connectivity status to reconnect a transiently+// disconnected channel. This is a temporary work-around before we have retry+// support.+class ChannelConnectivityWatcher {+ public:+  ChannelConnectivityWatcher() : thd_id_(0) {+    char* env = gpr_getenv(""GRPC_DISABLE_CHANNEL_CONNECTIVITY_WATCHER"");+    bool disabled = false;+    if (env != nullptr) {+      static const char* truthy[] = {""yes"",  ""Yes"",  ""YES"", ""true"",+                                     ""True"", ""TRUE"", ""1""};+      for (size_t i = 0; i < GPR_ARRAY_SIZE(truthy); i++) {+        if (0 == strcmp(env, truthy[i])) {+          disabled = true;+          break;+        }+      }+    }+    gpr_free(env);+    if (!disabled) {+      gpr_thd_options options = gpr_thd_options_default();+      gpr_thd_options_set_joinable(&options);+      gpr_thd_new(&thd_id_, &WatchStateChange, this, &options);+    }+  }++  ~ChannelConnectivityWatcher() {+    cq_.Shutdown();+    if (thd_id_ != 0) {+      gpr_thd_join(thd_id_);+    }+  }++  void WatchStateChangeImpl() {+    bool ok = false;+    void* tag = NULL;+    CompletionQueue::NextStatus status = CompletionQueue::GOT_EVENT;+    while (status != CompletionQueue::SHUTDOWN) {+      status = cq_.AsyncNext(&tag, &ok, gpr_inf_past(GPR_CLOCK_REALTIME));+      // Make sure we've seen 2 TIMEOUTs before going to sleep+      if (status == CompletionQueue::TIMEOUT) {+        status = cq_.AsyncNext(&tag, &ok, gpr_inf_past(GPR_CLOCK_REALTIME));+      }+      if (status == CompletionQueue::TIMEOUT) {+        gpr_sleep_until(+            gpr_time_add(gpr_now(GPR_CLOCK_REALTIME),+                         gpr_time_from_millis(kConnectivityCheckIntervalMsec,+                                              GPR_TIMESPAN)));+      } else if (status == CompletionQueue::GOT_EVENT) {+        ChannelState* channel_state = static_cast<ChannelState*>(tag);+        channel_state->state = grpc_channel_check_connectivity_state(+            channel_state->channel, false);+        if (channel_state->state == GRPC_CHANNEL_SHUTDOWN) {+          void* shutdown_tag = NULL;+          channel_state->shutdown_cq.Next(&shutdown_tag, &ok);+          delete channel_state;+        } else {+          TagSaver* tag_saver = new TagSaver(channel_state);+          grpc_channel_watch_connectivity_state(+              channel_state->channel, channel_state->state,+              gpr_inf_future(GPR_CLOCK_REALTIME), cq_.cq(), tag_saver);","I don't quite understand this code.  If the tag that we put in is a pointer to a `TagSaver` object, then how come we're interpreting the tag as a pointer to a `ChannelState` object on line 114 above?Actually, I don't understand the purpose of `TagSaver` at all.  It's just unconditionally returning the tag, so why do we need it?  Why not simply return the original tag directly?",
17460127,y-zeng,https://api.github.com/repos/grpc/grpc/pulls/12080,135147861,2017-08-24T22:35:16Z,src/cpp/client/channel_cc.cc,"@@ -35,17 +35,151 @@ #include <grpc/slice.h> #include <grpc/support/alloc.h> #include <grpc/support/log.h>+#include <grpc/support/sync.h>+#include <grpc/support/thd.h>+#include <grpc/support/time.h>+#include <grpc/support/useful.h> #include ""src/core/lib/profiling/timers.h""+#include ""src/core/lib/support/env.h""  namespace grpc { +namespace {+int kConnectivityCheckIntervalMsec = 500;+void WatchStateChange(void* arg);++class TagSaver final : public CompletionQueueTag {+ public:+  explicit TagSaver(void* tag) : tag_(tag) {}+  ~TagSaver() override {}+  bool FinalizeResult(void** tag, bool* status) override {+    *tag = tag_;+    delete this;+    return true;+  }++ private:+  void* tag_;+};++// Constantly watches channel connectivity status to reconnect a transiently+// disconnected channel. This is a temporary work-around before we have retry+// support.+class ChannelConnectivityWatcher {+ public:+  ChannelConnectivityWatcher() : thd_id_(0) {+    char* env = gpr_getenv(""GRPC_DISABLE_CHANNEL_CONNECTIVITY_WATCHER"");+    bool disabled = false;+    if (env != nullptr) {+      static const char* truthy[] = {""yes"",  ""Yes"",  ""YES"", ""true"",+                                     ""True"", ""TRUE"", ""1""};+      for (size_t i = 0; i < GPR_ARRAY_SIZE(truthy); i++) {+        if (0 == strcmp(env, truthy[i])) {+          disabled = true;+          break;+        }+      }+    }+    gpr_free(env);+    if (!disabled) {+      gpr_thd_options options = gpr_thd_options_default();+      gpr_thd_options_set_joinable(&options);+      gpr_thd_new(&thd_id_, &WatchStateChange, this, &options);+    }+  }++  ~ChannelConnectivityWatcher() {+    cq_.Shutdown();+    if (thd_id_ != 0) {+      gpr_thd_join(thd_id_);+    }+  }++  void WatchStateChangeImpl() {+    bool ok = false;+    void* tag = NULL;+    CompletionQueue::NextStatus status = CompletionQueue::GOT_EVENT;+    while (status != CompletionQueue::SHUTDOWN) {+      status = cq_.AsyncNext(&tag, &ok, gpr_inf_past(GPR_CLOCK_REALTIME));+      // Make sure we've seen 2 TIMEOUTs before going to sleep+      if (status == CompletionQueue::TIMEOUT) {+        status = cq_.AsyncNext(&tag, &ok, gpr_inf_past(GPR_CLOCK_REALTIME));+      }+      if (status == CompletionQueue::TIMEOUT) {+        gpr_sleep_until(+            gpr_time_add(gpr_now(GPR_CLOCK_REALTIME),+                         gpr_time_from_millis(kConnectivityCheckIntervalMsec,+                                              GPR_TIMESPAN)));+      } else if (status == CompletionQueue::GOT_EVENT) {+        ChannelState* channel_state = static_cast<ChannelState*>(tag);+        channel_state->state = grpc_channel_check_connectivity_state(+            channel_state->channel, false);+        if (channel_state->state == GRPC_CHANNEL_SHUTDOWN) {+          void* shutdown_tag = NULL;+          channel_state->shutdown_cq.Next(&shutdown_tag, &ok);+          delete channel_state;+        } else {+          TagSaver* tag_saver = new TagSaver(channel_state);+          grpc_channel_watch_connectivity_state(+              channel_state->channel, channel_state->state,+              gpr_inf_future(GPR_CLOCK_REALTIME), cq_.cq(), tag_saver);","The tags that c++ layer gives to the c API have to be wrapped with the `CompletionQueueTag` interface, so that c++ `Next` and `AsyncNext` can handle them correctly. They will be unwrapped by [CompletionQueue::AsyncNextInternal()](https://github.com/grpc/grpc/blob/master/src/cpp/common/completion_queue_cc.cc#L66).",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,135272269,2017-08-25T14:29:43Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -551,6 +551,22 @@ static grpc_lb_addresses *process_serverlist_locked(   return lb_addresses; } +static grpc_lb_addresses *process_fallback_backend_addresses_locked(","Since we now need our own custom function to create a copy of the address list, let's do the filtering for backend addresses at the same time.  In other words, let's do the following:1. Change this function to only copy addresses with `is_balancer` set to false.2. In the places where you are currently calling `grpc_lb_addresses_copy()` with the second parameter set to true, use this function instead.3. In the places where you are currently using this function, use `grpc_lb_addresses_copy()`.4. Revert the changes we made to lb_policy_factory.[ch] to add the second parameter to `grpc_lb_addresses_copy()`.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,135273276,2017-08-25T14:33:52Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1682,10 +1700,12 @@ static void lb_on_response_received_locked(grpc_exec_ctx *exec_ctx, void *arg,             rr_handover_locked(exec_ctx, glb_policy);           }         } else {-          if (GRPC_TRACER_ON(grpc_lb_glb_trace)) {-            gpr_log(GPR_INFO,-                    ""Received empty server list. Picks will stay pending until ""-                    ""a response with > 0 servers is received"");+          if (glb_policy->serverlist == NULL) {","I think we should log a message when we get an empty serverlist, even if we have a previous serverlist.  It's just that the message should be different in each case.  If we do not have a previous serverlist, the existing message is appropriate.  If we do have a previous serverlist, then the message should say that we're continuing to use the previous serverlist.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,135275976,2017-08-25T14:44:48Z,test/cpp/end2end/grpclb_end2end_test.cc,"@@ -643,7 +643,7 @@ TEST_F(SingleBalancerTest, Fallback) {   // Wait until the serverlist is ready.   gpr_sleep_until(second_call_time);","Instead of sleeping here, I suggest sending RPCs until you see that one of the backends returned by the balancer has gotten its first RPC:```do {  SendRpc(kMessage_, 1);} while (backend_servers_[kNumBackendInResolution].service_->request_count() == 0);```Once that loop finishes, you know that the serverlist has been processed, at which point you can call `ResetCounters()` on the backends and then do another loop showing that the backends returned by the balancer are getting traffic but the backends returned by the resolver are not.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12210,135308753,2017-08-25T17:14:26Z,test/cpp/naming/resolver_component_test.cc,"@@ -367,5 +360,50 @@ int main(int argc, char **argv) {   ::testing::InitGoogleTest(&argc, argv);   grpc::testing::InitTest(&argc, &argv, true); -  return RUN_ALL_TESTS();+  grpc_init();++  SubProcess *dns_server_subprocess = NULL;++  if (FLAGS_start_local_dns_server == true) {+    /* spawn a DNS server subprocess*/+    local_dns_server_port = grpc_pick_unused_port_or_die();+    std::string my_bin = argv[0];+    std::string bin_dir = my_bin.substr(0, my_bin.rfind('/'));+    std::vector<std::string> args = {+        ""tools/run_tests/python_utils/dns_server.py"",+        ""--dns_port="" + std::to_string(local_dns_server_port)};+    dns_server_subprocess = new SubProcess(args);++    // Wait for the DNS server to stand up.+    // TODO: can we get rid of the need to sleep here?","This seems a bit brittle, since we don't really have any guarantee as to how long it will take the DNS server to start up.  A better approach might be to have a loop where we periodically send a query to the DNS server (maybe via ""dig"") and keep looping until it succeeds.  Once we've gotten a successful result from it, we know it's up.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,135336186,2017-08-25T19:27:47Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1658,21 +1677,20 @@ static void lb_on_response_received_locked(grpc_exec_ctx *exec_ctx, void *arg,             }             grpc_grpclb_destroy_serverlist(serverlist);           } else { /* new serverlist */-            /* record the old status */-            /* TODO(juanlishen): this assumes that num_servers never decreases-             * to 0 once it's positive */-            bool first_serverlist = glb_policy->serverlist == NULL;             if (glb_policy->serverlist != NULL) {               /* dispose of the old serverlist */               grpc_grpclb_destroy_serverlist(glb_policy->serverlist);-            } +            }             /* and update the copy in the glb_lb_policy instance. This              * serverlist instance will be destroyed either upon the next              * update or in glb_destroy() */             glb_policy->serverlist = serverlist;             glb_policy->serverlist_index = 0;-            if (first_serverlist) {-              /* Don't use fallback any more. */+            /* dispose the fallback (if any). It should only be done once when the +             * first non-empty \a serverlist is received */+            if (glb_policy->fallback_backend_addresses != NULL) {","Yes, these two conditions are mutual exclusive. But I separated them because- the processing of the `serverlist` and the processing of the fallback can be clearly separated;- the fallback addresses can be destroyed just after the `glb_policy` has a non-empty `serverlist` (this order doesn't improve any correctness, but it's more consistent with (my) intuition);- this is consistent with the resolution update code on line 1896 (although it can also be changed to use `serverlist` to check).",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,135352152,2017-08-25T20:59:31Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1783,6 +1906,17 @@ static void glb_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,         &glb_policy->lb_channel_connectivity,         &glb_policy->lb_channel_on_connectivity_changed, NULL);   }++  // Propagate update to \a fallback_backend_addresses if the fallback is still +  // necessary, which is indicated by a non-NULL \a fallback_backend_addresses.+  if (glb_policy->fallback_backend_addresses != NULL) {+    grpc_lb_addresses_destroy(exec_ctx, glb_policy->fallback_backend_addresses);","If we previously have a non-empty `fallback_backend_addresses`, but receive a resolution that has no backend addresses, should we still update the `fallback_backend_addresses` (i.e., delete it)? I think I should add some change to make it continue to use the previous non-empty `fallback_backend_addresses`. The reason is that we did something similar to `serverlist`: if the previous `serverlist` is non-empty (non-NULL) and we receive an empty `serverlist`, we will continue to use the old one.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,135354513,2017-08-25T21:12:38Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1783,6 +1906,17 @@ static void glb_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,         &glb_policy->lb_channel_connectivity,         &glb_policy->lb_channel_on_connectivity_changed, NULL);   }++  // Propagate update to \a fallback_backend_addresses if the fallback is still +  // necessary, which is indicated by a non-NULL \a fallback_backend_addresses.+  if (glb_policy->fallback_backend_addresses != NULL) {","Do we ever use the `expiration_interval` field in a server list? I don't find any. And we mentioned this in the GSLB meeting? Anyways, I feel it's like a time bomb for the fallback logic, because it may cause the `serverlist` to be NULL from some non-NULL value. That's  why I prefer using `fallback_backend_address != NULL` to check, which is stable and contained in the fallback logic itself, if we only want fallback in the beginning of the connection.",
17460127,y-zeng,https://api.github.com/repos/grpc/grpc/pulls/12080,135357026,2017-08-25T21:27:57Z,src/cpp/client/channel_cc.cc,"@@ -71,65 +73,79 @@ class ChannelConnectivityWatcher {     char* env = gpr_getenv(""GRPC_DISABLE_CHANNEL_CONNECTIVITY_WATCHER"");     bool disabled = false;     if (env != nullptr) {-      static const char* truthy[] = {""yes"",  ""Yes"",  ""YES"", ""true"",-                                     ""True"", ""TRUE"", ""1""};+      static const char* truthy[] = {""yes"", ""true"", ""1""};       for (size_t i = 0; i < GPR_ARRAY_SIZE(truthy); i++) {-        if (0 == strcmp(env, truthy[i])) {+        if (0 == gpr_stricmp(env, truthy[i])) {           disabled = true;           break;         }       }     }     gpr_free(env);     if (!disabled) {+      gpr_ref_init(&ref_, 0);       gpr_thd_options options = gpr_thd_options_default();-      gpr_thd_options_set_joinable(&options);+      gpr_thd_options_set_detached(&options);       gpr_thd_new(&thd_id_, &WatchStateChange, this, &options);     }   } -  ~ChannelConnectivityWatcher() {-    cq_.Shutdown();-    if (thd_id_ != 0) {-      gpr_thd_join(thd_id_);-    }-  }-   void WatchStateChangeImpl() {     bool ok = false;     void* tag = NULL;     CompletionQueue::NextStatus status = CompletionQueue::GOT_EVENT;-    while (status != CompletionQueue::SHUTDOWN) {+    while (true) {       status = cq_.AsyncNext(&tag, &ok, gpr_inf_past(GPR_CLOCK_REALTIME));       // Make sure we've seen 2 TIMEOUTs before going to sleep       if (status == CompletionQueue::TIMEOUT) {         status = cq_.AsyncNext(&tag, &ok, gpr_inf_past(GPR_CLOCK_REALTIME));+        if (status == CompletionQueue::TIMEOUT) {+          gpr_sleep_until(+              gpr_time_add(gpr_now(GPR_CLOCK_REALTIME),+                           gpr_time_from_millis(kConnectivityCheckIntervalMsec,+                                                GPR_TIMESPAN)));+          continue;+        }       }-      if (status == CompletionQueue::TIMEOUT) {-        gpr_sleep_until(-            gpr_time_add(gpr_now(GPR_CLOCK_REALTIME),-                         gpr_time_from_millis(kConnectivityCheckIntervalMsec,-                                              GPR_TIMESPAN)));-      } else if (status == CompletionQueue::GOT_EVENT) {-        ChannelState* channel_state = static_cast<ChannelState*>(tag);-        channel_state->state = grpc_channel_check_connectivity_state(-            channel_state->channel, false);-        if (channel_state->state == GRPC_CHANNEL_SHUTDOWN) {-          void* shutdown_tag = NULL;-          channel_state->shutdown_cq.Next(&shutdown_tag, &ok);-          delete channel_state;-        } else {-          TagSaver* tag_saver = new TagSaver(channel_state);-          grpc_channel_watch_connectivity_state(-              channel_state->channel, channel_state->state,-              gpr_inf_future(GPR_CLOCK_REALTIME), cq_.cq(), tag_saver);+      ChannelState* channel_state = static_cast<ChannelState*>(tag);+      channel_state->state =+          grpc_channel_check_connectivity_state(channel_state->channel, false);+      if (channel_state->state == GRPC_CHANNEL_SHUTDOWN) {+        void* shutdown_tag = NULL;+        channel_state->shutdown_cq.Next(&shutdown_tag, &ok);+        delete channel_state;+        if (gpr_unref(&ref_)) {+          gpr_mu_lock(&g_watcher_mu_);+          delete g_watcher_;+          g_watcher_ = nullptr;+          gpr_mu_unlock(&g_watcher_mu_);+          break;         }+      } else {+        TagSaver* tag_saver = new TagSaver(channel_state);+        grpc_channel_watch_connectivity_state(+            channel_state->channel, channel_state->state,+            gpr_inf_future(GPR_CLOCK_REALTIME), cq_.cq(), tag_saver);       }     }   } -  void StartWatching(grpc_channel* channel) {+  static void StartWatching(grpc_channel* channel) {+    gpr_once_init(&g_connectivity_watcher_once_, InitConnectivityWatcherOnce);+    gpr_mu_lock(&g_watcher_mu_);+    if (g_watcher_ == nullptr) {+      g_watcher_ = new ChannelConnectivityWatcher();+    }+    g_watcher_->StartWatchingLocked(channel);+    gpr_mu_unlock(&g_watcher_mu_);+  }++  static void InitOnce() { gpr_mu_init(&g_watcher_mu_); }++ private:+  void StartWatchingLocked(grpc_channel* channel) {     if (thd_id_ != 0) {+      gpr_ref(&ref_);       ChannelState* channel_state = new ChannelState(channel);       // The first grpc_channel_watch_connectivity_state() is not used to","The two `grpc_channel_watch_connectivity_state` are queued in different completion queues. NULL tag is given to the `shutdown_cq`, which belongs to each `ChannelState`. `ChannelConnectivityWatcher::cq_` won't report a NULL tag.",
17460127,y-zeng,https://api.github.com/repos/grpc/grpc/pulls/12080,135357414,2017-08-25T21:30:35Z,src/cpp/client/channel_cc.cc,"@@ -71,65 +73,79 @@ class ChannelConnectivityWatcher {     char* env = gpr_getenv(""GRPC_DISABLE_CHANNEL_CONNECTIVITY_WATCHER"");     bool disabled = false;     if (env != nullptr) {-      static const char* truthy[] = {""yes"",  ""Yes"",  ""YES"", ""true"",-                                     ""True"", ""TRUE"", ""1""};+      static const char* truthy[] = {""yes"", ""true"", ""1""};       for (size_t i = 0; i < GPR_ARRAY_SIZE(truthy); i++) {-        if (0 == strcmp(env, truthy[i])) {+        if (0 == gpr_stricmp(env, truthy[i])) {           disabled = true;           break;         }       }     }     gpr_free(env);     if (!disabled) {+      gpr_ref_init(&ref_, 0);","Checked `sync.c`, I think it should be okay to initialize the refcount to 0, as long as we won't call `gpr_unref(&ref_)` before calling the first `gpr_ref(&ref_)`.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12100,135455295,2017-08-28T07:13:19Z,src/ruby/lib/grpc/generic/active_call.rb,"@@ -645,5 +666,9 @@ def initialize(wrapped)     Operation = view_class(:cancel, :cancelled?, :deadline, :execute,                            :metadata, :status, :start_call, :wait, :write_flag,                            :write_flag=, :trailing_metadata)++    # InterceptableView further limits access to an ActiveCall's methods+    # for use in interceptors on the client+    InterceptableView = view_class(:deadline, :metadata, :trailing_metadata)","Whoops, sorry! Realizing that `metadata` and `trailing_metadata` are probably not useful as well, since both only show the metadata/trailers sent from the server, and won't contain anything at the time that the interceptor sees them. Can we remove these too please?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,135564348,2017-08-28T16:10:35Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1783,6 +1906,17 @@ static void glb_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,         &glb_policy->lb_channel_connectivity,         &glb_policy->lb_channel_on_connectivity_changed, NULL);   }++  // Propagate update to \a fallback_backend_addresses if the fallback is still +  // necessary, which is indicated by a non-NULL \a fallback_backend_addresses.+  if (glb_policy->fallback_backend_addresses != NULL) {","We do not currently ever set `serverlist` to NULL once we originally set it, and I think it's safe to rely on that.  We might need to change this in the future if we decide to also start using the fallback if we can't talk to any of the backends indicated in the serverlist, but for now, the code guarantees this.To say this another way: Currently, we are structuring the code such that only one of `serverlist` and `fallback_backend_addresses` will ever be non-NULL.  As a result, I think we should use the same criteria everywhere for determining which of those two fields we should update.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,135564956,2017-08-28T16:12:16Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1783,6 +1906,17 @@ static void glb_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,         &glb_policy->lb_channel_connectivity,         &glb_policy->lb_channel_on_connectivity_changed, NULL);   }++  // Propagate update to \a fallback_backend_addresses if the fallback is still +  // necessary, which is indicated by a non-NULL \a fallback_backend_addresses.+  if (glb_policy->fallback_backend_addresses != NULL) {+    grpc_lb_addresses_destroy(exec_ctx, glb_policy->fallback_backend_addresses);","If the resolver removes all backend addresses, that means that the backends have been removed, and we do not want to keep using the old values.  This is what would happen if we were actually using the round_robin policy directly, and I don't see why the behavior should be any different here.  So I think the current code is fine.I'm not sure why we deliberately skip serverlists with zero entries, since that should never happen.  Maybe @dgquintas knows.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,135565754,2017-08-28T16:15:09Z,test/cpp/end2end/grpclb_end2end_test.cc,"@@ -237,7 +237,7 @@ class BalancerServiceImpl : public BalancerService {               .num_calls_finished_with_client_failed_to_send();       client_stats_.num_calls_finished_known_received +=           request.client_stats().num_calls_finished_known_received();-      for (const auto& drop_token_count :+      for (const auto drop_token_count :","I think the `&` is fine here, because the protobuf `calls_finish_with_drop()` method returns a reference to a `RepeatedPtrField<>`, so its elements will remain existing as long as the protobuf object does.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,135567891,2017-08-28T16:25:23Z,src/core/ext/filters/client_channel/lb_policy_factory.h,"@@ -66,8 +66,9 @@ typedef struct grpc_lb_addresses { grpc_lb_addresses *grpc_lb_addresses_create(     size_t num_addresses, const grpc_lb_user_data_vtable *user_data_vtable); -/** Creates a copy of \a addresses. */-grpc_lb_addresses *grpc_lb_addresses_copy(const grpc_lb_addresses *addresses);+/** Creates a copy of \a addresses. When \a only_backends is true, does not ",This comment now documents a parameter that no longer exists.There should be no differences between this file and the version in master.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,135568779,2017-08-28T16:28:41Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1658,21 +1677,20 @@ static void lb_on_response_received_locked(grpc_exec_ctx *exec_ctx, void *arg,             }             grpc_grpclb_destroy_serverlist(serverlist);           } else { /* new serverlist */-            /* record the old status */-            /* TODO(juanlishen): this assumes that num_servers never decreases-             * to 0 once it's positive */-            bool first_serverlist = glb_policy->serverlist == NULL;             if (glb_policy->serverlist != NULL) {               /* dispose of the old serverlist */               grpc_grpclb_destroy_serverlist(glb_policy->serverlist);-            } +            }             /* and update the copy in the glb_lb_policy instance. This              * serverlist instance will be destroyed either upon the next              * update or in glb_destroy() */             glb_policy->serverlist = serverlist;             glb_policy->serverlist_index = 0;-            if (first_serverlist) {-              /* Don't use fallback any more. */+            /* dispose the fallback (if any). It should only be done once when the +             * first non-empty \a serverlist is received */+            if (glb_policy->fallback_backend_addresses != NULL) {","> - the processing of the `serverlist` and the processing of the fallback can be clearly separated;As per my comment elsewhere, I think the code currently guarantees that exactly one of `serverlist` and `fallback_backend_addresses` will be non-NULL, and I think we should be consistent about using a single criteria to determine which one should be set.> - the fallback addresses can be destroyed just after the `glb_policy` has a non-empty `serverlist` (this order doesn't improve any correctness, but it's more consistent with (my) intuition);As you say, this doesn't improve correctness, so I don't think this is an issue.  It's important to understand the locking properties of this code, and I think your intuition needs to take that into account. :)> - this is consistent with the resolution update code on line 1896 (although it can also be changed to use `serverlist` to check).As I mentioned there, I think we should be consistent about this.  I think both places should look at `serverlist`.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,135605195,2017-08-28T18:59:53Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1783,6 +1906,17 @@ static void glb_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,         &glb_policy->lb_channel_connectivity,         &glb_policy->lb_channel_on_connectivity_changed, NULL);   }++  // Propagate update to \a fallback_backend_addresses if the fallback is still +  // necessary, which is indicated by a non-NULL \a fallback_backend_addresses.+  if (glb_policy->fallback_backend_addresses != NULL) {","So I guess we currently don't use the expiration information for the servers. Then using `serverlist` to determine the status for fallback is also good. Maybe I am being paranoid, but I feel it's still slightly riskier, because if `expiration_interval` is used in the future, we need to care about changing the fallback code to not use fallback unexpectedly. Admittedly, using `serverlist` to determine the fallback status is better if we do want to fall back when the number of servers drops to zero, which is not our target behavior for now. Yes, I totally agree that we should use a single criteria to determine whether we still need to update the fallback (I say ""whether we still need to update the fallback"" because we always update `serverlist`, but we don't always update the fallback because it's not preferred). Either `serverlist` or `fallback_backend_addresses` can correctly achieve the goal. But we have some different opinions about which one is better (a little bit).I will leave my reasoning in an other comment.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,135607234,2017-08-28T19:09:03Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1783,6 +1906,17 @@ static void glb_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,         &glb_policy->lb_channel_connectivity,         &glb_policy->lb_channel_on_connectivity_changed, NULL);   }++  // Propagate update to \a fallback_backend_addresses if the fallback is still +  // necessary, which is indicated by a non-NULL \a fallback_backend_addresses.+  if (glb_policy->fallback_backend_addresses != NULL) {+    grpc_lb_addresses_destroy(exec_ctx, glb_policy->fallback_backend_addresses);",Why should the `serverlist` never have zero entries? I am also curious why we don't want to accept the balancer's advice when it tells us that the `serverlist` is empty. My best guess is that we think having something to try is better than nothing.,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12305,135614047,2017-08-28T19:39:47Z,third_party/cares/config_linux/ares_config.h,"@@ -46,38 +45,29 @@ /* Specifies the number of arguments to getservbyport_r */ #define GETSERVBYPORT_R_ARGS 6 -/* Specifies the size of the buffer to pass to getservbyport_r */-#define GETSERVBYPORT_R_BUFSIZE 4096- /* Define to 1 if you have AF_INET6. */-#define HAVE_AF_INET6 1+#define HAVE_AF_INET6  /* Define to 1 if you have the <arpa/inet.h> header file. */-#define HAVE_ARPA_INET_H 1+#define HAVE_ARPA_INET_H  /* Define to 1 if you have the <arpa/nameser_compat.h> header file. */-#define HAVE_ARPA_NAMESER_COMPAT_H 1+#define HAVE_ARPA_NAMESER_COMPAT_H  /* Define to 1 if you have the <arpa/nameser.h> header file. */-#define HAVE_ARPA_NAMESER_H 1+#define HAVE_ARPA_NAMESER_H  /* Define to 1 if you have the <assert.h> header file. */-#define HAVE_ASSERT_H 1+#define HAVE_ASSERT_H  /* Define to 1 if you have the `bitncmp' function. */ /* #undef HAVE_BITNCMP */  /* Define to 1 if bool is an available type. */-#define HAVE_BOOL_T 1+#define HAVE_BOOL_T -/* Define HAVE_CLOCK_GETTIME_MONOTONIC to 1 if you have the clock_gettime- * function and monotonic timer.- *- * Note: setting HAVE_CLOCK_GETTIME_MONOTONIC causes use of the clock_gettime- * function from glibc, don't set it to support glibc < 2.17 */-#ifndef GPR_BACKWARDS_COMPATIBILITY_MODE-  #define HAVE_CLOCK_GETTIME_MONOTONIC 1",I think we need to preserve this manual edit. `HAVE_CLOCK_GETTIME_MONOTONIC` being defined forces a dependency on glibc 1.17+ - it should break a couple of ruby distrib tests.,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12305,135614956,2017-08-28T19:43:57Z,third_party/cares/config_linux/ares_config.h,"@@ -453,106 +409,15 @@ /* Define to the function return type for send. */ #define SEND_TYPE_RETV ssize_t -/* The size of `int', as computed by sizeof. */-#define SIZEOF_INT 4--/* The size of `long', as computed by sizeof. */-#define SIZEOF_LONG 4--/* The size of `short', as computed by sizeof. */-#define SIZEOF_SHORT 2--/* The size of `size_t', as computed by sizeof. */-#define SIZEOF_SIZE_T 4--/* The size of `struct in6_addr', as computed by sizeof. */-#define SIZEOF_STRUCT_IN6_ADDR 16--/* The size of `struct in_addr', as computed by sizeof. */-#define SIZEOF_STRUCT_IN_ADDR 4--/* The size of `time_t', as computed by sizeof. */-#define SIZEOF_TIME_T 4--/* Define to 1 if you have the ANSI C header files. */-#define STDC_HEADERS 1- /* Define to 1 if you can safely include both <sys/time.h> and <time.h>. */-#define TIME_WITH_SYS_TIME 1+#define TIME_WITH_SYS_TIME  /* Define to disable non-blocking sockets. */-/* #undef USE_BLOCKING_SOCKETS */--/* Version number of package */-#define VERSION ""-""+#undef USE_BLOCKING_SOCKETS  /* Define to avoid automatic inclusion of winsock.h */-/* #undef WIN32_LEAN_AND_MEAN */--/* Define WORDS_BIGENDIAN to 1 if your processor stores words with the most-   significant byte first (like Motorola and SPARC, unlike Intel). */-#if defined AC_APPLE_UNIVERSAL_BUILD-# if defined __BIG_ENDIAN__-#  define WORDS_BIGENDIAN 1-# endif-#else-# ifndef WORDS_BIGENDIAN-/* #  undef WORDS_BIGENDIAN */-# endif-#endif--/* Define to 1 if OS is AIX. */-#ifndef _ALL_SOURCE-/* #  undef _ALL_SOURCE */-#endif--/* Enable large inode numbers on Mac OS X 10.5.  */-#ifndef _DARWIN_USE_64_BIT_INODE-# define _DARWIN_USE_64_BIT_INODE 1-#endif--#ifdef GPR_BACKWARDS_COMPATIBILITY_MODE-  /* Redefine the fd_set macros for GLIBC < 2.15 support.","Same here, I think we also need to preserve this manual edit. Building against latest `FD_SET` macros forces the binary dependency on glibc1.5+ (a couple of ruby distrib tests should also fail on this, https://github.com/grpc/grpc/issues/11346 for context)",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,135623325,2017-08-28T20:19:26Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1611,13 +1698,30 @@ static void lb_on_response_received_locked(grpc_exec_ctx *exec_ctx, void *arg,              * update or in glb_destroy() */             glb_policy->serverlist = serverlist;             glb_policy->serverlist_index = 0;+            /* dispose the fallback (if any). It should only be done once when the ","I think using `fallback_backend_addresses` to determine the fallback status is a little better. And my main reason is that it's more coupled (inaccurate word, but I can't find a better one) with the newly-added fallback code and less coupled with the existing `serverlist` code. Specifically, `fallback_backend_addresses` is exclusively for the fallback logic, using it depends less on the other code and reduces the risk that we need to change it if the depended code changes in the future (e.g., the expiration is used). Also, we won't mix the code dealing with the `serverlist` (from line 1692 to line 1700) and the code dealing with the fallback (from line 1701 to line 1711), which I think is good to have. (Plus the order looks good to me: ""hey the new server list is ready in my hand now"", ""great, let's throw away the fallback"". Although flipping them doesn't introduce any issue to our code...)Many of the reasons are quite weak or/and personal, but I want to clarify them by my best effort. The only advantage I've understood of using `serverlist` instead is that we can reuse the if clause, which I think is even less important. However, if the advice is still to change it to use `serverlist`, I will accept it and I believe there is a reason for that but I haven't caught successfully. ",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,135643810,2017-08-28T21:45:18Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1783,6 +1906,17 @@ static void glb_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,         &glb_policy->lb_channel_connectivity,         &glb_policy->lb_channel_on_connectivity_changed, NULL);   }++  // Propagate update to \a fallback_backend_addresses if the fallback is still +  // necessary, which is indicated by a non-NULL \a fallback_backend_addresses.+  if (glb_policy->fallback_backend_addresses != NULL) {+    grpc_lb_addresses_destroy(exec_ctx, glb_policy->fallback_backend_addresses);","Thinking about this further, I suspect that this was originally added to deal with the fact that the initial response from the balancer will not include a serverlist.  I cleaned up the way that we handle the initial response from the balancer in #10821, but I didn't remove this case, since I didn't know if it was in use for anything else.  But in retrospect, that was probably too conservative of me, since the balancer protocol clearly shows that all subsequent responses should include a serverlist.@dgquintas, can you confirm that this check was originally added just to deal with the initial balancer response not including a serverlist?  If so, we can probably just remove the check.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,135646691,2017-08-28T22:00:04Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1611,13 +1698,30 @@ static void lb_on_response_received_locked(grpc_exec_ctx *exec_ctx, void *arg,              * update or in glb_destroy() */             glb_policy->serverlist = serverlist;             glb_policy->serverlist_index = 0;+            /* dispose the fallback (if any). It should only be done once when the ","I think there are two issues here.First, it seems that you're very concerned about the possibility of needing to handle the expiration case in the future, and I don't think that's something we need to worry about.  What we discussed at the meeting last week was that we were going to remove the expiration field from the load balancer protocol, because its behavior is not actually specified and it's not at all clear what it should do.  We have no plans to support this in the future, and if we did, we would need to write a new spec from scratch as to what its behavior would be.  Given that this is completely speculative, I don't think this is something we should plan for.Second, I disagree that the fallback code is independent of the serverlist.  By definition, the fallback is what happens when there's something wrong the serverlist.  Currently, ""there's something wrong the serverlist"" is defined as `serverlist == NULL`.  It's certainly possible that that will change in the future; for example, if we decide to use the fallback even after we get a serverlist if we can no longer reach any of the backends listed in the serverlist, then we might change  `serverlist == NULL` to something like `serverlist == NULL || serverlist->num_reachable_servers == 0`.  But either way, it would still be the case that the decision about whether to use the fallback will be based on the serverlist.  Ultimately, the serverlist is the primary source of information, and the fallback is what we use if there's something wrong with that primary source of information.With regard to the ordering, as I've said before, the locking here means that that's really not an issue.  And I think that as you gain more experience with our codebase, you'll see that there are many places where this sort of thing happens, and that it's something you will get used to.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12289,135658232,2017-08-28T23:10:23Z,tools/run_tests/python_utils/jobset.py,"@@ -474,11 +473,10 @@ def finish(self):     while self._running:       if self.cancelled(): pass  # poll cancellation       self.reap()-    # Clear the alarms when finished to avoid a race condition causing job-    # failures. Don't do this when running multi-VM tests because clearing-    # the alarms causes the test to stall-    if platform_string() != 'windows' and self._clear_alarms:-      signal.alarm(0)+    global have_alarm","IIC, currently `alarm(0)` is cancelling the alarm but not setting `have_alarm = False`, and the following jobset then has no pending alarm but thinks it does. But I think we can unconditionally set alarm in `reap` and cancel it in `finish`?",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/12306,135849041,2017-08-29T16:51:56Z,src/python/grpcio/grpc/_cython/_cygrpc/records.pyx.pxi,"@@ -255,10 +255,13 @@ cdef class ByteBuffer:    def __cinit__(self, bytes data):     grpc_init()+    self._own_buffer = True",This would end up being true for write ops.  This is no longer used in the current implementation however.,
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,135851843,2017-08-29T17:03:44Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1611,13 +1698,30 @@ static void lb_on_response_received_locked(grpc_exec_ctx *exec_ctx, void *arg,              * update or in glb_destroy() */             glb_policy->serverlist = serverlist;             glb_policy->serverlist_index = 0;+            /* dispose the fallback (if any). It should only be done once when the ",I see. I think I know how we viewed this differently now. I agree we should use `serverlist`.,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/12187,135864270,2017-08-29T17:51:26Z,test/cpp/end2end/grpclb_end2end_test.cc,"@@ -237,7 +237,7 @@ class BalancerServiceImpl : public BalancerService {               .num_calls_finished_with_client_failed_to_send();       client_stats_.num_calls_finished_known_received +=           request.client_stats().num_calls_finished_known_received();-      for (const auto& drop_token_count :+      for (const auto drop_token_count :",In fact it's always valid: binding a temporary object to a reference to const on the stack lengthens the lifetime of the temporary to the lifetime of the reference itself: see https://herbsutter.com/2008/01/01/gotw-88-a-candidate-for-the-most-important-const/,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/12187,135873022,2017-08-29T18:23:24Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1783,6 +1906,17 @@ static void glb_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,         &glb_policy->lb_channel_connectivity,         &glb_policy->lb_channel_on_connectivity_changed, NULL);   }++  // Propagate update to \a fallback_backend_addresses if the fallback is still +  // necessary, which is indicated by a non-NULL \a fallback_backend_addresses.+  if (glb_policy->fallback_backend_addresses != NULL) {+    grpc_lb_addresses_destroy(exec_ctx, glb_policy->fallback_backend_addresses);","Load balancers routinely return empty serverlists upon (re)starting, when they still having received information about backends. After asking @summerxyt (Yetian) why don't the LBs wait to send a non-empty response instead, he mentioned it's just how the current (internal) LB server implementation behaves. @markdroth it's not clear which check you are referring to, this thread is attached to new code. Perhaps [this](https://github.com/grpc/grpc/blob/9811915ba3fa1ccdf44b6a70fe1b1dd4782cd508/src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c#L1619)? About what to do when we receive an empty serverlist after having received non-empty ones: we do currently use the old one. Discarding it would be as simple as making `glb_policy->serverlist = NULL` [after this line](https://github.com/grpc/grpc/blob/9811915ba3fa1ccdf44b6a70fe1b1dd4782cd508/src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c#L1623). In that case, following picks would block, the same way they do when all we've received are empty ones. What to do is pretty much up to us. @slash-lib , any thoughts? ",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,135901214,2017-08-29T20:22:51Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1783,6 +1906,17 @@ static void glb_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,         &glb_policy->lb_channel_connectivity,         &glb_policy->lb_channel_on_connectivity_changed, NULL);   }++  // Propagate update to \a fallback_backend_addresses if the fallback is still +  // necessary, which is indicated by a non-NULL \a fallback_backend_addresses.+  if (glb_policy->fallback_backend_addresses != NULL) {+    grpc_lb_addresses_destroy(exec_ctx, glb_policy->fallback_backend_addresses);","Yes, that's the check I was asking about.If the only time that we ever get empty balancer lists is upon balancer startup, then we won't ever get an empty serverlist after we've already gotten a non-empty serverlist.  In that case, the check is probably fine as-is.@slash-lib can correct me if I'm wrong, but if we did ever somehow get an empty serverlist after getting a non-empty one, I don't think we want to throw out the existing serverlist.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/12187,135902245,2017-08-29T20:26:34Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1783,6 +1906,17 @@ static void glb_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,         &glb_policy->lb_channel_connectivity,         &glb_policy->lb_channel_on_connectivity_changed, NULL);   }++  // Propagate update to \a fallback_backend_addresses if the fallback is still +  // necessary, which is indicated by a non-NULL \a fallback_backend_addresses.+  if (glb_policy->fallback_backend_addresses != NULL) {+    grpc_lb_addresses_destroy(exec_ctx, glb_policy->fallback_backend_addresses);","Yetian (whom I've summoned to write his own comment on this thread) has confirmed that ""we should keep use the last cached server list."" in that scenario. I'll let him expand on this.",
5348297,summerxyt,https://api.github.com/repos/grpc/grpc/pulls/12187,135912775,2017-08-29T21:10:12Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1783,6 +1906,17 @@ static void glb_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,         &glb_policy->lb_channel_connectivity,         &glb_policy->lb_channel_on_connectivity_changed, NULL);   }++  // Propagate update to \a fallback_backend_addresses if the fallback is still +  // necessary, which is indicated by a non-NULL \a fallback_backend_addresses.+  if (glb_policy->fallback_backend_addresses != NULL) {+    grpc_lb_addresses_destroy(exec_ctx, glb_policy->fallback_backend_addresses);","The original question is related to  fallback backend resolution. In the current pending implementation, the resolver will never send a ""delete all"" (or say empty list) update. But the implementation is subject to change based on review.Same argument is applied on the balancer resolution.As for the server list returned from balancer to client, the current implementation can return an empty server list at ANY time. And yes, please keep using the old non-empty list if you receive an empty list.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12318,136088005,2017-08-30T14:40:31Z,test/cpp/end2end/client_lb_end2end_test.cc,"@@ -367,13 +385,28 @@ TEST_F(ClientLbEnd2endTest, RoundRobin) {     ports.emplace_back(server->port_);   }   SetNextResolution(ports);+  // Send one RPC per backend and make sure they are used in order.+  // Note: We cannot derive the connection order from the order reported by the+  // resolver: different polling engines introduce different delays that+  // affect which subchannel will transition into READY, even for local+  // addresses. However, given an initial connection order and in the absence of+  // disruptions, this order will be periodic.+  std::vector<int> first_connection_order;   for (size_t i = 0; i < servers_.size(); ++i) {     CheckRpcSendOk();+    UpdateConnectionOrder(servers_, &first_connection_order);   }-  // One request should have gone to each server.+  // ""first_connection_order"" has unique elements by construction. If its length+  // equals the number of servers, each server must have gotten a request.+  EXPECT_EQ(first_connection_order.size(), servers_.size());","Are we actually guaranteed that every server will have gotten a request at this point?  It seems like it could be possible for one of the servers to take too long to connect, thus having us send a second request to one of the servers that was already connected.  Perhaps the logic above needs to be changed to loop until every server has gotten at least one request?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12318,136093500,2017-08-30T14:58:16Z,test/cpp/end2end/grpclb_end2end_test.cc,"@@ -521,17 +540,12 @@ TEST_F(SingleBalancerTest, Vanilla) {       0);   // Make sure that trying to connect works without a call.   channel_->GetState(true /* try_to_connect */);-  // Send 100 RPCs per server.-  const auto& statuses_and_responses =-      SendRpc(kMessage_, kNumRpcsPerAddress * num_backends_);--  for (const auto& status_and_response : statuses_and_responses) {-    const Status& status = status_and_response.first;-    const EchoResponse& response = status_and_response.second;-    EXPECT_TRUE(status.ok()) << ""code="" << status.error_code()-                             << "" message="" << status.error_message();-    EXPECT_EQ(response.message(), kMessage_);-  }++  // We need to wait for all backends to come online.+  for (size_t i = 0; i < num_backends_; ++i) WaitForBackend(i);","This seems like it could be pretty inefficient if the backends become ready in a very different order than they are in the list.  For example, let's say that there are 5 backends and they become ready in the order 4, 3, 2, 1, 0.  We will wind up sending 5 RPCs for backend 0, 4 for backend 1, 3 for backend 2, etc.A better approach might be something like this:```bool SeenAllBackends() {  size_t seen_backends = 0;  for (const auto& backend : backends_) {    if (backend->request_count() > 0) ++seen_backends;  }  return seen_backends == backends_.size();}void WaitForAllBackends() {  while (!SeenAllBackends()) {    CheckRpcSendOk();  }  ResetBackendCounters();}```",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12318,136096017,2017-08-30T15:06:14Z,test/cpp/end2end/grpclb_end2end_test.cc,"@@ -606,49 +612,28 @@ TEST_F(SingleBalancerTest, RepeatedServerlist) {       kServerlistDelayMs);    // Send num_backends/2 requests.-  auto statuses_and_responses = SendRpc(kMessage_, num_backends_ / 2);-  // only the first half of the backends will receive them.+  CheckRpcSendOk(num_backends_ / 2);+  // only half of the backends will receive them.+  size_t num_requests = 0;   for (size_t i = 0; i < backends_.size(); ++i) {-    if (i < backends_.size() / 2)-      EXPECT_EQ(1U, backend_servers_[i].service_->request_count())-          << ""for backend #"" << i;-    else-      EXPECT_EQ(0U, backend_servers_[i].service_->request_count())-          << ""for backend #"" << i;-  }-  EXPECT_EQ(statuses_and_responses.size(), num_backends_ / 2);-  for (const auto& status_and_response : statuses_and_responses) {-    const Status& status = status_and_response.first;-    const EchoResponse& response = status_and_response.second;-    EXPECT_TRUE(status.ok()) << ""code="" << status.error_code()-                             << "" message="" << status.error_message();-    EXPECT_EQ(response.message(), kMessage_);+    num_requests += backend_servers_[i].service_->request_count();","I'm not sure this check is actually telling us anything, since it doesn't say anything about the distribution of requests across backends.  And it can't possibly fail, because if we already sent N successful requests, then the total number of requests served by all backends must be N.Stepping back a bit, what is the overall purpose of this test?  It seems like all we're really testing here is that if round_robin gets an update that is identical to its existing list of addresses, that it won't wind up changing anything.  Would it be better to just test that behavior in the round_robin test directly?",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,136130661,2017-08-30T17:06:17Z,test/cpp/end2end/grpclb_end2end_test.cc,"@@ -237,7 +237,7 @@ class BalancerServiceImpl : public BalancerService {               .num_calls_finished_with_client_failed_to_send();       client_stats_.num_calls_finished_known_received +=           request.client_stats().num_calls_finished_known_received();-      for (const auto& drop_token_count :+      for (const auto drop_token_count :","Yes. After reading both the internal totw and the external gotw, I think maybe it's generally better to avoid the `&` in such cases. The reason is detailed in the totw. In short, using a `&` here doesn't improve efficiency (because of return-value-optimization, which moves (instead of copies) the returned object to initialize the LHS object), but makes code reviewers consider more conditions to determine whether it's legit or not. ",
206364,mikelehen,https://api.github.com/repos/grpc/grpc/pulls/12339,136218742,2017-08-31T00:00:38Z,src/objective-c/GRPCClient/GRPCCall.h,"@@ -170,6 +170,11 @@ extern id const kGRPCTrailersKey; @property (atomic, copy, readwrite) NSString *serverName;  /**+ * The timeout for the RPC call in milliseconds. If set to 0, the call will not timeout.","This sounds like a value of 0 means the call could hang indefinitely or similar.  Is that really what it means?If so, that's not really what we're looking for. :-)  I'd like a way to make the call immediately attempt to connect to the backend (no backoff delay), and immediately surface an error to us if the connection fails (no retries).  That way we can do our own backoff / retry logic.So I'd expect the option we're looking for to be something like a boolean retryOnFailures or something.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12100,136251965,2017-08-31T06:06:37Z,src/ruby/spec/support/services.rb,"@@ -0,0 +1,140 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++# Test stubs for various scenarios+require 'grpc'++# A test message+class EchoMsg+  def self.marshal(_o)+    ''+  end++  def self.unmarshal(_o)+    EchoMsg.new+  end+end++# A test service with an echo implementation.+class EchoService",thanks for the de-dup of this test class,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12100,136252299,2017-08-31T06:09:44Z,src/ruby/spec/channel_connection_spec.rb,"@@ -18,38 +18,6 @@ include Timeout include GRPC::Core -# A test message",thanks for the de-dup of this test class.but can we add a `require spec_helper` at the top here for a standalone run?,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12100,136258398,2017-08-31T06:57:20Z,src/ruby/lib/grpc/generic/interceptor_registry.rb,"@@ -0,0 +1,51 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++# GRPC contains the General RPC module.+module GRPC+  ##+  # Represents a registry of added interceptors available for enumeration.+  # The registry can be used for both server and client interceptors.+  #",Can we comment here that this is class is is internal to the grpc and not for public usage? since this class is no longer used directly?,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12100,136258863,2017-08-31T07:00:26Z,src/ruby/spec/generic/interceptor_registry_spec.rb,"@@ -0,0 +1,75 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+require 'spec_helper'++describe GRPC::InterceptorRegistry do+  let(:server) { RpcServer.new }+  let(:interceptor) { TestServerInterceptor.new }+  let(:interceptors) { { key => interceptor } }+  let(:registry) { described_class.new(interceptors) }+  let(:key) { :test }++  describe 'initialization' do+    subject { registry }++    context 'with an interceptor extending GRPC::ServerInterceptor' do+      it 'should add the interceptor to the registry' do+        subject","I think this test can be removed, since IIC this functionality no longer used",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12100,136259170,2017-08-31T07:02:30Z,src/ruby/spec/generic/interceptor_registry_spec.rb,"@@ -0,0 +1,75 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+require 'spec_helper'++describe GRPC::InterceptorRegistry do+  let(:server) { RpcServer.new }+  let(:interceptor) { TestServerInterceptor.new }+  let(:interceptors) { { key => interceptor } }+  let(:registry) { described_class.new(interceptors) }+  let(:key) { :test }++  describe 'initialization' do+    subject { registry }++    context 'with an interceptor extending GRPC::ServerInterceptor' do+      it 'should add the interceptor to the registry' do+        subject+        is = registry.to_h+        expect(is.count).to eq 1+        expect(is.keys.first).to eq key+        expect(is.values.first).to eq interceptor+      end+    end++    context 'with an interceptor not extending GRPC::ServerInterceptor' do+      let(:interceptor) { Class }+      let(:err) { GRPC::InterceptorRegistry::DescendantError }++      it 'should raise an InvalidArgument exception' do+        expect { subject }.to raise_error(err)+      end+    end+  end++  describe '.[]' do+    subject { registry[key] }++    context 'when the interceptor exists with the given key' do+      it 'should return the interceptor' do+        expect(subject).to eq interceptor+      end+    end++    context 'when the interceptor does not exist with the given key' do+      let(:interceptors) { {} }++      it 'should return nil' do+        expect(subject).to be_nil+      end+    end+  end++  describe '.to_h' do","same here, I think we can remove this too since no longer used",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12100,136260065,2017-08-31T07:09:03Z,src/ruby/spec/support/helpers.rb,"@@ -0,0 +1,79 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++# GRPC contains the General RPC module.+module GRPC+  ##+  # GRPC RSpec base module+  #+  module Spec+    ##+    # A module that is used for providing generic helpers across the+    # GRPC test suite+    #+    module Helpers+      # Shortcut syntax for a GRPC RPC Server+      RpcServer = GRPC::RpcServer++      ##+      # Build an RPC server used for testing+      #+      def build_rpc_server(server_opts: {},+                           client_opts: {},+                           channel: nil)+        @server = RpcServer.new({ poll_period: 1 }.merge(server_opts))+        @port = @server.add_http2_port('0.0.0.0:0', :this_port_is_insecure)+        @host = ""0.0.0.0:#{@port}""+        @channel = channel || GRPC::Core::Channel.new(",can we get rid of the setting of `@channel` here? IIC this is unused,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12100,136264901,2017-08-31T07:33:55Z,src/ruby/spec/support/services.rb,"@@ -0,0 +1,140 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++# Test stubs for various scenarios+require 'grpc'++# A test message+class EchoMsg+  def self.marshal(_o)+    ''+  end++  def self.unmarshal(_o)+    EchoMsg.new+  end+end++# A test service with an echo implementation.+class EchoService+  include GRPC::GenericService+  rpc :an_rpc, EchoMsg, EchoMsg+  rpc :a_client_streaming_rpc, stream(EchoMsg), EchoMsg+  rpc :a_server_streaming_rpc, EchoMsg, stream(EchoMsg)+  rpc :a_bidi_rpc, stream(EchoMsg), stream(EchoMsg)+  attr_reader :received_md++  def initialize(**kw)+    @trailing_metadata = kw+    @received_md = []+  end++  def an_rpc(req, call)+    GRPC.logger.info('echo service received a request')+    call.output_metadata.update(@trailing_metadata)+    @received_md << call.metadata unless call.metadata.nil?+    req+  end++  def a_client_streaming_rpc(call)+    # iterate through requests so call can complete+    call.each_remote_read.each { |r| p r }+    EchoMsg.new+  end++  def a_server_streaming_rpc(_, _)+    [EchoMsg.new, EchoMsg.new]+  end++  def a_bidi_rpc(requests, _)+    requests.each { |r| p r }+    [EchoMsg.new, EchoMsg.new]+  end+end++EchoStub = EchoService.rpc_stub_class++# For testing server interceptors+class TestServerInterceptor < GRPC::ServerInterceptor+  def request_response(request:, call:, method:)+    p ""Received request/response call at method #{method}"" \+      "" with request #{request} for call #{call}""","similarly to the client interceptors, can we add usage of `merge_metadata_to_send` and `output_metadata[]` method in the server, and test for that metadata/trailing metadata in the client to the interceptors in this `TestServerInterceptor` class?",
233334,splittingred,https://api.github.com/repos/grpc/grpc/pulls/12100,136344037,2017-08-31T14:04:58Z,src/ruby/pb/grpc/testing/duplicate/echo_duplicate_services_pb.rb,"@@ -34,6 +34,7 @@ class Service           self.service_name = 'grpc.testing.duplicate.EchoTestService'            rpc :Echo, Grpc::Testing::EchoRequest, Grpc::Testing::EchoResponse+          rpc :ResponseStream, Grpc::Testing::EchoRequest, stream(Grpc::Testing::EchoResponse)","Adding that was the only way to get the tests to pass:```  1) Ping protobuf code generation should have the same content as created by code generation     Failure/Error: expect(got).to eq(want)       expected: ""# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# Source: src/proto/grpc/testing/duplica...choResponse\n        end\n\n        Stub = Service.rpc_stub_class\n      end\n    end\n  end\nend\n""            got: ""# Generated by the protocol buffer compiler.  DO NOT EDIT!\n# Source: src/proto/grpc/testing/duplica...hoResponse)\n        end\n\n        Stub = Service.rpc_stub_class\n      end\n    end\n  end\nend\n""       (compared using ==)       Diff:       @@ -34,6 +34,7 @@                  self.service_name = 'grpc.testing.duplicate.EchoTestService'                  rpc :Echo, Grpc::Testing::EchoRequest, Grpc::Testing::EchoResponse       +          rpc :ResponseStream, Grpc::Testing::EchoRequest, stream(Grpc::Testing::EchoResponse)                end                Stub = Service.rpc_stub_class```",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12347,136396404,2017-08-31T17:22:38Z,src/csharp/doc/docfx.json,"@@ -0,0 +1,37 @@+{+  ""metadata"": [+    {+      ""src"": [+        {+          ""files"": [""Grpc.Core/Grpc.Core.csproj"",+                    ""Grpc.Auth/Grpc.Auth.csproj"",+                    ""Grpc.Core.Testing/Grpc.Core.Testing.csproj"",+                    ""Grpc.HealthCheck/Grpc.HealthCheck.csproj"",+                    ""Grpc.Reflection/Grpc.HealthCheck.csproj""],+          ""exclude"": [ ""**/bin/**"", ""**/obj/**"" ],+          ""cwd"": ""..""+        }+      ],+      ""properties"": { ""TargetFramework"": ""net45"" },","One nit: does this not indicate only net45 support in the docs, and not netstandard1.5 support? (saw an example in https://dotnet.github.io/docfx/RELEASENOTE.html that used both a net46 and netstandard target, not sure if it's worth doing something similar).",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12100,136472232,2017-08-31T23:33:05Z,src/ruby/lib/grpc/generic/interceptor_registry.rb,"@@ -0,0 +1,52 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++# GRPC contains the General RPC module.+module GRPC+  ##+  # Represents a registry of added interceptors available for enumeration.+  # The registry can be used for both server and client interceptors.+  # This class is internal to gRPC and not meant for public usage.+  #+  class InterceptorRegistry < Hash","one more nit: instead of descending from `Hash`, can we have this class keeps it's `Hash` as an instance variable?",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12318,136495115,2017-09-01T04:06:32Z,test/cpp/end2end/grpclb_end2end_test.cc,"@@ -521,17 +540,12 @@ TEST_F(SingleBalancerTest, Vanilla) {       0);   // Make sure that trying to connect works without a call.   channel_->GetState(true /* try_to_connect */);-  // Send 100 RPCs per server.-  const auto& statuses_and_responses =-      SendRpc(kMessage_, kNumRpcsPerAddress * num_backends_);--  for (const auto& status_and_response : statuses_and_responses) {-    const Status& status = status_and_response.first;-    const EchoResponse& response = status_and_response.second;-    EXPECT_TRUE(status.ok()) << ""code="" << status.error_code()-                             << "" message="" << status.error_message();-    EXPECT_EQ(response.message(), kMessage_);-  }++  // We need to wait for all backends to come online.+  for (size_t i = 0; i < num_backends_; ++i) WaitForBackend(i);","I don't quite understand why this can be more efficient. For the time side: the total waiting time is almost equal to the time for the slowest backend to become ready in both conditions.For the space side: the total number of sent RPCs is like _the total waiting time * RPC sending rate_, which should also be the same in both conditions.What am I missing?",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/12318,137093768,2017-09-05T19:40:33Z,test/cpp/end2end/grpclb_end2end_test.cc,"@@ -606,49 +612,28 @@ TEST_F(SingleBalancerTest, RepeatedServerlist) {       kServerlistDelayMs);    // Send num_backends/2 requests.-  auto statuses_and_responses = SendRpc(kMessage_, num_backends_ / 2);-  // only the first half of the backends will receive them.+  CheckRpcSendOk(num_backends_ / 2);+  // only half of the backends will receive them.+  size_t num_requests = 0;   for (size_t i = 0; i < backends_.size(); ++i) {-    if (i < backends_.size() / 2)-      EXPECT_EQ(1U, backend_servers_[i].service_->request_count())-          << ""for backend #"" << i;-    else-      EXPECT_EQ(0U, backend_servers_[i].service_->request_count())-          << ""for backend #"" << i;-  }-  EXPECT_EQ(statuses_and_responses.size(), num_backends_ / 2);-  for (const auto& status_and_response : statuses_and_responses) {-    const Status& status = status_and_response.first;-    const EchoResponse& response = status_and_response.second;-    EXPECT_TRUE(status.ok()) << ""code="" << status.error_code()-                             << "" message="" << status.error_message();-    EXPECT_EQ(response.message(), kMessage_);+    num_requests += backend_servers_[i].service_->request_count();",I've reworked the test. We don't test this in round_robin because the code to ignore identical serverlists is in grpclb.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,137313983,2017-09-06T16:06:10Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -602,35 +644,37 @@ static bool pick_from_internal_rr_locked(     grpc_exec_ctx *exec_ctx, glb_lb_policy *glb_policy,     const grpc_lb_policy_pick_args *pick_args, bool force_async,     grpc_connected_subchannel **target, wrapped_rr_closure_arg *wc_arg) {-  // Look at the index into the serverlist to see if we should drop this call.-  grpc_grpclb_server *server =-      glb_policy->serverlist->servers[glb_policy->serverlist_index++];-  if (glb_policy->serverlist_index == glb_policy->serverlist->num_servers) {-    glb_policy->serverlist_index = 0;  // Wrap-around.-  }-  if (server->drop) {-    // Not using the RR policy, so unref it.-    if (GRPC_TRACER_ON(grpc_lb_glb_trace)) {-      gpr_log(GPR_INFO, ""Unreffing RR for drop (0x%"" PRIxPTR "")"",-              (intptr_t)wc_arg->rr_policy);+  if (glb_policy->serverlist != NULL) {","Might be a good idea to add a one-line comment here, to make it clear to future readers why this is done conditionally:```// Check for drops if we are not using fallback backend addresses.```",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,137318761,2017-09-06T16:23:30Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1616,9 +1711,17 @@ static void lb_on_response_received_locked(grpc_exec_ctx *exec_ctx, void *arg,           }         } else {           if (GRPC_TRACER_ON(grpc_lb_glb_trace)) {-            gpr_log(GPR_INFO,-                    ""Received empty server list. Picks will stay pending until ""-                    ""a response with > 0 servers is received"");+            if (glb_policy->serverlist == NULL) {+              gpr_log(+                  GPR_INFO,+                  ""Received empty server list. Picks will stay pending until ""","This message isn't necessarily accurate in all cases.  For example, if we're using fallback addresses and we get an empty serverlist as the first message from the balancer, then picks will not stay pending.Instead of trying to make this log message very specific and cover every possible case, I suggest replacing both branches of this with a single message that simply says ""Received empty server list; ignoring"".",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,137319538,2017-09-06T16:26:37Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1665,6 +1768,27 @@ static void lb_call_on_retry_timer_locked(grpc_exec_ctx *exec_ctx, void *arg,   GRPC_LB_POLICY_WEAK_UNREF(exec_ctx, &glb_policy->base, ""grpclb_retry_timer""); } +static void lb_on_fallback_timer_locked(grpc_exec_ctx *exec_ctx, void *arg,+                                        grpc_error *error) {+  glb_lb_policy *glb_policy = arg;+  /* after this callback is scheduled and before it is run, we may receive a","Suggest rewording this comment as follows:If we receive a serverlist after the timer fires but before this callback actually runs, don't do anything.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,137319727,2017-09-06T16:27:22Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1665,6 +1768,27 @@ static void lb_call_on_retry_timer_locked(grpc_exec_ctx *exec_ctx, void *arg,   GRPC_LB_POLICY_WEAK_UNREF(exec_ctx, &glb_policy->base, ""grpclb_retry_timer""); } +static void lb_on_fallback_timer_locked(grpc_exec_ctx *exec_ctx, void *arg,+                                        grpc_error *error) {+  glb_lb_policy *glb_policy = arg;+  /* after this callback is scheduled and before it is run, we may receive a+   * \a serverlist and want to cancel the callback, then we should cancel this+   * callback by returning at its very beginning */+  if (!glb_policy->fallback_timer_active) return;","I think it would be more consistent to check `serverlist != NULL` here, since we're now using that as the conditional everywhere else.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,137320666,2017-09-06T16:31:01Z,src/core/ext/filters/client_channel/lb_policy_factory.c,"@@ -55,7 +55,7 @@ grpc_lb_addresses* grpc_lb_addresses_copy(const grpc_lb_addresses* addresses) { }  void grpc_lb_addresses_set_address(grpc_lb_addresses* addresses, size_t index,-                                   void* address, size_t address_len,+                                   const void* address, size_t address_len,","What's the reason for changing the `address` parameter to be `const`?  It doesn't really hurt anything, so I don't necessarily object, but I also don't see what the advantage is, so I'm curious as to what motivated this change.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12187,137323311,2017-09-06T16:41:11Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -668,8 +712,21 @@ static bool pick_from_internal_rr_locked(  static grpc_lb_policy_args *lb_policy_args_create(grpc_exec_ctx *exec_ctx,                                                   glb_lb_policy *glb_policy) {-  grpc_lb_addresses *addresses =-      process_serverlist_locked(exec_ctx, glb_policy->serverlist);+  grpc_lb_addresses *addresses;+  if (glb_policy->serverlist != NULL) {+    // The serverlist is either NULL or non-empty.+    GPR_ASSERT(glb_policy->serverlist->num_servers > 0);+    addresses = process_serverlist_locked(exec_ctx, glb_policy->serverlist);+  } else {+    // The fallback_backend_addresses is non-NULL (but can be empty) until the","This comment can probably be reworded to be a bit more concise:If rr_handover_locked() is invoked when we haven't received any serverlist from the balancer, we use the fallback backends returned by the resolver.  Note that the fallback backend list may be empty, in which case the new round_robin policy will keep the requested picks pending.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12318,137342214,2017-09-06T17:53:07Z,test/cpp/end2end/grpclb_end2end_test.cc,"@@ -606,49 +612,28 @@ TEST_F(SingleBalancerTest, RepeatedServerlist) {       kServerlistDelayMs);    // Send num_backends/2 requests.-  auto statuses_and_responses = SendRpc(kMessage_, num_backends_ / 2);-  // only the first half of the backends will receive them.+  CheckRpcSendOk(num_backends_ / 2);+  // only half of the backends will receive them.+  size_t num_requests = 0;   for (size_t i = 0; i < backends_.size(); ++i) {-    if (i < backends_.size() / 2)-      EXPECT_EQ(1U, backend_servers_[i].service_->request_count())-          << ""for backend #"" << i;-    else-      EXPECT_EQ(0U, backend_servers_[i].service_->request_count())-          << ""for backend #"" << i;-  }-  EXPECT_EQ(statuses_and_responses.size(), num_backends_ / 2);-  for (const auto& status_and_response : statuses_and_responses) {-    const Status& status = status_and_response.first;-    const EchoResponse& response = status_and_response.second;-    EXPECT_TRUE(status.ok()) << ""code="" << status.error_code()-                             << "" message="" << status.error_message();-    EXPECT_EQ(response.message(), kMessage_);+    num_requests += backend_servers_[i].service_->request_count();","Why do we bother ignoring identical serverlists in grpclb these days?  If we pass an update to round_robin that is identical to its existing address list, it should be a no-op, shouldn't it?The only impact I can think of is that it would reset the index into the serverlist that we use for drops.  I guess it's good to do this for that reason, but then shouldn't this test include drops?",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/12318,137381463,2017-09-06T20:31:00Z,test/cpp/end2end/grpclb_end2end_test.cc,"@@ -606,49 +612,28 @@ TEST_F(SingleBalancerTest, RepeatedServerlist) {       kServerlistDelayMs);    // Send num_backends/2 requests.-  auto statuses_and_responses = SendRpc(kMessage_, num_backends_ / 2);-  // only the first half of the backends will receive them.+  CheckRpcSendOk(num_backends_ / 2);+  // only half of the backends will receive them.+  size_t num_requests = 0;   for (size_t i = 0; i < backends_.size(); ++i) {-    if (i < backends_.size() / 2)-      EXPECT_EQ(1U, backend_servers_[i].service_->request_count())-          << ""for backend #"" << i;-    else-      EXPECT_EQ(0U, backend_servers_[i].service_->request_count())-          << ""for backend #"" << i;-  }-  EXPECT_EQ(statuses_and_responses.size(), num_backends_ / 2);-  for (const auto& status_and_response : statuses_and_responses) {-    const Status& status = status_and_response.first;-    const EchoResponse& response = status_and_response.second;-    EXPECT_TRUE(status.ok()) << ""code="" << status.error_code()-                             << "" message="" << status.error_message();-    EXPECT_EQ(response.message(), kMessage_);+    num_requests += backend_servers_[i].service_->request_count();","As you hint, because ignoring repeated serverlists predates the ability to update LB policies. This PR was intended to be a cleanup (in addition to fixing the flakiness). Adding that test belong in a separate one IMHO. ",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,137394092,2017-09-06T21:24:11Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1616,9 +1711,17 @@ static void lb_on_response_received_locked(grpc_exec_ctx *exec_ctx, void *arg,           }         } else {           if (GRPC_TRACER_ON(grpc_lb_glb_trace)) {-            gpr_log(GPR_INFO,-                    ""Received empty server list. Picks will stay pending until ""-                    ""a response with > 0 servers is received"");+            if (glb_policy->serverlist == NULL) {+              gpr_log(+                  GPR_INFO,+                  ""Received empty server list. Picks will stay pending until ""","Yeah, fallback makes the timeline complex. Done.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12326,137396477,2017-09-06T21:36:28Z,src/core/ext/filters/client_channel/subchannel_index.c,"@@ -119,13 +121,23 @@ static const gpr_avl_vtable subchannel_avl_vtable = { void grpc_subchannel_index_init(void) {   g_subchannel_index = gpr_avl_create(&subchannel_avl_vtable);   gpr_mu_init(&g_mu);+  gpr_ref_init(&g_refcount, 1); }  void grpc_subchannel_index_shutdown(void) {-  grpc_exec_ctx exec_ctx = GRPC_EXEC_CTX_INIT;-  gpr_mu_destroy(&g_mu);-  gpr_avl_unref(g_subchannel_index, &exec_ctx);-  grpc_exec_ctx_finish(&exec_ctx);+  grpc_subchannel_index_unref();","C-core is basically a giant event loop.  Callbacks are generally only invoked as a result of polling on file descriptors.  If callbacks have not yet been invoked by the time we shut down C-core, then it is likely that they will never be invoked unless some polling is done.This change fixes the crash by ensuring that we don't destroy the global mutex until all callbacks have been invoked.  However, if the callbacks are never going to be run, then we will still have a memory leak, because the refcount will never reach zero, so we will never clean up the subchannel index.(There's also a pre-existing leak caused by the fact that callbacks that are not being run are holding references to the LB policies, which hold references to the channels, so there are a lot of other objects that are not being destroyed.  But the solution is the same for both the pre-existing leaks and the new leaks: We need to make sure that the callbacks actually get invoked.)Note that the iomgr library is where the polling engine lives, so the latest possible point at which polling can happen is the iomgr shutdown.  It's possible that the iomgr shutdown code tries to do some last-minute polling on its own (which is where the memory leaks are identified for `GRPC_ABORT_ON_LEAKS=true`), in which case there is probably no problem here.  But you should check that, because if it's not doing any polling, then we'll probably need to do it here.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12187,137397220,2017-09-06T21:40:27Z,src/core/ext/filters/client_channel/lb_policy_factory.c,"@@ -55,7 +55,7 @@ grpc_lb_addresses* grpc_lb_addresses_copy(const grpc_lb_addresses* addresses) { }  void grpc_lb_addresses_set_address(grpc_lb_addresses* addresses, size_t index,-                                   void* address, size_t address_len,+                                   const void* address, size_t address_len,","I add a `const` because I think this parameter should be read-only for a setter. Also, I made the argument [here](https://github.com/grpc/grpc/pull/12187/files#diff-8b42d287f67696893b2f8ffaae570bdfR570) a `const`.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/12249,137408013,2017-09-06T22:38:53Z,src/python/grpcio/grpc/_cython/_cygrpc/records.pyx.pxi,"@@ -462,6 +454,7 @@ cdef class Metadata:       grpc_init()       grpc_metadata_array_init(&self.c_metadata_array)     metadata = list(metadata_iterable)+    self._init_md_count = len(metadata)",Why introduce this instance-scope field? Is it not redundant with `self.c_metadata_array.count`?,
1168480,djanku,https://api.github.com/repos/grpc/grpc/pulls/12249,137471125,2017-09-07T08:00:47Z,src/python/grpcio/grpc/_cython/_cygrpc/records.pyx.pxi,"@@ -462,6 +454,7 @@ cdef class Metadata:       grpc_init()       grpc_metadata_array_init(&self.c_metadata_array)     metadata = list(metadata_iterable)+    self._init_md_count = len(metadata)","No, it isn't because sometimes (server role) is Metadata object initialized with empty `metadata_iterable` parameter. In this case, the `self.c_metadata_array` (internal C structure) is maintained later by C code itself, including allocation of memory and unreferencing allocated memory (remember that python `Metadata` class is only proxy to C structure data). But sometimes (client role) metadata are passed directly through `metadata_iterable` parameter and in this case we have to unref allocated items manually. If we try to unref items according `self.c_metadata_array.count>0` sigsegv is invoked in server role, because C code is trying to unref unreferenced data later. In this case  `self._init_md_count` is set to `0` and we know there is no need to unreferencing. Is it  understandable?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12318,137561130,2017-09-07T14:49:51Z,test/cpp/end2end/client_lb_end2end_test.cc,"@@ -367,13 +385,31 @@ TEST_F(ClientLbEnd2endTest, RoundRobin) {     ports.emplace_back(server->port_);   }   SetNextResolution(ports);-  for (size_t i = 0; i < servers_.size(); ++i) {-    CheckRpcSendOk();+  // We cannot derive the connection order from the order reported by the+  // resolver: different polling engines introduce different delays that affect+  // which subchannel will transition into READY, even for local addresses.+  // However, given an initial connection order and in the absence of+  // disruptions, this order will be periodic.+  std::vector<int> first_connection_order;+  while (true) {+    for (size_t i = 0; i < servers_.size(); ++i) {+      CheckRpcSendOk();+      UpdateConnectionOrder(servers_, &first_connection_order);+    }+    if (first_connection_order.size() == servers_.size()) break;+    first_connection_order.clear();   }-  // One request should have gone to each server.+  // ""first_connection_order"" has unique elements by construction. If its length+  // equals the number of servers, each server must have gotten a request.+  EXPECT_EQ(first_connection_order.size(), servers_.size());+  // Subsequent requests maintain the initial connection ordering.+  ResetCounters();","I think there's still a potential problem here.  Let's say that the backends become ready in the order 0, 2, 1.  If backend 1 doesn't become ready until after we've hit backend 2 for the first time, then the first loop above will hit the backends in the order 0, 2, 0, 1.  This means that after we exit the first loop, the next request will go to backend 2, not backend 0.  However, the second loop below assumes that the first request it sends will go to backend 0.I think that right after this line, we need to do something like this to reset round_robin to the start of the backend list:```WaitForServer(servers_.size() - 1);```",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12318,137562697,2017-09-07T14:54:57Z,test/cpp/end2end/grpclb_end2end_test.cc,"@@ -606,49 +612,28 @@ TEST_F(SingleBalancerTest, RepeatedServerlist) {       kServerlistDelayMs);    // Send num_backends/2 requests.-  auto statuses_and_responses = SendRpc(kMessage_, num_backends_ / 2);-  // only the first half of the backends will receive them.+  CheckRpcSendOk(num_backends_ / 2);+  // only half of the backends will receive them.+  size_t num_requests = 0;   for (size_t i = 0; i < backends_.size(); ++i) {-    if (i < backends_.size() / 2)-      EXPECT_EQ(1U, backend_servers_[i].service_->request_count())-          << ""for backend #"" << i;-    else-      EXPECT_EQ(0U, backend_servers_[i].service_->request_count())-          << ""for backend #"" << i;-  }-  EXPECT_EQ(statuses_and_responses.size(), num_backends_ / 2);-  for (const auto& status_and_response : statuses_and_responses) {-    const Status& status = status_and_response.first;-    const EchoResponse& response = status_and_response.second;-    EXPECT_TRUE(status.ok()) << ""code="" << status.error_code()-                             << "" message="" << status.error_message();-    EXPECT_EQ(response.message(), kMessage_);+    num_requests += backend_servers_[i].service_->request_count();","I'm fine with adding that new test in another PR, but then let's just delete this test in this PR.  As far as I can tell, this test is not proving anything -- as currently written, it would still pass, even if the grpclb code didn't do anything special to handle duplicate serverlists.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12421,137572868,2017-09-07T15:30:02Z,doc/wait-for-ready.md,"@@ -1,14 +1,26 @@ gRPC Wait for Ready Semantics ============================= -If an RPC is issued but the channel is in `TRANSIENT_FAILURE` or `SHUTDOWN`-states, the RPC is unable to be transmited promptly. By default, gRPC-implementations SHOULD fail such RPCs immediately. This is known as ""fail fast,""-but usage of the term is historical. RPCs SHOULD NOT fail as a result of the-channel being in other states (`CONNECTING`, `READY`, or `IDLE`).--gRPC implementations MAY provide a per-RPC option to not fail RPCs as a result-of the channel being in `TRANSIENT_FAILURE` state. Instead, the implementation-queues the RPCs until the channel is `READY`. This is known as ""wait for ready.""-The RPCs SHOULD still fail before `READY` if there are unrelated reasons, such-as the channel is `SHUTDOWN` or the RPC's deadline is reached.+Errors can occur in many places. For the propose of this document we can bucket the errors into three separate situations:++1. The RPC never leaves the gRPC client library, for example:+    * The connection was broken and the channel is in a `TRANSIENT_FAILURE` state.+2. The RPC reaches the gRPC server application, and is rejected. For example:","I think this should say server *library* here, not server *application*, right?",
2811396,ejona86,https://api.github.com/repos/grpc/grpc/pulls/12421,137590656,2017-09-07T16:33:30Z,doc/wait-for-ready.md,"@@ -1,14 +1,26 @@ gRPC Wait for Ready Semantics ============================= -If an RPC is issued but the channel is in `TRANSIENT_FAILURE` or `SHUTDOWN`-states, the RPC is unable to be transmited promptly. By default, gRPC-implementations SHOULD fail such RPCs immediately. This is known as ""fail fast,""-but usage of the term is historical. RPCs SHOULD NOT fail as a result of the-channel being in other states (`CONNECTING`, `READY`, or `IDLE`).--gRPC implementations MAY provide a per-RPC option to not fail RPCs as a result-of the channel being in `TRANSIENT_FAILURE` state. Instead, the implementation-queues the RPCs until the channel is `READY`. This is known as ""wait for ready.""-The RPCs SHOULD still fail before `READY` if there are unrelated reasons, such-as the channel is `SHUTDOWN` or the RPC's deadline is reached.+Errors can occur in many places. For the propose of this document we can bucket the errors into three separate situations:++1. The RPC never leaves the gRPC client library, for example:+    * The connection was broken and the channel is in a `TRANSIENT_FAILURE` state.+2. The RPC reaches the gRPC server library, and is rejected. For example:","Bringing this into things is re-defining, not ""clarifying"". I think this is mostly orthogonal to wait-for-ready/fail-fast. ""fail fast"" should be permitted to be replayed here. Now, we may choose not to, but I don't think we should permanently disallow it. We can discuss this particular case somewhere else; it doesn't need to be here as it has nothing to do with the semantics of either fail fast or wait-for-ready.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/12421,137826583,2017-09-08T15:56:12Z,doc/wait-for-ready.md,"@@ -1,14 +1,26 @@ gRPC Wait for Ready Semantics ============================= -If an RPC is issued but the channel is in `TRANSIENT_FAILURE` or `SHUTDOWN`-states, the RPC is unable to be transmited promptly. By default, gRPC-implementations SHOULD fail such RPCs immediately. This is known as ""fail fast,""-but usage of the term is historical. RPCs SHOULD NOT fail as a result of the-channel being in other states (`CONNECTING`, `READY`, or `IDLE`).--gRPC implementations MAY provide a per-RPC option to not fail RPCs as a result-of the channel being in `TRANSIENT_FAILURE` state. Instead, the implementation-queues the RPCs until the channel is `READY`. This is known as ""wait for ready.""-The RPCs SHOULD still fail before `READY` if there are unrelated reasons, such-as the channel is `SHUTDOWN` or the RPC's deadline is reached.+Errors can occur in many places. For the propose of this document we can bucket the errors into three separate situations:++1. The RPC never leaves the gRPC client library, for example:+    * The connection was broken and the channel is in a `TRANSIENT_FAILURE` state.","Due to a know c core issue, a broken connection can lead to TRANSIENT_FAILURE in some cases. However, I realize this is an implementation detail, and should be removed from the doc. I have removed specific examples to more general: If an RPC never leaves the client, it belongs in this bucket.",
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/12359,137831476,2017-09-08T16:17:57Z,src/core/tsi/ssl_transport_security.c,"@@ -846,6 +858,51 @@ static const tsi_frame_protector_vtable frame_protector_vtable = {     ssl_protector_destroy, }; +/* --- tsi_server_handshaker_factory methods implementation. --- */++static void tsi_ssl_handshaker_factory_destroy(+    tsi_ssl_handshaker_factory *self) {+  GPR_ASSERT(self != NULL);+  GPR_ASSERT(self->vtable != NULL);+  if (self->vtable->destroy != NULL) {+    self->vtable->destroy(self);+  }+  /* Note, we don't free(self) here because this object is always directly+   * embedded in another object. If tsi_ssl_handshaker_factory_init allocates+   * any memory, it should be free'd here. */+}++static void tsi_ssl_handshaker_factory_addref(+    tsi_ssl_handshaker_factory *self) {+  GPR_ASSERT(self != NULL);+  gpr_refn(&self->refcount, 1);+}++static int tsi_ssl_handshaker_factory_unref(tsi_ssl_handshaker_factory *self) {",see this example: https://github.com/grpc/grpc/blob/a07413368d632eb62e16bddd14442ba9a7d40eb3/src/core/lib/security/transport/security_connector.c#L195,
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/12359,137832583,2017-09-08T16:22:59Z,src/core/tsi/ssl_transport_security.c,"@@ -846,6 +858,51 @@ static const tsi_frame_protector_vtable frame_protector_vtable = {     ssl_protector_destroy, }; +/* --- tsi_server_handshaker_factory methods implementation. --- */++static void tsi_ssl_handshaker_factory_destroy(+    tsi_ssl_handshaker_factory *self) {+  GPR_ASSERT(self != NULL);+  GPR_ASSERT(self->vtable != NULL);+  if (self->vtable->destroy != NULL) {+    self->vtable->destroy(self);+  }+  /* Note, we don't free(self) here because this object is always directly+   * embedded in another object. If tsi_ssl_handshaker_factory_init allocates+   * any memory, it should be free'd here. */+}++static void tsi_ssl_handshaker_factory_addref(+    tsi_ssl_handshaker_factory *self) {+  GPR_ASSERT(self != NULL);",see https://github.com/grpc/grpc/blob/a07413368d632eb62e16bddd14442ba9a7d40eb3/src/core/lib/security/transport/security_connector.c#L174,
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/11758,137845218,2017-09-08T17:25:25Z,src/core/lib/iomgr/executor.c,"@@ -137,65 +151,146 @@ static void executor_thread(void *arg) {    size_t subtract_depth = 0;   for (;;) {+    if (GRPC_TRACER_ON(executor_trace)) {+      gpr_log(GPR_DEBUG, ""EXECUTOR[%d]: step (sub_depth=%"" PRIdPTR "")"",+              (int)(ts - g_thread_state), subtract_depth);+    }     gpr_mu_lock(&ts->mu);     ts->depth -= subtract_depth;     while (grpc_closure_list_empty(ts->elems) && !ts->shutdown) {+      ts->queued_long_job = false;       gpr_cv_wait(&ts->cv, &ts->mu, gpr_inf_future(GPR_CLOCK_REALTIME));     }     if (ts->shutdown) {+      if (GRPC_TRACER_ON(executor_trace)) {+        gpr_log(GPR_DEBUG, ""EXECUTOR[%d]: shutdown"",+                (int)(ts - g_thread_state));+      }       gpr_mu_unlock(&ts->mu);       break;     }     GRPC_STATS_INC_EXECUTOR_QUEUE_DRAINED(&exec_ctx);     grpc_closure_list exec = ts->elems;     ts->elems = (grpc_closure_list)GRPC_CLOSURE_LIST_INIT;     gpr_mu_unlock(&ts->mu);+    if (GRPC_TRACER_ON(executor_trace)) {+      gpr_log(GPR_DEBUG, ""EXECUTOR[%d]: execute"", (int)(ts - g_thread_state));+    }      subtract_depth = run_closures(&exec_ctx, exec);-    grpc_exec_ctx_flush(&exec_ctx);   }   grpc_exec_ctx_finish(&exec_ctx); }  static void executor_push(grpc_exec_ctx *exec_ctx, grpc_closure *closure,-                          grpc_error *error) {-  size_t cur_thread_count = (size_t)gpr_atm_no_barrier_load(&g_cur_threads);-  GRPC_STATS_INC_EXECUTOR_SCHEDULED_ITEMS(exec_ctx);-  if (cur_thread_count == 0) {-    grpc_closure_list_append(&exec_ctx->closure_list, closure, error);-    return;-  }-  thread_state *ts = (thread_state *)gpr_tls_get(&g_this_thread_state);-  if (ts == NULL) {-    ts = &g_thread_state[GPR_HASH_POINTER(exec_ctx, cur_thread_count)];+                          grpc_error *error, bool is_short) {+  bool retry_push;+  if (is_short) {+    GRPC_STATS_INC_EXECUTOR_SCHEDULED_SHORT_ITEMS(exec_ctx);   } else {-    GRPC_STATS_INC_EXECUTOR_SCHEDULED_TO_SELF(exec_ctx);-  }-  gpr_mu_lock(&ts->mu);-  if (grpc_closure_list_empty(ts->elems)) {-    GRPC_STATS_INC_EXECUTOR_WAKEUP_INITIATED(exec_ctx);-    gpr_cv_signal(&ts->cv);+    GRPC_STATS_INC_EXECUTOR_SCHEDULED_LONG_ITEMS(exec_ctx);   }-  grpc_closure_list_append(&ts->elems, closure, error);-  ts->depth++;-  bool try_new_thread = ts->depth > MAX_DEPTH &&-                        cur_thread_count < g_max_threads && !ts->shutdown;-  gpr_mu_unlock(&ts->mu);-  if (try_new_thread && gpr_spinlock_trylock(&g_adding_thread_lock)) {-    cur_thread_count = (size_t)gpr_atm_no_barrier_load(&g_cur_threads);-    if (cur_thread_count < g_max_threads) {-      gpr_atm_no_barrier_store(&g_cur_threads, cur_thread_count + 1);--      gpr_thd_options opt = gpr_thd_options_default();-      gpr_thd_options_set_joinable(&opt);-      gpr_thd_new(&g_thread_state[cur_thread_count].id, executor_thread,-                  &g_thread_state[cur_thread_count], &opt);+  do {+    retry_push = false;+    size_t cur_thread_count = (size_t)gpr_atm_no_barrier_load(&g_cur_threads);+    if (cur_thread_count == 0) {+      if (GRPC_TRACER_ON(executor_trace)) {+#ifndef NDEBUG+        gpr_log(GPR_DEBUG, ""EXECUTOR: schedule %p (created %s:%d) inline"",+                closure, closure->file_created, closure->line_created);+#else+        gpr_log(GPR_DEBUG, ""EXECUTOR: schedule %p inline"", closure);+#endif+      }+      grpc_closure_list_append(&exec_ctx->closure_list, closure, error);+      return;     }-    gpr_spinlock_unlock(&g_adding_thread_lock);-  }+    thread_state *ts = (thread_state *)gpr_tls_get(&g_this_thread_state);+    if (ts == NULL) {+      ts = &g_thread_state[GPR_HASH_POINTER(exec_ctx, cur_thread_count)];+    } else {+      GRPC_STATS_INC_EXECUTOR_SCHEDULED_TO_SELF(exec_ctx);+    }+    thread_state *orig_ts = ts;++    bool try_new_thread;+    for (;;) {+      if (GRPC_TRACER_ON(executor_trace)) {+#ifndef NDEBUG+        gpr_log(+            GPR_DEBUG,+            ""EXECUTOR: try to schedule %p (%s) (created %s:%d) to thread %d"",+            closure, is_short ? ""short"" : ""long"", closure->file_created,+            closure->line_created, (int)(ts - g_thread_state));+#else+        gpr_log(GPR_DEBUG, ""EXECUTOR: try to schedule %p (%s) to thread %d"",+                closure, is_short ? ""short"" : ""long"",+                (int)(ts - g_thread_state));+#endif+      }+      gpr_mu_lock(&ts->mu);+      if (ts->queued_long_job) {",A small comment here would be nice - we don't push any job on an executor that already has a long-job,
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/12214,137880191,2017-09-08T20:14:14Z,include/grpc++/impl/codegen/call.h,"@@ -285,33 +284,64 @@ class CallOpSendMessage {   protected:   void AddOp(grpc_op* ops, size_t* nops) {-    if (send_buf_ == nullptr) return;+    if (!send_buf_.Valid()) return;     grpc_op* op = &ops[(*nops)++];     op->op = GRPC_OP_SEND_MESSAGE;     op->flags = write_options_.flags();     op->reserved = NULL;-    op->data.send_message.send_message = send_buf_;+    op->data.send_message.send_message = send_buf_.c_buffer();     // Flags are per-message: clear them after use.     write_options_.Clear();   }-  void FinishOp(bool* status) {-    g_core_codegen_interface->grpc_byte_buffer_destroy(send_buf_);-    send_buf_ = nullptr;-  }+  void FinishOp(bool* status) { send_buf_.Clear(); }   private:-  grpc_byte_buffer* send_buf_;+  template <class M, class T = void>+  class MessageSerializer;++  ByteBuffer send_buf_;   WriteOptions write_options_; };  template <class M>+class CallOpSendMessage::MessageSerializer<+    M, typename std::enable_if<std::is_same<","Could this be simplified a little with:```c++template <class T> T example(); // no need to provide an implementation```So that the enable_if becomes:```c++std::enable_if<std::is_same<::grpc::Status, decltype(SerializationTraits<M>::Serialize(  example<M>(), example<grpc_byte_buffer**>(), example<bool*>()))>::value>::type>```I feel like the static casts are obscuring intent here",
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/12269,138143590,2017-09-11T17:52:55Z,include/grpc++/impl/codegen/async_stream.h,"@@ -35,6 +35,9 @@ class ClientAsyncStreamingInterface {  public:   virtual ~ClientAsyncStreamingInterface() {} +  /// Start the call that was set up by the constructor+  virtual void StartCall(void* tag) = 0;",We will need a big warning comment here saying this is only needed when a prepare call was used to create the reader object. I think it might be helpful to buffer the start bit in the object and assert fail if it is true.,
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/12466,138160733,2017-09-11T18:58:32Z,src/python/grpcio/grpc/_cython/_cygrpc/records.pyx.pxi,"@@ -437,48 +437,79 @@ cdef class Metadatum: cdef class _MetadataIterator:    cdef size_t i-  cdef Metadata metadata+  cdef size_t _length+  cdef object _metadatum_indexable -  def __cinit__(self, Metadata metadata not None):+  def __cinit__(self, length, metadatum_indexable):+    self._length = length+    self._metadatum_indexable = metadatum_indexable     self.i = 0-    self.metadata = metadata    def __iter__(self):     return self    def __next__(self):-    if self.i < len(self.metadata):-      result = self.metadata[self.i]+    if self.i < self._length:+      result = self._metadatum_indexable[self.i]       self.i = self.i + 1       return result     else:       raise StopIteration  +# TODO(https://github.com/grpc/grpc/issues/7950): Eliminate this; just use an+# ordinary sequence of pairs of bytestrings all the way down to the+# grpc_call_start_batch call. cdef class Metadata:+  """"""Metadata being passed from application to core.""""""    def __cinit__(self, metadata_iterable):+    metadata_sequence = tuple(metadata_iterable)+    cdef size_t count = len(metadata_sequence)     with nogil:       grpc_init()-      grpc_metadata_array_init(&self.c_metadata_array)-    metadata = list(metadata_iterable)-    for metadatum in metadata:-      if not isinstance(metadatum, Metadatum):-        raise TypeError(""expected list of Metadatum"")-    self.c_metadata_array.count = len(metadata)-    self.c_metadata_array.capacity = len(metadata)+      self.c_metadata = <grpc_metadata *>gpr_malloc(+          count * sizeof(grpc_metadata))+      self.c_count = count+    for index, metadatum in enumerate(metadata_sequence):+      self.c_metadata[index].key = grpc_slice_copy(+          (<Metadatum>metadatum).c_metadata.key)+      self.c_metadata[index].value = grpc_slice_copy(+          (<Metadatum>metadatum).c_metadata.value)++  def __dealloc__(self):+    with nogil:+      for index in range(self.c_count):+        grpc_slice_unref(self.c_metadata[index].key)+        grpc_slice_unref(self.c_metadata[index].value)+      gpr_free(self.c_metadata)+      grpc_shutdown()++  def __len__(self):+    return self.c_count++  def __getitem__(self, size_t index):+    if index < self.c_count:+      key = _slice_bytes(self.c_metadata[index].key)+      value = _slice_bytes(self.c_metadata[index].value)+      return Metadatum(key, value)+    else:+      raise IndexError()++  def __iter__(self):+    return _MetadataIterator(self.c_count, self)+++cdef class MetadataArray:","As I understand it, this is this is a Python wrapper for the array we pass to c-core that gets returned filled with the metadata.  Do we need to unreference the returned slices at all?  Or does that happen somewhere else?It looks like ```grpc_metadata_array_destroy()``` just frees the array.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/12466,138164476,2017-09-11T19:14:07Z,src/python/grpcio/grpc/_cython/_cygrpc/records.pyx.pxi,"@@ -437,48 +437,79 @@ cdef class Metadatum: cdef class _MetadataIterator:    cdef size_t i-  cdef Metadata metadata+  cdef size_t _length+  cdef object _metadatum_indexable -  def __cinit__(self, Metadata metadata not None):+  def __cinit__(self, length, metadatum_indexable):+    self._length = length+    self._metadatum_indexable = metadatum_indexable     self.i = 0-    self.metadata = metadata    def __iter__(self):     return self    def __next__(self):-    if self.i < len(self.metadata):-      result = self.metadata[self.i]+    if self.i < self._length:+      result = self._metadatum_indexable[self.i]       self.i = self.i + 1       return result     else:       raise StopIteration  +# TODO(https://github.com/grpc/grpc/issues/7950): Eliminate this; just use an+# ordinary sequence of pairs of bytestrings all the way down to the+# grpc_call_start_batch call. cdef class Metadata:+  """"""Metadata being passed from application to core.""""""    def __cinit__(self, metadata_iterable):+    metadata_sequence = tuple(metadata_iterable)+    cdef size_t count = len(metadata_sequence)     with nogil:       grpc_init()-      grpc_metadata_array_init(&self.c_metadata_array)-    metadata = list(metadata_iterable)-    for metadatum in metadata:-      if not isinstance(metadatum, Metadatum):-        raise TypeError(""expected list of Metadatum"")-    self.c_metadata_array.count = len(metadata)-    self.c_metadata_array.capacity = len(metadata)+      self.c_metadata = <grpc_metadata *>gpr_malloc(+          count * sizeof(grpc_metadata))+      self.c_count = count+    for index, metadatum in enumerate(metadata_sequence):+      self.c_metadata[index].key = grpc_slice_copy(+          (<Metadatum>metadatum).c_metadata.key)+      self.c_metadata[index].value = grpc_slice_copy(+          (<Metadatum>metadatum).c_metadata.value)++  def __dealloc__(self):+    with nogil:+      for index in range(self.c_count):+        grpc_slice_unref(self.c_metadata[index].key)+        grpc_slice_unref(self.c_metadata[index].value)+      gpr_free(self.c_metadata)+      grpc_shutdown()++  def __len__(self):+    return self.c_count++  def __getitem__(self, size_t index):+    if index < self.c_count:+      key = _slice_bytes(self.c_metadata[index].key)+      value = _slice_bytes(self.c_metadata[index].value)+      return Metadatum(key, value)+    else:+      raise IndexError()++  def __iter__(self):+    return _MetadataIterator(self.c_count, self)+++cdef class MetadataArray:","Good question; I think this was at the center of what we were getting wrong before. Based on the specifications [here](https://github.com/grpc/grpc/blob/7f6a27a4d3675adc0de263d291346aab2f46e733/include/grpc/impl/codegen/grpc_types.h#L530-L536) and [here](https://github.com/grpc/grpc/blob/7f6a27a4d3675adc0de263d291346aab2f46e733/include/grpc/impl/codegen/grpc_types.h#L544-L550), this structure deliberately _does not_ unref the `grpc_slice`s it accesses.A consequence of this is that instances of this class are only legitimate for use while their associated call is not-yet-destroyed, and a consequence of that are the `tuple` calls added in `CompletionQueue._interpret_event` and `Operation.received_metadata`.Does the `TODO` added to `Operation.received_metadata` help enough, or should I add more text calling out this pitfall?",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/12463,138197059,2017-09-11T21:29:33Z,src/core/ext/transport/chttp2/transport/frame_rst_stream.c,"@@ -103,6 +103,9 @@ grpc_error *grpc_chttp2_rst_stream_parser_parse(grpc_exec_ctx *exec_ctx,           GRPC_ERROR_INT_HTTP2_ERROR, (intptr_t)reason);       gpr_free(message);     }+    if (!s->write_closed) {",Same question. Seems like this will occur from [here](https://github.com/grpc/grpc/blob/master/src/core/ext/transport/chttp2/transport/chttp2_transport.c#L2103),
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/12463,138203611,2017-09-11T21:59:45Z,src/core/ext/transport/chttp2/transport/hpack_parser.c,"@@ -1650,6 +1650,7 @@ static void force_client_rst_stream(grpc_exec_ctx *exec_ctx, void *sp,         &t->qbuf, grpc_chttp2_rst_stream_create(s->id, GRPC_HTTP2_NO_ERROR,                                                 &s->stats.outgoing));     grpc_chttp2_initiate_write(exec_ctx, t, ""force_rst_stream"");+    grpc_chttp2_fail_pending_writes(exec_ctx, t, s, GRPC_ERROR_NONE);","The main issue is not with fail_pending_writes, but with a race while sending trailing metadata, and actually deleting the stream from the stream_map. The stream_map size is currently used to check the number of streams in use currently. Earlier, the server would send the trailing metadata and only remove the stream after that, which gave rise to the possibility of the client sending another stream before the original was removed, creating the flake that we see.The solution was to call mark_stream_closed before sending the data. To do this, I had to remove fail_pending_writes (from mark_stream_closed) which was causing a few issues.(I actually got confused when I saw your comment. I thought maybe that I had left removing the line from mark_stream_closed, but then I realized that your link points to the current grpc master, and not the pull request :))",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/12463,138205527,2017-09-11T22:09:23Z,src/core/ext/transport/chttp2/transport/hpack_parser.c,"@@ -1650,6 +1650,7 @@ static void force_client_rst_stream(grpc_exec_ctx *exec_ctx, void *sp,         &t->qbuf, grpc_chttp2_rst_stream_create(s->id, GRPC_HTTP2_NO_ERROR,                                                 &s->stats.outgoing));     grpc_chttp2_initiate_write(exec_ctx, t, ""force_rst_stream"");+    grpc_chttp2_fail_pending_writes(exec_ctx, t, s, GRPC_ERROR_NONE);","[accidentally wrote and delete comment. Re writing]Oops, I was half reviewing your code, and half reviewing an old chrome tab open at master. The dangers of too many tabs...",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/12463,138206401,2017-09-11T22:13:49Z,src/core/ext/transport/chttp2/transport/hpack_parser.c,"@@ -1650,6 +1650,7 @@ static void force_client_rst_stream(grpc_exec_ctx *exec_ctx, void *sp,         &t->qbuf, grpc_chttp2_rst_stream_create(s->id, GRPC_HTTP2_NO_ERROR,                                                 &s->stats.outgoing));     grpc_chttp2_initiate_write(exec_ctx, t, ""force_rst_stream"");+    grpc_chttp2_fail_pending_writes(exec_ctx, t, s, GRPC_ERROR_NONE);","Actually, this just reminded me something. I changed the fix a bit and this was after noticing the fail_pending_writes. The fail_pending_writes change may no longer be required. The last I talked to Craig, as long as something is put on the qbuf, it should go out. Let me try adding the fail_pending_writes back in.",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/12500,138383546,2017-09-12T15:31:08Z,tools/run_tests/run_tests.py,"@@ -325,13 +325,19 @@ def test_specs(self):         if cpu_cost == 'capacity':           cpu_cost = multiprocessing.cpu_count()         if os.path.isfile(binary):+          test_prefix = None           if 'gtest' in target and target['gtest']:-            # here we parse the output of --gtest_list_tests to build up a-            # complete list of the tests contained in a binary-            # for each test, we then add a job to run, filtering for just that-            # test+            test_prefix = 'gtest'+          elif 'benchmark' in target and target['benchmark']:+            test_prefix = 'benchmark'++          if test_prefix:+            # here we parse the output of --gtest_list_tests (or +            # --benchmark_list_tests)to build up a complete list of +            # the tests contained in a binary for each test, we then +            # add a job to run, filtering for just that test.             with open(os.devnull, 'w') as fnull:-              tests = subprocess.check_output([binary, '--gtest_list_tests'],+              tests = subprocess.check_output([binary, '--%s_list_tests' % test_prefix],","Cute... but can we explicitly callout gtest_list_tests, benchmark_list_tests?It'll be a few extra lines, but worth it for slightly less magic (and magic is a penalty in this code)",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12210,138392576,2017-09-12T16:00:45Z,test/cpp/naming/gen_build_yaml.py,"@@ -0,0 +1,118 @@+#!/usr/bin/env python2.7+# Copyright 2015 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+++""""""Generates the appropriate build.json data for all the end2end tests.""""""",s/end2end/naming/,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12210,138395847,2017-09-12T16:12:08Z,test/cpp/naming/resolver_component_test.cc,"@@ -0,0 +1,338 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/host_port.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>+#include <grpc/support/sync.h>+#include <grpc/support/time.h>+#include <string.h>++#include <gflags/gflags.h>+#include <gmock/gmock.h>+#include <vector>++#include ""test/cpp/util/subprocess.h""+#include ""test/cpp/util/test_config.h""++extern ""C"" {+#include ""src/core/ext/filters/client_channel/client_channel.h""+#include ""src/core/ext/filters/client_channel/resolver.h""+#include ""src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.h""+#include ""src/core/ext/filters/client_channel/resolver_registry.h""+#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/iomgr/combiner.h""+#include ""src/core/lib/iomgr/executor.h""+#include ""src/core/lib/iomgr/iomgr.h""+#include ""src/core/lib/iomgr/resolve_address.h""+#include ""src/core/lib/iomgr/sockaddr_utils.h""+#include ""src/core/lib/support/env.h""+#include ""src/core/lib/support/string.h""+#include ""test/core/util/port.h""+#include ""test/core/util/test_config.h""+}++using std::vector;+using grpc::SubProcess;+using testing::UnorderedElementsAreArray;++// Hack copied from ""test/cpp/end2end/server_crash_test_client.cc""!+// In some distros, gflags is in the namespace google, and in some others,+// in gflags. This hack is enabling us to find both.+namespace google {}+namespace gflags {}+using namespace google;+using namespace gflags;++DEFINE_string(target_name, """", ""Target name to resolve."");+DEFINE_string(expected_addrs, """",+              ""Comma-separated list of expected ""+              ""'<ip0:port0>,<is_balancer0>;<ip1:port1>,<is_balancer1>;...' ""+              ""addresses of ""+              ""backend and/or balancers. 'is_balancer' should be bool, i.e. ""+              ""true or false."");+DEFINE_string(expected_chosen_service_config, """",+              ""Expected service config json string that gets chosen (no ""+              ""whitespace). Empty for none."");+DEFINE_string(+    local_dns_server_address, """",+    ""Optional. This address is placed as the uri authority if present."");+DEFINE_string(expected_lb_policy, """",+              ""Expected lb policy name that appears in resolver result channel ""+              ""arg. Empty for none."");++namespace {++class GrpcLBAddress final {+ public:+  GrpcLBAddress(std::string address, bool is_balancer)+      : is_balancer(is_balancer), address(address) {}++  bool operator==(const GrpcLBAddress &other) const {+    return this->is_balancer == other.is_balancer &&+           this->address == other.address;+  }++  bool operator!=(const GrpcLBAddress &other) const {+    return !(*this == other);+  }++  bool is_balancer;+  std::string address;+};++bool ConvertStringToBool(std::string bool_str) {","It looks like a `gpr_is_true()` function was recently added, so we can use that here:https://github.com/grpc/grpc/blob/master/src/core/lib/support/string.h#L111",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12210,138396854,2017-09-12T16:16:00Z,test/cpp/naming/gen_build_yaml.py,"@@ -0,0 +1,118 @@+#!/usr/bin/env python2.7+# Copyright 2015 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+++""""""Generates the appropriate build.json data for all the end2end tests.""""""+++import yaml+import collections+import hashlib+import json++_LOCAL_DNS_SERVER_ADDRESS = '127.0.0.1:15353'++def _append_zone_name(name, zone_name):+  return '%s.%s' % (name, zone_name)++def _build_expected_addrs_cmd_arg(expected_addrs):+  out = []+  for addr in expected_addrs:+    out.append('%s,%s' % (addr['address'], str(addr['is_balancer'])))+  return ';'.join(out)++def main():+  resolver_component_data = ''+  with open('test/cpp/naming/resolver_test_record_groups.yaml') as f:+    resolver_component_data = yaml.load(f)++  json = {+      'resolver_component_test_cases': [+          {+              'target_name': _append_zone_name(test_case['record_to_resolve'],+                                                 resolver_component_data['resolver_component_tests_common_zone_name']),+              'expected_addrs': _build_expected_addrs_cmd_arg(test_case['expected_addrs']),+              'expected_chosen_service_config': (test_case['expected_chosen_service_config'] or ''),+              'expected_lb_policy': (test_case['expected_lb_policy'] or ''),+          } for test_case in resolver_component_data['resolver_component_tests']+      ],+      'libs': [+          {+              'name': 'resolver_component_tests_runner_invoker_common',+              'build': 'private',+              'language': 'c++',+              'src': ['test/cpp/naming/resolver_component_tests_runner_invoker_common.cc'],+              'headers': ['test/cpp/naming/resolver_component_tests_runner_invoker_common.h'],+              'platforms': ['linux', 'posix', 'mac'],","@nicolasnoble, I assume that we'll need to add windows to this list as part of your #12416.  As per our discussion, this PR will be merged before that one.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12210,138399468,2017-09-12T16:25:40Z,test/cpp/naming/resolver_component_tests_runner_invoker_common.cc,"@@ -0,0 +1,137 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>+#include <signal.h>+#include <string.h>+#include <unistd.h>++#include <gflags/gflags.h>+#include <string>+#include <thread>+#include <vector>++#include ""test/cpp/util/subprocess.h""+#include ""test/cpp/util/test_config.h""++#include ""test/cpp/naming/resolver_component_tests_runner_invoker_common.h""++extern ""C"" {+#include ""test/core/util/port.h""+}++using grpc::SubProcess;++static volatile sig_atomic_t abort_wait_for_child = 0;++static void sighandler(int sig) { abort_wait_for_child = 1; }++static void register_sighandler() {+  struct sigaction act;+  memset(&act, 0, sizeof(act));+  act.sa_handler = sighandler;+  sigaction(SIGINT, &act, NULL);+  sigaction(SIGTERM, &act, NULL);+}++namespace {++const int kTestTimeoutSeconds = 60 * 2;++void RunSigHandlingThread(SubProcess *test_driver, gpr_mu *test_driver_mu,+                          gpr_cv *test_driver_cv, int *test_driver_done) {+  for (size_t i = 0; i < kTestTimeoutSeconds && !abort_wait_for_child; i++) {","This seems a little inexact, since the time spent processing the body of the loop will be non-zero, so the total timeout time will be more than `kTestTimeoutSeconds`.  Instead, how about computing the overall deadline before starting the loop and then setting the timeout passed to `gpr_cv_wait()` to be min(1 second, time remaining before deadline)?",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/12509,138430029,2017-09-12T18:27:22Z,tools/codegen/core/gen_stats_data.py,"@@ -313,3 +313,90 @@ def put_banner(files, banner):       len(inst_map['Histogram']), ','.join('grpc_stats_table_%d' % x for x in histo_bucket_boundaries))   print >>C, ""void (*const grpc_stats_inc_histogram[%d])(grpc_exec_ctx *exec_ctx, int x) = {%s};"" % (       len(inst_map['Histogram']), ','.join('grpc_stats_inc_%s' % histogram.name.lower() for histogram in inst_map['Histogram']))++# patch qps_test bigquery schema+RECORD_EXPLICIT_PERCENTILES = [50, 95, 99]++with open('tools/run_tests/performance/scenario_result_schema.json', 'r') as f:+  qps_schema = json.loads(f.read())++def FindNamed(js, name):+  for el in js:+    if el['name'] == name:+      return el++def RemoveCoreFields(js):+  new_fields = []+  for field in js['fields']:+    if not field['name'].startswith('core_'):+      new_fields.append(field)+  js['fields'] = new_fields++RemoveCoreFields(FindNamed(qps_schema, 'clientStats'))+RemoveCoreFields(FindNamed(qps_schema, 'serverStats'))++def AddCoreFields(js):+  for counter in inst_map['Counter']:+    js['fields'].append({+      'name': 'core_%s' % counter.name,+      'type': 'INTEGER',+      'mode': 'NULLABLE'+    })+  for histogram in inst_map['Histogram']:+    js['fields'].append({+      'name': 'core_%s' % histogram.name,+      'type': 'STRING',+      'mode': 'NULLABLE'+    })+    js['fields'].append({+      'name': 'core_%s_bkts' % histogram.name,+      'type': 'STRING',+      'mode': 'NULLABLE'+    })+    for pctl in RECORD_EXPLICIT_PERCENTILES:+      js['fields'].append({+        'name': 'core_%s_%dp' % (histogram.name, pctl),+        'type': 'FLOAT',+        'mode': 'NULLABLE'+      })++AddCoreFields(FindNamed(qps_schema, 'clientStats'))+AddCoreFields(FindNamed(qps_schema, 'serverStats'))++with open('tools/run_tests/performance/scenario_result_schema.json', 'w') as f:","Why are we opening, modifying, and writing to the same file. Could this be accomplished in a cleaner way? Like: build.yaml (input to) gen_stats_data.py (generates) scenario_result_schema.json",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/12509,138431111,2017-09-12T18:32:01Z,tools/codegen/core/gen_stats_data.py,"@@ -313,3 +313,90 @@ def put_banner(files, banner):       len(inst_map['Histogram']), ','.join('grpc_stats_table_%d' % x for x in histo_bucket_boundaries))   print >>C, ""void (*const grpc_stats_inc_histogram[%d])(grpc_exec_ctx *exec_ctx, int x) = {%s};"" % (       len(inst_map['Histogram']), ','.join('grpc_stats_inc_%s' % histogram.name.lower() for histogram in inst_map['Histogram']))++# patch qps_test bigquery schema+RECORD_EXPLICIT_PERCENTILES = [50, 95, 99]++with open('tools/run_tests/performance/scenario_result_schema.json', 'r') as f:+  qps_schema = json.loads(f.read())++def FindNamed(js, name):+  for el in js:+    if el['name'] == name:+      return el++def RemoveCoreFields(js):+  new_fields = []+  for field in js['fields']:+    if not field['name'].startswith('core_'):+      new_fields.append(field)+  js['fields'] = new_fields++RemoveCoreFields(FindNamed(qps_schema, 'clientStats'))+RemoveCoreFields(FindNamed(qps_schema, 'serverStats'))++def AddCoreFields(js):+  for counter in inst_map['Counter']:+    js['fields'].append({+      'name': 'core_%s' % counter.name,+      'type': 'INTEGER',+      'mode': 'NULLABLE'+    })+  for histogram in inst_map['Histogram']:+    js['fields'].append({+      'name': 'core_%s' % histogram.name,+      'type': 'STRING',+      'mode': 'NULLABLE'+    })+    js['fields'].append({+      'name': 'core_%s_bkts' % histogram.name,+      'type': 'STRING',+      'mode': 'NULLABLE'+    })+    for pctl in RECORD_EXPLICIT_PERCENTILES:+      js['fields'].append({+        'name': 'core_%s_%dp' % (histogram.name, pctl),+        'type': 'FLOAT',+        'mode': 'NULLABLE'+      })++AddCoreFields(FindNamed(qps_schema, 'clientStats'))+AddCoreFields(FindNamed(qps_schema, 'serverStats'))++with open('tools/run_tests/performance/scenario_result_schema.json', 'w') as f:+  f.write(json.dumps(qps_schema, indent=2, sort_keys=True))++# and generate a helper script to massage scenario results into the format we'd+# like to query+with open('tools/run_tests/performance/massage_qps_stats.py', 'w') as P:",A python script that generates c code AND a sidecar python script for data massaging? We could just re-open build.yaml in bq_upload_result and done the config-specific modifications there. But I won't push for this since this solution is already implemented.,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/12499,138436291,2017-09-12T18:55:06Z,src/core/lib/iomgr/polling_entity.h,"@@ -22,6 +22,8 @@ #include ""src/core/lib/iomgr/pollset.h"" #include ""src/core/lib/iomgr/pollset_set.h"" +typedef enum pops_tag { POPS_NONE, POPS_POLLSET, POPS_POLLSET_SET } pops_tag;","Hmm, this abbreviation isn't obvious to me. I think stylistically, non-obvious abbrevations shouldn't be used.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12210,138437945,2017-09-12T19:02:54Z,test/cpp/naming/resolver_component_tests_runner_invoker_common.cc,"@@ -0,0 +1,137 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>+#include <signal.h>+#include <string.h>+#include <unistd.h>++#include <gflags/gflags.h>+#include <string>+#include <thread>+#include <vector>++#include ""test/cpp/util/subprocess.h""+#include ""test/cpp/util/test_config.h""++#include ""test/cpp/naming/resolver_component_tests_runner_invoker_common.h""++extern ""C"" {+#include ""test/core/util/port.h""+}++using grpc::SubProcess;++static volatile sig_atomic_t abort_wait_for_child = 0;++static void sighandler(int sig) { abort_wait_for_child = 1; }++static void register_sighandler() {+  struct sigaction act;+  memset(&act, 0, sizeof(act));+  act.sa_handler = sighandler;+  sigaction(SIGINT, &act, NULL);+  sigaction(SIGTERM, &act, NULL);+}++namespace {++const int kTestTimeoutSeconds = 60 * 2;++void RunSigHandlingThread(SubProcess *test_driver, gpr_mu *test_driver_mu,+                          gpr_cv *test_driver_cv, int *test_driver_done) {+  for (size_t i = 0; i < kTestTimeoutSeconds && !abort_wait_for_child; i++) {+    gpr_mu_lock(test_driver_mu);+    if (*test_driver_done) {+      gpr_mu_unlock(test_driver_mu);+      return;+    }+    gpr_cv_wait(test_driver_cv, test_driver_mu,+                gpr_time_add(gpr_now(GPR_CLOCK_REALTIME),+                             gpr_time_from_seconds(1, GPR_TIMESPAN)));+    gpr_mu_unlock(test_driver_mu);+  }+  gpr_log(GPR_DEBUG,+          ""Test timeout reached or received signal. Interrupting test driver ""+          ""child process."");+  test_driver->Interrupt();+  return;+}+}++namespace grpc {++namespace testing {++void InvokeResolverComponentTestsRunner(std::string test_runner_bin_path,+                                        std::string test_bin_path,+                                        std::string dns_server_bin_path,+                                        std::string records_config_path) {+  grpc_init();+  int test_dns_server_port = grpc_pick_unused_port_or_die();++  SubProcess *test_driver = new SubProcess(+      {test_runner_bin_path, ""--test_bin_path="" + test_bin_path,+       ""--dns_server_bin_path="" + dns_server_bin_path,+       ""--records_config_path="" + records_config_path,+       ""--test_dns_server_port="" + std::to_string(test_dns_server_port)});+  gpr_mu test_driver_mu;+  gpr_mu_init(&test_driver_mu);+  gpr_cv test_driver_cv;+  gpr_cv_init(&test_driver_cv);+  int test_driver_done = 0;+  register_sighandler();+  std::thread sig_handling_thread(RunSigHandlingThread, test_driver,","The only problem I can see is the main thread can't periodically poll the ""interrupted"" flag since it's blocked indefinitely in it's `Join` call (no other way to check if the test is done that I can see except for checking a `SIG_CHILD`), and it also can't break out from it's `Join` call after a minute or two has passed. I wanted to use the background thread originally because it allows forwarding `SIGTERM`/`SIGINT` to the child process after only a short delay, setting an overall timeout in the test, and allowing the  test to terminate quickly if is succeeds in << 1 second. I also wasn't sure about calling `Subprocess->Interrupt()` in the signal handler, just to be safe, since I wanted to avoid accidentally locking on something or causing a race. Does this sound ok?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12517,138464959,2017-09-12T21:02:21Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/dns_resolver_ares.c,"@@ -204,7 +204,7 @@ static char *choose_service_config(char *service_config_choice_json) {         int random_pct = rand() % 100;         int percentage;         if (sscanf(field->value, ""%d"", &percentage) != 1 ||-            random_pct > percentage) {+            random_pct > percentage || percentage == 0) {","I'm not sure this is necessary.  The percentage is an optional field, and if you don't want to restrict by percentage, you should just not specify the field.  If you do explicitly specify a value of 0, it's technically correct that no clients should select it.What test flake is being caused by this?  It's not clear to me why this would cause any flakes.",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/12499,138465392,2017-09-12T21:04:01Z,src/core/lib/iomgr/polling_entity.h,"@@ -22,6 +22,8 @@ #include ""src/core/lib/iomgr/pollset.h"" #include ""src/core/lib/iomgr/pollset_set.h"" +typedef enum pops_tag { POPS_NONE, POPS_POLLSET, POPS_POLLSET_SET } pops_tag;","The grpc_ prefix is for functions as per https://github.com/grpc/grpc/blob/master/doc/c-style-guide.md. But it might make sense ti add I guess we can substitute it withtypedef enum pollset_tag {POLLS_NONE, POLLS_POLLSET, POLLS_POLLSET_SET} pollset_tag;ortypedef enum grpc_pollset_tag {GRPC_POLLS_NONE, GRPC_POLLS_POLLSET, GRPC_POLLS_POLLSET_SET} grpc_pollset_tag;",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12517,138466560,2017-09-12T21:09:05Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/dns_resolver_ares.c,"@@ -204,7 +204,7 @@ static char *choose_service_config(char *service_config_choice_json) {         int random_pct = rand() % 100;         int percentage;         if (sscanf(field->value, ""%d"", &percentage) != 1 ||-            random_pct > percentage) {+            random_pct > percentage || percentage == 0) {","The flakiness was seen on a test that uses a value of zero as the percentage. In that case, if `random_pct` turns out to be zero, then this conditional doesn't get taken and the service config will be unexpectedly picked.FTR it could be repro'd on the branch of that PR (before it's most recent commit), but running the test server:```test/cpp/naming/test_dns_server.py --port=15353 --records_config_path=test/cpp/naming/resolver_test_record_groups.yaml```and then running a test that exercises a value of zero as a percentage:```CONFIG=dbg make resolver_component_testwhile [[ $? == 0 ]]; do GRPC_DNS_RESOLVER=ares  bins/dbg/resolver_component_test --target_name=ipv4-cpp-config-has-zero-percentage.resolver-tests.grpctestingexp. --expected_addrs=1.2.3.4:443,False --expected_chosen_service_config= --expected_lb_policy= --local_dns_server_address=127.0.0.1:15353; done;```",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/12519,138480699,2017-09-12T22:14:55Z,doc/c-style-guide.md,"@@ -72,8 +72,16 @@ Symbol Names  - Non-static functions must be prefixed by `grpc_` - Static functions must *not* be prefixed by `grpc_`+- Typenames of `struct`s , `union`s, and `enum`s must be prefixed by `grpc_` if+  they are declared in a header file. They must not be prefixed by `grpc_` if+  they are declared in a source file. - Enumeration values and `#define` names must be uppercase. All other values   must be lowercase.+- Enumeration values or `#define` names defined in a header file must be+  prefixed with `GRPC_` (except for `#define` macros that are being used to",I don't think this exception is needed. I can't imagine a scenario where we use macro substitutions written in global headers for static functions,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12210,138481581,2017-09-12T22:19:48Z,test/cpp/naming/resolver_component_tests_runner_invoker_common.cc,"@@ -0,0 +1,137 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>+#include <signal.h>+#include <string.h>+#include <unistd.h>++#include <gflags/gflags.h>+#include <string>+#include <thread>+#include <vector>++#include ""test/cpp/util/subprocess.h""+#include ""test/cpp/util/test_config.h""++#include ""test/cpp/naming/resolver_component_tests_runner_invoker_common.h""++extern ""C"" {+#include ""test/core/util/port.h""+}++using grpc::SubProcess;++static volatile sig_atomic_t abort_wait_for_child = 0;++static void sighandler(int sig) { abort_wait_for_child = 1; }++static void register_sighandler() {+  struct sigaction act;+  memset(&act, 0, sizeof(act));+  act.sa_handler = sighandler;+  sigaction(SIGINT, &act, NULL);+  sigaction(SIGTERM, &act, NULL);+}++namespace {++const int kTestTimeoutSeconds = 60 * 2;++void RunSigHandlingThread(SubProcess *test_driver, gpr_mu *test_driver_mu,+                          gpr_cv *test_driver_cv, int *test_driver_done) {+  for (size_t i = 0; i < kTestTimeoutSeconds && !abort_wait_for_child; i++) {","I don't think this would cause the response to `SIGINIT` / `SIGTERM` to be delayed.  The overall mechanics of the loop would not be different -- we would still be blocking for no more than 1 second at a time.What I'm thinking is something like this:```gpr_timespec deadline = gpr_time_add(    gpr_now(GPR_CLOCK_MONOTONIC),    gpr_time_from_seconds(kTestTimeoutSeconds, GPR_TIMESPAN));while (true) {  gpr_timespec now = gpr_now(GPR_CLOCK_MONOTONIC);  if (gpr_time_cmp(now, deadline) <= 0) break;  gpr_mu_lock(test_driver_mu);  if (*test_driver_done) {    gpr_mu_unlock(test_driver_mu);    return;  }  gpr_timespan wait_deadline = gpr_time_min(      deadline,      gpr_time_add(now, gpr_time_from_seconds(1, GPR_TIMESPAN)));  gpr_cv_wait(test_driver_cv, test_driver_mu, wait_deadline);  gpr_mu_unlock(test_driver_mu);    }```",
1069502,justinburke,https://api.github.com/repos/grpc/grpc/pulls/12359,138485623,2017-09-12T22:44:16Z,src/core/tsi/ssl_transport_security.c,"@@ -1322,16 +1410,26 @@ tsi_result tsi_create_ssl_client_handshaker_factory(     }   } while (0);   if (result != TSI_OK) {-    tsi_ssl_client_handshaker_factory_destroy(impl);+    tsi_ssl_client_handshaker_factory_destroy(&impl->base);","This was good to call out. I believe it was safe as originally submitted because the base `tsi_ssl_handshaker_factory` hadn't yet been initialized (so a call to `unref` would not have worked as intended.) To address this confusion, I've moved the base class initialization towards the top of this function; once the base class is initialized, subsequent error handlers call `unref`.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12532,138642612,2017-09-13T14:49:47Z,src/core/ext/filters/client_channel/client_channel_factory.c,"@@ -43,14 +43,15 @@ grpc_channel* grpc_client_channel_factory_create_channel( }  static void* factory_arg_copy(void* factory) {-  grpc_client_channel_factory_ref(factory);+  grpc_client_channel_factory_ref((grpc_client_channel_factory*)factory);   return factory; }  static void factory_arg_destroy(grpc_exec_ctx* exec_ctx, void* factory) {   // TODO(roth): Remove local exec_ctx when","Not really related to this PR, but it looks like this TODO has already been taken care of, so please remove it as long as you're in here.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/12549,138718662,2017-09-13T19:39:03Z,test/cpp/microbenchmarks/BUILD,"@@ -73,12 +73,35 @@ grpc_cc_binary(     deps = ["":helpers""], ) +grpc_cc_library(+    name = ""fullstack_streaming_ping_pong_h"",+    testonly = 1,+    srcs = [+        ""fullstack_streaming_ping_pong.h"",+    ],","If it's a header-only library, I don't think `srcs = ` is necessary, is it? We don't use it, for example, in some targets at the top level like `gpr_codegen`",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/12553,138742942,2017-09-13T21:21:03Z,src/core/tsi/transport_security.h,"@@ -88,7 +88,7 @@ struct tsi_handshaker { typedef struct {   tsi_result (*extract_peer)(const tsi_handshaker_result *self, tsi_peer *peer);   tsi_result (*create_zero_copy_grpc_protector)(-      const tsi_handshaker_result *self,+      void *exec_ctx, const tsi_handshaker_result *self,","Yes, the goal is to keep TSI interface (transport_security_interface.h, transport_security.x) independent of grpc. There are other callers of TSI besides grpc.How about we typedef grpc_exec_ctx, similar to what we did on tsi_zero_copy_grpc_protector on transport_security_interface.h. Just declare it without define it.https://github.com/grpc/grpc/blob/master/src/core/tsi/transport_security_interface.h#L72 ",
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/12522,138749802,2017-09-13T21:53:10Z,src/php/composer.json,"@@ -1,20 +1,23 @@ {-  ""name"": ""grpc/grpc-dev"",-  ""description"": ""gRPC library for PHP - for Developement use only"",+  ""name"": ""grpc/grpc"",+  ""type"": ""library"",+  ""description"": ""gRPC library for PHP"",+  ""keywords"": [""rpc""],+  ""homepage"": ""https://grpc.io"",   ""license"": ""Apache-2.0"",-  ""version"": ""1.7.0"",   ""require"": {     ""php"": "">=5.5.0"",-    ""google/protobuf"": ""^v3.3.0""+    ""google/protobuf"": ""^3.4.0""   },   ""require-dev"": {     ""google/auth"": ""v0.9""   },+  ""suggest"": {+    ""ext-protobuf"": ""For better performance, install the protobuf C extension.""+  },   ""autoload"": {     ""psr-4"": {-      ""Grpc\\"": ""lib/Grpc/"",","We need to keep this right? Relative to this directory `src/php`, the `Grpc\\` classes is under `lib/Grpc/` not `src/php/lib/Grpc`.In fact, I think we don't really need to touch this file much at all.",
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/12522,138750554,2017-09-13T21:56:54Z,src/php/composer.json,"@@ -1,20 +1,23 @@ {-  ""name"": ""grpc/grpc-dev"",-  ""description"": ""gRPC library for PHP - for Developement use only"",+  ""name"": ""grpc/grpc"",+  ""type"": ""library"",+  ""description"": ""gRPC library for PHP"",+  ""keywords"": [""rpc""],+  ""homepage"": ""https://grpc.io"",   ""license"": ""Apache-2.0"",-  ""version"": ""1.7.0"",",We need this. https://github.com/grpc/grpc/blob/master/src/php/lib/Grpc/BaseStub.php#L68I prefer we keep this file as is. This is basically useful only for internal development (as described by the `description` field above). We can update the `google/protobuf` to `^3.4.0`.,
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/12553,138751534,2017-09-13T22:01:56Z,src/core/tsi/transport_security.h,"@@ -88,7 +88,7 @@ struct tsi_handshaker { typedef struct {   tsi_result (*extract_peer)(const tsi_handshaker_result *self, tsi_peer *peer);   tsi_result (*create_zero_copy_grpc_protector)(-      const tsi_handshaker_result *self,+      void *exec_ctx, const tsi_handshaker_result *self,","It does not work. It breaks asan. I have chatted with Julien. He thinks we need to have tsi_handshaker and tsi_handshaker_result interface independent of grpc. I rolled back to use void in the vtable layer. For zero-copy protector, we will cast to grpc_exec_ctx. What do you think?",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/12553,138751936,2017-09-13T22:03:58Z,src/core/tsi/transport_security.h,"@@ -88,7 +88,7 @@ struct tsi_handshaker { typedef struct {   tsi_result (*extract_peer)(const tsi_handshaker_result *self, tsi_peer *peer);   tsi_result (*create_zero_copy_grpc_protector)(-      const tsi_handshaker_result *self,+      void *exec_ctx, const tsi_handshaker_result *self,",Note that in tsi_handshaker_result_create_zero_copy_grpc_protector() still pass grpc_exec_ctx. It is just vtable needs to use void to make TSI interface independent.,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/12545,138754865,2017-09-13T22:20:07Z,src/core/lib/iomgr/ev_epoll1_linux.c,"@@ -154,9 +154,9 @@ struct grpc_pollset_worker {   grpc_closure_list schedule_on_end_work; }; -#define SET_KICK_STATE(worker, state)        \+#define SET_KICK_STATE(worker, kick_state)   \",Why change the parameter name?,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/12545,138755309,2017-09-13T22:22:38Z,src/core/lib/iomgr/ev_epollex_linux.c,"@@ -122,27 +122,27 @@ static const char *polling_obj_type_string(polling_obj_type t) {   return ""<invalid>""; } -static char *pollable_desc(pollable_type *p) {+static char *pollable_desc(pollable *p) {   char *out;   gpr_asprintf(&out, ""type=%s group=%p epfd=%d wakeup=%d"",                polling_obj_type_string(p->po.type), p->po.group, p->epfd,                p->wakeup.read_fd);   return out; } -static pollable_type g_empty_pollable;+static pollable g_empty_pollable; -static void pollable_init(pollable_type *p, polling_obj_type type);-static void pollable_destroy(pollable_type *p);+static void pollable_init(pollable *p, polling_obj_type type);+static void pollable_destroy(pollable *p); /* ensure that p->epfd, p->wakeup are initialized; p->po.mu must be held */-static grpc_error *pollable_materialize(pollable_type *p);+static grpc_error *pollable_materialize(pollable *p);  /*******************************************************************************  * Fd Declarations  */  struct grpc_fd {-  pollable_type pollable;+  pollable pollable_obj;",`pollable_obj` is great because it makes it clear that this is an object and not just a boolean condition.,
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/12545,138757818,2017-09-13T22:37:49Z,src/core/lib/iomgr/ev_epoll1_linux.c,"@@ -154,9 +154,9 @@ struct grpc_pollset_worker {   grpc_closure_list schedule_on_end_work; }; -#define SET_KICK_STATE(worker, state)        \+#define SET_KICK_STATE(worker, kick_state)   \","Need to differentiate between the field name 'state' and macro parameter 'kick_state', otherwise it would try to find worker->KICKED instead of worker->state",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12553,138918200,2017-09-14T14:56:07Z,src/core/tsi/transport_security.h,"@@ -88,7 +88,7 @@ struct tsi_handshaker { typedef struct {   tsi_result (*extract_peer)(const tsi_handshaker_result *self, tsi_peer *peer);   tsi_result (*create_zero_copy_grpc_protector)(-      const tsi_handshaker_result *self,+      void *exec_ctx, const tsi_handshaker_result *self,","It's not clear to me how this could have caused asan failures.  Do we know how that happened?  I would have thought that it could have caused build failures, but I don't see how it could cause the build to succeed and then leak memory.If this won't work for some reason, I can live with void, but let's at least add a comment explaining why it's void:```// The exec_ctx parameter is supposed to be of type grpc_exec_ctx*, but// we're using void* instead to avoid making the TSI API depend on grpc.// The create_zero_copy_grpc_protector() method is only used in grpc, where we// do need the exec_ctx passed through, but the API still needs to compile// in other applications, where grpc_exec_ctx is not defined.```",
103941,bshaffer,https://api.github.com/repos/grpc/grpc/pulls/12522,138954579,2017-09-14T17:08:54Z,src/php/composer.json,"@@ -1,20 +1,23 @@ {-  ""name"": ""grpc/grpc-dev"",-  ""description"": ""gRPC library for PHP - for Developement use only"",+  ""name"": ""grpc/grpc"",+  ""type"": ""library"",+  ""description"": ""gRPC library for PHP"",+  ""keywords"": [""rpc""],+  ""homepage"": ""https://grpc.io"",   ""license"": ""Apache-2.0"",-  ""version"": ""1.7.0"",   ""require"": {     ""php"": "">=5.5.0"",-    ""google/protobuf"": ""^v3.3.0""+    ""google/protobuf"": ""^3.4.0""   },   ""require-dev"": {     ""google/auth"": ""v0.9""   },+  ""suggest"": {+    ""ext-protobuf"": ""For better performance, install the protobuf C extension.""+  },   ""autoload"": {     ""psr-4"": {-      ""Grpc\\"": ""lib/Grpc/"",","Woops, my bad. I've added it back",
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/12522,138965598,2017-09-14T17:53:17Z,src/php/composer.json,"@@ -1,20 +1,24 @@ {-  ""name"": ""grpc/grpc-dev"",-  ""description"": ""gRPC library for PHP - for Developement use only"",+  ""name"": ""grpc/grpc"",+  ""type"": ""library"",+  ""description"": ""gRPC library for PHP"",+  ""keywords"": [""rpc""],+  ""homepage"": ""https://grpc.io"",   ""license"": ""Apache-2.0"",   ""version"": ""1.7.0"",   ""require"": {     ""php"": "">=5.5.0"",-    ""google/protobuf"": ""^v3.3.0""+    ""google/protobuf"": ""^3.4.0""   },   ""require-dev"": {     ""google/auth"": ""v0.9""   },+  ""suggest"": {+    ""ext-protobuf"": ""For better performance, install the protobuf C extension.""+  },   ""autoload"": {     ""psr-4"": {-      ""Grpc\\"": ""lib/Grpc/"",-      """": [""tests/interop/"",",We also need these 2 lines back. There are several tests that rely on these. We can list out the namespaces in a separate enhancement,
103941,bshaffer,https://api.github.com/repos/grpc/grpc/pulls/12522,138999931,2017-09-14T20:16:17Z,src/php/composer.json,"@@ -1,20 +1,23 @@ {-  ""name"": ""grpc/grpc-dev"",-  ""description"": ""gRPC library for PHP - for Developement use only"",+  ""name"": ""grpc/grpc"",+  ""type"": ""library"",+  ""description"": ""gRPC library for PHP"",+  ""keywords"": [""rpc""],+  ""homepage"": ""https://grpc.io"",   ""license"": ""Apache-2.0"",-  ""version"": ""1.7.0"",   ""require"": {     ""php"": "">=5.5.0"",-    ""google/protobuf"": ""^v3.3.0""+    ""google/protobuf"": ""^3.4.0""   },   ""require-dev"": {     ""google/auth"": ""v0.9""   },+  ""suggest"": {+    ""ext-protobuf"": ""For better performance, install the protobuf C extension.""+  },   ""autoload"": {     ""psr-4"": {-      ""Grpc\\"": ""lib/Grpc/"",","I just realized the classes are actually under `src/lib`, which doesn't exist in this directory. it would be better if we could keep this path the same in `grpc/grpc-php`, i.e. `lib/Grpc`.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12299,139028569,2017-09-14T22:41:17Z,src/ruby/ext/grpc/rb_channel.c,"@@ -28,6 +28,10 @@ #include <grpc/support/alloc.h> #include <grpc/support/log.h> #include <grpc/support/time.h>+#include <grpc/support/port_platform.h>+#ifdef GPR_SUPPORT_CHANNELS_FROM_FD","since https://github.com/grpc/grpc/blob/master/src/core/ext/transport/chttp2/client/insecure/channel_create_posix.c#L24 is already handling platform compatiblity, I think we can remove this `ifdef` and unconditionally include the posix header",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12299,139028927,2017-09-14T22:43:51Z,src/ruby/ext/grpc/rb_channel.c,"@@ -261,6 +265,65 @@ static VALUE grpc_rb_channel_init(int argc, VALUE *argv, VALUE self) {   return self; } +/*+  call-seq:+    ch = Channel.insecure_create_from_fd(""fd:42"", 42, {'arg1': 'value1'})++  Creates channel instances from an existing file descriptor. */+static VALUE grpc_rb_channel_insecure_create_from_fd(+    VALUE klass, VALUE rb_target, VALUE rb_fd, VALUE rb_args) {+#ifdef GPR_SUPPORT_CHANNELS_FROM_FD","rather than placing an `ifdef` around this larger section of code, can we please instead create a ruby wrapper"" for `grpc_insecure_channel_create_from_fd`? e.g., `grpc_rb_insecure_channel_create_from_fd`?, which handles the platform compatiblity and throws `NotImplemented`?the `ifdef` could then wrap a smaller chunk of code within that.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12299,139029478,2017-09-14T22:48:02Z,src/ruby/spec/generic/rpc_server_spec.rb,"@@ -755,5 +757,59 @@ def common_check_of_finished_server_call(call)         check_multi_req_view_of_finished_call(@service.server_side_call)       end     end++    if Object.const_defined?('UNIXSocket')","I believe we can actually remove this conditional. There is a large TODO for this but continuous jenkins tests are actually not running windows/mingw builds for grpc-ruby currently - I think we can add platform compatibility for this test in once that becomes the case, as I believe this should pass on mac and linux.",
1069502,justinburke,https://api.github.com/repos/grpc/grpc/pulls/12359,139051112,2017-09-15T02:16:05Z,src/core/tsi/ssl_transport_security.c,"@@ -1013,6 +1062,8 @@ static tsi_result ssl_handshaker_create_frame_protector( static void ssl_handshaker_destroy(tsi_handshaker *self) {   tsi_ssl_handshaker *impl = (tsi_ssl_handshaker *)self;   SSL_free(impl->ssl); /* The BIO objects are owned by ssl */+  tsi_ssl_handshaker_factory_unref(impl->factory_ref);+  impl->factory_ref = NULL;","That is the result of many hours lost in front of debuggers chasing down zombie references. Ie. you can't accidentally dereference something that isn't there...Anyway, I'll remove it.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/12564,139204074,2017-09-15T17:19:56Z,src/core/lib/surface/completion_queue.c,"@@ -449,7 +449,7 @@ grpc_completion_queue *grpc_completion_queue_create_internal( static void cq_init_next(void *ptr) {   cq_next_data *cqd = (cq_next_data *)ptr;   /* Initial count is dropped by grpc_completion_queue_shutdown */-  gpr_atm_no_barrier_store(&cqd->pending_events, 1);+  gpr_atm_rel_store(&cqd->pending_events, 1);","Is there really a reason to have release semantic in the CQ init function? By definition, some other thread can't see this item until there's been some intervening synchronization operation",
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/12564,139242533,2017-09-15T20:26:34Z,src/core/lib/surface/completion_queue.c,"@@ -643,8 +643,7 @@ static void cq_end_op_for_next(grpc_exec_ctx *exec_ctx,   /* Add the completion to the queue */   bool is_first = cq_event_queue_push(&cqd->queue, storage);   gpr_atm_no_barrier_fetch_add(&cqd->things_queued_ever, 1);-  bool will_definitely_shutdown =-      gpr_atm_no_barrier_load(&cqd->pending_events) == 1;+  bool will_definitely_shutdown = gpr_atm_acq_load(&cqd->pending_events) == 1;","T1 wrote to the `cq` via  `cq_event_queue_push` in line 644 which is a lock free operation (and it did without having completion queue lock or without any other memory fence ) .. T2 called `completion_queue_destroy` which called cq-shutdown first which decremented `pending_events` to zero (under cq-lock AND also under a memory fence by doing `full_fetch_add` - but that doesn't matter) and this ended up destroying the `cq`My claim was that since there was no happens-before between T1 and T2,  tsan is complaining that there is a data race (It says T2 did a write and the previous write is done by T1 )This line is really the only fix to this bug.  However, I felt it is a good practice to just use `acq` for load and `release` for store as a good practice in general (especially considering the fact that using `no_barrier` operations was not a deliberate choice in the first place :) )..",
22083734,matt-kwong,https://api.github.com/repos/grpc/grpc/pulls/12562,139261640,2017-09-15T22:23:45Z,tools/internal_ci/helper_scripts/prepare_build_linux_perf_rc,"@@ -19,4 +19,23 @@ ulimit -n 32768 ulimit -c unlimited +# Remove this nbefore merging. Only used for testing+KOKORO_GITHUB_PULL_REQUEST_NUMBER=12552++# Performance PR testing needs GH API key and PR metadata to comment results+if [ -n ""$KOKORO_GITHUB_PULL_REQUEST_NUMBER"" ]; then+  set +x+  sudo apt-get install -y jq+  ghprbTargetBranch=$(curl -s https://api.github.com/repos/grpc/grpc/pulls/$KOKORO_GITHUB_PULL_REQUEST_NUMBER | jq -r .base.ref)++  gsutil cp gs://grpc-testing-secrets/github_credentials/oauth_token.txt ~/+  export JENKINS_OAUTH_TOKEN=$(cat ~/oauth_token.txt)",TODO added. There's also a lot of other Jenkins specific variables/naming conventions in our scripts that will need to be cleaned up after we're fully migrated.,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/12603,139294734,2017-09-16T20:27:16Z,src/python/grpcio_tests/tests/_sanity/_sanity_test.py,"@@ -21,24 +21,25 @@ import tests  -class Sanity(unittest.TestCase):+class SanityTest(unittest.TestCase):++    maxDiff = 32768","I mentioned it in the commit log message, though perhaps not in as much detail as I could have for readers who haven't before heard of it. It overrides a `unittest.TestCase` attribute that controls how much to print when an `assert<Something>` method fails. In our case in this test the list of tests can be as much as five whole kilobytes, and I got tired of seeing on test failure the ""we've truncated the diff that you're seeing"" message. Try it out for yourself by putting a typo into `tests.json` and then running `_sanity_test`?",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/12612,139799651,2017-09-19T19:50:50Z,include/grpc++/impl/codegen/async_stream.h,"@@ -424,6 +424,20 @@ class ClientAsyncReaderWriterInterface : public ClientAsyncStreamingInterface,   ///   /// \param[in] tag The tag identifying the operation.   virtual void WritesDone(void* tag) = 0;++  /// Special operation that is only available in this streaming interface+  /// as it allows batching of multiple operations into a single function+  /// call (and thus only a single CQ trip).+  /// Note that \a do_read_initial_metadata is only checked when relevant since+  /// it may be implicit otherwise. On the other hand, the other booleans+  /// are actually required to be used correctly+  /// \a write_request should be nullptr if nothing should be written+  /// \a read_response should be nullptr if nothing should be read+  /// \a status should be nullptr if not trying to get Status (not Finish-ing)+  virtual void BatchOps(bool do_start_call, const W* write_request,",What does this add (that's needed) that isn't addressed by https://github.com/grpc/proposal/blob/master/L1-c%2B%2B-stream-coalescing.md?,
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/12580,139818602,2017-09-19T21:08:51Z,src/core/lib/debug/stats_data.c,"@@ -588,6 +594,33 @@ void grpc_stats_inc_http2_send_flowctl_per_write(grpc_exec_ctx *exec_ctx,                            grpc_stats_histo_find_bucket_slow(                                (exec_ctx), value, grpc_stats_table_6, 64)); }+void grpc_stats_inc_executor_closures_per_wakeup(grpc_exec_ctx *exec_ctx,+                                                 int value) {+  value = GPR_CLAMP(value, 0, 1024);+  if (value < 13) {+    GRPC_STATS_INC_HISTOGRAM(+        (exec_ctx), GRPC_STATS_HISTOGRAM_EXECUTOR_CLOSURES_PER_WAKEUP, value);+    return;+  }+  union {+    double dbl;+    uint64_t uint;+  } _val, _bkt;+  _val.dbl = value;+  if (_val.uint < 4637863191261478912ull) {",This is code generated (there's a big banner at the head of the file)... hesitant to complicate the code generator.,
1170852,cauthu,https://api.github.com/repos/grpc/grpc/pulls/12644,139840495,2017-09-19T23:07:41Z,src/core/lib/security/transport/security_connector.c,"@@ -511,14 +537,107 @@ static void ssl_channel_add_handshakers(grpc_exec_ctx *exec_ctx,           exec_ctx, tsi_create_adapter_handshaker(tsi_hs), &sc->base)); } +static const char **fill_alpn_protocol_strings(void) {+  const size_t num_alpn_protocols = grpc_chttp2_num_alpn_versions();+  const char **alpn_protocol_strings =+      gpr_malloc(sizeof(const char *) * num_alpn_protocols);+  size_t i;+  for (i = 0; i < num_alpn_protocols; i++) {+    alpn_protocol_strings[i] = grpc_chttp2_get_alpn_version_index(i);+  }+  return alpn_protocol_strings;+}++/* Attempts to replace the server_handshaker_factory with a new factory using+ * the provided grpc_server_credentials. Should the credentials not be of type+ * SSL or should the new factory creation fail, the existing factory will not be+ * replaced. */+static void replace_server_handshaker_factory(+    grpc_ssl_server_security_connector *sc,+    grpc_server_credentials *server_creds) {+  const size_t num_alpn_protocols = grpc_chttp2_num_alpn_versions();+  const char **alpn_protocol_strings = NULL;+  grpc_ssl_server_credentials *ssl_server_creds = NULL;+  tsi_ssl_server_handshaker_factory *new_handshaker_factory = NULL;+  tsi_result result;++  if (server_creds == NULL) {+    gpr_log(GPR_ERROR,+            ""Server credentials callback returned invalid (NULL) credentials."");+    return;+  }++  if (0 != strcmp(GRPC_CHANNEL_CREDENTIALS_TYPE_SSL, server_creds->type)) {+    gpr_log(GPR_ERROR,+            ""Server credentials callback returned invalid, non-SSL ""+            ""credentials type (%s)."",+            server_creds->type);+    return;+  }++  gpr_log(GPR_DEBUG, ""Using new server credentials with server_creds=%p."",+          server_creds);++  ssl_server_creds = (grpc_ssl_server_credentials *)server_creds;++  alpn_protocol_strings = fill_alpn_protocol_strings();+  result = tsi_create_ssl_server_handshaker_factory_ex(+      ssl_server_creds->config.pem_key_cert_pairs,+      ssl_server_creds->config.num_key_cert_pairs,+      ssl_server_creds->config.pem_root_certs,+      get_tsi_client_certificate_request_type(+          ssl_server_creds->config.client_certificate_request),+      ssl_cipher_suites(), alpn_protocol_strings, (uint16_t)num_alpn_protocols,+      &new_handshaker_factory);+  gpr_free((void *)alpn_protocol_strings);++  if (result == TSI_OK) {+    tsi_ssl_server_handshaker_factory_unref(sc->server_handshaker_factory);+    sc->server_handshaker_factory = new_handshaker_factory;+  } else {+    gpr_log(GPR_ERROR, ""Handshaker factory creation failed with %s."",+            tsi_result_to_string(result));+  }+}++/* Attempts to reload the server credentials if a callback is available. Current+ * credentials will continue to be used if the callback returns an error. */+static void reload_ssl_server_credentials(+    grpc_ssl_server_security_connector *sc) {+  grpc_server_credentials *server_creds = NULL;+  grpc_get_server_credentials_result cb_result;++  if (sc == NULL || sc->base.get_server_credentials_cb == NULL) return;++  cb_result = sc->base.get_server_credentials_cb(+      &server_creds, sc->base.get_server_credentials_cb_arg);++  if (cb_result == GRPC_GET_SERVER_CREDENTIALS_UNCHANGED) {+    gpr_log(GPR_DEBUG, ""No change in SSL server credentials."");+  } else if (cb_result == GRPC_GET_SERVER_CREDENTIALS_NEW) {+    replace_server_handshaker_factory(sc, server_creds);+  } else {+    // Log error, continue using previously-loaded credentials.+    gpr_log(GPR_ERROR, ""Failed loading new server credentials, error code %d."",+            cb_result);+  }++  if (server_creds) {+    grpc_server_credentials_release(server_creds);+  }+}+ static void ssl_server_add_handshakers(grpc_exec_ctx *exec_ctx,                                        grpc_server_security_connector *sc,                                        grpc_handshake_manager *handshake_mgr) {   grpc_ssl_server_security_connector *c =       (grpc_ssl_server_security_connector *)sc;   // Instantiate TSI handshaker.   tsi_handshaker *tsi_hs = NULL;-  tsi_result result = tsi_ssl_server_handshaker_factory_create_handshaker(+  tsi_result result;++  reload_ssl_server_credentials(c);","naming nit: perhaps `maybe_reload_ssl_server_credentials()` to indicate that the reload is a ""maybe""?",
1069502,justinburke,https://api.github.com/repos/grpc/grpc/pulls/12644,139842305,2017-09-19T23:21:52Z,src/core/lib/security/credentials/ssl/ssl_credentials.c,"@@ -161,34 +163,49 @@ static void ssl_build_server_config(  grpc_server_credentials *grpc_ssl_server_credentials_create(     const char *pem_root_certs, grpc_ssl_pem_key_cert_pair *pem_key_cert_pairs,-    size_t num_key_cert_pairs, int force_client_auth, void *reserved) {+    size_t num_key_cert_pairs, int force_client_auth,+    grpc_ssl_server_credentials_create_options *options) {   return grpc_ssl_server_credentials_create_ex(       pem_root_certs, pem_key_cert_pairs, num_key_cert_pairs,       force_client_auth           ? GRPC_SSL_REQUEST_AND_REQUIRE_CLIENT_CERTIFICATE_AND_VERIFY           : GRPC_SSL_DONT_REQUEST_CLIENT_CERTIFICATE,-      reserved);+      options); }  grpc_server_credentials *grpc_ssl_server_credentials_create_ex(     const char *pem_root_certs, grpc_ssl_pem_key_cert_pair *pem_key_cert_pairs,     size_t num_key_cert_pairs,     grpc_ssl_client_certificate_request_type client_certificate_request,-    void *reserved) {+    grpc_ssl_server_credentials_create_options *options) {   grpc_ssl_server_credentials *c =       gpr_zalloc(sizeof(grpc_ssl_server_credentials));   GRPC_API_TRACE(       ""grpc_ssl_server_credentials_create_ex(""       ""pem_root_certs=%s, pem_key_cert_pairs=%p, num_key_cert_pairs=%lu, ""-      ""client_certificate_request=%d, reserved=%p)"",+      ""client_certificate_request=%d, options=%p)"",       5, (pem_root_certs, pem_key_cert_pairs, (unsigned long)num_key_cert_pairs,-          client_certificate_request, reserved));-  GPR_ASSERT(reserved == NULL);+          client_certificate_request, options));   c->base.type = GRPC_CHANNEL_CREDENTIALS_TYPE_SSL;   gpr_ref_init(&c->base.refcount, 1);   c->base.vtable = &ssl_server_vtable;   ssl_build_server_config(pem_root_certs, pem_key_cert_pairs,                           num_key_cert_pairs, client_certificate_request,                           &c->config);+  if (options != NULL) {+    GRPC_API_TRACE(+        ""grpc_ssl_server_credentials_create_options: ""+        ""get_server_credentials_cb = %p, get_server_credentials_cb_arg = %p"",+        2, (options->get_server_credentials_cb,+            options->get_server_credentials_cb_arg));+    if (options->get_server_credentials_cb != NULL) {","True, however most of the codebase prefers to be explicit, so I'd prefer to follow the same pattern here.",
1170852,cauthu,https://api.github.com/repos/grpc/grpc/pulls/12644,139845254,2017-09-19T23:44:46Z,include/grpc/grpc_security.h,"@@ -290,11 +290,22 @@ GRPCAPI grpc_channel *grpc_secure_channel_create(  typedef struct grpc_server_credentials grpc_server_credentials; +typedef grpc_get_server_credentials_result (+    *grpc_get_server_credentials_callback)(grpc_server_credentials **creds,+                                           void *cb_arg);+ /** Releases a server_credentials object.    The creator of the server_credentials object is responsible for its release.    */ GRPCAPI void grpc_server_credentials_release(grpc_server_credentials *creds); +/** Extended options for grpc_ssl_server_credentials_create. */+typedef struct {+  grpc_get_server_credentials_callback get_server_credentials_cb;+  void *get_server_credentials_cb_arg;+  void *reserved;","> If we omitted reserved and just added to the struct, I have some concern that we may not be able to determine if the caller is providing the old or new struct format.Hmm are you referring to binary compatibility concern where user compiles his application against older `options` struct but at run time runs with newer library that has newer/different `options` struct? If so I'm not sure how `reserved` would help detect? Is it a standard/generally accepted solution to have the `reserved` field as a solution?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12631,139863571,2017-09-20T02:35:36Z,test/cpp/naming/resolver_test_record_groups.yaml,"@@ -137,11 +137,6 @@ resolver_component_tests:     - {TTL: '2100', data: '2607:f8b0:400a:801::1002', type: AAAA}     srv-ipv6-target-has-backend-and-balancer:     - {TTL: '2100', data: '2607:f8b0:400a:801::1002', type: AAAA}--resolver_component_tests_TODO:-- 'TODO: enable this large-txt-record test once working. (it is much longer than 512-  bytes, likely to cause use of TCP even if max payload for UDP is changed somehow,-  e.g. via notes in RFC 2671)'","nit: this looks like a pre-existing bug in this yaml file actually, but it looks like there are accidentally two`record_to_resolve` key-value pairs in this ""test group"".It looks like line 149, with `record_to_resolve: srv-ipv6-target-has-backend-and-balancer` is getting silently ignored. Can we please remove that one since the test is now getting used.",
1170852,cauthu,https://api.github.com/repos/grpc/grpc/pulls/12644,140112429,2017-09-20T22:50:16Z,include/grpc/grpc_security.h,"@@ -290,11 +290,22 @@ GRPCAPI grpc_channel *grpc_secure_channel_create(  typedef struct grpc_server_credentials grpc_server_credentials; +typedef grpc_get_server_credentials_result (+    *grpc_get_server_credentials_callback)(grpc_server_credentials **creds,+                                           void *cb_arg);+ /** Releases a server_credentials object.    The creator of the server_credentials object is responsible for its release.    */ GRPCAPI void grpc_server_credentials_release(grpc_server_credentials *creds); +/** Extended options for grpc_ssl_server_credentials_create. */+typedef struct {+  grpc_get_server_credentials_callback get_server_credentials_cb;+  void *get_server_credentials_cb_arg;+  void *reserved;","discussed during video conference, that `reserved` can be omitted if we provide an opaque way to initialize/set options, e.g.,```options* new_[default_]options();void options_set_cb(...);void options_set_cb_arg(...);```etc.@justinburke maybe an example is `gpr_thd_options` in `tools/distrib/python/grpcio_tools/grpc_root/include/grpc/support/thd.h`: users of the library then would not directly access the struct's fields, and only the library itself would access the fields directly.",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/12663,140343182,2017-09-21T19:54:29Z,src/core/lib/iomgr/timer_generic.c,"@@ -79,6 +79,121 @@ static timer_shard g_shards[NUM_SHARDS];  * Access to this is protected by g_shared_mutables.mu */ static timer_shard *g_shard_queue[NUM_SHARDS]; +#ifndef NDEBUG++/* == Hash table for duplicate timer detection == */++#define NUM_HASH_BUCKETS 1000+#define NUM_SLOTS_PER_BUCKET 30++static gpr_mu g_hash_mu[NUM_HASH_BUCKETS]; /* One mutex per bucket */+static grpc_timer *g_timer_ht[NUM_HASH_BUCKETS]+                             [NUM_SLOTS_PER_BUCKET] = {{NULL, NULL}};++static void init_timer_ht() {+  for (int i = 0; i < NUM_HASH_BUCKETS; i++) {+    gpr_mu_init(&g_hash_mu[i]);+  }+}++static bool is_in_ht(grpc_timer *t) {+  size_t i = GPR_HASH_POINTER(t, NUM_HASH_BUCKETS);+  bool is_found = false;+  gpr_mu_lock(&g_hash_mu[i]);+  for (int j = 0; j < NUM_SLOTS_PER_BUCKET; j++) {+    if (g_timer_ht[i][j] == t) {+      is_found = true;+      break;+    }+  }+  gpr_mu_unlock(&g_hash_mu[i]);+  return is_found;+}++static void add_to_ht(grpc_timer *t) {+  size_t i = GPR_HASH_POINTER(t, NUM_HASH_BUCKETS);+  bool added = false;+  gpr_mu_lock(&g_hash_mu[i]);+  for (int j = 0; j < NUM_SLOTS_PER_BUCKET; j++) {+    if (g_timer_ht[i][j] == NULL) {+      g_timer_ht[i][j] = t;+      added = true;+      break;+    } else if (g_timer_ht[i][j] == t) {+      grpc_closure *c = t->closure;+      gpr_log(GPR_ERROR,+              ""** Duplicate timer (%p) being added. Closure: (%p), created at: ""+              ""(%s:%d), scheduled at: (%s:%d) **"",+              t, c, c->file_created, c->line_created, c->file_initiated,+              c->line_initiated);+      abort();+    }+  }++  gpr_mu_unlock(&g_hash_mu[i]);+  if (!added) {+    gpr_log(GPR_ERROR,","(would allow chaining, and eliminate this class of failure)",
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/12663,140344189,2017-09-21T19:59:11Z,src/core/lib/iomgr/timer_generic.c,"@@ -79,6 +79,121 @@ static timer_shard g_shards[NUM_SHARDS];  * Access to this is protected by g_shared_mutables.mu */ static timer_shard *g_shard_queue[NUM_SHARDS]; +#ifndef NDEBUG++/* == Hash table for duplicate timer detection == */++#define NUM_HASH_BUCKETS 1000+#define NUM_SLOTS_PER_BUCKET 30++static gpr_mu g_hash_mu[NUM_HASH_BUCKETS]; /* One mutex per bucket */+static grpc_timer *g_timer_ht[NUM_HASH_BUCKETS]+                             [NUM_SLOTS_PER_BUCKET] = {{NULL, NULL}};++static void init_timer_ht() {+  for (int i = 0; i < NUM_HASH_BUCKETS; i++) {+    gpr_mu_init(&g_hash_mu[i]);+  }+}++static bool is_in_ht(grpc_timer *t) {+  size_t i = GPR_HASH_POINTER(t, NUM_HASH_BUCKETS);+  bool is_found = false;+  gpr_mu_lock(&g_hash_mu[i]);+  for (int j = 0; j < NUM_SLOTS_PER_BUCKET; j++) {+    if (g_timer_ht[i][j] == t) {+      is_found = true;+      break;+    }+  }+  gpr_mu_unlock(&g_hash_mu[i]);+  return is_found;+}++static void add_to_ht(grpc_timer *t) {+  size_t i = GPR_HASH_POINTER(t, NUM_HASH_BUCKETS);+  bool added = false;+  gpr_mu_lock(&g_hash_mu[i]);+  for (int j = 0; j < NUM_SLOTS_PER_BUCKET; j++) {+    if (g_timer_ht[i][j] == NULL) {+      g_timer_ht[i][j] = t;+      added = true;+      break;+    } else if (g_timer_ht[i][j] == t) {+      grpc_closure *c = t->closure;+      gpr_log(GPR_ERROR,+              ""** Duplicate timer (%p) being added. Closure: (%p), created at: ""+              ""(%s:%d), scheduled at: (%s:%d) **"",+              t, c, c->file_created, c->line_created, c->file_initiated,+              c->line_initiated);+      abort();+    }+  }++  gpr_mu_unlock(&g_hash_mu[i]);+  if (!added) {+    gpr_log(GPR_ERROR,","Hmm..actually chaining might be better (the reason for adding fixed bucket width was because I was initially curious about the max collisions we would get. Now I know that it is somewhere between 5 to 10 - and that too just for a few tests. Yeah, I will change this to chaining based).",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12385,140549275,2017-09-22T17:20:03Z,src/ruby/ext/grpc/extconf.rb,"@@ -63,19 +63,10 @@ ENV['CFLAGS'] = '-DGPR_BACKWARDS_COMPATIBILITY_MODE'  output_dir = File.expand_path(RbConfig::CONFIG['topdir'])-grpc_lib_dir = File.join(output_dir, 'libs', grpc_config) ENV['BUILDDIR'] = output_dir -unless windows","This won't work because it breaks the windows build (which builds the core library in a  separate, earlier step",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12100,140618904,2017-09-23T00:13:06Z,src/ruby/lib/grpc/generic/rpc_desc.rb,"@@ -47,43 +47,88 @@ def unmarshal_proc(target)       proc { |o| unmarshal_class.method(unmarshal_method).call(o) }     end -    def handle_request_response(active_call, mth)+    def handle_request_response(active_call, mth, inter_ctx)       req = active_call.read_unary_request-      resp = mth.call(req, active_call.single_req_view)-      active_call.server_unary_response(-        resp, trailing_metadata: active_call.output_metadata)+      call = active_call.single_req_view++      inter_ctx.intercept!(+        :request_response,+        method: mth,+        call: call,+        request: req+      ) do+        resp = mth.call(req, call)+        active_call.server_unary_response(+          resp,+          trailing_metadata: active_call.output_metadata+        )+        resp","nit: similar to above, `resp` return val unneeded?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12610,140798210,2017-09-25T14:48:24Z,src/core/ext/filters/client_channel/client_channel_factory.c,"@@ -63,6 +63,6 @@ static const grpc_arg_pointer_vtable factory_arg_vtable = {  grpc_arg grpc_client_channel_factory_create_channel_arg(     grpc_client_channel_factory* factory) {-  return grpc_channel_arg_pointer_create(GRPC_ARG_CLIENT_CHANNEL_FACTORY,+  return grpc_channel_arg_pointer_create((char*)GRPC_ARG_CLIENT_CHANNEL_FACTORY,","Instead of casting away the const, how about changing all of the `grpc_channel_arg_*_create()` functions to expect a const value as the parameter?",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/12624,140828524,2017-09-25T16:32:07Z,src/core/ext/filters/client_channel/http_proxy.c,"@@ -56,8 +58,6 @@ static char* get_http_proxy_server(grpc_exec_ctx* exec_ctx, char** user_cred) {     goto done;   }   /* Split on '@' to separate user credentials from host */-  char** authority_strs = NULL;","We cross declarations with gotos. This is not allowed in C++. To do otherwise would mean significant refactoring, and since that'll happen anyway (in a parallelizable way) once we're compiling as c++, I'd hold that we should prefer the most mechanical transform possible at this point.",
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/12644,140960826,2017-09-26T05:34:54Z,include/grpc/grpc_security.h,"@@ -290,11 +290,28 @@ GRPCAPI grpc_channel *grpc_secure_channel_create(  typedef struct grpc_server_credentials grpc_server_credentials; +typedef grpc_get_server_credentials_result (+    *grpc_get_server_credentials_callback)(grpc_server_credentials **creds,","Re: Python. This is exactly what I find not ideal: we are getting confused between the credentials object itself and the data that it holds. A separation of concern would be much cleaner even if it would mean exposing previously private data structures (which is OK).It would also work much better with clients (when we add the feature) as client-side channel credentials can be combined with call credentials such as oauth2 tokens to form another channel creds. If we follow the server current pattern, the callback would return a channel credentials and what type of channel creds should be returned would be ambiguous in this case (combined or not?) and make both the caller side and the implementation more complex than necessary.  ",
1170852,cauthu,https://api.github.com/repos/grpc/grpc/pulls/12644,140963293,2017-09-26T05:59:22Z,include/grpc/grpc_security.h,"@@ -290,11 +290,28 @@ GRPCAPI grpc_channel *grpc_secure_channel_create(  typedef struct grpc_server_credentials grpc_server_credentials; +typedef grpc_get_server_credentials_result (+    *grpc_get_server_credentials_callback)(grpc_server_credentials **creds,","(continuing comments https://github.com/grpc/grpc/pull/12644#issuecomment-332091885 and https://github.com/grpc/grpc/pull/12644#issuecomment-332093486 here; sorry I replied via email and it started new comments)> I think that the callback is the right design for the reasons you mentioned> about the complexity of locking in the core stack which looks non-trivial.> This is not what I'm objecting to.> I would just like to make sure that the pattern that we are using also> works for clients:OK sounds good!> In the context of spiffe for example, we would want to have one certificate> store object (fed by the workload API) implementing both the the> get_client_config and get_server_config APIs. Does that make sense?I'm not familiar with spiffe; nevertheless the reasoning above sounds good to me! Though Justin will chime in :)",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12613,141015819,2017-09-26T10:20:59Z,src/csharp/Grpc.Core/ClientBase.cs,"@@ -147,6 +149,64 @@ internal ClientBaseConfiguration Configuration         /// </summary>         protected internal class ClientBaseConfiguration         {+            private class ClientHeaderInterceptor : ClientInterceptor+            {+                readonly Func<IMethod, string, CallOptions, Tuple<string, CallOptions>> interceptor;++                /// <summary>+                /// Creates a new instance of ClientHeaderInterceptor given the specified header interceptor function.+                /// </summary>+                public ClientHeaderInterceptor(Func<IMethod, string, CallOptions, Tuple<string, CallOptions>> interceptor)+                {+                    this.interceptor = GrpcPreconditions.CheckNotNull(interceptor);+                }++                /// <summary>+                /// Intercepts a blocking invocation of a simple remote call.+                /// </summary>+                public override TResponse BlockingUnaryCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request, Func<Method<TRequest, TResponse>, string, CallOptions, TRequest, TResponse> next)+                {+                    var newHeaders = interceptor(method, host, options);+                    return next(method, newHeaders.Item1, newHeaders.Item2, request);+                }++                /// <summary>+                /// Intercepts an asynchronous invocation of a simple remote call.+                /// </summary>+                public override AsyncUnaryCall<TResponse> AsyncUnaryCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request, Func<Method<TRequest, TResponse>, string, CallOptions, TRequest, AsyncUnaryCall<TResponse>> next)","Also, I think the name ""next"" can easily be confused as having to do with streaming, so we could come up with a better name (I think naming the delegate would also help here).",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/12613,141089076,2017-09-26T15:16:29Z,src/csharp/Grpc.Core.Tests/Interceptors/ClientInterceptorTest.cs,"@@ -0,0 +1,76 @@+#region Copyright notice and license++// Copyright 2017 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Generic;+using System.Linq;+using System.Threading;+using System.Threading.Tasks;+using Grpc.Core;+using Grpc.Core.Interceptors;+using Grpc.Core.Internal;+using Grpc.Core.Utils;+using Grpc.Core.Tests;+using NUnit.Framework;++namespace Grpc.Core.Interceptors.Tests+{+    public class ClientInterceptorTest+    {+        private class AddHeaderClientInterceptor : ClientInterceptor+        {+            readonly Metadata.Entry header;+            public AddHeaderClientInterceptor(string key, string value)+            {+                this.header = new Metadata.Entry(key, value);+            }+            public override TResponse BlockingUnaryCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request, Func<Method<TRequest, TResponse>, string, CallOptions, TRequest, TResponse> next)+            {+                options.Headers.Add(this.header);+                return next(method, host, options, request);+            }++            public Metadata.Entry Header+            {+                get+                {+                    return this.header;+                }+            }+        }++        const string Host = ""127.0.0.1"";++        [Test]+        public void AddRequestHeaderInClientInterceptor()+        {+            var helper = new MockServiceHelper(Host);+            var interceptor = new AddHeaderClientInterceptor(""x-client-interceptor"", ""hello world"");+            helper.UnaryHandler = new UnaryServerMethod<string, string>((request, context) =>+            {+                var interceptorHeader = context.RequestHeaders.Last(m => (m.Key == interceptor.Header.Key)).Value;+                Assert.AreEqual(interceptorHeader, interceptor.Header.Value);+                return Task.FromResult(""PASS"");+            });+            var server = helper.GetServer();+            server.Start();+            var callInvoker = helper.GetChannel().Intercept(interceptor);","Yes, that is how it is going to work.I am considering adding another overload that takes `params Interceptor[]` and adds the list in-order (not the opposite order implied by decorator style). ",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/12613,141092490,2017-09-26T15:26:45Z,src/csharp/Grpc.Core/CallOptions.cs,"@@ -36,6 +37,7 @@ public struct CallOptions         ContextPropagationToken propagationToken;         CallCredentials credentials;         CallFlags flags;+        Dictionary<object, object> items;","I'm not sure what you mean by "".NET context"" object? Synchronization context? Yes, my initial version actually had this as `<string, object>` like `HttpContext` does, but I found myself wanting to use `typeof(MyInterceptor)` as a key, and it would not have worked with string keys, and I found no reason to restrict the dictionary to string keys (keys are generally used as input, not output, so they are rarely read to need explicit casting)—and for the value object it did not make sense to have anything less general than `object`.What I have in mind is a higher level interceptor base class that inherits from `ClientInterceptor` that uses this dictionary under the hood, but relies on a convention to store data in that dictionary and expose it in a type-safe way.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12709,141106047,2017-09-26T16:11:45Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1394,13 +1374,8 @@ static void query_for_backends_locked(grpc_exec_ctx *exec_ctx,   op->flags = 0;   op->reserved = NULL;   op++;-  /* take a weak ref (won't prevent calling of \a glb_shutdown if the strong ref-   * count goes to zero) to be unref'd in lb_on_sent_initial_request_locked() */-  GRPC_LB_POLICY_WEAK_REF(&glb_policy->base,-                          ""lb_on_sent_initial_request_locked"");-  call_error = grpc_call_start_batch_and_execute(-      exec_ctx, glb_policy->lb_call, ops, (size_t)(op - ops),-      &glb_policy->lb_on_sent_initial_request);+  call_error = grpc_call_start_batch_and_execute(exec_ctx, glb_policy->lb_call,","The ownership semantics for most ops are documented in grpc_types.h.  For example, the send_message semantics are documented here:https://github.com/grpc/grpc/blob/master/include/grpc/impl/codegen/grpc_types.h#L518These docs could certainly be better, and we can improve them separately.In any case, this PR does not change anything related to ownership of the arguments being passed into `grpc_call_start_batch_and_execute()`, so regardless of the behavior, it's not affected by this PR.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12718,141126721,2017-09-26T17:29:36Z,tools/run_tests/performance/scenario_config.py,"@@ -1025,6 +1052,7 @@ def __str__(self):     'node_express': NodeExpressLanguage(),     'ruby' : RubyLanguage(),     'php' : PhpLanguage(),+    'php_ext' : PhpLanguage_ext(),",I'd use a more descriptive name (and also one that complies to python code style for naming classes).PhpWithProtobufCLanguage seems totally fine.,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12718,141127413,2017-09-26T17:32:12Z,tools/run_tests/performance/scenario_config.py,"@@ -1025,6 +1052,7 @@ def __str__(self):     'node_express': NodeExpressLanguage(),     'ruby' : RubyLanguage(),     'php' : PhpLanguage(),+    'php_ext' : PhpLanguage_ext(),","You can also reuse the same class:Something in this sense:'php' : PhpLanguage(),'php_XXX' : PhpLanguage(use_protobuf_c_extension=True),",
1069502,justinburke,https://api.github.com/repos/grpc/grpc/pulls/12644,141130246,2017-09-26T17:41:27Z,include/grpc/grpc_security.h,"@@ -309,7 +326,8 @@ GRPCAPI void grpc_server_credentials_release(grpc_server_credentials *creds);      NULL. */ GRPCAPI grpc_server_credentials *grpc_ssl_server_credentials_create(     const char *pem_root_certs, grpc_ssl_pem_key_cert_pair *pem_key_cert_pairs,-    size_t num_key_cert_pairs, int force_client_auth, void *reserved);+    size_t num_key_cert_pairs, int force_client_auth,","@jboeuf Could you say a bit more about this? Is your objection here of a technical or design nature?If the former: the only thing any current caller can do is pass a `NULL`-valued `void *` since there's an assert check on the `NULL` value. After this change, all existing call sites can continue to pass a `NULL`-valued `void *` by way of implicit conversion.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/12709,141135597,2017-09-26T18:00:52Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.c,"@@ -1565,39 +1608,12 @@ static void lb_on_server_status_received_locked(grpc_exec_ctx *exec_ctx,   }   /* We need to perform cleanups no matter what. */   lb_call_destroy_locked(exec_ctx, glb_policy);-  if (glb_policy->started_picking && glb_policy->updating_lb_call) {-    if (glb_policy->retry_timer_active) {-      grpc_timer_cancel(exec_ctx, &glb_policy->lb_call_retry_timer);-    }-    if (!glb_policy->shutting_down) start_picking_locked(exec_ctx, glb_policy);-    glb_policy->updating_lb_call = false;-  } else if (!glb_policy->shutting_down) {-    /* if we aren't shutting down, restart the LB client call after some time */-    gpr_timespec now = gpr_now(GPR_CLOCK_MONOTONIC);-    gpr_timespec next_try =-        gpr_backoff_step(&glb_policy->lb_call_backoff_state, now);-    if (GRPC_TRACER_ON(grpc_lb_glb_trace)) {-      gpr_log(GPR_DEBUG, ""Connection to LB server lost (grpclb: %p)..."",-              (void *)glb_policy);-      gpr_timespec timeout = gpr_time_sub(next_try, now);-      if (gpr_time_cmp(timeout, gpr_time_0(timeout.clock_type)) > 0) {-        gpr_log(GPR_DEBUG,-                ""... retry_timer_active in %"" PRId64 "".%09d seconds."",-                timeout.tv_sec, timeout.tv_nsec);-      } else {-        gpr_log(GPR_DEBUG, ""... retry_timer_active immediately."");-      }-    }-    GRPC_LB_POLICY_WEAK_REF(&glb_policy->base, ""grpclb_retry_timer"");-    GRPC_CLOSURE_INIT(&glb_policy->lb_on_call_retry,-                      lb_call_on_retry_timer_locked, glb_policy,-                      grpc_combiner_scheduler(glb_policy->base.combiner));-    glb_policy->retry_timer_active = true;-    grpc_timer_init(exec_ctx, &glb_policy->lb_call_retry_timer, next_try,-                    &glb_policy->lb_on_call_retry, now);+  // If the load report timer is still pending, we wait for it to be+  // called before restarting the call.  Otherwise, we restart the call+  // here.+  if (!glb_policy->client_load_report_timer_pending) {","Are we ok with the extra delay this may introduce? Given that the report time is external input, a very high value -accidental or malicious- could result in delaying the retry arbitrarily long. ",
20803483,fengli79,https://api.github.com/repos/grpc/grpc/pulls/12374,141165588,2017-09-26T19:54:44Z,src/core/lib/security/credentials/plugin/plugin_credentials.c,"@@ -125,6 +140,7 @@ static bool plugin_get_request_metadata(grpc_exec_ctx *exec_ctx,                                         grpc_closure *on_request_metadata,                                         grpc_error **error) {   grpc_plugin_credentials *c = (grpc_plugin_credentials *)creds;",@markdroth Could you add traces to track the begin/end of the sync/async request? It helps to debug potential deadlock issues mentioned here: https://github.com/grpc/grpc/pull/11553#issuecomment-332245169,
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/12374,141249420,2017-09-27T05:53:16Z,include/grpc/grpc_security.h,"@@ -249,19 +249,40 @@ typedef struct {   void *reserved; } grpc_auth_metadata_context; +/** Maximum number of credentials returnable by a credentials plugin via",Maximum number of metadata as opposed to credentials.,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12651,141429992,2017-09-27T18:31:46Z,test/cpp/naming/gen_build_yaml.py,"@@ -33,21 +39,107 @@ def _build_expected_addrs_cmd_arg(expected_addrs):     out.append('%s,%s' % (addr['address'], str(addr['is_balancer'])))   return ';'.join(out) +def _data_for_type(r_type, r_data, common_zone_name):+  if r_type in ['A', 'AAAA']:+    return ' '.join(map(lambda x: '\""%s\""' % x, r_data))+  if r_type == 'SRV':+    assert len(r_data) == 1+    target = r_data[0].split(' ')[3]+    uploadable_target = '%s.%s' % (target, common_zone_name)+    uploadable = r_data[0].split(' ')+    uploadable[3] = uploadable_target+    return '\""%s\""' % ' '.join(uploadable)+  if r_type == 'TXT':","SG, I think that gcloud has an alternate mode of uploading records that involves pointing it to a zone file, rather than specifying each record via command line parameters. I might try changing this around to use such a JSON -> TXT script a part of creating a zone file.",
25518558,yongni,https://api.github.com/repos/grpc/grpc/pulls/12701,141483653,2017-09-27T22:23:32Z,tools/interop_matrix/README.md,"@@ -5,6 +5,21 @@ This directory contains scripts that facilitate building and running gRPC tests The setup builds gRPC docker images for each language/runtime and upload it to Google Container Registry (GCR). These images, encapsulating gRPC stack from specific releases/tag, are used to test version compatiblity between gRPC release versions. +## Step-by-step instructions for adding a new release to compatibility test+We have continuous nightly test setup to test gRPC backward compatibility between old clients and latest server.  When a Google developer creates a new gRPC release, s/he is also responsible to add the just-released gRPC client to the nightly test.  The steps are:","Understand.  GCR access needs permission, so it is technically googler-only.  Tuned down this part regardless.",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/12744,141493109,2017-09-27T23:28:20Z,src/core/lib/surface/call.c,"@@ -1467,7 +1444,6 @@ static void receiving_stream_ready(grpc_exec_ctx *exec_ctx, void *bctlp,       grpc_byte_stream_destroy(exec_ctx, call->receiving_stream);       call->receiving_stream = NULL;     }-    add_batch_error(exec_ctx, bctl, GRPC_ERROR_REF(error), true);",I think this is safe to remove.  The only places it is called from is ```receiving_stream_ready_in_call_combiner``` and ```receiving_initial_metadata_ready```.  In both cases we already call ```add_batch_error``` with this error.,
20803483,fengli79,https://api.github.com/repos/grpc/grpc/pulls/12374,141493385,2017-09-27T23:30:31Z,include/grpc/grpc_security.h,"@@ -249,19 +249,40 @@ typedef struct {   void *reserved; } grpc_auth_metadata_context; +/** Maximum number of credentials returnable by a credentials plugin via+    a synchronous return. */+#define GRPC_METADATA_CREDENTIALS_PLUGIN_SYNC_MAX 4",Can we make it configurable? Php need to get the callback always invoked on the same thread. Thus Php may use a larger threshold to make sure it's always sync.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12374,141655273,2017-09-28T15:39:38Z,include/grpc/grpc_security.h,"@@ -249,19 +249,40 @@ typedef struct {   void *reserved; } grpc_auth_metadata_context; +/** Maximum number of credentials returnable by a credentials plugin via+    a synchronous return. */+#define GRPC_METADATA_CREDENTIALS_PLUGIN_SYNC_MAX 4","No, we can't make it configurable.  For performance reasons, we need to allocate space for the return parameters on the stack instead of heap-allocating it, so the number has to be set at compile time.This limitation may go away in the future with some metadata API changes that @ctiller has in mind.  But for now, if PHP needs to have a plugin return more then 4 metadata elements, then it needs to use the async API.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12742,141751220,2017-09-28T22:25:50Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.c,"@@ -491,7 +495,6 @@ static void pf_connectivity_changed_locked(grpc_exec_ctx *exec_ctx, void *arg,   }   if (p->updating_subchannels && error != GRPC_ERROR_NONE) {     /* Captured the unsubscription for the checking subchannel */-    GPR_ASSERT(p->selected == NULL);","Thank you for asking about this -- in the process of writing an explanation of what's going on here, I realized that I had actually misunderstood the problem and that this PR is actually the wrong solution.  I'm going to close it and work on a different fix, but in the interim, here's the explanation, just for your knowledge.The way this code is currently written, we start off with a list of subchannels in `p->subchannels`, one for each address given to us by the resolver.  When we start picking, we attempt to connect to each subchannel in order until one of them succeeds.  Once we successfully connect to a subchannel, we save that subchannel in `p->selected` (line 570) and then delete the list (in `destroy_subchannels_locked()`), so `p->subchannels` becomes NULL and `p->num_subchannels` becomes 0.  Thus, it should generally be the case that if `p->selected` is non-NULL, then `p->num_subchannels` should be 0.At any given time, we will have exactly one connectivity state notification pending.  Initially, that notification is for the current entry in `p->subchannels` that we're trying to connect to (whose index is stored in `p->checking_subchannel`), which tells us whether or not we've managed to connect to that subchannel.  Once we select a subchannel, that notification is for `p->selected`, which lets us monitor the state of the subchannel to report back to the application.At shutdown time, we need to avoid deleting the LB policy until the connectivity state notification callback (`pf_connectivity_changed_locked()`) has been invoked, so the callback holds a ref to the LB policy.  In order to make this work, the semantics of the notification callback are such that, once requested, it will _always_ be invoked -- even if you cancel it, it will just get invoked immediately with an error, so that it can give up the reference to the LB policy in either case.  (If this weren't the case, there would be a race condition, because you could not be sure at the moment you cancel it that there is not already a callback in flight.)When an update comes in (handled by `pf_update_locked()`), we need to cancel the pending connectivity state notification for the old subchannel before we can start a notification for a new subchannel, and we can't unref the old subchannel before the connectivity callback returns.  So we want the code in `pf_connectivity_changed_locked()` to be able to differentiate between a ""real"" error and a case where it's only getting an error because the notification was cancelled due to an update.To do this, we stash the update in `p->num_new_subchannels` and `p->new_subchannels`, and then set either `p->updating_selected` or `p->updating_subchannels` (depending on whether we have already selected a subchannel) before we cancel the notification.  Then, when the callback is invoked, it checks whether `p->updating_selected` or `p->updating_subchannels` is set to see whether it should interpret the notification as an update.  If so, it unrefs the old subchannel and moves `p->new_num_subchannels` and `p->new_subchannels` to `p->num_subchannels` and `p->subchannels`, which puts us back into our initial state: we now have a list of subchannels that we need to start connecting to in order, so that we can select the first one that we successfully connect to.So, all of the above explains how this code is supposed to work.  The problem that I _thought_ I was seeing here was that there was a race condition when the LB policy was shut down while an update was in flight, and I thought that the assertion was wrong for that case.  However, looking more closely at the code and the trace output of the failing test, I see that that's not actually the problem.I'll send you a different PR once I figure out the right fix.",
28968539,ZhouyihaiDing,https://api.github.com/repos/grpc/grpc/pulls/12760,141766142,2017-09-29T00:21:06Z,src/ruby/qps/proxy-worker.rb,"@@ -87,18 +87,24 @@ def cpu_cores   # status return value.   def run_client(reqs)     q = EnumeratorQueue.new(self)+    mark_ind = 0     Thread.new {       reqs.each do |req|         case req.argtype.to_s         when 'setup'           @bmc.setup(req.setup)           q.push(Grpc::Testing::ClientStatus.new(stats: @bmc.mark(false)))         when 'mark'+          # There are 3 marks: the first is for initiating the hist;+          # The second is for warm-up; The last is for the benchmark.","Thanks for the correction. Then I also can't assume that only the last mark is always for the benchmark. If there is a middle ""mark"" used for the benchmark, uploading the data still consumes time for the next mark, which lower the qps. I didn't see where I can pause the drive, letting ruby finish uploading before start next ""mark"".I guess I can continue the signal way to let php know when ""mark"" is called. But instead of uploading all latencies, I should implement histogram in the php side and upload it once before each mark. \Do you have some suggestions to let php knows when to upload other than using signal? The response from the server seems useless because it remains the same until it is closed.n the benchmark framework I ",
28968539,ZhouyihaiDing,https://api.github.com/repos/grpc/grpc/pulls/12760,141768399,2017-09-29T00:43:52Z,src/ruby/qps/proxy-worker.rb,"@@ -87,18 +87,24 @@ def cpu_cores   # status return value.   def run_client(reqs)     q = EnumeratorQueue.new(self)+    mark_ind = 0     Thread.new {       reqs.each do |req|         case req.argtype.to_s         when 'setup'           @bmc.setup(req.setup)           q.push(Grpc::Testing::ClientStatus.new(stats: @bmc.mark(false)))         when 'mark'+          # There are 3 marks: the first is for initiating the hist;+          # The second is for warm-up; The last is for the benchmark.","Is that right that ""reqs.each do |req|"" works as while (1){    in = stream.recv(); // the program will hang there for warm-up time, lots of benchmark time.    case in.isSetup:    case in.inMark: get data from php, upload histogram to the driver.}Thus in the in.inMark, streamming upload will always be expensive and it cost time from the next ""mark"". What I'm doing now is to make the split latency sent together, which may speed up cache or buffer re-use or something. But the best way is just uploading once, right?",
28968539,ZhouyihaiDing,https://api.github.com/repos/grpc/grpc/pulls/12760,141907986,2017-09-29T16:14:01Z,src/ruby/qps/proxy-worker.rb,"@@ -87,18 +87,24 @@ def cpu_cores   # status return value.   def run_client(reqs)     q = EnumeratorQueue.new(self)+    mark_ind = 0     Thread.new {       reqs.each do |req|         case req.argtype.to_s         when 'setup'           @bmc.setup(req.setup)           q.push(Grpc::Testing::ClientStatus.new(stats: @bmc.mark(false)))         when 'mark'+          # There are 3 marks: the first is for initiating the hist;+          # The second is for warm-up; The last is for the benchmark.",That sounds cool by using a bidi-streaming. I'll try use async way or fork a child process listening to this bidi-streaming RPC in sync way. Thanks for your help!I'll close this PR and reopen it until I finish them.,
28968539,ZhouyihaiDing,https://api.github.com/repos/grpc/grpc/pulls/12760,141984253,2017-09-29T22:58:30Z,src/ruby/qps/proxy-worker.rb,"@@ -87,18 +87,24 @@ def cpu_cores   # status return value.   def run_client(reqs)     q = EnumeratorQueue.new(self)+    mark_ind = 0     Thread.new {       reqs.each do |req|         case req.argtype.to_s         when 'setup'           @bmc.setup(req.setup)           q.push(Grpc::Testing::ClientStatus.new(stats: @bmc.mark(false)))         when 'mark'+          # There are 3 marks: the first is for initiating the hist;+          # The second is for warm-up; The last is for the benchmark.","I'm still using signal to let them talk to each other. I tried create a child process and let a streaming RPC listening there. But it seems php-gRPC doesn't work on child process(the same code works in the parent, will hang in the child). I don't know it's php's problem or php-gRPC's problem yet.Currently every mark will trigger php uploading, and continue until the data is uploaded. I'll implement histogram in the php side next.",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/12613,141991058,2017-09-30T00:18:30Z,src/csharp/Grpc.Core.Tests/Interceptors/ClientInterceptorTest.cs,"@@ -0,0 +1,76 @@+#region Copyright notice and license++// Copyright 2017 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Generic;+using System.Linq;+using System.Threading;+using System.Threading.Tasks;+using Grpc.Core;+using Grpc.Core.Interceptors;+using Grpc.Core.Internal;+using Grpc.Core.Utils;+using Grpc.Core.Tests;+using NUnit.Framework;++namespace Grpc.Core.Interceptors.Tests+{+    public class ClientInterceptorTest+    {+        private class AddHeaderClientInterceptor : ClientInterceptor+        {+            readonly Metadata.Entry header;+            public AddHeaderClientInterceptor(string key, string value)+            {+                this.header = new Metadata.Entry(key, value);+            }+            public override TResponse BlockingUnaryCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request, Func<Method<TRequest, TResponse>, string, CallOptions, TRequest, TResponse> next)+            {+                options.Headers.Add(this.header);+                return next(method, host, options, request);+            }++            public Metadata.Entry Header+            {+                get+                {+                    return this.header;+                }+            }+        }++        const string Host = ""127.0.0.1"";++        [Test]+        public void AddRequestHeaderInClientInterceptor()+        {+            var helper = new MockServiceHelper(Host);+            var interceptor = new AddHeaderClientInterceptor(""x-client-interceptor"", ""hello world"");+            helper.UnaryHandler = new UnaryServerMethod<string, string>((request, context) =>+            {+                var interceptorHeader = context.RequestHeaders.Last(m => (m.Key == interceptor.Header.Key)).Value;+                Assert.AreEqual(interceptorHeader, interceptor.Header.Value);+                return Task.FromResult(""PASS"");+            });+            var server = helper.GetServer();+            server.Start();+            var callInvoker = helper.GetChannel().Intercept(interceptor);","I think FIFO does not make sense when chaining calls like `.Intercept(a).Intercept(b)`, because you can imagine a scenario in which you are given a `CallInvoker` by another part of your program that is created with `channel.Intercept` and you then decide to intercept it again and see the whole thing as a black box.However, I do agree that an overload that takes multiple interceptors in a single call: `.Intercept(a, b, c)` should pass control to `a`, `b`, and `c` in that order.",
17011,jskeet,https://api.github.com/repos/grpc/grpc/pulls/12613,142069855,2017-10-02T07:33:34Z,src/csharp/Grpc.Core/CallOptions.cs,"@@ -36,6 +37,7 @@ public struct CallOptions         ContextPropagationToken propagationToken;         CallCredentials credentials;         CallFlags flags;+        Dictionary<object, object> items;","I'm concerned that this already-large struct is becoming huge. The threading is also a concern... `Dictionary<,>` isn't thread-safe - what are the expected uses here, and are we satisfied they won't cause problems?",
17011,jskeet,https://api.github.com/repos/grpc/grpc/pulls/12613,142070737,2017-10-02T07:40:23Z,src/csharp/Grpc.Core/Interceptors/ClientInterceptor.cs,"@@ -0,0 +1,281 @@+#region Copyright notice and license++// Copyright 2017 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Threading.Tasks;+using Grpc.Core.Utils;++namespace Grpc.Core.Interceptors+{+    /// <summary>+    /// Serves as the base class for gRPC client interceptors.+    /// This is an EXPERIMENTAL API.+    /// </summary>+    public abstract class ClientInterceptor+    {+        /// <summary>+        /// Intercepts a blocking invocation of a simple remote call.+        /// </summary>+        public virtual TResponse BlockingUnaryCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request, Func<Method<TRequest, TResponse>, string, CallOptions, TRequest, TResponse> next)+            where TRequest : class+            where TResponse : class+        {+            return next(method, host, options, request);+        }++        /// <summary>+        /// Intercepts an asynchronous invocation of a simple remote call.+        /// </summary>+        public virtual AsyncUnaryCall<TResponse> AsyncUnaryCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request, Func<Method<TRequest, TResponse>, string, CallOptions, TRequest, AsyncUnaryCall<TResponse>> next)+            where TRequest : class+            where TResponse : class+        {+            return next(method, host, options, request);+        }++        /// <summary>+        /// Intercepts an asynchronous invocation of a streaming remote call.+        /// </summary>+        public virtual AsyncServerStreamingCall<TResponse> AsyncServerStreamingCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request, Func<Method<TRequest, TResponse>, string, CallOptions, TRequest, AsyncServerStreamingCall<TResponse>> next)+            where TRequest : class+            where TResponse : class+        {+            return next(method, host, options, request);+        }++        /// <summary>+        /// Intercepts an asynchronous invocation of a client streaming call.+        /// </summary>+        public virtual AsyncClientStreamingCall<TRequest, TResponse> AsyncClientStreamingCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, Func<Method<TRequest, TResponse>, string, CallOptions, AsyncClientStreamingCall<TRequest, TResponse>> next)+            where TRequest : class+            where TResponse : class+        {+            return next(method, host, options);+        }++        /// <summary>+        /// Intercepts an asynchronous invocation of a duplex streaming call.+        /// </summary>+        public virtual AsyncDuplexStreamingCall<TRequest, TResponse> AsyncDuplexStreamingCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, Func<Method<TRequest, TResponse>, string, CallOptions, AsyncDuplexStreamingCall<TRequest, TResponse>> next)+            where TRequest : class+            where TResponse : class+        {+            return next(method, host, options);+        }++        /// <summary>+        /// Returns a new instance of <c>AsyncUnaryCall</c> that has hooks to intercept on an underlying object of the same type.+        /// </summary>+        protected static AsyncUnaryCall<TResponse> Intercept<TRequest, TResponse>(AsyncUnaryCall<TResponse> call,+            Func<Task<TResponse>, TResponse> response = null,+            Func<Task<Metadata>, Metadata> responseHeaders = null,+            Func<Func<Status>, Func<Status>> getStatus = null,+            Func<Func<Metadata>, Func<Metadata>> getTrailers = null,+            Func<Action, Action> dispose = null)+        {+            GrpcPreconditions.CheckNotNull(call, ""call"");+            var callResponse = call.ResponseAsync;+            Task<Metadata> callResponseHeaders = call.ResponseHeadersAsync;+            Func<Status> callStatus = call.GetStatus;+            Func<Metadata> callTrailers = call.GetTrailers;+            Action callDispose = call.Dispose;++            if (callResponse != null)+            {+                var responseOriginal = callResponse;+                callResponse = new Task<TResponse>(() => response(responseOriginal));+            }++            if (responseHeaders != null)+            {+                var callResponseHeadersOriginal = callResponseHeaders; // Ensure it will not be captured by the closure+                callResponseHeaders = new Task<Metadata>(() => responseHeaders(callResponseHeadersOriginal));+            }++            if (getStatus != null)+            {+                callStatus = getStatus(callStatus);+            }++            if (getTrailers != null)+            {+                callTrailers = getTrailers(callTrailers);+            }++            if (dispose != null)+            {+                callDispose = dispose(callDispose);+            }++            return new AsyncUnaryCall<TResponse>(callResponse, callResponseHeaders, callStatus, callTrailers, callDispose);+        }++        /// <summary>+        /// Returns a new instance of <c>AsyncServerStreamingCall</c> that has hooks to intercept on an underlying object of the same type.+        /// </summary>+        protected static AsyncServerStreamingCall<TResponse> Intercept<TRequest, TResponse>(AsyncServerStreamingCall<TResponse> call,",I'd quite like a way of creating an interceptor to just modify/inspect one aspect (e.g. metadata) of all calls - `Interceptor.ForMetadata(metadata => { ...})`,
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/12613,142084839,2017-10-02T08:51:00Z,src/csharp/Grpc.Core/Interceptors/ServerInterceptor.cs,"@@ -0,0 +1,150 @@+#region Copyright notice and license++// Copyright 2017 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Reflection;+using System.Threading.Tasks;+using Grpc.Core.Internal;++namespace Grpc.Core.Interceptors+{+    /// <summary>+    /// Serves as the base class for gRPC server interceptors.+    /// This is an EXPERIMENTAL API.+    /// </summary>+    public abstract class ServerInterceptor+    {+        /// <summary>+        /// Server-side handler for intercepting unary calls.+        /// </summary>+        /// <typeparam name=""TRequest"">Request message type for this method.</typeparam>+        /// <typeparam name=""TResponse"">Response message type for this method.</typeparam>+        public virtual async Task<TResponse> UnaryServerHandler<TRequest, TResponse>(TRequest request, ServerCallContext context, UnaryServerMethod<TRequest, TResponse> next)+            where TRequest : class+            where TResponse : class+        {+            return await next(request, context).ConfigureAwait(false);+        }++        /// <summary>+        /// Server-side handler for intercepting client streaming call.+        /// </summary>+        /// <typeparam name=""TRequest"">Request message type for this method.</typeparam>+        /// <typeparam name=""TResponse"">Response message type for this method.</typeparam>+        public virtual async Task<TResponse> ClientStreamingServerHandler<TRequest, TResponse>(IAsyncStreamReader<TRequest> requestStream, ServerCallContext context, ClientStreamingServerMethod<TRequest, TResponse> next)+            where TRequest : class+            where TResponse : class+        {+            return await next(requestStream, context).ConfigureAwait(false);+        }++        /// <summary>+        /// Server-side handler for intercepting server streaming calls.+        /// </summary>+        /// <typeparam name=""TRequest"">Request message type for this method.</typeparam>+        /// <typeparam name=""TResponse"">Response message type for this method.</typeparam>+        public virtual async Task ServerStreamingServerHandler<TRequest, TResponse>(TRequest request, IServerStreamWriter<TResponse> responseStream, ServerCallContext context, ServerStreamingServerMethod<TRequest, TResponse> next)+            where TRequest : class+            where TResponse : class+        {+            await next(request, responseStream, context).ConfigureAwait(false);+        }++        /// <summary>+        /// Server-side handler for intercepting bidi streaming calls.+        /// </summary>+        /// <typeparam name=""TRequest"">Request message type for this method.</typeparam>+        /// <typeparam name=""TResponse"">Response message type for this method.</typeparam>+        public virtual async Task DuplexStreamingServerHandler<TRequest, TResponse>(IAsyncStreamReader<TRequest> requestStream, IServerStreamWriter<TResponse> responseStream, ServerCallContext context, DuplexStreamingServerMethod<TRequest, TResponse> next)+            where TRequest : class+            where TResponse : class+        {+            await next(requestStream, responseStream, context).ConfigureAwait(false);+        }++        private static class WrapUtil<TRequest, TResponse>+            where TRequest : class+            where TResponse : class+        {+            public static UnaryServerMethod<TRequest, TResponse> Unary(UnaryServerMethod<TRequest, TResponse> handler, ServerInterceptor interceptor)+            {+                return async (request, context) => await interceptor.UnaryServerHandler<TRequest, TResponse>(request, context, handler).ConfigureAwait(false);+            }++            public static ClientStreamingServerMethod<TRequest, TResponse> ClientStreaming(ClientStreamingServerMethod<TRequest, TResponse> handler, ServerInterceptor interceptor)+            {+                return async (request, context) => await interceptor.ClientStreamingServerHandler<TRequest, TResponse>(request, context, handler).ConfigureAwait(false);+            }++            public static ServerStreamingServerMethod<TRequest, TResponse> ServerStreaming(ServerStreamingServerMethod<TRequest, TResponse> handler, ServerInterceptor interceptor)+            {+                return async (request, response, context) => await interceptor.ServerStreamingServerHandler<TRequest, TResponse>(request, response, context, handler).ConfigureAwait(false);+            }++            public static DuplexStreamingServerMethod<TRequest, TResponse> DuplexStreaming(DuplexStreamingServerMethod<TRequest, TResponse> handler, ServerInterceptor interceptor)+            {+                return async (request, response, context) => await interceptor.DuplexStreamingServerHandler<TRequest, TResponse>(request, response, context, handler).ConfigureAwait(false);+            }+        }++        private Delegate WrapDelegate(Delegate d)","This process only happens at the startup time of the service once, so I don't think the potential performance impact matters. Unfortunately, I don't know of any other way to avoid this dance, since `dynamic` or using C# binder to find the appropriate overload require depending on additional libraries. We need this to map a non-generic object back to the correct parameterized-type overload. If you have a better way to accomplish this in mind, definitely let me know please.",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/12613,142087138,2017-10-02T09:02:17Z,src/csharp/Grpc.Core/CallOptions.cs,"@@ -36,6 +37,7 @@ public struct CallOptions         ContextPropagationToken propagationToken;         CallCredentials credentials;         CallFlags flags;+        Dictionary<object, object> items;","@jskeet The use-case is to share some call-specific data between the interceptors and potentially the call invoker. (The closest .NET analogy I have in mind is `HttpContext.Context`.) I initially thought Metadata headers should be abused for this purpose, but it can be too inconvenient. For example, one use case is associating a `User` object (or any other state information) via an interceptor that can then be pulled and injected into the RPC.  Another design I contemplated with is replacing the dictionary with a single `object Tag`, however, from a struct size point of view, it has the same effect. It will alleviate the threading concerns though, perhaps at a cost to usability.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12742,142266104,2017-10-02T21:55:10Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.c,"@@ -491,7 +495,6 @@ static void pf_connectivity_changed_locked(grpc_exec_ctx *exec_ctx, void *arg,   }   if (p->updating_subchannels && error != GRPC_ERROR_NONE) {     /* Captured the unsubscription for the checking subchannel */-    GPR_ASSERT(p->selected == NULL);","Thanks for detailing this logic.I have some questions about the race condition when we cancel the notification callback. If we didn't invoke the notification callback with an error to cancel it, how would we cancel it? What will happen if we cancel it in that alternative way when there is already a callback in flight? ",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/12802,142446999,2017-10-03T16:05:48Z,test/cpp/microbenchmarks/bm_chttp2_hpack.cc,"@@ -545,30 +603,51 @@ class NonIndexedBinaryElem<100, false> { class RepresentativeClientInitialMetadata {  public:   static std::vector<grpc_slice> GetInitSlices() {-    return {grpc_slice_from_static_string(-        // generated with:-        // ```-        // tools/codegen/core/gen_header_frame.py --compression inc --no_framing-        // < test/core/bad_client/tests/simple_request.headers-        // ```-        ""@\x05:path\x08/foo/bar""-        ""@\x07:scheme\x04http""-        ""@\x07:method\x04POST""-        ""@\x0a:authority\x09localhost""-        ""@\x0c""-        ""content-type\x10""-        ""application/grpc""-        ""@\x14grpc-accept-encoding\x15identity,deflate,gzip""-        ""@\x02te\x08trailers""-        ""@\x0auser-agent\""bad-client grpc-c/0.12.0.0 (linux)"")};+    return {MakeSlice(","Can we retain the existing thing also, and add a new case (RepresentativeClientInitialMetadata2... or some better name)",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12742,142452105,2017-10-03T16:25:33Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.c,"@@ -491,7 +495,6 @@ static void pf_connectivity_changed_locked(grpc_exec_ctx *exec_ctx, void *arg,   }   if (p->updating_subchannels && error != GRPC_ERROR_NONE) {     /* Captured the unsubscription for the checking subchannel */-    GPR_ASSERT(p->selected == NULL);","In C-core, whenever a callback is invoked, there will usually be a window between when the closure is scheduled and when it is actually run.  Note that this can happen in several different ways, depending on which closure scheduler is being used.  For example, with the exec_ctx scheduler, the closure may have been added to the list in the exec_ctx to be executed before gRPC returns control of the thread to the application, but since we are still inside of the gRPC call stack, we have not yet run the closures that were added to the exec_ctx.  Another example is the combiner scheduler, where the closure may have been scheduled on the combiner, but some other thread is currently holding the combiner, so it hasn't been run yet.Most callbacks hold resources (e.g., refs to some object or allocated memory) that they need to remain alive until after they run.  If we free resources needed by a callback before the callback runs, bad things happen (e.g., crashes or memory corruption).  So the core problem here is that we need to know when we can safely free those resources.If canceling an async operation did not cause its callback to be invoked, then we would need to free the resources held by the callback immediately upon canceling it, on the assumption that the callback would not ever run.  However, we have no way of knowing at the moment we cancel the operation whether the callback is already pending.  And if it is already pending, then this would result in freeing the resources before the callback runs, which is what we need to avoid here.Our usual design pattern for solving this problem is to have async operations provide a guarantee that their callback will always be invoked exactly once, regardless of success or failure, so that the callback can free the resources either way.  When we cancel an async operation, there are two cases:- If the async operation's callback has not yet been scheduled, we schedule it immediately with an error to indicate the cancellation.- If the async operation's callback has already been scheduled (with no error), the cancellation is a no-op, because the result has already been sent.Note that in the second case, it's the responsibility of the calling code to know that the operation was cancelled even if the callback is invoked without an error.  Our usual pattern for this is to have the calling code maintain its own `bool shutdown` variable, which it sets to true when cancelling the async operation.  Then, when the callback runs, it knows that there was a problem if either (a) the callback was invoked with an error or (b) the shutdown variable was set to true.Please let me know if you have any questions about any of this.",
28968539,ZhouyihaiDing,https://api.github.com/repos/grpc/grpc/pulls/12760,142547039,2017-10-03T23:06:38Z,src/ruby/qps/proxy-worker.rb,"@@ -41,32 +41,54 @@ def setup(config)     @histmax = config.histogram_params.max_possible     @histogram = Histogram.new(@histres, @histmax)     @start_time = Time.now-    # TODO(vjpai): Support multiple client channels by spawning off a PHP client per channel-    if @use_c_ext-      puts ""Use protobuf c extension""-      command = ""php -d extension="" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/tests/qps/vendor/google/protobuf/php/ext/google/protobuf/modules/protobuf.so "" + ""-d extension="" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/ext/grpc/modules/grpc.so "" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/tests/qps/client.php "" + @mytarget-    else-      puts ""Use protobuf php extension""-      command = ""php -d extension="" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/ext/grpc/modules/grpc.so "" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/tests/qps/client.php "" + @mytarget-    end	-    puts ""Starting command: "" + command-    @php_pid = spawn(command)+    @php_pid = Array.new(@config.client_channels)+    (0..@config.client_channels-1).each do |chan|+      Thread.new {+        if @use_c_ext+          puts ""Use protobuf c extension""+          command = ""php -d extension="" + File.expand_path(File.dirname(__FILE__)) ++            ""/../../php/tests/qps/vendor/google/protobuf/php/ext/google/protobuf/modules/protobuf.so "" ++            ""-d extension="" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/ext/grpc/modules/grpc.so "" ++            File.expand_path(File.dirname(__FILE__)) + ""/../../php/tests/qps/client.php "" + @mytarget + "" #{chan%@config.server_targets.length}""+        else+          puts ""Use protobuf php extension""+          command = ""php -d extension="" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/ext/grpc/modules/grpc.so "" ++            File.expand_path(File.dirname(__FILE__)) + ""/../../php/tests/qps/client.php "" + @mytarget + "" #{chan%@config.server_targets.length}""+        end+        puts ""[ruby proxy] Starting #{chan}th php-client command use c protobuf #{@use_c_ext}: "" + command+        @php_pid[chan] = spawn(command)+        while true+          sleep+        end+      }+    end   end   def stop-    Process.kill(""TERM"", @php_pid)-    Process.wait(@php_pid)+    (0..@config.client_channels-1).each do |chan|+      Process.kill(""TERM"", @php_pid[chan])+      Process.wait(@php_pid[chan])+    end   end   def get_config(_args, _call)-    puts ""Answering get_config""     @config   end   def report_time(call)-    puts ""Starting a time reporting stream""     call.each_remote_read do |lat|       @histogram.add((lat.latency)*1e9)     end     Grpc::Testing::Void.new   end+  def report_hist(call)",Just come in mind. I am investigating multiple php client call it will cause race condition for `@histogram` or not.,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12760,142619128,2017-10-04T09:14:11Z,tools/run_tests/run_tests.py,"@@ -1132,6 +1132,8 @@ def __str__(self):     'node': NodeLanguage(),     'node_express': NodeExpressLanguage(),     'php': PhpLanguage(),+    'php_protobuf_php': PhpLanguage(),","I just realized this is in run_tests.py.1. I think there should be better ways around this than adding 2 more languages as a ""hack"".2. It sounds like 'php_protobuf_php'  is the same thing as 'php' (as php protobuf is the default).3. If you have a run_tests.py language 'php_protobuf_c', it should really build php with protobuf C extension, but the definition for php_protobuf_php and php_protobuf_c seem identical - which is pretty confusing and possibly wrong.I don't understand why adding the ""virtual"" languages to run_tests.py actually prevents a conflict in https://github.com/grpc/grpc/blob/master/tools/run_tests/performance/run_worker_php.sh(btw, I also noticed you are running some steps that should belong to build_performance.sh as part of ""run worker"" script, which doesn't seem correct -   phpize, composer install, make, configure are clearly build steps).Also, php_protobuf_php is the ""default"" setting, so you should only have ",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12822,142712539,2017-10-04T15:52:23Z,src/csharp/Grpc.Core/Internal/ClientResponseStream.cs,"@@ -49,19 +49,19 @@ public TResponse Current          public async Task<bool> MoveNext(CancellationToken token)         {-            if (token != CancellationToken.None)+            var cancellationTokenRegistration = token.CanBeCanceled ? token.Register(() => call.Cancel()) : (IDisposable) null;+            using (cancellationTokenRegistration)","There might be a timing dependent issue here:- I need to unregister the cancellation token registration at some point and doing that once the read has finish seems to make sense- the user expects the entire call to get cancelled whenever once he cancels the cancellation token, but there's effectively a race condition between the read finishing (and call.Cancel() invocation get unregistered) and user requesting the cancellation.We actually might need to keep the cancellationTokenRegistration around until the call finishes (which is unfortunate, because there can possibly be lots of registrations per call).",
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/10155,142805559,2017-10-04T22:06:36Z,src/core/lib/iomgr/fork_posix.c,"@@ -0,0 +1,75 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/core/lib/iomgr/port.h""++#ifdef GRPC_POSIX_FORK++#include <string.h>++#include <grpc/fork.h>+#include <grpc/support/log.h>+#include <grpc/support/thd.h>+#include <grpc/support/useful.h>++#include ""src/core/lib/iomgr/ev_posix.h""+#include ""src/core/lib/iomgr/executor.h""+#include ""src/core/lib/iomgr/timer_manager.h""+#include ""src/core/lib/iomgr/wakeup_fd_posix.h""+#include ""src/core/lib/support/env.h""+#include ""src/core/lib/support/fork.h""+#include ""src/core/lib/support/thd_internal.h""++int grpc_prefork() {",Some comments would help on what functions in this file are doing in general... (Right now timer manager and executor are the only two components that create threads. That part wouldn't be obvious for someone new reviewing the code in future),
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/10155,142806373,2017-10-04T22:11:15Z,src/core/lib/iomgr/wakeup_fd_posix.c,"@@ -76,11 +92,63 @@ grpc_error *grpc_wakeup_fd_wakeup(grpc_wakeup_fd *fd_info) { }  void grpc_wakeup_fd_destroy(grpc_wakeup_fd *fd_info) {+  global_fork_fd_list_remove(fd_info);   if (cv_wakeup_fds_enabled) {     grpc_cv_wakeup_fd_vtable.destroy(fd_info);   } else {     wakeup_fd_vtable->destroy(fd_info);   } } +/**********************************************************+ * Forking support",A more verbose comments will help here.  Something like you maintain a global list of wakeup fds so that you can call `grpc_wakeup_fds_postfork()` (i.e re-initialize all fds in the child process after fork),
28968539,ZhouyihaiDing,https://api.github.com/repos/grpc/grpc/pulls/12760,142807138,2017-10-04T22:15:09Z,tools/run_tests/run_tests.py,"@@ -1132,6 +1132,8 @@ def __str__(self):     'node': NodeLanguage(),     'node_express': NodeExpressLanguage(),     'php': PhpLanguage(),+    'php_protobuf_php': PhpLanguage(),","For the ""run worker"" script, ""composer install"" installs the library only used in qps test ""client.php"", and it actually installs tons of things (clone the whole repo of protobuf and grpc), which is unnecessary if no one runs ""run_worker"". Thus I put it in this file.Also ""phpize, make"" is cd to the protobuf repo downloaded by ""composer install"" and compile a protobuf.so c-extension, which is only needed by the qps test.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12680,142896695,2017-10-05T10:02:16Z,tools/run_tests/run_tests.py,"@@ -1570,7 +1570,12 @@ def _build_and_run(     for antagonist in antagonists:       antagonist.kill()     if args.bq_result_table and resultset:-      upload_results_to_bq(resultset, args.bq_result_table, args, platform_string())+      # There are transient errors with uploading to BQ from Kokoro and they+      # should not cause the build to fail.+      try:+        upload_results_to_bq(resultset, args.bq_result_table, args, platform_string())","I'm not sure this is a good idea.  If failure to upload is silent, we will not be aware of any problems with uploading the test results if it suddenly stops working (and we will have limited flakiness data from master and limited data from PRs).This is even a bit worse, because for successful test suite, run_tests_matrix.py eats all the output, so there will never be any useful output in the logs to check if the results were uploaded properly.Can we 1. try to figure out why results fail to be uploaded (it says deadline exceeded, so perhaps we can just increase the timeout for the upload)  2. retry the upload ",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12827,142900783,2017-10-05T10:23:26Z,tools/run_tests/run_interop_tests.py,"@@ -1205,6 +1215,13 @@ def aggregate_http2_results(stdout):   num_failures, resultset = jobset.run(jobs, newline_on_success=True,                                        maxjobs=args.jobs,                                        skip_jobs=args.manual_run)+  if args.bq_result_table and resultset:+    # Transient errors in uploading results to BQ should not cause the build to fail+    try:+      upload_results_to_bq(resultset, args.bq_result_table, args, jobset.platform_string())+    except Exception as e:","same issue as the other PR - except in this case we will at least see the logs if uploading to bigquery fails. Regardless what we do, we should stay consistent with what run_tests.py does.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12760,142914213,2017-10-05T11:40:07Z,tools/run_tests/run_tests.py,"@@ -1132,6 +1132,8 @@ def __str__(self):     'node': NodeLanguage(),     'node_express': NodeExpressLanguage(),     'php': PhpLanguage(),+    'php_protobuf_php': PhpLanguage(),","So there's 3 stages:1. php built by run_tests.py -l php --build_only  (here I agree you don't need to build qps test stuff - even though some languages actually do so)2. php qps worker built by build_performance.sh script - this is where you should build everything that's required for running php qps tests (all other languages do so).3. run_php_workers.sh  - this should really contain just commands to run an already-built php qps worker. If you include build steps here, building runs a part of qps worker invocation so there's going to be a delay (possibly a long one) before the qps worker is started - right now the qps_driver happens to work (because unlimited retries) with such delay, but it's more of a coincidence rather than something we are doing consciously.Please look athttps://github.com/grpc/grpc/blob/master/tools/run_tests/performance/build_performance.sh#L44Idea:you can actually provide case statement for both ""php"" and ""php_protobuf_c"" here and easily run the right build commands. That would save you from doing all the ""magic"" in run_performance_tests.py  (unifying php and php_with_argv etc.).",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12680,142940945,2017-10-05T13:44:33Z,tools/internal_ci/helper_scripts/prepare_build_macos_rc,"@@ -27,6 +27,12 @@ ulimit -n 10000 # show current limits ulimit -a +# Sync time because sometimes time on VM is unsynchronized",I actually just merged similar change https://github.com/grpc/grpc/pull/12784,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12822,142958154,2017-10-05T14:41:33Z,src/csharp/Grpc.Core.Tests/CallCancellationTest.cs,"@@ -0,0 +1,182 @@+#region Copyright notice and license++// Copyright 2015 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Generic;+using System.Diagnostics;+using System.Linq;+using System.Threading;+using System.Threading.Tasks;+using Grpc.Core;+using Grpc.Core.Internal;+using Grpc.Core.Profiling;+using Grpc.Core.Utils;+using NUnit.Framework;++namespace Grpc.Core.Tests+{+    public class CallCancellationTest+    {+        const string Host = ""127.0.0.1"";++        MockServiceHelper helper;+        Server server;+        Channel channel;++        [SetUp]+        public void Init()+        {+            helper = new MockServiceHelper(Host);+            server = helper.GetServer();+            server.Start();+            channel = helper.GetChannel();+        }++        [TearDown]+        public void Cleanup()+        {+            channel.ShutdownAsync().Wait();+            server.ShutdownAsync().Wait();+        }++        [Test]+        public async Task ClientStreamingCall_CancelAfterBegin()+        {+            var barrier = new TaskCompletionSource<object>();++            helper.ClientStreamingHandler = new ClientStreamingServerMethod<string, string>(async (requestStream, context) =>+            {+                barrier.SetResult(null);+                await requestStream.ToListAsync();+                return """";+            });++            var cts = new CancellationTokenSource();+            var call = Calls.AsyncClientStreamingCall(helper.CreateClientStreamingCall(new CallOptions(cancellationToken: cts.Token)));++            await barrier.Task;  // make sure the handler has started.+            cts.Cancel();++            try+            {+                // cannot use Assert.ThrowsAsync because it uses Task.Wait and would deadlock.+                await call.ResponseAsync;+                Assert.Fail();+            }+            catch (RpcException ex)+            {+                Assert.AreEqual(StatusCode.Cancelled, ex.Status.StatusCode);+            }+        }++        [Test]+        public async Task ClientStreamingCall_ServerSideReadAfterCancelNotificationReturnsNull()+        {+            var handlerStartedBarrier = new TaskCompletionSource<object>();+            var cancelNotificationReceivedBarrier = new TaskCompletionSource<object>();+            var successTcs = new TaskCompletionSource<string>();++            helper.ClientStreamingHandler = new ClientStreamingServerMethod<string, string>(async (requestStream, context) =>+            {+                handlerStartedBarrier.SetResult(null);++                // wait for cancellation to be delivered.+                context.CancellationToken.Register(() => cancelNotificationReceivedBarrier.SetResult(null));+                await cancelNotificationReceivedBarrier.Task;++                var moveNextResult = await requestStream.MoveNext();+                successTcs.SetResult(!moveNextResult ? ""SUCCESS"" : ""FAIL"");+                return """";+            });++            var cts = new CancellationTokenSource();+            var call = Calls.AsyncClientStreamingCall(helper.CreateClientStreamingCall(new CallOptions(cancellationToken: cts.Token)));++            await handlerStartedBarrier.Task;+            cts.Cancel();++            try+            {+                await call.ResponseAsync;+                Assert.Fail();+            }+            catch (RpcException ex)+            {+                Assert.AreEqual(StatusCode.Cancelled, ex.Status.StatusCode);+            }+            Assert.AreEqual(""SUCCESS"", await successTcs.Task);+        }++        [Test]+        public async Task ClientStreamingCall_CancelServerSideRead()+        {+            helper.ClientStreamingHandler = new ClientStreamingServerMethod<string, string>(async (requestStream, context) =>+            {+                var cts = new CancellationTokenSource();+                var moveNextTask = requestStream.MoveNext(cts.Token);+                await Task.Delay(100);+                cts.Cancel();+                await moveNextTask;+                return """";+            });++            var call = Calls.AsyncClientStreamingCall(helper.CreateClientStreamingCall());+            try+            {+                // cannot use Assert.ThrowsAsync because it uses Task.Wait and would deadlock.+                await call.ResponseAsync;+                Assert.Fail();+            }+            catch (RpcException ex)+            {+                Assert.AreEqual(StatusCode.Cancelled, ex.Status.StatusCode);+            }+        }++        [Test]+        public async Task ServerStreamingCall_CancelClientSideRead()+        {+            helper.ServerStreamingHandler = new ServerStreamingServerMethod<string, string>(async (request, responseStream, context) =>+            {+                await responseStream.WriteAsync(""abc"");+                await Task.Delay(10000);+                await responseStream.WriteAsync(""def"");+            });++            var call = Calls.AsyncServerStreamingCall(helper.CreateServerStreamingCall(), """");+            await call.ResponseStream.MoveNext();+            Assert.AreEqual(""abc"", call.ResponseStream.Current);++            var cts = new CancellationTokenSource();+            var moveNextTask = call.ResponseStream.MoveNext(cts.Token);+            await Task.Delay(100);+            cts.Cancel();++            try+            {+                // cannot use Assert.ThrowsAsync because it uses Task.Wait and would deadlock.+                await moveNextTask;+                Assert.Fail();+            }+            catch (RpcException ex)","Throwing anything else than RpcException here would be quite a big change to gRPC API semantics - when reading streams,  MoveNext() is the primary source from which info about call status is received, and any failed read means a failed RPC, so we should deliver info about call's status code and details (there's an inherent race and the call can end up with several other statuses that we probably want to know about).I understand the concern but I'm afraid we need to leave this as is if we want to maintain API consistency.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/12760,142973128,2017-10-05T15:29:17Z,src/php/tests/qps/histogram.php,"@@ -0,0 +1,93 @@+<?php+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++// Histogram class for use in performance testing and measurement+class Histogram {+  private $resolution;+  private $max_possible;+  private $sum;+  private $sum_of_squares;+  private $multiplier;+  private $count;+  private $min_seen;+  private $max_seen;+  private $buckets;++  private function bucket_for($value) {+    return log($value) / log($this->multiplier);","In the C version, this value is clamped between 0 and the maximum bucket number. Do you need to do something similar here?",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/12760,142974488,2017-10-05T15:34:03Z,src/ruby/qps/proxy-worker.rb,"@@ -41,32 +41,54 @@ def setup(config)     @histmax = config.histogram_params.max_possible     @histogram = Histogram.new(@histres, @histmax)     @start_time = Time.now-    # TODO(vjpai): Support multiple client channels by spawning off a PHP client per channel-    if @use_c_ext-      puts ""Use protobuf c extension""-      command = ""php -d extension="" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/tests/qps/vendor/google/protobuf/php/ext/google/protobuf/modules/protobuf.so "" + ""-d extension="" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/ext/grpc/modules/grpc.so "" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/tests/qps/client.php "" + @mytarget-    else-      puts ""Use protobuf php extension""-      command = ""php -d extension="" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/ext/grpc/modules/grpc.so "" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/tests/qps/client.php "" + @mytarget-    end	-    puts ""Starting command: "" + command-    @php_pid = spawn(command)+    @php_pid = Array.new(@config.client_channels)+    (0..@config.client_channels-1).each do |chan|+      Thread.new {+        if @use_c_ext+          puts ""Use protobuf c extension""+          command = ""php -d extension="" + File.expand_path(File.dirname(__FILE__)) ++            ""/../../php/tests/qps/vendor/google/protobuf/php/ext/google/protobuf/modules/protobuf.so "" ++            ""-d extension="" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/ext/grpc/modules/grpc.so "" ++            File.expand_path(File.dirname(__FILE__)) + ""/../../php/tests/qps/client.php "" + @mytarget + "" #{chan%@config.server_targets.length}""+        else+          puts ""Use protobuf php extension""+          command = ""php -d extension="" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/ext/grpc/modules/grpc.so "" ++            File.expand_path(File.dirname(__FILE__)) + ""/../../php/tests/qps/client.php "" + @mytarget + "" #{chan%@config.server_targets.length}""+        end+        puts ""[ruby proxy] Starting #{chan}th php-client command use c protobuf #{@use_c_ext}: "" + command+        @php_pid[chan] = spawn(command)+        while true+          sleep+        end+      }+    end   end   def stop-    Process.kill(""TERM"", @php_pid)-    Process.wait(@php_pid)+    (0..@config.client_channels-1).each do |chan|+      Process.kill(""TERM"", @php_pid[chan])+      Process.wait(@php_pid[chan])+    end   end   def get_config(_args, _call)-    puts ""Answering get_config""     @config   end   def report_time(call)-    puts ""Starting a time reporting stream""     call.each_remote_read do |lat|       @histogram.add((lat.latency)*1e9)     end     Grpc::Testing::Void.new   end+  def report_hist(call)","I actually don't think that's correct. You may have gotten lucky and not had a race when you ran it, but the Ruby server implementation spawns a new thread for a streaming RPC (and you should have @apolcyn review this also given the amount of Ruby changes you've made). So, technically there could be races between the different clients as they operate in this function. To avoid a potential race, just make the histogram have a lock and synchronize on it in the revised `add_contents` function that I've suggested above.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/12760,142974648,2017-10-05T15:34:38Z,src/ruby/qps/proxy-worker.rb,"@@ -143,7 +165,7 @@ def proxymain   # Configure any errors with client or server child threads to surface   Thread.abort_on_exception = true -  s = GRPC::RpcServer.new+  s = GRPC::RpcServer.new(pool_size: 1024, max_waiting_requests: 1024)",Why did you need to override these parameters? Can you add a comment explaining why?,
28968539,ZhouyihaiDing,https://api.github.com/repos/grpc/grpc/pulls/12760,142978984,2017-10-05T15:49:22Z,src/ruby/qps/proxy-worker.rb,"@@ -143,7 +165,7 @@ def proxymain   # Configure any errors with client or server child threads to surface   Thread.abort_on_exception = true -  s = GRPC::RpcServer.new+  s = GRPC::RpcServer.new(pool_size: 1024, max_waiting_requests: 1024)","`DEFAULT_POOL_SIZE = 30` and `DEFAULT_MAX_WAITING_REQUESTS = 20`,when ruby proxy create more than 30 php client, the connection fails.It performs as the server to the php client. I'll copy the comment from server.rb to here`# Make sure server can handle the large number of calls in benchmark`",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/12613,143013183,2017-10-05T18:04:29Z,src/csharp/Grpc.Core/Interceptors/ClientInterceptor.cs,"@@ -0,0 +1,281 @@+#region Copyright notice and license++// Copyright 2017 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Threading.Tasks;+using Grpc.Core.Utils;++namespace Grpc.Core.Interceptors+{+    /// <summary>+    /// Serves as the base class for gRPC client interceptors.+    /// This is an EXPERIMENTAL API.+    /// </summary>+    public abstract class ClientInterceptor+    {+        /// <summary>+        /// Intercepts a blocking invocation of a simple remote call.+        /// </summary>+        public virtual TResponse BlockingUnaryCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request, Func<Method<TRequest, TResponse>, string, CallOptions, TRequest, TResponse> next)+            where TRequest : class+            where TResponse : class+        {+            return next(method, host, options, request);+        }++        /// <summary>+        /// Intercepts an asynchronous invocation of a simple remote call.+        /// </summary>+        public virtual AsyncUnaryCall<TResponse> AsyncUnaryCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request, Func<Method<TRequest, TResponse>, string, CallOptions, TRequest, AsyncUnaryCall<TResponse>> next)+            where TRequest : class+            where TResponse : class+        {+            return next(method, host, options, request);+        }++        /// <summary>+        /// Intercepts an asynchronous invocation of a streaming remote call.+        /// </summary>+        public virtual AsyncServerStreamingCall<TResponse> AsyncServerStreamingCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request, Func<Method<TRequest, TResponse>, string, CallOptions, TRequest, AsyncServerStreamingCall<TResponse>> next)+            where TRequest : class+            where TResponse : class+        {+            return next(method, host, options, request);+        }++        /// <summary>+        /// Intercepts an asynchronous invocation of a client streaming call.+        /// </summary>+        public virtual AsyncClientStreamingCall<TRequest, TResponse> AsyncClientStreamingCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, Func<Method<TRequest, TResponse>, string, CallOptions, AsyncClientStreamingCall<TRequest, TResponse>> next)+            where TRequest : class+            where TResponse : class+        {+            return next(method, host, options);+        }++        /// <summary>+        /// Intercepts an asynchronous invocation of a duplex streaming call.+        /// </summary>+        public virtual AsyncDuplexStreamingCall<TRequest, TResponse> AsyncDuplexStreamingCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, Func<Method<TRequest, TResponse>, string, CallOptions, AsyncDuplexStreamingCall<TRequest, TResponse>> next)+            where TRequest : class+            where TResponse : class+        {+            return next(method, host, options);+        }++        /// <summary>+        /// Returns a new instance of <c>AsyncUnaryCall</c> that has hooks to intercept on an underlying object of the same type.+        /// </summary>+        protected static AsyncUnaryCall<TResponse> Intercept<TRequest, TResponse>(AsyncUnaryCall<TResponse> call,+            Func<Task<TResponse>, TResponse> response = null,+            Func<Task<Metadata>, Metadata> responseHeaders = null,+            Func<Func<Status>, Func<Status>> getStatus = null,+            Func<Func<Metadata>, Func<Metadata>> getTrailers = null,+            Func<Action, Action> dispose = null)+        {+            GrpcPreconditions.CheckNotNull(call, ""call"");+            var callResponse = call.ResponseAsync;+            Task<Metadata> callResponseHeaders = call.ResponseHeadersAsync;+            Func<Status> callStatus = call.GetStatus;+            Func<Metadata> callTrailers = call.GetTrailers;+            Action callDispose = call.Dispose;++            if (callResponse != null)+            {+                var responseOriginal = callResponse;+                callResponse = new Task<TResponse>(() => response(responseOriginal));+            }++            if (responseHeaders != null)+            {+                var callResponseHeadersOriginal = callResponseHeaders; // Ensure it will not be captured by the closure+                callResponseHeaders = new Task<Metadata>(() => responseHeaders(callResponseHeadersOriginal));+            }++            if (getStatus != null)+            {+                callStatus = getStatus(callStatus);+            }++            if (getTrailers != null)+            {+                callTrailers = getTrailers(callTrailers);+            }++            if (dispose != null)+            {+                callDispose = dispose(callDispose);+            }++            return new AsyncUnaryCall<TResponse>(callResponse, callResponseHeaders, callStatus, callTrailers, callDispose);+        }++        /// <summary>+        /// Returns a new instance of <c>AsyncServerStreamingCall</c> that has hooks to intercept on an underlying object of the same type.+        /// </summary>+        protected static AsyncServerStreamingCall<TResponse> Intercept<TRequest, TResponse>(AsyncServerStreamingCall<TResponse> call,+            Func<IAsyncStreamReader<TResponse>, IAsyncStreamReader<TResponse>> responseStream = null,+            Func<Task<Metadata>, Metadata> responseHeaders = null,+            Func<Func<Status>, Func<Status>> getStatus = null,+            Func<Func<Metadata>, Func<Metadata>> getTrailers = null,+            Func<Action, Action> dispose = null)+        {+            GrpcPreconditions.CheckNotNull(call, ""call"");+            var callResponseStream = call.ResponseStream;+            Task<Metadata> callResponseHeaders = call.ResponseHeadersAsync;+            Func<Status> callStatus = call.GetStatus;+            Func<Metadata> callTrailers = call.GetTrailers;+            Action callDispose = call.Dispose;++            if (responseStream != null)+            {+                callResponseStream = responseStream(callResponseStream);+            }++            if (responseHeaders != null)+            {+                var callResponseHeadersOriginal = callResponseHeaders; // Ensure it will not be captured by the closure+                callResponseHeaders = new Task<Metadata>(() => responseHeaders(callResponseHeadersOriginal));","> we'd need to polish the `Async*Call` constructor signature and be certain that it's not going to changeThe members are already public, so we cannot remove them and the constructor at the moment is basically initializing the existing members. We will be able to add additional constructors should we add new members (as long as we can find sensible defaults for values). In effect, by exposing this functionality within this PR under the interceptor API, we are transitively doing most of this API retention cost (admittedly it is a bit contained, but still would be breaking). I think we should seriously consider opening them up, since the class itself and its members are already not `internal` and the `InterceptAsync*` methods are really ugly in this PR.I do agree that polishing the constructor now makes sense, but I don't see anything wrong with it. What would be the ideal in your opinion?",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/12613,143014606,2017-10-05T18:09:48Z,src/csharp/Grpc.Core/CallOptions.cs,"@@ -36,6 +37,7 @@ public struct CallOptions         ContextPropagationToken propagationToken;         CallCredentials credentials;         CallFlags flags;+        Dictionary<object, object> items;","Happy to move `items` to a different PR, but this is an important requirement it seems, and we need to tackle it soon anyway. Metadata strings are a really ugly approach.Another idea is to introduce an `InterceptorContext` which holds interceptor state and pass it along in the continuation chain. However, the downside is there is no clear way to share that information with the final `CallInvoker` (which might or might not be necessary). If we are going to do this, we can't do it in another PR, because that is a core API change in the interceptor itself (adding another argument to interception callbacks. and the continuation delegate. I'd really like to know what @jskeet thinks about this alternative solution.",
28968539,ZhouyihaiDing,https://api.github.com/repos/grpc/grpc/pulls/12760,143034922,2017-10-05T19:28:49Z,src/ruby/qps/proxy-worker.rb,"@@ -41,32 +41,54 @@ def setup(config)     @histmax = config.histogram_params.max_possible     @histogram = Histogram.new(@histres, @histmax)     @start_time = Time.now-    # TODO(vjpai): Support multiple client channels by spawning off a PHP client per channel-    if @use_c_ext-      puts ""Use protobuf c extension""-      command = ""php -d extension="" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/tests/qps/vendor/google/protobuf/php/ext/google/protobuf/modules/protobuf.so "" + ""-d extension="" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/ext/grpc/modules/grpc.so "" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/tests/qps/client.php "" + @mytarget-    else-      puts ""Use protobuf php extension""-      command = ""php -d extension="" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/ext/grpc/modules/grpc.so "" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/tests/qps/client.php "" + @mytarget-    end	-    puts ""Starting command: "" + command-    @php_pid = spawn(command)+    @php_pid = Array.new(@config.client_channels)+    (0..@config.client_channels-1).each do |chan|+      Thread.new {+        if @use_c_ext+          puts ""Use protobuf c extension""+          command = ""php -d extension="" + File.expand_path(File.dirname(__FILE__)) ++            ""/../../php/tests/qps/vendor/google/protobuf/php/ext/google/protobuf/modules/protobuf.so "" ++            ""-d extension="" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/ext/grpc/modules/grpc.so "" ++            File.expand_path(File.dirname(__FILE__)) + ""/../../php/tests/qps/client.php "" + @mytarget + "" #{chan%@config.server_targets.length}""+        else+          puts ""Use protobuf php extension""+          command = ""php -d extension="" + File.expand_path(File.dirname(__FILE__)) + ""/../../php/ext/grpc/modules/grpc.so "" ++            File.expand_path(File.dirname(__FILE__)) + ""/../../php/tests/qps/client.php "" + @mytarget + "" #{chan%@config.server_targets.length}""+        end+        puts ""[ruby proxy] Starting #{chan}th php-client command use c protobuf #{@use_c_ext}: "" + command+        @php_pid[chan] = spawn(command)+        while true+          sleep+        end+      }+    end   end   def stop-    Process.kill(""TERM"", @php_pid)-    Process.wait(@php_pid)+    (0..@config.client_channels-1).each do |chan|+      Process.kill(""TERM"", @php_pid[chan])+      Process.wait(@php_pid[chan])+    end   end   def get_config(_args, _call)-    puts ""Answering get_config""     @config   end   def report_time(call)-    puts ""Starting a time reporting stream""     call.each_remote_read do |lat|       @histogram.add((lat.latency)*1e9)     end     Grpc::Testing::Void.new   end+  def report_hist(call)","Done. I add a ""Mutex"" inside histogram class. I think it can avoid race when multiple client call ""report_hist"". @apolcyn . Thank you for helping me review the pull request!",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12843,143136428,2017-10-06T08:41:23Z,CMakeLists.txt,"@@ -758,6 +758,7 @@ endif() add_dependencies(buildtests_cxx stress_test)","Normally when adding a new dependency, you need to add a section to CMakeLists.txt.template(similar to this: https://github.com/grpc/grpc/blob/d059e1c43ced2279ea4594df04f62761d7b95a86/templates/CMakeLists.txt.template#L176)Given the inlined vector seems to be header-only, you might get away with only adding the include path https://github.com/grpc/grpc/blob/d059e1c43ced2279ea4594df04f62761d7b95a86/templates/CMakeLists.txt.template#L515 (right now you are getting cmake compilation failures as cmake doesn't know anything about third_party/absl/container yet.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12843,143137635,2017-10-06T08:46:54Z,CMakeLists.txt,"@@ -758,6 +758,7 @@ endif() add_dependencies(buildtests_cxx stress_test)","Actually, you should at least add a comment to CMakeLists.txt.template saying that we're using header-only stuff from abseil so we didn't setup proper dependency the way it's done for other third_party deps.Btw, seems like abseil only supports building with bazel - so currently we cannot use anything else than header-only stuff unless we want to write Makefile and CMakeLists.txt for them (and we really don't want to).",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/12613,143236725,2017-10-06T16:37:36Z,src/csharp/Grpc.Core/Interceptors/ClientInterceptor.cs,"@@ -0,0 +1,281 @@+#region Copyright notice and license++// Copyright 2017 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Threading.Tasks;+using Grpc.Core.Utils;++namespace Grpc.Core.Interceptors+{+    /// <summary>+    /// Serves as the base class for gRPC client interceptors.+    /// This is an EXPERIMENTAL API.+    /// </summary>+    public abstract class ClientInterceptor+    {+        /// <summary>+        /// Intercepts a blocking invocation of a simple remote call.+        /// </summary>+        public virtual TResponse BlockingUnaryCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request, Func<Method<TRequest, TResponse>, string, CallOptions, TRequest, TResponse> next)+            where TRequest : class+            where TResponse : class+        {+            return next(method, host, options, request);+        }++        /// <summary>+        /// Intercepts an asynchronous invocation of a simple remote call.+        /// </summary>+        public virtual AsyncUnaryCall<TResponse> AsyncUnaryCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request, Func<Method<TRequest, TResponse>, string, CallOptions, TRequest, AsyncUnaryCall<TResponse>> next)+            where TRequest : class+            where TResponse : class+        {+            return next(method, host, options, request);+        }++        /// <summary>+        /// Intercepts an asynchronous invocation of a streaming remote call.+        /// </summary>+        public virtual AsyncServerStreamingCall<TResponse> AsyncServerStreamingCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request, Func<Method<TRequest, TResponse>, string, CallOptions, TRequest, AsyncServerStreamingCall<TResponse>> next)+            where TRequest : class+            where TResponse : class+        {+            return next(method, host, options, request);+        }++        /// <summary>+        /// Intercepts an asynchronous invocation of a client streaming call.+        /// </summary>+        public virtual AsyncClientStreamingCall<TRequest, TResponse> AsyncClientStreamingCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, Func<Method<TRequest, TResponse>, string, CallOptions, AsyncClientStreamingCall<TRequest, TResponse>> next)+            where TRequest : class+            where TResponse : class+        {+            return next(method, host, options);+        }++        /// <summary>+        /// Intercepts an asynchronous invocation of a duplex streaming call.+        /// </summary>+        public virtual AsyncDuplexStreamingCall<TRequest, TResponse> AsyncDuplexStreamingCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, Func<Method<TRequest, TResponse>, string, CallOptions, AsyncDuplexStreamingCall<TRequest, TResponse>> next)+            where TRequest : class+            where TResponse : class+        {+            return next(method, host, options);+        }++        /// <summary>+        /// Returns a new instance of <c>AsyncUnaryCall</c> that has hooks to intercept on an underlying object of the same type.+        /// </summary>+        protected static AsyncUnaryCall<TResponse> Intercept<TRequest, TResponse>(AsyncUnaryCall<TResponse> call,+            Func<Task<TResponse>, TResponse> response = null,+            Func<Task<Metadata>, Metadata> responseHeaders = null,+            Func<Func<Status>, Func<Status>> getStatus = null,+            Func<Func<Metadata>, Func<Metadata>> getTrailers = null,+            Func<Action, Action> dispose = null)+        {+            GrpcPreconditions.CheckNotNull(call, ""call"");+            var callResponse = call.ResponseAsync;+            Task<Metadata> callResponseHeaders = call.ResponseHeadersAsync;+            Func<Status> callStatus = call.GetStatus;+            Func<Metadata> callTrailers = call.GetTrailers;+            Action callDispose = call.Dispose;++            if (callResponse != null)+            {+                var responseOriginal = callResponse;+                callResponse = new Task<TResponse>(() => response(responseOriginal));+            }++            if (responseHeaders != null)+            {+                var callResponseHeadersOriginal = callResponseHeaders; // Ensure it will not be captured by the closure+                callResponseHeaders = new Task<Metadata>(() => responseHeaders(callResponseHeadersOriginal));+            }++            if (getStatus != null)+            {+                callStatus = getStatus(callStatus);+            }++            if (getTrailers != null)+            {+                callTrailers = getTrailers(callTrailers);+            }++            if (dispose != null)+            {+                callDispose = dispose(callDispose);+            }++            return new AsyncUnaryCall<TResponse>(callResponse, callResponseHeaders, callStatus, callTrailers, callDispose);+        }++        /// <summary>+        /// Returns a new instance of <c>AsyncServerStreamingCall</c> that has hooks to intercept on an underlying object of the same type.+        /// </summary>+        protected static AsyncServerStreamingCall<TResponse> Intercept<TRequest, TResponse>(AsyncServerStreamingCall<TResponse> call,+            Func<IAsyncStreamReader<TResponse>, IAsyncStreamReader<TResponse>> responseStream = null,+            Func<Task<Metadata>, Metadata> responseHeaders = null,+            Func<Func<Status>, Func<Status>> getStatus = null,+            Func<Func<Metadata>, Func<Metadata>> getTrailers = null,+            Func<Action, Action> dispose = null)+        {+            GrpcPreconditions.CheckNotNull(call, ""call"");+            var callResponseStream = call.ResponseStream;+            Task<Metadata> callResponseHeaders = call.ResponseHeadersAsync;+            Func<Status> callStatus = call.GetStatus;+            Func<Metadata> callTrailers = call.GetTrailers;+            Action callDispose = call.Dispose;++            if (responseStream != null)+            {+                callResponseStream = responseStream(callResponseStream);+            }++            if (responseHeaders != null)+            {+                var callResponseHeadersOriginal = callResponseHeaders; // Ensure it will not be captured by the closure+                callResponseHeaders = new Task<Metadata>(() => responseHeaders(callResponseHeadersOriginal));","What do you think about not opening the constructors but adding a static factory method that returns a new instance? The advantage would be that we will retain the freedom to *unseal* the class and return a derived instance without an API breakage, but it is debatable that it would be worth much.",
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/12644,143311763,2017-10-06T23:21:32Z,include/grpc/grpc_security.h,"@@ -320,6 +356,38 @@ GRPCAPI grpc_server_credentials *grpc_ssl_server_credentials_create_ex(     grpc_ssl_client_certificate_request_type client_certificate_request,     void *reserved); +typedef struct grpc_ssl_server_credentials_options+    grpc_ssl_server_credentials_options;++/** Creates an options object using a certificate config. Use this method when+   the certificates and keys of the SSL server will not changes during the+   server's lifetime. */+GRPCAPI grpc_ssl_server_credentials_options *+grpc_ssl_server_credentials_create_options_using_config(","One small thing that I find a bit unfortunate here is that it's a bit heavy to use. E.g.:```cgrpc_ssl_pem_key_cert_pair key_cert_pair = {my_cert_chain, my_priv_key};grpc_ssl_server_certificate_config *config = grpc_server_certificate_config_create(NULL, &key_cert_pair, 1);grpc_ssl_server_credentials_options *options = grpc_server_certificate_create_options_with_config(config);grpc_server_crededentials *creds = grpc_ssl_server_credentials_create_with_options(options);grpc_ssl_server_credentials_options_release(options);grpc_ssl_server_certificate_config(config);```Maybe we could skip the creation of the config in this case and have the `options_with_config` directly take the keys as an argument as opposed to the config. Just a thought... I'll leave that up to you. The proposed change has the drawback that we are not passing a real ""config"" now.  Yet another solution is to have the options take ownership of the config (which would make sense to me).",
10605667,chwarr,https://api.github.com/repos/grpc/grpc/pulls/12613,143316851,2017-10-07T00:32:20Z,src/csharp/Grpc.Core.Tests/Interceptors/ServerInterceptorTest.cs,"@@ -0,0 +1,78 @@+#region Copyright notice and license++// Copyright 2017 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Generic;+using System.Linq;+using System.Threading;+using System.Threading.Tasks;+using Grpc.Core;+using Grpc.Core.Interceptors;+using Grpc.Core.Internal;+using Grpc.Core.Tests;+using Grpc.Core.Utils;+using NUnit.Framework;++namespace Grpc.Core.Interceptors.Tests+{+    public class ServerInterceptorTest+    {+        const string Host = ""127.0.0.1"";++        private class AddRequestHeaderServerInterceptor : ServerInterceptor+        {+            readonly Metadata.Entry header;++            public AddRequestHeaderServerInterceptor(string key, string value)+            {+                this.header = new Metadata.Entry(key, value);+            }+            public override async Task<TResponse> UnaryServerHandler<TRequest, TResponse>(TRequest request, ServerCallContext context, UnaryServerMethod<TRequest, TResponse> next)","I was referring to difference between the client interceprot test  (in [`ClientInterceptorTest.AddHeaderClientInterceptor.BlockingUnaryCall`](https://github.com/grpc/grpc/pull/12613/files#diff-000199ab016d959fb86fd61611223f6eR42)) and the server interceptor test.The relevant client test code is:```public override TResponse BlockingUnaryCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request, Func<Method<TRequest, TResponse>, string, CallOptions, TRequest, TResponse> next){    options.Headers.Add(this.header);    return next(method, host, options, request);}```It just returns a Task, while in the similar `ServerInterceptorTest.AddRequestHeaderServerInterceptor.UnaryServerHandler`, the method is marked `async` and has the pattern `return await next(...)`. Since there's no other async action in this method, I would have expected a non-async method that just `return next(...);`Is there something special about the server-side or is this an unintentional difference?",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12827,143419534,2017-10-09T09:29:28Z,tools/internal_ci/linux/grpc_run_interop_tests.sh,"@@ -1,4 +1,4 @@-#!/usr/bin/env bash+#!/bin/bash",+1 to removing lots of duplicated run_interop scripts.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12880,143476844,2017-10-09T14:06:19Z,doc/core/moving-to-c++.md,"@@ -0,0 +1,54 @@+# Moving gRPC core to C++++October 2017++ctiller, markdroth, vjpai++## Background and Goal++gRPC core was originally written in C89 for several reasons (possibility of",Might be useful to add a link to https://github.com/grpc/proposal/blob/master/L6-allow-c%2B%2B-in-grpc-core.md for context.  Although it looks like the plan we discussed on Friday is somewhat different from the one described in the gRFC.,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12877,143511729,2017-10-09T16:04:20Z,src/csharp/Grpc.Core/AsyncClientStreamingCall.cs,"@@ -36,7 +36,21 @@ public sealed class AsyncClientStreamingCall<TRequest, TResponse> : IDisposable         readonly Func<Metadata> getTrailersFunc;         readonly Action disposeAction; -        internal AsyncClientStreamingCall(IClientStreamWriter<TRequest> requestStream, Task<TResponse> responseAsync, Task<Metadata> responseHeadersAsync, Func<Status> getStatusFunc, Func<Metadata> getTrailersFunc, Action disposeAction)+        /// <summary>+        /// Creates a new AsyncClientStreamingCall object with the specified properties.+        /// </summary>+        /// <param name=""requestStream"">Stream of request values.</param>+        /// <param name=""responseAsync"">The response of the asynchronous call.</param>+        /// <param name=""responseHeadersAsync"">Response headers of the asynchronous call.</param>+        /// <param name=""getStatusFunc"">Delegate returning the status of the call.</param>+        /// <param name=""getTrailersFunc"">Delegate returning the trailing metadata of the call.</param>+        /// <param name=""disposeAction"">Delegate to invoke when Dispose is called on the call object.</param>+        public AsyncClientStreamingCall(IClientStreamWriter<TRequest> requestStream,+                                        Task<TResponse> responseAsync,+                                        Task<Metadata> responseHeadersAsync,","All 4 call types  share these 4 arguments:`Task<Metadata> responseHeadersAsync, Func<Status> getStatusFunc, Func<Metadata> getTrailersFunc, Action disposeAction`.Wouldn't it be useful to wrap them in a single class (I am actually undecided what's better here)?",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12877,143512958,2017-10-09T16:09:41Z,src/csharp/Grpc.Core/AsyncClientStreamingCall.cs,"@@ -36,7 +36,21 @@ public sealed class AsyncClientStreamingCall<TRequest, TResponse> : IDisposable         readonly Func<Metadata> getTrailersFunc;         readonly Action disposeAction; -        internal AsyncClientStreamingCall(IClientStreamWriter<TRequest> requestStream, Task<TResponse> responseAsync, Task<Metadata> responseHeadersAsync, Func<Status> getStatusFunc, Func<Metadata> getTrailersFunc, Action disposeAction)+        /// <summary>+        /// Creates a new AsyncClientStreamingCall object with the specified properties.+        /// </summary>+        /// <param name=""requestStream"">Stream of request values.</param>+        /// <param name=""responseAsync"">The response of the asynchronous call.</param>+        /// <param name=""responseHeadersAsync"">Response headers of the asynchronous call.</param>+        /// <param name=""getStatusFunc"">Delegate returning the status of the call.</param>+        /// <param name=""getTrailersFunc"">Delegate returning the trailing metadata of the call.</param>+        /// <param name=""disposeAction"">Delegate to invoke when Dispose is called on the call object.</param>+        public AsyncClientStreamingCall(IClientStreamWriter<TRequest> requestStream,","alternatively, we can provide factory methods:currently, we have 2 factories: https://github.com/grpc/grpc/blob/master/src/csharp/Grpc.Core/Calls.cs (for ""actual"" calls)and https://github.com/grpc/grpc/blob/master/src/csharp/Grpc.Core.Testing/TestCalls.cs (for test doubles).Perhaps we could have a 3rd factory class for ""intercepted"" calls. That way, we would have an intermediate layer in case we wanted to make changes to Async**Call constructors.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12767,143515255,2017-10-09T16:18:45Z,src/core/lib/security/transport/security_connector.c,"@@ -637,6 +686,26 @@ static void ssl_server_check_peer(grpc_exec_ctx *exec_ctx,   GRPC_CLOSURE_SCHED(exec_ctx, on_peer_checked, error); } +static int ssl_channel_cmp(grpc_security_connector *sc1,+                           grpc_security_connector *sc2) {+  grpc_ssl_channel_security_connector *c1 =+      (grpc_ssl_channel_security_connector *)sc1;+  grpc_ssl_channel_security_connector *c2 =+      (grpc_ssl_channel_security_connector *)sc2;+  int c = grpc_channel_security_connector_cmp(&c1->base, &c2->base);+  if (c != 0) return c;","I've added incomplete comparison functions for the SSL handshaker factories.  The thing that's still missing is a way to compare the SSL_CTX objects, and I'm hoping you can help me with that, because I'm not very familiar with the OpenSSL API.  Is there an easy way to do this?  I did a quick websearch but didn't come up with anything, so I'm hoping you can suggest something.  The only alternative I can think of is to save our own copy of the parameters that we use to construct the SSL_CTX object, but that seems like a waste of memory, so I'm hoping that there's a better way.",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/12877,143515614,2017-10-09T16:20:15Z,src/csharp/Grpc.Core/AsyncClientStreamingCall.cs,"@@ -36,7 +36,21 @@ public sealed class AsyncClientStreamingCall<TRequest, TResponse> : IDisposable         readonly Func<Metadata> getTrailersFunc;         readonly Action disposeAction; -        internal AsyncClientStreamingCall(IClientStreamWriter<TRequest> requestStream, Task<TResponse> responseAsync, Task<Metadata> responseHeadersAsync, Func<Status> getStatusFunc, Func<Metadata> getTrailersFunc, Action disposeAction)+        /// <summary>+        /// Creates a new AsyncClientStreamingCall object with the specified properties.+        /// </summary>+        /// <param name=""requestStream"">Stream of request values.</param>+        /// <param name=""responseAsync"">The response of the asynchronous call.</param>+        /// <param name=""responseHeadersAsync"">Response headers of the asynchronous call.</param>+        /// <param name=""getStatusFunc"">Delegate returning the status of the call.</param>+        /// <param name=""getTrailersFunc"">Delegate returning the trailing metadata of the call.</param>+        /// <param name=""disposeAction"">Delegate to invoke when Dispose is called on the call object.</param>+        public AsyncClientStreamingCall(IClientStreamWriter<TRequest> requestStream,+                                        Task<TResponse> responseAsync,+                                        Task<Metadata> responseHeadersAsync,","The main advantage of having a class is future proofing the signature, so if we can add stuff in it in the future (which I think is a worthy goal), but if we are confident about the signature, I don't think wrapping in a class is more user-friendly here. What do you think?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12767,143534323,2017-10-09T17:43:57Z,src/core/lib/http/httpcli_security_connector.cc,"@@ -91,8 +91,17 @@ static void httpcli_ssl_check_peer(grpc_exec_ctx *exec_ctx,   tsi_peer_destruct(&peer); } +static int httpcli_ssl_cmp(grpc_security_connector *sc1,","Note that in the httpcli case, there are no channel creds.  Should I manually check the parameters that we're feeding into `tsi_create_ssl_client_handshaker_factory()`?",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/12856,143585542,2017-10-09T21:49:59Z,src/core/ext/transport/chttp2/transport/writing.cc,"@@ -174,343 +174,456 @@ static bool is_default_initial_metadata(grpc_metadata_batch *initial_metadata) {   return initial_metadata->list.default_count == initial_metadata->list.count; } -grpc_chttp2_begin_write_result grpc_chttp2_begin_write(-    grpc_exec_ctx *exec_ctx, grpc_chttp2_transport *t) {-  grpc_chttp2_stream *s;--  /* stats histogram counters: we increment these throughout this function,-     and at the end publish to the central stats histograms */-  int flow_control_writes = 0;-  int initial_metadata_writes = 0;-  int trailing_metadata_writes = 0;-  int message_writes = 0;+namespace {+class StreamWriteContext;++class WriteContext {+ public:+  WriteContext(grpc_exec_ctx *exec_ctx, grpc_chttp2_transport *t) : t_(t) {+    GRPC_STATS_INC_HTTP2_WRITES_BEGUN(exec_ctx);+    GPR_TIMER_BEGIN(""grpc_chttp2_begin_write"", 0);+  } -  GRPC_STATS_INC_HTTP2_WRITES_BEGUN(exec_ctx);+  // TODO(ctiller): make this the destructor+  void FlushStats(grpc_exec_ctx *exec_ctx) {+    GRPC_STATS_INC_HTTP2_SEND_INITIAL_METADATA_PER_WRITE(+        exec_ctx, initial_metadata_writes_);+    GRPC_STATS_INC_HTTP2_SEND_MESSAGE_PER_WRITE(exec_ctx, message_writes_);+    GRPC_STATS_INC_HTTP2_SEND_TRAILING_METADATA_PER_WRITE(+        exec_ctx, trailing_metadata_writes_);+    GRPC_STATS_INC_HTTP2_SEND_FLOWCTL_PER_WRITE(exec_ctx, flow_control_writes_);+  } -  GPR_TIMER_BEGIN(""grpc_chttp2_begin_write"", 0);+  void FlushSettings(grpc_exec_ctx *exec_ctx) {+    if (t_->dirtied_local_settings && !t_->sent_local_settings) {+      grpc_slice_buffer_add(+          &t_->outbuf, grpc_chttp2_settings_create(+                           t_->settings[GRPC_SENT_SETTINGS],+                           t_->settings[GRPC_LOCAL_SETTINGS],+                           t_->force_send_settings, GRPC_CHTTP2_NUM_SETTINGS));+      t_->force_send_settings = false;+      t_->dirtied_local_settings = false;+      t_->sent_local_settings = true;+      GRPC_STATS_INC_HTTP2_SETTINGS_WRITES(exec_ctx);+    }+  } -  if (t->dirtied_local_settings && !t->sent_local_settings) {-    grpc_slice_buffer_add(-        &t->outbuf,-        grpc_chttp2_settings_create(-            t->settings[GRPC_SENT_SETTINGS], t->settings[GRPC_LOCAL_SETTINGS],-            t->force_send_settings, GRPC_CHTTP2_NUM_SETTINGS));-    t->force_send_settings = 0;-    t->dirtied_local_settings = 0;-    t->sent_local_settings = 1;-    GRPC_STATS_INC_HTTP2_SETTINGS_WRITES(exec_ctx);+  void FlushQueuedBuffers(grpc_exec_ctx *exec_ctx) {+    /* simple writes are queued to qbuf, and flushed here */+    grpc_slice_buffer_move_into(&t_->qbuf, &t_->outbuf);+    GPR_ASSERT(t_->qbuf.count == 0);   } -  for (size_t i = 0; i < t->ping_ack_count; i++) {-    grpc_slice_buffer_add(&t->outbuf,-                          grpc_chttp2_ping_create(1, t->ping_acks[i]));+  void FlushWindowUpdates(grpc_exec_ctx *exec_ctx) {+    uint32_t transport_announce =+        grpc_chttp2_flowctl_maybe_send_transport_update(&t_->flow_control,+                                                        t_->outbuf.count > 0);+    if (transport_announce) {+      grpc_transport_one_way_stats throwaway_stats;+      grpc_slice_buffer_add(+          &t_->outbuf, grpc_chttp2_window_update_create(0, transport_announce,+                                                        &throwaway_stats));+      ResetPingRecvClock();+    }   }-  t->ping_ack_count = 0; -  /* simple writes are queued to qbuf, and flushed here */-  grpc_slice_buffer_move_into(&t->qbuf, &t->outbuf);-  GPR_ASSERT(t->qbuf.count == 0);+  void FlushPingAcks() {+    for (size_t i = 0; i < t_->ping_ack_count; i++) {+      grpc_slice_buffer_add(&t_->outbuf,+                            grpc_chttp2_ping_create(true, t_->ping_acks[i]));+    }+    t_->ping_ack_count = 0;+  } -  grpc_chttp2_hpack_compressor_set_max_table_size(-      &t->hpack_compressor,-      t->settings[GRPC_PEER_SETTINGS][GRPC_CHTTP2_SETTINGS_HEADER_TABLE_SIZE]);+  void EnactHpackSettings(grpc_exec_ctx *exec_ctx) {+    grpc_chttp2_hpack_compressor_set_max_table_size(+        &t_->hpack_compressor,+        t_->settings[GRPC_PEER_SETTINGS]+                    [GRPC_CHTTP2_SETTINGS_HEADER_TABLE_SIZE]);+  } -  if (t->flow_control.remote_window > 0) {-    while (grpc_chttp2_list_pop_stalled_by_transport(t, &s)) {-      if (!t->closed && grpc_chttp2_list_add_writable_stream(t, s)) {-        stream_ref_if_not_destroyed(&s->refcount->refs);+  void UpdateStreamsNoLongerStalled() {+    grpc_chttp2_stream *s;+    while (grpc_chttp2_list_pop_stalled_by_transport(t_, &s)) {+      if (!t_->closed && grpc_chttp2_list_add_writable_stream(t_, s)) {+        if (!stream_ref_if_not_destroyed(&s->refcount->refs)) {+          grpc_chttp2_list_remove_writable_stream(t_, s);+        }       }     }   } -  grpc_chttp2_begin_write_result result = {false, false, false};+  grpc_chttp2_stream *NextStream() {+    if (t_->outbuf.length > target_write_size(t_)) {+      result_.partial = true;+      return nullptr;+    } -  /* for each grpc_chttp2_stream that's become writable, frame it's data-     (according to available window sizes) and add to the output buffer */-  while (true) {-    if (t->outbuf.length > target_write_size(t)) {-      result.partial = true;-      break;+    grpc_chttp2_stream *s;+    if (!grpc_chttp2_list_pop_writable_stream(t_, &s)) {+      return nullptr;+    }++    return s;+  }++  void ResetPingRecvClock() {+    if (!t_->is_client) {+      t_->ping_recv_state.last_ping_recv_time = GRPC_MILLIS_INF_PAST;+      t_->ping_recv_state.ping_strikes = 0;+    }+  }++  void IncInitialMetadataWrites() { ++initial_metadata_writes_; }+  void IncWindowUpdateWrites() { ++flow_control_writes_; }+  void IncMessageWrites() { ++message_writes_; }+  void IncTrailingMetadataWrites() { ++trailing_metadata_writes_; }++  void NoteScheduledResults() { result_.early_results_scheduled = true; }++  grpc_chttp2_transport *transport() const { return t_; }++  grpc_chttp2_begin_write_result Result() {+    result_.writing = t_->outbuf.count > 0;+    return result_;+  }++ private:+  grpc_chttp2_transport *const t_;++  /* stats histogram counters: we increment these throughout this function,+     and at the end publish to the central stats histograms */+  int flow_control_writes_ = 0;+  int initial_metadata_writes_ = 0;+  int trailing_metadata_writes_ = 0;+  int message_writes_ = 0;+  grpc_chttp2_begin_write_result result_ = {false, false, false};+};++class DataSendContext {+ public:+  DataSendContext(WriteContext *write_context, grpc_chttp2_transport *t,+                  grpc_chttp2_stream *s)+      : write_context_(write_context),+        t_(t),+        s_(s),+        sending_bytes_before_(s_->sending_bytes) {}++  uint32_t stream_remote_window() const {+    return (uint32_t)GPR_MAX(+        0, s_->flow_control.remote_window_delta ++               (int64_t)t_->settings[GRPC_PEER_SETTINGS]+                                    [GRPC_CHTTP2_SETTINGS_INITIAL_WINDOW_SIZE]);+  }++  uint32_t max_outgoing() const {+    return (uint32_t)GPR_MIN(+        t_->settings[GRPC_PEER_SETTINGS][GRPC_CHTTP2_SETTINGS_MAX_FRAME_SIZE],+        GPR_MIN(stream_remote_window(), t_->flow_control.remote_window));+  }++  bool AnyOutgoing() const { return max_outgoing() != 0; }++  void FlushCompressedBytes() {+    uint32_t send_bytes =+        (uint32_t)GPR_MIN(max_outgoing(), s_->compressed_data_buffer.length);+    bool is_last_data_frame =+        (send_bytes == s_->compressed_data_buffer.length &&+         s_->flow_controlled_buffer.length == 0 &&+         s_->fetching_send_message == NULL);+    if (is_last_data_frame && s_->send_trailing_metadata != NULL &&+        s_->stream_compression_ctx != NULL) {+      if (!grpc_stream_compress(s_->stream_compression_ctx,+                                &s_->flow_controlled_buffer,+                                &s_->compressed_data_buffer, NULL, MAX_SIZE_T,+                                GRPC_STREAM_COMPRESSION_FLUSH_FINISH)) {+        gpr_log(GPR_ERROR, ""Stream compression failed."");+      }+      grpc_stream_compression_context_destroy(s_->stream_compression_ctx);+      s_->stream_compression_ctx = NULL;+      /* After finish, bytes in s->compressed_data_buffer may be+       * more than max_outgoing. Start another round of the current+       * while loop so that send_bytes and is_last_data_frame are+       * recalculated. */+      return;+    }+    is_last_frame_ = is_last_data_frame && s_->send_trailing_metadata != NULL &&+                     grpc_metadata_batch_is_empty(s_->send_trailing_metadata);+    grpc_chttp2_encode_data(s_->id, &s_->compressed_data_buffer, send_bytes,+                            is_last_frame_, &s_->stats.outgoing, &t_->outbuf);+    grpc_chttp2_flowctl_sent_data(&t_->flow_control, &s_->flow_control,+                                  send_bytes);+    if (s_->compressed_data_buffer.length == 0) {+      s_->sending_bytes += s_->uncompressed_data_size;     }+  } -    if (!grpc_chttp2_list_pop_writable_stream(t, &s)) {-      break;+  void CompressMoreBytes() {+    if (s_->stream_compression_ctx == NULL) {+      s_->stream_compression_ctx =+          grpc_stream_compression_context_create(s_->stream_compression_method);+    }+    s_->uncompressed_data_size = s_->flow_controlled_buffer.length;+    if (!grpc_stream_compress(s_->stream_compression_ctx,+                              &s_->flow_controlled_buffer,+                              &s_->compressed_data_buffer, NULL, MAX_SIZE_T,+                              GRPC_STREAM_COMPRESSION_FLUSH_SYNC)) {+      gpr_log(GPR_ERROR, ""Stream compression failed."");     }+  }++  bool WasLastFrame() const { return is_last_frame_; } -    bool sent_initial_metadata = s->sent_initial_metadata;-    bool now_writing = false;+  void CallCallbacks(grpc_exec_ctx *exec_ctx) {+    if (update_list(exec_ctx, t_, s_,+                    (int64_t)(s_->sending_bytes - sending_bytes_before_),+                    &s_->on_flow_controlled_cbs,+                    &s_->flow_controlled_bytes_flowed, GRPC_ERROR_NONE)) {+      write_context_->NoteScheduledResults();+    }+  } + private:+  WriteContext *write_context_;+  grpc_chttp2_transport *t_;+  grpc_chttp2_stream *s_;+  const size_t sending_bytes_before_;+  bool is_last_frame_ = false;+};++class StreamWriteContext {+ public:+  StreamWriteContext(WriteContext *write_context, grpc_chttp2_stream *s)+      : write_context_(write_context),+        t_(write_context->transport()),+        s_(s),+        sent_initial_metadata_(s->sent_initial_metadata) {     GRPC_CHTTP2_IF_TRACING(-        gpr_log(GPR_DEBUG, ""W:%p %s[%d] im-(sent,send)=(%d,%d) announce=%d"", t,-                t->is_client ? ""CLIENT"" : ""SERVER"", s->id,-                sent_initial_metadata, s->send_initial_metadata != NULL,+        gpr_log(GPR_DEBUG, ""W:%p %s[%d] im-(sent,send)=(%d,%d) announce=%d"", t_,+                t_->is_client ? ""CLIENT"" : ""SERVER"", s->id,+                sent_initial_metadata_, s->send_initial_metadata != NULL,                 (int)(s->flow_control.local_window_delta -                       s->flow_control.announced_window_delta)));+  } -    grpc_mdelem *extra_headers_for_trailing_metadata[2];-    size_t num_extra_headers_for_trailing_metadata = 0;-+  void FlushInitialMetadata(grpc_exec_ctx *exec_ctx) {     /* send initial metadata if it's available */-    if (!sent_initial_metadata && s->send_initial_metadata != NULL) {-      // We skip this on the server side if there is no custom initial-      // metadata, there are no messages to send, and we are also sending-      // trailing metadata.  This results in a Trailers-Only response,-      // which is required for retries, as per:-      // https://github.com/grpc/proposal/blob/master/A6-client-retries.md#when-retries-are-valid-      if (t->is_client || s->fetching_send_message != NULL ||-          s->flow_controlled_buffer.length != 0 ||-          s->send_trailing_metadata == NULL ||-          !is_default_initial_metadata(s->send_initial_metadata)) {-        grpc_encode_header_options hopt = {-            s->id,  // stream_id-            false,  // is_eof-            t->settings[GRPC_PEER_SETTINGS]-                       [GRPC_CHTTP2_SETTINGS_GRPC_ALLOW_TRUE_BINARY_METADATA] !=-                0,  // use_true_binary_metadata-            t->settings[GRPC_PEER_SETTINGS]-                       [GRPC_CHTTP2_SETTINGS_MAX_FRAME_SIZE],  // max_frame_size-            &s->stats.outgoing                                 // stats-        };-        grpc_chttp2_encode_header(exec_ctx, &t->hpack_compressor, NULL, 0,-                                  s->send_initial_metadata, &hopt, &t->outbuf);-        now_writing = true;-        if (!t->is_client) {-          t->ping_recv_state.last_ping_recv_time = GRPC_MILLIS_INF_PAST;-          t->ping_recv_state.ping_strikes = 0;-        }-        initial_metadata_writes++;-      } else {-        GRPC_CHTTP2_IF_TRACING(-            gpr_log(GPR_INFO, ""not sending initial_metadata (Trailers-Only)""));-        // When sending Trailers-Only, we need to move the :status and-        // content-type headers to the trailers.-        if (s->send_initial_metadata->idx.named.status != NULL) {-          extra_headers_for_trailing_metadata-              [num_extra_headers_for_trailing_metadata++] =-                  &s->send_initial_metadata->idx.named.status->md;-        }-        if (s->send_initial_metadata->idx.named.content_type != NULL) {-          extra_headers_for_trailing_metadata-              [num_extra_headers_for_trailing_metadata++] =-                  &s->send_initial_metadata->idx.named.content_type->md;-        }-        trailing_metadata_writes++;-      }-      s->send_initial_metadata = NULL;-      s->sent_initial_metadata = true;-      sent_initial_metadata = true;-      result.early_results_scheduled = true;-      grpc_chttp2_complete_closure_step(-          exec_ctx, t, s, &s->send_initial_metadata_finished, GRPC_ERROR_NONE,-          ""send_initial_metadata_finished"");+    if (sent_initial_metadata_) return;+    if (s_->send_initial_metadata == nullptr) return;++    // We skip this on the server side if there is no custom initial+    // metadata, there are no messages to send, and we are also sending+    // trailing metadata.  This results in a Trailers-Only response,+    // which is required for retries, as per:+    // https://github.com/grpc/proposal/blob/master/A6-client-retries.md#when-retries-are-valid+    if (!t_->is_client && s_->fetching_send_message == nullptr &&+        s_->flow_controlled_buffer.length == 0 &&+        s_->compressed_data_buffer.length == 0 &&+        s_->send_trailing_metadata != nullptr &&+        is_default_initial_metadata(s_->send_initial_metadata)) {+      ConvertInitialMetadataToTrailingMetadata();+    } else {+      grpc_encode_header_options hopt = {+          s_->id,  // stream_id+          false,   // is_eof+          t_->settings[GRPC_PEER_SETTINGS]+                      [GRPC_CHTTP2_SETTINGS_GRPC_ALLOW_TRUE_BINARY_METADATA] !=+              0,  // use_true_binary_metadata+          t_->settings[GRPC_PEER_SETTINGS]+                      [GRPC_CHTTP2_SETTINGS_MAX_FRAME_SIZE],  // max_frame_size+          &s_->stats.outgoing                                 // stats+      };+      grpc_chttp2_encode_header(exec_ctx, &t_->hpack_compressor, NULL, 0,+                                s_->send_initial_metadata, &hopt, &t_->outbuf);+      write_context_->ResetPingRecvClock();+      write_context_->IncInitialMetadataWrites();     } +    s_->send_initial_metadata = NULL;+    s_->sent_initial_metadata = true;+    sent_initial_metadata_ = true;+    write_context_->NoteScheduledResults();+    grpc_chttp2_complete_closure_step(+        exec_ctx, t_, s_, &s_->send_initial_metadata_finished, GRPC_ERROR_NONE,+        ""send_initial_metadata_finished"");+  }++  void FlushWindowUpdates(grpc_exec_ctx *exec_ctx) {     /* send any window updates */     uint32_t stream_announce = grpc_chttp2_flowctl_maybe_send_stream_update(-        &t->flow_control, &s->flow_control);-    if (stream_announce > 0) {-      grpc_slice_buffer_add(-          &t->outbuf, grpc_chttp2_window_update_create(s->id, stream_announce,-                                                       &s->stats.outgoing));-      if (!t->is_client) {-        t->ping_recv_state.last_ping_recv_time = GRPC_MILLIS_INF_PAST;-        t->ping_recv_state.ping_strikes = 0;+        &t_->flow_control, &s_->flow_control);+    if (stream_announce == 0) return;++    grpc_slice_buffer_add(+        &t_->outbuf, grpc_chttp2_window_update_create(s_->id, stream_announce,+                                                      &s_->stats.outgoing));+    write_context_->ResetPingRecvClock();+    write_context_->IncWindowUpdateWrites();+  }++  void FlushData(grpc_exec_ctx *exec_ctx) {+    if (!sent_initial_metadata_) return;++    if (s_->flow_controlled_buffer.length == 0 &&+        s_->compressed_data_buffer.length == 0) {+      return;  // early out: nothing to do+    }++    DataSendContext data_send_context(write_context_, t_, s_);++    if (!data_send_context.AnyOutgoing()) {+      if (t_->flow_control.remote_window == 0) {+        report_stall(t_, s_, ""transport"");+        grpc_chttp2_list_add_stalled_by_transport(t_, s_);+      } else if (data_send_context.stream_remote_window() == 0) {+        report_stall(t_, s_, ""stream"");+        grpc_chttp2_list_add_stalled_by_stream(t_, s_);       }-      flow_control_writes++;+      return;  // early out: nothing to do     }-    if (sent_initial_metadata) {-      /* send any body bytes, if allowed by flow control */-      if (s->flow_controlled_buffer.length > 0 ||-          s->compressed_data_buffer.length > 0) {-        uint32_t stream_remote_window = (uint32_t)GPR_MAX(-            0,-            s->flow_control.remote_window_delta +-                (int64_t)t->settings[GRPC_PEER_SETTINGS]-                                    [GRPC_CHTTP2_SETTINGS_INITIAL_WINDOW_SIZE]);-        uint32_t max_outgoing = (uint32_t)GPR_MIN(-            t->settings[GRPC_PEER_SETTINGS]-                       [GRPC_CHTTP2_SETTINGS_MAX_FRAME_SIZE],-            GPR_MIN(stream_remote_window, t->flow_control.remote_window));-        if (max_outgoing > 0) {-          bool is_last_data_frame = false;-          bool is_last_frame = false;-          size_t sending_bytes_before = s->sending_bytes;-          while ((s->flow_controlled_buffer.length > 0 ||-                  s->compressed_data_buffer.length > 0) &&-                 max_outgoing > 0) {-            if (s->compressed_data_buffer.length > 0) {-              uint32_t send_bytes = (uint32_t)GPR_MIN(-                  max_outgoing, s->compressed_data_buffer.length);-              is_last_data_frame =-                  (send_bytes == s->compressed_data_buffer.length &&-                   s->flow_controlled_buffer.length == 0 &&-                   s->fetching_send_message == NULL);-              if (is_last_data_frame && s->send_trailing_metadata != NULL &&-                  s->stream_compression_ctx != NULL) {-                if (!grpc_stream_compress(-                        s->stream_compression_ctx, &s->flow_controlled_buffer,-                        &s->compressed_data_buffer, NULL, MAX_SIZE_T,-                        GRPC_STREAM_COMPRESSION_FLUSH_FINISH)) {-                  gpr_log(GPR_ERROR, ""Stream compression failed."");-                }-                grpc_stream_compression_context_destroy(-                    s->stream_compression_ctx);-                s->stream_compression_ctx = NULL;-                /* After finish, bytes in s->compressed_data_buffer may be-                 * more than max_outgoing. Start another round of the current-                 * while loop so that send_bytes and is_last_data_frame are-                 * recalculated. */-                continue;-              }-              is_last_frame =-                  is_last_data_frame && s->send_trailing_metadata != NULL &&-                  grpc_metadata_batch_is_empty(s->send_trailing_metadata);-              grpc_chttp2_encode_data(s->id, &s->compressed_data_buffer,-                                      send_bytes, is_last_frame,-                                      &s->stats.outgoing, &t->outbuf);-              grpc_chttp2_flowctl_sent_data(&t->flow_control, &s->flow_control,-                                            send_bytes);-              max_outgoing -= send_bytes;-              if (s->compressed_data_buffer.length == 0) {-                s->sending_bytes += s->uncompressed_data_size;-              }-            } else {-              if (s->stream_compression_ctx == NULL) {-                s->stream_compression_ctx =-                    grpc_stream_compression_context_create(-                        s->stream_compression_method);-              }-              s->uncompressed_data_size = s->flow_controlled_buffer.length;-              if (!grpc_stream_compress(-                      s->stream_compression_ctx, &s->flow_controlled_buffer,-                      &s->compressed_data_buffer, NULL, MAX_SIZE_T,-                      GRPC_STREAM_COMPRESSION_FLUSH_SYNC)) {-                gpr_log(GPR_ERROR, ""Stream compression failed."");-              }-            }-          }-          if (!t->is_client) {-            t->ping_recv_state.last_ping_recv_time = 0;-            t->ping_recv_state.ping_strikes = 0;-          }-          if (is_last_frame) {-            s->send_trailing_metadata = NULL;-            s->sent_trailing_metadata = true;-            if (!t->is_client && !s->read_closed) {-              grpc_slice_buffer_add(&t->outbuf, grpc_chttp2_rst_stream_create(-                                                    s->id, GRPC_HTTP2_NO_ERROR,-                                                    &s->stats.outgoing));-            }-            grpc_chttp2_mark_stream_closed(exec_ctx, t, s, !t->is_client, 1,-                                           GRPC_ERROR_NONE);-          }-          result.early_results_scheduled |=-              update_list(exec_ctx, t, s,-                          (int64_t)(s->sending_bytes - sending_bytes_before),-                          &s->on_flow_controlled_cbs,-                          &s->flow_controlled_bytes_flowed, GRPC_ERROR_NONE);-          now_writing = true;-          if (s->flow_controlled_buffer.length > 0 ||-              s->compressed_data_buffer.length > 0) {-            GRPC_CHTTP2_STREAM_REF(s, ""chttp2_writing:fork"");-            grpc_chttp2_list_add_writable_stream(t, s);-          }-          message_writes++;-        } else if (t->flow_control.remote_window == 0) {-          report_stall(t, s, ""transport"");-          grpc_chttp2_list_add_stalled_by_transport(t, s);-          now_writing = true;-        } else if (stream_remote_window == 0) {-          report_stall(t, s, ""stream"");-          grpc_chttp2_list_add_stalled_by_stream(t, s);-          now_writing = true;-        }++    while ((s_->flow_controlled_buffer.length > 0 ||+            s_->compressed_data_buffer.length > 0) &&+           data_send_context.max_outgoing() > 0) {+      if (s_->compressed_data_buffer.length > 0) {+        data_send_context.FlushCompressedBytes();+      } else {+        data_send_context.CompressMoreBytes();       }-      if (s->send_trailing_metadata != NULL &&-          s->fetching_send_message == NULL &&-          s->flow_controlled_buffer.length == 0 &&-          s->compressed_data_buffer.length == 0) {-        GRPC_CHTTP2_IF_TRACING(gpr_log(GPR_INFO, ""sending trailing_metadata""));-        if (grpc_metadata_batch_is_empty(s->send_trailing_metadata)) {-          grpc_chttp2_encode_data(s->id, &s->flow_controlled_buffer, 0, true,-                                  &s->stats.outgoing, &t->outbuf);-        } else {-          grpc_encode_header_options hopt = {-              s->id, true,--              t->settings-                      [GRPC_PEER_SETTINGS]+    }+    write_context_->ResetPingRecvClock();+    if (data_send_context.WasLastFrame()) {+      SentLastFrame(exec_ctx);+    }+    data_send_context.CallCallbacks(exec_ctx);+    stream_became_writable_ = true;+    if (s_->flow_controlled_buffer.length > 0 ||+        s_->compressed_data_buffer.length > 0) {+      GRPC_CHTTP2_STREAM_REF(s_, ""chttp2_writing:fork"");+      grpc_chttp2_list_add_writable_stream(t_, s_);+    }+    write_context_->IncMessageWrites();+  }++  void FlushTrailingMetadata(grpc_exec_ctx *exec_ctx) {+    if (!sent_initial_metadata_) return;++    if (s_->send_trailing_metadata == NULL) return;+    if (s_->fetching_send_message != NULL) return;+    if (s_->flow_controlled_buffer.length != 0) return;+    if (s_->compressed_data_buffer.length != 0) return;++    GRPC_CHTTP2_IF_TRACING(gpr_log(GPR_INFO, ""sending trailing_metadata""));+    if (grpc_metadata_batch_is_empty(s_->send_trailing_metadata)) {+      grpc_chttp2_encode_data(s_->id, &s_->flow_controlled_buffer, 0, true,+                              &s_->stats.outgoing, &t_->outbuf);+    } else {+      grpc_encode_header_options hopt = {+          s_->id, true,+          t_->settings[GRPC_PEER_SETTINGS]                       [GRPC_CHTTP2_SETTINGS_GRPC_ALLOW_TRUE_BINARY_METADATA] !=-                  0,--              t->settings[GRPC_PEER_SETTINGS]-                         [GRPC_CHTTP2_SETTINGS_MAX_FRAME_SIZE],-              &s->stats.outgoing};-          grpc_chttp2_encode_header(exec_ctx, &t->hpack_compressor,-                                    extra_headers_for_trailing_metadata,-                                    num_extra_headers_for_trailing_metadata,-                                    s->send_trailing_metadata, &hopt,-                                    &t->outbuf);-          trailing_metadata_writes++;-        }-        s->send_trailing_metadata = NULL;-        s->sent_trailing_metadata = true;-        if (!t->is_client) {-          t->ping_recv_state.last_ping_recv_time = GRPC_MILLIS_INF_PAST;-          t->ping_recv_state.ping_strikes = 0;-        }-        if (!t->is_client && !s->read_closed) {-          grpc_slice_buffer_add(-              &t->outbuf, grpc_chttp2_rst_stream_create(-                              s->id, GRPC_HTTP2_NO_ERROR, &s->stats.outgoing));-        }-        grpc_chttp2_mark_stream_closed(exec_ctx, t, s, !t->is_client, 1,-                                       GRPC_ERROR_NONE);-        now_writing = true;-        result.early_results_scheduled = true;-        grpc_chttp2_complete_closure_step(-            exec_ctx, t, s, &s->send_trailing_metadata_finished,-            GRPC_ERROR_NONE, ""send_trailing_metadata_finished"");-      }+              0,++          t_->settings[GRPC_PEER_SETTINGS][GRPC_CHTTP2_SETTINGS_MAX_FRAME_SIZE],+          &s_->stats.outgoing};+      grpc_chttp2_encode_header(exec_ctx, &t_->hpack_compressor,+                                extra_headers_for_trailing_metadata_,+                                num_extra_headers_for_trailing_metadata_,+                                s_->send_trailing_metadata, &hopt, &t_->outbuf);+    }+    write_context_->IncTrailingMetadataWrites();+    write_context_->ResetPingRecvClock();+    SentLastFrame(exec_ctx);++    write_context_->NoteScheduledResults();+    grpc_chttp2_complete_closure_step(+        exec_ctx, t_, s_, &s_->send_trailing_metadata_finished, GRPC_ERROR_NONE,+        ""send_trailing_metadata_finished"");+  }++  bool stream_became_writable() { return stream_became_writable_; }++ private:+  void ConvertInitialMetadataToTrailingMetadata() {+    GRPC_CHTTP2_IF_TRACING(+        gpr_log(GPR_INFO, ""not sending initial_metadata (Trailers-Only)""));+    // When sending Trailers-Only, we need to move the :status and+    // content-type headers to the trailers.+    if (s_->send_initial_metadata->idx.named.status != NULL) {+      extra_headers_for_trailing_metadata_+          [num_extra_headers_for_trailing_metadata_++] =+              &s_->send_initial_metadata->idx.named.status->md;     }+    if (s_->send_initial_metadata->idx.named.content_type != NULL) {+      extra_headers_for_trailing_metadata_+          [num_extra_headers_for_trailing_metadata_++] =+              &s_->send_initial_metadata->idx.named.content_type->md;+    }+  }++  void SentLastFrame(grpc_exec_ctx *exec_ctx) {+    s_->send_trailing_metadata = NULL;+    s_->sent_trailing_metadata = true;++    if (!t_->is_client && !s_->read_closed) {+      grpc_slice_buffer_add(+          &t_->outbuf, grpc_chttp2_rst_stream_create(+                           s_->id, GRPC_HTTP2_NO_ERROR, &s_->stats.outgoing));+    }+    grpc_chttp2_mark_stream_closed(exec_ctx, t_, s_, !t_->is_client, true,+                                   GRPC_ERROR_NONE);+  } -    if (now_writing) {-      GRPC_STATS_INC_HTTP2_SEND_INITIAL_METADATA_PER_WRITE(-          exec_ctx, initial_metadata_writes);-      GRPC_STATS_INC_HTTP2_SEND_MESSAGE_PER_WRITE(exec_ctx, message_writes);-      GRPC_STATS_INC_HTTP2_SEND_TRAILING_METADATA_PER_WRITE(-          exec_ctx, trailing_metadata_writes);-      GRPC_STATS_INC_HTTP2_SEND_FLOWCTL_PER_WRITE(exec_ctx,-                                                  flow_control_writes);+  WriteContext *const write_context_;+  grpc_chttp2_transport *const t_;+  grpc_chttp2_stream *const s_;+  bool sent_initial_metadata_;",Can we just use s_->sent_initial_metadata?,
512598,amitsaha,https://api.github.com/repos/grpc/grpc/pulls/12778,143650547,2017-10-10T07:45:42Z,src/python/grpcio/grpc/__init__.py,"@@ -1021,6 +1021,105 @@ def set_details(self, details):         raise NotImplementedError()  +##############  Service-Side Interceptor Interfaces & Classes  #################+++class UnaryUnaryServerInterceptor(six.with_metaclass(abc.ABCMeta)):+    """"""Affords intercepting unary-unary RPCs on the service-side.++This is an EXPERIMENTAL API and is subject to change without notice.""""""++    @abc.abstractmethod+    def intercept_unary_unary_handler(self, handler, method, request,+                                      servicer_context):+        """"""Intercepts unary-unary RPCs on the service-side.++    Args:+      handler: The handler to continue processing the RPC.+      It takes a request value and a ServicerContext object+      and returns a response value.+      method: The full method name of the RPC.+      request: The request value for the RPC.+      servicer_context: The context of the current RPC.","I have been playing with the current implementation. Is `servicer_context` supposed to be an instance of `grpc._server._Context` (which subclasses `ServicerContext`) and not `ServicerContext`?_Context:_ I wanted to get the method_name, and i could only do so via `servicer_context._rpc_event.request_call_details.method`)",
1170852,cauthu,https://api.github.com/repos/grpc/grpc/pulls/12644,143780165,2017-10-10T16:21:35Z,include/grpc/grpc_security.h,"@@ -320,6 +356,38 @@ GRPCAPI grpc_server_credentials *grpc_ssl_server_credentials_create_ex(     grpc_ssl_client_certificate_request_type client_certificate_request,     void *reserved); +typedef struct grpc_ssl_server_credentials_options+    grpc_ssl_server_credentials_options;++/** Creates an options object using a certificate config. Use this method when+   the certificates and keys of the SSL server will not changes during the+   server's lifetime. */+GRPCAPI grpc_ssl_server_credentials_options *+grpc_ssl_server_credentials_create_options_using_config(",I think we can add a wrapper later to make it slightly more convenient to use these.... with the move to c++ i think things like releasing/freeing can be done by scoped/smart pointers etc... and it wouldn't be that bad at all.can we do this later? :),
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12878,143809611,2017-10-10T18:12:11Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -42,99 +43,73 @@ typedef struct {   /** base policy: must be first */   grpc_lb_policy base;   /** all our subchannels */-  grpc_subchannel **subchannels;-  grpc_subchannel **new_subchannels;-  size_t num_subchannels;-  size_t num_new_subchannels;--  grpc_closure connectivity_changed;--  /** remaining members are protected by the combiner */--  /** the selected channel */-  grpc_connected_subchannel *selected;--  /** the subchannel key for \a selected, or NULL if \a selected not set */-  const grpc_subchannel_key *selected_key;-+  grpc_lb_subchannel_list *subchannel_list;+  /** Latest pending subchannel list. */+  grpc_lb_subchannel_list *latest_pending_subchannel_list;+  /** Selected subchannel in \a subchannel_list. */",Nit similar with the above one.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12767,143870652,2017-10-10T22:33:16Z,src/core/lib/security/credentials/ssl/ssl_credentials.cc,"@@ -62,7 +62,8 @@ static grpc_security_status ssl_create_security_connector(     }   }   status = grpc_ssl_channel_security_connector_create(-      exec_ctx, call_creds, &c->config, target, overridden_target_name, sc);+      exec_ctx, creds, call_creds, &c->config, target, overridden_target_name,","As per our conversation, changed to enforce this in the base class.  PTAL.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/12778,144388925,2017-10-12T19:35:31Z,src/python/grpcio/grpc/__init__.py,"@@ -1021,6 +1021,105 @@ def set_details(self, details):         raise NotImplementedError()  +##############  Service-Side Interceptor Interfaces & Classes  #################+++class UnaryUnaryServerInterceptor(six.with_metaclass(abc.ABCMeta)):+    """"""Affords intercepting unary-unary RPCs on the service-side.++This is an EXPERIMENTAL API and is subject to change without notice.""""""++    @abc.abstractmethod+    def intercept_unary_unary_handler(self, handler, method, request,+                                      servicer_context):+        """"""Intercepts unary-unary RPCs on the service-side.++    Args:+      handler: The handler to continue processing the RPC.+      It takes a request value and a ServicerContext object+      and returns a response value.+      method: The full method name of the RPC.+      request: The request value for the RPC.+      servicer_context: The context of the current RPC.",`servicer_context` is supposed to be an instance of `grpc.ServicerContext`. We wouldn't expose in our API (even an experimental API) an internal class like `grpc._server._Context`.Why isn't the `method` parameter passed to this method the right way to get the method name?,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/12778,144425027,2017-10-12T22:22:09Z,src/python/grpcio_tests/tests/unit/_interceptor_test.py,"@@ -0,0 +1,390 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Test of gRPC Python interceptors.""""""++import itertools+import threading+import unittest+from concurrent import futures++import grpc+from grpc.framework.foundation import logging_pool++from tests.unit.framework.common import test_constants+from tests.unit.framework.common import test_control++_SERIALIZE_REQUEST = lambda bytestring: bytestring * 2+_DESERIALIZE_REQUEST = lambda bytestring: bytestring[len(bytestring) // 2:]+_SERIALIZE_RESPONSE = lambda bytestring: bytestring * 3+_DESERIALIZE_RESPONSE = lambda bytestring: bytestring[:len(bytestring) // 3]++_UNARY_UNARY = '/test/UnaryUnary'+_UNARY_STREAM = '/test/UnaryStream'+_STREAM_UNARY = '/test/StreamUnary'+_STREAM_STREAM = '/test/StreamStream'+++class _Callback(object):++    def __init__(self):+        self._condition = threading.Condition()+        self._value = None+        self._called = False++    def __call__(self, value):+        with self._condition:+            self._value = value+            self._called = True+            self._condition.notify_all()++    def value(self):+        with self._condition:+            while not self._called:+                self._condition.wait()+            return self._value+++class _Handler(object):++    def __init__(self, control):+        self._control = control++    def handle_unary_unary(self, request, servicer_context):+        self._control.control()+        if servicer_context is not None:+            servicer_context.set_trailing_metadata((('testkey', 'testvalue',),))+        return request++    def handle_unary_stream(self, request, servicer_context):+        for _ in range(test_constants.STREAM_LENGTH):+            self._control.control()+            yield request+        self._control.control()+        if servicer_context is not None:+            servicer_context.set_trailing_metadata((('testkey', 'testvalue',),))++    def handle_stream_unary(self, request_iterator, servicer_context):+        if servicer_context is not None:+            servicer_context.invocation_metadata()+        self._control.control()+        response_elements = []+        for request in request_iterator:+            self._control.control()+            response_elements.append(request)+        self._control.control()+        if servicer_context is not None:+            servicer_context.set_trailing_metadata((('testkey', 'testvalue',),))+        return b''.join(response_elements)++    def handle_stream_stream(self, request_iterator, servicer_context):+        self._control.control()+        if servicer_context is not None:+            servicer_context.set_trailing_metadata((('testkey', 'testvalue',),))+        for request in request_iterator:+            self._control.control()+            yield request+        self._control.control()+++class _MethodHandler(grpc.RpcMethodHandler):++    def __init__(self, request_streaming, response_streaming,+                 request_deserializer, response_serializer, unary_unary,+                 unary_stream, stream_unary, stream_stream):+        self.request_streaming = request_streaming+        self.response_streaming = response_streaming+        self.request_deserializer = request_deserializer+        self.response_serializer = response_serializer+        self.unary_unary = unary_unary+        self.unary_stream = unary_stream+        self.stream_unary = stream_unary+        self.stream_stream = stream_stream+++class _GenericHandler(grpc.GenericRpcHandler):++    def __init__(self, handler):+        self._handler = handler++    def service(self, handler_call_details):+        if handler_call_details.method == _UNARY_UNARY:+            return _MethodHandler(False, False, None, None,+                                  self._handler.handle_unary_unary, None, None,+                                  None)+        elif handler_call_details.method == _UNARY_STREAM:+            return _MethodHandler(False, True, _DESERIALIZE_REQUEST,+                                  _SERIALIZE_RESPONSE, None,+                                  self._handler.handle_unary_stream, None, None)+        elif handler_call_details.method == _STREAM_UNARY:+            return _MethodHandler(True, False, _DESERIALIZE_REQUEST,+                                  _SERIALIZE_RESPONSE, None, None,+                                  self._handler.handle_stream_unary, None)+        elif handler_call_details.method == _STREAM_STREAM:+            return _MethodHandler(True, True, None, None, None, None, None,+                                  self._handler.handle_stream_stream)+        else:+            return None+++def _unary_unary_multi_callable(channel):+    return channel.unary_unary(_UNARY_UNARY)+++def _unary_stream_multi_callable(channel):+    return channel.unary_stream(+        _UNARY_STREAM,+        request_serializer=_SERIALIZE_REQUEST,+        response_deserializer=_DESERIALIZE_RESPONSE)+++def _stream_unary_multi_callable(channel):+    return channel.stream_unary(+        _STREAM_UNARY,+        request_serializer=_SERIALIZE_REQUEST,+        response_deserializer=_DESERIALIZE_RESPONSE)+++def _stream_stream_multi_callable(channel):+    return channel.stream_stream(_STREAM_STREAM)+++class _Interceptor(","This object should do something ""interesting"" with the RPCs and RPC values that it intercepts. Double the value of an integer in the request payload, or insert metadata, or duplicate each message in the request stream, or triplicate each message in the response stream, or... all those things!Consider an implementation that calls the interceptor, but after calling the interceptor fails to make use of the RPC values returned by the interceptor and instead continued executing the RPC with the RPC values that it passed to the interceptor. This test, in its current form, would fail to detect that defect, right?",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12878,144425506,2017-10-12T22:25:10Z,src/core/ext/filters/client_channel/lb_policy/subchannel_list.cc,"@@ -0,0 +1,286 @@+/*+ *+ * Copyright 2015 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <string.h>++#include <grpc/support/alloc.h>++#include ""src/core/ext/filters/client_channel/lb_policy/subchannel_list.h""+#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/debug/trace.h""+#include ""src/core/lib/iomgr/closure.h""+#include ""src/core/lib/iomgr/combiner.h""+#include ""src/core/lib/iomgr/sockaddr_utils.h""+#include ""src/core/lib/transport/connectivity_state.h""++void grpc_lb_subchannel_data_unref_subchannel(grpc_exec_ctx *exec_ctx,+                                              grpc_lb_subchannel_data *sd,+                                              const char *reason) {+  if (sd->subchannel != NULL) {+    if (GRPC_TRACER_ON(*sd->subchannel_list->tracer)) {+      gpr_log(+          GPR_DEBUG, ""[%s %p] subchannel list %p index %"" PRIdPTR+                     "" of %"" PRIdPTR "" (subchannel %p): unreffing subchannel"",+          sd->subchannel_list->tracer->name, sd->subchannel_list->policy,+          sd->subchannel_list, (size_t)(sd - sd->subchannel_list->subchannels),+          sd->subchannel_list->num_subchannels, sd->subchannel);+    }+    GRPC_SUBCHANNEL_UNREF(exec_ctx, sd->subchannel, reason);+    sd->subchannel = NULL;+    if (sd->connected_subchannel != NULL) {+      GRPC_CONNECTED_SUBCHANNEL_UNREF(exec_ctx, sd->connected_subchannel,+                                      reason);+      sd->connected_subchannel = NULL;+    }+    if (sd->user_data != NULL) {+      GPR_ASSERT(sd->user_data_vtable != NULL);+      sd->user_data_vtable->destroy(exec_ctx, sd->user_data);+      sd->user_data = NULL;+    }+  }+}++void grpc_lb_subchannel_data_start_connectivity_watch(+    grpc_exec_ctx *exec_ctx, grpc_lb_subchannel_data *sd) {+  if (GRPC_TRACER_ON(*sd->subchannel_list->tracer)) {+    gpr_log(GPR_DEBUG,+            ""[%s %p] subchannel list %p index %"" PRIdPTR "" of %"" PRIdPTR+            "" (subchannel %p): requesting connectivity change notification"",+            sd->subchannel_list->tracer->name, sd->subchannel_list->policy,+            sd->subchannel_list,+            (size_t)(sd - sd->subchannel_list->subchannels),+            sd->subchannel_list->num_subchannels, sd->subchannel);+  }+  sd->connectivity_notification_pending = true;+  grpc_subchannel_notify_on_state_change(+      exec_ctx, sd->subchannel, sd->subchannel_list->policy->interested_parties,+      &sd->pending_connectivity_state_unsafe,+      &sd->connectivity_changed_closure);+}++void grpc_lb_subchannel_data_stop_connectivity_watch(+    grpc_exec_ctx *exec_ctx, grpc_lb_subchannel_data *sd) {+  if (GRPC_TRACER_ON(*sd->subchannel_list->tracer)) {+    gpr_log(+        GPR_DEBUG, ""[%s %p] subchannel list %p index %"" PRIdPTR "" of %"" PRIdPTR+                   "" (subchannel %p): stopping connectivity watch"",+        sd->subchannel_list->tracer->name, sd->subchannel_list->policy,+        sd->subchannel_list, (size_t)(sd - sd->subchannel_list->subchannels),+        sd->subchannel_list->num_subchannels, sd->subchannel);+  }+  GPR_ASSERT(sd->connectivity_notification_pending);+  sd->connectivity_notification_pending = false;+}++grpc_lb_subchannel_list *grpc_lb_subchannel_list_create(+    grpc_exec_ctx *exec_ctx, grpc_lb_policy *p, grpc_tracer_flag *tracer,+    const grpc_lb_addresses *addresses, const grpc_lb_policy_args *args,+    grpc_iomgr_cb_func connectivity_changed_cb) {+  grpc_lb_subchannel_list *subchannel_list =+      (grpc_lb_subchannel_list *)gpr_zalloc(sizeof(*subchannel_list));+  if (GRPC_TRACER_ON(*tracer)) {+    gpr_log(GPR_DEBUG,+            ""[%s %p] Creating subchannel list %p for %"" PRIdPTR "" subchannels"",+            tracer->name, p, subchannel_list, addresses->num_addresses);+  }+  subchannel_list->policy = p;+  subchannel_list->tracer = tracer;+  gpr_ref_init(&subchannel_list->refcount, 1);+  subchannel_list->subchannels = (grpc_lb_subchannel_data *)gpr_zalloc(+      sizeof(grpc_lb_subchannel_data) * addresses->num_addresses);+  /* We need to remove the LB addresses in order to be able to compare the+   * subchannel keys of subchannels from a different batch of addresses. */+  static const char *keys_to_remove[] = {GRPC_ARG_SUBCHANNEL_ADDRESS,+                                         GRPC_ARG_LB_ADDRESSES};+  /* Create subchannels for addresses in the update. */+  grpc_subchannel_args sc_args;+  size_t subchannel_index = 0;+  for (size_t i = 0; i < addresses->num_addresses; i++) {+    // If there were any balancer, we would have chosen grpclb policy instead.+    GPR_ASSERT(!addresses->addresses[i].is_balancer);+    memset(&sc_args, 0, sizeof(grpc_subchannel_args));+    grpc_arg addr_arg =+        grpc_create_subchannel_address_arg(&addresses->addresses[i].address);+    grpc_channel_args *new_args = grpc_channel_args_copy_and_add_and_remove(+        args->args, keys_to_remove, GPR_ARRAY_SIZE(keys_to_remove), &addr_arg,+        1);+    gpr_free(addr_arg.value.string);+    sc_args.args = new_args;+    grpc_subchannel *subchannel = grpc_client_channel_factory_create_subchannel(+        exec_ctx, args->client_channel_factory, &sc_args);+    grpc_channel_args_destroy(exec_ctx, new_args);+    if (subchannel == NULL) {+      // Subchannel could not be created.+      if (GRPC_TRACER_ON(*tracer)) {+        char *address_uri =+            grpc_sockaddr_to_uri(&addresses->addresses[i].address);+        gpr_log(GPR_DEBUG,+                ""[%s %p] could not create subchannel for address uri %s, ""+                ""ignoring"",+                tracer->name, subchannel_list->policy, address_uri);+        gpr_free(address_uri);+      }+      continue;+    }+    grpc_error *error;+    // Get the connectivity state of the subchannel. Already existing ones may+    // be in a state other than INIT.+    const grpc_connectivity_state subchannel_connectivity_state =+        grpc_subchannel_check_connectivity(subchannel, &error);+    if (error != GRPC_ERROR_NONE) {+      // The subchannel is in error (e.g. shutting down). Ignore it.+      if (GRPC_TRACER_ON(*tracer)) {+        char *address_uri =+            grpc_sockaddr_to_uri(&addresses->addresses[i].address);+        gpr_log(GPR_DEBUG,+                ""[%s %p] subchannel for address uri %s shutting down, ignoring"",+                tracer->name, subchannel_list->policy, address_uri);+        gpr_free(address_uri);+      }+      GRPC_SUBCHANNEL_UNREF(exec_ctx, subchannel, ""new_sc_connectivity_error"");+      GRPC_ERROR_UNREF(error);+      continue;+    }+    if (GRPC_TRACER_ON(*tracer)) {+      char *address_uri =+          grpc_sockaddr_to_uri(&addresses->addresses[i].address);+      gpr_log(GPR_DEBUG, ""[%s %p] subchannel list %p index %"" PRIdPTR+                         "": Created subchannel %p for address uri %s; ""+                         ""initial connectivity state: %s"",+              tracer->name, p, subchannel_list, subchannel_index, subchannel,+              address_uri,+              grpc_connectivity_state_name(subchannel_connectivity_state));+      gpr_free(address_uri);+    }+    grpc_lb_subchannel_data *sd =+        &subchannel_list->subchannels[subchannel_index++];+    sd->subchannel_list = subchannel_list;+    sd->subchannel = subchannel;+    GRPC_CLOSURE_INIT(&sd->connectivity_changed_closure,+                      connectivity_changed_cb, sd,+                      grpc_combiner_scheduler(args->combiner));+    /* use some sentinel value outside of the range of+     * grpc_connectivity_state to signal an undefined previous state. We+     * won't be referring to this value again and it'll be overwritten after+     * the first call to rr_connectivity_changed_locked */+    sd->prev_connectivity_state = GRPC_CHANNEL_INIT;+    sd->curr_connectivity_state = subchannel_connectivity_state;+    sd->user_data_vtable = addresses->user_data_vtable;+    if (sd->user_data_vtable != NULL) {+      sd->user_data =+          sd->user_data_vtable->copy(addresses->addresses[i].user_data);+    }+  }+  subchannel_list->num_subchannels = subchannel_index;+  return subchannel_list;+}++static void subchannel_list_destroy(grpc_exec_ctx *exec_ctx,",It may be better to name this function as `grpc_lb_subchannel_list_destroy()`.,
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12878,144460770,2017-10-13T03:50:15Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -317,270 +260,228 @@ static void pf_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,   }   const grpc_lb_addresses *addresses =       (const grpc_lb_addresses *)arg->value.pointer.p;-  if (addresses->num_addresses == 0) {-    // Empty update. Unsubscribe from all current subchannels and put the-    // channel in TRANSIENT_FAILURE.+  if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {+    gpr_log(GPR_INFO, ""Pick First %p received update with %lu addresses"",+            (void *)p, (unsigned long)addresses->num_addresses);+  }+  grpc_lb_subchannel_list *subchannel_list = grpc_lb_subchannel_list_create(+      exec_ctx, &p->base, &grpc_lb_pick_first_trace, addresses, args,+      pf_connectivity_changed_locked);+  if (subchannel_list->num_subchannels == 0) {+    // Empty update or no valid subchannels. Unsubscribe from all current+    // subchannels and put the channel in TRANSIENT_FAILURE.     grpc_connectivity_state_set(         exec_ctx, &p->state_tracker, GRPC_CHANNEL_TRANSIENT_FAILURE,         GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Empty update""),         ""pf_update_empty"");-    stop_connectivity_watchers(exec_ctx, p);+    if (p->subchannel_list != NULL) {+      grpc_lb_subchannel_list_shutdown_and_unref(exec_ctx, p->subchannel_list,+                                                 ""sl_shutdown_empty_update"");+    }+    p->subchannel_list = subchannel_list;  // Empty list.+    p->selected = NULL;     return;   }-  if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {-    gpr_log(GPR_INFO, ""Pick First %p received update with %lu addresses"",-            (void *)p, (unsigned long)addresses->num_addresses);-  }-  grpc_subchannel_args *sc_args = (grpc_subchannel_args *)gpr_zalloc(-      sizeof(*sc_args) * addresses->num_addresses);-  /* We remove the following keys in order for subchannel keys belonging to-   * subchannels point to the same address to match. */-  static const char *keys_to_remove[] = {GRPC_ARG_SUBCHANNEL_ADDRESS,-                                         GRPC_ARG_LB_ADDRESSES};-  size_t sc_args_count = 0;--  /* Create list of subchannel args for new addresses in \a args. */-  for (size_t i = 0; i < addresses->num_addresses; i++) {-    // If there were any balancer, we would have chosen grpclb policy instead.-    GPR_ASSERT(!addresses->addresses[i].is_balancer);-    if (addresses->addresses[i].user_data != NULL) {-      gpr_log(GPR_ERROR,-              ""This LB policy doesn't support user data. It will be ignored"");+  if (p->selected == NULL) {+    // We don't yet have a selected subchannel, so replace the current+    // subchannel list immediately.+    if (p->subchannel_list != NULL) {+      grpc_lb_subchannel_list_shutdown_and_unref(exec_ctx, p->subchannel_list,+                                                 ""pf_update_before_selected"");     }-    grpc_arg addr_arg =-        grpc_create_subchannel_address_arg(&addresses->addresses[i].address);-    grpc_channel_args *new_args = grpc_channel_args_copy_and_add_and_remove(-        args->args, keys_to_remove, GPR_ARRAY_SIZE(keys_to_remove), &addr_arg,-        1);-    gpr_free(addr_arg.value.string);-    sc_args[sc_args_count++].args = new_args;-  }--  /* Check if p->selected is amongst them. If so, we are done. */-  if (p->selected != NULL) {-    GPR_ASSERT(p->selected_key != NULL);-    for (size_t i = 0; i < sc_args_count; i++) {-      grpc_subchannel_key *ith_sc_key = grpc_subchannel_key_create(&sc_args[i]);-      const bool found_selected =-          grpc_subchannel_key_compare(p->selected_key, ith_sc_key) == 0;-      grpc_subchannel_key_destroy(exec_ctx, ith_sc_key);-      if (found_selected) {+    p->subchannel_list = subchannel_list;+  } else {+    // We do have a selected subchannel.+    // Check if it's present in the new list.  If so, we're done.+    for (size_t i = 0; i < subchannel_list->num_subchannels; ++i) {+      grpc_lb_subchannel_data *sd = &subchannel_list->subchannels[i];+      if (sd->subchannel == p->selected->subchannel) {         // The currently selected subchannel is in the update: we are done.         if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {           gpr_log(GPR_INFO,-                  ""Pick First %p found already selected subchannel %p amongst ""-                  ""updates. Update done."",-                  (void *)p, (void *)p->selected);+                  ""Pick First %p found already selected subchannel %p ""+                  ""at update index %"" PRIdPTR "" of %"" PRIdPTR ""; update done"",+                  p, p->selected->subchannel, i,+                  subchannel_list->num_subchannels);         }-        for (size_t j = 0; j < sc_args_count; j++) {-          grpc_channel_args_destroy(exec_ctx,-                                    (grpc_channel_args *)sc_args[j].args);+        grpc_lb_subchannel_list_ref_for_connectivity_watch(+            subchannel_list, ""connectivity_watch+replace_selected"");+        grpc_lb_subchannel_data_start_connectivity_watch(exec_ctx, sd);+        if (p->subchannel_list != NULL) {+          grpc_lb_subchannel_list_shutdown_and_unref(+              exec_ctx, p->subchannel_list, ""pf_update_includes_selected"");+        }+        p->subchannel_list = subchannel_list;+        if (p->selected->connected_subchannel != NULL) {+          sd->connected_subchannel = GRPC_CONNECTED_SUBCHANNEL_REF(+              grpc_subchannel_get_connected_subchannel(sd->subchannel),+              ""pf_update_includes_selected"");+        }+        p->selected = sd;+        destroy_unselected_subchannels_locked(exec_ctx, p);+        // If there was a previously pending update (which may or may+        // not have contained the currently selected subchannel), drop+        // it, so that it doesn't override what we've done here.+        if (p->latest_pending_subchannel_list != NULL) {+          grpc_lb_subchannel_list_shutdown_and_unref(+              exec_ctx, p->latest_pending_subchannel_list,+              ""pf_update_includes_selected+outdated"");+          p->latest_pending_subchannel_list = NULL;         }-        gpr_free(sc_args);         return;       }     }-  }-  // We only check for already running updates here because if the previous-  // steps were successful, the update can be considered done without any-  // interference (ie, no callbacks were scheduled).-  if (p->updating_selected || p->updating_subchannels) {-    if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {-      gpr_log(GPR_INFO,-              ""Update already in progress for pick first %p. Deferring update."",-              (void *)p);-    }-    if (p->pending_update_args != NULL) {-      grpc_channel_args_destroy(exec_ctx, p->pending_update_args->args);-      gpr_free(p->pending_update_args);-    }-    p->pending_update_args =-        (grpc_lb_policy_args *)gpr_zalloc(sizeof(*p->pending_update_args));-    p->pending_update_args->client_channel_factory =-        args->client_channel_factory;-    p->pending_update_args->args = grpc_channel_args_copy(args->args);-    p->pending_update_args->combiner = args->combiner;-    return;-  }-  /* Create the subchannels for the new subchannel args/addresses. */-  grpc_subchannel **new_subchannels =-      (grpc_subchannel **)gpr_zalloc(sizeof(*new_subchannels) * sc_args_count);-  size_t num_new_subchannels = 0;-  for (size_t i = 0; i < sc_args_count; i++) {-    grpc_subchannel *subchannel = grpc_client_channel_factory_create_subchannel(-        exec_ctx, args->client_channel_factory, &sc_args[i]);-    if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {-      char *address_uri =-          grpc_sockaddr_to_uri(&addresses->addresses[i].address);-      gpr_log(GPR_INFO,-              ""Pick First %p created subchannel %p for address uri %s"",-              (void *)p, (void *)subchannel, address_uri);-      gpr_free(address_uri);+    // Not keeping the previous selected subchannel, so set the latest+    // pending subchannel list to the new subchannel list.  We will wait+    // for it to report READY before swapping it into the current+    // subchannel list.+    if (p->latest_pending_subchannel_list != NULL) {+      if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {+        gpr_log(GPR_DEBUG,+                ""Pick First %p Shutting down latest pending subchannel list ""+                ""%p, about to be replaced by newer latest %p"",+                (void *)p, (void *)p->latest_pending_subchannel_list,+                (void *)subchannel_list);+      }+      grpc_lb_subchannel_list_shutdown_and_unref(+          exec_ctx, p->latest_pending_subchannel_list,+          ""sl_outdated_dont_smash"");     }-    grpc_channel_args_destroy(exec_ctx, (grpc_channel_args *)sc_args[i].args);-    if (subchannel != NULL) new_subchannels[num_new_subchannels++] = subchannel;+    p->latest_pending_subchannel_list = subchannel_list;   }-  gpr_free(sc_args);-  if (num_new_subchannels == 0) {-    gpr_free(new_subchannels);-    // Empty update. Unsubscribe from all current subchannels and put the-    // channel in TRANSIENT_FAILURE.-    grpc_connectivity_state_set(-        exec_ctx, &p->state_tracker, GRPC_CHANNEL_TRANSIENT_FAILURE,-        GRPC_ERROR_CREATE_FROM_STATIC_STRING(""No valid addresses in update""),-        ""pf_update_no_valid_addresses"");-    stop_connectivity_watchers(exec_ctx, p);-    return;-  }--  /* Destroy the current subchannels. Repurpose pf_shutdown/destroy. */-  stop_connectivity_watchers(exec_ctx, p);--  /* Save new subchannels. The switch over will happen in-   * pf_connectivity_changed_locked */-  if (p->updating_selected || p->updating_subchannels) {-    p->num_new_subchannels = num_new_subchannels;-    p->new_subchannels = new_subchannels;-  } else { /* nothing is updating. Get things moving from here */-    p->num_subchannels = num_new_subchannels;-    p->subchannels = new_subchannels;-    p->new_subchannels = NULL;-    p->num_new_subchannels = 0;-    if (p->started_picking) {-      p->checking_subchannel = 0;-      p->checking_connectivity = GRPC_CHANNEL_IDLE;-      grpc_subchannel_notify_on_state_change(-          exec_ctx, p->subchannels[p->checking_subchannel],-          p->base.interested_parties, &p->checking_connectivity,-          &p->connectivity_changed);-    }+  // If we've started picking, start trying to connect to the first+  // subchannel in the new list.+  if (p->started_picking && subchannel_list->num_subchannels > 0) {",We don't need to check `subchannel_list->num_subchannels > 0` because we would have already returned at line 283 if `subchannel_list->num_subchannels == 0`.,
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12878,144600804,2017-10-13T16:32:38Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -317,270 +260,228 @@ static void pf_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,   }   const grpc_lb_addresses *addresses =       (const grpc_lb_addresses *)arg->value.pointer.p;-  if (addresses->num_addresses == 0) {-    // Empty update. Unsubscribe from all current subchannels and put the-    // channel in TRANSIENT_FAILURE.+  if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {+    gpr_log(GPR_INFO, ""Pick First %p received update with %lu addresses"",+            (void *)p, (unsigned long)addresses->num_addresses);+  }+  grpc_lb_subchannel_list *subchannel_list = grpc_lb_subchannel_list_create(+      exec_ctx, &p->base, &grpc_lb_pick_first_trace, addresses, args,+      pf_connectivity_changed_locked);+  if (subchannel_list->num_subchannels == 0) {+    // Empty update or no valid subchannels. Unsubscribe from all current+    // subchannels and put the channel in TRANSIENT_FAILURE.     grpc_connectivity_state_set(         exec_ctx, &p->state_tracker, GRPC_CHANNEL_TRANSIENT_FAILURE,         GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Empty update""),         ""pf_update_empty"");-    stop_connectivity_watchers(exec_ctx, p);+    if (p->subchannel_list != NULL) {+      grpc_lb_subchannel_list_shutdown_and_unref(exec_ctx, p->subchannel_list,+                                                 ""sl_shutdown_empty_update"");+    }+    p->subchannel_list = subchannel_list;  // Empty list.+    p->selected = NULL;     return;   }-  if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {-    gpr_log(GPR_INFO, ""Pick First %p received update with %lu addresses"",-            (void *)p, (unsigned long)addresses->num_addresses);-  }-  grpc_subchannel_args *sc_args = (grpc_subchannel_args *)gpr_zalloc(-      sizeof(*sc_args) * addresses->num_addresses);-  /* We remove the following keys in order for subchannel keys belonging to-   * subchannels point to the same address to match. */-  static const char *keys_to_remove[] = {GRPC_ARG_SUBCHANNEL_ADDRESS,-                                         GRPC_ARG_LB_ADDRESSES};-  size_t sc_args_count = 0;--  /* Create list of subchannel args for new addresses in \a args. */-  for (size_t i = 0; i < addresses->num_addresses; i++) {-    // If there were any balancer, we would have chosen grpclb policy instead.-    GPR_ASSERT(!addresses->addresses[i].is_balancer);-    if (addresses->addresses[i].user_data != NULL) {-      gpr_log(GPR_ERROR,-              ""This LB policy doesn't support user data. It will be ignored"");+  if (p->selected == NULL) {+    // We don't yet have a selected subchannel, so replace the current+    // subchannel list immediately.+    if (p->subchannel_list != NULL) {+      grpc_lb_subchannel_list_shutdown_and_unref(exec_ctx, p->subchannel_list,+                                                 ""pf_update_before_selected"");     }-    grpc_arg addr_arg =-        grpc_create_subchannel_address_arg(&addresses->addresses[i].address);-    grpc_channel_args *new_args = grpc_channel_args_copy_and_add_and_remove(-        args->args, keys_to_remove, GPR_ARRAY_SIZE(keys_to_remove), &addr_arg,-        1);-    gpr_free(addr_arg.value.string);-    sc_args[sc_args_count++].args = new_args;-  }--  /* Check if p->selected is amongst them. If so, we are done. */-  if (p->selected != NULL) {-    GPR_ASSERT(p->selected_key != NULL);-    for (size_t i = 0; i < sc_args_count; i++) {-      grpc_subchannel_key *ith_sc_key = grpc_subchannel_key_create(&sc_args[i]);-      const bool found_selected =-          grpc_subchannel_key_compare(p->selected_key, ith_sc_key) == 0;-      grpc_subchannel_key_destroy(exec_ctx, ith_sc_key);-      if (found_selected) {+    p->subchannel_list = subchannel_list;+  } else {+    // We do have a selected subchannel.+    // Check if it's present in the new list.  If so, we're done.+    for (size_t i = 0; i < subchannel_list->num_subchannels; ++i) {+      grpc_lb_subchannel_data *sd = &subchannel_list->subchannels[i];+      if (sd->subchannel == p->selected->subchannel) {         // The currently selected subchannel is in the update: we are done.         if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {           gpr_log(GPR_INFO,-                  ""Pick First %p found already selected subchannel %p amongst ""-                  ""updates. Update done."",-                  (void *)p, (void *)p->selected);+                  ""Pick First %p found already selected subchannel %p ""+                  ""at update index %"" PRIdPTR "" of %"" PRIdPTR ""; update done"",+                  p, p->selected->subchannel, i,+                  subchannel_list->num_subchannels);         }-        for (size_t j = 0; j < sc_args_count; j++) {-          grpc_channel_args_destroy(exec_ctx,-                                    (grpc_channel_args *)sc_args[j].args);+        grpc_lb_subchannel_list_ref_for_connectivity_watch(+            subchannel_list, ""connectivity_watch+replace_selected"");+        grpc_lb_subchannel_data_start_connectivity_watch(exec_ctx, sd);+        if (p->subchannel_list != NULL) {+          grpc_lb_subchannel_list_shutdown_and_unref(+              exec_ctx, p->subchannel_list, ""pf_update_includes_selected"");+        }+        p->subchannel_list = subchannel_list;+        if (p->selected->connected_subchannel != NULL) {+          sd->connected_subchannel = GRPC_CONNECTED_SUBCHANNEL_REF(+              grpc_subchannel_get_connected_subchannel(sd->subchannel),+              ""pf_update_includes_selected"");+        }+        p->selected = sd;+        destroy_unselected_subchannels_locked(exec_ctx, p);+        // If there was a previously pending update (which may or may+        // not have contained the currently selected subchannel), drop+        // it, so that it doesn't override what we've done here.+        if (p->latest_pending_subchannel_list != NULL) {+          grpc_lb_subchannel_list_shutdown_and_unref(+              exec_ctx, p->latest_pending_subchannel_list,+              ""pf_update_includes_selected+outdated"");+          p->latest_pending_subchannel_list = NULL;         }-        gpr_free(sc_args);         return;       }     }-  }-  // We only check for already running updates here because if the previous-  // steps were successful, the update can be considered done without any-  // interference (ie, no callbacks were scheduled).-  if (p->updating_selected || p->updating_subchannels) {-    if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {-      gpr_log(GPR_INFO,-              ""Update already in progress for pick first %p. Deferring update."",-              (void *)p);-    }-    if (p->pending_update_args != NULL) {-      grpc_channel_args_destroy(exec_ctx, p->pending_update_args->args);-      gpr_free(p->pending_update_args);-    }-    p->pending_update_args =-        (grpc_lb_policy_args *)gpr_zalloc(sizeof(*p->pending_update_args));-    p->pending_update_args->client_channel_factory =-        args->client_channel_factory;-    p->pending_update_args->args = grpc_channel_args_copy(args->args);-    p->pending_update_args->combiner = args->combiner;-    return;-  }-  /* Create the subchannels for the new subchannel args/addresses. */-  grpc_subchannel **new_subchannels =-      (grpc_subchannel **)gpr_zalloc(sizeof(*new_subchannels) * sc_args_count);-  size_t num_new_subchannels = 0;-  for (size_t i = 0; i < sc_args_count; i++) {-    grpc_subchannel *subchannel = grpc_client_channel_factory_create_subchannel(-        exec_ctx, args->client_channel_factory, &sc_args[i]);-    if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {-      char *address_uri =-          grpc_sockaddr_to_uri(&addresses->addresses[i].address);-      gpr_log(GPR_INFO,-              ""Pick First %p created subchannel %p for address uri %s"",-              (void *)p, (void *)subchannel, address_uri);-      gpr_free(address_uri);+    // Not keeping the previous selected subchannel, so set the latest+    // pending subchannel list to the new subchannel list.  We will wait+    // for it to report READY before swapping it into the current+    // subchannel list.+    if (p->latest_pending_subchannel_list != NULL) {+      if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {+        gpr_log(GPR_DEBUG,+                ""Pick First %p Shutting down latest pending subchannel list ""+                ""%p, about to be replaced by newer latest %p"",+                (void *)p, (void *)p->latest_pending_subchannel_list,+                (void *)subchannel_list);+      }+      grpc_lb_subchannel_list_shutdown_and_unref(+          exec_ctx, p->latest_pending_subchannel_list,+          ""sl_outdated_dont_smash"");     }-    grpc_channel_args_destroy(exec_ctx, (grpc_channel_args *)sc_args[i].args);-    if (subchannel != NULL) new_subchannels[num_new_subchannels++] = subchannel;+    p->latest_pending_subchannel_list = subchannel_list;   }-  gpr_free(sc_args);-  if (num_new_subchannels == 0) {-    gpr_free(new_subchannels);-    // Empty update. Unsubscribe from all current subchannels and put the-    // channel in TRANSIENT_FAILURE.-    grpc_connectivity_state_set(-        exec_ctx, &p->state_tracker, GRPC_CHANNEL_TRANSIENT_FAILURE,-        GRPC_ERROR_CREATE_FROM_STATIC_STRING(""No valid addresses in update""),-        ""pf_update_no_valid_addresses"");-    stop_connectivity_watchers(exec_ctx, p);-    return;-  }--  /* Destroy the current subchannels. Repurpose pf_shutdown/destroy. */-  stop_connectivity_watchers(exec_ctx, p);--  /* Save new subchannels. The switch over will happen in-   * pf_connectivity_changed_locked */-  if (p->updating_selected || p->updating_subchannels) {-    p->num_new_subchannels = num_new_subchannels;-    p->new_subchannels = new_subchannels;-  } else { /* nothing is updating. Get things moving from here */-    p->num_subchannels = num_new_subchannels;-    p->subchannels = new_subchannels;-    p->new_subchannels = NULL;-    p->num_new_subchannels = 0;-    if (p->started_picking) {-      p->checking_subchannel = 0;-      p->checking_connectivity = GRPC_CHANNEL_IDLE;-      grpc_subchannel_notify_on_state_change(-          exec_ctx, p->subchannels[p->checking_subchannel],-          p->base.interested_parties, &p->checking_connectivity,-          &p->connectivity_changed);-    }+  // If we've started picking, start trying to connect to the first+  // subchannel in the new list.+  if (p->started_picking && subchannel_list->num_subchannels > 0) {+    grpc_lb_subchannel_list_ref_for_connectivity_watch(+        subchannel_list, ""connectivity_watch+update"");+    grpc_lb_subchannel_data_start_connectivity_watch(+        exec_ctx, &subchannel_list->subchannels[0]);   } }  static void pf_connectivity_changed_locked(grpc_exec_ctx *exec_ctx, void *arg,                                            grpc_error *error) {-  pick_first_lb_policy *p = (pick_first_lb_policy *)arg;-  grpc_subchannel *selected_subchannel;-  pending_pick *pp;-+  grpc_lb_subchannel_data *sd = (grpc_lb_subchannel_data *)arg;+  pick_first_lb_policy *p = (pick_first_lb_policy *)sd->subchannel_list->policy;   if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {-    gpr_log(-        GPR_DEBUG,-        ""Pick First %p connectivity changed. Updating selected: %d; Updating ""-        ""subchannels: %d; Checking %lu index (%lu total); State: %d; "",-        (void *)p, p->updating_selected, p->updating_subchannels,-        (unsigned long)p->checking_subchannel,-        (unsigned long)p->num_subchannels, p->checking_connectivity);-  }-  bool restart = false;-  if (p->updating_selected && error != GRPC_ERROR_NONE) {-    /* Captured the unsubscription for p->selected */-    GPR_ASSERT(p->selected != NULL);-    GRPC_CONNECTED_SUBCHANNEL_UNREF(exec_ctx, p->selected,-                                    ""pf_update_connectivity"");-    if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {-      gpr_log(GPR_DEBUG, ""Pick First %p unreffing selected subchannel %p"",-              (void *)p, (void *)p->selected);-    }-    p->updating_selected = false;-    if (p->num_new_subchannels == 0) {-      p->selected = NULL;-      return;-    }-    restart = true;+    gpr_log(GPR_DEBUG,+            ""Pick First %p connectivity changed for subchannel %p (%"" PRIdPTR+            "" of %"" PRIdPTR+            ""), subchannel_list %p: state=%s p->shutdown=%d ""+            ""sd->subchannel_list->shutting_down=%d error=%s"",+            (void *)p, (void *)sd->subchannel,+            sd->subchannel_list->checking_subchannel,+            sd->subchannel_list->num_subchannels, (void *)sd->subchannel_list,+            grpc_connectivity_state_name(sd->pending_connectivity_state_unsafe),+            p->shutdown, sd->subchannel_list->shutting_down,+            grpc_error_string(error));   }-  if (p->updating_subchannels && error != GRPC_ERROR_NONE) {-    /* Captured the unsubscription for the checking subchannel */-    GPR_ASSERT(p->selected == NULL);-    for (size_t i = 0; i < p->num_subchannels; i++) {-      GRPC_SUBCHANNEL_UNREF(exec_ctx, p->subchannels[i],-                            ""pf_update_connectivity"");-      if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {-        gpr_log(GPR_DEBUG, ""Pick First %p unreffing subchannel %p"", (void *)p,-                (void *)p->subchannels[i]);-      }-    }-    gpr_free(p->subchannels);-    p->subchannels = NULL;-    p->num_subchannels = 0;-    p->updating_subchannels = false;-    if (p->num_new_subchannels == 0) return;-    restart = true;-  }-  if (restart) {-    p->selected = NULL;-    p->selected_key = NULL;-    GPR_ASSERT(p->new_subchannels != NULL);-    GPR_ASSERT(p->num_new_subchannels > 0);-    p->num_subchannels = p->num_new_subchannels;-    p->subchannels = p->new_subchannels;-    p->num_new_subchannels = 0;-    p->new_subchannels = NULL;-    if (p->started_picking) {-      /* If we were picking, continue to do so over the new subchannels,-       * starting from the 0th index. */-      p->checking_subchannel = 0;-      p->checking_connectivity = GRPC_CHANNEL_IDLE;-      /* reuses the weak ref from start_picking_locked */-      grpc_subchannel_notify_on_state_change(-          exec_ctx, p->subchannels[p->checking_subchannel],-          p->base.interested_parties, &p->checking_connectivity,-          &p->connectivity_changed);-    }-    if (p->pending_update_args != NULL) {-      const grpc_lb_policy_args *args = p->pending_update_args;-      p->pending_update_args = NULL;-      pf_update_locked(exec_ctx, &p->base, args);-    }+  // If the policy is shutting down, unref and return.+  if (p->shutdown) {+    grpc_lb_subchannel_data_stop_connectivity_watch(exec_ctx, sd);+    grpc_lb_subchannel_data_unref_subchannel(exec_ctx, sd, ""pf_shutdown"");+    grpc_lb_subchannel_list_unref_for_connectivity_watch(+        exec_ctx, sd->subchannel_list, ""pf_shutdown"");     return;   }-  GRPC_ERROR_REF(error);-  if (p->shutdown) {-    GRPC_LB_POLICY_WEAK_UNREF(exec_ctx, &p->base, ""pick_first_connectivity"");-    GRPC_ERROR_UNREF(error);+  // If the subchannel list is shutting down, stop watching.+  if (sd->subchannel_list->shutting_down || error == GRPC_ERROR_CANCELLED) {+    grpc_lb_subchannel_data_stop_connectivity_watch(exec_ctx, sd);+    grpc_lb_subchannel_data_unref_subchannel(exec_ctx, sd, ""pf_sl_shutdown"");+    grpc_lb_subchannel_list_unref_for_connectivity_watch(+        exec_ctx, sd->subchannel_list, ""pf_sl_shutdown"");     return;-  } else if (p->selected != NULL) {-    if (p->checking_connectivity == GRPC_CHANNEL_TRANSIENT_FAILURE) {-      /* if the selected channel goes bad, we're done */-      p->checking_connectivity = GRPC_CHANNEL_SHUTDOWN;-    }-    grpc_connectivity_state_set(exec_ctx, &p->state_tracker,-                                p->checking_connectivity, GRPC_ERROR_REF(error),-                                ""selected_changed"");-    if (p->checking_connectivity != GRPC_CHANNEL_SHUTDOWN) {-      grpc_connected_subchannel_notify_on_state_change(-          exec_ctx, p->selected, p->base.interested_parties,-          &p->checking_connectivity, &p->connectivity_changed);+  }+  // If we're still here, the notification must be for a subchannel in+  // either the current or latest pending subchannel lists.+  GPR_ASSERT(sd->subchannel_list == p->subchannel_list ||+             sd->subchannel_list == p->latest_pending_subchannel_list);+  // Update state counters.+  sd->curr_connectivity_state = sd->pending_connectivity_state_unsafe;+  // Handle updates for the currently selected subchannel.+  if (p->selected == sd) {+    // If the new state is anything other than READY and there is a+    // pending update, switch to the pending update.+    if (sd->curr_connectivity_state != GRPC_CHANNEL_READY &&+        p->latest_pending_subchannel_list != NULL) {+      p->selected = NULL;+      grpc_lb_subchannel_list_shutdown_and_unref(+          exec_ctx, p->subchannel_list, ""selected_not_ready+switch_to_update"");+      p->subchannel_list = p->latest_pending_subchannel_list;+      p->latest_pending_subchannel_list = NULL;+      grpc_lb_subchannel_data *new_sd =+          &p->subchannel_list+               ->subchannels[p->subchannel_list->checking_subchannel];+      grpc_connectivity_state_set(+          exec_ctx, &p->state_tracker, new_sd->curr_connectivity_state,","If we set the policy's status to the status of the currently checking subchannel in the pending subchannel list, we may set the policy to `SHUTDOWN` where we may want to set a `GRPC_CHANNEL_TRANSIENT_FAILURE` because we still have other candidates. It might be OK for this PR because we don't prevent shutdown at this moment before my re-resolution PR is merged. ",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/12895,144633820,2017-10-13T19:02:09Z,src/core/ext/transport/chttp2/transport/chttp2_transport.cc,"@@ -638,8 +656,9 @@ static void close_transport_locked(grpc_exec_ctx *exec_ctx,     while (grpc_chttp2_list_pop_writable_stream(t, &s)) {       GRPC_CHTTP2_STREAM_UNREF(exec_ctx, s, ""chttp2_writing:close"");     }-    end_all_the_calls(exec_ctx, t, GRPC_ERROR_REF(error));-    cancel_pings(exec_ctx, t, GRPC_ERROR_REF(error));+    if (t->write_state == GRPC_CHTTP2_WRITE_STATE_IDLE) {",Won't this be unconditionally true from  `if (t->write_state != GRPC_CHTTP2_WRITE_STATE_IDLE) {` on original line 605,
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/12895,144636199,2017-10-13T19:13:58Z,test/core/end2end/tests/shutdown_finishes_calls.c,"@@ -159,7 +159,7 @@ static void test_early_server_shutdown_finishes_inflight_calls(    grpc_server_destroy(f.server); -  GPR_ASSERT(status == GRPC_STATUS_UNAVAILABLE);+  GPR_ASSERT(status == GRPC_STATUS_INTERNAL || status == GRPC_STATUS_UNAVAILABLE);",Why has this one become ambiguous. Is it timing dependent? Add comment if so,
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12878,144637318,2017-10-13T19:19:58Z,src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc,"@@ -758,115 +585,53 @@ static void rr_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,     return;   }   grpc_lb_addresses *addresses = (grpc_lb_addresses *)arg->value.pointer.p;-  rr_subchannel_list *subchannel_list =-      rr_subchannel_list_create(p, addresses->num_addresses);-  if (addresses->num_addresses == 0) {+  grpc_lb_subchannel_list *subchannel_list = grpc_lb_subchannel_list_create(+      exec_ctx, &p->base, &grpc_lb_round_robin_trace, addresses, args,+      rr_connectivity_changed_locked);+  if (subchannel_list->num_subchannels == 0) {     grpc_connectivity_state_set(         exec_ctx, &p->state_tracker, GRPC_CHANNEL_TRANSIENT_FAILURE,         GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Empty update""),         ""rr_update_empty"");     if (p->subchannel_list != NULL) {-      rr_subchannel_list_shutdown_and_unref(exec_ctx, p->subchannel_list,-                                            ""sl_shutdown_empty_update"");+      grpc_lb_subchannel_list_shutdown_and_unref(exec_ctx, p->subchannel_list,+                                                 ""sl_shutdown_empty_update"");     }     p->subchannel_list = subchannel_list;  // empty list     return;   }-  size_t subchannel_index = 0;-  if (p->latest_pending_subchannel_list != NULL && p->started_picking) {-    if (GRPC_TRACER_ON(grpc_lb_round_robin_trace)) {-      gpr_log(GPR_DEBUG,-              ""[RR %p] Shutting down latest pending subchannel list %p, about ""-              ""to be replaced by newer latest %p"",-              (void *)p, (void *)p->latest_pending_subchannel_list,-              (void *)subchannel_list);-    }-    rr_subchannel_list_shutdown_and_unref(-        exec_ctx, p->latest_pending_subchannel_list, ""sl_outdated_dont_smash"");-  }-  p->latest_pending_subchannel_list = subchannel_list;-  grpc_subchannel_args sc_args;-  /* We need to remove the LB addresses in order to be able to compare the-   * subchannel keys of subchannels from a different batch of addresses. */-  static const char *keys_to_remove[] = {GRPC_ARG_SUBCHANNEL_ADDRESS,-                                         GRPC_ARG_LB_ADDRESSES};-  /* Create subchannels for addresses in the update. */-  for (size_t i = 0; i < addresses->num_addresses; i++) {-    // If there were any balancer, we would have chosen grpclb policy instead.-    GPR_ASSERT(!addresses->addresses[i].is_balancer);-    memset(&sc_args, 0, sizeof(grpc_subchannel_args));-    grpc_arg addr_arg =-        grpc_create_subchannel_address_arg(&addresses->addresses[i].address);-    grpc_channel_args *new_args = grpc_channel_args_copy_and_add_and_remove(-        args->args, keys_to_remove, GPR_ARRAY_SIZE(keys_to_remove), &addr_arg,-        1);-    gpr_free(addr_arg.value.string);-    sc_args.args = new_args;-    grpc_subchannel *subchannel = grpc_client_channel_factory_create_subchannel(-        exec_ctx, args->client_channel_factory, &sc_args);-    grpc_channel_args_destroy(exec_ctx, new_args);-    grpc_error *error;-    // Get the connectivity state of the subchannel. Already existing ones may-    // be in a state other than INIT.-    const grpc_connectivity_state subchannel_connectivity_state =-        grpc_subchannel_check_connectivity(subchannel, &error);-    if (error != GRPC_ERROR_NONE) {-      // The subchannel is in error (e.g. shutting down). Ignore it.-      GRPC_SUBCHANNEL_UNREF(exec_ctx, subchannel, ""new_sc_connectivity_error"");-      GRPC_ERROR_UNREF(error);-      continue;-    }-    if (GRPC_TRACER_ON(grpc_lb_round_robin_trace)) {-      char *address_uri =-          grpc_sockaddr_to_uri(&addresses->addresses[i].address);-      gpr_log(-          GPR_DEBUG,-          ""[RR %p] index %lu: Created subchannel %p for address uri %s into ""-          ""subchannel_list %p. Connectivity state %s"",-          (void *)p, (unsigned long)subchannel_index, (void *)subchannel,-          address_uri, (void *)subchannel_list,-          grpc_connectivity_state_name(subchannel_connectivity_state));-      gpr_free(address_uri);-    }-    subchannel_data *sd = &subchannel_list->subchannels[subchannel_index++];-    sd->subchannel_list = subchannel_list;-    sd->subchannel = subchannel;-    GRPC_CLOSURE_INIT(&sd->connectivity_changed_closure,-                      rr_connectivity_changed_locked, sd,-                      grpc_combiner_scheduler(args->combiner));-    /* use some sentinel value outside of the range of-     * grpc_connectivity_state to signal an undefined previous state. We-     * won't be referring to this value again and it'll be overwritten after-     * the first call to rr_connectivity_changed_locked */-    sd->prev_connectivity_state = GRPC_CHANNEL_INIT;-    sd->curr_connectivity_state = subchannel_connectivity_state;-    sd->user_data_vtable = addresses->user_data_vtable;-    if (sd->user_data_vtable != NULL) {-      sd->user_data =-          sd->user_data_vtable->copy(addresses->addresses[i].user_data);+  if (p->started_picking) {+    if (p->latest_pending_subchannel_list != NULL && p->started_picking) {",`p->started_picking` is duplicate and always true here.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12878,144647289,2017-10-13T20:12:58Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -589,76 +490,86 @@ static void pf_connectivity_changed_locked(grpc_exec_ctx *exec_ctx, void *arg,           GRPC_CLOSURE_SCHED(exec_ctx, pp->on_complete, GRPC_ERROR_NONE);           gpr_free(pp);         }-        grpc_connected_subchannel_notify_on_state_change(-            exec_ctx, p->selected, p->base.interested_parties,-            &p->checking_connectivity, &p->connectivity_changed);-        break;-      case GRPC_CHANNEL_TRANSIENT_FAILURE:-        p->checking_subchannel =-            (p->checking_subchannel + 1) % p->num_subchannels;-        if (p->checking_subchannel == 0) {-          /* only trigger transient failure when we've tried all alternatives-           */+        // Renew notification.+        grpc_lb_subchannel_data_start_connectivity_watch(exec_ctx, sd);+        return;+      }+      case GRPC_CHANNEL_TRANSIENT_FAILURE: {+        do {+          sd->subchannel_list->checking_subchannel =+              (sd->subchannel_list->checking_subchannel + 1) %+              sd->subchannel_list->num_subchannels;+          sd = &sd->subchannel_list+                    ->subchannels[sd->subchannel_list->checking_subchannel];+        } while (sd->subchannel == NULL);+        // Case 1: Only set state to TRANSIENT_FAILURE if we've tried+        // all subchannels.+        if (sd->subchannel_list->checking_subchannel == 0 &&+            sd->subchannel_list == p->subchannel_list) {           grpc_connectivity_state_set(               exec_ctx, &p->state_tracker, GRPC_CHANNEL_TRANSIENT_FAILURE,               GRPC_ERROR_REF(error), ""connecting_transient_failure"");         }+        sd->curr_connectivity_state =+            grpc_subchannel_check_connectivity(sd->subchannel, &error);         GRPC_ERROR_UNREF(error);-        p->checking_connectivity = grpc_subchannel_check_connectivity(-            p->subchannels[p->checking_subchannel], &error);-        if (p->checking_connectivity == GRPC_CHANNEL_TRANSIENT_FAILURE) {-          grpc_subchannel_notify_on_state_change(-              exec_ctx, p->subchannels[p->checking_subchannel],-              p->base.interested_parties, &p->checking_connectivity,-              &p->connectivity_changed);-        } else {-          goto loop;+        if (sd->curr_connectivity_state == GRPC_CHANNEL_TRANSIENT_FAILURE) {+          // Reuses the connectivity refs from the previous watch.+          grpc_lb_subchannel_data_start_connectivity_watch(exec_ctx, sd);","The intent of pick_first is that we iterate through the subchannels in the order that the addresses were specified -- that's why it's called pick_first instead of pick_any. :)Also, I think that once a channel goes into state TRANSIENT_FAILURE and we stop watching it, it will not try to connect again until we start watching it again.  So it wouldn't actually help us to check the status of any other channel here, unless we decided to try to connect to all of the subchannels in parallel (which we don't want to do in pick_first, because in the common case where all backends are reachable, we don't want to connect to more than one of them).",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12878,144648183,2017-10-13T20:17:49Z,src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc,"@@ -758,115 +585,53 @@ static void rr_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,     return;   }   grpc_lb_addresses *addresses = (grpc_lb_addresses *)arg->value.pointer.p;-  rr_subchannel_list *subchannel_list =-      rr_subchannel_list_create(p, addresses->num_addresses);-  if (addresses->num_addresses == 0) {+  grpc_lb_subchannel_list *subchannel_list = grpc_lb_subchannel_list_create(+      exec_ctx, &p->base, &grpc_lb_round_robin_trace, addresses, args,+      rr_connectivity_changed_locked);+  if (subchannel_list->num_subchannels == 0) {     grpc_connectivity_state_set(         exec_ctx, &p->state_tracker, GRPC_CHANNEL_TRANSIENT_FAILURE,         GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Empty update""),         ""rr_update_empty"");     if (p->subchannel_list != NULL) {-      rr_subchannel_list_shutdown_and_unref(exec_ctx, p->subchannel_list,-                                            ""sl_shutdown_empty_update"");+      grpc_lb_subchannel_list_shutdown_and_unref(exec_ctx, p->subchannel_list,+                                                 ""sl_shutdown_empty_update"");     }     p->subchannel_list = subchannel_list;  // empty list     return;   }-  size_t subchannel_index = 0;-  if (p->latest_pending_subchannel_list != NULL && p->started_picking) {-    if (GRPC_TRACER_ON(grpc_lb_round_robin_trace)) {-      gpr_log(GPR_DEBUG,-              ""[RR %p] Shutting down latest pending subchannel list %p, about ""-              ""to be replaced by newer latest %p"",-              (void *)p, (void *)p->latest_pending_subchannel_list,-              (void *)subchannel_list);-    }-    rr_subchannel_list_shutdown_and_unref(-        exec_ctx, p->latest_pending_subchannel_list, ""sl_outdated_dont_smash"");-  }-  p->latest_pending_subchannel_list = subchannel_list;-  grpc_subchannel_args sc_args;-  /* We need to remove the LB addresses in order to be able to compare the-   * subchannel keys of subchannels from a different batch of addresses. */-  static const char *keys_to_remove[] = {GRPC_ARG_SUBCHANNEL_ADDRESS,-                                         GRPC_ARG_LB_ADDRESSES};-  /* Create subchannels for addresses in the update. */-  for (size_t i = 0; i < addresses->num_addresses; i++) {-    // If there were any balancer, we would have chosen grpclb policy instead.-    GPR_ASSERT(!addresses->addresses[i].is_balancer);-    memset(&sc_args, 0, sizeof(grpc_subchannel_args));-    grpc_arg addr_arg =-        grpc_create_subchannel_address_arg(&addresses->addresses[i].address);-    grpc_channel_args *new_args = grpc_channel_args_copy_and_add_and_remove(-        args->args, keys_to_remove, GPR_ARRAY_SIZE(keys_to_remove), &addr_arg,-        1);-    gpr_free(addr_arg.value.string);-    sc_args.args = new_args;-    grpc_subchannel *subchannel = grpc_client_channel_factory_create_subchannel(-        exec_ctx, args->client_channel_factory, &sc_args);-    grpc_channel_args_destroy(exec_ctx, new_args);-    grpc_error *error;-    // Get the connectivity state of the subchannel. Already existing ones may-    // be in a state other than INIT.-    const grpc_connectivity_state subchannel_connectivity_state =-        grpc_subchannel_check_connectivity(subchannel, &error);-    if (error != GRPC_ERROR_NONE) {-      // The subchannel is in error (e.g. shutting down). Ignore it.-      GRPC_SUBCHANNEL_UNREF(exec_ctx, subchannel, ""new_sc_connectivity_error"");-      GRPC_ERROR_UNREF(error);-      continue;-    }-    if (GRPC_TRACER_ON(grpc_lb_round_robin_trace)) {-      char *address_uri =-          grpc_sockaddr_to_uri(&addresses->addresses[i].address);-      gpr_log(-          GPR_DEBUG,-          ""[RR %p] index %lu: Created subchannel %p for address uri %s into ""-          ""subchannel_list %p. Connectivity state %s"",-          (void *)p, (unsigned long)subchannel_index, (void *)subchannel,-          address_uri, (void *)subchannel_list,-          grpc_connectivity_state_name(subchannel_connectivity_state));-      gpr_free(address_uri);-    }-    subchannel_data *sd = &subchannel_list->subchannels[subchannel_index++];-    sd->subchannel_list = subchannel_list;-    sd->subchannel = subchannel;-    GRPC_CLOSURE_INIT(&sd->connectivity_changed_closure,-                      rr_connectivity_changed_locked, sd,-                      grpc_combiner_scheduler(args->combiner));-    /* use some sentinel value outside of the range of-     * grpc_connectivity_state to signal an undefined previous state. We-     * won't be referring to this value again and it'll be overwritten after-     * the first call to rr_connectivity_changed_locked */-    sd->prev_connectivity_state = GRPC_CHANNEL_INIT;-    sd->curr_connectivity_state = subchannel_connectivity_state;-    sd->user_data_vtable = addresses->user_data_vtable;-    if (sd->user_data_vtable != NULL) {-      sd->user_data =-          sd->user_data_vtable->copy(addresses->addresses[i].user_data);+  if (p->started_picking) {+    if (p->latest_pending_subchannel_list != NULL && p->started_picking) {+      if (GRPC_TRACER_ON(grpc_lb_round_robin_trace)) {+        gpr_log(GPR_DEBUG,+                ""[RR %p] Shutting down latest pending subchannel list %p, ""+                ""about to be replaced by newer latest %p"",+                (void *)p, (void *)p->latest_pending_subchannel_list,+                (void *)subchannel_list);+      }+      grpc_lb_subchannel_list_shutdown_and_unref(+          exec_ctx, p->latest_pending_subchannel_list,+          ""sl_outdated_dont_smash"");","I just kept the existing name here.  I assume it means that we want to destroy the outdated update before we replace it.  But I agree that it's sort of redundant, since it's clear from the code that we're unreffing the subchannel list.I've changed the reason to just ""sl_outdated"".",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12878,144650275,2017-10-13T20:29:41Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -317,270 +260,228 @@ static void pf_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,   }   const grpc_lb_addresses *addresses =       (const grpc_lb_addresses *)arg->value.pointer.p;-  if (addresses->num_addresses == 0) {-    // Empty update. Unsubscribe from all current subchannels and put the-    // channel in TRANSIENT_FAILURE.+  if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {+    gpr_log(GPR_INFO, ""Pick First %p received update with %lu addresses"",+            (void *)p, (unsigned long)addresses->num_addresses);+  }+  grpc_lb_subchannel_list *subchannel_list = grpc_lb_subchannel_list_create(+      exec_ctx, &p->base, &grpc_lb_pick_first_trace, addresses, args,+      pf_connectivity_changed_locked);+  if (subchannel_list->num_subchannels == 0) {+    // Empty update or no valid subchannels. Unsubscribe from all current+    // subchannels and put the channel in TRANSIENT_FAILURE.     grpc_connectivity_state_set(         exec_ctx, &p->state_tracker, GRPC_CHANNEL_TRANSIENT_FAILURE,         GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Empty update""),         ""pf_update_empty"");-    stop_connectivity_watchers(exec_ctx, p);+    if (p->subchannel_list != NULL) {+      grpc_lb_subchannel_list_shutdown_and_unref(exec_ctx, p->subchannel_list,+                                                 ""sl_shutdown_empty_update"");+    }+    p->subchannel_list = subchannel_list;  // Empty list.+    p->selected = NULL;     return;   }-  if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {-    gpr_log(GPR_INFO, ""Pick First %p received update with %lu addresses"",-            (void *)p, (unsigned long)addresses->num_addresses);-  }-  grpc_subchannel_args *sc_args = (grpc_subchannel_args *)gpr_zalloc(-      sizeof(*sc_args) * addresses->num_addresses);-  /* We remove the following keys in order for subchannel keys belonging to-   * subchannels point to the same address to match. */-  static const char *keys_to_remove[] = {GRPC_ARG_SUBCHANNEL_ADDRESS,-                                         GRPC_ARG_LB_ADDRESSES};-  size_t sc_args_count = 0;--  /* Create list of subchannel args for new addresses in \a args. */-  for (size_t i = 0; i < addresses->num_addresses; i++) {-    // If there were any balancer, we would have chosen grpclb policy instead.-    GPR_ASSERT(!addresses->addresses[i].is_balancer);-    if (addresses->addresses[i].user_data != NULL) {-      gpr_log(GPR_ERROR,-              ""This LB policy doesn't support user data. It will be ignored"");+  if (p->selected == NULL) {+    // We don't yet have a selected subchannel, so replace the current+    // subchannel list immediately.+    if (p->subchannel_list != NULL) {+      grpc_lb_subchannel_list_shutdown_and_unref(exec_ctx, p->subchannel_list,+                                                 ""pf_update_before_selected"");     }-    grpc_arg addr_arg =-        grpc_create_subchannel_address_arg(&addresses->addresses[i].address);-    grpc_channel_args *new_args = grpc_channel_args_copy_and_add_and_remove(-        args->args, keys_to_remove, GPR_ARRAY_SIZE(keys_to_remove), &addr_arg,-        1);-    gpr_free(addr_arg.value.string);-    sc_args[sc_args_count++].args = new_args;-  }--  /* Check if p->selected is amongst them. If so, we are done. */-  if (p->selected != NULL) {-    GPR_ASSERT(p->selected_key != NULL);-    for (size_t i = 0; i < sc_args_count; i++) {-      grpc_subchannel_key *ith_sc_key = grpc_subchannel_key_create(&sc_args[i]);-      const bool found_selected =-          grpc_subchannel_key_compare(p->selected_key, ith_sc_key) == 0;-      grpc_subchannel_key_destroy(exec_ctx, ith_sc_key);-      if (found_selected) {+    p->subchannel_list = subchannel_list;+  } else {+    // We do have a selected subchannel.+    // Check if it's present in the new list.  If so, we're done.+    for (size_t i = 0; i < subchannel_list->num_subchannels; ++i) {+      grpc_lb_subchannel_data *sd = &subchannel_list->subchannels[i];+      if (sd->subchannel == p->selected->subchannel) {         // The currently selected subchannel is in the update: we are done.         if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {           gpr_log(GPR_INFO,-                  ""Pick First %p found already selected subchannel %p amongst ""-                  ""updates. Update done."",-                  (void *)p, (void *)p->selected);+                  ""Pick First %p found already selected subchannel %p ""+                  ""at update index %"" PRIdPTR "" of %"" PRIdPTR ""; update done"",+                  p, p->selected->subchannel, i,+                  subchannel_list->num_subchannels);         }-        for (size_t j = 0; j < sc_args_count; j++) {-          grpc_channel_args_destroy(exec_ctx,-                                    (grpc_channel_args *)sc_args[j].args);+        grpc_lb_subchannel_list_ref_for_connectivity_watch(+            subchannel_list, ""connectivity_watch+replace_selected"");+        grpc_lb_subchannel_data_start_connectivity_watch(exec_ctx, sd);+        if (p->subchannel_list != NULL) {+          grpc_lb_subchannel_list_shutdown_and_unref(+              exec_ctx, p->subchannel_list, ""pf_update_includes_selected"");+        }+        p->subchannel_list = subchannel_list;+        if (p->selected->connected_subchannel != NULL) {+          sd->connected_subchannel = GRPC_CONNECTED_SUBCHANNEL_REF(+              grpc_subchannel_get_connected_subchannel(sd->subchannel),+              ""pf_update_includes_selected"");+        }+        p->selected = sd;+        destroy_unselected_subchannels_locked(exec_ctx, p);+        // If there was a previously pending update (which may or may+        // not have contained the currently selected subchannel), drop+        // it, so that it doesn't override what we've done here.+        if (p->latest_pending_subchannel_list != NULL) {+          grpc_lb_subchannel_list_shutdown_and_unref(+              exec_ctx, p->latest_pending_subchannel_list,+              ""pf_update_includes_selected+outdated"");+          p->latest_pending_subchannel_list = NULL;         }-        gpr_free(sc_args);         return;       }     }-  }-  // We only check for already running updates here because if the previous-  // steps were successful, the update can be considered done without any-  // interference (ie, no callbacks were scheduled).-  if (p->updating_selected || p->updating_subchannels) {-    if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {-      gpr_log(GPR_INFO,-              ""Update already in progress for pick first %p. Deferring update."",-              (void *)p);-    }-    if (p->pending_update_args != NULL) {-      grpc_channel_args_destroy(exec_ctx, p->pending_update_args->args);-      gpr_free(p->pending_update_args);-    }-    p->pending_update_args =-        (grpc_lb_policy_args *)gpr_zalloc(sizeof(*p->pending_update_args));-    p->pending_update_args->client_channel_factory =-        args->client_channel_factory;-    p->pending_update_args->args = grpc_channel_args_copy(args->args);-    p->pending_update_args->combiner = args->combiner;-    return;-  }-  /* Create the subchannels for the new subchannel args/addresses. */-  grpc_subchannel **new_subchannels =-      (grpc_subchannel **)gpr_zalloc(sizeof(*new_subchannels) * sc_args_count);-  size_t num_new_subchannels = 0;-  for (size_t i = 0; i < sc_args_count; i++) {-    grpc_subchannel *subchannel = grpc_client_channel_factory_create_subchannel(-        exec_ctx, args->client_channel_factory, &sc_args[i]);-    if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {-      char *address_uri =-          grpc_sockaddr_to_uri(&addresses->addresses[i].address);-      gpr_log(GPR_INFO,-              ""Pick First %p created subchannel %p for address uri %s"",-              (void *)p, (void *)subchannel, address_uri);-      gpr_free(address_uri);+    // Not keeping the previous selected subchannel, so set the latest+    // pending subchannel list to the new subchannel list.  We will wait+    // for it to report READY before swapping it into the current+    // subchannel list.+    if (p->latest_pending_subchannel_list != NULL) {+      if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {+        gpr_log(GPR_DEBUG,+                ""Pick First %p Shutting down latest pending subchannel list ""+                ""%p, about to be replaced by newer latest %p"",+                (void *)p, (void *)p->latest_pending_subchannel_list,+                (void *)subchannel_list);+      }+      grpc_lb_subchannel_list_shutdown_and_unref(+          exec_ctx, p->latest_pending_subchannel_list,+          ""sl_outdated_dont_smash"");     }-    grpc_channel_args_destroy(exec_ctx, (grpc_channel_args *)sc_args[i].args);-    if (subchannel != NULL) new_subchannels[num_new_subchannels++] = subchannel;+    p->latest_pending_subchannel_list = subchannel_list;   }-  gpr_free(sc_args);-  if (num_new_subchannels == 0) {-    gpr_free(new_subchannels);-    // Empty update. Unsubscribe from all current subchannels and put the-    // channel in TRANSIENT_FAILURE.-    grpc_connectivity_state_set(-        exec_ctx, &p->state_tracker, GRPC_CHANNEL_TRANSIENT_FAILURE,-        GRPC_ERROR_CREATE_FROM_STATIC_STRING(""No valid addresses in update""),-        ""pf_update_no_valid_addresses"");-    stop_connectivity_watchers(exec_ctx, p);-    return;-  }--  /* Destroy the current subchannels. Repurpose pf_shutdown/destroy. */-  stop_connectivity_watchers(exec_ctx, p);--  /* Save new subchannels. The switch over will happen in-   * pf_connectivity_changed_locked */-  if (p->updating_selected || p->updating_subchannels) {-    p->num_new_subchannels = num_new_subchannels;-    p->new_subchannels = new_subchannels;-  } else { /* nothing is updating. Get things moving from here */-    p->num_subchannels = num_new_subchannels;-    p->subchannels = new_subchannels;-    p->new_subchannels = NULL;-    p->num_new_subchannels = 0;-    if (p->started_picking) {-      p->checking_subchannel = 0;-      p->checking_connectivity = GRPC_CHANNEL_IDLE;-      grpc_subchannel_notify_on_state_change(-          exec_ctx, p->subchannels[p->checking_subchannel],-          p->base.interested_parties, &p->checking_connectivity,-          &p->connectivity_changed);-    }+  // If we've started picking, start trying to connect to the first+  // subchannel in the new list.+  if (p->started_picking && subchannel_list->num_subchannels > 0) {+    grpc_lb_subchannel_list_ref_for_connectivity_watch(+        subchannel_list, ""connectivity_watch+update"");+    grpc_lb_subchannel_data_start_connectivity_watch(+        exec_ctx, &subchannel_list->subchannels[0]);   } }  static void pf_connectivity_changed_locked(grpc_exec_ctx *exec_ctx, void *arg,                                            grpc_error *error) {-  pick_first_lb_policy *p = (pick_first_lb_policy *)arg;-  grpc_subchannel *selected_subchannel;-  pending_pick *pp;-+  grpc_lb_subchannel_data *sd = (grpc_lb_subchannel_data *)arg;+  pick_first_lb_policy *p = (pick_first_lb_policy *)sd->subchannel_list->policy;   if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {-    gpr_log(-        GPR_DEBUG,-        ""Pick First %p connectivity changed. Updating selected: %d; Updating ""-        ""subchannels: %d; Checking %lu index (%lu total); State: %d; "",-        (void *)p, p->updating_selected, p->updating_subchannels,-        (unsigned long)p->checking_subchannel,-        (unsigned long)p->num_subchannels, p->checking_connectivity);-  }-  bool restart = false;-  if (p->updating_selected && error != GRPC_ERROR_NONE) {-    /* Captured the unsubscription for p->selected */-    GPR_ASSERT(p->selected != NULL);-    GRPC_CONNECTED_SUBCHANNEL_UNREF(exec_ctx, p->selected,-                                    ""pf_update_connectivity"");-    if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {-      gpr_log(GPR_DEBUG, ""Pick First %p unreffing selected subchannel %p"",-              (void *)p, (void *)p->selected);-    }-    p->updating_selected = false;-    if (p->num_new_subchannels == 0) {-      p->selected = NULL;-      return;-    }-    restart = true;+    gpr_log(GPR_DEBUG,+            ""Pick First %p connectivity changed for subchannel %p (%"" PRIdPTR+            "" of %"" PRIdPTR+            ""), subchannel_list %p: state=%s p->shutdown=%d ""+            ""sd->subchannel_list->shutting_down=%d error=%s"",+            (void *)p, (void *)sd->subchannel,+            sd->subchannel_list->checking_subchannel,+            sd->subchannel_list->num_subchannels, (void *)sd->subchannel_list,+            grpc_connectivity_state_name(sd->pending_connectivity_state_unsafe),+            p->shutdown, sd->subchannel_list->shutting_down,+            grpc_error_string(error));   }-  if (p->updating_subchannels && error != GRPC_ERROR_NONE) {-    /* Captured the unsubscription for the checking subchannel */-    GPR_ASSERT(p->selected == NULL);-    for (size_t i = 0; i < p->num_subchannels; i++) {-      GRPC_SUBCHANNEL_UNREF(exec_ctx, p->subchannels[i],-                            ""pf_update_connectivity"");-      if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {-        gpr_log(GPR_DEBUG, ""Pick First %p unreffing subchannel %p"", (void *)p,-                (void *)p->subchannels[i]);-      }-    }-    gpr_free(p->subchannels);-    p->subchannels = NULL;-    p->num_subchannels = 0;-    p->updating_subchannels = false;-    if (p->num_new_subchannels == 0) return;-    restart = true;-  }-  if (restart) {-    p->selected = NULL;-    p->selected_key = NULL;-    GPR_ASSERT(p->new_subchannels != NULL);-    GPR_ASSERT(p->num_new_subchannels > 0);-    p->num_subchannels = p->num_new_subchannels;-    p->subchannels = p->new_subchannels;-    p->num_new_subchannels = 0;-    p->new_subchannels = NULL;-    if (p->started_picking) {-      /* If we were picking, continue to do so over the new subchannels,-       * starting from the 0th index. */-      p->checking_subchannel = 0;-      p->checking_connectivity = GRPC_CHANNEL_IDLE;-      /* reuses the weak ref from start_picking_locked */-      grpc_subchannel_notify_on_state_change(-          exec_ctx, p->subchannels[p->checking_subchannel],-          p->base.interested_parties, &p->checking_connectivity,-          &p->connectivity_changed);-    }-    if (p->pending_update_args != NULL) {-      const grpc_lb_policy_args *args = p->pending_update_args;-      p->pending_update_args = NULL;-      pf_update_locked(exec_ctx, &p->base, args);-    }+  // If the policy is shutting down, unref and return.+  if (p->shutdown) {+    grpc_lb_subchannel_data_stop_connectivity_watch(exec_ctx, sd);+    grpc_lb_subchannel_data_unref_subchannel(exec_ctx, sd, ""pf_shutdown"");+    grpc_lb_subchannel_list_unref_for_connectivity_watch(+        exec_ctx, sd->subchannel_list, ""pf_shutdown"");     return;   }-  GRPC_ERROR_REF(error);-  if (p->shutdown) {-    GRPC_LB_POLICY_WEAK_UNREF(exec_ctx, &p->base, ""pick_first_connectivity"");-    GRPC_ERROR_UNREF(error);+  // If the subchannel list is shutting down, stop watching.+  if (sd->subchannel_list->shutting_down || error == GRPC_ERROR_CANCELLED) {+    grpc_lb_subchannel_data_stop_connectivity_watch(exec_ctx, sd);+    grpc_lb_subchannel_data_unref_subchannel(exec_ctx, sd, ""pf_sl_shutdown"");+    grpc_lb_subchannel_list_unref_for_connectivity_watch(+        exec_ctx, sd->subchannel_list, ""pf_sl_shutdown"");     return;-  } else if (p->selected != NULL) {-    if (p->checking_connectivity == GRPC_CHANNEL_TRANSIENT_FAILURE) {-      /* if the selected channel goes bad, we're done */-      p->checking_connectivity = GRPC_CHANNEL_SHUTDOWN;-    }-    grpc_connectivity_state_set(exec_ctx, &p->state_tracker,-                                p->checking_connectivity, GRPC_ERROR_REF(error),-                                ""selected_changed"");-    if (p->checking_connectivity != GRPC_CHANNEL_SHUTDOWN) {-      grpc_connected_subchannel_notify_on_state_change(-          exec_ctx, p->selected, p->base.interested_parties,-          &p->checking_connectivity, &p->connectivity_changed);+  }+  // If we're still here, the notification must be for a subchannel in+  // either the current or latest pending subchannel lists.+  GPR_ASSERT(sd->subchannel_list == p->subchannel_list ||+             sd->subchannel_list == p->latest_pending_subchannel_list);+  // Update state counters.+  sd->curr_connectivity_state = sd->pending_connectivity_state_unsafe;+  // Handle updates for the currently selected subchannel.+  if (p->selected == sd) {+    // If the new state is anything other than READY and there is a+    // pending update, switch to the pending update.+    if (sd->curr_connectivity_state != GRPC_CHANNEL_READY &&+        p->latest_pending_subchannel_list != NULL) {+      p->selected = NULL;+      grpc_lb_subchannel_list_shutdown_and_unref(+          exec_ctx, p->subchannel_list, ""selected_not_ready+switch_to_update"");+      p->subchannel_list = p->latest_pending_subchannel_list;+      p->latest_pending_subchannel_list = NULL;+      grpc_lb_subchannel_data *new_sd =+          &p->subchannel_list+               ->subchannels[p->subchannel_list->checking_subchannel];+      grpc_connectivity_state_set(+          exec_ctx, &p->state_tracker, new_sd->curr_connectivity_state,","Whoops, I somehow missed this comment in my last pass.We only execute this code if `p->selected == sd`, meaning that we've already chosen a subchannel (because it went into READY state) and this is an update for that subchannel.  In the current code, when we choose a subchannel, we unref all of the other subchannels in the subchannel list, thus committing to using only the selected subchannel, at least until we get a new update.  Thus, if the selected subchannel goes into state SHUTDOWN, we have no choice but to put ourselves in that state.There are two future changes that will improve this.  One of them is your PR to have the LB policy request re-resolution without putting itself in state SHUTDOWN, and I would expect your PR to modify the code in this location (indeed, I think it's already doing the right thing in this case, although you'll have to retain that when you merge the changes from this PR).  The other future change that I would like to make is to change pick_first to keep the other subchannels around so that it can try some of the other addresses if the originally selected address fails and we have not yet received an update.  But that will be done in a future PR.For this PR, I am leaving the existing logic here essentially the same.",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/12895,144651126,2017-10-13T20:33:49Z,src/core/ext/transport/chttp2/transport/chttp2_transport.cc,"@@ -2560,11 +2583,19 @@ static void read_action_locked(grpc_exec_ctx *exec_ctx, void *tp,   GPR_TIMER_END(""reading_action_locked"", 0); } +static void schedule_bdp_ping_locked(grpc_exec_ctx *exec_ctx,","We ref prior to calling this the first time, and unref once the chain completes... I'll add a comment.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12878,144652612,2017-10-13T20:41:52Z,src/core/ext/filters/client_channel/lb_policy/subchannel_list.cc,"@@ -0,0 +1,286 @@+/*+ *+ * Copyright 2015 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <string.h>++#include <grpc/support/alloc.h>++#include ""src/core/ext/filters/client_channel/lb_policy/subchannel_list.h""+#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/debug/trace.h""+#include ""src/core/lib/iomgr/closure.h""+#include ""src/core/lib/iomgr/combiner.h""+#include ""src/core/lib/iomgr/sockaddr_utils.h""+#include ""src/core/lib/transport/connectivity_state.h""++void grpc_lb_subchannel_data_unref_subchannel(grpc_exec_ctx *exec_ctx,+                                              grpc_lb_subchannel_data *sd,+                                              const char *reason) {+  if (sd->subchannel != NULL) {+    if (GRPC_TRACER_ON(*sd->subchannel_list->tracer)) {+      gpr_log(+          GPR_DEBUG, ""[%s %p] subchannel list %p index %"" PRIdPTR+                     "" of %"" PRIdPTR "" (subchannel %p): unreffing subchannel"",+          sd->subchannel_list->tracer->name, sd->subchannel_list->policy,+          sd->subchannel_list, (size_t)(sd - sd->subchannel_list->subchannels),+          sd->subchannel_list->num_subchannels, sd->subchannel);+    }+    GRPC_SUBCHANNEL_UNREF(exec_ctx, sd->subchannel, reason);+    sd->subchannel = NULL;+    if (sd->connected_subchannel != NULL) {+      GRPC_CONNECTED_SUBCHANNEL_UNREF(exec_ctx, sd->connected_subchannel,+                                      reason);+      sd->connected_subchannel = NULL;+    }+    if (sd->user_data != NULL) {+      GPR_ASSERT(sd->user_data_vtable != NULL);+      sd->user_data_vtable->destroy(exec_ctx, sd->user_data);+      sd->user_data = NULL;+    }+  }+}++void grpc_lb_subchannel_data_start_connectivity_watch(+    grpc_exec_ctx *exec_ctx, grpc_lb_subchannel_data *sd) {+  if (GRPC_TRACER_ON(*sd->subchannel_list->tracer)) {+    gpr_log(GPR_DEBUG,+            ""[%s %p] subchannel list %p index %"" PRIdPTR "" of %"" PRIdPTR+            "" (subchannel %p): requesting connectivity change notification"",+            sd->subchannel_list->tracer->name, sd->subchannel_list->policy,+            sd->subchannel_list,+            (size_t)(sd - sd->subchannel_list->subchannels),+            sd->subchannel_list->num_subchannels, sd->subchannel);+  }+  sd->connectivity_notification_pending = true;+  grpc_subchannel_notify_on_state_change(+      exec_ctx, sd->subchannel, sd->subchannel_list->policy->interested_parties,+      &sd->pending_connectivity_state_unsafe,+      &sd->connectivity_changed_closure);+}++void grpc_lb_subchannel_data_stop_connectivity_watch(+    grpc_exec_ctx *exec_ctx, grpc_lb_subchannel_data *sd) {+  if (GRPC_TRACER_ON(*sd->subchannel_list->tracer)) {+    gpr_log(+        GPR_DEBUG, ""[%s %p] subchannel list %p index %"" PRIdPTR "" of %"" PRIdPTR+                   "" (subchannel %p): stopping connectivity watch"",+        sd->subchannel_list->tracer->name, sd->subchannel_list->policy,+        sd->subchannel_list, (size_t)(sd - sd->subchannel_list->subchannels),+        sd->subchannel_list->num_subchannels, sd->subchannel);+  }+  GPR_ASSERT(sd->connectivity_notification_pending);+  sd->connectivity_notification_pending = false;+}++grpc_lb_subchannel_list *grpc_lb_subchannel_list_create(+    grpc_exec_ctx *exec_ctx, grpc_lb_policy *p, grpc_tracer_flag *tracer,+    const grpc_lb_addresses *addresses, const grpc_lb_policy_args *args,+    grpc_iomgr_cb_func connectivity_changed_cb) {+  grpc_lb_subchannel_list *subchannel_list =+      (grpc_lb_subchannel_list *)gpr_zalloc(sizeof(*subchannel_list));+  if (GRPC_TRACER_ON(*tracer)) {+    gpr_log(GPR_DEBUG,+            ""[%s %p] Creating subchannel list %p for %"" PRIdPTR "" subchannels"",+            tracer->name, p, subchannel_list, addresses->num_addresses);+  }+  subchannel_list->policy = p;+  subchannel_list->tracer = tracer;+  gpr_ref_init(&subchannel_list->refcount, 1);+  subchannel_list->subchannels = (grpc_lb_subchannel_data *)gpr_zalloc(+      sizeof(grpc_lb_subchannel_data) * addresses->num_addresses);+  /* We need to remove the LB addresses in order to be able to compare the+   * subchannel keys of subchannels from a different batch of addresses. */+  static const char *keys_to_remove[] = {GRPC_ARG_SUBCHANNEL_ADDRESS,+                                         GRPC_ARG_LB_ADDRESSES};+  /* Create subchannels for addresses in the update. */+  grpc_subchannel_args sc_args;+  size_t subchannel_index = 0;+  for (size_t i = 0; i < addresses->num_addresses; i++) {+    // If there were any balancer, we would have chosen grpclb policy instead.+    GPR_ASSERT(!addresses->addresses[i].is_balancer);+    memset(&sc_args, 0, sizeof(grpc_subchannel_args));+    grpc_arg addr_arg =+        grpc_create_subchannel_address_arg(&addresses->addresses[i].address);+    grpc_channel_args *new_args = grpc_channel_args_copy_and_add_and_remove(+        args->args, keys_to_remove, GPR_ARRAY_SIZE(keys_to_remove), &addr_arg,+        1);+    gpr_free(addr_arg.value.string);+    sc_args.args = new_args;+    grpc_subchannel *subchannel = grpc_client_channel_factory_create_subchannel(+        exec_ctx, args->client_channel_factory, &sc_args);+    grpc_channel_args_destroy(exec_ctx, new_args);+    if (subchannel == NULL) {+      // Subchannel could not be created.+      if (GRPC_TRACER_ON(*tracer)) {+        char *address_uri =+            grpc_sockaddr_to_uri(&addresses->addresses[i].address);+        gpr_log(GPR_DEBUG,+                ""[%s %p] could not create subchannel for address uri %s, ""+                ""ignoring"",+                tracer->name, subchannel_list->policy, address_uri);+        gpr_free(address_uri);+      }+      continue;+    }+    grpc_error *error;+    // Get the connectivity state of the subchannel. Already existing ones may+    // be in a state other than INIT.+    const grpc_connectivity_state subchannel_connectivity_state =+        grpc_subchannel_check_connectivity(subchannel, &error);+    if (error != GRPC_ERROR_NONE) {+      // The subchannel is in error (e.g. shutting down). Ignore it.+      if (GRPC_TRACER_ON(*tracer)) {+        char *address_uri =+            grpc_sockaddr_to_uri(&addresses->addresses[i].address);+        gpr_log(GPR_DEBUG,+                ""[%s %p] subchannel for address uri %s shutting down, ignoring"",+                tracer->name, subchannel_list->policy, address_uri);+        gpr_free(address_uri);+      }+      GRPC_SUBCHANNEL_UNREF(exec_ctx, subchannel, ""new_sc_connectivity_error"");+      GRPC_ERROR_UNREF(error);+      continue;+    }+    if (GRPC_TRACER_ON(*tracer)) {+      char *address_uri =+          grpc_sockaddr_to_uri(&addresses->addresses[i].address);+      gpr_log(GPR_DEBUG, ""[%s %p] subchannel list %p index %"" PRIdPTR+                         "": Created subchannel %p for address uri %s; ""+                         ""initial connectivity state: %s"",+              tracer->name, p, subchannel_list, subchannel_index, subchannel,+              address_uri,+              grpc_connectivity_state_name(subchannel_connectivity_state));+      gpr_free(address_uri);+    }+    grpc_lb_subchannel_data *sd =+        &subchannel_list->subchannels[subchannel_index++];+    sd->subchannel_list = subchannel_list;+    sd->subchannel = subchannel;+    GRPC_CLOSURE_INIT(&sd->connectivity_changed_closure,+                      connectivity_changed_cb, sd,+                      grpc_combiner_scheduler(args->combiner));+    /* use some sentinel value outside of the range of+     * grpc_connectivity_state to signal an undefined previous state. We+     * won't be referring to this value again and it'll be overwritten after+     * the first call to rr_connectivity_changed_locked */+    sd->prev_connectivity_state = GRPC_CHANNEL_INIT;+    sd->curr_connectivity_state = subchannel_connectivity_state;+    sd->user_data_vtable = addresses->user_data_vtable;+    if (sd->user_data_vtable != NULL) {+      sd->user_data =+          sd->user_data_vtable->copy(addresses->addresses[i].user_data);+    }+  }+  subchannel_list->num_subchannels = subchannel_index;+  return subchannel_list;+}++static void subchannel_list_destroy(grpc_exec_ctx *exec_ctx,","Yes, it doesn't need to. But please note that `grpc_lb_subchannel_data_cancel_connectivity_watch()` in this file is the other static function, and `subchannel_list_destroy()` is the only function without the `grpc_lb_` prefix. ",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12878,144655611,2017-10-13T20:57:55Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -317,270 +260,228 @@ static void pf_update_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *policy,   }   const grpc_lb_addresses *addresses =       (const grpc_lb_addresses *)arg->value.pointer.p;-  if (addresses->num_addresses == 0) {-    // Empty update. Unsubscribe from all current subchannels and put the-    // channel in TRANSIENT_FAILURE.+  if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {+    gpr_log(GPR_INFO, ""Pick First %p received update with %lu addresses"",+            (void *)p, (unsigned long)addresses->num_addresses);+  }+  grpc_lb_subchannel_list *subchannel_list = grpc_lb_subchannel_list_create(+      exec_ctx, &p->base, &grpc_lb_pick_first_trace, addresses, args,+      pf_connectivity_changed_locked);+  if (subchannel_list->num_subchannels == 0) {+    // Empty update or no valid subchannels. Unsubscribe from all current+    // subchannels and put the channel in TRANSIENT_FAILURE.     grpc_connectivity_state_set(         exec_ctx, &p->state_tracker, GRPC_CHANNEL_TRANSIENT_FAILURE,         GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Empty update""),         ""pf_update_empty"");-    stop_connectivity_watchers(exec_ctx, p);+    if (p->subchannel_list != NULL) {+      grpc_lb_subchannel_list_shutdown_and_unref(exec_ctx, p->subchannel_list,+                                                 ""sl_shutdown_empty_update"");+    }+    p->subchannel_list = subchannel_list;  // Empty list.+    p->selected = NULL;     return;   }-  if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {-    gpr_log(GPR_INFO, ""Pick First %p received update with %lu addresses"",-            (void *)p, (unsigned long)addresses->num_addresses);-  }-  grpc_subchannel_args *sc_args = (grpc_subchannel_args *)gpr_zalloc(-      sizeof(*sc_args) * addresses->num_addresses);-  /* We remove the following keys in order for subchannel keys belonging to-   * subchannels point to the same address to match. */-  static const char *keys_to_remove[] = {GRPC_ARG_SUBCHANNEL_ADDRESS,-                                         GRPC_ARG_LB_ADDRESSES};-  size_t sc_args_count = 0;--  /* Create list of subchannel args for new addresses in \a args. */-  for (size_t i = 0; i < addresses->num_addresses; i++) {-    // If there were any balancer, we would have chosen grpclb policy instead.-    GPR_ASSERT(!addresses->addresses[i].is_balancer);-    if (addresses->addresses[i].user_data != NULL) {-      gpr_log(GPR_ERROR,-              ""This LB policy doesn't support user data. It will be ignored"");+  if (p->selected == NULL) {+    // We don't yet have a selected subchannel, so replace the current+    // subchannel list immediately.+    if (p->subchannel_list != NULL) {+      grpc_lb_subchannel_list_shutdown_and_unref(exec_ctx, p->subchannel_list,+                                                 ""pf_update_before_selected"");     }-    grpc_arg addr_arg =-        grpc_create_subchannel_address_arg(&addresses->addresses[i].address);-    grpc_channel_args *new_args = grpc_channel_args_copy_and_add_and_remove(-        args->args, keys_to_remove, GPR_ARRAY_SIZE(keys_to_remove), &addr_arg,-        1);-    gpr_free(addr_arg.value.string);-    sc_args[sc_args_count++].args = new_args;-  }--  /* Check if p->selected is amongst them. If so, we are done. */-  if (p->selected != NULL) {-    GPR_ASSERT(p->selected_key != NULL);-    for (size_t i = 0; i < sc_args_count; i++) {-      grpc_subchannel_key *ith_sc_key = grpc_subchannel_key_create(&sc_args[i]);-      const bool found_selected =-          grpc_subchannel_key_compare(p->selected_key, ith_sc_key) == 0;-      grpc_subchannel_key_destroy(exec_ctx, ith_sc_key);-      if (found_selected) {+    p->subchannel_list = subchannel_list;+  } else {+    // We do have a selected subchannel.+    // Check if it's present in the new list.  If so, we're done.+    for (size_t i = 0; i < subchannel_list->num_subchannels; ++i) {+      grpc_lb_subchannel_data *sd = &subchannel_list->subchannels[i];+      if (sd->subchannel == p->selected->subchannel) {         // The currently selected subchannel is in the update: we are done.         if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {           gpr_log(GPR_INFO,-                  ""Pick First %p found already selected subchannel %p amongst ""-                  ""updates. Update done."",-                  (void *)p, (void *)p->selected);+                  ""Pick First %p found already selected subchannel %p ""+                  ""at update index %"" PRIdPTR "" of %"" PRIdPTR ""; update done"",+                  p, p->selected->subchannel, i,+                  subchannel_list->num_subchannels);         }-        for (size_t j = 0; j < sc_args_count; j++) {-          grpc_channel_args_destroy(exec_ctx,-                                    (grpc_channel_args *)sc_args[j].args);+        grpc_lb_subchannel_list_ref_for_connectivity_watch(+            subchannel_list, ""connectivity_watch+replace_selected"");+        grpc_lb_subchannel_data_start_connectivity_watch(exec_ctx, sd);+        if (p->subchannel_list != NULL) {+          grpc_lb_subchannel_list_shutdown_and_unref(+              exec_ctx, p->subchannel_list, ""pf_update_includes_selected"");+        }+        p->subchannel_list = subchannel_list;+        if (p->selected->connected_subchannel != NULL) {+          sd->connected_subchannel = GRPC_CONNECTED_SUBCHANNEL_REF(+              grpc_subchannel_get_connected_subchannel(sd->subchannel),+              ""pf_update_includes_selected"");+        }+        p->selected = sd;+        destroy_unselected_subchannels_locked(exec_ctx, p);+        // If there was a previously pending update (which may or may+        // not have contained the currently selected subchannel), drop+        // it, so that it doesn't override what we've done here.+        if (p->latest_pending_subchannel_list != NULL) {+          grpc_lb_subchannel_list_shutdown_and_unref(+              exec_ctx, p->latest_pending_subchannel_list,+              ""pf_update_includes_selected+outdated"");+          p->latest_pending_subchannel_list = NULL;         }-        gpr_free(sc_args);         return;       }     }-  }-  // We only check for already running updates here because if the previous-  // steps were successful, the update can be considered done without any-  // interference (ie, no callbacks were scheduled).-  if (p->updating_selected || p->updating_subchannels) {-    if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {-      gpr_log(GPR_INFO,-              ""Update already in progress for pick first %p. Deferring update."",-              (void *)p);-    }-    if (p->pending_update_args != NULL) {-      grpc_channel_args_destroy(exec_ctx, p->pending_update_args->args);-      gpr_free(p->pending_update_args);-    }-    p->pending_update_args =-        (grpc_lb_policy_args *)gpr_zalloc(sizeof(*p->pending_update_args));-    p->pending_update_args->client_channel_factory =-        args->client_channel_factory;-    p->pending_update_args->args = grpc_channel_args_copy(args->args);-    p->pending_update_args->combiner = args->combiner;-    return;-  }-  /* Create the subchannels for the new subchannel args/addresses. */-  grpc_subchannel **new_subchannels =-      (grpc_subchannel **)gpr_zalloc(sizeof(*new_subchannels) * sc_args_count);-  size_t num_new_subchannels = 0;-  for (size_t i = 0; i < sc_args_count; i++) {-    grpc_subchannel *subchannel = grpc_client_channel_factory_create_subchannel(-        exec_ctx, args->client_channel_factory, &sc_args[i]);-    if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {-      char *address_uri =-          grpc_sockaddr_to_uri(&addresses->addresses[i].address);-      gpr_log(GPR_INFO,-              ""Pick First %p created subchannel %p for address uri %s"",-              (void *)p, (void *)subchannel, address_uri);-      gpr_free(address_uri);+    // Not keeping the previous selected subchannel, so set the latest+    // pending subchannel list to the new subchannel list.  We will wait+    // for it to report READY before swapping it into the current+    // subchannel list.+    if (p->latest_pending_subchannel_list != NULL) {+      if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {+        gpr_log(GPR_DEBUG,+                ""Pick First %p Shutting down latest pending subchannel list ""+                ""%p, about to be replaced by newer latest %p"",+                (void *)p, (void *)p->latest_pending_subchannel_list,+                (void *)subchannel_list);+      }+      grpc_lb_subchannel_list_shutdown_and_unref(+          exec_ctx, p->latest_pending_subchannel_list,+          ""sl_outdated_dont_smash"");     }-    grpc_channel_args_destroy(exec_ctx, (grpc_channel_args *)sc_args[i].args);-    if (subchannel != NULL) new_subchannels[num_new_subchannels++] = subchannel;+    p->latest_pending_subchannel_list = subchannel_list;   }-  gpr_free(sc_args);-  if (num_new_subchannels == 0) {-    gpr_free(new_subchannels);-    // Empty update. Unsubscribe from all current subchannels and put the-    // channel in TRANSIENT_FAILURE.-    grpc_connectivity_state_set(-        exec_ctx, &p->state_tracker, GRPC_CHANNEL_TRANSIENT_FAILURE,-        GRPC_ERROR_CREATE_FROM_STATIC_STRING(""No valid addresses in update""),-        ""pf_update_no_valid_addresses"");-    stop_connectivity_watchers(exec_ctx, p);-    return;-  }--  /* Destroy the current subchannels. Repurpose pf_shutdown/destroy. */-  stop_connectivity_watchers(exec_ctx, p);--  /* Save new subchannels. The switch over will happen in-   * pf_connectivity_changed_locked */-  if (p->updating_selected || p->updating_subchannels) {-    p->num_new_subchannels = num_new_subchannels;-    p->new_subchannels = new_subchannels;-  } else { /* nothing is updating. Get things moving from here */-    p->num_subchannels = num_new_subchannels;-    p->subchannels = new_subchannels;-    p->new_subchannels = NULL;-    p->num_new_subchannels = 0;-    if (p->started_picking) {-      p->checking_subchannel = 0;-      p->checking_connectivity = GRPC_CHANNEL_IDLE;-      grpc_subchannel_notify_on_state_change(-          exec_ctx, p->subchannels[p->checking_subchannel],-          p->base.interested_parties, &p->checking_connectivity,-          &p->connectivity_changed);-    }+  // If we've started picking, start trying to connect to the first+  // subchannel in the new list.+  if (p->started_picking && subchannel_list->num_subchannels > 0) {+    grpc_lb_subchannel_list_ref_for_connectivity_watch(+        subchannel_list, ""connectivity_watch+update"");+    grpc_lb_subchannel_data_start_connectivity_watch(+        exec_ctx, &subchannel_list->subchannels[0]);   } }  static void pf_connectivity_changed_locked(grpc_exec_ctx *exec_ctx, void *arg,                                            grpc_error *error) {-  pick_first_lb_policy *p = (pick_first_lb_policy *)arg;-  grpc_subchannel *selected_subchannel;-  pending_pick *pp;-+  grpc_lb_subchannel_data *sd = (grpc_lb_subchannel_data *)arg;+  pick_first_lb_policy *p = (pick_first_lb_policy *)sd->subchannel_list->policy;   if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {-    gpr_log(-        GPR_DEBUG,-        ""Pick First %p connectivity changed. Updating selected: %d; Updating ""-        ""subchannels: %d; Checking %lu index (%lu total); State: %d; "",-        (void *)p, p->updating_selected, p->updating_subchannels,-        (unsigned long)p->checking_subchannel,-        (unsigned long)p->num_subchannels, p->checking_connectivity);-  }-  bool restart = false;-  if (p->updating_selected && error != GRPC_ERROR_NONE) {-    /* Captured the unsubscription for p->selected */-    GPR_ASSERT(p->selected != NULL);-    GRPC_CONNECTED_SUBCHANNEL_UNREF(exec_ctx, p->selected,-                                    ""pf_update_connectivity"");-    if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {-      gpr_log(GPR_DEBUG, ""Pick First %p unreffing selected subchannel %p"",-              (void *)p, (void *)p->selected);-    }-    p->updating_selected = false;-    if (p->num_new_subchannels == 0) {-      p->selected = NULL;-      return;-    }-    restart = true;+    gpr_log(GPR_DEBUG,+            ""Pick First %p connectivity changed for subchannel %p (%"" PRIdPTR+            "" of %"" PRIdPTR+            ""), subchannel_list %p: state=%s p->shutdown=%d ""+            ""sd->subchannel_list->shutting_down=%d error=%s"",+            (void *)p, (void *)sd->subchannel,+            sd->subchannel_list->checking_subchannel,+            sd->subchannel_list->num_subchannels, (void *)sd->subchannel_list,+            grpc_connectivity_state_name(sd->pending_connectivity_state_unsafe),+            p->shutdown, sd->subchannel_list->shutting_down,+            grpc_error_string(error));   }-  if (p->updating_subchannels && error != GRPC_ERROR_NONE) {-    /* Captured the unsubscription for the checking subchannel */-    GPR_ASSERT(p->selected == NULL);-    for (size_t i = 0; i < p->num_subchannels; i++) {-      GRPC_SUBCHANNEL_UNREF(exec_ctx, p->subchannels[i],-                            ""pf_update_connectivity"");-      if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {-        gpr_log(GPR_DEBUG, ""Pick First %p unreffing subchannel %p"", (void *)p,-                (void *)p->subchannels[i]);-      }-    }-    gpr_free(p->subchannels);-    p->subchannels = NULL;-    p->num_subchannels = 0;-    p->updating_subchannels = false;-    if (p->num_new_subchannels == 0) return;-    restart = true;-  }-  if (restart) {-    p->selected = NULL;-    p->selected_key = NULL;-    GPR_ASSERT(p->new_subchannels != NULL);-    GPR_ASSERT(p->num_new_subchannels > 0);-    p->num_subchannels = p->num_new_subchannels;-    p->subchannels = p->new_subchannels;-    p->num_new_subchannels = 0;-    p->new_subchannels = NULL;-    if (p->started_picking) {-      /* If we were picking, continue to do so over the new subchannels,-       * starting from the 0th index. */-      p->checking_subchannel = 0;-      p->checking_connectivity = GRPC_CHANNEL_IDLE;-      /* reuses the weak ref from start_picking_locked */-      grpc_subchannel_notify_on_state_change(-          exec_ctx, p->subchannels[p->checking_subchannel],-          p->base.interested_parties, &p->checking_connectivity,-          &p->connectivity_changed);-    }-    if (p->pending_update_args != NULL) {-      const grpc_lb_policy_args *args = p->pending_update_args;-      p->pending_update_args = NULL;-      pf_update_locked(exec_ctx, &p->base, args);-    }+  // If the policy is shutting down, unref and return.+  if (p->shutdown) {+    grpc_lb_subchannel_data_stop_connectivity_watch(exec_ctx, sd);+    grpc_lb_subchannel_data_unref_subchannel(exec_ctx, sd, ""pf_shutdown"");+    grpc_lb_subchannel_list_unref_for_connectivity_watch(+        exec_ctx, sd->subchannel_list, ""pf_shutdown"");     return;   }-  GRPC_ERROR_REF(error);-  if (p->shutdown) {-    GRPC_LB_POLICY_WEAK_UNREF(exec_ctx, &p->base, ""pick_first_connectivity"");-    GRPC_ERROR_UNREF(error);+  // If the subchannel list is shutting down, stop watching.+  if (sd->subchannel_list->shutting_down || error == GRPC_ERROR_CANCELLED) {+    grpc_lb_subchannel_data_stop_connectivity_watch(exec_ctx, sd);+    grpc_lb_subchannel_data_unref_subchannel(exec_ctx, sd, ""pf_sl_shutdown"");+    grpc_lb_subchannel_list_unref_for_connectivity_watch(+        exec_ctx, sd->subchannel_list, ""pf_sl_shutdown"");     return;-  } else if (p->selected != NULL) {-    if (p->checking_connectivity == GRPC_CHANNEL_TRANSIENT_FAILURE) {-      /* if the selected channel goes bad, we're done */-      p->checking_connectivity = GRPC_CHANNEL_SHUTDOWN;-    }-    grpc_connectivity_state_set(exec_ctx, &p->state_tracker,-                                p->checking_connectivity, GRPC_ERROR_REF(error),-                                ""selected_changed"");-    if (p->checking_connectivity != GRPC_CHANNEL_SHUTDOWN) {-      grpc_connected_subchannel_notify_on_state_change(-          exec_ctx, p->selected, p->base.interested_parties,-          &p->checking_connectivity, &p->connectivity_changed);+  }+  // If we're still here, the notification must be for a subchannel in+  // either the current or latest pending subchannel lists.+  GPR_ASSERT(sd->subchannel_list == p->subchannel_list ||+             sd->subchannel_list == p->latest_pending_subchannel_list);+  // Update state counters.+  sd->curr_connectivity_state = sd->pending_connectivity_state_unsafe;+  // Handle updates for the currently selected subchannel.+  if (p->selected == sd) {+    // If the new state is anything other than READY and there is a+    // pending update, switch to the pending update.+    if (sd->curr_connectivity_state != GRPC_CHANNEL_READY &&+        p->latest_pending_subchannel_list != NULL) {+      p->selected = NULL;+      grpc_lb_subchannel_list_shutdown_and_unref(+          exec_ctx, p->subchannel_list, ""selected_not_ready+switch_to_update"");+      p->subchannel_list = p->latest_pending_subchannel_list;+      p->latest_pending_subchannel_list = NULL;+      grpc_lb_subchannel_data *new_sd =+          &p->subchannel_list+               ->subchannels[p->subchannel_list->checking_subchannel];+      grpc_connectivity_state_set(+          exec_ctx, &p->state_tracker, new_sd->curr_connectivity_state,","Understood.I should have been clearer: we have switched to a new subchannel list at line 410, so we actually have a new set of candidates. So if `new_sd` is `SHUTDOWN`, we don't have to put the whole policy into `SHUTDOWN`. ",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12878,144662315,2017-10-13T21:38:45Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -589,76 +490,86 @@ static void pf_connectivity_changed_locked(grpc_exec_ctx *exec_ctx, void *arg,           GRPC_CLOSURE_SCHED(exec_ctx, pp->on_complete, GRPC_ERROR_NONE);           gpr_free(pp);         }-        grpc_connected_subchannel_notify_on_state_change(-            exec_ctx, p->selected, p->base.interested_parties,-            &p->checking_connectivity, &p->connectivity_changed);-        break;-      case GRPC_CHANNEL_TRANSIENT_FAILURE:-        p->checking_subchannel =-            (p->checking_subchannel + 1) % p->num_subchannels;-        if (p->checking_subchannel == 0) {-          /* only trigger transient failure when we've tried all alternatives-           */+        // Renew notification.+        grpc_lb_subchannel_data_start_connectivity_watch(exec_ctx, sd);+        return;+      }+      case GRPC_CHANNEL_TRANSIENT_FAILURE: {+        do {+          sd->subchannel_list->checking_subchannel =+              (sd->subchannel_list->checking_subchannel + 1) %+              sd->subchannel_list->num_subchannels;+          sd = &sd->subchannel_list+                    ->subchannels[sd->subchannel_list->checking_subchannel];+        } while (sd->subchannel == NULL);+        // Case 1: Only set state to TRANSIENT_FAILURE if we've tried+        // all subchannels.+        if (sd->subchannel_list->checking_subchannel == 0 &&+            sd->subchannel_list == p->subchannel_list) {           grpc_connectivity_state_set(               exec_ctx, &p->state_tracker, GRPC_CHANNEL_TRANSIENT_FAILURE,               GRPC_ERROR_REF(error), ""connecting_transient_failure"");         }+        sd->curr_connectivity_state =+            grpc_subchannel_check_connectivity(sd->subchannel, &error);         GRPC_ERROR_UNREF(error);-        p->checking_connectivity = grpc_subchannel_check_connectivity(-            p->subchannels[p->checking_subchannel], &error);-        if (p->checking_connectivity == GRPC_CHANNEL_TRANSIENT_FAILURE) {-          grpc_subchannel_notify_on_state_change(-              exec_ctx, p->subchannels[p->checking_subchannel],-              p->base.interested_parties, &p->checking_connectivity,-              &p->connectivity_changed);-        } else {-          goto loop;+        if (sd->curr_connectivity_state == GRPC_CHANNEL_TRANSIENT_FAILURE) {+          // Reuses the connectivity refs from the previous watch.+          grpc_lb_subchannel_data_start_connectivity_watch(exec_ctx, sd);","There must be something I am missing..I think if we just continue trying the current subchannel instead of the next one when both of them are `TRANSIENT_FAILURE`, the order won't be broken. Do we choose the next one to watch because it's been in `TRANSIENT_FAILURE` for a longer period hence is more probable to be ready soon?",
1170852,cauthu,https://api.github.com/repos/grpc/grpc/pulls/12644,144684514,2017-10-14T02:57:49Z,src/core/lib/security/credentials/ssl/ssl_credentials.cc,"@@ -231,6 +231,7 @@ grpc_ssl_server_credentials_create_options_using_config(   }    config = *c;+  *c = NULL;",similar comment about doing this only once success is certain,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12878,144892828,2017-10-16T16:09:29Z,src/core/ext/filters/client_channel/lb_policy/subchannel_list.cc,"@@ -0,0 +1,286 @@+/*+ *+ * Copyright 2015 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <string.h>++#include <grpc/support/alloc.h>++#include ""src/core/ext/filters/client_channel/lb_policy/subchannel_list.h""+#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/debug/trace.h""+#include ""src/core/lib/iomgr/closure.h""+#include ""src/core/lib/iomgr/combiner.h""+#include ""src/core/lib/iomgr/sockaddr_utils.h""+#include ""src/core/lib/transport/connectivity_state.h""++void grpc_lb_subchannel_data_unref_subchannel(grpc_exec_ctx *exec_ctx,+                                              grpc_lb_subchannel_data *sd,+                                              const char *reason) {+  if (sd->subchannel != NULL) {+    if (GRPC_TRACER_ON(*sd->subchannel_list->tracer)) {+      gpr_log(+          GPR_DEBUG, ""[%s %p] subchannel list %p index %"" PRIdPTR+                     "" of %"" PRIdPTR "" (subchannel %p): unreffing subchannel"",+          sd->subchannel_list->tracer->name, sd->subchannel_list->policy,+          sd->subchannel_list, (size_t)(sd - sd->subchannel_list->subchannels),+          sd->subchannel_list->num_subchannels, sd->subchannel);+    }+    GRPC_SUBCHANNEL_UNREF(exec_ctx, sd->subchannel, reason);+    sd->subchannel = NULL;+    if (sd->connected_subchannel != NULL) {+      GRPC_CONNECTED_SUBCHANNEL_UNREF(exec_ctx, sd->connected_subchannel,+                                      reason);+      sd->connected_subchannel = NULL;+    }+    if (sd->user_data != NULL) {+      GPR_ASSERT(sd->user_data_vtable != NULL);+      sd->user_data_vtable->destroy(exec_ctx, sd->user_data);+      sd->user_data = NULL;+    }+  }+}++void grpc_lb_subchannel_data_start_connectivity_watch(+    grpc_exec_ctx *exec_ctx, grpc_lb_subchannel_data *sd) {+  if (GRPC_TRACER_ON(*sd->subchannel_list->tracer)) {+    gpr_log(GPR_DEBUG,+            ""[%s %p] subchannel list %p index %"" PRIdPTR "" of %"" PRIdPTR+            "" (subchannel %p): requesting connectivity change notification"",+            sd->subchannel_list->tracer->name, sd->subchannel_list->policy,+            sd->subchannel_list,+            (size_t)(sd - sd->subchannel_list->subchannels),+            sd->subchannel_list->num_subchannels, sd->subchannel);+  }+  sd->connectivity_notification_pending = true;+  grpc_subchannel_notify_on_state_change(+      exec_ctx, sd->subchannel, sd->subchannel_list->policy->interested_parties,+      &sd->pending_connectivity_state_unsafe,+      &sd->connectivity_changed_closure);+}++void grpc_lb_subchannel_data_stop_connectivity_watch(+    grpc_exec_ctx *exec_ctx, grpc_lb_subchannel_data *sd) {+  if (GRPC_TRACER_ON(*sd->subchannel_list->tracer)) {+    gpr_log(+        GPR_DEBUG, ""[%s %p] subchannel list %p index %"" PRIdPTR "" of %"" PRIdPTR+                   "" (subchannel %p): stopping connectivity watch"",+        sd->subchannel_list->tracer->name, sd->subchannel_list->policy,+        sd->subchannel_list, (size_t)(sd - sd->subchannel_list->subchannels),+        sd->subchannel_list->num_subchannels, sd->subchannel);+  }+  GPR_ASSERT(sd->connectivity_notification_pending);+  sd->connectivity_notification_pending = false;+}++grpc_lb_subchannel_list *grpc_lb_subchannel_list_create(+    grpc_exec_ctx *exec_ctx, grpc_lb_policy *p, grpc_tracer_flag *tracer,+    const grpc_lb_addresses *addresses, const grpc_lb_policy_args *args,+    grpc_iomgr_cb_func connectivity_changed_cb) {+  grpc_lb_subchannel_list *subchannel_list =+      (grpc_lb_subchannel_list *)gpr_zalloc(sizeof(*subchannel_list));+  if (GRPC_TRACER_ON(*tracer)) {+    gpr_log(GPR_DEBUG,+            ""[%s %p] Creating subchannel list %p for %"" PRIdPTR "" subchannels"",+            tracer->name, p, subchannel_list, addresses->num_addresses);+  }+  subchannel_list->policy = p;+  subchannel_list->tracer = tracer;+  gpr_ref_init(&subchannel_list->refcount, 1);+  subchannel_list->subchannels = (grpc_lb_subchannel_data *)gpr_zalloc(+      sizeof(grpc_lb_subchannel_data) * addresses->num_addresses);+  /* We need to remove the LB addresses in order to be able to compare the+   * subchannel keys of subchannels from a different batch of addresses. */+  static const char *keys_to_remove[] = {GRPC_ARG_SUBCHANNEL_ADDRESS,+                                         GRPC_ARG_LB_ADDRESSES};+  /* Create subchannels for addresses in the update. */+  grpc_subchannel_args sc_args;+  size_t subchannel_index = 0;+  for (size_t i = 0; i < addresses->num_addresses; i++) {+    // If there were any balancer, we would have chosen grpclb policy instead.+    GPR_ASSERT(!addresses->addresses[i].is_balancer);+    memset(&sc_args, 0, sizeof(grpc_subchannel_args));+    grpc_arg addr_arg =+        grpc_create_subchannel_address_arg(&addresses->addresses[i].address);+    grpc_channel_args *new_args = grpc_channel_args_copy_and_add_and_remove(+        args->args, keys_to_remove, GPR_ARRAY_SIZE(keys_to_remove), &addr_arg,+        1);+    gpr_free(addr_arg.value.string);+    sc_args.args = new_args;+    grpc_subchannel *subchannel = grpc_client_channel_factory_create_subchannel(+        exec_ctx, args->client_channel_factory, &sc_args);+    grpc_channel_args_destroy(exec_ctx, new_args);+    if (subchannel == NULL) {+      // Subchannel could not be created.+      if (GRPC_TRACER_ON(*tracer)) {+        char *address_uri =+            grpc_sockaddr_to_uri(&addresses->addresses[i].address);+        gpr_log(GPR_DEBUG,+                ""[%s %p] could not create subchannel for address uri %s, ""+                ""ignoring"",+                tracer->name, subchannel_list->policy, address_uri);+        gpr_free(address_uri);+      }+      continue;+    }+    grpc_error *error;+    // Get the connectivity state of the subchannel. Already existing ones may+    // be in a state other than INIT.+    const grpc_connectivity_state subchannel_connectivity_state =+        grpc_subchannel_check_connectivity(subchannel, &error);+    if (error != GRPC_ERROR_NONE) {+      // The subchannel is in error (e.g. shutting down). Ignore it.+      if (GRPC_TRACER_ON(*tracer)) {+        char *address_uri =+            grpc_sockaddr_to_uri(&addresses->addresses[i].address);+        gpr_log(GPR_DEBUG,+                ""[%s %p] subchannel for address uri %s shutting down, ignoring"",+                tracer->name, subchannel_list->policy, address_uri);+        gpr_free(address_uri);+      }+      GRPC_SUBCHANNEL_UNREF(exec_ctx, subchannel, ""new_sc_connectivity_error"");+      GRPC_ERROR_UNREF(error);+      continue;+    }+    if (GRPC_TRACER_ON(*tracer)) {+      char *address_uri =+          grpc_sockaddr_to_uri(&addresses->addresses[i].address);+      gpr_log(GPR_DEBUG, ""[%s %p] subchannel list %p index %"" PRIdPTR+                         "": Created subchannel %p for address uri %s; ""+                         ""initial connectivity state: %s"",+              tracer->name, p, subchannel_list, subchannel_index, subchannel,+              address_uri,+              grpc_connectivity_state_name(subchannel_connectivity_state));+      gpr_free(address_uri);+    }+    grpc_lb_subchannel_data *sd =+        &subchannel_list->subchannels[subchannel_index++];+    sd->subchannel_list = subchannel_list;+    sd->subchannel = subchannel;+    GRPC_CLOSURE_INIT(&sd->connectivity_changed_closure,+                      connectivity_changed_cb, sd,+                      grpc_combiner_scheduler(args->combiner));+    /* use some sentinel value outside of the range of+     * grpc_connectivity_state to signal an undefined previous state. We+     * won't be referring to this value again and it'll be overwritten after+     * the first call to rr_connectivity_changed_locked */+    sd->prev_connectivity_state = GRPC_CHANNEL_INIT;+    sd->curr_connectivity_state = subchannel_connectivity_state;+    sd->user_data_vtable = addresses->user_data_vtable;+    if (sd->user_data_vtable != NULL) {+      sd->user_data =+          sd->user_data_vtable->copy(addresses->addresses[i].user_data);+    }+  }+  subchannel_list->num_subchannels = subchannel_index;+  return subchannel_list;+}++static void subchannel_list_destroy(grpc_exec_ctx *exec_ctx,","Good point.  This is because `grpc_lb_subchannel_data_cancel_connectivity_watch()` was originally a non-static function, exposed via the header file, until I noticed that it wasn't being used externally anywhere.  But I forgot to remove the `grpc_lb_` prefix when I made it a static function.  I've fixed that now.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12878,144904821,2017-10-16T16:55:11Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -589,76 +490,86 @@ static void pf_connectivity_changed_locked(grpc_exec_ctx *exec_ctx, void *arg,           GRPC_CLOSURE_SCHED(exec_ctx, pp->on_complete, GRPC_ERROR_NONE);           gpr_free(pp);         }-        grpc_connected_subchannel_notify_on_state_change(-            exec_ctx, p->selected, p->base.interested_parties,-            &p->checking_connectivity, &p->connectivity_changed);-        break;-      case GRPC_CHANNEL_TRANSIENT_FAILURE:-        p->checking_subchannel =-            (p->checking_subchannel + 1) % p->num_subchannels;-        if (p->checking_subchannel == 0) {-          /* only trigger transient failure when we've tried all alternatives-           */+        // Renew notification.+        grpc_lb_subchannel_data_start_connectivity_watch(exec_ctx, sd);+        return;+      }+      case GRPC_CHANNEL_TRANSIENT_FAILURE: {+        do {+          sd->subchannel_list->checking_subchannel =+              (sd->subchannel_list->checking_subchannel + 1) %+              sd->subchannel_list->num_subchannels;+          sd = &sd->subchannel_list+                    ->subchannels[sd->subchannel_list->checking_subchannel];+        } while (sd->subchannel == NULL);+        // Case 1: Only set state to TRANSIENT_FAILURE if we've tried+        // all subchannels.+        if (sd->subchannel_list->checking_subchannel == 0 &&+            sd->subchannel_list == p->subchannel_list) {           grpc_connectivity_state_set(               exec_ctx, &p->state_tracker, GRPC_CHANNEL_TRANSIENT_FAILURE,               GRPC_ERROR_REF(error), ""connecting_transient_failure"");         }+        sd->curr_connectivity_state =+            grpc_subchannel_check_connectivity(sd->subchannel, &error);         GRPC_ERROR_UNREF(error);-        p->checking_connectivity = grpc_subchannel_check_connectivity(-            p->subchannels[p->checking_subchannel], &error);-        if (p->checking_connectivity == GRPC_CHANNEL_TRANSIENT_FAILURE) {-          grpc_subchannel_notify_on_state_change(-              exec_ctx, p->subchannels[p->checking_subchannel],-              p->base.interested_parties, &p->checking_connectivity,-              &p->connectivity_changed);-        } else {-          goto loop;+        if (sd->curr_connectivity_state == GRPC_CHANNEL_TRANSIENT_FAILURE) {+          // Reuses the connectivity refs from the previous watch.+          grpc_lb_subchannel_data_start_connectivity_watch(exec_ctx, sd);","The expected behavior of the pick_first LB policy is to try to connect to the subchannels in the order they were given to us and to pick the first one for which the connection attempt succeeds.  So the logic is basically the following (pseudo-code):```for subchannel in subchannel_list:  try to connect to subchannel  if connection attempt succeeded:    p->selected = subchannel    break```When we try to connect to a given subchannel, the subchannel goes from IDLE to CONNECTING.  If the connection attempt succeeds, the subchannel goes from CONNECTING to READY, at which point we choose that subchannel and don't try to connect to any others.  However, if the connection attempt fails, the subchannel goes from CONNECTING to TRANSIENT_FAILURE, which is how we know that it failed.  When this happens, we need to move on to the next subchannel in the list and start attempting to connect to it.If we didn't move on to the next subchannel when the current one goes into TRANSIENT_FAILURE, then we would only ever be checking the first subchannel in the list -- we would never move on to trying any of the others.(Note that because the subchannel code is currently lying to us and converting TRANSIENT_FAILURE into SHUTDOWN, this code-path will never actually be triggered right now.  However, the same explanation applies to the SHUTDOWN case, and the logic is essentially the same there.)",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12878,144993685,2017-10-16T23:15:40Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -589,76 +490,86 @@ static void pf_connectivity_changed_locked(grpc_exec_ctx *exec_ctx, void *arg,           GRPC_CLOSURE_SCHED(exec_ctx, pp->on_complete, GRPC_ERROR_NONE);           gpr_free(pp);         }-        grpc_connected_subchannel_notify_on_state_change(-            exec_ctx, p->selected, p->base.interested_parties,-            &p->checking_connectivity, &p->connectivity_changed);-        break;-      case GRPC_CHANNEL_TRANSIENT_FAILURE:-        p->checking_subchannel =-            (p->checking_subchannel + 1) % p->num_subchannels;-        if (p->checking_subchannel == 0) {-          /* only trigger transient failure when we've tried all alternatives-           */+        // Renew notification.+        grpc_lb_subchannel_data_start_connectivity_watch(exec_ctx, sd);+        return;+      }+      case GRPC_CHANNEL_TRANSIENT_FAILURE: {+        do {+          sd->subchannel_list->checking_subchannel =+              (sd->subchannel_list->checking_subchannel + 1) %+              sd->subchannel_list->num_subchannels;+          sd = &sd->subchannel_list+                    ->subchannels[sd->subchannel_list->checking_subchannel];+        } while (sd->subchannel == NULL);+        // Case 1: Only set state to TRANSIENT_FAILURE if we've tried+        // all subchannels.+        if (sd->subchannel_list->checking_subchannel == 0 &&+            sd->subchannel_list == p->subchannel_list) {           grpc_connectivity_state_set(               exec_ctx, &p->state_tracker, GRPC_CHANNEL_TRANSIENT_FAILURE,               GRPC_ERROR_REF(error), ""connecting_transient_failure"");         }+        sd->curr_connectivity_state =+            grpc_subchannel_check_connectivity(sd->subchannel, &error);         GRPC_ERROR_UNREF(error);-        p->checking_connectivity = grpc_subchannel_check_connectivity(-            p->subchannels[p->checking_subchannel], &error);-        if (p->checking_connectivity == GRPC_CHANNEL_TRANSIENT_FAILURE) {-          grpc_subchannel_notify_on_state_change(-              exec_ctx, p->subchannels[p->checking_subchannel],-              p->base.interested_parties, &p->checking_connectivity,-              &p->connectivity_changed);-        } else {-          goto loop;+        if (sd->curr_connectivity_state == GRPC_CHANNEL_TRANSIENT_FAILURE) {+          // Reuses the connectivity refs from the previous watch.+          grpc_lb_subchannel_data_start_connectivity_watch(exec_ctx, sd);","I think if the failure is really transient, we can still watch it unless it is shut down or ready. However, if we don't want to wait for a subchannel in `TRANSIENT_FAILURE`, we can continue to find the next subchannel that is not in `TRANSIENT_FAILURE`. But I don't quite understand why we skip the current subchannel in `TRANSIENT_FAILURE`, and watch the next subchannel in `TRANSIENT_FAILURE`. It's kind of a mix.. And the only reason I can think of is that we have more hope to the subchannel in `TRANSIENT_FAILURE` for a longer time.",
20848495,plaisted,https://api.github.com/repos/grpc/grpc/pulls/12613,145249701,2017-10-17T20:40:52Z,src/csharp/Grpc.Core.Tests/Interceptors/ClientInterceptorTest.cs,"@@ -0,0 +1,76 @@+#region Copyright notice and license++// Copyright 2017 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Generic;+using System.Linq;+using System.Threading;+using System.Threading.Tasks;+using Grpc.Core;+using Grpc.Core.Interceptors;+using Grpc.Core.Internal;+using Grpc.Core.Utils;+using Grpc.Core.Tests;+using NUnit.Framework;++namespace Grpc.Core.Interceptors.Tests+{+    public class ClientInterceptorTest+    {+        private class AddHeaderClientInterceptor : ClientInterceptor+        {+            readonly Metadata.Entry header;+            public AddHeaderClientInterceptor(string key, string value)+            {+                this.header = new Metadata.Entry(key, value);+            }+            public override TResponse BlockingUnaryCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request, Func<Method<TRequest, TResponse>, string, CallOptions, TRequest, TResponse> next)+            {+                options.Headers.Add(this.header);+                return next(method, host, options, request);+            }++            public Metadata.Entry Header+            {+                get+                {+                    return this.header;+                }+            }+        }++        const string Host = ""127.0.0.1"";++        [Test]+        public void AddRequestHeaderInClientInterceptor()+        {+            var helper = new MockServiceHelper(Host);+            var interceptor = new AddHeaderClientInterceptor(""x-client-interceptor"", ""hello world"");+            helper.UnaryHandler = new UnaryServerMethod<string, string>((request, context) =>+            {+                var interceptorHeader = context.RequestHeaders.Last(m => (m.Key == interceptor.Header.Key)).Value;+                Assert.AreEqual(interceptorHeader, interceptor.Header.Value);+                return Task.FromResult(""PASS"");+            });+            var server = helper.GetServer();+            server.Start();+            var callInvoker = helper.GetChannel().Intercept(interceptor);","@mehrdada Functionally they are the same but using the extension method allows you to nicely encapsulate what ""API"" you want the user of the package to use vs. what the actual constructor that the class needs.As a contrived example the `Authenticator` interceptor may require a `TokenValidator` service so it's constructor is actually `Authenticator(ITokenValidator validator)`. Adding an extensions method in your package of `AddJwtAuth()` would simply construct the `Authenticator` interceptor with a `JwtTokenValidator` that implements `ITokenValidator`.Now the extension method would generally do a lot more than that, maybe even add multiple interceptors which is trivial with this sort of setup:```csharp//extension methodpublic static void AddJwtAuth(this IInterceptorPipeline pipeline, Action<JwtOptions> optionsBuilder) {    var options = optionsBuilder(new JwtOptions());    pipeline.Add(new Authenticator(new JwtTokenValidator(options)));    pipeline.AddInterceptor2(); // add a dependent interceptor    pipeline.AddInterceptor3(); // add another}//using it.Intercept(p => {        p.AddJwtAuth(o=>{ o.ValidationCertificate = cert; });    });```I've written a few addons (aspcore mainly) that use this sort of approach and it works very nicely as you don't have to expose any implementation details to the users of the package.  Admittedly all of this other than adding multiple interceptors could all be implemented relatively easily using a static ""factory"" method so a lot of this is preference and wanting to stay similar to how I see this done across different frameworks in c#.",
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/12789,145266716,2017-10-17T21:51:08Z,src/core/lib/iomgr/ev_epollex_linux.cc,"@@ -215,8 +193,19 @@ struct grpc_pollset { /*******************************************************************************  * Pollset-set Declarations  */+ struct grpc_pollset_set {-  polling_obj po;+  gpr_refcount refs;+  gpr_mu mu;+  grpc_pollset_set *parent;++  size_t pollset_count;+  size_t pollset_capacity;+  grpc_pollset **pollsets;++  size_t fd_count;+  size_t fd_capacity;+  grpc_fd **fds; }; ","The comment at line 242  (i.e ""The alarm system needs to be ..."") is no longer relevant",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12878,145271675,2017-10-17T22:16:47Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -589,76 +490,86 @@ static void pf_connectivity_changed_locked(grpc_exec_ctx *exec_ctx, void *arg,           GRPC_CLOSURE_SCHED(exec_ctx, pp->on_complete, GRPC_ERROR_NONE);           gpr_free(pp);         }-        grpc_connected_subchannel_notify_on_state_change(-            exec_ctx, p->selected, p->base.interested_parties,-            &p->checking_connectivity, &p->connectivity_changed);-        break;-      case GRPC_CHANNEL_TRANSIENT_FAILURE:-        p->checking_subchannel =-            (p->checking_subchannel + 1) % p->num_subchannels;-        if (p->checking_subchannel == 0) {-          /* only trigger transient failure when we've tried all alternatives-           */+        // Renew notification.+        grpc_lb_subchannel_data_start_connectivity_watch(exec_ctx, sd);+        return;+      }+      case GRPC_CHANNEL_TRANSIENT_FAILURE: {+        do {+          sd->subchannel_list->checking_subchannel =+              (sd->subchannel_list->checking_subchannel + 1) %+              sd->subchannel_list->num_subchannels;+          sd = &sd->subchannel_list+                    ->subchannels[sd->subchannel_list->checking_subchannel];+        } while (sd->subchannel == NULL);+        // Case 1: Only set state to TRANSIENT_FAILURE if we've tried+        // all subchannels.+        if (sd->subchannel_list->checking_subchannel == 0 &&+            sd->subchannel_list == p->subchannel_list) {           grpc_connectivity_state_set(               exec_ctx, &p->state_tracker, GRPC_CHANNEL_TRANSIENT_FAILURE,               GRPC_ERROR_REF(error), ""connecting_transient_failure"");         }+        sd->curr_connectivity_state =+            grpc_subchannel_check_connectivity(sd->subchannel, &error);         GRPC_ERROR_UNREF(error);-        p->checking_connectivity = grpc_subchannel_check_connectivity(-            p->subchannels[p->checking_subchannel], &error);-        if (p->checking_connectivity == GRPC_CHANNEL_TRANSIENT_FAILURE) {-          grpc_subchannel_notify_on_state_change(-              exec_ctx, p->subchannels[p->checking_subchannel],-              p->base.interested_parties, &p->checking_connectivity,-              &p->connectivity_changed);-        } else {-          goto loop;+        if (sd->curr_connectivity_state == GRPC_CHANNEL_TRANSIENT_FAILURE) {+          // Reuses the connectivity refs from the previous watch.+          grpc_lb_subchannel_data_start_connectivity_watch(exec_ctx, sd);","I think the intent here is that any time a subchannel transitions into TRANSIENT_FAILURE, that means that the most recent connection attempt has failed.  In other words, TRANSIENT_FAILURE is expected to always mean that a connection attempt has failed, and we won't try connecting to that subchannel again until we loop back around to it (i.e., wrap-around after iterating through the whole list).  If we did loop back around, then we would expect that on the second attempt, the channel would start in state TRANSIENT_FAILURE, because that's where we left it on the last attempt, and it will never have changed out of that state in the interim, since we have not been watching it.That having been said, as I mentioned above, this code is not ever actually getting executed today, because the subchannel code is always lying by converting TRANSIENT_FAILURE to SHUTDOWN.  And as a result of the way we're handling SHUTDOWN, we never actually wrap around to the beginning of the list -- we only give each subchannel one attempt, and if it fails we unref it and move on to the next one.In any case, this is basically pre-existing logic, and I did not want to change it as part of this PR.  But I do agree that we will probably want to rework this when we eventually get around to fixing the lie in the subchannel code.",
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/12789,145272679,2017-10-17T22:21:26Z,src/core/lib/iomgr/ev_epollex_linux.cc,"@@ -535,159 +534,131 @@ GPR_TLS_DECL(g_current_thread_worker); static grpc_error *pollset_global_init(void) {   gpr_tls_init(&g_current_thread_pollset);   gpr_tls_init(&g_current_thread_worker);-  pollable_init(&g_empty_pollable, PO_EMPTY_POLLABLE);-  return GRPC_ERROR_NONE;+  return pollable_create(PO_EMPTY, &g_empty_pollable); }  static void pollset_global_shutdown(void) {-  pollable_destroy(&g_empty_pollable);+  POLLABLE_UNREF(g_empty_pollable, ""g_empty_pollable"");   gpr_tls_destroy(&g_current_thread_pollset);   gpr_tls_destroy(&g_current_thread_worker); }  static void pollset_maybe_finish_shutdown(grpc_exec_ctx *exec_ctx,                                           grpc_pollset *pollset) {+  if (GRPC_TRACER_ON(grpc_polling_trace)) {+    gpr_log(GPR_DEBUG,+            ""PS:%p (pollable:%p) maybe_finish_shutdown sc=%p (target:!NULL) ""+            ""rw=%p (target:NULL) cpsc=%d (target:0)"",+            pollset, pollset->active_pollable, pollset->shutdown_closure,+            pollset->root_worker, pollset->containing_pollset_set_count);+  }   if (pollset->shutdown_closure != NULL && pollset->root_worker == NULL &&-      pollset->kick_alls_pending == 0) {+      pollset->containing_pollset_set_count == 0) {     GRPC_CLOSURE_SCHED(exec_ctx, pollset->shutdown_closure, GRPC_ERROR_NONE);     pollset->shutdown_closure = NULL;   } } -static void do_kick_all(grpc_exec_ctx *exec_ctx, void *arg,-                        grpc_error *error_unused) {-  grpc_error *error = GRPC_ERROR_NONE;-  grpc_pollset *pollset = (grpc_pollset *)arg;-  gpr_mu_lock(&pollset->pollable_obj.po.mu);-  if (pollset->root_worker != NULL) {-    grpc_pollset_worker *worker = pollset->root_worker;-    do {-      GRPC_STATS_INC_POLLSET_KICK(exec_ctx);-      if (worker->pollable_obj != &pollset->pollable_obj) {-        gpr_mu_lock(&worker->pollable_obj->po.mu);-      }-      if (worker->initialized_cv && worker != pollset->root_worker) {-        if (GRPC_TRACER_ON(grpc_polling_trace)) {-          gpr_log(GPR_DEBUG, ""PS:%p kickall_via_cv %p (pollable %p vs %p)"",-                  pollset, worker, &pollset->pollable_obj,-                  worker->pollable_obj);-        }-        worker->kicked = true;-        gpr_cv_signal(&worker->cv);-      } else {-        if (GRPC_TRACER_ON(grpc_polling_trace)) {-          gpr_log(GPR_DEBUG, ""PS:%p kickall_via_wakeup %p (pollable %p vs %p)"",-                  pollset, worker, &pollset->pollable_obj,-                  worker->pollable_obj);-        }-        append_error(&error,-                     grpc_wakeup_fd_wakeup(&worker->pollable_obj->wakeup),-                     ""pollset_shutdown"");-      }-      if (worker->pollable_obj != &pollset->pollable_obj) {-        gpr_mu_unlock(&worker->pollable_obj->po.mu);-      }--      worker = worker->links[PWL_POLLSET].next;-    } while (worker != pollset->root_worker);-  }-  pollset->kick_alls_pending--;-  pollset_maybe_finish_shutdown(exec_ctx, pollset);-  gpr_mu_unlock(&pollset->pollable_obj.po.mu);-  GRPC_LOG_IF_ERROR(""kick_all"", error);-}--static void pollset_kick_all(grpc_exec_ctx *exec_ctx, grpc_pollset *pollset) {-  pollset->kick_alls_pending++;-  GRPC_CLOSURE_SCHED(exec_ctx, GRPC_CLOSURE_CREATE(do_kick_all, pollset,-                                                   grpc_schedule_on_exec_ctx),-                     GRPC_ERROR_NONE);-}--static grpc_error *pollset_kick_inner(grpc_pollset *pollset, pollable *p,-                                      grpc_pollset_worker *specific_worker) {-  if (GRPC_TRACER_ON(grpc_polling_trace)) {-    gpr_log(GPR_DEBUG,-            ""PS:%p kick %p tls_pollset=%p tls_worker=%p ""-            ""root_worker=(pollset:%p pollable:%p)"",-            p, specific_worker, (void *)gpr_tls_get(&g_current_thread_pollset),-            (void *)gpr_tls_get(&g_current_thread_worker), pollset->root_worker,-            p->root_worker);-  }-  if (specific_worker == NULL) {-    if (gpr_tls_get(&g_current_thread_pollset) != (intptr_t)pollset) {-      if (pollset->root_worker == NULL) {-        if (GRPC_TRACER_ON(grpc_polling_trace)) {-          gpr_log(GPR_DEBUG, ""PS:%p kicked_any_without_poller"", p);-        }-        pollset->kicked_without_poller = true;-        return GRPC_ERROR_NONE;-      } else {-        if (GRPC_TRACER_ON(grpc_polling_trace)) {-          gpr_log(GPR_DEBUG, ""PS:%p kicked_any_via_wakeup_fd"", p);-        }-        grpc_error *err = pollable_materialize(p);-        if (err != GRPC_ERROR_NONE) return err;-        return grpc_wakeup_fd_wakeup(&p->wakeup);-      }-    } else {-      if (GRPC_TRACER_ON(grpc_polling_trace)) {-        gpr_log(GPR_DEBUG, ""PS:%p kicked_any_but_awake"", p);-      }-      return GRPC_ERROR_NONE;-    }-  } else if (specific_worker->kicked) {+/* pollset->mu must be held before calling this function,+ * pollset->active_pollable->mu & specific_worker->pollable_obj->mu must not be+ * held */+static grpc_error *pollset_kick_one(grpc_exec_ctx *exec_ctx,+                                    grpc_pollset *pollset,+                                    grpc_pollset_worker *specific_worker) {+  pollable *p = specific_worker->pollable_obj;+  grpc_core::mu_guard lock(&p->mu);+  GRPC_STATS_INC_POLLSET_KICK(exec_ctx);+  GPR_ASSERT(specific_worker != NULL);+  if (specific_worker->kicked) {     if (GRPC_TRACER_ON(grpc_polling_trace)) {       gpr_log(GPR_DEBUG, ""PS:%p kicked_specific_but_already_kicked"", p);     }+    GRPC_STATS_INC_POLLSET_KICKED_AGAIN(exec_ctx);     return GRPC_ERROR_NONE;-  } else if (gpr_tls_get(&g_current_thread_worker) ==-             (intptr_t)specific_worker) {+  }+  if (gpr_tls_get(&g_current_thread_worker) == (intptr_t)specific_worker) {     if (GRPC_TRACER_ON(grpc_polling_trace)) {       gpr_log(GPR_DEBUG, ""PS:%p kicked_specific_but_awake"", p);     }+    GRPC_STATS_INC_POLLSET_KICK_OWN_THREAD(exec_ctx);     specific_worker->kicked = true;     return GRPC_ERROR_NONE;-  } else if (specific_worker == p->root_worker) {+  }+  if (specific_worker == p->root_worker) {+    GRPC_STATS_INC_POLLSET_KICK_WAKEUP_FD(exec_ctx);     if (GRPC_TRACER_ON(grpc_polling_trace)) {       gpr_log(GPR_DEBUG, ""PS:%p kicked_specific_via_wakeup_fd"", p);     }-    grpc_error *err = pollable_materialize(p);-    if (err != GRPC_ERROR_NONE) return err;     specific_worker->kicked = true;-    return grpc_wakeup_fd_wakeup(&p->wakeup);-  } else {+    grpc_error *error = grpc_wakeup_fd_wakeup(&p->wakeup);+    return error;+  }+  if (specific_worker->initialized_cv) {+    GRPC_STATS_INC_POLLSET_KICK_WAKEUP_CV(exec_ctx);     if (GRPC_TRACER_ON(grpc_polling_trace)) {       gpr_log(GPR_DEBUG, ""PS:%p kicked_specific_via_cv"", p);     }     specific_worker->kicked = true;     gpr_cv_signal(&specific_worker->cv);     return GRPC_ERROR_NONE;   }+  // we can get here during end_worker after removing specific_worker from the+  // pollable list but before removing it from the pollset list+  return GRPC_ERROR_NONE; } -/* p->po.mu must be held before calling this function */ static grpc_error *pollset_kick(grpc_exec_ctx *exec_ctx, grpc_pollset *pollset,                                 grpc_pollset_worker *specific_worker) {-  pollable *p = pollset->current_pollable_obj;-  GRPC_STATS_INC_POLLSET_KICK(exec_ctx);-  if (p != &pollset->pollable_obj) {-    gpr_mu_lock(&p->po.mu);+  if (GRPC_TRACER_ON(grpc_polling_trace)) {+    gpr_log(GPR_DEBUG,+            ""PS:%p kick %p tls_pollset=%p tls_worker=%p pollset.root_worker=%p"",+            pollset, specific_worker,+            (void *)gpr_tls_get(&g_current_thread_pollset),+            (void *)gpr_tls_get(&g_current_thread_worker),+            pollset->root_worker);   }-  grpc_error *error = pollset_kick_inner(pollset, p, specific_worker);-  if (p != &pollset->pollable_obj) {-    gpr_mu_unlock(&p->po.mu);+  if (specific_worker == NULL) {+    if (gpr_tls_get(&g_current_thread_pollset) != (intptr_t)pollset) {+      if (pollset->root_worker == NULL) {+        if (GRPC_TRACER_ON(grpc_polling_trace)) {+          gpr_log(GPR_DEBUG, ""PS:%p kicked_any_without_poller"", pollset);+        }+        pollset->kicked_without_poller = true;+        return GRPC_ERROR_NONE;+      } else {+        return pollset_kick_one(+            exec_ctx, pollset,+            pollset->root_worker->links[PWLINK_POLLSET].next);","(oh..i guess `next` its never null. If the list only has the `root_worker`, i am assuming the `next` points to the `root_worker`). ",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12878,145283476,2017-10-17T23:30:23Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -589,76 +490,86 @@ static void pf_connectivity_changed_locked(grpc_exec_ctx *exec_ctx, void *arg,           GRPC_CLOSURE_SCHED(exec_ctx, pp->on_complete, GRPC_ERROR_NONE);           gpr_free(pp);         }-        grpc_connected_subchannel_notify_on_state_change(-            exec_ctx, p->selected, p->base.interested_parties,-            &p->checking_connectivity, &p->connectivity_changed);-        break;-      case GRPC_CHANNEL_TRANSIENT_FAILURE:-        p->checking_subchannel =-            (p->checking_subchannel + 1) % p->num_subchannels;-        if (p->checking_subchannel == 0) {-          /* only trigger transient failure when we've tried all alternatives-           */+        // Renew notification.+        grpc_lb_subchannel_data_start_connectivity_watch(exec_ctx, sd);+        return;+      }+      case GRPC_CHANNEL_TRANSIENT_FAILURE: {+        do {+          sd->subchannel_list->checking_subchannel =+              (sd->subchannel_list->checking_subchannel + 1) %+              sd->subchannel_list->num_subchannels;+          sd = &sd->subchannel_list+                    ->subchannels[sd->subchannel_list->checking_subchannel];+        } while (sd->subchannel == NULL);+        // Case 1: Only set state to TRANSIENT_FAILURE if we've tried+        // all subchannels.+        if (sd->subchannel_list->checking_subchannel == 0 &&+            sd->subchannel_list == p->subchannel_list) {           grpc_connectivity_state_set(               exec_ctx, &p->state_tracker, GRPC_CHANNEL_TRANSIENT_FAILURE,               GRPC_ERROR_REF(error), ""connecting_transient_failure"");         }+        sd->curr_connectivity_state =+            grpc_subchannel_check_connectivity(sd->subchannel, &error);         GRPC_ERROR_UNREF(error);-        p->checking_connectivity = grpc_subchannel_check_connectivity(-            p->subchannels[p->checking_subchannel], &error);-        if (p->checking_connectivity == GRPC_CHANNEL_TRANSIENT_FAILURE) {-          grpc_subchannel_notify_on_state_change(-              exec_ctx, p->subchannels[p->checking_subchannel],-              p->base.interested_parties, &p->checking_connectivity,-              &p->connectivity_changed);-        } else {-          goto loop;+        if (sd->curr_connectivity_state == GRPC_CHANNEL_TRANSIENT_FAILURE) {+          // Reuses the connectivity refs from the previous watch.+          grpc_lb_subchannel_data_start_connectivity_watch(exec_ctx, sd);","Yes, I'm fine with the ""try the failed one again later"" logic as long as that is the intended logic. I agree that we should put it aside for now and work on it later.",
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/12789,145294262,2017-10-18T00:56:24Z,src/core/lib/iomgr/ev_epollex_linux.cc,"@@ -784,13 +769,8 @@ static grpc_error *pollset_process_events(grpc_exec_ctx *exec_ctx,  /* pollset_shutdown is guaranteed to be called before pollset_destroy. */ static void pollset_destroy(grpc_exec_ctx *exec_ctx, grpc_pollset *pollset) {-  pollable_destroy(&pollset->pollable_obj);-  if (pollset_is_pollable_fd(pollset, pollset->current_pollable_obj)) {-    UNREF_BY(exec_ctx, (grpc_fd *)pollset->current_pollable_obj, 2,-             ""pollset_pollable"");-  }-  GRPC_LOG_IF_ERROR(""pollset_process_events"",-                    pollset_process_events(exec_ctx, pollset, true));+  POLLABLE_UNREF(pollset->active_pollable, ""pollset"");+  pollset->active_pollable = NULL; }  static grpc_error *pollset_epoll(grpc_exec_ctx *exec_ctx, grpc_pollset *pollset,",This doesn't really doesn't need `pollset` parameter anymore. Should we rename this to `pollable_epoll` ?,
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/12789,145473437,2017-10-18T16:43:23Z,src/core/lib/iomgr/ev_epollex_linux.cc,"@@ -916,460 +891,484 @@ static bool begin_worker(grpc_exec_ctx *exec_ctx, grpc_pollset *pollset,                 worker->pollable_obj, worker);       }     }-    if (worker->pollable_obj != &pollset->pollable_obj) {-      gpr_mu_unlock(&worker->pollable_obj->po.mu);-      gpr_mu_lock(&pollset->pollable_obj.po.mu);-      gpr_mu_lock(&worker->pollable_obj->po.mu);-    }     grpc_exec_ctx_invalidate_now(exec_ctx);+  } else {+    gpr_mu_unlock(&pollset->mu);   }+  gpr_mu_unlock(&worker->pollable_obj->mu); -  return do_poll && pollset->shutdown_closure == NULL &&-         pollset->current_pollable_obj == worker->pollable_obj;+  return do_poll; }  static void end_worker(grpc_exec_ctx *exec_ctx, grpc_pollset *pollset,                        grpc_pollset_worker *worker,                        grpc_pollset_worker **worker_hdl) {-  if (NEW_ROOT ==-      worker_remove(&worker->pollable_obj->root_worker, PWL_POLLABLE, worker)) {-    gpr_cv_signal(&worker->pollable_obj->root_worker->cv);+  gpr_mu_lock(&pollset->mu);+  gpr_mu_lock(&worker->pollable_obj->mu);+  switch (worker_remove(&worker->pollable_obj->root_worker, worker,+                        PWLINK_POLLABLE)) {+    case WRR_NEW_ROOT: {+      // wakeup new poller+      grpc_pollset_worker *new_root = worker->pollable_obj->root_worker;+      GPR_ASSERT(new_root->initialized_cv);+      gpr_cv_signal(&new_root->cv);+      break;+    }+    case WRR_EMPTIED:+      if (pollset->active_pollable != worker->pollable_obj) {+        // pollable no longer being polled: flush events+        pollable_process_events(exec_ctx, pollset, worker->pollable_obj, true);+      }+      break;+    case WRR_REMOVED:+      break;+  }+  gpr_mu_unlock(&worker->pollable_obj->mu);+  POLLABLE_UNREF(worker->pollable_obj, ""pollset_worker"");+  if (worker_remove(&pollset->root_worker, worker, PWLINK_POLLSET) ==+      WRR_EMPTIED) {+    pollset_maybe_finish_shutdown(exec_ctx, pollset);   }   if (worker->initialized_cv) {     gpr_cv_destroy(&worker->cv);   }-  if (pollset_is_pollable_fd(pollset, worker->pollable_obj)) {-    UNREF_BY(exec_ctx, (grpc_fd *)worker->pollable_obj, 2, ""one_poll"");-  }-  if (EMPTIED == worker_remove(&pollset->root_worker, PWL_POLLSET, worker)) {-    pollset_maybe_finish_shutdown(exec_ctx, pollset);-  } } +static long gettid(void) { return syscall(__NR_gettid); }+ /* pollset->po.mu lock must be held by the caller before calling this.    The function pollset_work() may temporarily release the lock (pollset->po.mu)    during the course of its execution but it will always re-acquire the lock and    ensure that it is held by the time the function returns */ static grpc_error *pollset_work(grpc_exec_ctx *exec_ctx, grpc_pollset *pollset,                                 grpc_pollset_worker **worker_hdl,                                 grpc_millis deadline) {+#ifdef GRPC_EPOLLEX_CREATE_WORKERS_ON_HEAP+  grpc_pollset_worker *worker =+      (grpc_pollset_worker *)gpr_malloc(sizeof(*worker));+#define WORKER_PTR (worker)+#else   grpc_pollset_worker worker;-  if (0 && GRPC_TRACER_ON(grpc_polling_trace)) {+#define WORKER_PTR (&worker)+#endif+  WORKER_PTR->originator = gettid();+  if (GRPC_TRACER_ON(grpc_polling_trace)) {     gpr_log(GPR_DEBUG, ""PS:%p work hdl=%p worker=%p now=%"" PRIdPTR-                       "" deadline=%"" PRIdPTR "" kwp=%d root_worker=%p"",-            pollset, worker_hdl, &worker, grpc_exec_ctx_now(exec_ctx), deadline,-            pollset->kicked_without_poller, pollset->root_worker);+                       "" deadline=%"" PRIdPTR "" kwp=%d pollable=%p"",+            pollset, worker_hdl, WORKER_PTR, grpc_exec_ctx_now(exec_ctx),+            deadline, pollset->kicked_without_poller, pollset->active_pollable);   }-  grpc_error *error = GRPC_ERROR_NONE;   static const char *err_desc = ""pollset_work"";+  grpc_error *error = GRPC_ERROR_NONE;   if (pollset->kicked_without_poller) {     pollset->kicked_without_poller = false;-    return GRPC_ERROR_NONE;-  }-  if (pollset->current_pollable_obj != &pollset->pollable_obj) {-    gpr_mu_lock(&pollset->current_pollable_obj->po.mu);-  }-  if (begin_worker(exec_ctx, pollset, &worker, worker_hdl, deadline)) {-    gpr_tls_set(&g_current_thread_pollset, (intptr_t)pollset);-    gpr_tls_set(&g_current_thread_worker, (intptr_t)&worker);-    GPR_ASSERT(!pollset->shutdown_closure);-    append_error(&error, pollable_materialize(worker.pollable_obj), err_desc);-    if (worker.pollable_obj != &pollset->pollable_obj) {-      gpr_mu_unlock(&worker.pollable_obj->po.mu);-    }-    gpr_mu_unlock(&pollset->pollable_obj.po.mu);-    if (pollset->event_cursor == pollset->event_count) {-      append_error(&error, pollset_epoll(exec_ctx, pollset, worker.pollable_obj,-                                         deadline),+  } else {+    if (begin_worker(exec_ctx, pollset, WORKER_PTR, worker_hdl, deadline)) {+      gpr_tls_set(&g_current_thread_pollset, (intptr_t)pollset);+      gpr_tls_set(&g_current_thread_worker, (intptr_t)WORKER_PTR);+      if (WORKER_PTR->pollable_obj->event_cursor ==+          WORKER_PTR->pollable_obj->event_count) {+        append_error(&error, pollset_epoll(exec_ctx, pollset,+                                           WORKER_PTR->pollable_obj, deadline),+                     err_desc);+      }+      append_error(&error,+                   pollable_process_events(exec_ctx, pollset,+                                           WORKER_PTR->pollable_obj, false),                    err_desc);+      grpc_exec_ctx_flush(exec_ctx);+      gpr_tls_set(&g_current_thread_pollset, 0);+      gpr_tls_set(&g_current_thread_worker, 0);     }-    append_error(&error, pollset_process_events(exec_ctx, pollset, false),-                 err_desc);-    gpr_mu_lock(&pollset->pollable_obj.po.mu);-    if (worker.pollable_obj != &pollset->pollable_obj) {-      gpr_mu_lock(&worker.pollable_obj->po.mu);-    }-    gpr_tls_set(&g_current_thread_pollset, 0);-    gpr_tls_set(&g_current_thread_worker, 0);-    pollset_maybe_finish_shutdown(exec_ctx, pollset);-  }-  end_worker(exec_ctx, pollset, &worker, worker_hdl);-  if (worker.pollable_obj != &pollset->pollable_obj) {-    gpr_mu_unlock(&worker.pollable_obj->po.mu);+    end_worker(exec_ctx, pollset, WORKER_PTR, worker_hdl);   }-  if (grpc_exec_ctx_has_work(exec_ctx)) {-    gpr_mu_unlock(&pollset->pollable_obj.po.mu);-    grpc_exec_ctx_flush(exec_ctx);-    gpr_mu_lock(&pollset->pollable_obj.po.mu);+#ifdef GRPC_EPOLLEX_CREATE_WORKERS_ON_HEAP+  gpr_free(worker);+#endif+#undef WORKER_PTR+  return error;+}++static grpc_error *pollset_transition_pollable_from_empty_to_fd_locked(+    grpc_exec_ctx *exec_ctx, grpc_pollset *pollset, grpc_fd *fd) {+  static const char *err_desc = ""pollset_transition_pollable_from_empty_to_fd"";+  grpc_error *error = GRPC_ERROR_NONE;+  if (GRPC_TRACER_ON(grpc_polling_trace)) {+    gpr_log(GPR_DEBUG,+            ""PS:%p add fd %p (%d); transition pollable from empty to fd"",+            pollset, fd, fd->fd);   }+  append_error(&error, pollset_kick_all(exec_ctx, pollset), err_desc);+  POLLABLE_UNREF(pollset->active_pollable, ""pollset"");+  append_error(&error, fd_become_pollable(fd, &pollset->active_pollable),+               err_desc);   return error; } -static void unref_fd_no_longer_poller(grpc_exec_ctx *exec_ctx, void *arg,-                                      grpc_error *error) {-  grpc_fd *fd = (grpc_fd *)arg;-  UNREF_BY(exec_ctx, fd, 2, ""pollset_pollable"");+static grpc_error *pollset_transition_pollable_from_fd_to_multi_locked(+    grpc_exec_ctx *exec_ctx, grpc_pollset *pollset, grpc_fd *and_add_fd) {+  static const char *err_desc = ""pollset_transition_pollable_from_fd_to_multi"";+  grpc_error *error = GRPC_ERROR_NONE;+  if (GRPC_TRACER_ON(grpc_polling_trace)) {+    gpr_log(+        GPR_DEBUG,+        ""PS:%p add fd %p (%d); transition pollable from fd %p to multipoller"",+        pollset, and_add_fd, and_add_fd ? and_add_fd->fd : -1,+        pollset->active_pollable->owner_fd);+  }+  append_error(&error, pollset_kick_all(exec_ctx, pollset), err_desc);+  grpc_fd *initial_fd = pollset->active_pollable->owner_fd;+  POLLABLE_UNREF(pollset->active_pollable, ""pollset"");+  pollset->active_pollable = NULL;+  if (append_error(&error, pollable_create(PO_MULTI, &pollset->active_pollable),+                   err_desc)) {+    append_error(&error, pollable_add_fd(pollset->active_pollable, initial_fd),+                 err_desc);+    if (and_add_fd != NULL) {+      append_error(&error,+                   pollable_add_fd(pollset->active_pollable, and_add_fd),+                   err_desc);+    }+  }+  return error; }  /* expects pollsets locked, flag whether fd is locked or not */ static grpc_error *pollset_add_fd_locked(grpc_exec_ctx *exec_ctx,-                                         grpc_pollset *pollset, grpc_fd *fd,-                                         bool fd_locked) {-  static const char *err_desc = ""pollset_add_fd"";+                                         grpc_pollset *pollset, grpc_fd *fd) {   grpc_error *error = GRPC_ERROR_NONE;-  if (pollset->current_pollable_obj == &g_empty_pollable) {-    if (GRPC_TRACER_ON(grpc_polling_trace)) {-      gpr_log(GPR_DEBUG,-              ""PS:%p add fd %p; transition pollable from empty to fd"", pollset,-              fd);-    }-    /* empty pollable --> single fd pollable */-    pollset_kick_all(exec_ctx, pollset);-    pollset->current_pollable_obj = &fd->pollable_obj;-    if (!fd_locked) gpr_mu_lock(&fd->pollable_obj.po.mu);-    append_error(&error, fd_become_pollable_locked(fd), err_desc);-    if (!fd_locked) gpr_mu_unlock(&fd->pollable_obj.po.mu);-    REF_BY(fd, 2, ""pollset_pollable"");-  } else if (pollset->current_pollable_obj == &pollset->pollable_obj) {-    if (GRPC_TRACER_ON(grpc_polling_trace)) {-      gpr_log(GPR_DEBUG, ""PS:%p add fd %p; already multipolling"", pollset, fd);-    }-    append_error(&error, pollable_add_fd(pollset->current_pollable_obj, fd),-                 err_desc);-  } else if (pollset->current_pollable_obj != &fd->pollable_obj) {-    grpc_fd *had_fd = (grpc_fd *)pollset->current_pollable_obj;-    if (GRPC_TRACER_ON(grpc_polling_trace)) {-      gpr_log(GPR_DEBUG,-              ""PS:%p add fd %p; transition pollable from fd %p to multipoller"",-              pollset, fd, had_fd);-    }-    /* Introduce a spurious completion.-       If we do not, then it may be that the fd-specific epoll set consumed-       a completion without being polled, leading to a missed edge going up. */-    grpc_lfev_set_ready(exec_ctx, &had_fd->read_closure, ""read"");-    grpc_lfev_set_ready(exec_ctx, &had_fd->write_closure, ""write"");-    pollset_kick_all(exec_ctx, pollset);-    pollset->current_pollable_obj = &pollset->pollable_obj;-    if (append_error(&error, pollable_materialize(&pollset->pollable_obj),-                     err_desc)) {-      pollable_add_fd(&pollset->pollable_obj, had_fd);-      pollable_add_fd(&pollset->pollable_obj, fd);-    }-    GRPC_CLOSURE_SCHED(exec_ctx,-                       GRPC_CLOSURE_CREATE(unref_fd_no_longer_poller, had_fd,-                                           grpc_schedule_on_exec_ctx),-                       GRPC_ERROR_NONE);+  pollable *po_at_start =+      POLLABLE_REF(pollset->active_pollable, ""pollset_add_fd"");+  switch (pollset->active_pollable->type) {+    case PO_EMPTY:+      /* empty pollable --> single fd pollable */+      error = pollset_transition_pollable_from_empty_to_fd_locked(exec_ctx,+                                                                  pollset, fd);+      break;+    case PO_FD:+      gpr_mu_lock(&po_at_start->owner_fd->orphan_mu);+      if ((gpr_atm_no_barrier_load(&pollset->active_pollable->owner_fd->refst) &+           1) == 0) {+        error = pollset_transition_pollable_from_empty_to_fd_locked(+            exec_ctx, pollset, fd);+      } else {+        /* fd --> multipoller */+        error = pollset_transition_pollable_from_fd_to_multi_locked(+            exec_ctx, pollset, fd);+      }+      gpr_mu_unlock(&po_at_start->owner_fd->orphan_mu);+      break;+    case PO_MULTI:+      error = pollable_add_fd(pollset->active_pollable, fd);+      break;+  }+  if (error != GRPC_ERROR_NONE) {+    POLLABLE_UNREF(pollset->active_pollable, ""pollset"");+    pollset->active_pollable = po_at_start;+  } else {+    POLLABLE_UNREF(po_at_start, ""pollset_add_fd"");+  }+  return error;+}++static grpc_error *pollset_as_multipollable_locked(grpc_exec_ctx *exec_ctx,+                                                   grpc_pollset *pollset,+                                                   pollable **pollable_obj) {+  grpc_error *error = GRPC_ERROR_NONE;+  pollable *po_at_start =+      POLLABLE_REF(pollset->active_pollable, ""pollset_as_multipollable"");+  switch (pollset->active_pollable->type) {+    case PO_EMPTY:+      POLLABLE_UNREF(pollset->active_pollable, ""pollset"");+      error = pollable_create(PO_MULTI, &pollset->active_pollable);+      break;+    case PO_FD:+      gpr_mu_lock(&po_at_start->owner_fd->orphan_mu);+      if ((gpr_atm_no_barrier_load(&pollset->active_pollable->owner_fd->refst) &+           1) == 0) {+        POLLABLE_UNREF(pollset->active_pollable, ""pollset"");+        error = pollable_create(PO_MULTI, &pollset->active_pollable);+      } else {+        error = pollset_transition_pollable_from_fd_to_multi_locked(+            exec_ctx, pollset, NULL);+      }+      gpr_mu_unlock(&po_at_start->owner_fd->orphan_mu);+      break;+    case PO_MULTI:+      break;+  }+  if (error != GRPC_ERROR_NONE) {+    POLLABLE_UNREF(pollset->active_pollable, ""pollset"");+    pollset->active_pollable = po_at_start;+    *pollable_obj = NULL;+  } else {+    *pollable_obj = POLLABLE_REF(pollset->active_pollable, ""pollset_set"");+    POLLABLE_UNREF(po_at_start, ""pollset_as_multipollable"");   }   return error; }  static void pollset_add_fd(grpc_exec_ctx *exec_ctx, grpc_pollset *pollset,                            grpc_fd *fd) {-  gpr_mu_lock(&pollset->pollable_obj.po.mu);-  grpc_error *error = pollset_add_fd_locked(exec_ctx, pollset, fd, false);-  gpr_mu_unlock(&pollset->pollable_obj.po.mu);+  gpr_mu_lock(&pollset->mu);+  grpc_error *error = pollset_add_fd_locked(exec_ctx, pollset, fd);+  gpr_mu_unlock(&pollset->mu);   GRPC_LOG_IF_ERROR(""pollset_add_fd"", error); }  /*******************************************************************************  * Pollset-set Definitions  */ +static grpc_pollset_set *pss_lock_adam(grpc_pollset_set *pss) {",I can't take credit... I learned the name here:https://github.com/CRYTEK/CRYENGINE/blob/ba1b181d5559ea23d84467c9a1f684214dcbdf52/Code/CryEngine/CryEntitySystem/PhysicsProxy.cpp#L213,
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/12789,145473506,2017-10-18T16:43:36Z,src/core/lib/iomgr/ev_epollex_linux.cc,"@@ -916,460 +891,484 @@ static bool begin_worker(grpc_exec_ctx *exec_ctx, grpc_pollset *pollset,                 worker->pollable_obj, worker);       }     }-    if (worker->pollable_obj != &pollset->pollable_obj) {-      gpr_mu_unlock(&worker->pollable_obj->po.mu);-      gpr_mu_lock(&pollset->pollable_obj.po.mu);-      gpr_mu_lock(&worker->pollable_obj->po.mu);-    }     grpc_exec_ctx_invalidate_now(exec_ctx);+  } else {+    gpr_mu_unlock(&pollset->mu);   }+  gpr_mu_unlock(&worker->pollable_obj->mu); -  return do_poll && pollset->shutdown_closure == NULL &&-         pollset->current_pollable_obj == worker->pollable_obj;+  return do_poll; }  static void end_worker(grpc_exec_ctx *exec_ctx, grpc_pollset *pollset,                        grpc_pollset_worker *worker,                        grpc_pollset_worker **worker_hdl) {-  if (NEW_ROOT ==-      worker_remove(&worker->pollable_obj->root_worker, PWL_POLLABLE, worker)) {-    gpr_cv_signal(&worker->pollable_obj->root_worker->cv);+  gpr_mu_lock(&pollset->mu);+  gpr_mu_lock(&worker->pollable_obj->mu);+  switch (worker_remove(&worker->pollable_obj->root_worker, worker,+                        PWLINK_POLLABLE)) {+    case WRR_NEW_ROOT: {+      // wakeup new poller+      grpc_pollset_worker *new_root = worker->pollable_obj->root_worker;+      GPR_ASSERT(new_root->initialized_cv);+      gpr_cv_signal(&new_root->cv);+      break;+    }+    case WRR_EMPTIED:+      if (pollset->active_pollable != worker->pollable_obj) {+        // pollable no longer being polled: flush events+        pollable_process_events(exec_ctx, pollset, worker->pollable_obj, true);+      }+      break;+    case WRR_REMOVED:+      break;+  }+  gpr_mu_unlock(&worker->pollable_obj->mu);+  POLLABLE_UNREF(worker->pollable_obj, ""pollset_worker"");+  if (worker_remove(&pollset->root_worker, worker, PWLINK_POLLSET) ==+      WRR_EMPTIED) {+    pollset_maybe_finish_shutdown(exec_ctx, pollset);   }   if (worker->initialized_cv) {     gpr_cv_destroy(&worker->cv);   }-  if (pollset_is_pollable_fd(pollset, worker->pollable_obj)) {-    UNREF_BY(exec_ctx, (grpc_fd *)worker->pollable_obj, 2, ""one_poll"");-  }-  if (EMPTIED == worker_remove(&pollset->root_worker, PWL_POLLSET, worker)) {-    pollset_maybe_finish_shutdown(exec_ctx, pollset);-  } } +static long gettid(void) { return syscall(__NR_gettid); }+ /* pollset->po.mu lock must be held by the caller before calling this.    The function pollset_work() may temporarily release the lock (pollset->po.mu)    during the course of its execution but it will always re-acquire the lock and    ensure that it is held by the time the function returns */ static grpc_error *pollset_work(grpc_exec_ctx *exec_ctx, grpc_pollset *pollset,                                 grpc_pollset_worker **worker_hdl,                                 grpc_millis deadline) {+#ifdef GRPC_EPOLLEX_CREATE_WORKERS_ON_HEAP+  grpc_pollset_worker *worker =+      (grpc_pollset_worker *)gpr_malloc(sizeof(*worker));+#define WORKER_PTR (worker)+#else   grpc_pollset_worker worker;-  if (0 && GRPC_TRACER_ON(grpc_polling_trace)) {+#define WORKER_PTR (&worker)+#endif+  WORKER_PTR->originator = gettid();+  if (GRPC_TRACER_ON(grpc_polling_trace)) {     gpr_log(GPR_DEBUG, ""PS:%p work hdl=%p worker=%p now=%"" PRIdPTR-                       "" deadline=%"" PRIdPTR "" kwp=%d root_worker=%p"",-            pollset, worker_hdl, &worker, grpc_exec_ctx_now(exec_ctx), deadline,-            pollset->kicked_without_poller, pollset->root_worker);+                       "" deadline=%"" PRIdPTR "" kwp=%d pollable=%p"",+            pollset, worker_hdl, WORKER_PTR, grpc_exec_ctx_now(exec_ctx),+            deadline, pollset->kicked_without_poller, pollset->active_pollable);   }-  grpc_error *error = GRPC_ERROR_NONE;   static const char *err_desc = ""pollset_work"";+  grpc_error *error = GRPC_ERROR_NONE;   if (pollset->kicked_without_poller) {     pollset->kicked_without_poller = false;-    return GRPC_ERROR_NONE;-  }-  if (pollset->current_pollable_obj != &pollset->pollable_obj) {-    gpr_mu_lock(&pollset->current_pollable_obj->po.mu);-  }-  if (begin_worker(exec_ctx, pollset, &worker, worker_hdl, deadline)) {-    gpr_tls_set(&g_current_thread_pollset, (intptr_t)pollset);-    gpr_tls_set(&g_current_thread_worker, (intptr_t)&worker);-    GPR_ASSERT(!pollset->shutdown_closure);-    append_error(&error, pollable_materialize(worker.pollable_obj), err_desc);-    if (worker.pollable_obj != &pollset->pollable_obj) {-      gpr_mu_unlock(&worker.pollable_obj->po.mu);-    }-    gpr_mu_unlock(&pollset->pollable_obj.po.mu);-    if (pollset->event_cursor == pollset->event_count) {-      append_error(&error, pollset_epoll(exec_ctx, pollset, worker.pollable_obj,-                                         deadline),+  } else {+    if (begin_worker(exec_ctx, pollset, WORKER_PTR, worker_hdl, deadline)) {+      gpr_tls_set(&g_current_thread_pollset, (intptr_t)pollset);+      gpr_tls_set(&g_current_thread_worker, (intptr_t)WORKER_PTR);+      if (WORKER_PTR->pollable_obj->event_cursor ==+          WORKER_PTR->pollable_obj->event_count) {+        append_error(&error, pollset_epoll(exec_ctx, pollset,+                                           WORKER_PTR->pollable_obj, deadline),+                     err_desc);+      }+      append_error(&error,+                   pollable_process_events(exec_ctx, pollset,+                                           WORKER_PTR->pollable_obj, false),                    err_desc);+      grpc_exec_ctx_flush(exec_ctx);+      gpr_tls_set(&g_current_thread_pollset, 0);+      gpr_tls_set(&g_current_thread_worker, 0);     }-    append_error(&error, pollset_process_events(exec_ctx, pollset, false),-                 err_desc);-    gpr_mu_lock(&pollset->pollable_obj.po.mu);-    if (worker.pollable_obj != &pollset->pollable_obj) {-      gpr_mu_lock(&worker.pollable_obj->po.mu);-    }-    gpr_tls_set(&g_current_thread_pollset, 0);-    gpr_tls_set(&g_current_thread_worker, 0);-    pollset_maybe_finish_shutdown(exec_ctx, pollset);-  }-  end_worker(exec_ctx, pollset, &worker, worker_hdl);-  if (worker.pollable_obj != &pollset->pollable_obj) {-    gpr_mu_unlock(&worker.pollable_obj->po.mu);+    end_worker(exec_ctx, pollset, WORKER_PTR, worker_hdl);   }-  if (grpc_exec_ctx_has_work(exec_ctx)) {-    gpr_mu_unlock(&pollset->pollable_obj.po.mu);-    grpc_exec_ctx_flush(exec_ctx);-    gpr_mu_lock(&pollset->pollable_obj.po.mu);+#ifdef GRPC_EPOLLEX_CREATE_WORKERS_ON_HEAP+  gpr_free(worker);+#endif+#undef WORKER_PTR+  return error;+}++static grpc_error *pollset_transition_pollable_from_empty_to_fd_locked(+    grpc_exec_ctx *exec_ctx, grpc_pollset *pollset, grpc_fd *fd) {+  static const char *err_desc = ""pollset_transition_pollable_from_empty_to_fd"";+  grpc_error *error = GRPC_ERROR_NONE;+  if (GRPC_TRACER_ON(grpc_polling_trace)) {+    gpr_log(GPR_DEBUG,+            ""PS:%p add fd %p (%d); transition pollable from empty to fd"",+            pollset, fd, fd->fd);   }+  append_error(&error, pollset_kick_all(exec_ctx, pollset), err_desc);+  POLLABLE_UNREF(pollset->active_pollable, ""pollset"");+  append_error(&error, fd_become_pollable(fd, &pollset->active_pollable),+               err_desc);   return error; } -static void unref_fd_no_longer_poller(grpc_exec_ctx *exec_ctx, void *arg,-                                      grpc_error *error) {-  grpc_fd *fd = (grpc_fd *)arg;-  UNREF_BY(exec_ctx, fd, 2, ""pollset_pollable"");+static grpc_error *pollset_transition_pollable_from_fd_to_multi_locked(+    grpc_exec_ctx *exec_ctx, grpc_pollset *pollset, grpc_fd *and_add_fd) {+  static const char *err_desc = ""pollset_transition_pollable_from_fd_to_multi"";+  grpc_error *error = GRPC_ERROR_NONE;+  if (GRPC_TRACER_ON(grpc_polling_trace)) {+    gpr_log(+        GPR_DEBUG,+        ""PS:%p add fd %p (%d); transition pollable from fd %p to multipoller"",+        pollset, and_add_fd, and_add_fd ? and_add_fd->fd : -1,+        pollset->active_pollable->owner_fd);+  }+  append_error(&error, pollset_kick_all(exec_ctx, pollset), err_desc);+  grpc_fd *initial_fd = pollset->active_pollable->owner_fd;+  POLLABLE_UNREF(pollset->active_pollable, ""pollset"");+  pollset->active_pollable = NULL;+  if (append_error(&error, pollable_create(PO_MULTI, &pollset->active_pollable),+                   err_desc)) {+    append_error(&error, pollable_add_fd(pollset->active_pollable, initial_fd),+                 err_desc);+    if (and_add_fd != NULL) {+      append_error(&error,+                   pollable_add_fd(pollset->active_pollable, and_add_fd),+                   err_desc);+    }+  }+  return error; }  /* expects pollsets locked, flag whether fd is locked or not */ static grpc_error *pollset_add_fd_locked(grpc_exec_ctx *exec_ctx,-                                         grpc_pollset *pollset, grpc_fd *fd,-                                         bool fd_locked) {-  static const char *err_desc = ""pollset_add_fd"";+                                         grpc_pollset *pollset, grpc_fd *fd) {   grpc_error *error = GRPC_ERROR_NONE;-  if (pollset->current_pollable_obj == &g_empty_pollable) {-    if (GRPC_TRACER_ON(grpc_polling_trace)) {-      gpr_log(GPR_DEBUG,-              ""PS:%p add fd %p; transition pollable from empty to fd"", pollset,-              fd);-    }-    /* empty pollable --> single fd pollable */-    pollset_kick_all(exec_ctx, pollset);-    pollset->current_pollable_obj = &fd->pollable_obj;-    if (!fd_locked) gpr_mu_lock(&fd->pollable_obj.po.mu);-    append_error(&error, fd_become_pollable_locked(fd), err_desc);-    if (!fd_locked) gpr_mu_unlock(&fd->pollable_obj.po.mu);-    REF_BY(fd, 2, ""pollset_pollable"");-  } else if (pollset->current_pollable_obj == &pollset->pollable_obj) {-    if (GRPC_TRACER_ON(grpc_polling_trace)) {-      gpr_log(GPR_DEBUG, ""PS:%p add fd %p; already multipolling"", pollset, fd);-    }-    append_error(&error, pollable_add_fd(pollset->current_pollable_obj, fd),-                 err_desc);-  } else if (pollset->current_pollable_obj != &fd->pollable_obj) {-    grpc_fd *had_fd = (grpc_fd *)pollset->current_pollable_obj;-    if (GRPC_TRACER_ON(grpc_polling_trace)) {-      gpr_log(GPR_DEBUG,-              ""PS:%p add fd %p; transition pollable from fd %p to multipoller"",-              pollset, fd, had_fd);-    }-    /* Introduce a spurious completion.-       If we do not, then it may be that the fd-specific epoll set consumed-       a completion without being polled, leading to a missed edge going up. */-    grpc_lfev_set_ready(exec_ctx, &had_fd->read_closure, ""read"");-    grpc_lfev_set_ready(exec_ctx, &had_fd->write_closure, ""write"");-    pollset_kick_all(exec_ctx, pollset);-    pollset->current_pollable_obj = &pollset->pollable_obj;-    if (append_error(&error, pollable_materialize(&pollset->pollable_obj),-                     err_desc)) {-      pollable_add_fd(&pollset->pollable_obj, had_fd);-      pollable_add_fd(&pollset->pollable_obj, fd);-    }-    GRPC_CLOSURE_SCHED(exec_ctx,-                       GRPC_CLOSURE_CREATE(unref_fd_no_longer_poller, had_fd,-                                           grpc_schedule_on_exec_ctx),-                       GRPC_ERROR_NONE);+  pollable *po_at_start =+      POLLABLE_REF(pollset->active_pollable, ""pollset_add_fd"");+  switch (pollset->active_pollable->type) {+    case PO_EMPTY:+      /* empty pollable --> single fd pollable */+      error = pollset_transition_pollable_from_empty_to_fd_locked(exec_ctx,+                                                                  pollset, fd);+      break;+    case PO_FD:+      gpr_mu_lock(&po_at_start->owner_fd->orphan_mu);+      if ((gpr_atm_no_barrier_load(&pollset->active_pollable->owner_fd->refst) &+           1) == 0) {+        error = pollset_transition_pollable_from_empty_to_fd_locked(+            exec_ctx, pollset, fd);+      } else {+        /* fd --> multipoller */+        error = pollset_transition_pollable_from_fd_to_multi_locked(+            exec_ctx, pollset, fd);+      }+      gpr_mu_unlock(&po_at_start->owner_fd->orphan_mu);+      break;+    case PO_MULTI:+      error = pollable_add_fd(pollset->active_pollable, fd);+      break;+  }+  if (error != GRPC_ERROR_NONE) {+    POLLABLE_UNREF(pollset->active_pollable, ""pollset"");+    pollset->active_pollable = po_at_start;+  } else {+    POLLABLE_UNREF(po_at_start, ""pollset_add_fd"");+  }+  return error;+}++static grpc_error *pollset_as_multipollable_locked(grpc_exec_ctx *exec_ctx,+                                                   grpc_pollset *pollset,+                                                   pollable **pollable_obj) {+  grpc_error *error = GRPC_ERROR_NONE;+  pollable *po_at_start =+      POLLABLE_REF(pollset->active_pollable, ""pollset_as_multipollable"");+  switch (pollset->active_pollable->type) {+    case PO_EMPTY:+      POLLABLE_UNREF(pollset->active_pollable, ""pollset"");+      error = pollable_create(PO_MULTI, &pollset->active_pollable);+      break;+    case PO_FD:+      gpr_mu_lock(&po_at_start->owner_fd->orphan_mu);+      if ((gpr_atm_no_barrier_load(&pollset->active_pollable->owner_fd->refst) &+           1) == 0) {+        POLLABLE_UNREF(pollset->active_pollable, ""pollset"");+        error = pollable_create(PO_MULTI, &pollset->active_pollable);+      } else {+        error = pollset_transition_pollable_from_fd_to_multi_locked(+            exec_ctx, pollset, NULL);+      }+      gpr_mu_unlock(&po_at_start->owner_fd->orphan_mu);+      break;+    case PO_MULTI:+      break;+  }+  if (error != GRPC_ERROR_NONE) {+    POLLABLE_UNREF(pollset->active_pollable, ""pollset"");+    pollset->active_pollable = po_at_start;+    *pollable_obj = NULL;+  } else {+    *pollable_obj = POLLABLE_REF(pollset->active_pollable, ""pollset_set"");+    POLLABLE_UNREF(po_at_start, ""pollset_as_multipollable"");   }   return error; }  static void pollset_add_fd(grpc_exec_ctx *exec_ctx, grpc_pollset *pollset,                            grpc_fd *fd) {-  gpr_mu_lock(&pollset->pollable_obj.po.mu);-  grpc_error *error = pollset_add_fd_locked(exec_ctx, pollset, fd, false);-  gpr_mu_unlock(&pollset->pollable_obj.po.mu);+  gpr_mu_lock(&pollset->mu);+  grpc_error *error = pollset_add_fd_locked(exec_ctx, pollset, fd);+  gpr_mu_unlock(&pollset->mu);   GRPC_LOG_IF_ERROR(""pollset_add_fd"", error); }  /*******************************************************************************  * Pollset-set Definitions  */ +static grpc_pollset_set *pss_lock_adam(grpc_pollset_set *pss) {",(a long long time ago in a galaxy far far away),
17460127,y-zeng,https://api.github.com/repos/grpc/grpc/pulls/12732,145541805,2017-10-18T21:03:32Z,doc/environment_variables.md,"@@ -118,10 +118,10 @@ some configuration as environment variables that can be set.     perform name resolution   - ares - a DNS resolver based around the c-ares library -* GRPC_DISABLE_CHANNEL_CONNECTIVITY_WATCHER-  The channel connectivity watcher uses one extra thread to check the channel-  state every 500 ms on the client side. It can help reconnect disconnected-  client channels (mostly due to idleness), so that the next RPC on this channel-  won't fail. Set to 1 to turn off this watcher and save a thread. Please note-  this is a temporary work-around, it will be removed in the future once we have-  support for automatically reestablishing failed connections.+* GRPC_CLIENT_CHANNEL_BACKUP_POLL_INTERVAL_MS+  Default: 500","Changed to 5s. I agree that 5s would be a safer number to use without hurting correctness. But if the concern is about the performance impact, our implementation here has minimized its performance impact. I've tested it with our benchmark suite. It had similar scores with 500ms, 5s, and Inf intervals. The differences between their scores are less than 0.005.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/12878,145667410,2017-10-19T11:02:41Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -42,99 +43,73 @@ typedef struct {   /** base policy: must be first */   grpc_lb_policy base;   /** all our subchannels */-  grpc_subchannel **subchannels;-  grpc_subchannel **new_subchannels;-  size_t num_subchannels;-  size_t num_new_subchannels;--  grpc_closure connectivity_changed;--  /** remaining members are protected by the combiner */--  /** the selected channel */-  grpc_connected_subchannel *selected;--  /** the subchannel key for \a selected, or NULL if \a selected not set */-  const grpc_subchannel_key *selected_key;-+  grpc_lb_subchannel_list *subchannel_list;+  /** latest pending subchannel list */+  grpc_lb_subchannel_list *latest_pending_subchannel_list;+  /** selected subchannel in \a subchannel_list */+  grpc_lb_subchannel_data *selected;   /** have we started picking? */   bool started_picking;   /** are we shut down? */   bool shutdown;-  /** are we updating the selected subchannel? */-  bool updating_selected;-  /** are we updating the subchannel candidates? */-  bool updating_subchannels;-  /** args from the latest update received while already updating, or NULL */-  grpc_lb_policy_args *pending_update_args;-  /** which subchannel are we watching? */-  size_t checking_subchannel;-  /** what is the connectivity of that channel? */-  grpc_connectivity_state checking_connectivity;   /** list of picks that are waiting on connectivity */   pending_pick *pending_picks;-   /** our connectivity state tracker */   grpc_connectivity_state_tracker state_tracker; } pick_first_lb_policy;  static void pf_destroy(grpc_exec_ctx *exec_ctx, grpc_lb_policy *pol) {   pick_first_lb_policy *p = (pick_first_lb_policy *)pol;+  GPR_ASSERT(p->subchannel_list == NULL);+  GPR_ASSERT(p->latest_pending_subchannel_list == NULL);   GPR_ASSERT(p->pending_picks == NULL);-  for (size_t i = 0; i < p->num_subchannels; i++) {-    GRPC_SUBCHANNEL_UNREF(exec_ctx, p->subchannels[i], ""pick_first_destroy"");-  }-  if (p->selected != NULL) {-    GRPC_CONNECTED_SUBCHANNEL_UNREF(exec_ctx, p->selected,-                                    ""picked_first_destroy"");-  }   grpc_connectivity_state_destroy(exec_ctx, &p->state_tracker);-  grpc_subchannel_index_unref();-  if (p->pending_update_args != NULL) {-    grpc_channel_args_destroy(exec_ctx, p->pending_update_args->args);-    gpr_free(p->pending_update_args);-  }-  gpr_free(p->subchannels);-  gpr_free(p->new_subchannels);   gpr_free(p);+  grpc_subchannel_index_unref();   if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {     gpr_log(GPR_DEBUG, ""Pick First %p destroyed."", (void *)p);   } } -static void pf_shutdown_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *pol) {-  pick_first_lb_policy *p = (pick_first_lb_policy *)pol;-  pending_pick *pp;-  p->shutdown = true;-  pp = p->pending_picks;-  p->pending_picks = NULL;-  grpc_connectivity_state_set(-      exec_ctx, &p->state_tracker, GRPC_CHANNEL_SHUTDOWN,-      GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Channel shutdown""), ""shutdown"");-  /* cancel subscription */-  if (p->selected != NULL) {-    grpc_connected_subchannel_notify_on_state_change(-        exec_ctx, p->selected, NULL, NULL, &p->connectivity_changed);-  } else if (p->num_subchannels > 0 && p->started_picking) {-    grpc_subchannel_notify_on_state_change(-        exec_ctx, p->subchannels[p->checking_subchannel], NULL, NULL,-        &p->connectivity_changed);+static void shutdown_locked(grpc_exec_ctx *exec_ctx, pick_first_lb_policy *p,+                            grpc_error *error) {+  if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {+    gpr_log(GPR_DEBUG, ""Pick First %p Shutting down"", p);   }-  while (pp != NULL) {-    pending_pick *next = pp->next;+  p->shutdown = true;+  pending_pick *pp;+  while ((pp = p->pending_picks) != NULL) {+    p->pending_picks = pp->next;     *pp->target = NULL;-    GRPC_CLOSURE_SCHED(exec_ctx, pp->on_complete, GRPC_ERROR_NONE);+    GRPC_CLOSURE_SCHED(exec_ctx, pp->on_complete, GRPC_ERROR_REF(error));     gpr_free(pp);-    pp = next;   }+  grpc_connectivity_state_set(exec_ctx, &p->state_tracker,+                              GRPC_CHANNEL_SHUTDOWN, GRPC_ERROR_REF(error),+                              ""shutdown"");+  if (p->subchannel_list != NULL) {+    grpc_lb_subchannel_list_shutdown_and_unref(exec_ctx, p->subchannel_list,+                                               ""pf_shutdown"");+    p->subchannel_list = NULL;+  }+  if (p->latest_pending_subchannel_list != NULL) {","We probably want to replicate [what RR does](https://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc#L337), not shutting down the ""pending"" one if it's been made the current one. ",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12878,145721490,2017-10-19T14:43:24Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -42,99 +43,73 @@ typedef struct {   /** base policy: must be first */   grpc_lb_policy base;   /** all our subchannels */-  grpc_subchannel **subchannels;-  grpc_subchannel **new_subchannels;-  size_t num_subchannels;-  size_t num_new_subchannels;--  grpc_closure connectivity_changed;--  /** remaining members are protected by the combiner */--  /** the selected channel */-  grpc_connected_subchannel *selected;--  /** the subchannel key for \a selected, or NULL if \a selected not set */-  const grpc_subchannel_key *selected_key;-+  grpc_lb_subchannel_list *subchannel_list;+  /** latest pending subchannel list */+  grpc_lb_subchannel_list *latest_pending_subchannel_list;+  /** selected subchannel in \a subchannel_list */+  grpc_lb_subchannel_data *selected;   /** have we started picking? */   bool started_picking;   /** are we shut down? */   bool shutdown;-  /** are we updating the selected subchannel? */-  bool updating_selected;-  /** are we updating the subchannel candidates? */-  bool updating_subchannels;-  /** args from the latest update received while already updating, or NULL */-  grpc_lb_policy_args *pending_update_args;-  /** which subchannel are we watching? */-  size_t checking_subchannel;-  /** what is the connectivity of that channel? */-  grpc_connectivity_state checking_connectivity;   /** list of picks that are waiting on connectivity */   pending_pick *pending_picks;-   /** our connectivity state tracker */   grpc_connectivity_state_tracker state_tracker; } pick_first_lb_policy;  static void pf_destroy(grpc_exec_ctx *exec_ctx, grpc_lb_policy *pol) {   pick_first_lb_policy *p = (pick_first_lb_policy *)pol;+  GPR_ASSERT(p->subchannel_list == NULL);+  GPR_ASSERT(p->latest_pending_subchannel_list == NULL);   GPR_ASSERT(p->pending_picks == NULL);-  for (size_t i = 0; i < p->num_subchannels; i++) {-    GRPC_SUBCHANNEL_UNREF(exec_ctx, p->subchannels[i], ""pick_first_destroy"");-  }-  if (p->selected != NULL) {-    GRPC_CONNECTED_SUBCHANNEL_UNREF(exec_ctx, p->selected,-                                    ""picked_first_destroy"");-  }   grpc_connectivity_state_destroy(exec_ctx, &p->state_tracker);-  grpc_subchannel_index_unref();-  if (p->pending_update_args != NULL) {-    grpc_channel_args_destroy(exec_ctx, p->pending_update_args->args);-    gpr_free(p->pending_update_args);-  }-  gpr_free(p->subchannels);-  gpr_free(p->new_subchannels);   gpr_free(p);+  grpc_subchannel_index_unref();   if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {     gpr_log(GPR_DEBUG, ""Pick First %p destroyed."", (void *)p);   } } -static void pf_shutdown_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *pol) {-  pick_first_lb_policy *p = (pick_first_lb_policy *)pol;-  pending_pick *pp;-  p->shutdown = true;-  pp = p->pending_picks;-  p->pending_picks = NULL;-  grpc_connectivity_state_set(-      exec_ctx, &p->state_tracker, GRPC_CHANNEL_SHUTDOWN,-      GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Channel shutdown""), ""shutdown"");-  /* cancel subscription */-  if (p->selected != NULL) {-    grpc_connected_subchannel_notify_on_state_change(-        exec_ctx, p->selected, NULL, NULL, &p->connectivity_changed);-  } else if (p->num_subchannels > 0 && p->started_picking) {-    grpc_subchannel_notify_on_state_change(-        exec_ctx, p->subchannels[p->checking_subchannel], NULL, NULL,-        &p->connectivity_changed);+static void shutdown_locked(grpc_exec_ctx *exec_ctx, pick_first_lb_policy *p,+                            grpc_error *error) {+  if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {+    gpr_log(GPR_DEBUG, ""Pick First %p Shutting down"", p);   }-  while (pp != NULL) {-    pending_pick *next = pp->next;+  p->shutdown = true;+  pending_pick *pp;+  while ((pp = p->pending_picks) != NULL) {+    p->pending_picks = pp->next;     *pp->target = NULL;-    GRPC_CLOSURE_SCHED(exec_ctx, pp->on_complete, GRPC_ERROR_NONE);+    GRPC_CLOSURE_SCHED(exec_ctx, pp->on_complete, GRPC_ERROR_REF(error));     gpr_free(pp);-    pp = next;   }+  grpc_connectivity_state_set(exec_ctx, &p->state_tracker,+                              GRPC_CHANNEL_SHUTDOWN, GRPC_ERROR_REF(error),+                              ""shutdown"");+  if (p->subchannel_list != NULL) {+    grpc_lb_subchannel_list_shutdown_and_unref(exec_ctx, p->subchannel_list,+                                               ""pf_shutdown"");+    p->subchannel_list = NULL;+  }+  if (p->latest_pending_subchannel_list != NULL) {","I'm not sure why RR does that.  If we promote `latest_pending_subchannel_list` to `subchannel_list`, then we should reset the former to NULL (and I believe that the code always does this).  There's no reason why we should ever leave both fields pointing to the same subchannel list.I've removed the unnecessary check in RR.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12878,145722715,2017-10-19T14:47:16Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -181,15 +155,12 @@ static void pf_cancel_picks_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *pol, static void start_picking_locked(grpc_exec_ctx *exec_ctx,                                  pick_first_lb_policy *p) {   p->started_picking = true;-  if (p->subchannels != NULL) {-    GPR_ASSERT(p->num_subchannels > 0);-    p->checking_subchannel = 0;-    p->checking_connectivity = GRPC_CHANNEL_IDLE;-    GRPC_LB_POLICY_WEAK_REF(&p->base, ""pick_first_connectivity"");-    grpc_subchannel_notify_on_state_change(-        exec_ctx, p->subchannels[p->checking_subchannel],-        p->base.interested_parties, &p->checking_connectivity,-        &p->connectivity_changed);+  if (p->subchannel_list != NULL && p->subchannel_list->num_subchannels > 0) {+    p->subchannel_list->checking_subchannel = 0;+    grpc_lb_subchannel_list_ref_for_connectivity_watch(+        p->subchannel_list, ""connectivity_watch+start_picking"");+    grpc_lb_subchannel_data_start_connectivity_watch(","It doesn't need to be initialized.  The only place we ever look at it is in the connectivity callback, which won't be called until it's set.  Note that the RR code prior to this PR did not initialize it either.Perhaps you're thinking of `prev_connectivity_state`?  That gets initialized in `grpc_lb_subchannel_list_create()`, the same way that it was initialized in RR before this PR.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13068,146022928,2017-10-20T17:30:43Z,src/core/lib/support/closure_ref.h,"@@ -0,0 +1,248 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_SUPPORT_CLOSURE_REF_H+#define GRPC_CORE_LIB_SUPPORT_CLOSURE_REF_H++#include <stdio.h>+#include <stdlib.h>+#include <utility>++namespace grpc_core {++// Value type reference to some closure+// Template arguments list argument types to the closure+// Closures have an implicit scheduling policy bound when they are created+template <typename... Args>+class ClosureRef {+ public:+  struct VTable {+    void (*schedule)(void* env, Args&&... args);+    void (*run)(void* env, Args&&... args);+  };++  ClosureRef(const VTable* vtable, void* env) : vtable_(vtable), env_(env) {}+  ClosureRef() : vtable_(&null_vtable_), env_(nullptr) {}++  // Run this closure, in-place if possible+  void Run(Args&&... args) { vtable_->run(env_, std::forward<Args>(args)...); }++  // Schedule this closure for execution in a safe environment+  void Schedule(Args&&... args) {+    vtable_->schedule(env_, std::forward<Args>(args)...);+  }++ private:+  const VTable* vtable_;+  void* env_;++  static void null_exec(void* env, Args&&... args) { abort(); }++  static const VTable null_vtable_;+};++template <typename... Args>+const typename ClosureRef<Args...>::VTable ClosureRef<Args...>::null_vtable_ = {+    ClosureRef<Args...>::null_exec, ClosureRef<Args...>::null_exec,+};++//+// MakeClosure implementation details...+// Expect to write a code generator for this+//++namespace impl {+template <class Scheduler, class Env, void (*F)()>+class FnClosure {+ public:+  static const typename ClosureRef<>::VTable vtable;++ private:+  static void Schedule(void* env) {+    Scheduler::Schedule([](void*) { F(); }, static_cast<Env*>(env));+  }+  static void Run(void* env) {+    Scheduler::Run([](void*) { F(); }, static_cast<Env*>(env));+  }+};+template <class Scheduler, class Env, void (*F)()>+const typename ClosureRef<>::VTable FnClosure<Scheduler, Env, F>::vtable = {+    FnClosure<Scheduler, Env, F>::Schedule, FnClosure<Scheduler, Env, F>::Run};++template <class Scheduler, class Env, typename T, void (*F)(T)>+class FnClosure1 {+ public:+  static const typename ClosureRef<T>::VTable vtable;++ private:+  static void Schedule(void* env, T&& t) {+    Scheduler::Schedule([t](void*) { F(t); }, static_cast<Env*>(env));+  }+  static void Run(void* env, T&& t) {+    Scheduler::Run([t](void*) { F(t); }, static_cast<Env*>(env));+  }+};+template <class Scheduler, class Env, typename T, void (*F)(T)>+const typename ClosureRef<T>::VTable FnClosure1<Scheduler, Env, T, F>::vtable =+    {FnClosure1<Scheduler, Env, T, F>::Schedule,+     FnClosure1<Scheduler, Env, T, F>::Run};++template <class Scheduler, class T, void (T::*F)()>+class MemClosure {+ public:+  static const typename ClosureRef<>::VTable vtable;++ private:+  static void Schedule(void* env) {+    Scheduler::Schedule([](void* env) { (static_cast<T*>(env)->*F)(); },+                        static_cast<T*>(env));+  }+  static void Run(void* env) {+    Scheduler::Run([](void* env) { (static_cast<T*>(env)->*F)(); },+                   static_cast<T*>(env));+  }+};+template <class Scheduler, class T, void (T::*F)()>+const typename ClosureRef<>::VTable MemClosure<Scheduler, T, F>::vtable = {+    MemClosure<Scheduler, T, F>::Schedule, MemClosure<Scheduler, T, F>::Run};+}++template <class Scheduler, void (*F)(), typename Env = std::nullptr_t>+ClosureRef<> MakeClosure(Env* env = nullptr) {+  return ClosureRef<>(&impl::FnClosure<Scheduler, Env, F>::vtable, env);+}++template <class Scheduler, typename T, void (*F)(T),+          typename Env = std::nullptr_t>+ClosureRef<T> MakeClosure(Env* env = nullptr) {+  return ClosureRef<int>(&impl::FnClosure1<Scheduler, Env, T, F>::vtable, env);+}++template <class Scheduler, typename T, void (T::*F)()>+ClosureRef<> MakeClosure(T* p) {+  return ClosureRef<>(&impl::MemClosure<Scheduler, T, F>::vtable, p);+}++//+// SCHEDULERS+//++class AcquiresNoLocks {+ public:+  template <class T, class F>+  static void Schedule(F&& f, T* env) {+    f(env);+  }+  template <class T, class F>+  static void Run(F&& f, T* env) {+    f(env);+  }+};++template <class F>+void QueueOnExecCtx(F&& f);++class RunInCurrentThread {+ public:+  template <class T, class F>+  static void Schedule(F&& f, T* env) {+    QueueOnExecCtx([f, env]() { f(env); });+  }+  template <class T, class F>+  static void Run(F&& f, T* env) {+    f(env);+  }+};++class RunInCombiner {+ public:+  template <class T, class F>+  static void Schedule(F&& f, T* env) {+    env->combiner()->Schedule([f, env]() { f(env); });+  }+  template <class T, class F>+  static void Run(F&& f, T* env) {+    env->combiner()->Run([f, env]() { f(env); });+  }+};++// Dummy combiner lock impl++class Combiner {+ public:+  template <class F>+  void Schedule(F&& f);+  template <class F>+  void Run(F&& f);+};++//+// TEST CODE+//++void PrintLine();+void PrintInt(int);++class Foo {+ public:+  void Callback();++  Combiner* combiner() { return &combiner_; }++ private:+  Combiner combiner_;+};++ClosureRef<> Hidden();++void test() {+  // simple closures around functions, member functions+  ClosureRef<> print_line = MakeClosure<AcquiresNoLocks, PrintLine>();+  ClosureRef<int> print_int = MakeClosure<AcquiresNoLocks, int, PrintInt>();+  Foo foo;+  ClosureRef<> foo_cb = MakeClosure<AcquiresNoLocks, Foo, &Foo::Callback>(&foo);","As we've discussed, I expect this to be the common case, and I'd like to see some syntactic sugar to make it less verbose.  Ideally, I'd like to be able to say something like this:```ClosureRef<> foo_cb = MakeClosure(AcquiresNoLocks, &foo, &Foo::Callback);```Even better would be if the middle arg wasn't needed, but I suspect that would be harder.",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/13084,146037456,2017-10-20T18:34:31Z,include/grpc++/impl/codegen/completion_queue.h,"@@ -109,6 +111,26 @@ class CompletionQueue : private GrpcLibraryCodegen {     TIMEOUT     ///< deadline was reached.   }; +  /// EXPERIMENTAL+  /// First executes \a F, then reads from the queue, blocking up to+  /// \a deadline (or the queue's shutdown).+  /// Both \a tag and \a ok are updated upon success (if an event is available+  /// within the \a deadline).  A \a tag points to an arbitrary location usually+  /// employed to uniquely identify an event.+  ///+  /// \param F[in] Function to execute before calling AsyncNext on this queue.+  /// \param tag[out] Upon sucess, updated to point to the event's tag.+  /// \param ok[out] Upon sucess, true if read a regular event, false otherwise.+  /// \param deadline[in] How long to block in wait for an event.+  ///+  /// \return The type of event read.+  template <typename T>+  NextStatus DoThenAsyncNext(const std::function<void(void)>& F, void** tag,","can we do:```c++template <typename T, typename F>NextStatus DoThenAsyncNext(F&& f, /* ... rest of args ... */) {  // ... rest of code}```and avoid unnecessarily instantiating a std::function (since this is not for free, and lambda's pretty much are)",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/13084,146037610,2017-10-20T18:35:14Z,include/grpc++/impl/codegen/completion_queue.h,"@@ -215,6 +237,10 @@ class CompletionQueue : private GrpcLibraryCodegen {    NextStatus AsyncNextInternal(void** tag, bool* ok, gpr_timespec deadline); +  NextStatus DoThenAsyncNextInternal(const std::function<void(void)>& F,","similarly here, and hoist the implementation into the header",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/13084,146037921,2017-10-20T18:36:42Z,src/cpp/common/completion_queue_cc.cc,"@@ -50,6 +50,26 @@ void CompletionQueue::CompleteAvalanching() {   } } +CompletionQueue::NextStatus CompletionQueue::DoThenAsyncNextInternal(+    const std::function<void(void)>& F, void** tag, bool* ok,+    gpr_timespec deadline) {+  grpc_prepare_cq_tls_cache(cq_);",Can we make a small class to handle the TLS cache here... constructor calls grpc_prepare... destructor does the cleanup (and could be in a cc file out of line since it's sufficiently complex),
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/12878,146066141,2017-10-20T21:02:54Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -181,15 +155,12 @@ static void pf_cancel_picks_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *pol, static void start_picking_locked(grpc_exec_ctx *exec_ctx,                                  pick_first_lb_policy *p) {   p->started_picking = true;-  if (p->subchannels != NULL) {-    GPR_ASSERT(p->num_subchannels > 0);-    p->checking_subchannel = 0;-    p->checking_connectivity = GRPC_CHANNEL_IDLE;-    GRPC_LB_POLICY_WEAK_REF(&p->base, ""pick_first_connectivity"");-    grpc_subchannel_notify_on_state_change(-        exec_ctx, p->subchannels[p->checking_subchannel],-        p->base.interested_parties, &p->checking_connectivity,-        &p->connectivity_changed);+  if (p->subchannel_list != NULL && p->subchannel_list->num_subchannels > 0) {+    p->subchannel_list->checking_subchannel = 0;+    grpc_lb_subchannel_list_ref_for_connectivity_watch(+        p->subchannel_list, ""connectivity_watch+start_picking"");+    grpc_lb_subchannel_data_start_connectivity_watch(","The docs of `grpc_subchannel_notify_on_state_change` say ""call notify when the connectivity state of a channel changes from *state"". That is, it's also part of the input, not just the output. If RR didn't previously do it, it was a bug. I remember similar bugs in the recent past: a subchannel went from INIT to CONNECTING without passing through IDLE (the default state, being int 0), resulting in the callback never being invoked. ",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/12878,146066586,2017-10-20T21:05:15Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -42,99 +43,73 @@ typedef struct {   /** base policy: must be first */   grpc_lb_policy base;   /** all our subchannels */-  grpc_subchannel **subchannels;-  grpc_subchannel **new_subchannels;-  size_t num_subchannels;-  size_t num_new_subchannels;--  grpc_closure connectivity_changed;--  /** remaining members are protected by the combiner */--  /** the selected channel */-  grpc_connected_subchannel *selected;--  /** the subchannel key for \a selected, or NULL if \a selected not set */-  const grpc_subchannel_key *selected_key;-+  grpc_lb_subchannel_list *subchannel_list;+  /** latest pending subchannel list */+  grpc_lb_subchannel_list *latest_pending_subchannel_list;+  /** selected subchannel in \a subchannel_list */+  grpc_lb_subchannel_data *selected;   /** have we started picking? */   bool started_picking;   /** are we shut down? */   bool shutdown;-  /** are we updating the selected subchannel? */-  bool updating_selected;-  /** are we updating the subchannel candidates? */-  bool updating_subchannels;-  /** args from the latest update received while already updating, or NULL */-  grpc_lb_policy_args *pending_update_args;-  /** which subchannel are we watching? */-  size_t checking_subchannel;-  /** what is the connectivity of that channel? */-  grpc_connectivity_state checking_connectivity;   /** list of picks that are waiting on connectivity */   pending_pick *pending_picks;-   /** our connectivity state tracker */   grpc_connectivity_state_tracker state_tracker; } pick_first_lb_policy;  static void pf_destroy(grpc_exec_ctx *exec_ctx, grpc_lb_policy *pol) {   pick_first_lb_policy *p = (pick_first_lb_policy *)pol;+  GPR_ASSERT(p->subchannel_list == NULL);+  GPR_ASSERT(p->latest_pending_subchannel_list == NULL);   GPR_ASSERT(p->pending_picks == NULL);-  for (size_t i = 0; i < p->num_subchannels; i++) {-    GRPC_SUBCHANNEL_UNREF(exec_ctx, p->subchannels[i], ""pick_first_destroy"");-  }-  if (p->selected != NULL) {-    GRPC_CONNECTED_SUBCHANNEL_UNREF(exec_ctx, p->selected,-                                    ""picked_first_destroy"");-  }   grpc_connectivity_state_destroy(exec_ctx, &p->state_tracker);-  grpc_subchannel_index_unref();-  if (p->pending_update_args != NULL) {-    grpc_channel_args_destroy(exec_ctx, p->pending_update_args->args);-    gpr_free(p->pending_update_args);-  }-  gpr_free(p->subchannels);-  gpr_free(p->new_subchannels);   gpr_free(p);+  grpc_subchannel_index_unref();   if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {     gpr_log(GPR_DEBUG, ""Pick First %p destroyed."", (void *)p);   } } -static void pf_shutdown_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *pol) {-  pick_first_lb_policy *p = (pick_first_lb_policy *)pol;-  pending_pick *pp;-  p->shutdown = true;-  pp = p->pending_picks;-  p->pending_picks = NULL;-  grpc_connectivity_state_set(-      exec_ctx, &p->state_tracker, GRPC_CHANNEL_SHUTDOWN,-      GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Channel shutdown""), ""shutdown"");-  /* cancel subscription */-  if (p->selected != NULL) {-    grpc_connected_subchannel_notify_on_state_change(-        exec_ctx, p->selected, NULL, NULL, &p->connectivity_changed);-  } else if (p->num_subchannels > 0 && p->started_picking) {-    grpc_subchannel_notify_on_state_change(-        exec_ctx, p->subchannels[p->checking_subchannel], NULL, NULL,-        &p->connectivity_changed);+static void shutdown_locked(grpc_exec_ctx *exec_ctx, pick_first_lb_policy *p,+                            grpc_error *error) {+  if (GRPC_TRACER_ON(grpc_lb_pick_first_trace)) {+    gpr_log(GPR_DEBUG, ""Pick First %p Shutting down"", p);   }-  while (pp != NULL) {-    pending_pick *next = pp->next;+  p->shutdown = true;+  pending_pick *pp;+  while ((pp = p->pending_picks) != NULL) {+    p->pending_picks = pp->next;     *pp->target = NULL;-    GRPC_CLOSURE_SCHED(exec_ctx, pp->on_complete, GRPC_ERROR_NONE);+    GRPC_CLOSURE_SCHED(exec_ctx, pp->on_complete, GRPC_ERROR_REF(error));     gpr_free(pp);-    pp = next;   }+  grpc_connectivity_state_set(exec_ctx, &p->state_tracker,+                              GRPC_CHANNEL_SHUTDOWN, GRPC_ERROR_REF(error),+                              ""shutdown"");+  if (p->subchannel_list != NULL) {+    grpc_lb_subchannel_list_shutdown_and_unref(exec_ctx, p->subchannel_list,+                                               ""pf_shutdown"");+    p->subchannel_list = NULL;+  }+  if (p->latest_pending_subchannel_list != NULL) {","This is a reason for adding better comments... I added that line in July (https://github.com/grpc/grpc/pull/11761), as part of a bugfix. I follow your logic, and I can't immediately prove how they could be ==. Perhaps other parts of the code have changed in the meantime... ",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/13068,146070751,2017-10-20T21:28:39Z,src/core/lib/support/closure_ref.h,"@@ -0,0 +1,248 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_SUPPORT_CLOSURE_REF_H+#define GRPC_CORE_LIB_SUPPORT_CLOSURE_REF_H++#include <stdio.h>+#include <stdlib.h>+#include <utility>++namespace grpc_core {++// Value type reference to some closure+// Template arguments list argument types to the closure+// Closures have an implicit scheduling policy bound when they are created+template <typename... Args>+class ClosureRef {+ public:+  struct VTable {+    void (*schedule)(void* env, Args&&... args);+    void (*run)(void* env, Args&&... args);+  };++  ClosureRef(const VTable* vtable, void* env) : vtable_(vtable), env_(env) {}+  ClosureRef() : vtable_(&null_vtable_), env_(nullptr) {}++  // Run this closure, in-place if possible+  void Run(Args&&... args) { vtable_->run(env_, std::forward<Args>(args)...); }++  // Schedule this closure for execution in a safe environment+  void Schedule(Args&&... args) {+    vtable_->schedule(env_, std::forward<Args>(args)...);+  }++ private:+  const VTable* vtable_;+  void* env_;++  static void null_exec(void* env, Args&&... args) { abort(); }++  static const VTable null_vtable_;+};++template <typename... Args>+const typename ClosureRef<Args...>::VTable ClosureRef<Args...>::null_vtable_ = {+    ClosureRef<Args...>::null_exec, ClosureRef<Args...>::null_exec,+};++//+// MakeClosure implementation details...+// Expect to write a code generator for this+//++namespace impl {+template <class Scheduler, class Env, void (*F)()>+class FnClosure {+ public:+  static const typename ClosureRef<>::VTable vtable;++ private:+  static void Schedule(void* env) {+    Scheduler::Schedule([](void*) { F(); }, static_cast<Env*>(env));+  }+  static void Run(void* env) {+    Scheduler::Run([](void*) { F(); }, static_cast<Env*>(env));+  }+};+template <class Scheduler, class Env, void (*F)()>+const typename ClosureRef<>::VTable FnClosure<Scheduler, Env, F>::vtable = {+    FnClosure<Scheduler, Env, F>::Schedule, FnClosure<Scheduler, Env, F>::Run};++template <class Scheduler, class Env, typename T, void (*F)(T)>+class FnClosure1 {+ public:+  static const typename ClosureRef<T>::VTable vtable;++ private:+  static void Schedule(void* env, T&& t) {+    Scheduler::Schedule([t](void*) { F(t); }, static_cast<Env*>(env));+  }+  static void Run(void* env, T&& t) {+    Scheduler::Run([t](void*) { F(t); }, static_cast<Env*>(env));+  }+};+template <class Scheduler, class Env, typename T, void (*F)(T)>+const typename ClosureRef<T>::VTable FnClosure1<Scheduler, Env, T, F>::vtable =+    {FnClosure1<Scheduler, Env, T, F>::Schedule,+     FnClosure1<Scheduler, Env, T, F>::Run};++template <class Scheduler, class T, void (T::*F)()>+class MemClosure {+ public:+  static const typename ClosureRef<>::VTable vtable;++ private:+  static void Schedule(void* env) {+    Scheduler::Schedule([](void* env) { (static_cast<T*>(env)->*F)(); },+                        static_cast<T*>(env));+  }+  static void Run(void* env) {+    Scheduler::Run([](void* env) { (static_cast<T*>(env)->*F)(); },+                   static_cast<T*>(env));+  }+};+template <class Scheduler, class T, void (T::*F)()>+const typename ClosureRef<>::VTable MemClosure<Scheduler, T, F>::vtable = {+    MemClosure<Scheduler, T, F>::Schedule, MemClosure<Scheduler, T, F>::Run};+}++template <class Scheduler, void (*F)(), typename Env = std::nullptr_t>+ClosureRef<> MakeClosure(Env* env = nullptr) {+  return ClosureRef<>(&impl::FnClosure<Scheduler, Env, F>::vtable, env);+}++template <class Scheduler, typename T, void (*F)(T),+          typename Env = std::nullptr_t>+ClosureRef<T> MakeClosure(Env* env = nullptr) {+  return ClosureRef<int>(&impl::FnClosure1<Scheduler, Env, T, F>::vtable, env);+}++template <class Scheduler, typename T, void (T::*F)()>+ClosureRef<> MakeClosure(T* p) {+  return ClosureRef<>(&impl::MemClosure<Scheduler, T, F>::vtable, p);+}++//+// SCHEDULERS+//++class AcquiresNoLocks {+ public:+  template <class T, class F>+  static void Schedule(F&& f, T* env) {+    f(env);+  }+  template <class T, class F>+  static void Run(F&& f, T* env) {+    f(env);+  }+};++template <class F>+void QueueOnExecCtx(F&& f);++class RunInCurrentThread {+ public:+  template <class T, class F>+  static void Schedule(F&& f, T* env) {+    QueueOnExecCtx([f, env]() { f(env); });+  }+  template <class T, class F>+  static void Run(F&& f, T* env) {+    f(env);+  }+};++class RunInCombiner {+ public:+  template <class T, class F>+  static void Schedule(F&& f, T* env) {+    env->combiner()->Schedule([f, env]() { f(env); });+  }+  template <class T, class F>+  static void Run(F&& f, T* env) {+    env->combiner()->Run([f, env]() { f(env); });+  }+};++// Dummy combiner lock impl++class Combiner {+ public:+  template <class F>+  void Schedule(F&& f);+  template <class F>+  void Run(F&& f);+};++//+// TEST CODE+//++void PrintLine();+void PrintInt(int);++class Foo {+ public:+  void Callback();++  Combiner* combiner() { return &combiner_; }++ private:+  Combiner combiner_;+};++ClosureRef<> Hidden();++void test() {+  // simple closures around functions, member functions+  ClosureRef<> print_line = MakeClosure<AcquiresNoLocks, PrintLine>();+  ClosureRef<int> print_int = MakeClosure<AcquiresNoLocks, int, PrintInt>();+  Foo foo;+  ClosureRef<> foo_cb = MakeClosure<AcquiresNoLocks, Foo, &Foo::Callback>(&foo);",I think I have a similar but not quite identical issue as Mark. I'm wondering why the callable should be a template parameter as opposed to a function parameter at the API level. (I'm fine with whatever is needed at the implementation level.),
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/13068,146083830,2017-10-20T23:05:15Z,src/core/lib/support/closure_ref.h,"@@ -0,0 +1,248 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_SUPPORT_CLOSURE_REF_H+#define GRPC_CORE_LIB_SUPPORT_CLOSURE_REF_H++#include <stdio.h>+#include <stdlib.h>+#include <utility>++namespace grpc_core {++// Value type reference to some closure+// Template arguments list argument types to the closure+// Closures have an implicit scheduling policy bound when they are created+template <typename... Args>+class ClosureRef {+ public:+  struct VTable {+    void (*schedule)(void* env, Args&&... args);+    void (*run)(void* env, Args&&... args);+  };++  ClosureRef(const VTable* vtable, void* env) : vtable_(vtable), env_(env) {}+  ClosureRef() : vtable_(&null_vtable_), env_(nullptr) {}++  // Run this closure, in-place if possible+  void Run(Args&&... args) { vtable_->run(env_, std::forward<Args>(args)...); }++  // Schedule this closure for execution in a safe environment+  void Schedule(Args&&... args) {+    vtable_->schedule(env_, std::forward<Args>(args)...);+  }++ private:+  const VTable* vtable_;+  void* env_;++  static void null_exec(void* env, Args&&... args) { abort(); }++  static const VTable null_vtable_;+};++template <typename... Args>+const typename ClosureRef<Args...>::VTable ClosureRef<Args...>::null_vtable_ = {+    ClosureRef<Args...>::null_exec, ClosureRef<Args...>::null_exec,+};++//+// MakeClosure implementation details...+// Expect to write a code generator for this+//++namespace impl {+template <class Scheduler, class Env, void (*F)()>+class FnClosure {+ public:+  static const typename ClosureRef<>::VTable vtable;++ private:+  static void Schedule(void* env) {+    Scheduler::Schedule([](void*) { F(); }, static_cast<Env*>(env));+  }+  static void Run(void* env) {+    Scheduler::Run([](void*) { F(); }, static_cast<Env*>(env));+  }+};+template <class Scheduler, class Env, void (*F)()>+const typename ClosureRef<>::VTable FnClosure<Scheduler, Env, F>::vtable = {+    FnClosure<Scheduler, Env, F>::Schedule, FnClosure<Scheduler, Env, F>::Run};++template <class Scheduler, class Env, typename T, void (*F)(T)>+class FnClosure1 {+ public:+  static const typename ClosureRef<T>::VTable vtable;++ private:+  static void Schedule(void* env, T&& t) {+    Scheduler::Schedule([t](void*) { F(t); }, static_cast<Env*>(env));+  }+  static void Run(void* env, T&& t) {+    Scheduler::Run([t](void*) { F(t); }, static_cast<Env*>(env));+  }+};+template <class Scheduler, class Env, typename T, void (*F)(T)>+const typename ClosureRef<T>::VTable FnClosure1<Scheduler, Env, T, F>::vtable =+    {FnClosure1<Scheduler, Env, T, F>::Schedule,+     FnClosure1<Scheduler, Env, T, F>::Run};++template <class Scheduler, class T, void (T::*F)()>+class MemClosure {+ public:+  static const typename ClosureRef<>::VTable vtable;++ private:+  static void Schedule(void* env) {+    Scheduler::Schedule([](void* env) { (static_cast<T*>(env)->*F)(); },+                        static_cast<T*>(env));+  }+  static void Run(void* env) {+    Scheduler::Run([](void* env) { (static_cast<T*>(env)->*F)(); },+                   static_cast<T*>(env));+  }+};+template <class Scheduler, class T, void (T::*F)()>+const typename ClosureRef<>::VTable MemClosure<Scheduler, T, F>::vtable = {+    MemClosure<Scheduler, T, F>::Schedule, MemClosure<Scheduler, T, F>::Run};+}++template <class Scheduler, void (*F)(), typename Env = std::nullptr_t>+ClosureRef<> MakeClosure(Env* env = nullptr) {+  return ClosureRef<>(&impl::FnClosure<Scheduler, Env, F>::vtable, env);+}++template <class Scheduler, typename T, void (*F)(T),+          typename Env = std::nullptr_t>+ClosureRef<T> MakeClosure(Env* env = nullptr) {+  return ClosureRef<int>(&impl::FnClosure1<Scheduler, Env, T, F>::vtable, env);+}++template <class Scheduler, typename T, void (T::*F)()>+ClosureRef<> MakeClosure(T* p) {+  return ClosureRef<>(&impl::MemClosure<Scheduler, T, F>::vtable, p);+}++//+// SCHEDULERS+//++class AcquiresNoLocks {+ public:+  template <class T, class F>+  static void Schedule(F&& f, T* env) {+    f(env);+  }+  template <class T, class F>+  static void Run(F&& f, T* env) {+    f(env);+  }+};++template <class F>+void QueueOnExecCtx(F&& f);++class RunInCurrentThread {+ public:+  template <class T, class F>+  static void Schedule(F&& f, T* env) {+    QueueOnExecCtx([f, env]() { f(env); });+  }+  template <class T, class F>+  static void Run(F&& f, T* env) {+    f(env);+  }+};++class RunInCombiner {+ public:+  template <class T, class F>+  static void Schedule(F&& f, T* env) {+    env->combiner()->Schedule([f, env]() { f(env); });+  }+  template <class T, class F>+  static void Run(F&& f, T* env) {+    env->combiner()->Run([f, env]() { f(env); });+  }+};++// Dummy combiner lock impl++class Combiner {+ public:+  template <class F>+  void Schedule(F&& f);+  template <class F>+  void Run(F&& f);+};++//+// TEST CODE+//++void PrintLine();+void PrintInt(int);++class Foo {+ public:+  void Callback();++  Combiner* combiner() { return &combiner_; }++ private:+  Combiner combiner_;+};++ClosureRef<> Hidden();++void test() {+  // simple closures around functions, member functions+  ClosureRef<> print_line = MakeClosure<AcquiresNoLocks, PrintLine>();+  ClosureRef<int> print_int = MakeClosure<AcquiresNoLocks, int, PrintInt>();+  Foo foo;+  ClosureRef<> foo_cb = MakeClosure<AcquiresNoLocks, Foo, &Foo::Callback>(&foo);++  print_line.Run();+  print_int.Run(42);+  foo_cb.Run();++  // exec context test+  ClosureRef<> foo_cb_in_exec_ctx =+      MakeClosure<RunInCurrentThread, Foo, &Foo::Callback>(&foo);+  foo_cb_in_exec_ctx.Schedule();++  // combiner lock test - picks up combiner from Foo+  ClosureRef<> foo_cb_in_combiner =+      MakeClosure<RunInCombiner, Foo, &Foo::Callback>(&foo);+  foo_cb_in_combiner.Schedule();+  // can pass in a raw function too, but need to provide an environment+  // in this case something that provides a combiner() method+  ClosureRef<> print_line_in_combiner =+      MakeClosure<RunInCombiner, PrintLine>(&foo);+  print_line_in_combiner.Schedule();++  Hidden().Run();","This was mainly to check code generation in godbolt: the expectation is to see an indirect call in generated code, but not much else (and that's what happened)",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/13068,146084097,2017-10-20T23:08:15Z,src/core/lib/support/closure_ref.h,"@@ -0,0 +1,248 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_SUPPORT_CLOSURE_REF_H+#define GRPC_CORE_LIB_SUPPORT_CLOSURE_REF_H++#include <stdio.h>+#include <stdlib.h>+#include <utility>++namespace grpc_core {++// Value type reference to some closure+// Template arguments list argument types to the closure+// Closures have an implicit scheduling policy bound when they are created+template <typename... Args>+class ClosureRef {+ public:+  struct VTable {+    void (*schedule)(void* env, Args&&... args);+    void (*run)(void* env, Args&&... args);+  };++  ClosureRef(const VTable* vtable, void* env) : vtable_(vtable), env_(env) {}+  ClosureRef() : vtable_(&null_vtable_), env_(nullptr) {}++  // Run this closure, in-place if possible+  void Run(Args&&... args) { vtable_->run(env_, std::forward<Args>(args)...); }++  // Schedule this closure for execution in a safe environment+  void Schedule(Args&&... args) {+    vtable_->schedule(env_, std::forward<Args>(args)...);+  }++ private:+  const VTable* vtable_;+  void* env_;++  static void null_exec(void* env, Args&&... args) { abort(); }++  static const VTable null_vtable_;+};++template <typename... Args>+const typename ClosureRef<Args...>::VTable ClosureRef<Args...>::null_vtable_ = {+    ClosureRef<Args...>::null_exec, ClosureRef<Args...>::null_exec,+};++//+// MakeClosure implementation details...+// Expect to write a code generator for this+//++namespace impl {+template <class Scheduler, class Env, void (*F)()>+class FnClosure {+ public:+  static const typename ClosureRef<>::VTable vtable;++ private:+  static void Schedule(void* env) {+    Scheduler::Schedule([](void*) { F(); }, static_cast<Env*>(env));+  }+  static void Run(void* env) {+    Scheduler::Run([](void*) { F(); }, static_cast<Env*>(env));+  }+};+template <class Scheduler, class Env, void (*F)()>+const typename ClosureRef<>::VTable FnClosure<Scheduler, Env, F>::vtable = {+    FnClosure<Scheduler, Env, F>::Schedule, FnClosure<Scheduler, Env, F>::Run};++template <class Scheduler, class Env, typename T, void (*F)(T)>+class FnClosure1 {+ public:+  static const typename ClosureRef<T>::VTable vtable;++ private:+  static void Schedule(void* env, T&& t) {+    Scheduler::Schedule([t](void*) { F(t); }, static_cast<Env*>(env));+  }+  static void Run(void* env, T&& t) {+    Scheduler::Run([t](void*) { F(t); }, static_cast<Env*>(env));+  }+};+template <class Scheduler, class Env, typename T, void (*F)(T)>+const typename ClosureRef<T>::VTable FnClosure1<Scheduler, Env, T, F>::vtable =+    {FnClosure1<Scheduler, Env, T, F>::Schedule,+     FnClosure1<Scheduler, Env, T, F>::Run};++template <class Scheduler, class T, void (T::*F)()>+class MemClosure {+ public:+  static const typename ClosureRef<>::VTable vtable;++ private:+  static void Schedule(void* env) {+    Scheduler::Schedule([](void* env) { (static_cast<T*>(env)->*F)(); },+                        static_cast<T*>(env));+  }+  static void Run(void* env) {+    Scheduler::Run([](void* env) { (static_cast<T*>(env)->*F)(); },+                   static_cast<T*>(env));+  }+};+template <class Scheduler, class T, void (T::*F)()>+const typename ClosureRef<>::VTable MemClosure<Scheduler, T, F>::vtable = {+    MemClosure<Scheduler, T, F>::Schedule, MemClosure<Scheduler, T, F>::Run};+}++template <class Scheduler, void (*F)(), typename Env = std::nullptr_t>+ClosureRef<> MakeClosure(Env* env = nullptr) {+  return ClosureRef<>(&impl::FnClosure<Scheduler, Env, F>::vtable, env);+}++template <class Scheduler, typename T, void (*F)(T),+          typename Env = std::nullptr_t>+ClosureRef<T> MakeClosure(Env* env = nullptr) {+  return ClosureRef<int>(&impl::FnClosure1<Scheduler, Env, T, F>::vtable, env);+}++template <class Scheduler, typename T, void (T::*F)()>+ClosureRef<> MakeClosure(T* p) {+  return ClosureRef<>(&impl::MemClosure<Scheduler, T, F>::vtable, p);+}++//+// SCHEDULERS+//++class AcquiresNoLocks {+ public:+  template <class T, class F>+  static void Schedule(F&& f, T* env) {+    f(env);+  }+  template <class T, class F>+  static void Run(F&& f, T* env) {+    f(env);+  }+};++template <class F>+void QueueOnExecCtx(F&& f);++class RunInCurrentThread {+ public:+  template <class T, class F>+  static void Schedule(F&& f, T* env) {+    QueueOnExecCtx([f, env]() { f(env); });+  }+  template <class T, class F>+  static void Run(F&& f, T* env) {+    f(env);+  }+};++class RunInCombiner {+ public:+  template <class T, class F>+  static void Schedule(F&& f, T* env) {+    env->combiner()->Schedule([f, env]() { f(env); });+  }+  template <class T, class F>+  static void Run(F&& f, T* env) {+    env->combiner()->Run([f, env]() { f(env); });+  }+};++// Dummy combiner lock impl++class Combiner {+ public:+  template <class F>+  void Schedule(F&& f);+  template <class F>+  void Run(F&& f);+};++//+// TEST CODE+//++void PrintLine();+void PrintInt(int);++class Foo {+ public:+  void Callback();++  Combiner* combiner() { return &combiner_; }++ private:+  Combiner combiner_;+};++ClosureRef<> Hidden();++void test() {+  // simple closures around functions, member functions+  ClosureRef<> print_line = MakeClosure<AcquiresNoLocks, PrintLine>();+  ClosureRef<int> print_int = MakeClosure<AcquiresNoLocks, int, PrintInt>();+  Foo foo;+  ClosureRef<> foo_cb = MakeClosure<AcquiresNoLocks, Foo, &Foo::Callback>(&foo);","I made one tweak... to move the scheduler out of the argument list here, so now you write:```c++SchedulerType::MakeClosure<Foo, &Foo::Callback>();```Too address @vjpai's comment below also: it's needed to be in the template parameter list to save needing to store an additional word in ClosureRef (instead adding a little bit to the library size for each closure - which is a good tradeoff for us I believe).Imagine this more like a code-generator that runs at compile time and generates specialized code to call the passed in function within the selected scheduler.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/13068,146085070,2017-10-20T23:19:48Z,src/core/lib/support/closure_ref.h,"@@ -0,0 +1,248 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_SUPPORT_CLOSURE_REF_H+#define GRPC_CORE_LIB_SUPPORT_CLOSURE_REF_H++#include <stdio.h>+#include <stdlib.h>+#include <utility>++namespace grpc_core {++// Value type reference to some closure+// Template arguments list argument types to the closure+// Closures have an implicit scheduling policy bound when they are created+template <typename... Args>+class ClosureRef {+ public:+  struct VTable {+    void (*schedule)(void* env, Args&&... args);+    void (*run)(void* env, Args&&... args);+  };++  ClosureRef(const VTable* vtable, void* env) : vtable_(vtable), env_(env) {}+  ClosureRef() : vtable_(&null_vtable_), env_(nullptr) {}++  // Run this closure, in-place if possible+  void Run(Args&&... args) { vtable_->run(env_, std::forward<Args>(args)...); }++  // Schedule this closure for execution in a safe environment+  void Schedule(Args&&... args) {+    vtable_->schedule(env_, std::forward<Args>(args)...);+  }++ private:+  const VTable* vtable_;+  void* env_;++  static void null_exec(void* env, Args&&... args) { abort(); }++  static const VTable null_vtable_;+};++template <typename... Args>+const typename ClosureRef<Args...>::VTable ClosureRef<Args...>::null_vtable_ = {+    ClosureRef<Args...>::null_exec, ClosureRef<Args...>::null_exec,+};++//+// MakeClosure implementation details...+// Expect to write a code generator for this+//++namespace impl {+template <class Scheduler, class Env, void (*F)()>+class FnClosure {+ public:+  static const typename ClosureRef<>::VTable vtable;++ private:+  static void Schedule(void* env) {+    Scheduler::Schedule([](void*) { F(); }, static_cast<Env*>(env));+  }+  static void Run(void* env) {+    Scheduler::Run([](void*) { F(); }, static_cast<Env*>(env));+  }+};+template <class Scheduler, class Env, void (*F)()>+const typename ClosureRef<>::VTable FnClosure<Scheduler, Env, F>::vtable = {+    FnClosure<Scheduler, Env, F>::Schedule, FnClosure<Scheduler, Env, F>::Run};++template <class Scheduler, class Env, typename T, void (*F)(T)>+class FnClosure1 {+ public:+  static const typename ClosureRef<T>::VTable vtable;++ private:+  static void Schedule(void* env, T&& t) {+    Scheduler::Schedule([t](void*) { F(t); }, static_cast<Env*>(env));+  }+  static void Run(void* env, T&& t) {+    Scheduler::Run([t](void*) { F(t); }, static_cast<Env*>(env));+  }+};+template <class Scheduler, class Env, typename T, void (*F)(T)>+const typename ClosureRef<T>::VTable FnClosure1<Scheduler, Env, T, F>::vtable =+    {FnClosure1<Scheduler, Env, T, F>::Schedule,+     FnClosure1<Scheduler, Env, T, F>::Run};++template <class Scheduler, class T, void (T::*F)()>+class MemClosure {+ public:+  static const typename ClosureRef<>::VTable vtable;++ private:+  static void Schedule(void* env) {+    Scheduler::Schedule([](void* env) { (static_cast<T*>(env)->*F)(); },+                        static_cast<T*>(env));+  }+  static void Run(void* env) {+    Scheduler::Run([](void* env) { (static_cast<T*>(env)->*F)(); },+                   static_cast<T*>(env));+  }+};+template <class Scheduler, class T, void (T::*F)()>+const typename ClosureRef<>::VTable MemClosure<Scheduler, T, F>::vtable = {+    MemClosure<Scheduler, T, F>::Schedule, MemClosure<Scheduler, T, F>::Run};+}++template <class Scheduler, void (*F)(), typename Env = std::nullptr_t>+ClosureRef<> MakeClosure(Env* env = nullptr) {+  return ClosureRef<>(&impl::FnClosure<Scheduler, Env, F>::vtable, env);+}++template <class Scheduler, typename T, void (*F)(T),+          typename Env = std::nullptr_t>+ClosureRef<T> MakeClosure(Env* env = nullptr) {+  return ClosureRef<int>(&impl::FnClosure1<Scheduler, Env, T, F>::vtable, env);+}++template <class Scheduler, typename T, void (T::*F)()>+ClosureRef<> MakeClosure(T* p) {+  return ClosureRef<>(&impl::MemClosure<Scheduler, T, F>::vtable, p);+}++//+// SCHEDULERS+//++class AcquiresNoLocks {+ public:+  template <class T, class F>+  static void Schedule(F&& f, T* env) {+    f(env);+  }+  template <class T, class F>+  static void Run(F&& f, T* env) {+    f(env);+  }+};++template <class F>+void QueueOnExecCtx(F&& f);++class RunInCurrentThread {+ public:+  template <class T, class F>+  static void Schedule(F&& f, T* env) {+    QueueOnExecCtx([f, env]() { f(env); });+  }+  template <class T, class F>+  static void Run(F&& f, T* env) {+    f(env);+  }+};++class RunInCombiner {+ public:+  template <class T, class F>+  static void Schedule(F&& f, T* env) {+    env->combiner()->Schedule([f, env]() { f(env); });+  }+  template <class T, class F>+  static void Run(F&& f, T* env) {+    env->combiner()->Run([f, env]() { f(env); });+  }+};++// Dummy combiner lock impl++class Combiner {+ public:+  template <class F>+  void Schedule(F&& f);+  template <class F>+  void Run(F&& f);+};++//+// TEST CODE+//++void PrintLine();+void PrintInt(int);++class Foo {+ public:+  void Callback();++  Combiner* combiner() { return &combiner_; }++ private:+  Combiner combiner_;+};++ClosureRef<> Hidden();++void test() {+  // simple closures around functions, member functions+  ClosureRef<> print_line = MakeClosure<AcquiresNoLocks, PrintLine>();+  ClosureRef<int> print_int = MakeClosure<AcquiresNoLocks, int, PrintInt>();+  Foo foo;+  ClosureRef<> foo_cb = MakeClosure<AcquiresNoLocks, Foo, &Foo::Callback>(&foo);","`SchedulerType::MakeClosure` is very nice.I'm pretty template friendly in general, but using a callable as a template parameter isn't yet common for our repo, so it jars a little. I'm ok with the performance tradeoff, though.",
1069502,justinburke,https://api.github.com/repos/grpc/grpc/pulls/12809,146369237,2017-10-23T19:27:50Z,test/core/security/ssl_credentials_test.c,"@@ -0,0 +1,66 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <stdio.h>+#include <string.h>++#include <grpc/grpc_security.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>++#include ""src/core/lib/security/credentials/ssl/ssl_credentials.h""+#include ""src/core/tsi/ssl_transport_security.h""+#include ""test/core/util/test_config.h""++static void test_convert_grpc_to_tsi_cert_pairs() {+  grpc_ssl_pem_key_cert_pair grpc_pairs[] = {{""private_key1"", ""cert_chain1""},+                                             {""private_key2"", ""cert_chain2""},+                                             {""private_key3"", ""cert_chain3""}};+  const size_t num_pairs = 3;++  {+    tsi_ssl_pem_key_cert_pair *tsi_pairs =+        grpc_convert_grpc_to_tsi_cert_pairs(grpc_pairs, 0);+    GPR_ASSERT(tsi_pairs == NULL);+  }++  {+    tsi_ssl_pem_key_cert_pair *tsi_pairs =+        grpc_convert_grpc_to_tsi_cert_pairs(grpc_pairs, num_pairs);++    GPR_ASSERT(tsi_pairs != NULL);+    for (size_t i = 0; i < num_pairs; i++) {+      GPR_ASSERT(!strncmp(grpc_pairs[i].private_key, tsi_pairs[i].private_key,","There is a mixture of usages in the codebase, but your suggested pattern is the most explicit (and perhaps also the preferred convention). Will fix.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12878,146371553,2017-10-23T19:37:48Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -181,15 +155,12 @@ static void pf_cancel_picks_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *pol, static void start_picking_locked(grpc_exec_ctx *exec_ctx,                                  pick_first_lb_policy *p) {   p->started_picking = true;-  if (p->subchannels != NULL) {-    GPR_ASSERT(p->num_subchannels > 0);-    p->checking_subchannel = 0;-    p->checking_connectivity = GRPC_CHANNEL_IDLE;-    GRPC_LB_POLICY_WEAK_REF(&p->base, ""pick_first_connectivity"");-    grpc_subchannel_notify_on_state_change(-        exec_ctx, p->subchannels[p->checking_subchannel],-        p->base.interested_parties, &p->checking_connectivity,-        &p->connectivity_changed);+  if (p->subchannel_list != NULL && p->subchannel_list->num_subchannels > 0) {+    p->subchannel_list->checking_subchannel = 0;+    grpc_lb_subchannel_list_ref_for_connectivity_watch(+        p->subchannel_list, ""connectivity_watch+start_picking"");+    grpc_lb_subchannel_data_start_connectivity_watch(","Then yeah, this is a pre-existing bug.  I've added a line in subchannel_list.cc to initialize it.",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/13084,146422324,2017-10-23T23:41:27Z,include/grpc++/impl/codegen/completion_queue.h,"@@ -79,12 +82,28 @@ class ServerContext;  extern CoreCodegenInterface* g_core_codegen_interface; +/// EXPERIMENTAL+/// Creates a Thread Local cache to store the first event+/// On this completion queue queued from this thread.  Once+/// initialized, it must be flushed on the same thread.+class CompletionQueueTLSCache : private GrpcLibraryCodegen {",Maybe make this a private member class of CompletionQueue (public names are forever)... If we need to we can promote later,
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/12937,146455853,2017-10-24T05:22:58Z,src/core/lib/security/transport/security_handshaker.cc,"@@ -227,7 +228,18 @@ static grpc_error *on_handshake_next_done_locked(                        &h->on_handshake_data_received_from_peer);     return error;   }+  // Handle TSI errors.   if (result != TSI_OK) {+    if (result == TSI_SEND_ALERT_AND_CLOSE && bytes_to_send_size > 0) {+      gpr_log(GPR_DEBUG,+              ""Encountered TSI error. Sending alert message before closing"");+      grpc_slice to_send = grpc_slice_from_copied_buffer(+          (const char *)bytes_to_send, bytes_to_send_size);+      grpc_slice_buffer_reset_and_unref_internal(exec_ctx, &h->outgoing);+      grpc_slice_buffer_add(&h->outgoing, to_send);+      grpc_endpoint_write(exec_ctx, h->args->endpoint, &h->outgoing,+                          &h->on_handshake_data_sent_to_peer);+    }     return grpc_set_tsi_error_result(","In the case of TSI_SEND_ALERT_AND_CLOSE, if we return a grpc_error here, then the error will be propagated to do_handshaker_next_locked(), immediately after this, security_handshake_failed_locked and security_handshaker_unref will be called in Line 347 and Line 424. The security handshaker object could be destroyed before on_handshake_data_sent_to_peer callback is executed (since grpc_endpoint_write Line 240 is async).",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/13084,146653969,2017-10-24T18:36:24Z,include/grpc/grpc.h,"@@ -143,6 +143,17 @@ GRPCAPI void grpc_completion_queue_shutdown(grpc_completion_queue *cq);     drained and no threads are executing grpc_completion_queue_next */ GRPCAPI void grpc_completion_queue_destroy(grpc_completion_queue *cq); +/*********** EXPERIMENTAL API ************/+/** Initializes a thread local cache for this cq+  * grpc_flush_cq_tls_cache() MUST be called on the same thread.+  */+GRPCAPI void grpc_prepare_cq_tls_cache(grpc_completion_queue *cq);","grpc_cq_tls_cache_prepare to be more consistent with naming throughout the core API (object name first, then action verb). Additionally, since this is API, I would suggest not using ""tls"" because of abbreviation-ambiguity. (Note that C++ style guide doesn't like abbreviations.) Please call it grpc_cq_thread_local_cache or grpc_thread_local_cq or something like that",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/13084,146657502,2017-10-24T18:49:24Z,include/grpc/grpc.h,"@@ -143,6 +143,17 @@ GRPCAPI void grpc_completion_queue_shutdown(grpc_completion_queue *cq);     drained and no threads are executing grpc_completion_queue_next */ GRPCAPI void grpc_completion_queue_destroy(grpc_completion_queue *cq); +/*********** EXPERIMENTAL API ************/+/** Initializes a thread local cache for this cq+  * grpc_flush_cq_tls_cache() MUST be called on the same thread.+  */+GRPCAPI void grpc_prepare_cq_tls_cache(grpc_completion_queue *cq);","Additionally, even though these are experimental, please document the parameters and return values (more important for flush than prepare)",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/13084,146721669,2017-10-24T23:36:09Z,grpc.def,"@@ -54,8 +54,8 @@ EXPORTS     grpc_completion_queue_pluck     grpc_completion_queue_shutdown     grpc_completion_queue_destroy-    grpc_prepare_cq_tls_cache-    grpc_flush_cq_tls_cache+    grpc_completion_queue_thread_local_cache_init",Please rename to `grpc_thread_local_completion_queue_cache_init` because it is more rhythmic (can be sung to the tune of Supercalifragilisticexpialidocious),
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/13033,146833667,2017-10-25T12:01:02Z,tools/jenkins/run_full_performance.sh,"@@ -34,7 +34,7 @@ git clean -fdxq --exclude='report*.xml'  # scalability with 32cores (and upload to a different BQ table) tools/run_tests/run_performance_tests.py \-    -l c++ java csharp go \+    -l c++ java csharp go php7 php7_protobuf_c \","Yes (if the 32core workers have the right prerequisites installed. just saying - ideally all the workers should have identical setup).From a practical perspective, running PHP benchmarks on 32core machines (as opposed to 8core) makes a little sense IMHO. It's useful for languages designed for scalability and high performance (C++, java, go, C# I think). So I don't think there's any reason to run PHP on 32core setup - it will only make the suite take longer.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/13135,146835859,2017-10-25T12:12:01Z,tools/internal_ci/linux/grpc_run_tests_matrix.sh,"@@ -27,7 +27,8 @@ if [ -n ""$KOKORO_GITHUB_PULL_REQUEST_NUMBER"" ] && [ -n ""$RUN_TESTS_FLAGS"" ]; the   export RUN_TESTS_FLAGS=""$RUN_TESTS_FLAGS --filter_pr_tests --base_branch origin/$ghprbTargetBranch"" fi -tools/run_tests/run_tests_matrix.py $RUN_TESTS_FLAGS || FAILED=""true""+# Throttle stdout, so workers don't run out of memory+tools/run_tests/run_tests_matrix.py $RUN_TESTS_FLAGS | pv -q -L 128000 || FAILED=""true""","Mixing pipes and `||` can be tricky (and depends on `pipefail` settings). I'd rather not make this change.Also, AFAIK kokoro redirects both stdout and stderr to a .log file  and then the agent streams data from that file - so this change actually might not be helping with the problem at all (while making things complicated and more error prone on our side).",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/13121,146938157,2017-10-25T18:00:39Z,src/core/lib/backoff/backoff.cc,"@@ -34,9 +34,7 @@ void grpc_backoff_init(grpc_backoff *backoff,  grpc_millis grpc_backoff_begin(grpc_exec_ctx *exec_ctx, grpc_backoff *backoff) {   backoff->current_timeout_millis = backoff->initial_connect_timeout;-  const grpc_millis first_timeout =-      GPR_MAX(backoff->current_timeout_millis, backoff->min_timeout_millis);-  return grpc_exec_ctx_now(exec_ctx) + first_timeout;+  return grpc_exec_ctx_now(exec_ctx) + backoff->current_timeout_millis;","A similar fix should be at line 63. From specification, deadline update should not be dependent on MIN_CONNECT_TIMEOUT. This parameter is only used when attempting to connect.",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/13121,146938860,2017-10-25T18:02:55Z,src/core/lib/backoff/backoff.cc,"@@ -34,9 +34,7 @@ void grpc_backoff_init(grpc_backoff *backoff,  grpc_millis grpc_backoff_begin(grpc_exec_ctx *exec_ctx, grpc_backoff *backoff) {   backoff->current_timeout_millis = backoff->initial_connect_timeout;-  const grpc_millis first_timeout =-      GPR_MAX(backoff->current_timeout_millis, backoff->min_timeout_millis);-  return grpc_exec_ctx_now(exec_ctx) + first_timeout;+  return grpc_exec_ctx_now(exec_ctx) + backoff->current_timeout_millis;","In line 57, jitter is added to `current_timeout_millis`. That does not follow the specification as the jitter only affects **deadline** and should not roll over to next round of **backoff** calculation.",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/11572,147282484,2017-10-26T22:17:17Z,include/grpc++/impl/codegen/async_stream.h,"@@ -146,31 +147,66 @@ class AsyncWriterInterface {   } }; +}  // namespace internal+ template <class R>-class ClientAsyncReaderInterface : public ClientAsyncStreamingInterface,-                                   public AsyncReaderInterface<R> {};+class ClientAsyncReaderInterface+    : public internal::ClientAsyncStreamingInterface,+      public internal::AsyncReaderInterface<R> {};++/// Common interface for client side asynchronous writing.+template <class W>+class ClientAsyncWriterInterface+    : public internal::ClientAsyncStreamingInterface,+      public internal::AsyncWriterInterface<W> {+ public:+  /// Signal the client is done with the writes (half-close the client stream).+  /// Thread-safe with respect to \a AsyncReaderInterface::Read+  ///+  /// \param[in] tag The tag identifying the operation.+  virtual void WritesDone(void* tag) = 0;+};++/// Async client-side interface for bi-directional streaming,+/// where the client-to-server message stream has messages of type \a W,+/// and the server-to-client message stream has messages of type \a R.+template <class W, class R>+class ClientAsyncReaderWriterInterface+    : public internal::ClientAsyncStreamingInterface,+      public internal::AsyncWriterInterface<W>,+      public internal::AsyncReaderInterface<R> {+ public:+  /// Signal the client is done with the writes (half-close the client stream).+  /// Thread-safe with respect to \a AsyncReaderInterface::Read+  ///+  /// \param[in] tag The tag identifying the operation.+  virtual void WritesDone(void* tag) = 0;+};  /// Async client-side API for doing server-streaming RPCs, /// where the incoming message stream coming from the server has /// messages of type \a R. template <class R> class ClientAsyncReader final : public ClientAsyncReaderInterface<R> {  public:-  /// Create a stream and write the first request out.-  /// \a tag will be notified on \a cq when the call has been started and-  /// \a request has been written out.-  /// Note that \a context will be used to fill in custom initial metadata-  /// used to send to the server when starting the call.-  template <class W>-  static ClientAsyncReader* Create(ChannelInterface* channel,-                                   CompletionQueue* cq, const RpcMethod& method,-                                   ClientContext* context, const W& request,-                                   void* tag) {-    Call call = channel->CreateCall(method, context, cq);-    return new (g_core_codegen_interface->grpc_call_arena_alloc(-        call.call(), sizeof(ClientAsyncReader)))-        ClientAsyncReader(call, context, request, tag);-  }+  struct internal {","Maybe move Create to a builder class that is in the internal namespace, and remove this internal struct.",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/11572,147292531,2017-10-26T23:23:27Z,include/grpc++/impl/codegen/sync_stream.h,"@@ -159,28 +185,14 @@ class ClientReaderInterface : public ClientStreamingInterface, template <class R> class ClientReader final : public ClientReaderInterface<R> {  public:-  /// Block to create a stream and write the initial metadata and \a request-  /// out. Note that \a context will be used to fill in custom initial-  /// metadata used to send to the server when starting the call.-  template <class W>-  ClientReader(ChannelInterface* channel, const RpcMethod& method,-               ClientContext* context, const W& request)-      : context_(context),-        cq_(grpc_completion_queue_attributes{-            GRPC_CQ_CURRENT_VERSION, GRPC_CQ_PLUCK,-            GRPC_CQ_DEFAULT_POLLING}),  // Pluckable cq-        call_(channel->CreateCall(method, context, &cq_)) {-    CallOpSet<CallOpSendInitialMetadata, CallOpSendMessage,-              CallOpClientSendClose>-        ops;-    ops.SendInitialMetadata(context->send_initial_metadata_,-                            context->initial_metadata_flags());-    // TODO(ctiller): don't assert-    GPR_CODEGEN_ASSERT(ops.SendMessage(request).ok());-    ops.ClientSendClose();-    call_.PerformOps(&ops);-    cq_.Pluck(&ops);-  }+  struct internal {",Same comment about builder pattern.,
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/11572,147292582,2017-10-26T23:23:49Z,include/grpc++/impl/codegen/sync_stream.h,"@@ -235,53 +250,48 @@ class ClientReader final : public ClientReaderInterface<R> {  private:   ClientContext* context_;   CompletionQueue cq_;-  Call call_;-};+  ::grpc::internal::Call call_; -/// Client-side interface for streaming writes of message type \a W.-template <class W>-class ClientWriterInterface : public ClientStreamingInterface,-                              public WriterInterface<W> {- public:-  /// Half close writing from the client. (signal that the stream of messages-  /// coming from the clinet is complete).-  /// Blocks until currently-pending writes are completed.-  /// Thread safe with respect to \a ReaderInterface::Read operations only-  ///-  /// \return Whether the writes were successful.-  virtual bool WritesDone() = 0;+  /// Block to create a stream and write the initial metadata and \a request+  /// out. Note that \a context will be used to fill in custom initial+  /// metadata used to send to the server when starting the call.+  template <class W>+  ClientReader(::grpc::ChannelInterface* channel,+               const ::grpc::internal::RpcMethod& method,+               ClientContext* context, const W& request)+      : context_(context),+        cq_(grpc_completion_queue_attributes{+            GRPC_CQ_CURRENT_VERSION, GRPC_CQ_PLUCK,+            GRPC_CQ_DEFAULT_POLLING}),  // Pluckable cq+        call_(channel->CreateCall(method, context, &cq_)) {+    ::grpc::internal::CallOpSet<::grpc::internal::CallOpSendInitialMetadata,+                                ::grpc::internal::CallOpSendMessage,+                                ::grpc::internal::CallOpClientSendClose>+        ops;+    ops.SendInitialMetadata(context->send_initial_metadata_,+                            context->initial_metadata_flags());+    // TODO(ctiller): don't assert+    GPR_CODEGEN_ASSERT(ops.SendMessage(request).ok());+    ops.ClientSendClose();+    call_.PerformOps(&ops);+    cq_.Pluck(&ops);+  } };  /// Synchronous (blocking) client-side API for doing client-streaming RPCs, /// where the outgoing message stream coming from the client has messages of /// type \a W. template <class W>-class ClientWriter : public ClientWriterInterface<W> {+class ClientWriter final : public ClientWriterInterface<W> {  public:-  /// Block to create a stream (i.e. send request headers and other initial-  /// metadata to the server). Note that \a context will be used to fill-  /// in custom initial metadata. \a response will be filled in with the-  /// single expected response message from the server upon a successful-  /// call to the \a Finish method of this instance.-  template <class R>-  ClientWriter(ChannelInterface* channel, const RpcMethod& method,-               ClientContext* context, R* response)-      : context_(context),-        cq_(grpc_completion_queue_attributes{-            GRPC_CQ_CURRENT_VERSION, GRPC_CQ_PLUCK,-            GRPC_CQ_DEFAULT_POLLING}),  // Pluckable cq-        call_(channel->CreateCall(method, context, &cq_)) {-    finish_ops_.RecvMessage(response);-    finish_ops_.AllowNoMessage();--    if (!context_->initial_metadata_corked_) {-      CallOpSet<CallOpSendInitialMetadata> ops;-      ops.SendInitialMetadata(context->send_initial_metadata_,-                              context->initial_metadata_flags());-      call_.PerformOps(&ops);-      cq_.Pluck(&ops);+  struct internal {",Suggest Builder pattern.,
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/11572,147292693,2017-10-26T23:24:31Z,include/grpc++/impl/codegen/sync_stream.h,"@@ -353,61 +365,55 @@ class ClientWriter : public ClientWriterInterface<W> {   private:   ClientContext* context_;-  CallOpSet<CallOpRecvInitialMetadata, CallOpGenericRecvMessage,-            CallOpClientRecvStatus>+  ::grpc::internal::CallOpSet<::grpc::internal::CallOpRecvInitialMetadata,+                              ::grpc::internal::CallOpGenericRecvMessage,+                              ::grpc::internal::CallOpClientRecvStatus>       finish_ops_;   CompletionQueue cq_;-  Call call_;-};+  ::grpc::internal::Call call_; -/// Client-side interface for bi-directional streaming with-/// client-to-server stream messages of type \a W and-/// server-to-client stream messages of type \a R.-template <class W, class R>-class ClientReaderWriterInterface : public ClientStreamingInterface,-                                    public WriterInterface<W>,-                                    public ReaderInterface<R> {- public:-  /// Block to wait for initial metadata from server. The received metadata-  /// can only be accessed after this call returns. Should only be called before-  /// the first read. Calling this method is optional, and if it is not called-  /// the metadata will be available in ClientContext after the first read.-  virtual void WaitForInitialMetadata() = 0;--  /// Half close writing from the client. (signal that the stream of messages-  /// coming from the clinet is complete).-  /// Blocks until currently-pending writes are completed.-  /// Thread-safe with respect to \a ReaderInterface::Read-  ///-  /// \return Whether the writes were successful.-  virtual bool WritesDone() = 0;-};--/// Synchronous (blocking) client-side API for bi-directional streaming RPCs,-/// where the outgoing message stream coming from the client has messages of-/// type \a W, and the incoming messages stream coming from the server has-/// messages of type \a R.-template <class W, class R>-class ClientReaderWriter final : public ClientReaderWriterInterface<W, R> {- public:-  /// Block to create a stream and write the initial metadata and \a request-  /// out. Note that \a context will be used to fill in custom initial metadata-  /// used to send to the server when starting the call.-  ClientReaderWriter(ChannelInterface* channel, const RpcMethod& method,-                     ClientContext* context)+  /// Block to create a stream (i.e. send request headers and other initial+  /// metadata to the server). Note that \a context will be used to fill+  /// in custom initial metadata. \a response will be filled in with the+  /// single expected response message from the server upon a successful+  /// call to the \a Finish method of this instance.+  template <class R>+  ClientWriter(::grpc::ChannelInterface* channel,+               const ::grpc::internal::RpcMethod& method,+               ClientContext* context, R* response)       : context_(context),         cq_(grpc_completion_queue_attributes{             GRPC_CQ_CURRENT_VERSION, GRPC_CQ_PLUCK,             GRPC_CQ_DEFAULT_POLLING}),  // Pluckable cq         call_(channel->CreateCall(method, context, &cq_)) {+    finish_ops_.RecvMessage(response);+    finish_ops_.AllowNoMessage();+     if (!context_->initial_metadata_corked_) {-      CallOpSet<CallOpSendInitialMetadata> ops;+      ::grpc::internal::CallOpSet<::grpc::internal::CallOpSendInitialMetadata>+          ops;       ops.SendInitialMetadata(context->send_initial_metadata_,                               context->initial_metadata_flags());       call_.PerformOps(&ops);       cq_.Pluck(&ops);     }   }+};++/// Synchronous (blocking) client-side API for bi-directional streaming RPCs,+/// where the outgoing message stream coming from the client has messages of+/// type \a W, and the incoming messages stream coming from the server has+/// messages of type \a R.+template <class W, class R>+class ClientReaderWriter final : public ClientReaderWriterInterface<W, R> {+ public:+  struct internal {",Builder pattern,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13121,147433915,2017-10-27T14:58:17Z,src/core/lib/backoff/backoff.h,"@@ -27,36 +27,40 @@ extern ""C"" {  typedef struct {   /// const:  how long to wait after the first failure before retrying-  grpc_millis initial_connect_timeout;+  grpc_millis initial_backoff;+   /// const: factor with which to multiply backoff after a failed retry   double multiplier;+   /// const: amount to randomize backoffs   double jitter;-  /// const: minimum time between retries in milliseconds-  grpc_millis min_timeout_millis;-  /// const: maximum time between retries in milliseconds-  grpc_millis max_timeout_millis;++  /// const: minimum time between retries+  grpc_millis min_backoff;++  /// const: maximum time between retries+  grpc_millis max_backoff;++  /// current delay before retries+  grpc_millis current_backoff;    /// random number generator   uint32_t rng_state;--  /// current retry timeout in milliseconds-  grpc_millis current_timeout_millis; } grpc_backoff;  /// Initialize backoff machinery - does not need to be destroyed-void grpc_backoff_init(grpc_backoff *backoff,-                       grpc_millis initial_connect_timeout, double multiplier,-                       double jitter, grpc_millis min_timeout_millis,-                       grpc_millis max_timeout_millis);+void grpc_backoff_init(grpc_backoff *backoff, grpc_millis initial_backoff,+                       double multiplier, double jitter,+                       grpc_millis min_timeout, grpc_millis max_timeout);","These last two parameters should be named `max_backoff` and `min_connect_timeout`, to match what's in the spec.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13121,147434850,2017-10-27T15:01:30Z,src/core/lib/backoff/backoff.cc,"@@ -20,23 +20,23 @@  #include <grpc/support/useful.h> -void grpc_backoff_init(grpc_backoff *backoff,-                       grpc_millis initial_connect_timeout, double multiplier,-                       double jitter, grpc_millis min_timeout_millis,-                       grpc_millis max_timeout_millis) {-  backoff->initial_connect_timeout = initial_connect_timeout;+void grpc_backoff_init(grpc_backoff *backoff, grpc_millis initial_backoff,+                       double multiplier, double jitter,+                       grpc_millis min_backoff, grpc_millis max_backoff) {","These last two parameter names do not match what's in the header file, and neither of these matches what's in the spec.I think these should be changed to `max_backoff` and `min_connect_timeout`, to match what's in the spec.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13121,147442716,2017-10-27T15:31:26Z,src/core/lib/backoff/backoff.cc,"@@ -20,23 +20,23 @@  #include <grpc/support/useful.h> -void grpc_backoff_init(grpc_backoff *backoff,-                       grpc_millis initial_connect_timeout, double multiplier,-                       double jitter, grpc_millis min_timeout_millis,-                       grpc_millis max_timeout_millis) {-  backoff->initial_connect_timeout = initial_connect_timeout;+void grpc_backoff_init(grpc_backoff *backoff, grpc_millis initial_backoff,+                       double multiplier, double jitter,+                       grpc_millis min_backoff, grpc_millis max_backoff) {+  backoff->initial_backoff = initial_backoff;   backoff->multiplier = multiplier;   backoff->jitter = jitter;-  backoff->min_timeout_millis = min_timeout_millis;-  backoff->max_timeout_millis = max_timeout_millis;+  backoff->min_backoff = min_backoff;+  backoff->max_backoff = max_backoff;   backoff->rng_state = (uint32_t)gpr_now(GPR_CLOCK_REALTIME).tv_nsec; }  grpc_millis grpc_backoff_begin(grpc_exec_ctx *exec_ctx, grpc_backoff *backoff) {-  backoff->current_timeout_millis = backoff->initial_connect_timeout;-  const grpc_millis first_timeout =-      GPR_MAX(backoff->current_timeout_millis, backoff->min_timeout_millis);-  return grpc_exec_ctx_now(exec_ctx) + first_timeout;+  backoff->current_backoff = backoff->initial_backoff;+  const grpc_millis current_deadline =","As we discussed, the backoff code needs to generate two values, `current_backoff` and `current_deadline`, where the latter may be greater than the former.  However, both this method and `grpc_backoff_step()` return only a single value, which it looks like is supposed to be `current_deadline`.  This seems fundamentally wrong, because the calling code needs to know and use both values.  So I think we need some sort of API change here.In particular, the subchannel connection code uses the return value for two things:- Scheduling an alarm for the next attempt.- The deadline for the current attempt.We need to return two values so that the subchannel connection code knows the right value to use for both of these things.There are three other callers of this code as well: the grpclb LB policy and both DNS resolver implementations.  They all seem to use the return value just to schedule a timer for the next attempt; they don't seem to use it for setting deadlines at all, which may actually skew their use of this code -- the algorithm in the spec says that they need to take into account the time taken by each attempt, but they're not doing that.  So they may need some changes as well.  (Although the spec is really about connection backoff, so it would also be fine to say that these other cases don't really need to behave exactly the same way -- we should just make sure that we're happy with whatever behavior we are implementing here.  If we find that we aren't actually happy with the same behavior, it would be fine to use different code for these cases than for the subchannel connection code.)",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/13121,147496091,2017-10-27T19:21:13Z,src/core/lib/backoff/backoff.cc,"@@ -20,23 +20,23 @@  #include <grpc/support/useful.h> -void grpc_backoff_init(grpc_backoff *backoff,-                       grpc_millis initial_connect_timeout, double multiplier,-                       double jitter, grpc_millis min_timeout_millis,-                       grpc_millis max_timeout_millis) {-  backoff->initial_connect_timeout = initial_connect_timeout;+void grpc_backoff_init(grpc_backoff *backoff, grpc_millis initial_backoff,+                       double multiplier, double jitter,+                       grpc_millis min_backoff, grpc_millis max_backoff) {+  backoff->initial_backoff = initial_backoff;   backoff->multiplier = multiplier;   backoff->jitter = jitter;-  backoff->min_timeout_millis = min_timeout_millis;-  backoff->max_timeout_millis = max_timeout_millis;+  backoff->min_backoff = min_backoff;+  backoff->max_backoff = max_backoff;   backoff->rng_state = (uint32_t)gpr_now(GPR_CLOCK_REALTIME).tv_nsec; }  grpc_millis grpc_backoff_begin(grpc_exec_ctx *exec_ctx, grpc_backoff *backoff) {-  backoff->current_timeout_millis = backoff->initial_connect_timeout;-  const grpc_millis first_timeout =-      GPR_MAX(backoff->current_timeout_millis, backoff->min_timeout_millis);-  return grpc_exec_ctx_now(exec_ctx) + first_timeout;+  backoff->current_backoff = backoff->initial_backoff;+  const grpc_millis current_deadline =","@markdroth I do not agree that `current_backoff` should be returned. `current_backoff` should be an internal variable that is rolled over in each backoff step internally in backoff.cc. Callers do not need to know about `current_backoff` at all when making TryConnect() (see that in [spec](https://github.com/grpc/grpc/blob/master/doc/connection-backoff.md)).The only thing the caller should know is `min_connect_timeout`. They should make a connect with time-out being `MAX(current_deadline, now + min_connect_timeout)`. Then...* If they failed after `current_deadline`, they immediately call `backoff_step` to get a new `current_deadline` and attempt another connection immediately.* If they failed before `current_deadline`, they set a timer to wait until `current_deadline` then do the same in the previous bullet.",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/13121,147498860,2017-10-27T19:35:40Z,src/core/lib/backoff/backoff.cc,"@@ -20,23 +20,23 @@  #include <grpc/support/useful.h> -void grpc_backoff_init(grpc_backoff *backoff,-                       grpc_millis initial_connect_timeout, double multiplier,-                       double jitter, grpc_millis min_timeout_millis,-                       grpc_millis max_timeout_millis) {-  backoff->initial_connect_timeout = initial_connect_timeout;+void grpc_backoff_init(grpc_backoff *backoff, grpc_millis initial_backoff,+                       double multiplier, double jitter,+                       grpc_millis min_backoff, grpc_millis max_backoff) {+  backoff->initial_backoff = initial_backoff;   backoff->multiplier = multiplier;   backoff->jitter = jitter;-  backoff->min_timeout_millis = min_timeout_millis;-  backoff->max_timeout_millis = max_timeout_millis;+  backoff->min_backoff = min_backoff;+  backoff->max_backoff = max_backoff;   backoff->rng_state = (uint32_t)gpr_now(GPR_CLOCK_REALTIME).tv_nsec; }  grpc_millis grpc_backoff_begin(grpc_exec_ctx *exec_ctx, grpc_backoff *backoff) {-  backoff->current_timeout_millis = backoff->initial_connect_timeout;-  const grpc_millis first_timeout =-      GPR_MAX(backoff->current_timeout_millis, backoff->min_timeout_millis);-  return grpc_exec_ctx_now(exec_ctx) + first_timeout;+  backoff->current_backoff = backoff->initial_backoff;+  const grpc_millis current_deadline =+      grpc_exec_ctx_now(exec_ctx) + backoff->initial_backoff;+  return GPR_MAX(current_deadline,+                 grpc_exec_ctx_now(exec_ctx) + backoff->min_backoff);","If we intend to make the return value to be `current_deadline` here, this should not be max'ed with min_backoff (min_timeout is a more appropriate name I think). Max'ing should be taken care of by caller when they make TryConnect.",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/13121,147498911,2017-10-27T19:35:55Z,src/core/lib/backoff/backoff.cc,"@@ -45,29 +45,27 @@ static double generate_uniform_random_number(uint32_t *rng_state) {   return *rng_state / (double)((uint32_t)1 << 31); } -grpc_millis grpc_backoff_step(grpc_exec_ctx *exec_ctx, grpc_backoff *backoff) {-  const double new_timeout_millis =-      backoff->multiplier * (double)backoff->current_timeout_millis;-  backoff->current_timeout_millis =-      GPR_MIN((grpc_millis)new_timeout_millis, backoff->max_timeout_millis);--  const double jitter_range_width = backoff->jitter * new_timeout_millis;-  const double jitter =-      (2 * generate_uniform_random_number(&backoff->rng_state) - 1) *-      jitter_range_width;--  backoff->current_timeout_millis =-      (grpc_millis)((double)(backoff->current_timeout_millis) + jitter);+static double generate_uniform_random_number_between(uint32_t *rng_state,+                                                     double a, double b) {+  if (a == b) return a;+  if (a > b) GPR_SWAP(double, a, b);  // make sure a < b+  const double range = b - a;+  return a + generate_uniform_random_number(rng_state) * range;+} +grpc_millis grpc_backoff_step(grpc_exec_ctx *exec_ctx, grpc_backoff *backoff) {+  backoff->current_backoff = (grpc_millis)(GPR_MIN(+      backoff->current_backoff * backoff->multiplier, backoff->max_backoff));+  const double jitter = generate_uniform_random_number_between(+      &backoff->rng_state, -backoff->jitter * backoff->current_backoff,+      backoff->jitter * backoff->current_backoff);   const grpc_millis current_deadline =-      grpc_exec_ctx_now(exec_ctx) + backoff->current_timeout_millis;--  const grpc_millis min_deadline =-      grpc_exec_ctx_now(exec_ctx) + backoff->min_timeout_millis;--  return GPR_MAX(current_deadline, min_deadline);+      grpc_exec_ctx_now(exec_ctx) ++      (grpc_millis)(backoff->current_backoff + jitter);+  return GPR_MAX(current_deadline,+                 grpc_exec_ctx_now(exec_ctx) + backoff->min_backoff);","This is the same as grpc_backoff_begin. `current_deadline` should be max'ed with min_timeout by caller, not by backoff.cc.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/13121,147532943,2017-10-27T22:59:38Z,src/core/lib/backoff/backoff.cc,"@@ -20,23 +20,23 @@  #include <grpc/support/useful.h> -void grpc_backoff_init(grpc_backoff *backoff,-                       grpc_millis initial_connect_timeout, double multiplier,-                       double jitter, grpc_millis min_timeout_millis,-                       grpc_millis max_timeout_millis) {-  backoff->initial_connect_timeout = initial_connect_timeout;+void grpc_backoff_init(grpc_backoff *backoff, grpc_millis initial_backoff,+                       double multiplier, double jitter,+                       grpc_millis min_backoff, grpc_millis max_backoff) {+  backoff->initial_backoff = initial_backoff;   backoff->multiplier = multiplier;   backoff->jitter = jitter;-  backoff->min_timeout_millis = min_timeout_millis;-  backoff->max_timeout_millis = max_timeout_millis;+  backoff->min_backoff = min_backoff;+  backoff->max_backoff = max_backoff;   backoff->rng_state = (uint32_t)gpr_now(GPR_CLOCK_REALTIME).tv_nsec; }  grpc_millis grpc_backoff_begin(grpc_exec_ctx *exec_ctx, grpc_backoff *backoff) {-  backoff->current_timeout_millis = backoff->initial_connect_timeout;-  const grpc_millis first_timeout =-      GPR_MAX(backoff->current_timeout_millis, backoff->min_timeout_millis);-  return grpc_exec_ctx_now(exec_ctx) + first_timeout;+  backoff->current_backoff = backoff->initial_backoff;+  const grpc_millis current_deadline =+      grpc_exec_ctx_now(exec_ctx) + backoff->initial_backoff;+  return GPR_MAX(current_deadline,+                 grpc_exec_ctx_now(exec_ctx) + backoff->min_backoff);",Why make the caller do the comparison? Why not hide that detail?,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/13121,147602452,2017-10-30T00:52:11Z,src/core/lib/backoff/backoff.cc,"@@ -53,17 +56,22 @@ static double generate_uniform_random_number_between(uint32_t *rng_state,   return a + generate_uniform_random_number(rng_state) * range; } -grpc_millis grpc_backoff_step(grpc_exec_ctx *exec_ctx, grpc_backoff *backoff) {+grpc_backoff_deadlines grpc_backoff_step(grpc_exec_ctx *exec_ctx,+                                         grpc_backoff *backoff) {   backoff->current_backoff = (grpc_millis)(GPR_MIN(       backoff->current_backoff * backoff->multiplier, backoff->max_backoff));+   const double jitter = generate_uniform_random_number_between(       &backoff->rng_state, -backoff->jitter * backoff->current_backoff,       backoff->jitter * backoff->current_backoff);-  const grpc_millis current_deadline =-      grpc_exec_ctx_now(exec_ctx) +-      (grpc_millis)(backoff->current_backoff + jitter);-  return GPR_MAX(current_deadline,-                 grpc_exec_ctx_now(exec_ctx) + backoff->min_backoff);++  const grpc_millis current_timeout =+      GPR_MAX((grpc_millis)(backoff->current_backoff + jitter),+              backoff->min_connect_timeout);++  const grpc_millis now = grpc_exec_ctx_now(exec_ctx);+  return (grpc_backoff_deadlines){now + current_timeout,+                                  now + backoff->current_backoff};","Good catch. It makes me uneasy that, while it makes sense to add the jitter to the `next_backoff_deadline` field, that's nowhere in the spec. Still, it makes sense that the deadline of a potential re-attempt be shifted by the jitter as well.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/10684,147711326,2017-10-30T14:06:37Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -865,98 +1121,1221 @@ grpc_subchannel_call *grpc_client_channel_get_subchannel_call(   return calld->subchannel_call; } +static void start_retriable_subchannel_batches(grpc_exec_ctx *exec_ctx,+                                               void *arg, grpc_error *ignored);++static size_t get_batch_index(grpc_transport_stream_op_batch *batch) {+  // Note: It is important the send_initial_metadata be the first entry+  // here, since the code in pick_subchannel_locked() assumes it will be.+  if (batch->send_initial_metadata) return 0;+  if (batch->send_message) return 1;+  if (batch->send_trailing_metadata) return 2;+  if (batch->recv_initial_metadata) return 3;+  if (batch->recv_message) return 4;+  if (batch->recv_trailing_metadata) return 5;+  GPR_UNREACHABLE_CODE(return (size_t)-1);+}++// Cleans up retry state.  Called when the RPC is committed (i.e., we will+// not attempt any more retries).+static void retry_commit(grpc_exec_ctx *exec_ctx, grpc_call_element *elem,+                         subchannel_call_retry_state *retry_state) {+  call_data *calld = (call_data *)elem->call_data;+  channel_data *chand = (channel_data *)elem->channel_data;+  if (calld->retry_committed) return;+  calld->retry_committed = true;+  if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    gpr_log(GPR_DEBUG, ""chand=%p calld=%p: committing retries"", chand, calld);+  }+  if (retry_state == NULL) return;+  if (retry_state->completed_send_initial_metadata) {+    grpc_metadata_batch_destroy(exec_ctx, &calld->send_initial_metadata);+  }+  for (size_t i = 0; i < retry_state->completed_send_message_count; ++i) {+    grpc_byte_stream_cache_destroy(exec_ctx, calld->send_messages[i]);+  }+  if (retry_state->completed_send_trailing_metadata) {+    grpc_metadata_batch_destroy(exec_ctx, &calld->send_trailing_metadata);+  }+}+ // This is called via the call combiner, so access to calld is synchronized.-static void waiting_for_pick_batches_add(-    call_data *calld, grpc_transport_stream_op_batch *batch) {+static void pending_batches_add(grpc_exec_ctx *exec_ctx,+                                grpc_call_element *elem,+                                grpc_transport_stream_op_batch *batch) {+  call_data *calld = (call_data *)elem->call_data;+  channel_data *chand = (channel_data *)elem->channel_data;+  const size_t idx = get_batch_index(batch);+  if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    gpr_log(GPR_DEBUG,+            ""chand=%p calld=%p: adding pending batch at index %"" PRIdPTR, chand,+            calld, idx);+  }+  pending_batch *pending = &calld->pending_batches[idx];+  GPR_ASSERT(pending->batch == NULL);+  pending->batch = batch;+  pending->send_ops_cached = false;+  pending->elem = elem;   if (batch->send_initial_metadata) {-    GPR_ASSERT(calld->initial_metadata_batch == NULL);-    calld->initial_metadata_batch = batch;-  } else {-    GPR_ASSERT(calld->waiting_for_pick_batches_count < MAX_WAITING_BATCHES);-    calld->waiting_for_pick_batches[calld->waiting_for_pick_batches_count++] =-        batch;+    calld->pending_send_initial_metadata = true;+  }+  if (batch->send_message) {+    calld->pending_send_message = true;+  }+  if (batch->send_trailing_metadata) {+    calld->pending_send_trailing_metadata = true;+  }+  // Check if the batch takes us over the retry buffer limit.+  // Note: We don't check trailing metadata here, because gRPC clients+  // do not send trailing metadata.+  if (batch->send_initial_metadata) {+    calld->bytes_buffered_for_retry += grpc_metadata_batch_size(+        batch->payload->send_initial_metadata.send_initial_metadata);+  }+  if (batch->send_message) {+    calld->bytes_buffered_for_retry +=+        batch->payload->send_message.send_message->length;+  }+  if (calld->bytes_buffered_for_retry > chand->per_rpc_retry_buffer_size) {+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      gpr_log(GPR_DEBUG,+              ""chand=%p calld=%p: exceeded retry buffer size, committing"",+              chand, calld);+    }+    subchannel_call_retry_state *retry_state =+        calld->subchannel_call == NULL+            ? NULL+            : (subchannel_call_retry_state *)+                  grpc_connected_subchannel_call_get_parent_data(+                      calld->subchannel_call);+    retry_commit(exec_ctx, elem, retry_state);+    // If we are not going to retry and have not yet started, pretend+    // retries are disabled so that we don't bother with retry overhead.+    if (calld->num_attempts_completed == 0) calld->enable_retries = false;+  }+}++static void pending_batch_clear(call_data *calld, pending_batch *pending) {+  if (pending->batch->send_initial_metadata) {+    calld->pending_send_initial_metadata = false;+  }+  if (pending->batch->send_message) {+    calld->pending_send_message = false;   }+  if (pending->batch->send_trailing_metadata) {+    calld->pending_send_trailing_metadata = false;+  }+  pending->batch = NULL; }  // This is called via the call combiner, so access to calld is synchronized. static void fail_pending_batch_in_call_combiner(grpc_exec_ctx *exec_ctx,                                                 void *arg, grpc_error *error) {-  call_data *calld = (call_data *)arg;-  if (calld->waiting_for_pick_batches_count > 0) {-    --calld->waiting_for_pick_batches_count;-    grpc_transport_stream_op_batch_finish_with_failure(-        exec_ctx,-        calld->waiting_for_pick_batches[calld->waiting_for_pick_batches_count],-        GRPC_ERROR_REF(error), calld->call_combiner);-  }+  grpc_transport_stream_op_batch *batch = (grpc_transport_stream_op_batch *)arg;+  call_data *calld = (call_data *)batch->handler_private.extra_arg;+  grpc_transport_stream_op_batch_finish_with_failure(+      exec_ctx, batch, GRPC_ERROR_REF(error), calld->call_combiner); }  // This is called via the call combiner, so access to calld is synchronized.-static void waiting_for_pick_batches_fail(grpc_exec_ctx *exec_ctx,-                                          grpc_call_element *elem,-                                          grpc_error *error) {+// If yield_call_combiner is true, assumes responsibility for yielding+// the call combiner.+static void pending_batches_fail(grpc_exec_ctx *exec_ctx,+                                 grpc_call_element *elem, grpc_error *error,+                                 bool yield_call_combiner) {   call_data *calld = (call_data *)elem->call_data;   if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    size_t num_batches = 0;+    for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+      if (calld->pending_batches[i].batch != NULL) ++num_batches;+    }     gpr_log(GPR_DEBUG,             ""chand=%p calld=%p: failing %"" PRIdPTR "" pending batches: %s"",-            elem->channel_data, calld, calld->waiting_for_pick_batches_count,-            grpc_error_string(error));+            elem->channel_data, calld, num_batches, grpc_error_string(error));+  }+  grpc_transport_stream_op_batch+      *batches[GPR_ARRAY_SIZE(calld->pending_batches)];+  size_t num_batches = 0;+  for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+    pending_batch *pending = &calld->pending_batches[i];+    grpc_transport_stream_op_batch *batch = pending->batch;+    if (batch != NULL) {+      batches[num_batches++] = batch;+      pending_batch_clear(calld, pending);+    }   }-  for (size_t i = 0; i < calld->waiting_for_pick_batches_count; ++i) {-    GRPC_CLOSURE_INIT(&calld->handle_pending_batch_in_call_combiner[i],-                      fail_pending_batch_in_call_combiner, calld,+  for (size_t i = yield_call_combiner ? 1 : 0; i < num_batches; ++i) {+    grpc_transport_stream_op_batch *batch = batches[i];+    batch->handler_private.extra_arg = calld;+    GRPC_CLOSURE_INIT(&batch->handler_private.closure,+                      fail_pending_batch_in_call_combiner, batch,                       grpc_schedule_on_exec_ctx);     GRPC_CALL_COMBINER_START(exec_ctx, calld->call_combiner,-                             &calld->handle_pending_batch_in_call_combiner[i],-                             GRPC_ERROR_REF(error),-                             ""waiting_for_pick_batches_fail"");+                             &batch->handler_private.closure,+                             GRPC_ERROR_REF(error), ""pending_batches_fail"");   }-  if (calld->initial_metadata_batch != NULL) {-    grpc_transport_stream_op_batch_finish_with_failure(-        exec_ctx, calld->initial_metadata_batch, GRPC_ERROR_REF(error),-        calld->call_combiner);+  if (yield_call_combiner) {+    if (num_batches > 0) {+      grpc_transport_stream_op_batch_finish_with_failure(+          exec_ctx, batches[0], GRPC_ERROR_REF(error), calld->call_combiner);+    } else {+      GRPC_CALL_COMBINER_STOP(exec_ctx, calld->call_combiner,+                              ""pending_batches_fail"");+    }+  }+  GRPC_ERROR_UNREF(error);+}++// This is called via the call combiner, so access to calld is synchronized.+static void resume_pending_batch_in_call_combiner(grpc_exec_ctx *exec_ctx,+                                                  void *arg,+                                                  grpc_error *ignored) {+  grpc_transport_stream_op_batch *batch = (grpc_transport_stream_op_batch *)arg;+  grpc_subchannel_call *subchannel_call =+      (grpc_subchannel_call *)batch->handler_private.extra_arg;+  grpc_subchannel_call_process_op(exec_ctx, subchannel_call, batch);+}++// This is called via the call combiner, so access to calld is synchronized.+static void pending_batches_resume(grpc_exec_ctx *exec_ctx,+                                   grpc_call_element *elem) {+  channel_data *chand = (channel_data *)elem->channel_data;+  call_data *calld = (call_data *)elem->call_data;+  if (calld->enable_retries) {+    start_retriable_subchannel_batches(exec_ctx, elem, GRPC_ERROR_NONE);+    return;+  }+  // Retries not enabled; send down batches as-is.+  if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    size_t num_batches = 0;+    for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+      if (calld->pending_batches[i].batch != NULL) ++num_batches;+    }+    gpr_log(GPR_DEBUG, ""chand=%p calld=%p: starting %"" PRIdPTR+                       "" pending batches on subchannel_call=%p"",+            chand, calld, num_batches, calld->subchannel_call);+  }+  grpc_transport_stream_op_batch+      *batches[GPR_ARRAY_SIZE(calld->pending_batches)];+  size_t num_batches = 0;+  for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+    pending_batch *pending = &calld->pending_batches[i];+    grpc_transport_stream_op_batch *batch = pending->batch;+    if (batch != NULL) {+      batches[num_batches++] = batch;+      pending_batch_clear(calld, pending);+    }+  }+  for (size_t i = 1; i < num_batches; ++i) {+    grpc_transport_stream_op_batch *batch = batches[i];+    batch->handler_private.extra_arg = calld->subchannel_call;+    GRPC_CLOSURE_INIT(&batch->handler_private.closure,+                      resume_pending_batch_in_call_combiner, batch,+                      grpc_schedule_on_exec_ctx);+    GRPC_CALL_COMBINER_START(exec_ctx, calld->call_combiner,+                             &batch->handler_private.closure, GRPC_ERROR_NONE,+                             ""pending_batches_resume"");+  }+  GPR_ASSERT(num_batches > 0);+  grpc_subchannel_call_process_op(exec_ctx, calld->subchannel_call, batches[0]);+}++static void on_complete(grpc_exec_ctx *exec_ctx, void *arg, grpc_error *error);++static subchannel_batch_data *batch_data_create(grpc_call_element *elem,+                                                int refcount) {+  call_data *calld = (call_data *)elem->call_data;+  subchannel_call_retry_state *retry_state = (subchannel_call_retry_state *)+      grpc_connected_subchannel_call_get_parent_data(calld->subchannel_call);+  subchannel_batch_data *batch_data = (subchannel_batch_data *)gpr_arena_alloc(+      calld->arena, sizeof(*batch_data));+  batch_data->elem = elem;+  batch_data->subchannel_call =+      GRPC_SUBCHANNEL_CALL_REF(calld->subchannel_call, ""batch_data_create"");+  batch_data->batch.payload = &retry_state->batch_payload;+  gpr_ref_init(&batch_data->refs, refcount);+  GRPC_CLOSURE_INIT(&batch_data->on_complete, on_complete, batch_data,+                    grpc_schedule_on_exec_ctx);+  batch_data->batch.on_complete = &batch_data->on_complete;+  return batch_data;+}++static void batch_data_unref(grpc_exec_ctx *exec_ctx,+                             subchannel_batch_data *batch_data) {+  if (gpr_unref(&batch_data->refs)) {+    if (batch_data->send_initial_metadata_storage != NULL) {+      grpc_metadata_batch_destroy(exec_ctx, &batch_data->send_initial_metadata);+    }+    if (batch_data->send_trailing_metadata_storage != NULL) {+      grpc_metadata_batch_destroy(exec_ctx,+                                  &batch_data->send_trailing_metadata);+    }+    if (batch_data->batch.recv_initial_metadata) {+      grpc_metadata_batch_destroy(exec_ctx, &batch_data->recv_initial_metadata);+    }+    if (batch_data->batch.recv_trailing_metadata) {+      grpc_metadata_batch_destroy(exec_ctx,+                                  &batch_data->recv_trailing_metadata);+    }+    GRPC_SUBCHANNEL_CALL_UNREF(exec_ctx, batch_data->subchannel_call,+                               ""batch_data_unref"");+  }+}++static void maybe_clear_pending_batch(call_data *calld,+                                      pending_batch *pending) {+  grpc_transport_stream_op_batch *batch = pending->batch;+  if (batch->on_complete == NULL &&+      (!batch->recv_initial_metadata ||+       batch->payload->recv_initial_metadata.recv_initial_metadata_ready ==+           NULL) &&+      (!batch->recv_message ||+       batch->payload->recv_message.recv_message_ready == NULL)) {+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      channel_data *chand = (channel_data *)pending->elem->channel_data;+      call_data *calld = (call_data *)pending->elem->call_data;+      gpr_log(GPR_DEBUG, ""chand=%p calld=%p: clearing pending batch"", chand,+              calld);+    }+    pending_batch_clear(calld, pending);+  }+}++// Caches data for send ops so that it can be retried later, if not+// already cached.+static void maybe_cache_send_ops_for_batch(grpc_exec_ctx *exec_ctx,+                                           call_data *calld,+                                           pending_batch *pending) {+  if (pending->send_ops_cached) return;+  pending->send_ops_cached = true;+  grpc_transport_stream_op_batch *batch = pending->batch;+  // Save a copy of metadata for send_initial_metadata ops.+  if (batch->send_initial_metadata) {+    calld->seen_send_initial_metadata = true;+    GPR_ASSERT(calld->send_initial_metadata_storage == NULL);+    grpc_metadata_batch *send_initial_metadata =+        batch->payload->send_initial_metadata.send_initial_metadata;+    calld->send_initial_metadata_storage =+        (grpc_linked_mdelem *)gpr_arena_alloc(+            calld->arena,+            sizeof(grpc_linked_mdelem) * send_initial_metadata->list.count);+    grpc_metadata_batch_copy(exec_ctx, send_initial_metadata,+                             &calld->send_initial_metadata,+                             calld->send_initial_metadata_storage);+    calld->send_initial_metadata_flags =+        batch->payload->send_initial_metadata.send_initial_metadata_flags;+    calld->peer_string = batch->payload->send_initial_metadata.peer_string;+  }+  // Set up cache for send_message ops.+  if (batch->send_message) {+    grpc_byte_stream_cache *cache = (grpc_byte_stream_cache *)gpr_arena_alloc(+        calld->arena, sizeof(grpc_byte_stream_cache));+    grpc_byte_stream_cache_init(cache,+                                batch->payload->send_message.send_message);+    calld->send_messages.push_back(cache);+  }+  // Save metadata batch for send_trailing_metadata ops.+  if (batch->send_trailing_metadata) {+    calld->seen_send_trailing_metadata = true;+    GPR_ASSERT(calld->send_trailing_metadata_storage == NULL);+    grpc_metadata_batch *send_trailing_metadata =+        batch->payload->send_trailing_metadata.send_trailing_metadata;+    calld->send_trailing_metadata_storage =+        (grpc_linked_mdelem *)gpr_arena_alloc(+            calld->arena,+            sizeof(grpc_linked_mdelem) * send_trailing_metadata->list.count);+    grpc_metadata_batch_copy(exec_ctx, send_trailing_metadata,+                             &calld->send_trailing_metadata,+                             calld->send_trailing_metadata_storage);+  }+}++static bool is_status_code_in_list(grpc_status_code status,+                                   grpc_status_code *list, size_t list_size) {+  if (list == NULL) return true;+  for (size_t i = 0; i < list_size; ++i) {+    if (status == list[i]) return true;+  }+  return false;+}++static void start_pick_locked(grpc_exec_ctx *exec_ctx, void *arg,+                              grpc_error *ignored);++// Returns true if the call is being retried.+static bool maybe_retry(grpc_exec_ctx *exec_ctx, grpc_call_element *elem,+                        subchannel_batch_data *batch_data,+                        grpc_status_code status,+                        grpc_mdelem *server_pushback_md) {+  channel_data *chand = (channel_data *)elem->channel_data;+  call_data *calld = (call_data *)elem->call_data;+  // Get retry policy.+  GPR_ASSERT(calld->method_params != NULL);+  retry_policy_params *retry_policy = calld->method_params->retry_policy;+  GPR_ASSERT(retry_policy != NULL);+  // If we've already dispatched a retry from this call, return true.+  // This catches the case where the batch has multiple callbacks+  // (i.e., it includes either recv_message or recv_initial_metadata).+  subchannel_call_retry_state *retry_state = NULL;+  if (batch_data != NULL) {+    retry_state = (subchannel_call_retry_state *)+        grpc_connected_subchannel_call_get_parent_data(+            batch_data->subchannel_call);+    if (retry_state->retry_dispatched) {+      if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+        gpr_log(GPR_DEBUG, ""chand=%p calld=%p: retry already dispatched"", chand,+                calld);+      }+      return true;+    }+  }+  // Check status.+  if (status == GRPC_STATUS_OK) {+    grpc_server_retry_throttle_data_record_success(calld->retry_throttle_data);+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      gpr_log(GPR_DEBUG, ""chand=%p calld=%p: call succeeded"", chand, calld);+    }+    return false;+  }+  // Status is not OK.  Check whether the status is retryable.+  if (!is_status_code_in_list(status, retry_policy->retryable_status_codes,+                              retry_policy->num_retryable_status_codes)) {+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      gpr_log(GPR_DEBUG,+              ""chand=%p calld=%p: status %s not configured as retryable"", chand,+              calld, grpc_status_string(status));+    }+    return false;+  }+  // Record the failure and check whether retries are throttled.+  // Note that it's important for this check to come after the status+  // code check above, since we should only record failures whose statuses+  // match the configured retryable status codes, so that we don't count+  // things like failures due to malformed requests (INVALID_ARGUMENT).+  // Conversely, it's important for this to come before the remaining+  // checks, so that we don't fail to record failures due to other factors.+  if (!grpc_server_retry_throttle_data_record_failure(+          calld->retry_throttle_data)) {+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      gpr_log(GPR_DEBUG, ""chand=%p calld=%p: retries throttled"", chand, calld);+    }+    return false;+  }+  // Check whether the call is committed.+  if (calld->retry_committed) {+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      gpr_log(GPR_DEBUG, ""chand=%p calld=%p: retries committed"", chand, calld);+    }+    return false;+  }+  // Check whether we have retries remaining.+  ++calld->num_attempts_completed;+  if (calld->num_attempts_completed == retry_policy->max_attempts) {+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      gpr_log(GPR_DEBUG, ""chand=%p calld=%p: exceeded %d retry attempts"", chand,+              calld, retry_policy->max_attempts);+    }+    return false;+  }+  // If the call was cancelled from the surface, don't retry.+  if (calld->error != GRPC_ERROR_NONE) {+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      gpr_log(GPR_DEBUG,+              ""chand=%p calld=%p: call cancelled from surface, not retrying"",+              chand, calld);+    }+    return false;+  }+  // Check server push-back.+  grpc_millis server_pushback_ms = -1;+  if (server_pushback_md != NULL) {+    // If the value is ""-1"" or any other unparseable string, we do not retry.+    uint32_t ms;+    if (!grpc_parse_slice_to_uint32(GRPC_MDVALUE(*server_pushback_md), &ms)) {+      if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+        gpr_log(GPR_DEBUG,+                ""chand=%p calld=%p: not retrying due to server push-back"",+                chand, calld);+      }+      return false;+    } else {+      if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+        gpr_log(GPR_DEBUG,+                ""chand=%p calld=%p: server push-back: retry in %u ms"", chand,+                calld, ms);+      }+      server_pushback_ms = (grpc_millis)ms;+    }+  }+  // Reset subchannel call.+  if (calld->subchannel_call != NULL) {+    GRPC_SUBCHANNEL_CALL_UNREF(exec_ctx, calld->subchannel_call,+                               ""client_channel_call_retry"");+    calld->subchannel_call = NULL;+  }+  // Compute backoff delay.+  grpc_millis next_attempt_time;+  if (server_pushback_ms >= 0) {+    next_attempt_time = grpc_exec_ctx_now(exec_ctx) + server_pushback_ms;+    calld->last_attempt_got_server_pushback = true;+  } else if (calld->num_attempts_completed == 1 ||+             calld->last_attempt_got_server_pushback) {+    grpc_backoff_init(+        &calld->retry_backoff, retry_policy->initial_backoff,+        retry_policy->backoff_multiplier, RETRY_BACKOFF_JITTER,+        GPR_MIN(retry_policy->initial_backoff, retry_policy->max_backoff),+        retry_policy->max_backoff);+    next_attempt_time = grpc_backoff_begin(exec_ctx, &calld->retry_backoff);+    calld->last_attempt_got_server_pushback = false;+  } else {+    next_attempt_time = grpc_backoff_step(exec_ctx, &calld->retry_backoff);+  }+  if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    gpr_log(GPR_DEBUG,+            ""chand=%p calld=%p: retrying failed call in %"" PRIdPTR "" ms"", chand,+            calld, next_attempt_time - grpc_exec_ctx_now(exec_ctx));+  }+  // Schedule retry after computed delay.+  GRPC_CLOSURE_INIT(&calld->pick_closure, start_pick_locked, elem,+                    grpc_combiner_scheduler(chand->combiner));+  grpc_timer_init(exec_ctx, &calld->retry_timer, next_attempt_time,+                  &calld->pick_closure);+  // Update bookkeeping.+  if (retry_state != NULL) retry_state->retry_dispatched = true;+  return true;+}++static void invoke_recv_initial_metadata_callback(grpc_exec_ctx *exec_ctx,+                                                  void *arg,+                                                  grpc_error *error) {+  subchannel_batch_data *batch_data = (subchannel_batch_data *)arg;+  call_data *calld = (call_data *)batch_data->elem->call_data;+  channel_data *chand = (channel_data *)batch_data->elem->channel_data;+  // Find pending batch.+  pending_batch *pending = NULL;+  for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+    grpc_transport_stream_op_batch *batch = calld->pending_batches[i].batch;+    if (batch != NULL && batch->recv_initial_metadata &&+        batch->payload->recv_initial_metadata.recv_initial_metadata_ready !=+            NULL) {+      if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+        gpr_log(GPR_DEBUG,+                ""chand=%p calld=%p: invoking recv_initial_metadata_ready for ""+                ""pending batch at index %"" PRIdPTR,+                chand, calld, i);+      }+      pending = &calld->pending_batches[i];+      break;+    }+  }+  GPR_ASSERT(pending != NULL);+  // Return metadata.+  grpc_metadata_batch_move(+      &batch_data->recv_initial_metadata,+      pending->batch->payload->recv_initial_metadata.recv_initial_metadata);+  // Update bookkeeping.+  // Note: Need to do this before invoking the callback, since invoking+  // the callback will result in yielding the call combiner.+  grpc_closure *recv_initial_metadata_ready =+      pending->batch->payload->recv_initial_metadata+          .recv_initial_metadata_ready;+  pending->batch->payload->recv_initial_metadata.recv_initial_metadata_ready =+      NULL;+  maybe_clear_pending_batch(calld, pending);+  batch_data_unref(exec_ctx, batch_data);+  // Invoke callback.+  GRPC_CLOSURE_RUN(exec_ctx, recv_initial_metadata_ready,+                   GRPC_ERROR_REF(error));+}++// Intercepts recv_initial_metadata_ready callback for retries.+// Commits the call and returns the initial metadata up the stack.+static void recv_initial_metadata_ready(grpc_exec_ctx *exec_ctx, void *arg,+                                        grpc_error *error) {+  subchannel_batch_data *batch_data = (subchannel_batch_data *)arg;+  grpc_call_element *elem = batch_data->elem;+  channel_data *chand = (channel_data *)elem->channel_data;+  call_data *calld = (call_data *)elem->call_data;+  if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    gpr_log(GPR_DEBUG,+            ""chand=%p calld=%p: got recv_initial_metadata_ready, error=%s"",+            chand, calld, grpc_error_string(error));+  }+  // If we got an error, attempt to retry the call.+  if (error != GRPC_ERROR_NONE) {+    grpc_status_code status;+    grpc_error_get_status(exec_ctx, error, calld->deadline, &status, NULL,+                          NULL);+    if (maybe_retry(exec_ctx, batch_data->elem, batch_data, status,+                    NULL /* server_pushback_md */)) {+      batch_data_unref(exec_ctx, batch_data);+      return;+    }   } else {+    // If we got a Trailers-Only response and have not yet gotten the+    // recv_trailing_metadata on_complete callback, do nothing.  We can+    // evaluate whether to retry when recv_trailing_metadata comes back.+    subchannel_call_retry_state *retry_state = (subchannel_call_retry_state *)+        grpc_connected_subchannel_call_get_parent_data(+            batch_data->subchannel_call);+    if (batch_data->trailing_metadata_available &&+        !retry_state->completed_recv_trailing_metadata) {+      if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+        gpr_log(GPR_DEBUG,+                ""chand=%p calld=%p: deferring recv_initial_metadata_ready ""+                ""(Trailers-Only)"",+                chand, calld);+      }+      retry_state->recv_initial_metadata_ready_deferred = true;+      retry_state->recv_initial_metadata_error = GRPC_ERROR_REF(error);+      GRPC_CALL_COMBINER_STOP(exec_ctx, calld->call_combiner,+                              ""recv_initial_metadata_ready trailers-only"");+      return;+    }+    // No error, so commit the call.+    retry_commit(exec_ctx, elem, retry_state);+  }+  // Manually invoking a callback function; it does not take ownership of error.+  invoke_recv_initial_metadata_callback(exec_ctx, batch_data, error);+  GRPC_ERROR_UNREF(error);+}++static void invoke_recv_message_callback(grpc_exec_ctx *exec_ctx, void *arg,+                                         grpc_error *error) {+  subchannel_batch_data *batch_data = (subchannel_batch_data *)arg;+  call_data *calld = (call_data *)batch_data->elem->call_data;+  channel_data *chand = (channel_data *)batch_data->elem->channel_data;+  // Find pending op.+  pending_batch *pending = NULL;+  for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+    grpc_transport_stream_op_batch *batch = calld->pending_batches[i].batch;+    if (batch != NULL && batch->recv_message &&+        batch->payload->recv_message.recv_message_ready != NULL) {+      if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+        gpr_log(GPR_DEBUG,+                ""chand=%p calld=%p: invoking recv_message_ready for ""+                ""pending batch at index %"" PRIdPTR,+                chand, calld, i);+      }+      pending = &calld->pending_batches[i];+      break;+    }+  }+  GPR_ASSERT(pending != NULL);+  // Return payload.+  *pending->batch->payload->recv_message.recv_message =+      batch_data->recv_message;+  // Update bookkeeping.+  // Note: Need to do this before invoking the callback, since invoking+  // the callback will result in yielding the call combiner.+  grpc_closure *recv_message_ready =+      pending->batch->payload->recv_message.recv_message_ready;+  pending->batch->payload->recv_message.recv_message_ready = NULL;+  maybe_clear_pending_batch(calld, pending);+  batch_data_unref(exec_ctx, batch_data);+  // Invoke callback.+  GRPC_CLOSURE_RUN(exec_ctx, recv_message_ready, GRPC_ERROR_REF(error));+}++// Intercepts recv_message_ready callback for retries.+// Commits the call and returns the message up the stack.+static void recv_message_ready(grpc_exec_ctx *exec_ctx, void *arg,+                               grpc_error *error) {+  subchannel_batch_data *batch_data = (subchannel_batch_data *)arg;+  grpc_call_element *elem = batch_data->elem;+  channel_data *chand = (channel_data *)elem->channel_data;+  call_data *calld = (call_data *)elem->call_data;+  if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    gpr_log(GPR_DEBUG, ""chand=%p calld=%p: got recv_message_ready, error=%s"",+            chand, calld, grpc_error_string(error));+  }+  subchannel_call_retry_state *retry_state = (subchannel_call_retry_state *)+      grpc_connected_subchannel_call_get_parent_data(+          batch_data->subchannel_call);+  // If we got an error, attempt to retry the call.+  if (error != GRPC_ERROR_NONE) {+    grpc_status_code status;+    grpc_error_get_status(exec_ctx, error, calld->deadline, &status, NULL,+                          NULL);+    if (maybe_retry(exec_ctx, batch_data->elem, batch_data, status,+                    NULL /* server_pushback_md */)) {+      batch_data_unref(exec_ctx, batch_data);+      return;+    }+  } else if (batch_data->recv_message == NULL &&+             !retry_state->completed_recv_trailing_metadata) {+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      gpr_log(GPR_DEBUG,+              ""chand=%p calld=%p: deferring recv_message_ready (NULL ""+              ""message and recv_trailing_metadata pending)"",+              chand, calld);+    }+    retry_state->recv_message_ready_deferred = true;+    retry_state->recv_message_error = GRPC_ERROR_REF(error);     GRPC_CALL_COMBINER_STOP(exec_ctx, calld->call_combiner,-                            ""waiting_for_pick_batches_fail"");+                            ""recv_message_ready null"");+    return;+  } else {+    // No error, so commit the call.+    retry_commit(exec_ctx, elem, retry_state);   }+  // Manually invoking a callback function; it does not take ownership of error.+  invoke_recv_message_callback(exec_ctx, batch_data, error);   GRPC_ERROR_UNREF(error); } -// This is called via the call combiner, so access to calld is synchronized.-static void run_pending_batch_in_call_combiner(grpc_exec_ctx *exec_ctx,-                                               void *arg, grpc_error *ignored) {-  call_data *calld = (call_data *)arg;-  if (calld->waiting_for_pick_batches_count > 0) {-    --calld->waiting_for_pick_batches_count;-    grpc_subchannel_call_process_op(-        exec_ctx, calld->subchannel_call,-        calld->waiting_for_pick_batches[calld->waiting_for_pick_batches_count]);+// Returns true if all pending ops in the pending batch have been completed.+static bool pending_batch_is_completed(+    pending_batch *pending, call_data *calld,+    subchannel_call_retry_state *retry_state) {+  if (pending->batch == NULL || pending->batch->on_complete == NULL) {+    return false;+  }+  if (pending->batch->send_initial_metadata &&+      !retry_state->completed_send_initial_metadata) {+    return false;+  }+  if (pending->batch->send_message &&+      retry_state->completed_send_message_count < calld->send_messages.size()) {+    return false;+  }+  if (pending->batch->send_trailing_metadata &&+      !retry_state->completed_send_trailing_metadata) {+    return false;+  }+  if (pending->batch->recv_initial_metadata &&+      !retry_state->completed_recv_initial_metadata) {+    return false;   }+  if (pending->batch->recv_message &&+      retry_state->completed_recv_message_count <+          retry_state->started_recv_message_count) {+    return false;+  }+  if (pending->batch->recv_trailing_metadata &&+      !retry_state->completed_recv_trailing_metadata) {+    return false;+  }+  return true; } -// This is called via the call combiner, so access to calld is synchronized.-static void waiting_for_pick_batches_resume(grpc_exec_ctx *exec_ctx,-                                            grpc_call_element *elem) {+// Callback used to intercept on_complete from subchannel calls.+// Called only when retries are enabled.+static void on_complete(grpc_exec_ctx *exec_ctx, void *arg, grpc_error *error) {+  subchannel_batch_data *batch_data = (subchannel_batch_data *)arg;+  grpc_call_element *elem = batch_data->elem;   channel_data *chand = (channel_data *)elem->channel_data;   call_data *calld = (call_data *)elem->call_data;   if (GRPC_TRACER_ON(grpc_client_channel_trace)) {-    gpr_log(GPR_DEBUG, ""chand=%p calld=%p: sending %"" PRIdPTR-                       "" pending batches to subchannel_call=%p"",-            chand, calld, calld->waiting_for_pick_batches_count,-            calld->subchannel_call);-  }-  for (size_t i = 0; i < calld->waiting_for_pick_batches_count; ++i) {-    GRPC_CLOSURE_INIT(&calld->handle_pending_batch_in_call_combiner[i],-                      run_pending_batch_in_call_combiner, calld,+    char *op_str = grpc_transport_stream_op_batch_string(&batch_data->batch);+    gpr_log(GPR_DEBUG, ""chand=%p calld=%p: got on_complete, error=%s, batch=%s"",+            chand, calld, grpc_error_string(error), op_str);+    gpr_free(op_str);+  }+  // Update bookkeeping in retry_state.+  subchannel_call_retry_state *retry_state = (subchannel_call_retry_state *)+      grpc_connected_subchannel_call_get_parent_data(+          batch_data->subchannel_call);+  if (batch_data->batch.send_initial_metadata) {+    retry_state->completed_send_initial_metadata = true;+  }+  if (batch_data->batch.send_message) {+    ++retry_state->completed_send_message_count;+  }+  if (batch_data->batch.send_trailing_metadata) {+    retry_state->completed_send_trailing_metadata = true;+  }+  if (batch_data->batch.recv_initial_metadata) {+    retry_state->completed_recv_initial_metadata = true;+  }+  if (batch_data->batch.recv_message) {+    ++retry_state->completed_recv_message_count;+  }+  if (batch_data->batch.recv_trailing_metadata) {+    retry_state->completed_recv_trailing_metadata = true;+  }+  // Check if the call is finished, and if so, get its status.+  // The call is finished if either (a) this callback was invoked with","@ctiller, a question here: Currently, the retry code is just looking at the first error we see, whether it's a callback being invoked with `error != GRPC_ERROR_NONE` or receiving a non-OK status from recv_trailing_metadata.  However, given that those two things can happen at the same time, I am wondering if we actually need to use a heuristic similar to what surface/call.cc uses to determine the call's status based on multiple inputs.If we do need to do something like this, then we would presumably want to wait until we get back the result from recv_trailing_metadata before we decide on the final status.  However, if the application has not yet started a recv_trailing_metadata op (e.g., if it doesn't try starting that op until recv_message returns a NULL byte buffer), then we will never see the status.  But perhaps we could work around this by having the client_channel code preemptively start a batch on the subchannel call containing only recv_trailing_metadata, so that we always get status as soon as possible, even if the application hasn't yet asked for it.Thoughts...?",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,147769570,2017-10-30T17:07:08Z,src/python/grpcio/grpc/__init__.py,"@@ -424,6 +424,23 @@ def __init__(self, credentials):         self._credentials = credentials  +class ServerCertificateConfig(object):+    """"""A certificate config for use with an SSL-enabled Server, e.g., can+    be returned in the certificate config fetching callback.++    This class has no supported interface -- it exists to define the+    type of its instances and its instances exist to be passed to+    other functions.++    NOTE: do not re-use instances of this class, i.e, always create a",This seems like a usability problem. What's the reason for this restriction? What problems arise if it is violated?,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,147770108,2017-10-30T17:09:00Z,src/python/grpcio/grpc/__init__.py,"@@ -1252,6 +1269,65 @@ def ssl_server_credentials(private_key_certificate_chain_pairs,             ], require_client_auth))  +def ssl_server_credentials_with_cert_config_fetcher(cert_config_fetcher_cb,+                                                    require_client_auth=False):+    """"""Creates a ServerCredentials for use with an SSL-enabled Server.++    Args:+      cert_config_fetcher_cb (callable): a callback that takes no+        arguments and should return a ServerCertificateConfig to+        replace the server's current cert, or None for no change+        (i.e., the server will continue its current certificate+        config). The library will call this callback once during+        server instantiation to obtain the initial certificate+        config---a valid ServerCertificateConfig must be returned in+        this case. Then, the library will call this callback on+        *every* new client connection before starting the TLS+        handshake with the client, thus allowing the user application+        to optionally return a new ServerCertificateConfig that the+        server will then use for the handshake.+      require_client_auth: A boolean indicating whether or not to+        require clients to be authenticated. May only be True if+        root_certificates is not None.++    Returns:+      A ServerCredentials for use with an SSL-enabled+      Server. Typically, this object is an argument to+      add_secure_port() method during server setup.+    """"""++    if not callable(cert_config_fetcher_cb):+        raise ValueError('cert_config_fetcher_cb must be callable')+    return ServerCredentials(+        _cygrpc.server_credentials_ssl_with_cert_config_fetcher(+            cert_config_fetcher_cb, require_client_auth))+++def ssl_server_certificate_config(private_key_certificate_chain_pairs,+                                  root_certificates=None):+    """"""Creates a ServerCertificateConfig for use with an SSL-enabled Server.++    Args:+      private_key_certificate_chain_pairs: A list of pairs of the form","Why a list rather than a sequence, collection, or iterable?",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,147771781,2017-10-30T17:15:16Z,src/python/grpcio/grpc/__init__.py,"@@ -1252,6 +1269,65 @@ def ssl_server_credentials(private_key_certificate_chain_pairs,             ], require_client_auth))  +def ssl_server_credentials_with_cert_config_fetcher(cert_config_fetcher_cb,+                                                    require_client_auth=False):+    """"""Creates a ServerCredentials for use with an SSL-enabled Server.++    Args:+      cert_config_fetcher_cb (callable): a callback that takes no",Why one parameter that must behave in two different ways depending on context rather than two different parameters each subject to simpler constraints?,
1170852,cauthu,https://api.github.com/repos/grpc/grpc/pulls/13188,147784731,2017-10-30T17:58:45Z,src/python/grpcio/grpc/__init__.py,"@@ -1252,6 +1269,65 @@ def ssl_server_credentials(private_key_certificate_chain_pairs,             ], require_client_auth))  +def ssl_server_credentials_with_cert_config_fetcher(cert_config_fetcher_cb,+                                                    require_client_auth=False):+    """"""Creates a ServerCredentials for use with an SSL-enabled Server.++    Args:+      cert_config_fetcher_cb (callable): a callback that takes no","are you referring to the fact that during server initialization the callback must return a valid config, vs subsequently it can return a valid config or `None`?if so, that's because it is required by the C-core: during sever initialization, the C-core has to call the callback to obtain the certificate config, and C-core will error without a valid cert config returned. https://github.com/grpc/grpc/blob/master/include/grpc/grpc_security.h#L396",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13189,148010617,2017-10-31T14:23:05Z,src/core/lib/security/transport/security_handshaker.cc,"@@ -403,7 +403,22 @@ static void security_handshaker_do_handshake(grpc_exec_ctx *exec_ctx,   h->args = args;   h->on_handshake_done = on_handshake_done;   gpr_ref(&h->refs);-  grpc_error *error = do_handshaker_next_locked(exec_ctx, h, NULL, 0);+  size_t bytes_received_size = args->read_buffer->length;",This code looks almost identical to the existing code in `on_handshake_data_received_from_peer()`.  How about refactoring to avoid duplication?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/10684,148029709,2017-10-31T15:21:04Z,src/core/lib/support/arena.cc,"@@ -22,6 +22,45 @@ #include <grpc/support/log.h> #include <grpc/support/useful.h> +//#define SIMPLE_ARENA_FOR_DEBUGGING++#ifdef SIMPLE_ARENA_FOR_DEBUGGING","This was something suggested by @ctiller at one point while I was trying to debug something.  It's been long enough that I don't actually remember why I needed it at this point, but I remember Craig saying that it might be useful for other things in the future, so I left it in.  If we don't think it's going to be useful, I am happy to remove it, or even move it to a separate PR if you want.",
1170852,cauthu,https://api.github.com/repos/grpc/grpc/pulls/13188,148074705,2017-10-31T17:45:39Z,src/python/grpcio_tests/tests/interop/server_ssl_cert_reload_test/helloworld_pb2_grpc.py,"@@ -0,0 +1,47 @@+import grpc",done... tests no longer using these.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13189,148102412,2017-10-31T19:22:43Z,src/core/lib/security/transport/security_handshaker.cc,"@@ -65,6 +65,25 @@ typedef struct {   tsi_handshaker_result *handshaker_result; } security_handshaker; +static size_t move_read_buffer_into_handshake_buffer(grpc_exec_ctx *exec_ctx,+                                                     security_handshaker *h) {+  size_t bytes_in_read_buffer = h->args->read_buffer->length;+  if (h->handshake_buffer_size < h->args->read_buffer->length) {+    h->handshake_buffer =+        (uint8_t *)gpr_realloc(h->handshake_buffer, bytes_in_read_buffer);+    h->handshake_buffer_size = h->args->read_buffer->length;+  }+  size_t offset = 0;+  while (h->args->read_buffer->count > 0) {+    grpc_slice next_slice = grpc_slice_buffer_take_first(h->args->read_buffer);","Since we're now removing these slices from the buffer, we probably no longer need to explicitly clear out `h->args->read_buffer` in `on_peer_checked_inner()` (line 200).",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13189,148119462,2017-10-31T20:34:08Z,src/core/lib/security/credentials/fake/fake_credentials.cc,"@@ -33,6 +33,11 @@ #define GRPC_ARG_FAKE_SECURITY_EXPECTED_TARGETS \   ""grpc.fake_security.expected_targets"" +typedef struct {+  grpc_server_credentials base;+  int add_sniffing_handshaker;","Okay, I think I see what what the goal is here.  But in that case, I don't think this implementation is correct.In order to test that the security handshaker is doing the right thing, we need to inject a new non-security handshaker into the handshaker list that will run before the security handshaker does, read some bytes into `h->args->read_buffer`, and then hand off control to the security handshaker.  That way, we can verify that the security handshaker will process the bytes read for it by the preceding handshaker.As currently written, this code will actually replace the security handshaker with this new handshaker.  In other words, this is actually testing that the **transport** is using `h->args->read_buffer`, not that the security handshaker is -- in fact, the security handshaker is not actually running at all in this test.So here's what I suggest:- Move this new handshaker into a test.  It should not be defined outside of the test, because it won't be used anywhere else.- The new handshaker should not be injected using security credentials, because that will replace the security handshaker.  Instead, we want to inject the new handshaker prior to the security handshaker.  You can do that using a handshaker factory; as an example, see https://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/http_connect_handshaker.cc#L373.Once you do that, I think you can use your new test handshaker with SSL credentials and verify that the TLS handshake still succeeds.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13189,148273408,2017-11-01T14:23:36Z,test/core/handshake/sniffing_handshaker_server_ssl.c,"@@ -0,0 +1,137 @@+/*+ *+ * Copyright 2016 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <arpa/inet.h>+#include <openssl/err.h>+#include <openssl/ssl.h>+#include <string.h>+#include <sys/socket.h>+#include <unistd.h>++#include <grpc/grpc.h>+#include <grpc/grpc_security.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>+#include <grpc/support/sync.h>+#include <grpc/support/thd.h>+#include ""src/core/lib/iomgr/load_file.h""+#include ""test/core/util/port.h""+#include ""test/core/util/test_config.h""++#include ""src/core/lib/channel/handshaker_factory.h""+#include ""src/core/lib/channel/handshaker_registry.h""+#include ""src/core/lib/security/transport/security_handshaker.h""++#include ""test/core/handshake/server_ssl_common.h""++static void fake_sniffing_handshaker_destroy(grpc_exec_ctx *ctx,+                                             grpc_handshaker *handshaker);+static void fake_sniffing_handshaker_shutdown(grpc_exec_ctx *ctx,+                                              grpc_handshaker *handshaker,+                                              grpc_error *error);+static void fake_sniffing_handshaker_do_handshake(+    grpc_exec_ctx *ctx, grpc_handshaker *handshaker,+    grpc_tcp_server_acceptor *acceptor, grpc_closure *on_handshake_done,+    grpc_handshaker_args *args);++const grpc_handshaker_vtable fake_sniffing_handshaker_vtable = {+    fake_sniffing_handshaker_destroy, fake_sniffing_handshaker_shutdown,+    fake_sniffing_handshaker_do_handshake};++typedef struct {+  grpc_handshaker base;+  gpr_mu mu;+  grpc_closure on_read;+  grpc_closure *on_handshake_done;+  grpc_handshaker_args *args;+  grpc_slice_buffer read_scratch_buffer;","I don't think this field is necessary.  We can use `h->args->read_buffer` directly in the call to `grpc_endpoint_read()`.As a consequence of this, `fake_sniffing_handshaker_on_read()` is no longer needed, since its only real purpose is to copy the slices from `h->read_scratch_buffer` into `h->args->read_buffer`.  Instead, we can use `on_handshake_done` as the callback we pass to `grpc_endpoint_read()`.And once we eliminate `fake_sniffing_handshaker_on_read()`, then we can eliminate all of the data fields in this struct, because their only purpose was to retain state between `fake_sniffing_handshaker_do_handshake()` and `fake_sniffing_handshaker_on_read()`.  And if there are no data members, then there's no need for a mutex, which means that this entire struct is unnecessary.In other words, I think we can just use `grpc_handshaker` directly instead of creating our own struct here.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,148316464,2017-11-01T16:48:24Z,src/python/grpcio/grpc/__init__.py,"@@ -1252,6 +1269,65 @@ def ssl_server_credentials(private_key_certificate_chain_pairs,             ], require_client_auth))  +def ssl_server_credentials_with_cert_config_fetcher(cert_config_fetcher_cb,+                                                    require_client_auth=False):+    """"""Creates a ServerCredentials for use with an SSL-enabled Server.++    Args:+      cert_config_fetcher_cb (callable): a callback that takes no","[If gRPC Core jumped off a bridge, should gRPC Python too?](https://xkcd.com/1170/) Surely we should have the capacity within gRPC Python to make two callbacks look like one? What's a developer-oriented, application-oriented reason for why one complex callback is better than two simpler callbacks?",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,148318027,2017-11-01T16:54:18Z,src/python/grpcio/grpc/__init__.py,"@@ -1252,6 +1269,65 @@ def ssl_server_credentials(private_key_certificate_chain_pairs,             ], require_client_auth))  +def ssl_server_credentials_with_cert_config_fetcher(cert_config_fetcher_cb,+                                                    require_client_auth=False):+    """"""Creates a ServerCredentials for use with an SSL-enabled Server.++    Args:+      cert_config_fetcher_cb (callable): a callback that takes no+        arguments and should return a ServerCertificateConfig to+        replace the server's current cert, or None for no change+        (i.e., the server will continue its current certificate+        config). The library will call this callback once during+        server instantiation to obtain the initial certificate+        config---a valid ServerCertificateConfig must be returned in+        this case. Then, the library will call this callback on+        *every* new client connection before starting the TLS+        handshake with the client, thus allowing the user application+        to optionally return a new ServerCertificateConfig that the+        server will then use for the handshake.+      require_client_auth: A boolean indicating whether or not to+        require clients to be authenticated. May only be True if+        root_certificates is not None.++    Returns:+      A ServerCredentials for use with an SSL-enabled+      Server. Typically, this object is an argument to+      add_secure_port() method during server setup.+    """"""++    if not callable(cert_config_fetcher_cb):+        raise ValueError('cert_config_fetcher_cb must be callable')+    return ServerCredentials(+        _cygrpc.server_credentials_ssl_with_cert_config_fetcher(+            cert_config_fetcher_cb, require_client_auth))+++def ssl_server_certificate_config(private_key_certificate_chain_pairs,+                                  root_certificates=None):+    """"""Creates a ServerCertificateConfig for use with an SSL-enabled Server.++    Args:+      private_key_certificate_chain_pairs: A list of pairs of the form","Well, does order matter? Do duplicates matter? Will the parameter be iterated over more than once? Need all the parameter's data fit in memory all at once?(I suspect the answer is going to be ""A collection of pairs..."".)",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,148321011,2017-11-01T17:05:32Z,src/python/grpcio_tests/tests/interop/server_ssl_cert_reload_test/_test.py,"@@ -0,0 +1,363 @@+# Copyright 2017 gRPC authors.",Why locate this test in tests/interop rather than tests/unit? tests/interop is a bit of a special directory because everything there should have something to do with [the gRPC Interop Test Cases](https://github.com/grpc/grpc/blob/master/doc/interop-test-descriptions.md).,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,148321318,2017-11-01T17:06:39Z,src/python/grpcio_tests/tests/interop/server_ssl_cert_reload_test/_test.py,"@@ -0,0 +1,363 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++'''+This tests the ability of gRPC server to rotate its SSL cert for use+in future channels with clients while not affecting any existing+channel.++For the credentials, we use two disjoint certificate hierarchies+`cert_hier_1` and `cert_hier_2`.++The test involves one server and two clients. Client 1 is a one-shot+client: establish the secure channel, perform the RPC, and exit;+client 2 establishes a secure channel, performs the RPC request, then+sleeps for a specified amount, then performs a second RPC request on+the same secure channel.++All three start out using `cert_hier_1` and we check that everything+works as expected, i.e., both client 1 and client 2 successfully+perform RPCs.++Then the server switches to `cert_hier_2`. Client 2, with its existing+secure channel to the server, must be able to perform another RPC+after the server's switch. Client 1 must fail while it continues to+use `cert_hier_1`, and must succeed when it switches to `cert_hier_2`.++All the ""success"" checks are based on the standard output/error of the+two clients.+'''++import os+import unittest+from concurrent import futures++import grpc+from src.proto.grpc.testing import test_pb2_grpc++from tests.interop import methods+++DIR = os.path.abspath(os.path.dirname(__file__))++def _get_abs_path(path):+    return DIR + '/' + path+++ca_1_pem = open(_get_abs_path('cert_hier_1/certs/ca.cert.pem')).read()+ca_2_pem = open(_get_abs_path('cert_hier_2/certs/ca.cert.pem')).read()++client_key_1_pem = \+    open(_get_abs_path('cert_hier_1/intermediate/private/client.key.pem')).read()+client_chain_1_pem = '\n'.join([+    open(_get_abs_path('cert_hier_1/intermediate/certs/client.cert.pem')).read(),+    open(_get_abs_path('cert_hier_1/intermediate/certs/intermediate.cert.pem')).read(),+    ])++client_key_2_pem = \+    open(_get_abs_path('cert_hier_2/intermediate/private/client.key.pem')).read()+client_chain_2_pem = '\n'.join([+    open(_get_abs_path('cert_hier_2/intermediate/certs/client.cert.pem')).read(),+    open(_get_abs_path('cert_hier_2/intermediate/certs/intermediate.cert.pem')).read(),+    ])++server_key_1_pem = \+    open(_get_abs_path('cert_hier_1/intermediate/private/localhost-1.key.pem')).read()+server_cert_1_pem = '\n'.join([+    open(_get_abs_path('cert_hier_1/intermediate/certs/localhost-1.cert.pem')).read(),+    open(_get_abs_path('cert_hier_1/intermediate/certs/intermediate.cert.pem')).read(),+])++server_key_2_pem = \+    open(_get_abs_path('cert_hier_2/intermediate/private/localhost-1.key.pem')).read()+server_cert_2_pem = '\n'.join([+    open(_get_abs_path('cert_hier_2/intermediate/certs/localhost-1.cert.pem')).read(),+    open(_get_abs_path('cert_hier_2/intermediate/certs/intermediate.cert.pem')).read(),+])+++class CertConfigFetcher(object):+  def __init__(self, ca_1_pem, my_key_1_pem, my_cert_1_pem,+               ca_2_pem, my_key_2_pem, my_cert_2_pem,+               switch_cert_on_client_num):+    self.client_num = -1+    self.ca_2_pem = ca_2_pem+    self.my_key_2_pem = my_key_2_pem+    self.my_cert_2_pem = my_cert_2_pem+    self.switch_cert_on_client_num = switch_cert_on_client_num+    self.cert_config = grpc.ssl_server_certificate_config(+        [(my_key_1_pem, my_cert_1_pem)],+        root_certificates=ca_1_pem,+      )+    # we simulate cb failures at 2 and 3+    assert self.switch_cert_on_client_num > 3++  def __call__(self):+    self.client_num += 1+    if self.client_num == 0:+      # this is actually during server initialzation+      return self.cert_config+    else:+      if self.client_num in (2, 3):+        raise ValueError('just an error for fun, should not affect the test')++      if self.client_num != self.switch_cert_on_client_num:+        return None+      else:+        # do the switch+        return grpc.ssl_server_certificate_config(+          [(self.my_key_2_pem, self.my_cert_2_pem)],+          root_certificates=self.ca_2_pem,+        )+++class _ServerSSLCertReloadTestBase(unittest.TestCase):",Don't put `Base` in the names of classes you intend to use as base classes.,
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/13173,148321487,2017-11-01T17:07:15Z,src/core/lib/support/cpu_posix.cc,"@@ -52,7 +53,27 @@ unsigned gpr_cpu_current_cpu(void) {      most code that's using this is using it to shard across work queues though,      so here we use thread identity instead to achieve a similar though not      identical effect */-  return (unsigned)GPR_HASH_POINTER(&magic_thread_local, gpr_cpu_num_cores());+  static auto DeleteValue = [](void *value_ptr) {+    unsigned int *value = static_cast<unsigned int *>(value_ptr);+    if (value) {+      delete value;+    }+  };+  static pthread_key_t thread_id_key;+  static int thread_id_key_create_result __attribute__((unused)) =+      pthread_key_create(&thread_id_key, DeleteValue);+  // pthread_t isn't portably defined to map to an integral type. So keep track+  // of thread identity explicitly so hashing works reliably.+  static std::atomic<unsigned int> thread_counter(0);++  unsigned int *thread_id =+      static_cast<unsigned int *>(pthread_getspecific(thread_id_key));+  if (thread_id == nullptr) {+    thread_id = new unsigned int(thread_counter++);","Sorry, we can't use new and delete into the core: https://github.com/grpc/grpc/blob/master/doc/core/moving-to-c%2B%2B.mdPlease change to using gpr_malloc and gpr_free instead.",
1170852,cauthu,https://api.github.com/repos/grpc/grpc/pulls/13188,148333445,2017-11-01T17:50:13Z,src/python/grpcio/grpc/__init__.py,"@@ -1252,6 +1269,65 @@ def ssl_server_credentials(private_key_certificate_chain_pairs,             ], require_client_auth))  +def ssl_server_credentials_with_cert_config_fetcher(cert_config_fetcher_cb,+                                                    require_client_auth=False):+    """"""Creates a ServerCredentials for use with an SSL-enabled Server.++    Args:+      cert_config_fetcher_cb (callable): a callback that takes no","in the two different ways i've implemented the callback (in the `interop` test and in a separate example for my own use case), it doesn't seem that complex. essentially the callback has to determine: ""do i have new cert info that i want the server to use, if so, return the new cert info, else return None"", and the initialization case is a trivial check.nevertheless, do you mind specifying the interface you have in mind? is it: python grpc asks for two callbacks: one will be called only once for initialization, and the other will be called for every new client connection? the user can of course choose to, for example, provide the same callable object for both.thanks!",
1170852,cauthu,https://api.github.com/repos/grpc/grpc/pulls/13188,148588586,2017-11-02T16:34:42Z,src/python/grpcio_tests/tests/unit/server_ssl_cert_reload_test/_test.py,"@@ -0,0 +1,364 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++""""""+This tests server certificate rotation support.++This tests the ability of gRPC server to rotate its SSL cert for use+in future channels with clients while not affecting any existing+channel.++For the credentials, we use two disjoint certificate hierarchies+`cert_hier_1` and `cert_hier_2`.++The test involves one server and two clients. Client 1 is a one-shot+client: establish the secure channel, perform the RPC, and exit;+client 2 establishes a secure channel, performs the RPC request, then+sleeps for a specified amount, then performs a second RPC request on+the same secure channel.++All three start out using `cert_hier_1` and we check that everything+works as expected, i.e., both client 1 and client 2 successfully+perform RPCs.++Then the server switches to `cert_hier_2`. Client 2, with its existing+secure channel to the server, must be able to perform another RPC+after the server's switch. Client 1 must fail while it continues to+use `cert_hier_1`, and must succeed when it switches to `cert_hier_2`.++All the ""success"" checks are based on the standard output/error of the+two clients.+""""""++import os+import unittest+from concurrent import futures++import grpc+from src.proto.grpc.testing import test_pb2_grpc++from tests.interop import methods",fixed with https://github.com/grpc/grpc/pull/13188/commits/a6cd8906fc5d0de133c42e36b8bf6905256386ff : no longer use `interop.modules`,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/13246,148700746,2017-11-03T02:10:13Z,templates/test/core/surface/public_headers_must_be_c89.c.template,"@@ -35,9 +35,23 @@       assert(hdr[0:len(pfx)] == pfx)       hdrs.add(hdr[len(pfx):])   hdrs = sorted(list(hdrs))+  fns = list()+  for api in c_apis:+    if is_platform_header(api.header):+      continue+    fns.append(api.name)   %>\   % for hdr in hdrs:   #include <${hdr}>   % endfor -  int main(int argc, char **argv) { return 0; }+  #include <stdio.h>++  int main(int argc, char **argv) {+    if(argc == 12345678) {+      % for fn in fns:+      printf(""%lx"", (unsigned long) ${fn});;",Why two semicolongs?,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/12427,148802345,2017-11-03T14:47:27Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc,"@@ -1163,36 +1163,56 @@ static int glb_pick_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *pol,                            ""won't work without it. Failing""));     return 0;   }-   glb_lb_policy *glb_policy = (glb_lb_policy *)pol;-  bool pick_done;-+  bool pick_done = false;   if (glb_policy->rr_policy != NULL) {-    if (GRPC_TRACER_ON(grpc_lb_glb_trace)) {-      gpr_log(GPR_INFO, ""grpclb %p about to PICK from RR %p"",-              (void *)glb_policy, (void *)glb_policy->rr_policy);-    }-    GRPC_LB_POLICY_REF(glb_policy->rr_policy, ""glb_pick"");+    const grpc_connectivity_state rr_connectivity_state =+        grpc_lb_policy_check_connectivity_locked(exec_ctx,+                                                 glb_policy->rr_policy, NULL);+    // The glb_policy->rr_policy may have transition to SHUTDOWN but the+    // callback registered to capture this event+    // (glb_rr_connectivity_changed_locked) may not have been invoked yet. We+    // need to make sure we aren't trying to pick from a RR policy instance+    // that's in shutdown.+    if (rr_connectivity_state == GRPC_CHANNEL_SHUTDOWN) {+      if (GRPC_TRACER_ON(grpc_lb_glb_trace)) {+        gpr_log(GPR_INFO,+                ""grpclb %p NOT picking from from RR %p: RR conn state=%s"",+                (void *)glb_policy, (void *)glb_policy->rr_policy,+                grpc_connectivity_state_name(rr_connectivity_state));+      }+      // Attempt to switch over to a pending update.","The intent is to take action ASAP. While it's true that an eventual  `glb_rr_connectivity_changed_locked` would set `rr_policy` to `NULL`, it'd then take _another_ pick attempt for the `else {  // glb_policy->rr_policy == NULL` branch in `glb_pick_locked` (line 1213) to add the pick to the pending list. Moreover, a new RR policy won't be created until a new serverlist is received (the `glb_rr_connectivity_changed_locked` function does not perform any handover or processing of pending updates when the RR's connectivity state is `SHUTDOWN`).",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12427,148810973,2017-11-03T15:15:20Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc,"@@ -1163,36 +1163,56 @@ static int glb_pick_locked(grpc_exec_ctx *exec_ctx, grpc_lb_policy *pol,                            ""won't work without it. Failing""));     return 0;   }-   glb_lb_policy *glb_policy = (glb_lb_policy *)pol;-  bool pick_done;-+  bool pick_done = false;   if (glb_policy->rr_policy != NULL) {-    if (GRPC_TRACER_ON(grpc_lb_glb_trace)) {-      gpr_log(GPR_INFO, ""grpclb %p about to PICK from RR %p"",-              (void *)glb_policy, (void *)glb_policy->rr_policy);-    }-    GRPC_LB_POLICY_REF(glb_policy->rr_policy, ""glb_pick"");+    const grpc_connectivity_state rr_connectivity_state =+        grpc_lb_policy_check_connectivity_locked(exec_ctx,+                                                 glb_policy->rr_policy, NULL);+    // The glb_policy->rr_policy may have transition to SHUTDOWN but the+    // callback registered to capture this event+    // (glb_rr_connectivity_changed_locked) may not have been invoked yet. We+    // need to make sure we aren't trying to pick from a RR policy instance+    // that's in shutdown.+    if (rr_connectivity_state == GRPC_CHANNEL_SHUTDOWN) {+      if (GRPC_TRACER_ON(grpc_lb_glb_trace)) {+        gpr_log(GPR_INFO,+                ""grpclb %p NOT picking from from RR %p: RR conn state=%s"",+                (void *)glb_policy, (void *)glb_policy->rr_policy,+                grpc_connectivity_state_name(rr_connectivity_state));+      }+      // Attempt to switch over to a pending update.","My concern isn't about adding the pick to the pending pick list; that's clearly the right thing to do here.  My concern is about calling `rr_handover_locked()`.  I could be missing something here, but I think this is both pointless and possibly dangerous.The comment here implies that the reason for calling `rr_handover_locked()` is to switch to a pending update (i.e., new list of backend addresses for the RR policy).  However, it's not clear to me when that there would ever be an update available when we get here.  When we get a new serverlist from the balancer, we call `rr_handover_locked()` immediately (see `lb_on_response_received_locked()`), so there's basically no way this can run between when we get a new serverlist and when `rr_handover_locked()` is called on that serverlist.  If this runs before we get a new serverlist, then all we're doing is recreating the RR policy with the same set of addresses that went bad; if it runs afterwards, it's a no-op, because it's updating the RR policy with the list of addresses it already has.Furthermore, it's not clear to me that it's actually safe to give an update to the RR policy when it's in state SHUTDOWN.  I don't think we've tested that case, and it seems to me that it's conceptually not something we should ever do.  In fact, I would argue that we should have an assertion in `rr_update_locked()` that the policy is not being shut down.  (Same for all LB policies, actually.)And finally, even if it is safe to call update on a policy that's shutting down, it seems completely pointless to do so, because we'll still wind up unreffing the RR policy very soon anyway, as soon as the connectivity state callback comes back telling us that the RR policy is in state SHUTDOWN.  It's not clear to me whether the RR policy will make any forward progress in that case, but this is yet another code-path that seems untested and dangerous to me.Wouldn't it make sense to just put the pick on the pending list and wait for the the normal mechanism to recreate the RR policy and drain the pending pick list?  In other words, we treat the case where the RR policy is in state SHUTDOWN the same as if it was NULL.  That seems like a much safer approach here.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/13256,148841290,2017-11-03T17:08:28Z,src/core/lib/iomgr/exec_ctx.cc,"@@ -140,7 +140,7 @@ static gpr_atm timespec_to_atm_round_up(gpr_timespec ts) {  grpc_millis grpc_exec_ctx_now(grpc_exec_ctx *exec_ctx) {   if (!exec_ctx->now_is_valid) {-    exec_ctx->now = timespec_to_atm_round_down(gpr_now(GPR_CLOCK_MONOTONIC));+    exec_ctx->now = timespec_to_atm_round_up(gpr_now(GPR_CLOCK_MONOTONIC));","This will make deadlines expire before they are supposed to, correct?",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/13201,149470627,2017-11-07T19:01:45Z,src/core/ext/transport/chttp2/transport/parsing.cc,"@@ -588,7 +588,11 @@ static grpc_error *init_header_frame_parser(grpc_exec_ctx *exec_ctx,         GRPC_CHTTP2_IF_TRACING(gpr_log(             GPR_ERROR, ""ignoring new grpc_chttp2_stream creation on client""));       }-      return init_skip_frame_parser(exec_ctx, t, 1);+      init_skip_frame_parser(exec_ctx, t, 1);","I know this unconditionally returns GRPC_ERROR_NONE at this point, but would be good practice to track that and return it, regardless of handling this priority edge cases",
28968539,ZhouyihaiDing,https://api.github.com/repos/grpc/grpc/pulls/13209,149498239,2017-11-07T20:45:24Z,examples/php/composer.json,"@@ -7,7 +7,7 @@   },   ""autoload"": {     ""psr-4"": {-      """": ""route_guide/""+      """": "".""","If you remove it, you'll also need to add code below into the router_guide/route_guide_client.php to make the example work.```@include_once dirname(__FILE__).'/GPBMetadata/RouteGuide.php';@include_once dirname(__FILE__).'/Routeguide/RouteGuideClient.php';@include_once dirname(__FILE__).'/Routeguide/RouteNote.php';@include_once dirname(__FILE__).'/Routeguide/RouteSummary.php';@include_once dirname(__FILE__).'/Routeguide/Rectangle.php';@include_once dirname(__FILE__).'/Routeguide/Point.php';@include_once dirname(__FILE__).'/Routeguide/Feature.php';```@stanley-cheung ,is this supposed to be the example including by composer or include by hand is better here?Greeter_client example is including manually, but router_guide example has more files need to be included.",
4578188,pmarks-net,https://api.github.com/repos/grpc/grpc/pulls/13290,149524917,2017-11-07T22:33:07Z,third_party/address_sorting/address_sorting.h,"@@ -0,0 +1,83 @@+/*	$NetBSD: getaddrinfo.c,v 1.82 2006/03/25 12:09:40 rpaulo Exp $	*/+/*	$KAME: getaddrinfo.c,v 1.29 2000/08/31 17:26:57 itojun Exp $	*/+/*+ * Copyright (C) 1995, 1996, 1997, and 1998 WIDE Project.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions+ * are met:+ * 1. Redistributions of source code must retain the above copyright+ *    notice, this list of conditions and the following disclaimer.+ * 2. Redistributions in binary form must reproduce the above copyright+ *    notice, this list of conditions and the following disclaimer in the+ *    documentation and/or other materials provided with the distribution.+ * 3. Neither the name of the project nor the names of its contributors+ *    may be used to endorse or promote products derived from this software+ *    without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE PROJECT AND CONTRIBUTORS ``AS IS'' AND+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE PROJECT OR CONTRIBUTORS BE LIABLE+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF+ * SUCH DAMAGE.+ *+ */++/*+ * This is an adaptation of Android's implementation of RFC 6724+ * (in Android's getaddrinfo.c). It has some cosmetic differences+ * from Android's getaddrinfo.c, but Android's getaddrinfo.c was+ * used as a guide or example of a way to implement the RFC 6724 spec when+ * this was written.+ */++#ifndef GRPC_ADDRESS_SORTING_H+#define GRPC_ADDRESS_SORTING_H++#include <grpc/support/port_platform.h>++#include <netinet/in.h>+#include ""src/core/ext/filters/client_channel/lb_policy_factory.h""++#ifdef __cplusplus+extern ""C"" {+#endif++void address_sorting_rfc_6724_sort(grpc_lb_addresses* resolved_lb_addrs);++void address_sorting_init();+void address_sorting_shutdown();++struct address_sorting_socket_factory;++/* The socket factory interface is exposed only for testing */+typedef struct {+  int (*socket)(struct address_sorting_socket_factory* factory, int domain,+                int type, int protocol);+  int (*connect)(struct address_sorting_socket_factory* factory, int sockfd,+                 const struct sockaddr* addr, socklen_t addrlen);+  int (*getsockname)(struct address_sorting_socket_factory* factory, int sockfd,+                     struct sockaddr* addr, socklen_t* addrlen);+  int (*close)(struct address_sorting_socket_factory* factory, int sockfd);+  void (*destroy)(struct address_sorting_socket_factory* factory);+} address_sorting_socket_factory_vtable;++typedef struct address_sorting_socket_factory {+  const address_sorting_socket_factory_vtable* vtable;+} address_sorting_socket_factory;++void address_sorting_override_socket_factory_for_testing(+    address_sorting_socket_factory* factory);",Is this pointer-to-pointer-to-pointers pattern used elsewhere in gRPC?  Seems like a lot of indirection.,
4578188,pmarks-net,https://api.github.com/repos/grpc/grpc/pulls/13290,149530249,2017-11-07T22:57:58Z,third_party/address_sorting/address_sorting.c,"@@ -0,0 +1,405 @@+/*	$NetBSD: getaddrinfo.c,v 1.82 2006/03/25 12:09:40 rpaulo Exp $	*/+/*	$KAME: getaddrinfo.c,v 1.29 2000/08/31 17:26:57 itojun Exp $	*/+/*+ * Copyright (C) 1995, 1996, 1997, and 1998 WIDE Project.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions+ * are met:+ * 1. Redistributions of source code must retain the above copyright+ *    notice, this list of conditions and the following disclaimer.+ * 2. Redistributions in binary form must reproduce the above copyright+ *    notice, this list of conditions and the following disclaimer in the+ *    documentation and/or other materials provided with the distribution.+ * 3. Neither the name of the project nor the names of its contributors+ *    may be used to endorse or promote products derived from this software+ *    without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE PROJECT AND CONTRIBUTORS ``AS IS'' AND+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE PROJECT OR CONTRIBUTORS BE LIABLE+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF+ * SUCH DAMAGE.+ *+ */++/*+ * This is an adaptation of Android's implementation of RFC 6724+ * (in Android's getaddrinfo.c). It has some cosmetic differences+ * from Android's getaddrinfo.c, but Android's getaddrinfo.c was+ * used as a guide or example of a way to implement the RFC 6724 spec when+ * this was written.+ */++#include ""address_sorting.h""+#include <errno.h>+#include <grpc/support/alloc.h>+#include <grpc/support/port_platform.h>+#include <grpc/support/useful.h>+#include <limits.h>+#include <netinet/in.h>+#include <string.h>+#include <sys/socket.h>+#include <sys/types.h>+#include ""src/core/ext/filters/client_channel/lb_policy_factory.h""+#include ""src/core/lib/iomgr/sockaddr.h""+#include ""src/core/lib/iomgr/sockaddr_utils.h""+#include ""third_party/address_sorting/address_sorting.h""++// Scope values increase with increase in scope.+static const int kIpv6AddrScopeLinkLocal = 1;+const int kIpv6AddrScopeSiteLocal = 2;+const int kIpv6AddrScopeGlobal = 3;++static address_sorting_socket_factory* g_current_socket_factory = NULL;++static int default_socket_factory_socket(address_sorting_socket_factory* self,+                                         int domain, int type, int protocol) {+  return socket(domain, type, protocol);+}++static int default_socket_factory_connect(address_sorting_socket_factory* self,+                                          int sockfd,+                                          const struct sockaddr* addr,+                                          socklen_t addrlen) {+  return connect(sockfd, addr, addrlen);+}++static int default_socket_factory_getsockname(+    address_sorting_socket_factory* self, int sockfd, struct sockaddr* addr,+    socklen_t* addrlen) {+  return getsockname(sockfd, addr, addrlen);+}++static int default_socket_factory_close(address_sorting_socket_factory* self,+                                        int sockfd) {+  return close(sockfd);+}++static void default_socket_factory_destroy(+    address_sorting_socket_factory* self) {+  return;+}++const address_sorting_socket_factory_vtable default_socket_factory_vtable = {+    default_socket_factory_socket,      default_socket_factory_connect,+    default_socket_factory_getsockname, default_socket_factory_close,+    default_socket_factory_destroy,+};++static address_sorting_socket_factory* create_default_socket_factory() {+  address_sorting_socket_factory* factory =+      gpr_zalloc(sizeof(address_sorting_socket_factory));+  factory->vtable = &default_socket_factory_vtable;+  return factory;+}++static int address_sorting_socket(int domain, int type, int protocol) {+  return g_current_socket_factory->vtable->socket(g_current_socket_factory,+                                                  domain, type, protocol);+}++static int address_sorting_connect(int sockfd, const struct sockaddr* addr,+                                   socklen_t addrlen) {+  return g_current_socket_factory->vtable->connect(g_current_socket_factory,+                                                   sockfd, addr, addrlen);+}++static int address_sorting_getsockname(int sockfd, struct sockaddr* addr,+                                       socklen_t* addrlen) {+  return g_current_socket_factory->vtable->getsockname(g_current_socket_factory,+                                                       sockfd, addr, addrlen);+}++static int address_sorting_close(int sockfd) {+  return g_current_socket_factory->vtable->close(g_current_socket_factory,+                                                 sockfd);+}++static int ipv6_prefix_match_length(const struct sockaddr_in6* sa,+                                    const struct sockaddr_in6* sb) {+  unsigned char* a = (unsigned char*)&sa->sin6_addr;+  unsigned char* b = (unsigned char*)&sb->sin6_addr;+  int cur_bit = 0;+  while (cur_bit < 128) {+    int a_val = a[cur_bit / CHAR_BIT] & (1 << (cur_bit % CHAR_BIT));+    int b_val = b[cur_bit / CHAR_BIT] & (1 << (cur_bit % CHAR_BIT));+    if (a_val == b_val) {+      cur_bit++;+    } else {+      break;+    }+  }+  return cur_bit;+}++static int in6_is_addr_6to4(const struct in6_addr* s_addr) {+  uint8_t* bytes = (uint8_t*)s_addr;+  return bytes[0] == 0x20 && bytes[1] == 0x02;+}++static int in6_is_addr_ula(const struct in6_addr* s_addr) {+  uint8_t* bytes = (uint8_t*)s_addr;+  return (bytes[0] & 0xfe) == 0xfc;+}++static int in6_is_addr_toredo(const struct in6_addr* s_addr) {+  uint8_t* bytes = (uint8_t*)s_addr;+  return bytes[0] == 0x20 && bytes[1] == 0x02 && bytes[2] == 0x00 &&+         bytes[3] == 0x00;+}++static int in6_is_addr_6bone(const struct in6_addr* s_addr) {+  uint8_t* bytes = (uint8_t*)s_addr;+  return bytes[0] == 0x3f && bytes[1] == 0xfe;+}++static int get_label_value(const grpc_resolved_address* resolved_addr) {+  if (grpc_sockaddr_get_family(resolved_addr) == AF_INET) {+    return 4;+  } else if (grpc_sockaddr_get_family(resolved_addr) != AF_INET6) {+    gpr_log(GPR_INFO, ""Address is not AF_INET or AF_INET6."");+    return 1;+  }+  struct sockaddr_in6* ipv6_addr = (struct sockaddr_in6*)&resolved_addr->addr;+  if (IN6_IS_ADDR_LOOPBACK(&ipv6_addr->sin6_addr)) {+    return 0;+  } else if (IN6_IS_ADDR_V4MAPPED(&ipv6_addr->sin6_addr)) {+    return 4;+  } else if (in6_is_addr_6to4(&ipv6_addr->sin6_addr)) {+    return 2;+  } else if (in6_is_addr_toredo(&ipv6_addr->sin6_addr)) {+    return 5;+  } else if (in6_is_addr_ula(&ipv6_addr->sin6_addr)) {+    return 13;+  } else if (IN6_IS_ADDR_V4COMPAT(&ipv6_addr->sin6_addr)) {+    return 3;+  } else if (IN6_IS_ADDR_SITELOCAL(&ipv6_addr->sin6_addr)) {+    return 11;+  } else if (in6_is_addr_6bone(&ipv6_addr->sin6_addr)) {+    return 12;+  }+  return 1;+}++static int get_precedence_value(const grpc_resolved_address* resolved_addr) {+  if (grpc_sockaddr_get_family(resolved_addr) == AF_INET) {+    return 35;+  } else if (grpc_sockaddr_get_family(resolved_addr) != AF_INET6) {+    gpr_log(GPR_INFO, ""Address is not AF_INET or AF_INET6."");+    return 1;+  }+  struct sockaddr_in6* ipv6_addr = (struct sockaddr_in6*)&resolved_addr->addr;+  if (IN6_IS_ADDR_LOOPBACK(&ipv6_addr->sin6_addr)) {+    return 50;+  } else if (IN6_IS_ADDR_V4MAPPED(&ipv6_addr->sin6_addr)) {+    return 35;+  } else if (in6_is_addr_6to4(&ipv6_addr->sin6_addr)) {+    return 30;+  } else if (in6_is_addr_toredo(&ipv6_addr->sin6_addr)) {+    return 5;+  } else if (in6_is_addr_ula(&ipv6_addr->sin6_addr)) {+    return 3;+  } else if (IN6_IS_ADDR_V4COMPAT(&ipv6_addr->sin6_addr) ||+             IN6_IS_ADDR_SITELOCAL(&ipv6_addr->sin6_addr) ||+             in6_is_addr_6bone(&ipv6_addr->sin6_addr)) {+    return 1;+  }+  return 40;+}++static int sockaddr_get_scope(const grpc_resolved_address* resolved_addr) {+  if (grpc_sockaddr_get_family(resolved_addr) == AF_INET) {+    return kIpv6AddrScopeGlobal;+  } else if (grpc_sockaddr_get_family(resolved_addr) == AF_INET6) {+    struct sockaddr_in6* ipv6_addr = (struct sockaddr_in6*)&resolved_addr->addr;+    if (IN6_IS_ADDR_LOOPBACK(&ipv6_addr->sin6_addr) ||+        IN6_IS_ADDR_LINKLOCAL(&ipv6_addr->sin6_addr)) {+      return kIpv6AddrScopeLinkLocal;+    }+    if (IN6_IS_ADDR_SITELOCAL(&ipv6_addr->sin6_addr)) {+      return kIpv6AddrScopeSiteLocal;+    }+    return kIpv6AddrScopeGlobal;+  }+  gpr_log(GPR_ERROR, ""Unknown socket family %d."",+          grpc_sockaddr_get_family(resolved_addr));+  return 0;+}++typedef struct {+  grpc_lb_address lb_addr;+  grpc_resolved_address dest_addr;+  grpc_resolved_address source_addr;+  size_t original_index;+  int source_addr_exists;+} sortable_address;",What is `sizeof(sortable_address)`?  We should consider whether this is too large for pass-by-value.,
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/13288,149541105,2017-11-07T23:58:10Z,Makefile,"@@ -328,6 +328,7 @@ ifeq ($(SYSTEM),Darwin) CXXFLAGS += -stdlib=libc++ endif CPPFLAGS += -g -Wall -Wextra -Werror -Wno-long-long -Wno-unused-parameter -DOSATOMIC_USE_INLINED=1 -Ithird_party/abseil-cpp+COREFLAGS += -fno-rtti -fno-exceptions",is it safe to use fno-exceptions?,
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/13288,149544461,2017-11-08T00:20:16Z,Makefile,"@@ -328,6 +328,7 @@ ifeq ($(SYSTEM),Darwin) CXXFLAGS += -stdlib=libc++ endif CPPFLAGS += -g -Wall -Wextra -Werror -Wno-long-long -Wno-unused-parameter -DOSATOMIC_USE_INLINED=1 -Ithird_party/abseil-cpp+COREFLAGS += -fno-rtti -fno-exceptions","It should be for now since this is only passed to core. If we ever want to start statically linking and using libstd, then we would need to reconsider. But I'd rather have this for now, then whoever needs exceptions in core first can remove it, if they have a convincing argument",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/13290,149546482,2017-11-08T00:34:15Z,third_party/address_sorting/address_sorting.h,"@@ -0,0 +1,83 @@+/*	$NetBSD: getaddrinfo.c,v 1.82 2006/03/25 12:09:40 rpaulo Exp $	*/+/*	$KAME: getaddrinfo.c,v 1.29 2000/08/31 17:26:57 itojun Exp $	*/+/*+ * Copyright (C) 1995, 1996, 1997, and 1998 WIDE Project.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions+ * are met:+ * 1. Redistributions of source code must retain the above copyright+ *    notice, this list of conditions and the following disclaimer.+ * 2. Redistributions in binary form must reproduce the above copyright+ *    notice, this list of conditions and the following disclaimer in the+ *    documentation and/or other materials provided with the distribution.+ * 3. Neither the name of the project nor the names of its contributors+ *    may be used to endorse or promote products derived from this software+ *    without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE PROJECT AND CONTRIBUTORS ``AS IS'' AND+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE PROJECT OR CONTRIBUTORS BE LIABLE+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF+ * SUCH DAMAGE.+ *+ */++/*+ * This is an adaptation of Android's implementation of RFC 6724+ * (in Android's getaddrinfo.c). It has some cosmetic differences+ * from Android's getaddrinfo.c, but Android's getaddrinfo.c was+ * used as a guide or example of a way to implement the RFC 6724 spec when+ * this was written.+ */++#ifndef GRPC_ADDRESS_SORTING_H+#define GRPC_ADDRESS_SORTING_H++#include <grpc/support/port_platform.h>++#include <netinet/in.h>+#include ""src/core/ext/filters/client_channel/lb_policy_factory.h""++#ifdef __cplusplus+extern ""C"" {+#endif++void address_sorting_rfc_6724_sort(grpc_lb_addresses* resolved_lb_addrs);++void address_sorting_init();+void address_sorting_shutdown();++struct address_sorting_socket_factory;++/* The socket factory interface is exposed only for testing */+typedef struct {+  int (*socket)(struct address_sorting_socket_factory* factory, int domain,+                int type, int protocol);+  int (*connect)(struct address_sorting_socket_factory* factory, int sockfd,+                 const struct sockaddr* addr, socklen_t addrlen);+  int (*getsockname)(struct address_sorting_socket_factory* factory, int sockfd,+                     struct sockaddr* addr, socklen_t* addrlen);+  int (*close)(struct address_sorting_socket_factory* factory, int sockfd);+  void (*destroy)(struct address_sorting_socket_factory* factory);+} address_sorting_socket_factory_vtable;++typedef struct address_sorting_socket_factory {+  const address_sorting_socket_factory_vtable* vtable;+} address_sorting_socket_factory;++void address_sorting_override_socket_factory_for_testing(+    address_sorting_socket_factory* factory);","From what I've seen this is relatively common. E.g., [security_handshaker](https://github.com/grpc/grpc/blob/master/src/core/lib/security/transport/security_handshaker.cc#L66)'s use of the [grpc_handshaker vtable and base struct](https://github.com/grpc/grpc/blob/master/src/core/lib/channel/handshaker.h#L94).I'm wondering if this might be able to be refactored after more c++ support in c-core, e.g., https://github.com/grpc/grpc/pull/13288.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/13153,149549470,2017-11-08T00:53:25Z,src/ruby/pb/grpc/health/checker.rb,"@@ -48,6 +48,18 @@ def add_status(service, status)         @status_mutex.synchronize { @statuses[""#{service}""] = status }       end +      # Adds given health status for all given services+      def set_status_for_services(status, *services)+        services.each { |service| add_status(service, status) }","AFAICS setting the status of a server shouldn't be on any fast path and shouldn't need to be fast. Personally I'm more worried about causing possibly unexpected behavior, where e.g., a call to `set_status_for_services` is made, and then RPC's start seeing that new status for some servers but the old status for others; it's probably not a big deal but it might be nice if the status setting is atomic across the whole thing.",
4578188,pmarks-net,https://api.github.com/repos/grpc/grpc/pulls/13290,149552813,2017-11-08T01:17:38Z,third_party/address_sorting/address_sorting.c,"@@ -0,0 +1,405 @@+/*	$NetBSD: getaddrinfo.c,v 1.82 2006/03/25 12:09:40 rpaulo Exp $	*/+/*	$KAME: getaddrinfo.c,v 1.29 2000/08/31 17:26:57 itojun Exp $	*/+/*+ * Copyright (C) 1995, 1996, 1997, and 1998 WIDE Project.+ * All rights reserved.+ *+ * Redistribution and use in source and binary forms, with or without+ * modification, are permitted provided that the following conditions+ * are met:+ * 1. Redistributions of source code must retain the above copyright+ *    notice, this list of conditions and the following disclaimer.+ * 2. Redistributions in binary form must reproduce the above copyright+ *    notice, this list of conditions and the following disclaimer in the+ *    documentation and/or other materials provided with the distribution.+ * 3. Neither the name of the project nor the names of its contributors+ *    may be used to endorse or promote products derived from this software+ *    without specific prior written permission.+ *+ * THIS SOFTWARE IS PROVIDED BY THE PROJECT AND CONTRIBUTORS ``AS IS'' AND+ * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE+ * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE PROJECT OR CONTRIBUTORS BE LIABLE+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL+ * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS+ * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)+ * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT+ * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY+ * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF+ * SUCH DAMAGE.+ *+ */++/*+ * This is an adaptation of Android's implementation of RFC 6724+ * (in Android's getaddrinfo.c). It has some cosmetic differences+ * from Android's getaddrinfo.c, but Android's getaddrinfo.c was+ * used as a guide or example of a way to implement the RFC 6724 spec when+ * this was written.+ */++#include ""address_sorting.h""+#include <errno.h>+#include <grpc/support/alloc.h>+#include <grpc/support/port_platform.h>+#include <grpc/support/useful.h>+#include <limits.h>+#include <netinet/in.h>+#include <string.h>+#include <sys/socket.h>+#include <sys/types.h>+#include ""src/core/ext/filters/client_channel/lb_policy_factory.h""+#include ""src/core/lib/iomgr/sockaddr.h""+#include ""src/core/lib/iomgr/sockaddr_utils.h""+#include ""third_party/address_sorting/address_sorting.h""++// Scope values increase with increase in scope.+static const int kIpv6AddrScopeLinkLocal = 1;+const int kIpv6AddrScopeSiteLocal = 2;+const int kIpv6AddrScopeGlobal = 3;++static address_sorting_socket_factory* g_current_socket_factory = NULL;++static int default_socket_factory_socket(address_sorting_socket_factory* self,+                                         int domain, int type, int protocol) {+  return socket(domain, type, protocol);+}++static int default_socket_factory_connect(address_sorting_socket_factory* self,+                                          int sockfd,+                                          const struct sockaddr* addr,+                                          socklen_t addrlen) {+  return connect(sockfd, addr, addrlen);+}++static int default_socket_factory_getsockname(+    address_sorting_socket_factory* self, int sockfd, struct sockaddr* addr,+    socklen_t* addrlen) {+  return getsockname(sockfd, addr, addrlen);+}++static int default_socket_factory_close(address_sorting_socket_factory* self,+                                        int sockfd) {+  return close(sockfd);+}++static void default_socket_factory_destroy(+    address_sorting_socket_factory* self) {+  return;+}++const address_sorting_socket_factory_vtable default_socket_factory_vtable = {+    default_socket_factory_socket,      default_socket_factory_connect,+    default_socket_factory_getsockname, default_socket_factory_close,+    default_socket_factory_destroy,+};++static address_sorting_socket_factory* create_default_socket_factory() {+  address_sorting_socket_factory* factory =+      gpr_zalloc(sizeof(address_sorting_socket_factory));+  factory->vtable = &default_socket_factory_vtable;+  return factory;+}++static int address_sorting_socket(int domain, int type, int protocol) {+  return g_current_socket_factory->vtable->socket(g_current_socket_factory,+                                                  domain, type, protocol);+}++static int address_sorting_connect(int sockfd, const struct sockaddr* addr,+                                   socklen_t addrlen) {+  return g_current_socket_factory->vtable->connect(g_current_socket_factory,+                                                   sockfd, addr, addrlen);+}++static int address_sorting_getsockname(int sockfd, struct sockaddr* addr,+                                       socklen_t* addrlen) {+  return g_current_socket_factory->vtable->getsockname(g_current_socket_factory,+                                                       sockfd, addr, addrlen);+}++static int address_sorting_close(int sockfd) {+  return g_current_socket_factory->vtable->close(g_current_socket_factory,+                                                 sockfd);+}++static int ipv6_prefix_match_length(const struct sockaddr_in6* sa,+                                    const struct sockaddr_in6* sb) {+  unsigned char* a = (unsigned char*)&sa->sin6_addr;+  unsigned char* b = (unsigned char*)&sb->sin6_addr;+  int cur_bit = 0;+  while (cur_bit < 128) {+    int a_val = a[cur_bit / CHAR_BIT] & (1 << (cur_bit % CHAR_BIT));+    int b_val = b[cur_bit / CHAR_BIT] & (1 << (cur_bit % CHAR_BIT));+    if (a_val == b_val) {+      cur_bit++;+    } else {+      break;+    }+  }+  return cur_bit;+}++static int in6_is_addr_6to4(const struct in6_addr* s_addr) {+  uint8_t* bytes = (uint8_t*)s_addr;+  return bytes[0] == 0x20 && bytes[1] == 0x02;+}++static int in6_is_addr_ula(const struct in6_addr* s_addr) {+  uint8_t* bytes = (uint8_t*)s_addr;+  return (bytes[0] & 0xfe) == 0xfc;+}++static int in6_is_addr_toredo(const struct in6_addr* s_addr) {+  uint8_t* bytes = (uint8_t*)s_addr;+  return bytes[0] == 0x20 && bytes[1] == 0x02 && bytes[2] == 0x00 &&+         bytes[3] == 0x00;+}++static int in6_is_addr_6bone(const struct in6_addr* s_addr) {+  uint8_t* bytes = (uint8_t*)s_addr;+  return bytes[0] == 0x3f && bytes[1] == 0xfe;+}++static int get_label_value(const grpc_resolved_address* resolved_addr) {+  if (grpc_sockaddr_get_family(resolved_addr) == AF_INET) {+    return 4;+  } else if (grpc_sockaddr_get_family(resolved_addr) != AF_INET6) {+    gpr_log(GPR_INFO, ""Address is not AF_INET or AF_INET6."");+    return 1;+  }+  struct sockaddr_in6* ipv6_addr = (struct sockaddr_in6*)&resolved_addr->addr;+  if (IN6_IS_ADDR_LOOPBACK(&ipv6_addr->sin6_addr)) {+    return 0;+  } else if (IN6_IS_ADDR_V4MAPPED(&ipv6_addr->sin6_addr)) {+    return 4;+  } else if (in6_is_addr_6to4(&ipv6_addr->sin6_addr)) {+    return 2;+  } else if (in6_is_addr_toredo(&ipv6_addr->sin6_addr)) {+    return 5;+  } else if (in6_is_addr_ula(&ipv6_addr->sin6_addr)) {+    return 13;+  } else if (IN6_IS_ADDR_V4COMPAT(&ipv6_addr->sin6_addr)) {+    return 3;+  } else if (IN6_IS_ADDR_SITELOCAL(&ipv6_addr->sin6_addr)) {+    return 11;+  } else if (in6_is_addr_6bone(&ipv6_addr->sin6_addr)) {+    return 12;+  }+  return 1;+}++static int get_precedence_value(const grpc_resolved_address* resolved_addr) {+  if (grpc_sockaddr_get_family(resolved_addr) == AF_INET) {+    return 35;+  } else if (grpc_sockaddr_get_family(resolved_addr) != AF_INET6) {+    gpr_log(GPR_INFO, ""Address is not AF_INET or AF_INET6."");+    return 1;+  }+  struct sockaddr_in6* ipv6_addr = (struct sockaddr_in6*)&resolved_addr->addr;+  if (IN6_IS_ADDR_LOOPBACK(&ipv6_addr->sin6_addr)) {+    return 50;+  } else if (IN6_IS_ADDR_V4MAPPED(&ipv6_addr->sin6_addr)) {+    return 35;+  } else if (in6_is_addr_6to4(&ipv6_addr->sin6_addr)) {+    return 30;+  } else if (in6_is_addr_toredo(&ipv6_addr->sin6_addr)) {+    return 5;+  } else if (in6_is_addr_ula(&ipv6_addr->sin6_addr)) {+    return 3;+  } else if (IN6_IS_ADDR_V4COMPAT(&ipv6_addr->sin6_addr) ||+             IN6_IS_ADDR_SITELOCAL(&ipv6_addr->sin6_addr) ||+             in6_is_addr_6bone(&ipv6_addr->sin6_addr)) {+    return 1;+  }+  return 40;+}++static int sockaddr_get_scope(const grpc_resolved_address* resolved_addr) {+  if (grpc_sockaddr_get_family(resolved_addr) == AF_INET) {+    return kIpv6AddrScopeGlobal;+  } else if (grpc_sockaddr_get_family(resolved_addr) == AF_INET6) {+    struct sockaddr_in6* ipv6_addr = (struct sockaddr_in6*)&resolved_addr->addr;+    if (IN6_IS_ADDR_LOOPBACK(&ipv6_addr->sin6_addr) ||+        IN6_IS_ADDR_LINKLOCAL(&ipv6_addr->sin6_addr)) {+      return kIpv6AddrScopeLinkLocal;+    }+    if (IN6_IS_ADDR_SITELOCAL(&ipv6_addr->sin6_addr)) {+      return kIpv6AddrScopeSiteLocal;+    }+    return kIpv6AddrScopeGlobal;+  }+  gpr_log(GPR_ERROR, ""Unknown socket family %d."",+          grpc_sockaddr_get_family(resolved_addr));+  return 0;+}++typedef struct {+  grpc_lb_address lb_addr;+  grpc_resolved_address dest_addr;+  grpc_resolved_address source_addr;+  size_t original_index;+  int source_addr_exists;+} sortable_address;",That is quite large.  I would avoid making copies from `rfc_6724_compare()` and its children (use `const sortable_address*` instead.),
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/13290,149561500,2017-11-08T02:31:32Z,test/cpp/naming/address_sorting_test.cc,"@@ -0,0 +1,540 @@+#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/host_port.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>+#include <grpc/support/sync.h>+#include <grpc/support/time.h>+#include <string.h>++#include <arpa/inet.h>+#include <gflags/gflags.h>+#include <gmock/gmock.h>+#include <sys/socket.h>+#include <sys/types.h>+#include <vector>++#include <address_sorting.h>++#include ""test/cpp/util/subprocess.h""+#include ""test/cpp/util/test_config.h""++extern ""C"" {+#include ""src/core/ext/filters/client_channel/client_channel.h""+#include ""src/core/ext/filters/client_channel/resolver.h""+#include ""src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.h""+#include ""src/core/ext/filters/client_channel/resolver_registry.h""+#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/iomgr/combiner.h""+#include ""src/core/lib/iomgr/executor.h""+#include ""src/core/lib/iomgr/iomgr.h""+#include ""src/core/lib/iomgr/resolve_address.h""+#include ""src/core/lib/iomgr/sockaddr_utils.h""+#include ""src/core/lib/support/env.h""+#include ""src/core/lib/support/string.h""+#include ""test/core/util/port.h""+#include ""test/core/util/test_config.h""+}++namespace {++struct TestAddress {+  std::string dest_addr;+  int family;+};++grpc_resolved_address TestAddressToGrpcResolvedAddress(TestAddress test_addr) {+  char* host;+  char* port;+  grpc_resolved_address resolved_addr;+  gpr_split_host_port(test_addr.dest_addr.c_str(), &host, &port);+  if (test_addr.family == AF_INET) {+    sockaddr_in in_dest;+    in_dest.sin_port = htons(atoi(port));+    ;+    in_dest.sin_family = AF_INET;+    int zeros[2]{0, 0};+    memcpy(&in_dest.sin_zero, &zeros, 8);+    GPR_ASSERT(inet_pton(AF_INET, host, &in_dest.sin_addr) == 1);+    memcpy(&resolved_addr.addr, &in_dest, sizeof(sockaddr_in));+    resolved_addr.len = sizeof(sockaddr_in);+  } else {+    GPR_ASSERT(test_addr.family == AF_INET6);+    sockaddr_in6 in6_dest;+    in6_dest.sin6_port = htons(atoi(port));+    in6_dest.sin6_family = AF_INET6;+    in6_dest.sin6_flowinfo = 0;+    in6_dest.sin6_scope_id = 0;+    GPR_ASSERT(inet_pton(AF_INET6, host, &in6_dest.sin6_addr) == 1);+    memcpy(&resolved_addr.addr, &in6_dest, sizeof(sockaddr_in6));+    resolved_addr.len = sizeof(sockaddr_in6);+  }+  return resolved_addr;+}++class MockSocketFactory : public address_sorting_socket_factory {+ public:+  MockSocketFactory(bool ipv4_supported, bool ipv6_supported,+                    std::map<std::string, TestAddress> dest_addr_to_src_addr)+      : ipv4_supported_(ipv4_supported),+        ipv6_supported_(ipv6_supported),+        dest_addr_to_src_addr_(dest_addr_to_src_addr),+        fd_to_getsockname_return_vals_(std::map<int, TestAddress>()),+        cur_socket_(0) {}++  int Socket(int domain, int type, int protocol) {+    EXPECT_TRUE(domain == AF_INET || domain == AF_INET6);+    if ((domain == AF_INET && !ipv4_supported_) ||+        (domain == AF_INET6 && !ipv6_supported_)) {+      errno = EAFNOSUPPORT;+      return -1;+    }+    return cur_socket_++;+  }++  int Connect(int sockfd, const struct sockaddr* addr, socklen_t addrlen) {+    if ((addr->sa_family == AF_INET && !ipv4_supported_) ||+        (addr->sa_family == AF_INET6 && !ipv6_supported_)) {+      errno = EAFNOSUPPORT;+      return -1;+    }+    char* ip_addr_str;+    grpc_resolved_address resolved_addr;+    memcpy(&resolved_addr.addr, addr, addrlen);+    resolved_addr.len = addrlen;+    grpc_sockaddr_to_string(&ip_addr_str, &resolved_addr,+                            false /* normalize */);+    auto it = dest_addr_to_src_addr_.find(ip_addr_str);+    if (it == dest_addr_to_src_addr_.end()) {+      gpr_log(GPR_DEBUG, ""can't find |%s| in dest to src map"", ip_addr_str);+      errno = ENETUNREACH;+      return -1;+    }+    fd_to_getsockname_return_vals_.insert(+        std::pair<int, TestAddress>(sockfd, it->second));+    return 0;+  }++  int GetSockName(int sockfd, struct sockaddr* addr, socklen_t* addrlen) {+    auto it = fd_to_getsockname_return_vals_.find(sockfd);+    EXPECT_TRUE(it != fd_to_getsockname_return_vals_.end());+    grpc_resolved_address resolved_addr =+        TestAddressToGrpcResolvedAddress(it->second);+    memcpy(addr, &resolved_addr.addr, resolved_addr.len);","ah this was not honoring description of that parameter, fixed",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12829,149593022,2017-11-08T07:40:18Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -541,16 +553,10 @@ static void pf_connectivity_changed_locked(grpc_exec_ctx* exec_ctx, void* arg,         if (sd == original_sd) {           grpc_lb_subchannel_list_unref_for_connectivity_watch(               exec_ctx, sd->subchannel_list, ""pf_candidate_shutdown"");-          shutdown_locked(exec_ctx, p,-                          GRPC_ERROR_CREATE_REFERENCING_FROM_STATIC_STRING(-                              ""Pick first exhausted channels"", &error, 1));+          grpc_lb_policy_try_reresolve(+              exec_ctx, &p->base, &grpc_lb_pick_first_trace, GRPC_ERROR_NONE);           return;         }-        if (sd->subchannel_list == p->subchannel_list) {",Line 549 to line 553 is moved up to make sure we set the state even when the whole subchannel_list is invalid.,
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/12829,149594056,2017-11-08T07:47:18Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -307,16 +309,16 @@ static void pf_update_locked(grpc_exec_ctx* exec_ctx, grpc_lb_policy* policy,         grpc_lb_subchannel_list_ref_for_connectivity_watch(             subchannel_list, ""connectivity_watch+replace_selected"");         grpc_lb_subchannel_data_start_connectivity_watch(exec_ctx, sd);-        if (p->subchannel_list != NULL) {","Line 310 to 314 is moved down to fix a use-after-free (subchannel_list) bug. I am not sure why this PR can trigger such a bug by `if (p->selected->connected_subchannel != NULL)` while master is fine. Anyways, reordering works.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/10684,149749322,2017-11-08T18:03:53Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -868,98 +1128,1238 @@ grpc_subchannel_call *grpc_client_channel_get_subchannel_call(   return calld->subchannel_call; } +static void start_retriable_subchannel_batches(grpc_exec_ctx *exec_ctx,+                                               void *arg, grpc_error *ignored);++static size_t get_batch_index(grpc_transport_stream_op_batch *batch) {+  // Note: It is important the send_initial_metadata be the first entry+  // here, since the code in pick_subchannel_locked() assumes it will be.+  if (batch->send_initial_metadata) return 0;+  if (batch->send_message) return 1;+  if (batch->send_trailing_metadata) return 2;+  if (batch->recv_initial_metadata) return 3;+  if (batch->recv_message) return 4;+  if (batch->recv_trailing_metadata) return 5;+  GPR_UNREACHABLE_CODE(return (size_t)-1);+}++// Cleans up retry state.  Called when the RPC is committed (i.e., we will+// not attempt any more retries).+static void retry_commit(grpc_exec_ctx *exec_ctx, grpc_call_element *elem,+                         subchannel_call_retry_state *retry_state) {+  call_data *calld = (call_data *)elem->call_data;+  channel_data *chand = (channel_data *)elem->channel_data;+  if (calld->retry_committed) return;+  calld->retry_committed = true;+  if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    gpr_log(GPR_DEBUG, ""chand=%p calld=%p: committing retries"", chand, calld);+  }+  if (retry_state == NULL) return;+  if (retry_state->completed_send_initial_metadata) {+    grpc_metadata_batch_destroy(exec_ctx, &calld->send_initial_metadata);+  }+  for (size_t i = 0; i < retry_state->completed_send_message_count; ++i) {+    grpc_byte_stream_cache_destroy(exec_ctx, calld->send_messages[i]);+  }+  if (retry_state->completed_send_trailing_metadata) {+    grpc_metadata_batch_destroy(exec_ctx, &calld->send_trailing_metadata);+  }+}+ // This is called via the call combiner, so access to calld is synchronized.-static void waiting_for_pick_batches_add(-    call_data *calld, grpc_transport_stream_op_batch *batch) {+static void pending_batches_add(grpc_exec_ctx *exec_ctx,+                                grpc_call_element *elem,+                                grpc_transport_stream_op_batch *batch) {+  call_data *calld = (call_data *)elem->call_data;+  channel_data *chand = (channel_data *)elem->channel_data;+  const size_t idx = get_batch_index(batch);+  if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    gpr_log(GPR_DEBUG,+            ""chand=%p calld=%p: adding pending batch at index %"" PRIuPTR, chand,+            calld, idx);+  }+  pending_batch *pending = &calld->pending_batches[idx];+  GPR_ASSERT(pending->batch == NULL);+  pending->batch = batch;+  pending->send_ops_cached = false;   if (batch->send_initial_metadata) {-    GPR_ASSERT(calld->initial_metadata_batch == NULL);-    calld->initial_metadata_batch = batch;-  } else {-    GPR_ASSERT(calld->waiting_for_pick_batches_count < MAX_WAITING_BATCHES);-    calld->waiting_for_pick_batches[calld->waiting_for_pick_batches_count++] =-        batch;+    calld->pending_send_initial_metadata = true;+  }+  if (batch->send_message) {+    calld->pending_send_message = true;+  }+  if (batch->send_trailing_metadata) {+    calld->pending_send_trailing_metadata = true;+  }+  // Check if the batch takes us over the retry buffer limit.+  // Note: We don't check trailing metadata here, because gRPC clients+  // do not send trailing metadata.+  if (batch->send_initial_metadata) {",Combine the bodies of these two conditionals with the earlier if (batch->send_initial_metadata) and if (batch->send_message),
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/10684,149750484,2017-11-08T18:08:21Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -868,98 +1128,1238 @@ grpc_subchannel_call *grpc_client_channel_get_subchannel_call(   return calld->subchannel_call; } +static void start_retriable_subchannel_batches(grpc_exec_ctx *exec_ctx,+                                               void *arg, grpc_error *ignored);++static size_t get_batch_index(grpc_transport_stream_op_batch *batch) {+  // Note: It is important the send_initial_metadata be the first entry+  // here, since the code in pick_subchannel_locked() assumes it will be.+  if (batch->send_initial_metadata) return 0;+  if (batch->send_message) return 1;+  if (batch->send_trailing_metadata) return 2;+  if (batch->recv_initial_metadata) return 3;+  if (batch->recv_message) return 4;+  if (batch->recv_trailing_metadata) return 5;+  GPR_UNREACHABLE_CODE(return (size_t)-1);+}++// Cleans up retry state.  Called when the RPC is committed (i.e., we will+// not attempt any more retries).+static void retry_commit(grpc_exec_ctx *exec_ctx, grpc_call_element *elem,+                         subchannel_call_retry_state *retry_state) {+  call_data *calld = (call_data *)elem->call_data;+  channel_data *chand = (channel_data *)elem->channel_data;+  if (calld->retry_committed) return;+  calld->retry_committed = true;+  if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    gpr_log(GPR_DEBUG, ""chand=%p calld=%p: committing retries"", chand, calld);+  }+  if (retry_state == NULL) return;+  if (retry_state->completed_send_initial_metadata) {+    grpc_metadata_batch_destroy(exec_ctx, &calld->send_initial_metadata);+  }+  for (size_t i = 0; i < retry_state->completed_send_message_count; ++i) {+    grpc_byte_stream_cache_destroy(exec_ctx, calld->send_messages[i]);+  }+  if (retry_state->completed_send_trailing_metadata) {+    grpc_metadata_batch_destroy(exec_ctx, &calld->send_trailing_metadata);+  }+}+ // This is called via the call combiner, so access to calld is synchronized.-static void waiting_for_pick_batches_add(-    call_data *calld, grpc_transport_stream_op_batch *batch) {+static void pending_batches_add(grpc_exec_ctx *exec_ctx,+                                grpc_call_element *elem,+                                grpc_transport_stream_op_batch *batch) {+  call_data *calld = (call_data *)elem->call_data;+  channel_data *chand = (channel_data *)elem->channel_data;+  const size_t idx = get_batch_index(batch);+  if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    gpr_log(GPR_DEBUG,+            ""chand=%p calld=%p: adding pending batch at index %"" PRIuPTR, chand,+            calld, idx);+  }+  pending_batch *pending = &calld->pending_batches[idx];+  GPR_ASSERT(pending->batch == NULL);+  pending->batch = batch;+  pending->send_ops_cached = false;   if (batch->send_initial_metadata) {-    GPR_ASSERT(calld->initial_metadata_batch == NULL);-    calld->initial_metadata_batch = batch;-  } else {-    GPR_ASSERT(calld->waiting_for_pick_batches_count < MAX_WAITING_BATCHES);-    calld->waiting_for_pick_batches[calld->waiting_for_pick_batches_count++] =-        batch;+    calld->pending_send_initial_metadata = true;+  }+  if (batch->send_message) {+    calld->pending_send_message = true;+  }+  if (batch->send_trailing_metadata) {+    calld->pending_send_trailing_metadata = true;+  }+  // Check if the batch takes us over the retry buffer limit.+  // Note: We don't check trailing metadata here, because gRPC clients+  // do not send trailing metadata.+  if (batch->send_initial_metadata) {+    calld->bytes_buffered_for_retry += grpc_metadata_batch_size(+        batch->payload->send_initial_metadata.send_initial_metadata);+  }+  if (batch->send_message) {+    calld->bytes_buffered_for_retry +=+        batch->payload->send_message.send_message->length;+  }+  if (calld->bytes_buffered_for_retry > chand->per_rpc_retry_buffer_size) {+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      gpr_log(GPR_DEBUG,+              ""chand=%p calld=%p: exceeded retry buffer size, committing"",+              chand, calld);+    }+    subchannel_call_retry_state *retry_state =+        calld->subchannel_call == NULL+            ? NULL+            : (subchannel_call_retry_state *)+                  grpc_connected_subchannel_call_get_parent_data(+                      calld->subchannel_call);+    retry_commit(exec_ctx, elem, retry_state);+    // If we are not going to retry and have not yet started, pretend+    // retries are disabled so that we don't bother with retry overhead.+    if (calld->num_attempts_completed == 0) calld->enable_retries = false;   } } +static void pending_batch_clear(call_data *calld, pending_batch *pending) {+  if (pending->batch->send_initial_metadata) {+    calld->pending_send_initial_metadata = false;+  }+  if (pending->batch->send_message) {+    calld->pending_send_message = false;+  }+  if (pending->batch->send_trailing_metadata) {+    calld->pending_send_trailing_metadata = false;+  }+  pending->batch = NULL;+}+ // This is called via the call combiner, so access to calld is synchronized. static void fail_pending_batch_in_call_combiner(grpc_exec_ctx *exec_ctx,                                                 void *arg, grpc_error *error) {-  call_data *calld = (call_data *)arg;-  if (calld->waiting_for_pick_batches_count > 0) {-    --calld->waiting_for_pick_batches_count;-    grpc_transport_stream_op_batch_finish_with_failure(-        exec_ctx,-        calld->waiting_for_pick_batches[calld->waiting_for_pick_batches_count],-        GRPC_ERROR_REF(error), calld->call_combiner);-  }+  grpc_transport_stream_op_batch *batch = (grpc_transport_stream_op_batch *)arg;+  call_data *calld = (call_data *)batch->handler_private.extra_arg;+  grpc_transport_stream_op_batch_finish_with_failure(+      exec_ctx, batch, GRPC_ERROR_REF(error), calld->call_combiner); }  // This is called via the call combiner, so access to calld is synchronized.-static void waiting_for_pick_batches_fail(grpc_exec_ctx *exec_ctx,-                                          grpc_call_element *elem,-                                          grpc_error *error) {+// If yield_call_combiner is true, assumes responsibility for yielding+// the call combiner.+static void pending_batches_fail(grpc_exec_ctx *exec_ctx,+                                 grpc_call_element *elem, grpc_error *error,+                                 bool yield_call_combiner) {   call_data *calld = (call_data *)elem->call_data;   if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    size_t num_batches = 0;+    for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+      if (calld->pending_batches[i].batch != NULL) ++num_batches;+    }     gpr_log(GPR_DEBUG,             ""chand=%p calld=%p: failing %"" PRIuPTR "" pending batches: %s"",-            elem->channel_data, calld, calld->waiting_for_pick_batches_count,-            grpc_error_string(error));+            elem->channel_data, calld, num_batches, grpc_error_string(error));+  }+  grpc_transport_stream_op_batch+      *batches[GPR_ARRAY_SIZE(calld->pending_batches)];+  size_t num_batches = 0;+  for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+    pending_batch *pending = &calld->pending_batches[i];+    grpc_transport_stream_op_batch *batch = pending->batch;+    if (batch != NULL) {+      batches[num_batches++] = batch;+      pending_batch_clear(calld, pending);+    }   }-  for (size_t i = 0; i < calld->waiting_for_pick_batches_count; ++i) {-    GRPC_CLOSURE_INIT(&calld->handle_pending_batch_in_call_combiner[i],-                      fail_pending_batch_in_call_combiner, calld,+  for (size_t i = yield_call_combiner ? 1 : 0; i < num_batches; ++i) {","Why do we skip the first batch if we are yielding the call combiner?I read a bit further on, and will amend the question. Why do we ensure that we fail initial metadata last?",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/13288,149753581,2017-11-08T18:19:34Z,src/core/lib/support/manual_constructor.h,"@@ -22,12 +22,137 @@ // manually construct a region of memory with some type  #include <stddef.h>+#include <stdlib.h> #include <new> #include <type_traits> #include <utility>  namespace grpc_core { +#define ASSERT(x) \","delete this, use GPR_ASSERT(while we were in godbolt.org, it was convenient to have something else)",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/13288,149753719,2017-11-08T18:20:07Z,src/core/lib/support/manual_constructor.h,"@@ -22,12 +22,137 @@ // manually construct a region of memory with some type  #include <stddef.h>+#include <stdlib.h> #include <new> #include <type_traits> #include <utility>  namespace grpc_core { +#define ASSERT(x) \+  if ((x))        \+    ;             \+  else            \+    abort()++template <class Needle, class... Haystack>",Move all these helpers into `namespace poly_impl` (or similar),
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/10684,149753956,2017-11-08T18:21:08Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -868,98 +1128,1238 @@ grpc_subchannel_call *grpc_client_channel_get_subchannel_call(   return calld->subchannel_call; } +static void start_retriable_subchannel_batches(grpc_exec_ctx *exec_ctx,+                                               void *arg, grpc_error *ignored);++static size_t get_batch_index(grpc_transport_stream_op_batch *batch) {+  // Note: It is important the send_initial_metadata be the first entry+  // here, since the code in pick_subchannel_locked() assumes it will be.+  if (batch->send_initial_metadata) return 0;+  if (batch->send_message) return 1;+  if (batch->send_trailing_metadata) return 2;+  if (batch->recv_initial_metadata) return 3;+  if (batch->recv_message) return 4;+  if (batch->recv_trailing_metadata) return 5;+  GPR_UNREACHABLE_CODE(return (size_t)-1);+}++// Cleans up retry state.  Called when the RPC is committed (i.e., we will+// not attempt any more retries).+static void retry_commit(grpc_exec_ctx *exec_ctx, grpc_call_element *elem,+                         subchannel_call_retry_state *retry_state) {+  call_data *calld = (call_data *)elem->call_data;+  channel_data *chand = (channel_data *)elem->channel_data;+  if (calld->retry_committed) return;+  calld->retry_committed = true;+  if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    gpr_log(GPR_DEBUG, ""chand=%p calld=%p: committing retries"", chand, calld);+  }+  if (retry_state == NULL) return;+  if (retry_state->completed_send_initial_metadata) {+    grpc_metadata_batch_destroy(exec_ctx, &calld->send_initial_metadata);+  }+  for (size_t i = 0; i < retry_state->completed_send_message_count; ++i) {+    grpc_byte_stream_cache_destroy(exec_ctx, calld->send_messages[i]);+  }+  if (retry_state->completed_send_trailing_metadata) {+    grpc_metadata_batch_destroy(exec_ctx, &calld->send_trailing_metadata);+  }+}+ // This is called via the call combiner, so access to calld is synchronized.-static void waiting_for_pick_batches_add(-    call_data *calld, grpc_transport_stream_op_batch *batch) {+static void pending_batches_add(grpc_exec_ctx *exec_ctx,+                                grpc_call_element *elem,+                                grpc_transport_stream_op_batch *batch) {+  call_data *calld = (call_data *)elem->call_data;+  channel_data *chand = (channel_data *)elem->channel_data;+  const size_t idx = get_batch_index(batch);+  if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    gpr_log(GPR_DEBUG,+            ""chand=%p calld=%p: adding pending batch at index %"" PRIuPTR, chand,+            calld, idx);+  }+  pending_batch *pending = &calld->pending_batches[idx];+  GPR_ASSERT(pending->batch == NULL);+  pending->batch = batch;+  pending->send_ops_cached = false;   if (batch->send_initial_metadata) {-    GPR_ASSERT(calld->initial_metadata_batch == NULL);-    calld->initial_metadata_batch = batch;-  } else {-    GPR_ASSERT(calld->waiting_for_pick_batches_count < MAX_WAITING_BATCHES);-    calld->waiting_for_pick_batches[calld->waiting_for_pick_batches_count++] =-        batch;+    calld->pending_send_initial_metadata = true;+  }+  if (batch->send_message) {+    calld->pending_send_message = true;+  }+  if (batch->send_trailing_metadata) {+    calld->pending_send_trailing_metadata = true;+  }+  // Check if the batch takes us over the retry buffer limit.+  // Note: We don't check trailing metadata here, because gRPC clients+  // do not send trailing metadata.+  if (batch->send_initial_metadata) {+    calld->bytes_buffered_for_retry += grpc_metadata_batch_size(+        batch->payload->send_initial_metadata.send_initial_metadata);+  }+  if (batch->send_message) {+    calld->bytes_buffered_for_retry +=+        batch->payload->send_message.send_message->length;+  }+  if (calld->bytes_buffered_for_retry > chand->per_rpc_retry_buffer_size) {+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      gpr_log(GPR_DEBUG,+              ""chand=%p calld=%p: exceeded retry buffer size, committing"",+              chand, calld);+    }+    subchannel_call_retry_state *retry_state =+        calld->subchannel_call == NULL+            ? NULL+            : (subchannel_call_retry_state *)+                  grpc_connected_subchannel_call_get_parent_data(+                      calld->subchannel_call);+    retry_commit(exec_ctx, elem, retry_state);+    // If we are not going to retry and have not yet started, pretend+    // retries are disabled so that we don't bother with retry overhead.+    if (calld->num_attempts_completed == 0) calld->enable_retries = false;   } } +static void pending_batch_clear(call_data *calld, pending_batch *pending) {+  if (pending->batch->send_initial_metadata) {+    calld->pending_send_initial_metadata = false;+  }+  if (pending->batch->send_message) {+    calld->pending_send_message = false;+  }+  if (pending->batch->send_trailing_metadata) {+    calld->pending_send_trailing_metadata = false;+  }+  pending->batch = NULL;+}+ // This is called via the call combiner, so access to calld is synchronized. static void fail_pending_batch_in_call_combiner(grpc_exec_ctx *exec_ctx,                                                 void *arg, grpc_error *error) {-  call_data *calld = (call_data *)arg;-  if (calld->waiting_for_pick_batches_count > 0) {-    --calld->waiting_for_pick_batches_count;-    grpc_transport_stream_op_batch_finish_with_failure(-        exec_ctx,-        calld->waiting_for_pick_batches[calld->waiting_for_pick_batches_count],-        GRPC_ERROR_REF(error), calld->call_combiner);-  }+  grpc_transport_stream_op_batch *batch = (grpc_transport_stream_op_batch *)arg;+  call_data *calld = (call_data *)batch->handler_private.extra_arg;+  grpc_transport_stream_op_batch_finish_with_failure(+      exec_ctx, batch, GRPC_ERROR_REF(error), calld->call_combiner); }  // This is called via the call combiner, so access to calld is synchronized.-static void waiting_for_pick_batches_fail(grpc_exec_ctx *exec_ctx,-                                          grpc_call_element *elem,-                                          grpc_error *error) {+// If yield_call_combiner is true, assumes responsibility for yielding+// the call combiner.+static void pending_batches_fail(grpc_exec_ctx *exec_ctx,+                                 grpc_call_element *elem, grpc_error *error,+                                 bool yield_call_combiner) {   call_data *calld = (call_data *)elem->call_data;   if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    size_t num_batches = 0;+    for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+      if (calld->pending_batches[i].batch != NULL) ++num_batches;+    }     gpr_log(GPR_DEBUG,             ""chand=%p calld=%p: failing %"" PRIuPTR "" pending batches: %s"",-            elem->channel_data, calld, calld->waiting_for_pick_batches_count,-            grpc_error_string(error));+            elem->channel_data, calld, num_batches, grpc_error_string(error));+  }+  grpc_transport_stream_op_batch+      *batches[GPR_ARRAY_SIZE(calld->pending_batches)];+  size_t num_batches = 0;+  for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+    pending_batch *pending = &calld->pending_batches[i];+    grpc_transport_stream_op_batch *batch = pending->batch;+    if (batch != NULL) {+      batches[num_batches++] = batch;+      pending_batch_clear(calld, pending);+    }   }-  for (size_t i = 0; i < calld->waiting_for_pick_batches_count; ++i) {-    GRPC_CLOSURE_INIT(&calld->handle_pending_batch_in_call_combiner[i],-                      fail_pending_batch_in_call_combiner, calld,+  for (size_t i = yield_call_combiner ? 1 : 0; i < num_batches; ++i) {+    grpc_transport_stream_op_batch *batch = batches[i];+    batch->handler_private.extra_arg = calld;+    GRPC_CLOSURE_INIT(&batch->handler_private.closure,+                      fail_pending_batch_in_call_combiner, batch,                       grpc_schedule_on_exec_ctx);     GRPC_CALL_COMBINER_START(exec_ctx, calld->call_combiner,-                             &calld->handle_pending_batch_in_call_combiner[i],-                             GRPC_ERROR_REF(error),-                             ""waiting_for_pick_batches_fail"");+                             &batch->handler_private.closure,+                             GRPC_ERROR_REF(error), ""pending_batches_fail"");   }-  if (calld->initial_metadata_batch != NULL) {-    grpc_transport_stream_op_batch_finish_with_failure(-        exec_ctx, calld->initial_metadata_batch, GRPC_ERROR_REF(error),-        calld->call_combiner);-  } else {-    GRPC_CALL_COMBINER_STOP(exec_ctx, calld->call_combiner,-                            ""waiting_for_pick_batches_fail"");+  if (yield_call_combiner) {+    if (num_batches > 0) {+      grpc_transport_stream_op_batch_finish_with_failure(+          exec_ctx, batches[0], GRPC_ERROR_REF(error), calld->call_combiner);+    } else {+      GRPC_CALL_COMBINER_STOP(exec_ctx, calld->call_combiner,+                              ""pending_batches_fail"");+    }   }   GRPC_ERROR_UNREF(error); }  // This is called via the call combiner, so access to calld is synchronized.-static void run_pending_batch_in_call_combiner(grpc_exec_ctx *exec_ctx,-                                               void *arg, grpc_error *ignored) {-  call_data *calld = (call_data *)arg;-  if (calld->waiting_for_pick_batches_count > 0) {-    --calld->waiting_for_pick_batches_count;-    grpc_subchannel_call_process_op(-        exec_ctx, calld->subchannel_call,-        calld->waiting_for_pick_batches[calld->waiting_for_pick_batches_count]);-  }+static void resume_pending_batch_in_call_combiner(grpc_exec_ctx *exec_ctx,+                                                  void *arg,+                                                  grpc_error *ignored) {+  grpc_transport_stream_op_batch *batch = (grpc_transport_stream_op_batch *)arg;+  grpc_subchannel_call *subchannel_call =+      (grpc_subchannel_call *)batch->handler_private.extra_arg;+  grpc_subchannel_call_process_op(exec_ctx, subchannel_call, batch); }  // This is called via the call combiner, so access to calld is synchronized.-static void waiting_for_pick_batches_resume(grpc_exec_ctx *exec_ctx,-                                            grpc_call_element *elem) {+static void pending_batches_resume(grpc_exec_ctx *exec_ctx,+                                   grpc_call_element *elem) {   channel_data *chand = (channel_data *)elem->channel_data;   call_data *calld = (call_data *)elem->call_data;+  if (calld->enable_retries) {+    start_retriable_subchannel_batches(exec_ctx, elem, GRPC_ERROR_NONE);+    return;+  }+  // Retries not enabled; send down batches as-is.   if (GRPC_TRACER_ON(grpc_client_channel_trace)) {-    gpr_log(GPR_DEBUG, ""chand=%p calld=%p: sending %"" PRIuPTR-                       "" pending batches to subchannel_call=%p"",-            chand, calld, calld->waiting_for_pick_batches_count,-            calld->subchannel_call);-  }-  for (size_t i = 0; i < calld->waiting_for_pick_batches_count; ++i) {-    GRPC_CLOSURE_INIT(&calld->handle_pending_batch_in_call_combiner[i],-                      run_pending_batch_in_call_combiner, calld,+    size_t num_batches = 0;+    for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+      if (calld->pending_batches[i].batch != NULL) ++num_batches;+    }+    gpr_log(GPR_DEBUG, ""chand=%p calld=%p: starting %"" PRIuPTR+                       "" pending batches on subchannel_call=%p"",+            chand, calld, num_batches, calld->subchannel_call);+  }+  grpc_transport_stream_op_batch+      *batches[GPR_ARRAY_SIZE(calld->pending_batches)];+  size_t num_batches = 0;+  for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+    pending_batch *pending = &calld->pending_batches[i];+    grpc_transport_stream_op_batch *batch = pending->batch;+    if (batch != NULL) {+      batches[num_batches++] = batch;+      pending_batch_clear(calld, pending);+    }+  }+  for (size_t i = 1; i < num_batches; ++i) {+    grpc_transport_stream_op_batch *batch = batches[i];+    batch->handler_private.extra_arg = calld->subchannel_call;+    GRPC_CLOSURE_INIT(&batch->handler_private.closure,+                      resume_pending_batch_in_call_combiner, batch,                       grpc_schedule_on_exec_ctx);     GRPC_CALL_COMBINER_START(exec_ctx, calld->call_combiner,-                             &calld->handle_pending_batch_in_call_combiner[i],-                             GRPC_ERROR_NONE,-                             ""waiting_for_pick_batches_resume"");+                             &batch->handler_private.closure, GRPC_ERROR_NONE,+                             ""pending_batches_resume"");+  }+  GPR_ASSERT(num_batches > 0);+  grpc_subchannel_call_process_op(exec_ctx, calld->subchannel_call, batches[0]);+}++static void on_complete(grpc_exec_ctx *exec_ctx, void *arg, grpc_error *error);++static subchannel_batch_data *batch_data_create(grpc_call_element *elem,+                                                int refcount) {+  call_data *calld = (call_data *)elem->call_data;+  subchannel_call_retry_state *retry_state = (subchannel_call_retry_state *)+      grpc_connected_subchannel_call_get_parent_data(calld->subchannel_call);+  subchannel_batch_data *batch_data = (subchannel_batch_data *)gpr_arena_alloc(+      calld->arena, sizeof(*batch_data));+  batch_data->elem = elem;+  batch_data->subchannel_call =+      GRPC_SUBCHANNEL_CALL_REF(calld->subchannel_call, ""batch_data_create"");+  batch_data->batch.payload = &retry_state->batch_payload;+  gpr_ref_init(&batch_data->refs, refcount);+  GRPC_CLOSURE_INIT(&batch_data->on_complete, on_complete, batch_data,+                    grpc_schedule_on_exec_ctx);+  batch_data->batch.on_complete = &batch_data->on_complete;+  return batch_data;+}++static void batch_data_unref(grpc_exec_ctx *exec_ctx,+                             subchannel_batch_data *batch_data) {+  if (gpr_unref(&batch_data->refs)) {+    if (batch_data->send_initial_metadata_storage != NULL) {+      grpc_metadata_batch_destroy(exec_ctx, &batch_data->send_initial_metadata);+    }+    if (batch_data->send_trailing_metadata_storage != NULL) {+      grpc_metadata_batch_destroy(exec_ctx,+                                  &batch_data->send_trailing_metadata);+    }+    if (batch_data->batch.recv_initial_metadata) {+      grpc_metadata_batch_destroy(exec_ctx, &batch_data->recv_initial_metadata);+    }+    if (batch_data->batch.recv_trailing_metadata) {+      grpc_metadata_batch_destroy(exec_ctx,+                                  &batch_data->recv_trailing_metadata);+    }+    GRPC_SUBCHANNEL_CALL_UNREF(exec_ctx, batch_data->subchannel_call,+                               ""batch_data_unref"");+  }+}++static void maybe_clear_pending_batch(grpc_call_element *elem,+                                      pending_batch *pending) {+  call_data *calld = (call_data *)elem->call_data;+  channel_data *chand = (channel_data *)elem->channel_data;+  grpc_transport_stream_op_batch *batch = pending->batch;+  if (batch->on_complete == NULL &&",Can you add a comment? 5 conditions are checked here and it's not clear to me which states would require a pending_batch_clear,
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/10684,149754987,2017-11-08T18:24:58Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -868,98 +1128,1238 @@ grpc_subchannel_call *grpc_client_channel_get_subchannel_call(   return calld->subchannel_call; } +static void start_retriable_subchannel_batches(grpc_exec_ctx *exec_ctx,+                                               void *arg, grpc_error *ignored);++static size_t get_batch_index(grpc_transport_stream_op_batch *batch) {+  // Note: It is important the send_initial_metadata be the first entry+  // here, since the code in pick_subchannel_locked() assumes it will be.+  if (batch->send_initial_metadata) return 0;+  if (batch->send_message) return 1;+  if (batch->send_trailing_metadata) return 2;+  if (batch->recv_initial_metadata) return 3;+  if (batch->recv_message) return 4;+  if (batch->recv_trailing_metadata) return 5;+  GPR_UNREACHABLE_CODE(return (size_t)-1);+}++// Cleans up retry state.  Called when the RPC is committed (i.e., we will+// not attempt any more retries).+static void retry_commit(grpc_exec_ctx *exec_ctx, grpc_call_element *elem,+                         subchannel_call_retry_state *retry_state) {+  call_data *calld = (call_data *)elem->call_data;+  channel_data *chand = (channel_data *)elem->channel_data;+  if (calld->retry_committed) return;+  calld->retry_committed = true;+  if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    gpr_log(GPR_DEBUG, ""chand=%p calld=%p: committing retries"", chand, calld);+  }+  if (retry_state == NULL) return;+  if (retry_state->completed_send_initial_metadata) {+    grpc_metadata_batch_destroy(exec_ctx, &calld->send_initial_metadata);+  }+  for (size_t i = 0; i < retry_state->completed_send_message_count; ++i) {+    grpc_byte_stream_cache_destroy(exec_ctx, calld->send_messages[i]);+  }+  if (retry_state->completed_send_trailing_metadata) {+    grpc_metadata_batch_destroy(exec_ctx, &calld->send_trailing_metadata);+  }+}+ // This is called via the call combiner, so access to calld is synchronized.-static void waiting_for_pick_batches_add(-    call_data *calld, grpc_transport_stream_op_batch *batch) {+static void pending_batches_add(grpc_exec_ctx *exec_ctx,+                                grpc_call_element *elem,+                                grpc_transport_stream_op_batch *batch) {+  call_data *calld = (call_data *)elem->call_data;+  channel_data *chand = (channel_data *)elem->channel_data;+  const size_t idx = get_batch_index(batch);+  if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    gpr_log(GPR_DEBUG,+            ""chand=%p calld=%p: adding pending batch at index %"" PRIuPTR, chand,+            calld, idx);+  }+  pending_batch *pending = &calld->pending_batches[idx];+  GPR_ASSERT(pending->batch == NULL);+  pending->batch = batch;+  pending->send_ops_cached = false;   if (batch->send_initial_metadata) {-    GPR_ASSERT(calld->initial_metadata_batch == NULL);-    calld->initial_metadata_batch = batch;-  } else {-    GPR_ASSERT(calld->waiting_for_pick_batches_count < MAX_WAITING_BATCHES);-    calld->waiting_for_pick_batches[calld->waiting_for_pick_batches_count++] =-        batch;+    calld->pending_send_initial_metadata = true;+  }+  if (batch->send_message) {+    calld->pending_send_message = true;+  }+  if (batch->send_trailing_metadata) {+    calld->pending_send_trailing_metadata = true;+  }+  // Check if the batch takes us over the retry buffer limit.+  // Note: We don't check trailing metadata here, because gRPC clients+  // do not send trailing metadata.+  if (batch->send_initial_metadata) {+    calld->bytes_buffered_for_retry += grpc_metadata_batch_size(+        batch->payload->send_initial_metadata.send_initial_metadata);+  }+  if (batch->send_message) {+    calld->bytes_buffered_for_retry +=+        batch->payload->send_message.send_message->length;+  }+  if (calld->bytes_buffered_for_retry > chand->per_rpc_retry_buffer_size) {+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      gpr_log(GPR_DEBUG,+              ""chand=%p calld=%p: exceeded retry buffer size, committing"",+              chand, calld);+    }+    subchannel_call_retry_state *retry_state =+        calld->subchannel_call == NULL+            ? NULL+            : (subchannel_call_retry_state *)+                  grpc_connected_subchannel_call_get_parent_data(+                      calld->subchannel_call);+    retry_commit(exec_ctx, elem, retry_state);+    // If we are not going to retry and have not yet started, pretend+    // retries are disabled so that we don't bother with retry overhead.+    if (calld->num_attempts_completed == 0) calld->enable_retries = false;   } } +static void pending_batch_clear(call_data *calld, pending_batch *pending) {+  if (pending->batch->send_initial_metadata) {+    calld->pending_send_initial_metadata = false;+  }+  if (pending->batch->send_message) {+    calld->pending_send_message = false;+  }+  if (pending->batch->send_trailing_metadata) {+    calld->pending_send_trailing_metadata = false;+  }+  pending->batch = NULL;+}+ // This is called via the call combiner, so access to calld is synchronized. static void fail_pending_batch_in_call_combiner(grpc_exec_ctx *exec_ctx,                                                 void *arg, grpc_error *error) {-  call_data *calld = (call_data *)arg;-  if (calld->waiting_for_pick_batches_count > 0) {-    --calld->waiting_for_pick_batches_count;-    grpc_transport_stream_op_batch_finish_with_failure(-        exec_ctx,-        calld->waiting_for_pick_batches[calld->waiting_for_pick_batches_count],-        GRPC_ERROR_REF(error), calld->call_combiner);-  }+  grpc_transport_stream_op_batch *batch = (grpc_transport_stream_op_batch *)arg;+  call_data *calld = (call_data *)batch->handler_private.extra_arg;+  grpc_transport_stream_op_batch_finish_with_failure(+      exec_ctx, batch, GRPC_ERROR_REF(error), calld->call_combiner); }  // This is called via the call combiner, so access to calld is synchronized.-static void waiting_for_pick_batches_fail(grpc_exec_ctx *exec_ctx,-                                          grpc_call_element *elem,-                                          grpc_error *error) {+// If yield_call_combiner is true, assumes responsibility for yielding+// the call combiner.+static void pending_batches_fail(grpc_exec_ctx *exec_ctx,+                                 grpc_call_element *elem, grpc_error *error,+                                 bool yield_call_combiner) {   call_data *calld = (call_data *)elem->call_data;   if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    size_t num_batches = 0;+    for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+      if (calld->pending_batches[i].batch != NULL) ++num_batches;+    }     gpr_log(GPR_DEBUG,             ""chand=%p calld=%p: failing %"" PRIuPTR "" pending batches: %s"",-            elem->channel_data, calld, calld->waiting_for_pick_batches_count,-            grpc_error_string(error));+            elem->channel_data, calld, num_batches, grpc_error_string(error));+  }+  grpc_transport_stream_op_batch+      *batches[GPR_ARRAY_SIZE(calld->pending_batches)];+  size_t num_batches = 0;+  for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+    pending_batch *pending = &calld->pending_batches[i];+    grpc_transport_stream_op_batch *batch = pending->batch;+    if (batch != NULL) {+      batches[num_batches++] = batch;+      pending_batch_clear(calld, pending);+    }   }-  for (size_t i = 0; i < calld->waiting_for_pick_batches_count; ++i) {-    GRPC_CLOSURE_INIT(&calld->handle_pending_batch_in_call_combiner[i],-                      fail_pending_batch_in_call_combiner, calld,+  for (size_t i = yield_call_combiner ? 1 : 0; i < num_batches; ++i) {+    grpc_transport_stream_op_batch *batch = batches[i];+    batch->handler_private.extra_arg = calld;+    GRPC_CLOSURE_INIT(&batch->handler_private.closure,+                      fail_pending_batch_in_call_combiner, batch,                       grpc_schedule_on_exec_ctx);     GRPC_CALL_COMBINER_START(exec_ctx, calld->call_combiner,-                             &calld->handle_pending_batch_in_call_combiner[i],-                             GRPC_ERROR_REF(error),-                             ""waiting_for_pick_batches_fail"");+                             &batch->handler_private.closure,+                             GRPC_ERROR_REF(error), ""pending_batches_fail"");   }-  if (calld->initial_metadata_batch != NULL) {-    grpc_transport_stream_op_batch_finish_with_failure(-        exec_ctx, calld->initial_metadata_batch, GRPC_ERROR_REF(error),-        calld->call_combiner);-  } else {-    GRPC_CALL_COMBINER_STOP(exec_ctx, calld->call_combiner,-                            ""waiting_for_pick_batches_fail"");+  if (yield_call_combiner) {+    if (num_batches > 0) {+      grpc_transport_stream_op_batch_finish_with_failure(+          exec_ctx, batches[0], GRPC_ERROR_REF(error), calld->call_combiner);+    } else {+      GRPC_CALL_COMBINER_STOP(exec_ctx, calld->call_combiner,+                              ""pending_batches_fail"");+    }   }   GRPC_ERROR_UNREF(error); }  // This is called via the call combiner, so access to calld is synchronized.-static void run_pending_batch_in_call_combiner(grpc_exec_ctx *exec_ctx,-                                               void *arg, grpc_error *ignored) {-  call_data *calld = (call_data *)arg;-  if (calld->waiting_for_pick_batches_count > 0) {-    --calld->waiting_for_pick_batches_count;-    grpc_subchannel_call_process_op(-        exec_ctx, calld->subchannel_call,-        calld->waiting_for_pick_batches[calld->waiting_for_pick_batches_count]);-  }+static void resume_pending_batch_in_call_combiner(grpc_exec_ctx *exec_ctx,+                                                  void *arg,+                                                  grpc_error *ignored) {+  grpc_transport_stream_op_batch *batch = (grpc_transport_stream_op_batch *)arg;+  grpc_subchannel_call *subchannel_call =+      (grpc_subchannel_call *)batch->handler_private.extra_arg;+  grpc_subchannel_call_process_op(exec_ctx, subchannel_call, batch); }  // This is called via the call combiner, so access to calld is synchronized.-static void waiting_for_pick_batches_resume(grpc_exec_ctx *exec_ctx,-                                            grpc_call_element *elem) {+static void pending_batches_resume(grpc_exec_ctx *exec_ctx,+                                   grpc_call_element *elem) {   channel_data *chand = (channel_data *)elem->channel_data;   call_data *calld = (call_data *)elem->call_data;+  if (calld->enable_retries) {+    start_retriable_subchannel_batches(exec_ctx, elem, GRPC_ERROR_NONE);+    return;+  }+  // Retries not enabled; send down batches as-is.   if (GRPC_TRACER_ON(grpc_client_channel_trace)) {-    gpr_log(GPR_DEBUG, ""chand=%p calld=%p: sending %"" PRIuPTR-                       "" pending batches to subchannel_call=%p"",-            chand, calld, calld->waiting_for_pick_batches_count,-            calld->subchannel_call);-  }-  for (size_t i = 0; i < calld->waiting_for_pick_batches_count; ++i) {-    GRPC_CLOSURE_INIT(&calld->handle_pending_batch_in_call_combiner[i],-                      run_pending_batch_in_call_combiner, calld,+    size_t num_batches = 0;+    for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+      if (calld->pending_batches[i].batch != NULL) ++num_batches;+    }+    gpr_log(GPR_DEBUG, ""chand=%p calld=%p: starting %"" PRIuPTR+                       "" pending batches on subchannel_call=%p"",+            chand, calld, num_batches, calld->subchannel_call);+  }+  grpc_transport_stream_op_batch+      *batches[GPR_ARRAY_SIZE(calld->pending_batches)];+  size_t num_batches = 0;+  for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+    pending_batch *pending = &calld->pending_batches[i];+    grpc_transport_stream_op_batch *batch = pending->batch;+    if (batch != NULL) {+      batches[num_batches++] = batch;+      pending_batch_clear(calld, pending);+    }+  }+  for (size_t i = 1; i < num_batches; ++i) {+    grpc_transport_stream_op_batch *batch = batches[i];+    batch->handler_private.extra_arg = calld->subchannel_call;+    GRPC_CLOSURE_INIT(&batch->handler_private.closure,+                      resume_pending_batch_in_call_combiner, batch,                       grpc_schedule_on_exec_ctx);     GRPC_CALL_COMBINER_START(exec_ctx, calld->call_combiner,-                             &calld->handle_pending_batch_in_call_combiner[i],-                             GRPC_ERROR_NONE,-                             ""waiting_for_pick_batches_resume"");+                             &batch->handler_private.closure, GRPC_ERROR_NONE,+                             ""pending_batches_resume"");+  }+  GPR_ASSERT(num_batches > 0);+  grpc_subchannel_call_process_op(exec_ctx, calld->subchannel_call, batches[0]);+}++static void on_complete(grpc_exec_ctx *exec_ctx, void *arg, grpc_error *error);++static subchannel_batch_data *batch_data_create(grpc_call_element *elem,+                                                int refcount) {+  call_data *calld = (call_data *)elem->call_data;+  subchannel_call_retry_state *retry_state = (subchannel_call_retry_state *)+      grpc_connected_subchannel_call_get_parent_data(calld->subchannel_call);+  subchannel_batch_data *batch_data = (subchannel_batch_data *)gpr_arena_alloc(+      calld->arena, sizeof(*batch_data));+  batch_data->elem = elem;+  batch_data->subchannel_call =+      GRPC_SUBCHANNEL_CALL_REF(calld->subchannel_call, ""batch_data_create"");+  batch_data->batch.payload = &retry_state->batch_payload;+  gpr_ref_init(&batch_data->refs, refcount);+  GRPC_CLOSURE_INIT(&batch_data->on_complete, on_complete, batch_data,+                    grpc_schedule_on_exec_ctx);+  batch_data->batch.on_complete = &batch_data->on_complete;+  return batch_data;+}++static void batch_data_unref(grpc_exec_ctx *exec_ctx,+                             subchannel_batch_data *batch_data) {+  if (gpr_unref(&batch_data->refs)) {+    if (batch_data->send_initial_metadata_storage != NULL) {+      grpc_metadata_batch_destroy(exec_ctx, &batch_data->send_initial_metadata);+    }+    if (batch_data->send_trailing_metadata_storage != NULL) {+      grpc_metadata_batch_destroy(exec_ctx,+                                  &batch_data->send_trailing_metadata);+    }+    if (batch_data->batch.recv_initial_metadata) {+      grpc_metadata_batch_destroy(exec_ctx, &batch_data->recv_initial_metadata);+    }+    if (batch_data->batch.recv_trailing_metadata) {+      grpc_metadata_batch_destroy(exec_ctx,+                                  &batch_data->recv_trailing_metadata);+    }+    GRPC_SUBCHANNEL_CALL_UNREF(exec_ctx, batch_data->subchannel_call,+                               ""batch_data_unref"");+  }+}++static void maybe_clear_pending_batch(grpc_call_element *elem,+                                      pending_batch *pending) {+  call_data *calld = (call_data *)elem->call_data;+  channel_data *chand = (channel_data *)elem->channel_data;+  grpc_transport_stream_op_batch *batch = pending->batch;+  if (batch->on_complete == NULL &&+      (!batch->recv_initial_metadata ||+       batch->payload->recv_initial_metadata.recv_initial_metadata_ready ==+           NULL) &&+      (!batch->recv_message ||+       batch->payload->recv_message.recv_message_ready == NULL)) {+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      gpr_log(GPR_DEBUG, ""chand=%p calld=%p: clearing pending batch"", chand,+              calld);+    }+    pending_batch_clear(calld, pending);+  }+}++// Caches data for send ops so that it can be retried later, if not+// already cached.+static void maybe_cache_send_ops_for_batch(grpc_exec_ctx *exec_ctx,+                                           call_data *calld,+                                           pending_batch *pending) {+  if (pending->send_ops_cached) return;+  pending->send_ops_cached = true;+  grpc_transport_stream_op_batch *batch = pending->batch;+  // Save a copy of metadata for send_initial_metadata ops.+  if (batch->send_initial_metadata) {+    calld->seen_send_initial_metadata = true;+    GPR_ASSERT(calld->send_initial_metadata_storage == NULL);+    grpc_metadata_batch *send_initial_metadata =+        batch->payload->send_initial_metadata.send_initial_metadata;+    calld->send_initial_metadata_storage =+        (grpc_linked_mdelem *)gpr_arena_alloc(+            calld->arena,+            sizeof(grpc_linked_mdelem) * send_initial_metadata->list.count);+    grpc_metadata_batch_copy(exec_ctx, send_initial_metadata,+                             &calld->send_initial_metadata,+                             calld->send_initial_metadata_storage);+    calld->send_initial_metadata_flags =+        batch->payload->send_initial_metadata.send_initial_metadata_flags;+    calld->peer_string = batch->payload->send_initial_metadata.peer_string;+  }+  // Set up cache for send_message ops.+  if (batch->send_message) {+    grpc_byte_stream_cache *cache = (grpc_byte_stream_cache *)gpr_arena_alloc(+        calld->arena, sizeof(grpc_byte_stream_cache));+    grpc_byte_stream_cache_init(cache,+                                batch->payload->send_message.send_message);+    calld->send_messages.push_back(cache);+  }+  // Save metadata batch for send_trailing_metadata ops.+  if (batch->send_trailing_metadata) {",Why is this needed if clients don't sent trailing metadata?,
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/10684,149758721,2017-11-08T18:38:31Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -868,98 +1128,1238 @@ grpc_subchannel_call *grpc_client_channel_get_subchannel_call(   return calld->subchannel_call; } +static void start_retriable_subchannel_batches(grpc_exec_ctx *exec_ctx,+                                               void *arg, grpc_error *ignored);++static size_t get_batch_index(grpc_transport_stream_op_batch *batch) {+  // Note: It is important the send_initial_metadata be the first entry+  // here, since the code in pick_subchannel_locked() assumes it will be.+  if (batch->send_initial_metadata) return 0;+  if (batch->send_message) return 1;+  if (batch->send_trailing_metadata) return 2;+  if (batch->recv_initial_metadata) return 3;+  if (batch->recv_message) return 4;+  if (batch->recv_trailing_metadata) return 5;+  GPR_UNREACHABLE_CODE(return (size_t)-1);+}++// Cleans up retry state.  Called when the RPC is committed (i.e., we will+// not attempt any more retries).+static void retry_commit(grpc_exec_ctx *exec_ctx, grpc_call_element *elem,+                         subchannel_call_retry_state *retry_state) {+  call_data *calld = (call_data *)elem->call_data;+  channel_data *chand = (channel_data *)elem->channel_data;+  if (calld->retry_committed) return;+  calld->retry_committed = true;+  if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    gpr_log(GPR_DEBUG, ""chand=%p calld=%p: committing retries"", chand, calld);+  }+  if (retry_state == NULL) return;+  if (retry_state->completed_send_initial_metadata) {+    grpc_metadata_batch_destroy(exec_ctx, &calld->send_initial_metadata);+  }+  for (size_t i = 0; i < retry_state->completed_send_message_count; ++i) {+    grpc_byte_stream_cache_destroy(exec_ctx, calld->send_messages[i]);+  }+  if (retry_state->completed_send_trailing_metadata) {+    grpc_metadata_batch_destroy(exec_ctx, &calld->send_trailing_metadata);+  }+}+ // This is called via the call combiner, so access to calld is synchronized.-static void waiting_for_pick_batches_add(-    call_data *calld, grpc_transport_stream_op_batch *batch) {+static void pending_batches_add(grpc_exec_ctx *exec_ctx,+                                grpc_call_element *elem,+                                grpc_transport_stream_op_batch *batch) {+  call_data *calld = (call_data *)elem->call_data;+  channel_data *chand = (channel_data *)elem->channel_data;+  const size_t idx = get_batch_index(batch);+  if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    gpr_log(GPR_DEBUG,+            ""chand=%p calld=%p: adding pending batch at index %"" PRIuPTR, chand,+            calld, idx);+  }+  pending_batch *pending = &calld->pending_batches[idx];+  GPR_ASSERT(pending->batch == NULL);+  pending->batch = batch;+  pending->send_ops_cached = false;   if (batch->send_initial_metadata) {-    GPR_ASSERT(calld->initial_metadata_batch == NULL);-    calld->initial_metadata_batch = batch;-  } else {-    GPR_ASSERT(calld->waiting_for_pick_batches_count < MAX_WAITING_BATCHES);-    calld->waiting_for_pick_batches[calld->waiting_for_pick_batches_count++] =-        batch;+    calld->pending_send_initial_metadata = true;+  }+  if (batch->send_message) {+    calld->pending_send_message = true;+  }+  if (batch->send_trailing_metadata) {+    calld->pending_send_trailing_metadata = true;+  }+  // Check if the batch takes us over the retry buffer limit.+  // Note: We don't check trailing metadata here, because gRPC clients+  // do not send trailing metadata.+  if (batch->send_initial_metadata) {+    calld->bytes_buffered_for_retry += grpc_metadata_batch_size(+        batch->payload->send_initial_metadata.send_initial_metadata);+  }+  if (batch->send_message) {+    calld->bytes_buffered_for_retry +=+        batch->payload->send_message.send_message->length;+  }+  if (calld->bytes_buffered_for_retry > chand->per_rpc_retry_buffer_size) {+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      gpr_log(GPR_DEBUG,+              ""chand=%p calld=%p: exceeded retry buffer size, committing"",+              chand, calld);+    }+    subchannel_call_retry_state *retry_state =+        calld->subchannel_call == NULL+            ? NULL+            : (subchannel_call_retry_state *)+                  grpc_connected_subchannel_call_get_parent_data(+                      calld->subchannel_call);+    retry_commit(exec_ctx, elem, retry_state);+    // If we are not going to retry and have not yet started, pretend+    // retries are disabled so that we don't bother with retry overhead.+    if (calld->num_attempts_completed == 0) calld->enable_retries = false;   } } +static void pending_batch_clear(call_data *calld, pending_batch *pending) {+  if (pending->batch->send_initial_metadata) {+    calld->pending_send_initial_metadata = false;+  }+  if (pending->batch->send_message) {+    calld->pending_send_message = false;+  }+  if (pending->batch->send_trailing_metadata) {+    calld->pending_send_trailing_metadata = false;+  }+  pending->batch = NULL;+}+ // This is called via the call combiner, so access to calld is synchronized. static void fail_pending_batch_in_call_combiner(grpc_exec_ctx *exec_ctx,                                                 void *arg, grpc_error *error) {-  call_data *calld = (call_data *)arg;-  if (calld->waiting_for_pick_batches_count > 0) {-    --calld->waiting_for_pick_batches_count;-    grpc_transport_stream_op_batch_finish_with_failure(-        exec_ctx,-        calld->waiting_for_pick_batches[calld->waiting_for_pick_batches_count],-        GRPC_ERROR_REF(error), calld->call_combiner);-  }+  grpc_transport_stream_op_batch *batch = (grpc_transport_stream_op_batch *)arg;+  call_data *calld = (call_data *)batch->handler_private.extra_arg;+  grpc_transport_stream_op_batch_finish_with_failure(+      exec_ctx, batch, GRPC_ERROR_REF(error), calld->call_combiner); }  // This is called via the call combiner, so access to calld is synchronized.-static void waiting_for_pick_batches_fail(grpc_exec_ctx *exec_ctx,-                                          grpc_call_element *elem,-                                          grpc_error *error) {+// If yield_call_combiner is true, assumes responsibility for yielding+// the call combiner.+static void pending_batches_fail(grpc_exec_ctx *exec_ctx,+                                 grpc_call_element *elem, grpc_error *error,+                                 bool yield_call_combiner) {   call_data *calld = (call_data *)elem->call_data;   if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    size_t num_batches = 0;+    for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+      if (calld->pending_batches[i].batch != NULL) ++num_batches;+    }     gpr_log(GPR_DEBUG,             ""chand=%p calld=%p: failing %"" PRIuPTR "" pending batches: %s"",-            elem->channel_data, calld, calld->waiting_for_pick_batches_count,-            grpc_error_string(error));+            elem->channel_data, calld, num_batches, grpc_error_string(error));+  }+  grpc_transport_stream_op_batch+      *batches[GPR_ARRAY_SIZE(calld->pending_batches)];+  size_t num_batches = 0;+  for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+    pending_batch *pending = &calld->pending_batches[i];+    grpc_transport_stream_op_batch *batch = pending->batch;+    if (batch != NULL) {+      batches[num_batches++] = batch;+      pending_batch_clear(calld, pending);+    }   }-  for (size_t i = 0; i < calld->waiting_for_pick_batches_count; ++i) {-    GRPC_CLOSURE_INIT(&calld->handle_pending_batch_in_call_combiner[i],-                      fail_pending_batch_in_call_combiner, calld,+  for (size_t i = yield_call_combiner ? 1 : 0; i < num_batches; ++i) {+    grpc_transport_stream_op_batch *batch = batches[i];+    batch->handler_private.extra_arg = calld;+    GRPC_CLOSURE_INIT(&batch->handler_private.closure,+                      fail_pending_batch_in_call_combiner, batch,                       grpc_schedule_on_exec_ctx);     GRPC_CALL_COMBINER_START(exec_ctx, calld->call_combiner,-                             &calld->handle_pending_batch_in_call_combiner[i],-                             GRPC_ERROR_REF(error),-                             ""waiting_for_pick_batches_fail"");+                             &batch->handler_private.closure,+                             GRPC_ERROR_REF(error), ""pending_batches_fail"");   }-  if (calld->initial_metadata_batch != NULL) {-    grpc_transport_stream_op_batch_finish_with_failure(-        exec_ctx, calld->initial_metadata_batch, GRPC_ERROR_REF(error),-        calld->call_combiner);-  } else {-    GRPC_CALL_COMBINER_STOP(exec_ctx, calld->call_combiner,-                            ""waiting_for_pick_batches_fail"");+  if (yield_call_combiner) {+    if (num_batches > 0) {+      grpc_transport_stream_op_batch_finish_with_failure(+          exec_ctx, batches[0], GRPC_ERROR_REF(error), calld->call_combiner);+    } else {+      GRPC_CALL_COMBINER_STOP(exec_ctx, calld->call_combiner,+                              ""pending_batches_fail"");+    }   }   GRPC_ERROR_UNREF(error); }  // This is called via the call combiner, so access to calld is synchronized.-static void run_pending_batch_in_call_combiner(grpc_exec_ctx *exec_ctx,-                                               void *arg, grpc_error *ignored) {-  call_data *calld = (call_data *)arg;-  if (calld->waiting_for_pick_batches_count > 0) {-    --calld->waiting_for_pick_batches_count;-    grpc_subchannel_call_process_op(-        exec_ctx, calld->subchannel_call,-        calld->waiting_for_pick_batches[calld->waiting_for_pick_batches_count]);-  }+static void resume_pending_batch_in_call_combiner(grpc_exec_ctx *exec_ctx,+                                                  void *arg,+                                                  grpc_error *ignored) {+  grpc_transport_stream_op_batch *batch = (grpc_transport_stream_op_batch *)arg;+  grpc_subchannel_call *subchannel_call =+      (grpc_subchannel_call *)batch->handler_private.extra_arg;+  grpc_subchannel_call_process_op(exec_ctx, subchannel_call, batch); }  // This is called via the call combiner, so access to calld is synchronized.-static void waiting_for_pick_batches_resume(grpc_exec_ctx *exec_ctx,-                                            grpc_call_element *elem) {+static void pending_batches_resume(grpc_exec_ctx *exec_ctx,+                                   grpc_call_element *elem) {   channel_data *chand = (channel_data *)elem->channel_data;   call_data *calld = (call_data *)elem->call_data;+  if (calld->enable_retries) {+    start_retriable_subchannel_batches(exec_ctx, elem, GRPC_ERROR_NONE);+    return;+  }+  // Retries not enabled; send down batches as-is.   if (GRPC_TRACER_ON(grpc_client_channel_trace)) {-    gpr_log(GPR_DEBUG, ""chand=%p calld=%p: sending %"" PRIuPTR-                       "" pending batches to subchannel_call=%p"",-            chand, calld, calld->waiting_for_pick_batches_count,-            calld->subchannel_call);-  }-  for (size_t i = 0; i < calld->waiting_for_pick_batches_count; ++i) {-    GRPC_CLOSURE_INIT(&calld->handle_pending_batch_in_call_combiner[i],-                      run_pending_batch_in_call_combiner, calld,+    size_t num_batches = 0;+    for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+      if (calld->pending_batches[i].batch != NULL) ++num_batches;+    }+    gpr_log(GPR_DEBUG, ""chand=%p calld=%p: starting %"" PRIuPTR+                       "" pending batches on subchannel_call=%p"",+            chand, calld, num_batches, calld->subchannel_call);+  }+  grpc_transport_stream_op_batch+      *batches[GPR_ARRAY_SIZE(calld->pending_batches)];+  size_t num_batches = 0;+  for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+    pending_batch *pending = &calld->pending_batches[i];+    grpc_transport_stream_op_batch *batch = pending->batch;+    if (batch != NULL) {+      batches[num_batches++] = batch;+      pending_batch_clear(calld, pending);+    }+  }+  for (size_t i = 1; i < num_batches; ++i) {+    grpc_transport_stream_op_batch *batch = batches[i];+    batch->handler_private.extra_arg = calld->subchannel_call;+    GRPC_CLOSURE_INIT(&batch->handler_private.closure,+                      resume_pending_batch_in_call_combiner, batch,                       grpc_schedule_on_exec_ctx);     GRPC_CALL_COMBINER_START(exec_ctx, calld->call_combiner,-                             &calld->handle_pending_batch_in_call_combiner[i],-                             GRPC_ERROR_NONE,-                             ""waiting_for_pick_batches_resume"");+                             &batch->handler_private.closure, GRPC_ERROR_NONE,+                             ""pending_batches_resume"");+  }+  GPR_ASSERT(num_batches > 0);+  grpc_subchannel_call_process_op(exec_ctx, calld->subchannel_call, batches[0]);+}++static void on_complete(grpc_exec_ctx *exec_ctx, void *arg, grpc_error *error);++static subchannel_batch_data *batch_data_create(grpc_call_element *elem,+                                                int refcount) {+  call_data *calld = (call_data *)elem->call_data;+  subchannel_call_retry_state *retry_state = (subchannel_call_retry_state *)+      grpc_connected_subchannel_call_get_parent_data(calld->subchannel_call);+  subchannel_batch_data *batch_data = (subchannel_batch_data *)gpr_arena_alloc(+      calld->arena, sizeof(*batch_data));+  batch_data->elem = elem;+  batch_data->subchannel_call =+      GRPC_SUBCHANNEL_CALL_REF(calld->subchannel_call, ""batch_data_create"");+  batch_data->batch.payload = &retry_state->batch_payload;+  gpr_ref_init(&batch_data->refs, refcount);+  GRPC_CLOSURE_INIT(&batch_data->on_complete, on_complete, batch_data,+                    grpc_schedule_on_exec_ctx);+  batch_data->batch.on_complete = &batch_data->on_complete;+  return batch_data;+}++static void batch_data_unref(grpc_exec_ctx *exec_ctx,+                             subchannel_batch_data *batch_data) {+  if (gpr_unref(&batch_data->refs)) {+    if (batch_data->send_initial_metadata_storage != NULL) {+      grpc_metadata_batch_destroy(exec_ctx, &batch_data->send_initial_metadata);+    }+    if (batch_data->send_trailing_metadata_storage != NULL) {+      grpc_metadata_batch_destroy(exec_ctx,+                                  &batch_data->send_trailing_metadata);+    }+    if (batch_data->batch.recv_initial_metadata) {+      grpc_metadata_batch_destroy(exec_ctx, &batch_data->recv_initial_metadata);+    }+    if (batch_data->batch.recv_trailing_metadata) {+      grpc_metadata_batch_destroy(exec_ctx,+                                  &batch_data->recv_trailing_metadata);+    }+    GRPC_SUBCHANNEL_CALL_UNREF(exec_ctx, batch_data->subchannel_call,+                               ""batch_data_unref"");+  }+}++static void maybe_clear_pending_batch(grpc_call_element *elem,+                                      pending_batch *pending) {+  call_data *calld = (call_data *)elem->call_data;+  channel_data *chand = (channel_data *)elem->channel_data;+  grpc_transport_stream_op_batch *batch = pending->batch;+  if (batch->on_complete == NULL &&+      (!batch->recv_initial_metadata ||+       batch->payload->recv_initial_metadata.recv_initial_metadata_ready ==+           NULL) &&+      (!batch->recv_message ||+       batch->payload->recv_message.recv_message_ready == NULL)) {+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      gpr_log(GPR_DEBUG, ""chand=%p calld=%p: clearing pending batch"", chand,+              calld);+    }+    pending_batch_clear(calld, pending);+  }+}++// Caches data for send ops so that it can be retried later, if not+// already cached.+static void maybe_cache_send_ops_for_batch(grpc_exec_ctx *exec_ctx,+                                           call_data *calld,+                                           pending_batch *pending) {+  if (pending->send_ops_cached) return;+  pending->send_ops_cached = true;+  grpc_transport_stream_op_batch *batch = pending->batch;+  // Save a copy of metadata for send_initial_metadata ops.+  if (batch->send_initial_metadata) {+    calld->seen_send_initial_metadata = true;+    GPR_ASSERT(calld->send_initial_metadata_storage == NULL);+    grpc_metadata_batch *send_initial_metadata =+        batch->payload->send_initial_metadata.send_initial_metadata;+    calld->send_initial_metadata_storage =+        (grpc_linked_mdelem *)gpr_arena_alloc(+            calld->arena,+            sizeof(grpc_linked_mdelem) * send_initial_metadata->list.count);+    grpc_metadata_batch_copy(exec_ctx, send_initial_metadata,+                             &calld->send_initial_metadata,+                             calld->send_initial_metadata_storage);+    calld->send_initial_metadata_flags =+        batch->payload->send_initial_metadata.send_initial_metadata_flags;+    calld->peer_string = batch->payload->send_initial_metadata.peer_string;+  }+  // Set up cache for send_message ops.+  if (batch->send_message) {+    grpc_byte_stream_cache *cache = (grpc_byte_stream_cache *)gpr_arena_alloc(+        calld->arena, sizeof(grpc_byte_stream_cache));+    grpc_byte_stream_cache_init(cache,+                                batch->payload->send_message.send_message);+    calld->send_messages.push_back(cache);+  }+  // Save metadata batch for send_trailing_metadata ops.+  if (batch->send_trailing_metadata) {+    calld->seen_send_trailing_metadata = true;+    GPR_ASSERT(calld->send_trailing_metadata_storage == NULL);+    grpc_metadata_batch *send_trailing_metadata =+        batch->payload->send_trailing_metadata.send_trailing_metadata;+    calld->send_trailing_metadata_storage =+        (grpc_linked_mdelem *)gpr_arena_alloc(+            calld->arena,+            sizeof(grpc_linked_mdelem) * send_trailing_metadata->list.count);+    grpc_metadata_batch_copy(exec_ctx, send_trailing_metadata,+                             &calld->send_trailing_metadata,+                             calld->send_trailing_metadata_storage);+  }+}++static bool is_status_code_in_list(grpc_status_code status,+                                   grpc_status_code *list, size_t list_size) {+  if (list == NULL) return true;+  for (size_t i = 0; i < list_size; ++i) {+    if (status == list[i]) return true;+  }+  return false;+}++static void start_pick_locked(grpc_exec_ctx *exec_ctx, void *arg,+                              grpc_error *ignored);++// Returns true if the call is being retried.+static bool maybe_retry(grpc_exec_ctx *exec_ctx, grpc_call_element *elem,+                        subchannel_batch_data *batch_data,+                        grpc_status_code status,+                        grpc_mdelem *server_pushback_md) {+  channel_data *chand = (channel_data *)elem->channel_data;+  call_data *calld = (call_data *)elem->call_data;+  // Get retry policy.+  if (calld->method_params == NULL) return false;+  retry_policy_params *retry_policy = calld->method_params->retry_policy;+  if (retry_policy == NULL) return false;+  // If we've already dispatched a retry from this call, return true.+  // This catches the case where the batch has multiple callbacks+  // (i.e., it includes either recv_message or recv_initial_metadata).+  subchannel_call_retry_state *retry_state = NULL;+  if (batch_data != NULL) {+    retry_state = (subchannel_call_retry_state *)+        grpc_connected_subchannel_call_get_parent_data(+            batch_data->subchannel_call);+    if (retry_state->retry_dispatched) {+      if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+        gpr_log(GPR_DEBUG, ""chand=%p calld=%p: retry already dispatched"", chand,+                calld);+      }+      return true;+    }+  }+  // Check status.+  if (status == GRPC_STATUS_OK) {+    grpc_server_retry_throttle_data_record_success(calld->retry_throttle_data);+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      gpr_log(GPR_DEBUG, ""chand=%p calld=%p: call succeeded"", chand, calld);+    }+    return false;+  }+  // Status is not OK.  Check whether the status is retryable.+  if (!is_status_code_in_list(status, retry_policy->retryable_status_codes,+                              retry_policy->num_retryable_status_codes)) {+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      gpr_log(GPR_DEBUG,+              ""chand=%p calld=%p: status %s not configured as retryable"", chand,+              calld, grpc_status_string(status));+    }+    return false;+  }+  // Record the failure and check whether retries are throttled.+  // Note that it's important for this check to come after the status+  // code check above, since we should only record failures whose statuses+  // match the configured retryable status codes, so that we don't count+  // things like failures due to malformed requests (INVALID_ARGUMENT).+  // Conversely, it's important for this to come before the remaining+  // checks, so that we don't fail to record failures due to other factors.+  if (!grpc_server_retry_throttle_data_record_failure(+          calld->retry_throttle_data)) {+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      gpr_log(GPR_DEBUG, ""chand=%p calld=%p: retries throttled"", chand, calld);+    }+    return false;+  }+  // Check whether the call is committed.+  if (calld->retry_committed) {+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      gpr_log(GPR_DEBUG, ""chand=%p calld=%p: retries committed"", chand, calld);+    }+    return false;+  }+  // Check whether we have retries remaining.+  ++calld->num_attempts_completed;+  if (calld->num_attempts_completed == retry_policy->max_attempts) {+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      gpr_log(GPR_DEBUG, ""chand=%p calld=%p: exceeded %d retry attempts"", chand,+              calld, retry_policy->max_attempts);+    }+    return false;+  }+  // If the call was cancelled from the surface, don't retry.+  if (calld->error != GRPC_ERROR_NONE) {+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      gpr_log(GPR_DEBUG,+              ""chand=%p calld=%p: call cancelled from surface, not retrying"",+              chand, calld);+    }+    return false;+  }+  // Check server push-back.+  grpc_millis server_pushback_ms = -1;+  if (server_pushback_md != NULL) {+    // If the value is ""-1"" or any other unparseable string, we do not retry.+    uint32_t ms;+    if (!grpc_parse_slice_to_uint32(GRPC_MDVALUE(*server_pushback_md), &ms)) {+      if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+        gpr_log(GPR_DEBUG,+                ""chand=%p calld=%p: not retrying due to server push-back"",+                chand, calld);+      }+      return false;+    } else {+      if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+        gpr_log(GPR_DEBUG,+                ""chand=%p calld=%p: server push-back: retry in %u ms"", chand,+                calld, ms);+      }+      server_pushback_ms = (grpc_millis)ms;+    }+  }+  // Reset subchannel call.+  if (calld->subchannel_call != NULL) {+    GRPC_SUBCHANNEL_CALL_UNREF(exec_ctx, calld->subchannel_call,+                               ""client_channel_call_retry"");+    calld->subchannel_call = NULL;+  }+  // Compute backoff delay.+  grpc_millis next_attempt_time;+  if (server_pushback_ms >= 0) {+    next_attempt_time = grpc_exec_ctx_now(exec_ctx) + server_pushback_ms;+    calld->last_attempt_got_server_pushback = true;+  } else if (calld->num_attempts_completed == 1 ||+             calld->last_attempt_got_server_pushback) {+    grpc_backoff_init(+        &calld->retry_backoff, retry_policy->initial_backoff,+        retry_policy->backoff_multiplier, RETRY_BACKOFF_JITTER,+        GPR_MIN(retry_policy->initial_backoff, retry_policy->max_backoff),+        retry_policy->max_backoff);+    next_attempt_time = grpc_backoff_begin(exec_ctx, &calld->retry_backoff)+        .next_attempt_start_time;+    calld->last_attempt_got_server_pushback = false;+  } else {+    next_attempt_time = grpc_backoff_step(exec_ctx, &calld->retry_backoff)+        .next_attempt_start_time;+  }+  if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    gpr_log(GPR_DEBUG,+            ""chand=%p calld=%p: retrying failed call in %"" PRIuPTR "" ms"", chand,+            calld, next_attempt_time - grpc_exec_ctx_now(exec_ctx));+  }+  // Schedule retry after computed delay.+  GRPC_CLOSURE_INIT(&calld->pick_closure, start_pick_locked, elem,+                    grpc_combiner_scheduler(chand->combiner));+  grpc_timer_init(exec_ctx, &calld->retry_timer, next_attempt_time,+                  &calld->pick_closure);+  // Update bookkeeping.+  if (retry_state != NULL) retry_state->retry_dispatched = true;+  return true;+}++static void start_internal_recv_trailing_metadata(grpc_exec_ctx *exec_ctx,+                                                  grpc_call_element *elem);++static void invoke_recv_initial_metadata_callback(grpc_exec_ctx *exec_ctx,+                                                  void *arg,+                                                  grpc_error *error) {+  subchannel_batch_data *batch_data = (subchannel_batch_data *)arg;+  call_data *calld = (call_data *)batch_data->elem->call_data;+  channel_data *chand = (channel_data *)batch_data->elem->channel_data;+  // Find pending batch.+  pending_batch *pending = NULL;+  for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+    grpc_transport_stream_op_batch *batch = calld->pending_batches[i].batch;+    if (batch != NULL && batch->recv_initial_metadata &&+        batch->payload->recv_initial_metadata.recv_initial_metadata_ready !=+            NULL) {+      if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+        gpr_log(GPR_DEBUG,+                ""chand=%p calld=%p: invoking recv_initial_metadata_ready for ""+                ""pending batch at index %"" PRIuPTR,+                chand, calld, i);+      }+      pending = &calld->pending_batches[i];+      break;+    }+  }+  GPR_ASSERT(pending != NULL);+  // Return metadata.+  grpc_metadata_batch_move(+      &batch_data->recv_initial_metadata,+      pending->batch->payload->recv_initial_metadata.recv_initial_metadata);+  // Update bookkeeping.+  // Note: Need to do this before invoking the callback, since invoking+  // the callback will result in yielding the call combiner.+  grpc_closure *recv_initial_metadata_ready =+      pending->batch->payload->recv_initial_metadata+          .recv_initial_metadata_ready;+  pending->batch->payload->recv_initial_metadata.recv_initial_metadata_ready =+      NULL;+  maybe_clear_pending_batch(batch_data->elem, pending);+  batch_data_unref(exec_ctx, batch_data);+  // Invoke callback.+  GRPC_CLOSURE_RUN(exec_ctx, recv_initial_metadata_ready,+                   GRPC_ERROR_REF(error));+}++// Intercepts recv_initial_metadata_ready callback for retries.+// Commits the call and returns the initial metadata up the stack.+static void recv_initial_metadata_ready(grpc_exec_ctx *exec_ctx, void *arg,+                                        grpc_error *error) {+  subchannel_batch_data *batch_data = (subchannel_batch_data *)arg;+  grpc_call_element *elem = batch_data->elem;+  channel_data *chand = (channel_data *)elem->channel_data;+  call_data *calld = (call_data *)elem->call_data;+  if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    gpr_log(GPR_DEBUG,+            ""chand=%p calld=%p: got recv_initial_metadata_ready, error=%s"",+            chand, calld, grpc_error_string(error));+  }+  subchannel_call_retry_state *retry_state = (subchannel_call_retry_state *)+      grpc_connected_subchannel_call_get_parent_data(+          batch_data->subchannel_call);+  // If we got an error or a Trailers-Only response and have not yet gotten+  // the recv_trailing_metadata on_complete callback, then defer+  // propagating this callback back to the surface.  We can evaluate whether+  // to retry when recv_trailing_metadata comes back.+  if ((batch_data->trailing_metadata_available || error != GRPC_ERROR_NONE) &&+      !retry_state->completed_recv_trailing_metadata) {+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      gpr_log(GPR_DEBUG,+              ""chand=%p calld=%p: deferring recv_initial_metadata_ready ""+              ""(Trailers-Only)"",+              chand, calld);+    }+    retry_state->recv_initial_metadata_ready_deferred = true;+    retry_state->recv_initial_metadata_error = GRPC_ERROR_REF(error);+    if (!retry_state->started_recv_trailing_metadata) {+      // recv_trailing_metadata not yet started by application; start it+      // ourselves to get status.+      start_internal_recv_trailing_metadata(exec_ctx, elem);+    } else {+      GRPC_CALL_COMBINER_STOP(+          exec_ctx, calld->call_combiner,+          ""recv_initial_metadata_ready trailers-only or error"");+    }+    return;+  }+  // Received valid initial metadata, so commit the call.+  retry_commit(exec_ctx, elem, retry_state);+  // Manually invoking a callback function; it does not take ownership of error.+  invoke_recv_initial_metadata_callback(exec_ctx, batch_data, error);+  GRPC_ERROR_UNREF(error);+}++static void invoke_recv_message_callback(grpc_exec_ctx *exec_ctx, void *arg,+                                         grpc_error *error) {+  subchannel_batch_data *batch_data = (subchannel_batch_data *)arg;+  call_data *calld = (call_data *)batch_data->elem->call_data;+  channel_data *chand = (channel_data *)batch_data->elem->channel_data;+  // Find pending op.+  pending_batch *pending = NULL;+  for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+    grpc_transport_stream_op_batch *batch = calld->pending_batches[i].batch;+    if (batch != NULL && batch->recv_message &&+        batch->payload->recv_message.recv_message_ready != NULL) {+      if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+        gpr_log(GPR_DEBUG,+                ""chand=%p calld=%p: invoking recv_message_ready for ""+                ""pending batch at index %"" PRIuPTR,+                chand, calld, i);+      }+      pending = &calld->pending_batches[i];+      break;+    }+  }+  GPR_ASSERT(pending != NULL);+  // Return payload.+  *pending->batch->payload->recv_message.recv_message =+      batch_data->recv_message;+  // Update bookkeeping.+  // Note: Need to do this before invoking the callback, since invoking+  // the callback will result in yielding the call combiner.+  grpc_closure *recv_message_ready =+      pending->batch->payload->recv_message.recv_message_ready;+  pending->batch->payload->recv_message.recv_message_ready = NULL;+  maybe_clear_pending_batch(batch_data->elem, pending);+  batch_data_unref(exec_ctx, batch_data);+  // Invoke callback.+  GRPC_CLOSURE_RUN(exec_ctx, recv_message_ready, GRPC_ERROR_REF(error));+}++// Intercepts recv_message_ready callback for retries.+// Commits the call and returns the message up the stack.+static void recv_message_ready(grpc_exec_ctx *exec_ctx, void *arg,+                               grpc_error *error) {+  subchannel_batch_data *batch_data = (subchannel_batch_data *)arg;+  grpc_call_element *elem = batch_data->elem;+  channel_data *chand = (channel_data *)elem->channel_data;+  call_data *calld = (call_data *)elem->call_data;+  if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    gpr_log(GPR_DEBUG, ""chand=%p calld=%p: got recv_message_ready, error=%s"",+            chand, calld, grpc_error_string(error));+  }+  subchannel_call_retry_state *retry_state = (subchannel_call_retry_state *)+      grpc_connected_subchannel_call_get_parent_data(+          batch_data->subchannel_call);+  // If we got an error or the payload was NULL and we have not yet gotten+  // the recv_trailing_metadata on_complete callback, then defer+  // propagating this callback back to the surface.  We can evaluate whether+  // to retry when recv_trailing_metadata comes back.+  if ((batch_data->recv_message == NULL || error != GRPC_ERROR_NONE) &&+      !retry_state->completed_recv_trailing_metadata) {+    if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+      gpr_log(GPR_DEBUG,+              ""chand=%p calld=%p: deferring recv_message_ready (NULL ""+              ""message and recv_trailing_metadata pending)"",+              chand, calld);+    }+    retry_state->recv_message_ready_deferred = true;+    retry_state->recv_message_error = GRPC_ERROR_REF(error);+    if (!retry_state->started_recv_trailing_metadata) {+      // recv_trailing_metadata not yet started by application; start it+      // ourselves to get status.+      start_internal_recv_trailing_metadata(exec_ctx, elem);+    } else {+      GRPC_CALL_COMBINER_STOP(exec_ctx, calld->call_combiner,+                              ""recv_message_ready null"");+    }+    return;+  }+  // Received a valid message, so commit the call.+  retry_commit(exec_ctx, elem, retry_state);+  // Manually invoking a callback function; it does not take ownership of error.+  invoke_recv_message_callback(exec_ctx, batch_data, error);+  GRPC_ERROR_UNREF(error);+}++// Returns true if all pending ops in the pending batch have been completed.+static bool pending_batch_is_completed(+    pending_batch *pending, call_data *calld,+    subchannel_call_retry_state *retry_state) {+  if (pending->batch == NULL || pending->batch->on_complete == NULL) {+    return false;+  }+  if (pending->batch->send_initial_metadata &&+      !retry_state->completed_send_initial_metadata) {+    return false;+  }+  if (pending->batch->send_message &&+      retry_state->completed_send_message_count < calld->send_messages.size()) {+    return false;+  }+  if (pending->batch->send_trailing_metadata &&+      !retry_state->completed_send_trailing_metadata) {+    return false;+  }+  if (pending->batch->recv_initial_metadata &&+      !retry_state->completed_recv_initial_metadata) {+    return false;+  }+  if (pending->batch->recv_message &&+      retry_state->completed_recv_message_count <+          retry_state->started_recv_message_count) {+    return false;   }-  GPR_ASSERT(calld->initial_metadata_batch != NULL);+  if (pending->batch->recv_trailing_metadata &&+      !retry_state->completed_recv_trailing_metadata) {+    return false;+  }+  return true;+}++// Callback used to intercept on_complete from subchannel calls.+// Called only when retries are enabled.+static void on_complete(grpc_exec_ctx *exec_ctx, void *arg, grpc_error *error) {+  subchannel_batch_data *batch_data = (subchannel_batch_data *)arg;+  grpc_call_element *elem = batch_data->elem;+  channel_data *chand = (channel_data *)elem->channel_data;+  call_data *calld = (call_data *)elem->call_data;+  if (GRPC_TRACER_ON(grpc_client_channel_trace)) {+    char *op_str = grpc_transport_stream_op_batch_string(&batch_data->batch);+    gpr_log(GPR_DEBUG, ""chand=%p calld=%p: got on_complete, error=%s, batch=%s"",+            chand, calld, grpc_error_string(error), op_str);+    gpr_free(op_str);+  }+  // Update bookkeeping in retry_state.+  subchannel_call_retry_state *retry_state = (subchannel_call_retry_state *)+      grpc_connected_subchannel_call_get_parent_data(+          batch_data->subchannel_call);+  if (batch_data->batch.send_initial_metadata) {+    retry_state->completed_send_initial_metadata = true;+  }+  if (batch_data->batch.send_message) {+    ++retry_state->completed_send_message_count;+  }+  if (batch_data->batch.send_trailing_metadata) {+    retry_state->completed_send_trailing_metadata = true;+  }+  if (batch_data->batch.recv_initial_metadata) {+    retry_state->completed_recv_initial_metadata = true;+  }+  if (batch_data->batch.recv_message) {+    ++retry_state->completed_recv_message_count;+  }+  if (batch_data->batch.recv_trailing_metadata) {+    retry_state->completed_recv_trailing_metadata = true;+  }+  // Check if the call is finished, and if so, get its status.+  // The call is finished if either (a) this callback was invoked with+  // an error or (b) we receive status.+  bool call_finished = false;+  grpc_status_code status = GRPC_STATUS_OK;+  grpc_mdelem *server_pushback_md = NULL;+  if (error != GRPC_ERROR_NONE) {  // Case (a).+    call_finished = true;+    grpc_error_get_status(exec_ctx, error, calld->deadline, &status, NULL,+                          NULL);+  } else if (batch_data->batch.recv_trailing_metadata) {  // Case (b).+    call_finished = true;+    grpc_metadata_batch *md_batch =+        batch_data->batch.payload->recv_trailing_metadata+            .recv_trailing_metadata;+    GPR_ASSERT(md_batch->idx.named.grpc_status != NULL);+    status = grpc_get_status_from_metadata(md_batch->idx.named.grpc_status->md);+    if (md_batch->idx.named.grpc_retry_pushback_ms != NULL) {+      server_pushback_md = &md_batch->idx.named.grpc_retry_pushback_ms->md;+    }+  }+  if (call_finished && GRPC_TRACER_ON(grpc_client_channel_trace)) {+    gpr_log(GPR_DEBUG, ""chand=%p calld=%p: call finished, status=%s"", chand,+            calld, grpc_status_string(status));+  }+  // If the call is finished, check if we should retry.+  if (call_finished &&+      maybe_retry(exec_ctx, elem, batch_data, status, server_pushback_md)) {+    batch_data_unref(exec_ctx, batch_data);+    // Unref batch_data for deferred recv_initial_metadata_ready or+    // recv_message_ready callbacks, if any.+    if (batch_data->batch.recv_trailing_metadata &&+        retry_state->recv_initial_metadata_ready_deferred) {+      batch_data_unref(exec_ctx, batch_data);","How is it safe to call this potentially twice in a row? Wont if unref everything in it, not just the recv_trailing_metadata",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13306,150033359,2017-11-09T17:36:02Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc,"@@ -1752,18 +1768,18 @@ static void glb_update_locked(grpc_exec_ctx* exec_ctx, grpc_lb_policy* policy,           ""glb_update_missing"");     } else {       // otherwise, keep using the current LB channel (ignore this update).-      gpr_log(GPR_ERROR,-              ""No valid LB addresses channel arg for grpclb %p update, ""-              ""ignoring."",-              (void*)glb_policy);+      gpr_log(+          GPR_ERROR,+          ""[grpclb %p] No valid LB addresses channel arg in update, ignoring."",+          glb_policy);     }     return;   }   const grpc_lb_addresses* addresses =       (const grpc_lb_addresses*)arg->value.pointer.p;   // If a non-empty serverlist hasn't been received from the balancer,   // propagate the update to fallback_backend_addresses.-  if (glb_policy->serverlist == NULL) {+  if (glb_policy->started_picking && glb_policy->serverlist == NULL) {","I don't think this is correct.Two things happen inside of `fallback_update_locked()`:1. We update `glb_policy->fallback_backend_addresses` with the new list of backends provided by the resolver.2. If we are already in fallback mode, we pass that updated list of addresses to the RR policy by calling `rr_handover_locked()`.Note that even if we have not yet started picking, we still need to do (1), so that when we do start picking later, we will use the right set of backend addresses as the fallback.  However, we do not want (2) to happen in this case.  So I think the bug here is that `fallback_update_locked()` is using the wrong condition to decide when to call `rr_handover_locked()`.  This fix should be made there instead of here.Note that in #12587, I suggested that the condition in `fallback_update_locked()` should actually be `glb_policy->rr_policy != NULL`.  However, @AspirinSJL responded correctly that that causes problems when the RR policy shuts down due to all of the backends going away.  That problem will go away with #12829, so if that PR gets merged before this one, we can just check that.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13306,150081825,2017-11-09T20:45:33Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc,"@@ -1752,18 +1768,18 @@ static void glb_update_locked(grpc_exec_ctx* exec_ctx, grpc_lb_policy* policy,           ""glb_update_missing"");     } else {       // otherwise, keep using the current LB channel (ignore this update).-      gpr_log(GPR_ERROR,-              ""No valid LB addresses channel arg for grpclb %p update, ""-              ""ignoring."",-              (void*)glb_policy);+      gpr_log(+          GPR_ERROR,+          ""[grpclb %p] No valid LB addresses channel arg in update, ignoring."",+          glb_policy);     }     return;   }   const grpc_lb_addresses* addresses =       (const grpc_lb_addresses*)arg->value.pointer.p;   // If a non-empty serverlist hasn't been received from the balancer,   // propagate the update to fallback_backend_addresses.-  if (glb_policy->serverlist == NULL) {+  if (glb_policy->started_picking && glb_policy->serverlist == NULL) {","Perhaps I was unclear.  I don't think we need a separate issue for this, nor do I think we need to wait for #12829 to go in first.  I think we can just change `fallback_update_locked()` from this:```   if (glb_policy->lb_fallback_timeout_ms > 0 &&       !glb_policy->fallback_timer_active) {```to this:```   if (glb_policy->started_picking &&       glb_policy->lb_fallback_timeout_ms > 0 &&       !glb_policy->fallback_timer_active) {```I think we can go ahead and do that immediately, without waiting for #12829.My comment was simply that once #12829 goes in, the condition in `fallback_update_locked()` can change from what's shown above to simply `glb_policy->rr_policy != NULL`.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13331,150084344,2017-11-09T20:56:50Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc,"@@ -1264,8 +1264,9 @@ static void lb_call_on_retry_timer_locked(grpc_exec_ctx* exec_ctx, void* arg,       gpr_log(GPR_INFO, ""Restaring call to LB server (grpclb %p)"",               (void*)glb_policy);     }-    GPR_ASSERT(glb_policy->lb_call == NULL);-    query_for_backends_locked(exec_ctx, glb_policy);+    if (glb_policy->lb_call == NULL) {",Let's add this condition to the `if` statement on line 1262 above.  We shouldn't execute this block at all if `lb_call` is not NULL.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13331,150085170,2017-11-09T21:00:34Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc,"@@ -1264,8 +1264,9 @@ static void lb_call_on_retry_timer_locked(grpc_exec_ctx* exec_ctx, void* arg,       gpr_log(GPR_INFO, ""Restaring call to LB server (grpclb %p)"",               (void*)glb_policy);     }-    GPR_ASSERT(glb_policy->lb_call == NULL);-    query_for_backends_locked(exec_ctx, glb_policy);+    if (glb_policy->lb_call == NULL) {","I assume that the problem here is the race condition I spoke about in my talk at the team meeting last week?  In other words, this happens when the timer closure is scheduled before we cancel the timer but not actually run until after we recreate the call?If that's not the case, please explain what actually triggers this condition.  Thanks!",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/13325,150088992,2017-11-09T21:17:04Z,src/core/lib/support/murmur_hash.cc,"@@ -45,7 +45,8 @@ uint32_t gpr_murmur_hash3(const void *key, size_t len, uint32_t seed) {    /* body */   for (i = -(int)nblocks; i; i++) {-    memcpy(&k1, blocks + i, sizeof(uint32_t));+    memcpy(&k1, (const uint8_t*)(blocks) + i * sizeof(uint32_t),","Also, I haven't properly thought through whether this is a strict aliasing violation or not.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/13332,150102485,2017-11-09T22:13:20Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc,"@@ -213,7 +217,8 @@ static void wrapped_rr_closure(grpc_exec_ctx* exec_ctx, void* arg,       grpc_grpclb_client_stats_unref(wc_arg->client_stats);     }     if (GRPC_TRACER_ON(grpc_lb_glb_trace)) {-      gpr_log(GPR_INFO, ""Unreffing RR %p"", (void*)wc_arg->rr_policy);+      gpr_log(GPR_INFO, ""[grpclb %p] Unreffing RR %p"", wc_arg->glb_policy,",Do we have any guideline about this? I think those concerns are independent.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13332,150106978,2017-11-09T22:33:49Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc,"@@ -213,7 +217,8 @@ static void wrapped_rr_closure(grpc_exec_ctx* exec_ctx, void* arg,       grpc_grpclb_client_stats_unref(wc_arg->client_stats);     }     if (GRPC_TRACER_ON(grpc_lb_glb_trace)) {-      gpr_log(GPR_INFO, ""Unreffing RR %p"", (void*)wc_arg->rr_policy);+      gpr_log(GPR_INFO, ""[grpclb %p] Unreffing RR %p"", wc_arg->glb_policy,","I don't think we've historically paid enough attention to this, but in general I think trace information belongs at the debug log level.  But we certainly don't need to hold up this PR for that if you don't want to.",
5120183,jcanizales,https://api.github.com/repos/grpc/grpc/pulls/13196,150114189,2017-11-09T23:07:58Z,gRPC-ProtoRPC.podspec,"@@ -28,6 +28,10 @@ Pod::Spec.new do |s|   s.license  = 'Apache License, Version 2.0'   s.authors  = { 'The gRPC contributors' => 'grpc-packages@google.com' } +  # gRPC podspecs depend on fix for https://github.com/CocoaPods/CocoaPods/issues/6024,+  # which was released in Cocoapods v1.2.0.+  s.cocoapods_version = '>= 1.2.0'","Given that the fix is needed by `gRPC-Core.podspec`, why not put the restriction just there, and let dependent podspecs just inherit it?",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,150116054,2017-11-09T23:18:10Z,src/python/grpcio/grpc/__init__.py,"@@ -1252,6 +1269,65 @@ def ssl_server_credentials(private_key_certificate_chain_pairs,             ], require_client_auth))  +def ssl_server_credentials_with_cert_config_fetcher(cert_config_fetcher_cb,+                                                    require_client_auth=False):+    """"""Creates a ServerCredentials for use with an SSL-enabled Server.++    Args:+      cert_config_fetcher_cb (callable): a callback that takes no",One question I'd like us to address: why pass an `initial_cert_config_fetcher` rather than pass an `initial_cert_config`? Why do this dance of indirection rather than just pass the data?,
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/13344,150156194,2017-11-10T05:21:51Z,src/core/lib/iomgr/exec_ctx.cc,"@@ -176,6 +183,27 @@ grpc_millis grpc_timespec_to_millis_round_up(gpr_timespec ts) {   return timespec_to_atm_round_up(ts); } +void grpc_exec_ctx_maybe_update_start_time(grpc_exec_ctx* exec_ctx) {+  grpc_exec_ctx_invalidate_now(exec_ctx);+  grpc_millis now = grpc_exec_ctx_now(exec_ctx);+  grpc_millis last_start_time_update = gpr_atm_acq_load(&g_last_start_time_update);+  if (now > last_start_time_update &&+      now - last_start_time_update > GRPC_START_TIME_UPDATE_INTERVAL) {+    gpr_timespec real_now = gpr_now(GPR_CLOCK_REALTIME);+    gpr_timespec old_now = grpc_millis_to_timespec(now, GPR_CLOCK_REALTIME);+    gpr_timespec diff = gpr_time_sub(real_now, old_now);+    if (GRPC_TRACER_ON(grpc_timer_check_trace)) {+      gpr_log(GPR_DEBUG, ""Update start time with diff: %"" PRId64 ""s %dns"", diff.tv_sec, diff.tv_nsec);+    }+    gpr_mu_lock(&g_start_time_mu);+    if (last_start_time_update == gpr_atm_acq_load(&g_last_start_time_update)) {",Because `next` at [here](https://github.com/grpc/grpc/blob/master/src/core/lib/iomgr/timer_manager.cc#L197) is relative time from monotonic clock. It is added up with g_start_time[GPR_CLOCK_REALTIME] to determine the time until which `gpr_cv_wait` should wait.,
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/13306,150172521,2017-11-10T08:02:28Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc,"@@ -1752,18 +1768,18 @@ static void glb_update_locked(grpc_exec_ctx* exec_ctx, grpc_lb_policy* policy,           ""glb_update_missing"");     } else {       // otherwise, keep using the current LB channel (ignore this update).-      gpr_log(GPR_ERROR,-              ""No valid LB addresses channel arg for grpclb %p update, ""-              ""ignoring."",-              (void*)glb_policy);+      gpr_log(+          GPR_ERROR,+          ""[grpclb %p] No valid LB addresses channel arg in update, ignoring."",+          glb_policy);     }     return;   }   const grpc_lb_addresses* addresses =       (const grpc_lb_addresses*)arg->value.pointer.p;   // If a non-empty serverlist hasn't been received from the balancer,   // propagate the update to fallback_backend_addresses.-  if (glb_policy->serverlist == NULL) {+  if (glb_policy->started_picking && glb_policy->serverlist == NULL) {","I have appended a commit in #12829 to change the condition to ""glb_policy->rr_policy != NULL"".",
118517,skyostil,https://api.github.com/repos/grpc/grpc/pulls/13325,150200471,2017-11-10T10:26:47Z,src/core/lib/support/murmur_hash.cc,"@@ -45,7 +45,8 @@ uint32_t gpr_murmur_hash3(const void *key, size_t len, uint32_t seed) {    /* body */   for (i = -(int)nblocks; i; i++) {-    memcpy(&k1, blocks + i, sizeof(uint32_t));+    memcpy(&k1, (const uint8_t*)(blocks) + i * sizeof(uint32_t),","That's true, fixed. Not sure what the strict aliasing violation here would be however.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13343,150259552,2017-11-10T15:15:04Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -506,11 +508,13 @@ static void pf_connectivity_changed_locked(grpc_exec_ctx* exec_ctx, void* arg,         }         sd->curr_connectivity_state =",What happens if we simply remove the call to `grpc_subchannel_check_connectivity()` and instead unconditionally call `grpc_lb_subchannel_data_start_connectivity_watch()`?  Does anything break?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13277,150276179,2017-11-10T16:18:03Z,src/core/lib/iomgr/polling_interface.h,"@@ -0,0 +1,167 @@+/*+ *+ * Copyright 2015 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_IOMGR_POLLING_INTERFACE_H+#define GRPC_CORE_LIB_IOMGR_POLLING_INTERFACE_H++#include <grpc/support/port_platform.h>+#include <grpc/support/sync.h>+#include <grpc/support/time.h>++#include ""src/core/lib/iomgr/exec_ctx.h""++#ifndef NDEBUG+extern grpc_tracer_flag grpc_trace_fd_refcount;+#endif++namespace grpc_core {++// Forward declarations+class PollingJoin;++// A Pollable is an object that can be polled+// Polling engines derive from this interface and implement+// This interface should not be implemented outside of a polling engine+class Pollable {};++// A PollableSet is a front-end interface to Poller & PollingJoin,+// collecting common methods.+// In many situations we don't care which we're dealing with, and so this class+// serves to abstract away that detail+class PollableSet {+ public:+  // Add a Pollable to this collection+  virtual void AddPollable(Pollable* pollable) = 0;++ protected:+  PollableSet() {}+  ~PollableSet() {}++ private:+  friend class PollingJoin;+  virtual void AddToPollingJoin(PollingJoin* join) = 0;+};++// A Poller is a set of file descriptors that a higher level item is+// interested in, and a method to poll on them. For example:+//    - a server will typically keep a poller containing all connected channels,+//      so that it can find new calls to service+//    - a completion queue might keep a poller with an entry for each transport+//      that is servicing a call that it's tracking+class Poller : public PollableSet {+ public:+  virtual ~Poller() {}++  class Worker {};++  // Do some work on a pollset.+  // May involve invoking asynchronous callbacks, or actually polling file+  // descriptors.+  //+  // Requires pollset's mutex locked. May unlock its mutex during its execution.+  //+  // worker is a (platform-specific) handle that can be used to wake up+  // from grpc_pollset_work before any events are received and before the+  // timeout has expired. It is both initialized and destroyed by+  // grpc_pollset_work. Initialization of worker is guaranteed to occur BEFORE+  // the pollset's mutex is released for the first time by grpc_pollset_work and+  // it is guaranteed that it will not be released by grpc_pollset_work AFTER+  // worker has been destroyed.+  //+  // It's legal for worker to be NULL: in that case, this specific thread can+  // not be directly woken with a kick, but maybe be indirectly (with a kick+  // against the pollset as a whole).+  //+  // Tries not to block past deadline. May call grpc_closure_list_run on+  // grpc_closure_list, without holding the pollset lock+  virtual grpc_error* Poll(grpc_exec_ctx* exec_ctx, Worker** worker,+                           grpc_millis deadline) GRPC_MUST_USE_RESULT = 0;++  // Break one polling thread out of polling work for this pollset.+  // If specific_worker is non-NULL, then kick that worker.+  virtual grpc_error* Kick(grpc_exec_ctx* exec_ctx,+                           Worker* specific_worker) GRPC_MUST_USE_RESULT = 0;++  // Begin shutting down the pollset, and call on_done when done.+  // pollset's mutex must be held+  virtual void Shutdown(grpc_exec_ctx* exec_ctx, grpc_closure* on_done) = 0;++  // CHANGING: return the size of a Poller with the current polling engine+  // (will be moved to the polling engine interface directly in a future+  // revision)+  static size_t PollerSize();++  // CHANGING: instantiate a Poller with the current polling engine+  static Poller* Create(void* memory, gpr_mu** mu);++ protected:+  Poller() {}++ private:+  void AddToPollingJoin(PollingJoin* polling_join) override final;+};++// A PollingJoin serves to join multiple pollers and pollables.+// Each Pollable that's added to a PollingJoin is added to ALL Poller instances+// contained within it+// Each Poller that's added to a PollingJoin receives ALL Pollable's that have+// been added to it+// (both in perpetuity)+//+// Using a PollingJoin is often cheaper than manually updating the same using+// just the Poller/Pollable interfaces as some polling engines have short-cut+// paths to bulk update pollers/pollables+class PollingJoin : public PollableSet {+ public:+  // inherits AddPollable++  // remove a pollable from a join - it's unspecified whether this stops+  // existing Poller's in this join from polling on the Pollable, but guarantees+  // it will not be added to future Pollables+  virtual void RemovePollable(Pollable* pollable) = 0;++  // Add a Poller to the join+  virtual void AddPoller(Poller* poller) = 0;+  // and remove it again (so it doesn't receive new Pollables)+  virtual void RemovePoller(Poller* poller) = 0;++  // Merge a PollingJoin with this one+  // Each PollingJoin subsequently acts as a different handle to the same","Let's explicitly document the exact semantics of a merge.For example, consider the following case:- create PollingJoin A- create PollingJoin B- merge A and B- add Poller to A- add Pollable to BI assume that polling on the Poller added to A will then include the Pollable added to B?  And if the Pollable is subsequently removed from B, that polling on the Poller may no longer include the Pollable (subject to the same caveat documented for `RemovePollable()` above)?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12434,150289254,2017-11-10T17:05:19Z,doc/connectivity-semantics-and-api.md,"@@ -28,7 +28,10 @@ through TLS handshake (or equivalent) and all subsequent attempt to communicate have succeeded (or are pending without any known failure ).  TRANSIENT_FAILURE: There has been some transient failure (such as a TCP 3-way-handshake timing out or a socket error). Channels in this state will eventually+handshake timing out or a socket error). New RPCs should, by default, fail+immediately with status UNAVAILABLE, but implementations may support a per-RPC+option specifying an RPC is 'wait-for-ready' which will leave the RPC as+pending. Channels in this state will eventually",...until either the channel becomes READY and the RPC can be attempted or the RPC's deadline expires.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12434,150290677,2017-11-10T17:11:33Z,doc/connectivity-semantics-and-api.md,"@@ -28,7 +28,10 @@ through TLS handshake (or equivalent) and all subsequent attempt to communicate have succeeded (or are pending without any known failure ).  TRANSIENT_FAILURE: There has been some transient failure (such as a TCP 3-way-handshake timing out or a socket error). Channels in this state will eventually+handshake timing out or a socket error). New RPCs should, by default, fail","I'm a little leery of explicitly tying RPC handling to channel state, because the channel state notifications are asynchronous with respect to the RPC handling.  In other words, at the point at which we're trying to decide which backend to send an RPC to, I think we should actually try to send it and see what happens instead of checking the most recent connectivity state notification, because it could be the case that the most recent notification was for TRANSIENT_FAILURE but the channel has since recovered and is now in state READY, only we haven't yet received the notification about that.I think it would be better to consider the connectivity state to be a parallel but independent path to the RPC handling path.  In other words, the same conditions that cause us to go into state TRANSIENT_FAILURE should cause new RPCs to be failed with UNAVAILABLE by default.  But that's different from saying that we should check the state itself in order to make this decision.",
2811396,ejona86,https://api.github.com/repos/grpc/grpc/pulls/12434,150299995,2017-11-10T17:58:31Z,doc/connectivity-semantics-and-api.md,"@@ -28,7 +28,10 @@ through TLS handshake (or equivalent) and all subsequent attempt to communicate have succeeded (or are pending without any known failure ).  TRANSIENT_FAILURE: There has been some transient failure (such as a TCP 3-way-handshake timing out or a socket error). Channels in this state will eventually+handshake timing out or a socket error). New RPCs should, by default, fail","> I'm a little leery of explicitly tying RPC handling to channel state, because the channel state notifications are asynchronous with respect to the RPC handling.Them being asynchronous is the exact reason I'm okay with this. The channel state API is guaranteed to be imprecise, so we still have leeway as we just have to produce a _plausible_ ordering.> I think we should actually try to send it and see what happens instead of checking the most recent connectivity state notificationOh, definitely. I don't see this as disallowing that.> only we haven't yet received the notification about that.Notifications, by their very nature are after-the-fact. Even in a system where they were immediately delivered there would still be a delay for application processing, so it'd _still_ be after-the-fact. The behavior here is instantaneous, which the user never gets to see.> I think it would be better to consider the connectivity state to be a parallel but independent path to the RPC handling path.:-/ This is complex enough already. I see that as making it even worse. I like this definition because it is concise, non-repetitive, and is comprehensible to users.",
2811396,ejona86,https://api.github.com/repos/grpc/grpc/pulls/12434,150300915,2017-11-10T18:03:05Z,doc/connectivity-semantics-and-api.md,"@@ -28,7 +28,10 @@ through TLS handshake (or equivalent) and all subsequent attempt to communicate have succeeded (or are pending without any known failure ).  TRANSIENT_FAILURE: There has been some transient failure (such as a TCP 3-way-handshake timing out or a socket error). Channels in this state will eventually+handshake timing out or a socket error). New RPCs should, by default, fail+immediately with status UNAVAILABLE, but implementations may support a per-RPC+option specifying an RPC is 'wait-for-ready' which will leave the RPC as+pending. Channels in this state will eventually","FYI: this is pre-existing text.> until either the channel becomes READYYes, but no. CONNECTING can lead to READY, yes. But this is a one-time deal. I say nothing about after the transition to CONNECTING.> or the RPC's deadline expiresActually, no. It has nothing to do with whether there are RPCs. We'll still reconnect even without RPCs. The only exception is IDLE_TIMEOUT, which applies to CONNECTING, not TRANSIENT_FAILURE.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/13344,150359920,2017-11-10T23:31:07Z,src/core/lib/iomgr/exec_ctx.cc,"@@ -104,23 +107,43 @@ static void exec_ctx_sched(grpc_exec_ctx* exec_ctx, grpc_closure* closure,   grpc_closure_list_append(&exec_ctx->closure_list, closure, error); } -static gpr_timespec+typedef struct time_atm_pair {",Nit: this is only going to ever be used for this special case global start time. I would suggest naming it as such to be clearer. something like global_start_time_atm_pair.Same this with the functions. `timespec_from_global_start_time(gpr_clock_type clock_type)``update_global_start_time(const gpr_timespec src)`,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,150583290,2017-11-13T16:07:09Z,src/python/grpcio/grpc/_cython/_cygrpc/server.pyx.pxi,"@@ -17,6 +17,36 @@ cimport cpython import time  +cdef grpc_ssl_certificate_config_reload_status _server_cert_config_fetcher_wrapper(+        void* user_data, grpc_ssl_server_certificate_config **config) with gil:+  # We are not catching any exception here, because cython will+  # happily catch and ignore it, and will log for us, and also the+  # core lib will continue as if the cert has not changed, which is a+  # reasonable behavior.","This comment reminds me of one of my favorite bits of [_PHP: A Fractal Of Bad Design_](https://eev.ee/blog/2012/04/09/php-a-fractal-of-bad-design/): ""PHP is built to keep chugging along at all costs. When faced with either doing something nonsensical or aborting with an error, it will do something nonsensical. Anything is better than nothing."".What kind of exceptions might happen here? Why is continuing execution the right way to respond to them, rather than allowing the process to crash?",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,150584207,2017-11-13T16:10:05Z,src/python/grpcio_tests/tests/unit/_server_ssl_cert_config_test.py,"@@ -0,0 +1,357 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""+This tests server certificate rotation support.++Here we test various aspects of gRPC Python, and in some cases C-core+by extension, support for server certificate rotation.++* ServerSSLCertReloadTestWithClientAuth: test ability to rotate+  server's SSL cert for use in future channels with clients while not+  affecting any existing channel. The server requires client+  authentication.++* ServerSSLCertReloadTestWithoutClientAuth: like+  ServerSSLCertReloadTestWithClientAuth except that the server does+  not authenticate the client.++* ServerSSLCertReloadTestCertConfigReuse: tests gRPC Python's ability+  to deal with user's reuse of ServerCertificateConfig instances.++""""""++import os+import unittest+from concurrent import futures++import grpc+from tests.unit import resources+from tests.testing import _application_common+from tests.testing import _server_application+from tests.testing.proto import services_pb2_grpc++ca_1_pem = resources.cert_hier_1_root_ca_cert()+ca_2_pem = resources.cert_hier_2_root_ca_cert()++client_key_1_pem = resources.cert_hier_1_client_1_key()+client_chain_1_pem = '\n'.join([+    resources.cert_hier_1_client_1_cert(),+    resources.cert_hier_1_intermediate_ca_cert(),+])++client_key_2_pem = resources.cert_hier_2_client_1_key()+client_chain_2_pem = '\n'.join([+    resources.cert_hier_2_client_1_cert(),+    resources.cert_hier_2_intermediate_ca_cert(),+])++server_key_1_pem = resources.cert_hier_1_server_1_key()+server_cert_1_pem = '\n'.join([+    resources.cert_hier_1_server_1_cert(),+    resources.cert_hier_1_intermediate_ca_cert(),+])++server_key_2_pem = resources.cert_hier_2_server_1_key()+server_cert_2_pem = '\n'.join([+    resources.cert_hier_2_server_1_cert(),+    resources.cert_hier_2_intermediate_ca_cert(),+])+++class CertConfigFetcher(object):++    def __init__(self, ca_pem, key_pem, cert_pem, switch_cert_on_client_num):+        self.client_num = 0+        self.switch_cert_on_client_num = switch_cert_on_client_num+        # we simulate cb failures at 2 and 3+        assert self.switch_cert_on_client_num > 3+        self.cert_config = grpc.ssl_server_certificate_config(+            [(key_pem, cert_pem)],+            root_certificates=ca_pem,)++    def __call__(self):+        self.client_num += 1+        if self.client_num in (2, 3):+            raise ValueError(+                'just an error for fun, should not affect the test')+        if self.client_num != self.switch_cert_on_client_num:+            return None+        else:+            # do the switch+            ret = self.cert_config+            self.cert_config = None+            return ret+++class _ServerSSLCertReloadTest(object):++    def _do_setUp(self, with_client_auth):+        self.with_client_auth = with_client_auth+        self.server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))+        services_pb2_grpc.add_FirstServiceServicer_to_server(+            _server_application.FirstServiceServicer(), self.server)+        switch_cert_on_client_num = 10+        initial_cert_config = grpc.ssl_server_certificate_config(+            [(server_key_1_pem, server_cert_1_pem)], root_certificates=ca_2_pem)+        cert_config_fetcher = CertConfigFetcher(ca_1_pem, server_key_2_pem,+                                                server_cert_2_pem,+                                                switch_cert_on_client_num)+        server_credentials = grpc.ssl_server_credentials_dynamic_cert_config(+            initial_cert_config,+            cert_config_fetcher,+            require_client_auth=self.with_client_auth)+        self.port = self.server.add_secure_port('[::]:0', server_credentials)+        self.server.start()++    def _do_tearDown(self):+        if self.server:+            self.server.stop(0)++    def _perform_rpc(self, client_stub, expect_success):+        # we don't care about the actual response of the rpc; only+        # whether we can perform it or not, and if not, the reason+        # must be ""connect failed""+        if expect_success:+            client_stub.UnUn(_application_common.UNARY_UNARY_REQUEST)+        else:+            with self.assertRaises(grpc.RpcError) as exc:","Spell out `exception_context` rather than use the abbreviation ""`exc`"". And then name it `rpc_error_context`, since that's more specific and more likely to be more helpful. (It's not clear if what you're abbreviating is ""exception"" or ""exception_context""; note that the value assigned to the field is **not** an `Exception`, and this is something that a lot of users of `assertRaises` get wrong.)",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,150584534,2017-11-13T16:11:08Z,src/python/grpcio_tests/tests/unit/_server_ssl_cert_config_test.py,"@@ -0,0 +1,357 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""+This tests server certificate rotation support.++Here we test various aspects of gRPC Python, and in some cases C-core+by extension, support for server certificate rotation.++* ServerSSLCertReloadTestWithClientAuth: test ability to rotate+  server's SSL cert for use in future channels with clients while not+  affecting any existing channel. The server requires client+  authentication.++* ServerSSLCertReloadTestWithoutClientAuth: like+  ServerSSLCertReloadTestWithClientAuth except that the server does+  not authenticate the client.++* ServerSSLCertReloadTestCertConfigReuse: tests gRPC Python's ability+  to deal with user's reuse of ServerCertificateConfig instances.++""""""++import os+import unittest+from concurrent import futures++import grpc+from tests.unit import resources+from tests.testing import _application_common+from tests.testing import _server_application+from tests.testing.proto import services_pb2_grpc++ca_1_pem = resources.cert_hier_1_root_ca_cert()+ca_2_pem = resources.cert_hier_2_root_ca_cert()++client_key_1_pem = resources.cert_hier_1_client_1_key()+client_chain_1_pem = '\n'.join([+    resources.cert_hier_1_client_1_cert(),+    resources.cert_hier_1_intermediate_ca_cert(),+])++client_key_2_pem = resources.cert_hier_2_client_1_key()+client_chain_2_pem = '\n'.join([+    resources.cert_hier_2_client_1_cert(),+    resources.cert_hier_2_intermediate_ca_cert(),+])++server_key_1_pem = resources.cert_hier_1_server_1_key()+server_cert_1_pem = '\n'.join([+    resources.cert_hier_1_server_1_cert(),+    resources.cert_hier_1_intermediate_ca_cert(),+])++server_key_2_pem = resources.cert_hier_2_server_1_key()+server_cert_2_pem = '\n'.join([+    resources.cert_hier_2_server_1_cert(),+    resources.cert_hier_2_intermediate_ca_cert(),+])+++class CertConfigFetcher(object):++    def __init__(self, ca_pem, key_pem, cert_pem, switch_cert_on_client_num):+        self.client_num = 0+        self.switch_cert_on_client_num = switch_cert_on_client_num+        # we simulate cb failures at 2 and 3+        assert self.switch_cert_on_client_num > 3+        self.cert_config = grpc.ssl_server_certificate_config(+            [(key_pem, cert_pem)],+            root_certificates=ca_pem,)++    def __call__(self):+        self.client_num += 1+        if self.client_num in (2, 3):+            raise ValueError(+                'just an error for fun, should not affect the test')+        if self.client_num != self.switch_cert_on_client_num:+            return None+        else:+            # do the switch+            ret = self.cert_config+            self.cert_config = None+            return ret+++class _ServerSSLCertReloadTest(object):++    def _do_setUp(self, with_client_auth):+        self.with_client_auth = with_client_auth+        self.server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))+        services_pb2_grpc.add_FirstServiceServicer_to_server(+            _server_application.FirstServiceServicer(), self.server)+        switch_cert_on_client_num = 10+        initial_cert_config = grpc.ssl_server_certificate_config(+            [(server_key_1_pem, server_cert_1_pem)], root_certificates=ca_2_pem)+        cert_config_fetcher = CertConfigFetcher(ca_1_pem, server_key_2_pem,+                                                server_cert_2_pem,+                                                switch_cert_on_client_num)+        server_credentials = grpc.ssl_server_credentials_dynamic_cert_config(+            initial_cert_config,+            cert_config_fetcher,+            require_client_auth=self.with_client_auth)+        self.port = self.server.add_secure_port('[::]:0', server_credentials)+        self.server.start()++    def _do_tearDown(self):+        if self.server:+            self.server.stop(0)++    def _perform_rpc(self, client_stub, expect_success):+        # we don't care about the actual response of the rpc; only+        # whether we can perform it or not, and if not, the reason+        # must be ""connect failed""+        if expect_success:+            client_stub.UnUn(_application_common.UNARY_UNARY_REQUEST)+        else:+            with self.assertRaises(grpc.RpcError) as exc:+                client_stub.UnUn(_application_common.UNARY_UNARY_REQUEST)+            self.assertEqual(exc.exception.code(), grpc.StatusCode.UNAVAILABLE)+            self.assertEqual(exc.exception.details(), 'Connect Failed')",It's generally a terrible idea to require in a test that some natural-language prose string intended for a human reader match some exact condition. Why is doing so appropriate here?,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,150585034,2017-11-13T16:12:53Z,src/python/grpcio_tests/tests/unit/_server_ssl_cert_config_test.py,"@@ -0,0 +1,357 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""+This tests server certificate rotation support.++Here we test various aspects of gRPC Python, and in some cases C-core+by extension, support for server certificate rotation.++* ServerSSLCertReloadTestWithClientAuth: test ability to rotate+  server's SSL cert for use in future channels with clients while not+  affecting any existing channel. The server requires client+  authentication.++* ServerSSLCertReloadTestWithoutClientAuth: like+  ServerSSLCertReloadTestWithClientAuth except that the server does+  not authenticate the client.++* ServerSSLCertReloadTestCertConfigReuse: tests gRPC Python's ability+  to deal with user's reuse of ServerCertificateConfig instances.++""""""++import os+import unittest+from concurrent import futures++import grpc+from tests.unit import resources+from tests.testing import _application_common+from tests.testing import _server_application+from tests.testing.proto import services_pb2_grpc++ca_1_pem = resources.cert_hier_1_root_ca_cert()+ca_2_pem = resources.cert_hier_2_root_ca_cert()++client_key_1_pem = resources.cert_hier_1_client_1_key()+client_chain_1_pem = '\n'.join([+    resources.cert_hier_1_client_1_cert(),+    resources.cert_hier_1_intermediate_ca_cert(),+])++client_key_2_pem = resources.cert_hier_2_client_1_key()+client_chain_2_pem = '\n'.join([+    resources.cert_hier_2_client_1_cert(),+    resources.cert_hier_2_intermediate_ca_cert(),+])++server_key_1_pem = resources.cert_hier_1_server_1_key()+server_cert_1_pem = '\n'.join([+    resources.cert_hier_1_server_1_cert(),+    resources.cert_hier_1_intermediate_ca_cert(),+])++server_key_2_pem = resources.cert_hier_2_server_1_key()+server_cert_2_pem = '\n'.join([+    resources.cert_hier_2_server_1_cert(),+    resources.cert_hier_2_intermediate_ca_cert(),+])+++class CertConfigFetcher(object):++    def __init__(self, ca_pem, key_pem, cert_pem, switch_cert_on_client_num):+        self.client_num = 0+        self.switch_cert_on_client_num = switch_cert_on_client_num+        # we simulate cb failures at 2 and 3+        assert self.switch_cert_on_client_num > 3+        self.cert_config = grpc.ssl_server_certificate_config(+            [(key_pem, cert_pem)],+            root_certificates=ca_pem,)++    def __call__(self):+        self.client_num += 1+        if self.client_num in (2, 3):+            raise ValueError(+                'just an error for fun, should not affect the test')+        if self.client_num != self.switch_cert_on_client_num:+            return None+        else:+            # do the switch+            ret = self.cert_config+            self.cert_config = None+            return ret+++class _ServerSSLCertReloadTest(object):++    def _do_setUp(self, with_client_auth):+        self.with_client_auth = with_client_auth+        self.server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))+        services_pb2_grpc.add_FirstServiceServicer_to_server(+            _server_application.FirstServiceServicer(), self.server)+        switch_cert_on_client_num = 10+        initial_cert_config = grpc.ssl_server_certificate_config(+            [(server_key_1_pem, server_cert_1_pem)], root_certificates=ca_2_pem)+        cert_config_fetcher = CertConfigFetcher(ca_1_pem, server_key_2_pem,+                                                server_cert_2_pem,+                                                switch_cert_on_client_num)+        server_credentials = grpc.ssl_server_credentials_dynamic_cert_config(+            initial_cert_config,+            cert_config_fetcher,+            require_client_auth=self.with_client_auth)+        self.port = self.server.add_secure_port('[::]:0', server_credentials)+        self.server.start()++    def _do_tearDown(self):+        if self.server:+            self.server.stop(0)++    def _perform_rpc(self, client_stub, expect_success):+        # we don't care about the actual response of the rpc; only+        # whether we can perform it or not, and if not, the reason+        # must be ""connect failed""+        if expect_success:+            client_stub.UnUn(_application_common.UNARY_UNARY_REQUEST)+        else:+            with self.assertRaises(grpc.RpcError) as exc:+                client_stub.UnUn(_application_common.UNARY_UNARY_REQUEST)+            self.assertEqual(exc.exception.code(), grpc.StatusCode.UNAVAILABLE)+            self.assertEqual(exc.exception.details(), 'Connect Failed')++    def _create_client_stub(self,+                            root_certificates=None,+                            private_key=None,+                            certificate_chain=None):+        return services_pb2_grpc.FirstServiceStub(+            grpc.secure_channel('localhost:{}'.format(self.port),+                                grpc.ssl_channel_credentials(+                                    root_certificates=root_certificates,+                                    private_key=private_key,+                                    certificate_chain=certificate_chain)))++    def _do_one_shot_client_rpc(self,+                                expect_success,+                                root_certificates=None,+                                private_key=None,+                                certificate_chain=None):+        client_stub = self._create_client_stub(+            root_certificates=root_certificates,+            private_key=private_key,+            certificate_chain=certificate_chain)+        self._perform_rpc(client_stub, expect_success)+        del client_stub++    def _do_common_test_recipe(self):+        # things should work...+        self._do_one_shot_client_rpc(+            True,+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # client should reject server...+        # fails because client trusts ca2 and so will reject server+        self._do_one_shot_client_rpc(+            False,+            root_certificates=ca_2_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # should work again...+        self._do_one_shot_client_rpc(+            True,+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # if with_client_auth, then client should be rejected by+        # server because client uses key/cert1, but server trusts ca2,+        # so server will reject+        self._do_one_shot_client_rpc(+            not self.with_client_auth,+            root_certificates=ca_1_pem,+            private_key=client_key_1_pem,+            certificate_chain=client_chain_1_pem)++        # one more time, client should be rejected by server if+        # with_client_auth+        self._do_one_shot_client_rpc(+            not self.with_client_auth,+            root_certificates=ca_1_pem,+            private_key=client_key_1_pem,+            certificate_chain=client_chain_1_pem)++        # should work again...+        self._do_one_shot_client_rpc(+            True,+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # and again...+        self._do_one_shot_client_rpc(+            True,+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # now create the ""persistent"" clients+        persistent_client_stub_A = self._create_client_stub(+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)+        self._perform_rpc(persistent_client_stub_A, True)++        persistent_client_stub_B = self._create_client_stub(+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)+        self._perform_rpc(persistent_client_stub_B, True)++        # moment of truth!! client should reject server because the+        # server switch cert...+        self._do_one_shot_client_rpc(+            False,+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # now should work again...+        self._do_one_shot_client_rpc(+            True,+            root_certificates=ca_2_pem,+            private_key=client_key_1_pem,+            certificate_chain=client_chain_1_pem)++        # and again...+        self._do_one_shot_client_rpc(+            True,+            root_certificates=ca_2_pem,+            private_key=client_key_1_pem,+            certificate_chain=client_chain_1_pem)++        # client should be rejected by server if with_client_auth+        self._do_one_shot_client_rpc(+            not self.with_client_auth,+            root_certificates=ca_2_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # here client should reject server...+        self._do_one_shot_client_rpc(+            False,+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # persistent clients should continue to work+        self._perform_rpc(persistent_client_stub_A, True)+        self._perform_rpc(persistent_client_stub_B, True)+++class ServerSSLCertConfigFetcherParamsChecks(unittest.TestCase):++    def test_params_checks(self):+        for initial_config, subsequent_config_fetcher, exc_msg in (","Rather than a single test method that loops over a list of ""test scenarios"" of length two, just make this two test methods. If there's common logic worth sharing, put it in a shared helper behavior.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,150586010,2017-11-13T16:15:52Z,src/python/grpcio_tests/tests/unit/resources.py,"@@ -11,7 +11,7 @@ # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License.-""""""Constants and functions for data used in interoperability testing.""""""+""""""Constants and functions for data used in unit testing.""""""","As long as we're here, let's just go with ""testing"" rather than ""interoperability testing"" or ""unit testing"".",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,150603528,2017-11-13T17:08:41Z,src/python/grpcio_tests/tests/unit/_server_ssl_cert_config_test.py,"@@ -0,0 +1,357 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""+This tests server certificate rotation support.++Here we test various aspects of gRPC Python, and in some cases C-core+by extension, support for server certificate rotation.++* ServerSSLCertReloadTestWithClientAuth: test ability to rotate+  server's SSL cert for use in future channels with clients while not+  affecting any existing channel. The server requires client+  authentication.++* ServerSSLCertReloadTestWithoutClientAuth: like+  ServerSSLCertReloadTestWithClientAuth except that the server does+  not authenticate the client.++* ServerSSLCertReloadTestCertConfigReuse: tests gRPC Python's ability+  to deal with user's reuse of ServerCertificateConfig instances.++""""""++import os+import unittest+from concurrent import futures++import grpc+from tests.unit import resources+from tests.testing import _application_common+from tests.testing import _server_application+from tests.testing.proto import services_pb2_grpc++ca_1_pem = resources.cert_hier_1_root_ca_cert()+ca_2_pem = resources.cert_hier_2_root_ca_cert()++client_key_1_pem = resources.cert_hier_1_client_1_key()+client_chain_1_pem = '\n'.join([+    resources.cert_hier_1_client_1_cert(),+    resources.cert_hier_1_intermediate_ca_cert(),+])++client_key_2_pem = resources.cert_hier_2_client_1_key()+client_chain_2_pem = '\n'.join([+    resources.cert_hier_2_client_1_cert(),+    resources.cert_hier_2_intermediate_ca_cert(),+])++server_key_1_pem = resources.cert_hier_1_server_1_key()+server_cert_1_pem = '\n'.join([+    resources.cert_hier_1_server_1_cert(),+    resources.cert_hier_1_intermediate_ca_cert(),+])++server_key_2_pem = resources.cert_hier_2_server_1_key()+server_cert_2_pem = '\n'.join([+    resources.cert_hier_2_server_1_cert(),+    resources.cert_hier_2_intermediate_ca_cert(),+])+++class CertConfigFetcher(object):++    def __init__(self, ca_pem, key_pem, cert_pem, switch_cert_on_client_num):+        self.client_num = 0+        self.switch_cert_on_client_num = switch_cert_on_client_num+        # we simulate cb failures at 2 and 3+        assert self.switch_cert_on_client_num > 3+        self.cert_config = grpc.ssl_server_certificate_config(+            [(key_pem, cert_pem)],+            root_certificates=ca_pem,)++    def __call__(self):+        self.client_num += 1+        if self.client_num in (2, 3):+            raise ValueError(+                'just an error for fun, should not affect the test')+        if self.client_num != self.switch_cert_on_client_num:+            return None+        else:+            # do the switch+            ret = self.cert_config+            self.cert_config = None+            return ret+++class _ServerSSLCertReloadTest(object):","Eww, yuck, a mixin![I'm no fan of implementation inheritance](https://www.youtube.com/watch?v=3MNVP9-hglc), but implementation inheritance is a better choice here than a mixin. Are you able to follow a pattern like```pyfrom __future__ import absolute_importfrom __future__ import divisionfrom __future__ import print_functionimport abcimport unittestimport sixclass AbstractSuperClassTest(six.with_metaclass(abc.ABCMeta, unittest.TestCase)):  def setUp(self):    print('AbstractSuperClassTest.setUp!')  def tearDown(self):    print('AbstractSuperClassTest.tearDown!')class AppleTest(AbstractSuperClassTest):  def test_apple(self):    print('AppleTest.test_apple!')class BananaTest(AbstractSuperClassTest):  def setUp(self):    super(BananaTest, self).setUp()    print('Banana.setUp!')  def tearDown(self):    print('Banana.tearDown!')    super(BananaTest, self).tearDown()  def test_banana(self):    print('BananaTest.test_banana!')if __name__ == '__main__':  unittest.main(verbosity=2)```?",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,150604108,2017-11-13T17:10:54Z,src/python/grpcio_tests/tests/unit/credentials/cert_hier_1/certs/ca.cert.pem,"@@ -0,0 +1,31 @@+-----BEGIN CERTIFICATE-----","Even though they're just test data, how would you feel about adding a `README.md` that describes what these files are and what they mean to one another?",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,150605476,2017-11-13T17:15:27Z,src/python/grpcio_tests/tests/unit/resources.py,"@@ -34,3 +34,71 @@ def private_key(): def certificate_chain():     return pkg_resources.resource_string(__name__,                                          _CERTIFICATE_CHAIN_RESOURCE_PATH)+++# the following are two disjoint certificate hierarchies 1 and 2,","Drop this; we generally dislike ""stanza"" markings in our source code (with the solution being to reshape the code so that no module needs ""stanzas"".) (Yes, the `grpc/__init__.py` file is an exception to this, although we're not thrilled with the stanza markings there either...)",
1170852,cauthu,https://api.github.com/repos/grpc/grpc/pulls/13188,150613984,2017-11-13T17:47:41Z,src/python/grpcio/grpc/_cython/_cygrpc/server.pyx.pxi,"@@ -17,6 +17,36 @@ cimport cpython import time  +cdef grpc_ssl_certificate_config_reload_status _server_cert_config_fetcher_wrapper(+        void* user_data, grpc_ssl_server_certificate_config **config) with gil:+  # We are not catching any exception here, because cython will+  # happily catch and ignore it, and will log for us, and also the+  # core lib will continue as if the cert has not changed, which is a+  # reasonable behavior.","thanks for the tidbit on PHP; it is funny and definitely not something I would subscribe to :)the exceptions i'm referring to are mainly from the user's fetcher callback. It would be totally advocating for crashing; please let me know how to do that, i.e., instruct cython to not catch and ignore exceptions here.Another option is to manually catch exceptions here and return `GRPC_SSL_CERTIFICATE_CONFIG_RELOAD_ERROR`; however, the outcome would not be materially different, since the C-core will again just log the error and continue as if the certificate has not changed.",
1170852,cauthu,https://api.github.com/repos/grpc/grpc/pulls/13188,150614631,2017-11-13T17:50:06Z,src/python/grpcio_tests/tests/unit/_server_ssl_cert_config_test.py,"@@ -0,0 +1,357 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""+This tests server certificate rotation support.++Here we test various aspects of gRPC Python, and in some cases C-core+by extension, support for server certificate rotation.++* ServerSSLCertReloadTestWithClientAuth: test ability to rotate+  server's SSL cert for use in future channels with clients while not+  affecting any existing channel. The server requires client+  authentication.++* ServerSSLCertReloadTestWithoutClientAuth: like+  ServerSSLCertReloadTestWithClientAuth except that the server does+  not authenticate the client.++* ServerSSLCertReloadTestCertConfigReuse: tests gRPC Python's ability+  to deal with user's reuse of ServerCertificateConfig instances.++""""""++import os+import unittest+from concurrent import futures++import grpc+from tests.unit import resources+from tests.testing import _application_common+from tests.testing import _server_application+from tests.testing.proto import services_pb2_grpc++ca_1_pem = resources.cert_hier_1_root_ca_cert()",i'd suspected this would be an issue :) will move inside the base class perhaps?,
1170852,cauthu,https://api.github.com/repos/grpc/grpc/pulls/13188,150616163,2017-11-13T17:55:40Z,src/python/grpcio_tests/tests/unit/_server_ssl_cert_config_test.py,"@@ -0,0 +1,357 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""+This tests server certificate rotation support.++Here we test various aspects of gRPC Python, and in some cases C-core+by extension, support for server certificate rotation.++* ServerSSLCertReloadTestWithClientAuth: test ability to rotate+  server's SSL cert for use in future channels with clients while not+  affecting any existing channel. The server requires client+  authentication.++* ServerSSLCertReloadTestWithoutClientAuth: like+  ServerSSLCertReloadTestWithClientAuth except that the server does+  not authenticate the client.++* ServerSSLCertReloadTestCertConfigReuse: tests gRPC Python's ability+  to deal with user's reuse of ServerCertificateConfig instances.++""""""++import os+import unittest+from concurrent import futures++import grpc+from tests.unit import resources+from tests.testing import _application_common+from tests.testing import _server_application+from tests.testing.proto import services_pb2_grpc++ca_1_pem = resources.cert_hier_1_root_ca_cert()+ca_2_pem = resources.cert_hier_2_root_ca_cert()++client_key_1_pem = resources.cert_hier_1_client_1_key()+client_chain_1_pem = '\n'.join([+    resources.cert_hier_1_client_1_cert(),+    resources.cert_hier_1_intermediate_ca_cert(),+])++client_key_2_pem = resources.cert_hier_2_client_1_key()+client_chain_2_pem = '\n'.join([+    resources.cert_hier_2_client_1_cert(),+    resources.cert_hier_2_intermediate_ca_cert(),+])++server_key_1_pem = resources.cert_hier_1_server_1_key()+server_cert_1_pem = '\n'.join([+    resources.cert_hier_1_server_1_cert(),+    resources.cert_hier_1_intermediate_ca_cert(),+])++server_key_2_pem = resources.cert_hier_2_server_1_key()+server_cert_2_pem = '\n'.join([+    resources.cert_hier_2_server_1_cert(),+    resources.cert_hier_2_intermediate_ca_cert(),+])+++class CertConfigFetcher(object):++    def __init__(self, ca_pem, key_pem, cert_pem, switch_cert_on_client_num):+        self.client_num = 0+        self.switch_cert_on_client_num = switch_cert_on_client_num+        # we simulate cb failures at 2 and 3+        assert self.switch_cert_on_client_num > 3+        self.cert_config = grpc.ssl_server_certificate_config(+            [(key_pem, cert_pem)],+            root_certificates=ca_pem,)++    def __call__(self):+        self.client_num += 1+        if self.client_num in (2, 3):+            raise ValueError(+                'just an error for fun, should not affect the test')+        if self.client_num != self.switch_cert_on_client_num:+            return None+        else:+            # do the switch+            ret = self.cert_config+            self.cert_config = None+            return ret+++class _ServerSSLCertReloadTest(object):++    def _do_setUp(self, with_client_auth):+        self.with_client_auth = with_client_auth+        self.server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))+        services_pb2_grpc.add_FirstServiceServicer_to_server(+            _server_application.FirstServiceServicer(), self.server)+        switch_cert_on_client_num = 10+        initial_cert_config = grpc.ssl_server_certificate_config(+            [(server_key_1_pem, server_cert_1_pem)], root_certificates=ca_2_pem)+        cert_config_fetcher = CertConfigFetcher(ca_1_pem, server_key_2_pem,+                                                server_cert_2_pem,+                                                switch_cert_on_client_num)+        server_credentials = grpc.ssl_server_credentials_dynamic_cert_config(+            initial_cert_config,+            cert_config_fetcher,+            require_client_auth=self.with_client_auth)+        self.port = self.server.add_secure_port('[::]:0', server_credentials)+        self.server.start()++    def _do_tearDown(self):+        if self.server:+            self.server.stop(0)++    def _perform_rpc(self, client_stub, expect_success):+        # we don't care about the actual response of the rpc; only+        # whether we can perform it or not, and if not, the reason+        # must be ""connect failed""+        if expect_success:+            client_stub.UnUn(_application_common.UNARY_UNARY_REQUEST)+        else:+            with self.assertRaises(grpc.RpcError) as exc:+                client_stub.UnUn(_application_common.UNARY_UNARY_REQUEST)+            self.assertEqual(exc.exception.code(), grpc.StatusCode.UNAVAILABLE)+            self.assertEqual(exc.exception.details(), 'Connect Failed')","it's in the similar vein as my earlier question about checking `stderr` (for specific cause of a failure, i.e., ""client rejects server"" vs ""server rejects client""): lacking a defined api to get at the specific reason for the failure, i resort to checking the `""Connect Failed""` message, i.e., the channel might have been `UNAVAILABLE` due to some other ""unexpected"" (by the test) reason.i'm not saying what i'm doing is appropriate; just trying to be clear what i'm trying to do. other suggestions on that? or just remove the `Connect Failed` check and live with it? :)",
1170852,cauthu,https://api.github.com/repos/grpc/grpc/pulls/13188,150616343,2017-11-13T17:56:22Z,src/python/grpcio_tests/tests/unit/_server_ssl_cert_config_test.py,"@@ -0,0 +1,357 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""+This tests server certificate rotation support.++Here we test various aspects of gRPC Python, and in some cases C-core+by extension, support for server certificate rotation.++* ServerSSLCertReloadTestWithClientAuth: test ability to rotate+  server's SSL cert for use in future channels with clients while not+  affecting any existing channel. The server requires client+  authentication.++* ServerSSLCertReloadTestWithoutClientAuth: like+  ServerSSLCertReloadTestWithClientAuth except that the server does+  not authenticate the client.++* ServerSSLCertReloadTestCertConfigReuse: tests gRPC Python's ability+  to deal with user's reuse of ServerCertificateConfig instances.++""""""++import os+import unittest+from concurrent import futures++import grpc+from tests.unit import resources+from tests.testing import _application_common+from tests.testing import _server_application+from tests.testing.proto import services_pb2_grpc++ca_1_pem = resources.cert_hier_1_root_ca_cert()+ca_2_pem = resources.cert_hier_2_root_ca_cert()++client_key_1_pem = resources.cert_hier_1_client_1_key()+client_chain_1_pem = '\n'.join([+    resources.cert_hier_1_client_1_cert(),+    resources.cert_hier_1_intermediate_ca_cert(),+])++client_key_2_pem = resources.cert_hier_2_client_1_key()+client_chain_2_pem = '\n'.join([+    resources.cert_hier_2_client_1_cert(),+    resources.cert_hier_2_intermediate_ca_cert(),+])++server_key_1_pem = resources.cert_hier_1_server_1_key()+server_cert_1_pem = '\n'.join([+    resources.cert_hier_1_server_1_cert(),+    resources.cert_hier_1_intermediate_ca_cert(),+])++server_key_2_pem = resources.cert_hier_2_server_1_key()+server_cert_2_pem = '\n'.join([+    resources.cert_hier_2_server_1_cert(),+    resources.cert_hier_2_intermediate_ca_cert(),+])+++class CertConfigFetcher(object):++    def __init__(self, ca_pem, key_pem, cert_pem, switch_cert_on_client_num):+        self.client_num = 0+        self.switch_cert_on_client_num = switch_cert_on_client_num+        # we simulate cb failures at 2 and 3+        assert self.switch_cert_on_client_num > 3+        self.cert_config = grpc.ssl_server_certificate_config(+            [(key_pem, cert_pem)],+            root_certificates=ca_pem,)++    def __call__(self):+        self.client_num += 1+        if self.client_num in (2, 3):+            raise ValueError(+                'just an error for fun, should not affect the test')+        if self.client_num != self.switch_cert_on_client_num:+            return None+        else:+            # do the switch+            ret = self.cert_config+            self.cert_config = None+            return ret+++class _ServerSSLCertReloadTest(object):++    def _do_setUp(self, with_client_auth):+        self.with_client_auth = with_client_auth+        self.server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))+        services_pb2_grpc.add_FirstServiceServicer_to_server(+            _server_application.FirstServiceServicer(), self.server)+        switch_cert_on_client_num = 10+        initial_cert_config = grpc.ssl_server_certificate_config(+            [(server_key_1_pem, server_cert_1_pem)], root_certificates=ca_2_pem)+        cert_config_fetcher = CertConfigFetcher(ca_1_pem, server_key_2_pem,+                                                server_cert_2_pem,+                                                switch_cert_on_client_num)+        server_credentials = grpc.ssl_server_credentials_dynamic_cert_config(+            initial_cert_config,+            cert_config_fetcher,+            require_client_auth=self.with_client_auth)+        self.port = self.server.add_secure_port('[::]:0', server_credentials)+        self.server.start()++    def _do_tearDown(self):+        if self.server:+            self.server.stop(0)++    def _perform_rpc(self, client_stub, expect_success):+        # we don't care about the actual response of the rpc; only+        # whether we can perform it or not, and if not, the reason+        # must be ""connect failed""+        if expect_success:+            client_stub.UnUn(_application_common.UNARY_UNARY_REQUEST)+        else:+            with self.assertRaises(grpc.RpcError) as exc:+                client_stub.UnUn(_application_common.UNARY_UNARY_REQUEST)+            self.assertEqual(exc.exception.code(), grpc.StatusCode.UNAVAILABLE)+            self.assertEqual(exc.exception.details(), 'Connect Failed')++    def _create_client_stub(self,+                            root_certificates=None,+                            private_key=None,+                            certificate_chain=None):+        return services_pb2_grpc.FirstServiceStub(+            grpc.secure_channel('localhost:{}'.format(self.port),+                                grpc.ssl_channel_credentials(+                                    root_certificates=root_certificates,+                                    private_key=private_key,+                                    certificate_chain=certificate_chain)))++    def _do_one_shot_client_rpc(self,+                                expect_success,+                                root_certificates=None,+                                private_key=None,+                                certificate_chain=None):+        client_stub = self._create_client_stub(+            root_certificates=root_certificates,+            private_key=private_key,+            certificate_chain=certificate_chain)+        self._perform_rpc(client_stub, expect_success)+        del client_stub++    def _do_common_test_recipe(self):+        # things should work...+        self._do_one_shot_client_rpc(+            True,+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # client should reject server...+        # fails because client trusts ca2 and so will reject server+        self._do_one_shot_client_rpc(+            False,+            root_certificates=ca_2_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # should work again...+        self._do_one_shot_client_rpc(+            True,+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # if with_client_auth, then client should be rejected by+        # server because client uses key/cert1, but server trusts ca2,+        # so server will reject+        self._do_one_shot_client_rpc(+            not self.with_client_auth,+            root_certificates=ca_1_pem,+            private_key=client_key_1_pem,+            certificate_chain=client_chain_1_pem)++        # one more time, client should be rejected by server if+        # with_client_auth+        self._do_one_shot_client_rpc(+            not self.with_client_auth,+            root_certificates=ca_1_pem,+            private_key=client_key_1_pem,+            certificate_chain=client_chain_1_pem)++        # should work again...+        self._do_one_shot_client_rpc(+            True,+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # and again...+        self._do_one_shot_client_rpc(+            True,+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # now create the ""persistent"" clients+        persistent_client_stub_A = self._create_client_stub(+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)+        self._perform_rpc(persistent_client_stub_A, True)++        persistent_client_stub_B = self._create_client_stub(+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)+        self._perform_rpc(persistent_client_stub_B, True)++        # moment of truth!! client should reject server because the+        # server switch cert...+        self._do_one_shot_client_rpc(+            False,+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # now should work again...+        self._do_one_shot_client_rpc(+            True,+            root_certificates=ca_2_pem,+            private_key=client_key_1_pem,+            certificate_chain=client_chain_1_pem)++        # and again...+        self._do_one_shot_client_rpc(+            True,+            root_certificates=ca_2_pem,+            private_key=client_key_1_pem,+            certificate_chain=client_chain_1_pem)++        # client should be rejected by server if with_client_auth+        self._do_one_shot_client_rpc(+            not self.with_client_auth,+            root_certificates=ca_2_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # here client should reject server...+        self._do_one_shot_client_rpc(+            False,+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # persistent clients should continue to work+        self._perform_rpc(persistent_client_stub_A, True)+        self._perform_rpc(persistent_client_stub_B, True)+++class ServerSSLCertConfigFetcherParamsChecks(unittest.TestCase):++    def test_params_checks(self):+        for initial_config, subsequent_config_fetcher, exc_msg in (",sure. (it used to be list of length 3 :),
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/13058,150644292,2017-11-13T19:42:36Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc,"@@ -108,11 +107,11 @@ static void grpc_ares_request_unref(grpc_exec_ctx* exec_ctx,          the newly created exec_ctx, since the caller has been warned not to          acquire locks in on_done. ares_dns_resolver is using combiner to          protect resources needed by on_done. */-      grpc_exec_ctx new_exec_ctx = GRPC_EXEC_CTX_INIT;",This should no longer be needed,
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/13058,150644669,2017-11-13T19:44:05Z,src/core/ext/filters/client_channel/subchannel_index.cc,"@@ -135,17 +132,16 @@ void grpc_subchannel_index_shutdown(void) {  void grpc_subchannel_index_unref(void) {   if (gpr_unref(&g_refcount)) {-    grpc_exec_ctx exec_ctx = GRPC_EXEC_CTX_INIT;+    ExecCtx _local_exec_ctx;",This should no longer be necessary,
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/13058,150648892,2017-11-13T20:00:02Z,src/core/lib/iomgr/exec_ctx.h,"@@ -74,56 +75,87 @@ struct grpc_exec_ctx {   uintptr_t flags;   unsigned starting_cpu;   void* check_ready_to_finish_arg;-  bool (*check_ready_to_finish)(grpc_exec_ctx* exec_ctx, void* arg);+  bool (*check_ready_to_finish)(void* arg);    bool now_is_valid;   grpc_millis now;+  const char* creator; }; -/* initializer for grpc_exec_ctx:-   prefer to use GRPC_EXEC_CTX_INIT whenever possible */-#define GRPC_EXEC_CTX_INITIALIZER(flags, finish_check, finish_check_arg) \-  {                                                                      \-    GRPC_CLOSURE_LIST_INIT, NULL, NULL, flags, gpr_cpu_current_cpu(),    \-        finish_check_arg, finish_check, false, 0                         \-  }--/* initialize an execution context at the top level of an API call into grpc-   (this is safe to use elsewhere, though possibly not as efficient) */-#define GRPC_EXEC_CTX_INIT \-  GRPC_EXEC_CTX_INITIALIZER(GRPC_EXEC_CTX_FLAG_IS_FINISHED, NULL, NULL)- extern grpc_closure_scheduler* grpc_schedule_on_exec_ctx; -bool grpc_exec_ctx_has_work(grpc_exec_ctx* exec_ctx);+bool grpc_exec_ctx_has_work();  /** Flush any work that has been enqueued onto this grpc_exec_ctx.  *  Caller must guarantee that no interfering locks are held.  *  Returns true if work was performed, false otherwise. */-bool grpc_exec_ctx_flush(grpc_exec_ctx* exec_ctx);+bool grpc_exec_ctx_flush(); /** Finish any pending work for a grpc_exec_ctx. Must be called before  *  the instance is destroyed, or work may be lost. */-void grpc_exec_ctx_finish(grpc_exec_ctx* exec_ctx);+void grpc_exec_ctx_finish(); /** Returns true if we'd like to leave this execution context as soon as     possible: useful for deciding whether to do something more or not depending     on outside context */-bool grpc_exec_ctx_ready_to_finish(grpc_exec_ctx* exec_ctx);+bool grpc_exec_ctx_ready_to_finish(); /** A finish check that is never ready to finish */-bool grpc_never_ready_to_finish(grpc_exec_ctx* exec_ctx, void* arg_ignored);+bool grpc_never_ready_to_finish(void* arg_ignored); /** A finish check that is always ready to finish */-bool grpc_always_ready_to_finish(grpc_exec_ctx* exec_ctx, void* arg_ignored);+bool grpc_always_ready_to_finish(void* arg_ignored);  void grpc_exec_ctx_global_init(void);  void grpc_exec_ctx_global_init(void); void grpc_exec_ctx_global_shutdown(void); -grpc_millis grpc_exec_ctx_now(grpc_exec_ctx* exec_ctx);-void grpc_exec_ctx_invalidate_now(grpc_exec_ctx* exec_ctx);+grpc_millis grpc_exec_ctx_now();+void grpc_exec_ctx_invalidate_now(); gpr_timespec grpc_millis_to_timespec(grpc_millis millis, gpr_clock_type clock); grpc_millis grpc_timespec_to_millis_round_down(gpr_timespec timespec); grpc_millis grpc_timespec_to_millis_round_up(gpr_timespec timespec); +inline grpc_exec_ctx make_exec_ctx(grpc_exec_ctx r) {+  grpc_exec_ctx_flush();+  return r;+}++class ExecCtx {+ public:+  ExecCtx();+  ExecCtx(uintptr_t fl, bool (*finish_check)(void* arg),+          void* finish_check_arg);+  ~ExecCtx();++  grpc_closure_list closure_list;+  /** currently active combiner: updated only via combiner.c */+  grpc_combiner* active_combiner;","We'll want to declare a friend relationship eventually, but for now can we do this:``` c++public:struct CombinerData {  grpc_combiner* active_combiner;  grpc_combiner* last_combiner;};// only to be used by grpc-combiner codeCombinerData* combiner_data() { return combiner_data_; }private:CombinerData combiner_data_;```",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/13058,150650456,2017-11-13T20:06:31Z,src/core/lib/iomgr/exec_ctx.h,"@@ -74,56 +75,87 @@ struct grpc_exec_ctx {   uintptr_t flags;   unsigned starting_cpu;   void* check_ready_to_finish_arg;-  bool (*check_ready_to_finish)(grpc_exec_ctx* exec_ctx, void* arg);+  bool (*check_ready_to_finish)(void* arg);    bool now_is_valid;   grpc_millis now;+  const char* creator; }; -/* initializer for grpc_exec_ctx:-   prefer to use GRPC_EXEC_CTX_INIT whenever possible */-#define GRPC_EXEC_CTX_INITIALIZER(flags, finish_check, finish_check_arg) \-  {                                                                      \-    GRPC_CLOSURE_LIST_INIT, NULL, NULL, flags, gpr_cpu_current_cpu(),    \-        finish_check_arg, finish_check, false, 0                         \-  }--/* initialize an execution context at the top level of an API call into grpc-   (this is safe to use elsewhere, though possibly not as efficient) */-#define GRPC_EXEC_CTX_INIT \-  GRPC_EXEC_CTX_INITIALIZER(GRPC_EXEC_CTX_FLAG_IS_FINISHED, NULL, NULL)- extern grpc_closure_scheduler* grpc_schedule_on_exec_ctx; -bool grpc_exec_ctx_has_work(grpc_exec_ctx* exec_ctx);+bool grpc_exec_ctx_has_work();  /** Flush any work that has been enqueued onto this grpc_exec_ctx.  *  Caller must guarantee that no interfering locks are held.  *  Returns true if work was performed, false otherwise. */-bool grpc_exec_ctx_flush(grpc_exec_ctx* exec_ctx);+bool grpc_exec_ctx_flush(); /** Finish any pending work for a grpc_exec_ctx. Must be called before  *  the instance is destroyed, or work may be lost. */-void grpc_exec_ctx_finish(grpc_exec_ctx* exec_ctx);+void grpc_exec_ctx_finish(); /** Returns true if we'd like to leave this execution context as soon as     possible: useful for deciding whether to do something more or not depending     on outside context */-bool grpc_exec_ctx_ready_to_finish(grpc_exec_ctx* exec_ctx);+bool grpc_exec_ctx_ready_to_finish(); /** A finish check that is never ready to finish */-bool grpc_never_ready_to_finish(grpc_exec_ctx* exec_ctx, void* arg_ignored);+bool grpc_never_ready_to_finish(void* arg_ignored); /** A finish check that is always ready to finish */-bool grpc_always_ready_to_finish(grpc_exec_ctx* exec_ctx, void* arg_ignored);+bool grpc_always_ready_to_finish(void* arg_ignored);  void grpc_exec_ctx_global_init(void);",Remove duplicate function decl,
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/13058,150651438,2017-11-13T20:10:38Z,src/core/lib/iomgr/exec_ctx.cc,"@@ -25,10 +25,46 @@ #include ""src/core/lib/iomgr/combiner.h"" #include ""src/core/lib/profiling/timers.h"" -bool grpc_exec_ctx_ready_to_finish(grpc_exec_ctx* exec_ctx) {+thread_local ExecCtx* exec_ctx = nullptr;++ExecCtx::ExecCtx()+    : closure_list(GRPC_CLOSURE_LIST_INIT),",Prefer member initializers to constructor initializers to avoid duplication... that is:```c++class ExecCtx {  /* ... */  const unsigned starting_cpu_ = gpr_cpu_current_cpu();};```,
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/13058,150652369,2017-11-13T20:14:41Z,src/core/lib/iomgr/exec_ctx.h,"@@ -74,56 +75,87 @@ struct grpc_exec_ctx {   uintptr_t flags;   unsigned starting_cpu;   void* check_ready_to_finish_arg;-  bool (*check_ready_to_finish)(grpc_exec_ctx* exec_ctx, void* arg);+  bool (*check_ready_to_finish)(void* arg);    bool now_is_valid;   grpc_millis now;+  const char* creator; }; -/* initializer for grpc_exec_ctx:-   prefer to use GRPC_EXEC_CTX_INIT whenever possible */-#define GRPC_EXEC_CTX_INITIALIZER(flags, finish_check, finish_check_arg) \-  {                                                                      \-    GRPC_CLOSURE_LIST_INIT, NULL, NULL, flags, gpr_cpu_current_cpu(),    \-        finish_check_arg, finish_check, false, 0                         \-  }--/* initialize an execution context at the top level of an API call into grpc-   (this is safe to use elsewhere, though possibly not as efficient) */-#define GRPC_EXEC_CTX_INIT \-  GRPC_EXEC_CTX_INITIALIZER(GRPC_EXEC_CTX_FLAG_IS_FINISHED, NULL, NULL)- extern grpc_closure_scheduler* grpc_schedule_on_exec_ctx; -bool grpc_exec_ctx_has_work(grpc_exec_ctx* exec_ctx);+bool grpc_exec_ctx_has_work();  /** Flush any work that has been enqueued onto this grpc_exec_ctx.  *  Caller must guarantee that no interfering locks are held.  *  Returns true if work was performed, false otherwise. */-bool grpc_exec_ctx_flush(grpc_exec_ctx* exec_ctx);+bool grpc_exec_ctx_flush(); /** Finish any pending work for a grpc_exec_ctx. Must be called before  *  the instance is destroyed, or work may be lost. */-void grpc_exec_ctx_finish(grpc_exec_ctx* exec_ctx);+void grpc_exec_ctx_finish(); /** Returns true if we'd like to leave this execution context as soon as     possible: useful for deciding whether to do something more or not depending     on outside context */-bool grpc_exec_ctx_ready_to_finish(grpc_exec_ctx* exec_ctx);+bool grpc_exec_ctx_ready_to_finish(); /** A finish check that is never ready to finish */-bool grpc_never_ready_to_finish(grpc_exec_ctx* exec_ctx, void* arg_ignored);+bool grpc_never_ready_to_finish(void* arg_ignored); /** A finish check that is always ready to finish */-bool grpc_always_ready_to_finish(grpc_exec_ctx* exec_ctx, void* arg_ignored);+bool grpc_always_ready_to_finish(void* arg_ignored);  void grpc_exec_ctx_global_init(void);  void grpc_exec_ctx_global_init(void); void grpc_exec_ctx_global_shutdown(void); -grpc_millis grpc_exec_ctx_now(grpc_exec_ctx* exec_ctx);-void grpc_exec_ctx_invalidate_now(grpc_exec_ctx* exec_ctx);+grpc_millis grpc_exec_ctx_now();+void grpc_exec_ctx_invalidate_now(); gpr_timespec grpc_millis_to_timespec(grpc_millis millis, gpr_clock_type clock); grpc_millis grpc_timespec_to_millis_round_down(gpr_timespec timespec); grpc_millis grpc_timespec_to_millis_round_up(gpr_timespec timespec); +inline grpc_exec_ctx make_exec_ctx(grpc_exec_ctx r) {+  grpc_exec_ctx_flush();+  return r;+}++class ExecCtx {+ public:+  ExecCtx();+  ExecCtx(uintptr_t fl, bool (*finish_check)(void* arg),+          void* finish_check_arg);+  ~ExecCtx();++  grpc_closure_list closure_list;+  /** currently active combiner: updated only via combiner.c */+  grpc_combiner* active_combiner;+  /** last active combiner in the active combiner list */+  grpc_combiner* last_combiner;+  uintptr_t flags;+  unsigned starting_cpu;+  void* check_ready_to_finish_arg;+  bool (*check_ready_to_finish)(void* arg);++  bool now_is_valid;+  grpc_millis now;++ private:+  ExecCtx* last_exec_ctx;+};++extern thread_local ExecCtx* exec_ctx;","We also need to check that thread_local is available everywhere we are.... IIRC shipping OSX or iPhone compilers don't provide support, meaning we may need to fall back to gpr_ library support",
1170852,cauthu,https://api.github.com/repos/grpc/grpc/pulls/13188,150657600,2017-11-13T20:36:57Z,src/python/grpcio_tests/tests/unit/_server_ssl_cert_config_test.py,"@@ -0,0 +1,357 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""+This tests server certificate rotation support.++Here we test various aspects of gRPC Python, and in some cases C-core+by extension, support for server certificate rotation.++* ServerSSLCertReloadTestWithClientAuth: test ability to rotate+  server's SSL cert for use in future channels with clients while not+  affecting any existing channel. The server requires client+  authentication.++* ServerSSLCertReloadTestWithoutClientAuth: like+  ServerSSLCertReloadTestWithClientAuth except that the server does+  not authenticate the client.++* ServerSSLCertReloadTestCertConfigReuse: tests gRPC Python's ability+  to deal with user's reuse of ServerCertificateConfig instances.++""""""++import os+import unittest+from concurrent import futures++import grpc+from tests.unit import resources+from tests.testing import _application_common+from tests.testing import _server_application+from tests.testing.proto import services_pb2_grpc++ca_1_pem = resources.cert_hier_1_root_ca_cert()+ca_2_pem = resources.cert_hier_2_root_ca_cert()++client_key_1_pem = resources.cert_hier_1_client_1_key()+client_chain_1_pem = '\n'.join([+    resources.cert_hier_1_client_1_cert(),+    resources.cert_hier_1_intermediate_ca_cert(),+])++client_key_2_pem = resources.cert_hier_2_client_1_key()+client_chain_2_pem = '\n'.join([+    resources.cert_hier_2_client_1_cert(),+    resources.cert_hier_2_intermediate_ca_cert(),+])++server_key_1_pem = resources.cert_hier_1_server_1_key()+server_cert_1_pem = '\n'.join([+    resources.cert_hier_1_server_1_cert(),+    resources.cert_hier_1_intermediate_ca_cert(),+])++server_key_2_pem = resources.cert_hier_2_server_1_key()+server_cert_2_pem = '\n'.join([+    resources.cert_hier_2_server_1_cert(),+    resources.cert_hier_2_intermediate_ca_cert(),+])+++class CertConfigFetcher(object):++    def __init__(self, ca_pem, key_pem, cert_pem, switch_cert_on_client_num):+        self.client_num = 0+        self.switch_cert_on_client_num = switch_cert_on_client_num+        # we simulate cb failures at 2 and 3+        assert self.switch_cert_on_client_num > 3+        self.cert_config = grpc.ssl_server_certificate_config(+            [(key_pem, cert_pem)],+            root_certificates=ca_pem,)++    def __call__(self):+        self.client_num += 1+        if self.client_num in (2, 3):+            raise ValueError(+                'just an error for fun, should not affect the test')+        if self.client_num != self.switch_cert_on_client_num:+            return None+        else:+            # do the switch+            ret = self.cert_config+            self.cert_config = None+            return ret+++class _ServerSSLCertReloadTest(object):++    def _do_setUp(self, with_client_auth):+        self.with_client_auth = with_client_auth+        self.server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))+        services_pb2_grpc.add_FirstServiceServicer_to_server(+            _server_application.FirstServiceServicer(), self.server)+        switch_cert_on_client_num = 10+        initial_cert_config = grpc.ssl_server_certificate_config(+            [(server_key_1_pem, server_cert_1_pem)], root_certificates=ca_2_pem)+        cert_config_fetcher = CertConfigFetcher(ca_1_pem, server_key_2_pem,+                                                server_cert_2_pem,+                                                switch_cert_on_client_num)+        server_credentials = grpc.ssl_server_credentials_dynamic_cert_config(+            initial_cert_config,+            cert_config_fetcher,+            require_client_auth=self.with_client_auth)+        self.port = self.server.add_secure_port('[::]:0', server_credentials)+        self.server.start()++    def _do_tearDown(self):+        if self.server:+            self.server.stop(0)++    def _perform_rpc(self, client_stub, expect_success):+        # we don't care about the actual response of the rpc; only+        # whether we can perform it or not, and if not, the reason+        # must be ""connect failed""+        if expect_success:+            client_stub.UnUn(_application_common.UNARY_UNARY_REQUEST)+        else:+            with self.assertRaises(grpc.RpcError) as exc:+                client_stub.UnUn(_application_common.UNARY_UNARY_REQUEST)+            self.assertEqual(exc.exception.code(), grpc.StatusCode.UNAVAILABLE)+            self.assertEqual(exc.exception.details(), 'Connect Failed')",done: removed the assertion on the exception `details() == 'Connect Failed'`,
1170852,cauthu,https://api.github.com/repos/grpc/grpc/pulls/13188,150658092,2017-11-13T20:39:04Z,src/python/grpcio_tests/tests/unit/_server_ssl_cert_config_test.py,"@@ -0,0 +1,357 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""+This tests server certificate rotation support.++Here we test various aspects of gRPC Python, and in some cases C-core+by extension, support for server certificate rotation.++* ServerSSLCertReloadTestWithClientAuth: test ability to rotate+  server's SSL cert for use in future channels with clients while not+  affecting any existing channel. The server requires client+  authentication.++* ServerSSLCertReloadTestWithoutClientAuth: like+  ServerSSLCertReloadTestWithClientAuth except that the server does+  not authenticate the client.++* ServerSSLCertReloadTestCertConfigReuse: tests gRPC Python's ability+  to deal with user's reuse of ServerCertificateConfig instances.++""""""++import os+import unittest+from concurrent import futures++import grpc+from tests.unit import resources+from tests.testing import _application_common+from tests.testing import _server_application+from tests.testing.proto import services_pb2_grpc++ca_1_pem = resources.cert_hier_1_root_ca_cert()",done: moved into the base class,
1170852,cauthu,https://api.github.com/repos/grpc/grpc/pulls/13188,150659021,2017-11-13T20:43:22Z,src/python/grpcio_tests/tests/unit/_server_ssl_cert_config_test.py,"@@ -0,0 +1,357 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""+This tests server certificate rotation support.++Here we test various aspects of gRPC Python, and in some cases C-core+by extension, support for server certificate rotation.++* ServerSSLCertReloadTestWithClientAuth: test ability to rotate+  server's SSL cert for use in future channels with clients while not+  affecting any existing channel. The server requires client+  authentication.++* ServerSSLCertReloadTestWithoutClientAuth: like+  ServerSSLCertReloadTestWithClientAuth except that the server does+  not authenticate the client.++* ServerSSLCertReloadTestCertConfigReuse: tests gRPC Python's ability+  to deal with user's reuse of ServerCertificateConfig instances.++""""""++import os+import unittest+from concurrent import futures++import grpc+from tests.unit import resources+from tests.testing import _application_common+from tests.testing import _server_application+from tests.testing.proto import services_pb2_grpc++ca_1_pem = resources.cert_hier_1_root_ca_cert()+ca_2_pem = resources.cert_hier_2_root_ca_cert()++client_key_1_pem = resources.cert_hier_1_client_1_key()+client_chain_1_pem = '\n'.join([+    resources.cert_hier_1_client_1_cert(),+    resources.cert_hier_1_intermediate_ca_cert(),+])++client_key_2_pem = resources.cert_hier_2_client_1_key()+client_chain_2_pem = '\n'.join([+    resources.cert_hier_2_client_1_cert(),+    resources.cert_hier_2_intermediate_ca_cert(),+])++server_key_1_pem = resources.cert_hier_1_server_1_key()+server_cert_1_pem = '\n'.join([+    resources.cert_hier_1_server_1_cert(),+    resources.cert_hier_1_intermediate_ca_cert(),+])++server_key_2_pem = resources.cert_hier_2_server_1_key()+server_cert_2_pem = '\n'.join([+    resources.cert_hier_2_server_1_cert(),+    resources.cert_hier_2_intermediate_ca_cert(),+])+++class CertConfigFetcher(object):++    def __init__(self, ca_pem, key_pem, cert_pem, switch_cert_on_client_num):+        self.client_num = 0+        self.switch_cert_on_client_num = switch_cert_on_client_num+        # we simulate cb failures at 2 and 3+        assert self.switch_cert_on_client_num > 3+        self.cert_config = grpc.ssl_server_certificate_config(+            [(key_pem, cert_pem)],+            root_certificates=ca_pem,)++    def __call__(self):+        self.client_num += 1+        if self.client_num in (2, 3):+            raise ValueError(+                'just an error for fun, should not affect the test')+        if self.client_num != self.switch_cert_on_client_num:+            return None+        else:+            # do the switch+            ret = self.cert_config+            self.cert_config = None+            return ret+++class _ServerSSLCertReloadTest(object):++    def _do_setUp(self, with_client_auth):+        self.with_client_auth = with_client_auth+        self.server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))+        services_pb2_grpc.add_FirstServiceServicer_to_server(+            _server_application.FirstServiceServicer(), self.server)+        switch_cert_on_client_num = 10+        initial_cert_config = grpc.ssl_server_certificate_config(+            [(server_key_1_pem, server_cert_1_pem)], root_certificates=ca_2_pem)+        cert_config_fetcher = CertConfigFetcher(ca_1_pem, server_key_2_pem,+                                                server_cert_2_pem,+                                                switch_cert_on_client_num)+        server_credentials = grpc.ssl_server_credentials_dynamic_cert_config(+            initial_cert_config,+            cert_config_fetcher,+            require_client_auth=self.with_client_auth)+        self.port = self.server.add_secure_port('[::]:0', server_credentials)+        self.server.start()++    def _do_tearDown(self):+        if self.server:+            self.server.stop(0)++    def _perform_rpc(self, client_stub, expect_success):+        # we don't care about the actual response of the rpc; only+        # whether we can perform it or not, and if not, the reason+        # must be ""connect failed""+        if expect_success:+            client_stub.UnUn(_application_common.UNARY_UNARY_REQUEST)+        else:+            with self.assertRaises(grpc.RpcError) as exc:+                client_stub.UnUn(_application_common.UNARY_UNARY_REQUEST)+            self.assertEqual(exc.exception.code(), grpc.StatusCode.UNAVAILABLE)+            self.assertEqual(exc.exception.details(), 'Connect Failed')++    def _create_client_stub(self,+                            root_certificates=None,+                            private_key=None,+                            certificate_chain=None):+        return services_pb2_grpc.FirstServiceStub(+            grpc.secure_channel('localhost:{}'.format(self.port),+                                grpc.ssl_channel_credentials(+                                    root_certificates=root_certificates,+                                    private_key=private_key,+                                    certificate_chain=certificate_chain)))++    def _do_one_shot_client_rpc(self,+                                expect_success,+                                root_certificates=None,+                                private_key=None,+                                certificate_chain=None):+        client_stub = self._create_client_stub(+            root_certificates=root_certificates,+            private_key=private_key,+            certificate_chain=certificate_chain)+        self._perform_rpc(client_stub, expect_success)+        del client_stub++    def _do_common_test_recipe(self):+        # things should work...+        self._do_one_shot_client_rpc(+            True,+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # client should reject server...+        # fails because client trusts ca2 and so will reject server+        self._do_one_shot_client_rpc(+            False,+            root_certificates=ca_2_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # should work again...+        self._do_one_shot_client_rpc(+            True,+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # if with_client_auth, then client should be rejected by+        # server because client uses key/cert1, but server trusts ca2,+        # so server will reject+        self._do_one_shot_client_rpc(+            not self.with_client_auth,+            root_certificates=ca_1_pem,+            private_key=client_key_1_pem,+            certificate_chain=client_chain_1_pem)++        # one more time, client should be rejected by server if+        # with_client_auth+        self._do_one_shot_client_rpc(+            not self.with_client_auth,+            root_certificates=ca_1_pem,+            private_key=client_key_1_pem,+            certificate_chain=client_chain_1_pem)++        # should work again...+        self._do_one_shot_client_rpc(+            True,+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # and again...+        self._do_one_shot_client_rpc(+            True,+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # now create the ""persistent"" clients+        persistent_client_stub_A = self._create_client_stub(+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)+        self._perform_rpc(persistent_client_stub_A, True)++        persistent_client_stub_B = self._create_client_stub(+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)+        self._perform_rpc(persistent_client_stub_B, True)++        # moment of truth!! client should reject server because the+        # server switch cert...+        self._do_one_shot_client_rpc(+            False,+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # now should work again...+        self._do_one_shot_client_rpc(+            True,+            root_certificates=ca_2_pem,+            private_key=client_key_1_pem,+            certificate_chain=client_chain_1_pem)++        # and again...+        self._do_one_shot_client_rpc(+            True,+            root_certificates=ca_2_pem,+            private_key=client_key_1_pem,+            certificate_chain=client_chain_1_pem)++        # client should be rejected by server if with_client_auth+        self._do_one_shot_client_rpc(+            not self.with_client_auth,+            root_certificates=ca_2_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # here client should reject server...+        self._do_one_shot_client_rpc(+            False,+            root_certificates=ca_1_pem,+            private_key=client_key_2_pem,+            certificate_chain=client_chain_2_pem)++        # persistent clients should continue to work+        self._perform_rpc(persistent_client_stub_A, True)+        self._perform_rpc(persistent_client_stub_B, True)+++class ServerSSLCertConfigFetcherParamsChecks(unittest.TestCase):++    def test_params_checks(self):+        for initial_config, subsequent_config_fetcher, exc_msg in (+            (None, str, 'initial certificate config must be specified'),+            (1, '1', 'certificate config fetcher must be callable'),):+            with self.assertRaises(ValueError) as exc:","exception context no longer needed since the it was used only to check the error message, and i'm not doing that any more since as you suggest earlier it's not advisable.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,150694670,2017-11-13T23:14:04Z,src/python/grpcio_tests/tests/unit/_server_ssl_cert_config_test.py,"@@ -263,38 +266,32 @@ def _do_common_test_recipe(self):  class ServerSSLCertConfigFetcherParamsChecks(unittest.TestCase): -    def test_params_checks(self):-        for initial_config, subsequent_config_fetcher, exc_msg in (-            (None, str, 'initial certificate config must be specified'),-            (1, '1', 'certificate config fetcher must be callable'),):-            with self.assertRaises(ValueError) as exc:-                grpc.ssl_server_credentials_dynamic_cert_config(-                    initial_config, subsequent_config_fetcher)-            self.assertEqual(exc.exception.message, exc_msg)+    def test_check_on_initial_config(self):+        with self.assertRaises(ValueError):+            grpc.ssl_server_credentials_dynamic_cert_config(None, str) +    def test_check_on_config_fetcher(self):+        with self.assertRaises(ValueError):+            grpc.ssl_server_credentials_dynamic_cert_config(1, '1') -class ServerSSLCertReloadTestWithClientAuth(_ServerSSLCertReloadTest,-                                            unittest.TestCase): -    def setUp(self):-        self._do_setUp(True)+class ServerSSLCertReloadTestWithClientAuth(_ServerSSLCertReloadTest):      def test(self):         self._do_common_test_recipe()  -class ServerSSLCertReloadTestWithoutClientAuth(_ServerSSLCertReloadTest,-                                               unittest.TestCase):+class ServerSSLCertReloadTestWithoutClientAuth(_ServerSSLCertReloadTest): -    def setUp(self):-        self._do_setUp(False)+    def __init__(self, *args, **kwargs):+        super(ServerSSLCertReloadTestWithoutClientAuth, self).__init__(*args, **kwargs)+        self.with_client_auth = False",... so why not make `with_client_auth` a parameter of `do_common_test_recipe`?,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,150696405,2017-11-13T23:24:13Z,src/python/grpcio_tests/tests/unit/_server_ssl_cert_config_test.py,"@@ -0,0 +1,357 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""+This tests server certificate rotation support.++Here we test various aspects of gRPC Python, and in some cases C-core+by extension, support for server certificate rotation.++* ServerSSLCertReloadTestWithClientAuth: test ability to rotate+  server's SSL cert for use in future channels with clients while not+  affecting any existing channel. The server requires client+  authentication.++* ServerSSLCertReloadTestWithoutClientAuth: like+  ServerSSLCertReloadTestWithClientAuth except that the server does+  not authenticate the client.++* ServerSSLCertReloadTestCertConfigReuse: tests gRPC Python's ability+  to deal with user's reuse of ServerCertificateConfig instances.+""""""++import abc+import os+import six+import unittest++from concurrent import futures++import grpc+from tests.unit import resources+from tests.testing import _application_common+from tests.testing import _server_application+from tests.testing.proto import services_pb2_grpc++class CertConfigFetcher(object):++    def __init__(self, ca_pem, key_pem, cert_pem, switch_cert_on_client_num):+        self.client_num = 0+        self.switch_cert_on_client_num = switch_cert_on_client_num+        # we simulate cb failures at 2 and 3+        assert self.switch_cert_on_client_num > 3+        self.cert_config = grpc.ssl_server_certificate_config(+            [(key_pem, cert_pem)],+            root_certificates=ca_pem,)++    def __call__(self):+        self.client_num += 1+        if self.client_num in (2, 3):+            raise ValueError(+                'just an error for fun, should not affect the test')+        if self.client_num != self.switch_cert_on_client_num:+            return None+        else:+            # do the switch+            ret = self.cert_config+            self.cert_config = None+            return ret+++class _ServerSSLCertReloadTest(six.with_metaclass(abc.ABCMeta, unittest.TestCase)):++    def __init__(self, *args, **kwargs):+        super(_ServerSSLCertReloadTest, self).__init__(*args, **kwargs)+        self.client_key_1_pem = resources.cert_hier_1_client_1_key()+        self.client_chain_1_pem = '\n'.join([+            resources.cert_hier_1_client_1_cert(),+            resources.cert_hier_1_intermediate_ca_cert(),+        ])+        self.client_key_2_pem = resources.cert_hier_2_client_1_key()+        self.client_chain_2_pem = '\n'.join([+            resources.cert_hier_2_client_1_cert(),+            resources.cert_hier_2_intermediate_ca_cert(),+        ])+        self.server_key_1_pem = resources.cert_hier_1_server_1_key()+        self.server_cert_1_pem = '\n'.join([+            resources.cert_hier_1_server_1_cert(),+            resources.cert_hier_1_intermediate_ca_cert(),+        ])+        self.server_key_2_pem = resources.cert_hier_2_server_1_key()+        self.server_cert_2_pem = '\n'.join([+            resources.cert_hier_2_server_1_cert(),+            resources.cert_hier_2_intermediate_ca_cert(),+        ])+        self.with_client_auth = True+        self.server = None+        self.port = None++    def setUp(self):+        self.server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))+        services_pb2_grpc.add_FirstServiceServicer_to_server(+            _server_application.FirstServiceServicer(), self.server)+        switch_cert_on_client_num = 10+        initial_cert_config = grpc.ssl_server_certificate_config(+            [(self.server_key_1_pem, self.server_cert_1_pem)],+            root_certificates=resources.cert_hier_2_root_ca_cert())+        cert_config_fetcher = CertConfigFetcher(resources.cert_hier_1_root_ca_cert(),+                                                self.server_key_2_pem,+                                                self.server_cert_2_pem,+                                                switch_cert_on_client_num)+        server_credentials = grpc.ssl_server_credentials_dynamic_cert_config(+            initial_cert_config,+            cert_config_fetcher,+            require_client_auth=self.with_client_auth)+        self.port = self.server.add_secure_port('[::]:0', server_credentials)+        self.server.start()++    def tearDown(self):+        if self.server:+            self.server.stop(0)++    def _perform_rpc(self, client_stub, expect_success):+        # we don't care about the actual response of the rpc; only+        # whether we can perform it or not, and if not, the reason+        # must be ""connect failed""+        if expect_success:+            client_stub.UnUn(_application_common.UNARY_UNARY_REQUEST)+        else:+            with self.assertRaises(grpc.RpcError) as exception_context:+                client_stub.UnUn(_application_common.UNARY_UNARY_REQUEST)+            self.assertEqual(exception_context.exception.code(), grpc.StatusCode.UNAVAILABLE)++    def _create_client_stub(self,","Insufficient use of `self` parameter to justify placing this at instance-scope. Devolve it to module-scope by swapping `port` for `self`. Since it will be called from the class, place it earlier-in-the-file-than (""above"") the class.",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/13233,150697313,2017-11-13T23:29:02Z,src/python/grpcio_health_checking/setup.py,"@@ -40,17 +53,28 @@     '': '.', } -SETUP_REQUIRES = (-    'grpcio-tools>={version}'.format(version=grpc_version.VERSION),)- INSTALL_REQUIRES = ('protobuf>=3.3.0',                     'grpcio>={version}'.format(version=grpc_version.VERSION),) -COMMAND_CLASS = {-    # Run preprocess from the repository *before* doing any packaging!-    'preprocess': health_commands.CopyProtoModules,-    'build_package_protos': health_commands.BuildPackageProtos,-}+try:+    # ensure we can load the _pb2_grpc module:+    from grpc_health.v1 import health_pb2_grpc as _pb2_grpc+    # if we can find the _pb2_grpc module, the package has already been built.+    SETUP_REQUIRES = ()+    COMMAND_CLASS = {+        # wire up commands to no-op not to break the external dependencies",https://github.com/grpc/grpc/blob/e52772451a7bbf4f3f7b72cfc369781fd74a6930/tools/run_tests/artifacts/build_artifact_python.sh#L69,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13233,150697870,2017-11-13T23:32:37Z,src/python/grpcio_health_checking/setup.py,"@@ -40,17 +53,28 @@     '': '.', } -SETUP_REQUIRES = (-    'grpcio-tools>={version}'.format(version=grpc_version.VERSION),)- INSTALL_REQUIRES = ('protobuf>=3.3.0',                     'grpcio>={version}'.format(version=grpc_version.VERSION),) -COMMAND_CLASS = {-    # Run preprocess from the repository *before* doing any packaging!-    'preprocess': health_commands.CopyProtoModules,-    'build_package_protos': health_commands.BuildPackageProtos,-}+try:+    # ensure we can load the _pb2_grpc module:+    from grpc_health.v1 import health_pb2_grpc as _pb2_grpc+    # if we can find the _pb2_grpc module, the package has already been built.+    SETUP_REQUIRES = ()+    COMMAND_CLASS = {+        # wire up commands to no-op not to break the external dependencies",Take a stab at it! The worst that happens is that we learn that it's a larger work item than anticipated and fall back on this instead. :-),
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/13233,150699934,2017-11-13T23:45:11Z,src/python/grpcio_reflection/setup.py,"@@ -41,17 +53,28 @@     '': '.', } -SETUP_REQUIRES = (-    'grpcio-tools>={version}'.format(version=grpc_version.VERSION),)- INSTALL_REQUIRES = ('protobuf>=3.3.0',                     'grpcio>={version}'.format(version=grpc_version.VERSION),) -COMMAND_CLASS = {-    # Run preprocess from the repository *before* doing any packaging!-    'preprocess': reflection_commands.CopyProtoModules,-    'build_package_protos': reflection_commands.BuildPackageProtos,-}+try:+    # ensure we can load the _pb2_grpc module:+    from grpc_reflection.v1alpha import reflection_pb2_grpc as _pb2_grpc+    # if we can find the _pb2_grpc module, the package has already been built.+    SETUP_REQUIRES = ()+    COMMAND_CLASS = {+        # wire up commands to no-op not to break the external dependencies+        'preprocess': _NoOpCommand,+        'build_package_protos': _NoOpCommand,+    }+except ImportError: # we are in the build environment+    import reflection_commands+    SETUP_REQUIRES = (+        'grpcio-tools=={version}'.format(version=grpc_version.VERSION),)+    COMMAND_CLASS = {+        # Run preprocess from the repository *before* doing any packaging!","I could have sworn I saw an ""h"" in any (anh).  Looks like my eyesight is just bad.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,150703280,2017-11-14T00:05:57Z,src/python/grpcio/grpc/_cython/_cygrpc/server.pyx.pxi,"@@ -17,6 +17,36 @@ cimport cpython import time  +cdef grpc_ssl_certificate_config_reload_status _server_cert_config_fetcher_wrapper(+        void* user_data, grpc_ssl_server_certificate_config **config) with gil:+  # We are not catching any exception here, because cython will+  # happily catch and ignore it, and will log for us, and also the+  # core lib will continue as if the cert has not changed, which is a+  # reasonable behavior.",`except Exception:` rather than `except:`.I think we should just do plain old ordinary Python logging: `logging.exception(<string message>)`.,
1170852,cauthu,https://api.github.com/repos/grpc/grpc/pulls/13188,150721169,2017-11-14T02:14:39Z,src/python/grpcio/grpc/_cython/_cygrpc/server.pyx.pxi,"@@ -17,6 +17,36 @@ cimport cpython import time  +cdef grpc_ssl_certificate_config_reload_status _server_cert_config_fetcher_wrapper(+        void* user_data, grpc_ssl_server_certificate_config **config) with gil:+  # We are not catching any exception here, because cython will+  # happily catch and ignore it, and will log for us, and also the+  # core lib will continue as if the cert has not changed, which is a+  # reasonable behavior.","tl;dr: done.so it seems like the logging does work when i run the a server outside of the testing environment: this is in `server.pyx.pxi`:```except Exception:    logging.exception('Error fetching certificate config')    return GRPC_SSL_CERTIFICATE_CONFIG_RELOAD_FAIL...elif not isinstance(cert_config_wrapper, ServerCertificateConfig):    logging.error('Error fetching certificate config: certificate '                  'config must be of type grpc.ServerCertificateConfig')```* make the config fetcher always raise an exception:```$ python foo.py server 1>/dev/nullERROR:root:Error fetching certificate configTraceback (most recent call last):  File ""src/python/grpcio/grpc/_cython/_cygrpc/server.pyx.pxi"", line 35, in grpc._cython.cygrpc._server_cert_config_fetcher_wrapper  File ""foo.py"", line 57, in __call__    raise Exception('ALWAYS RAISE')Exception: ALWAYS RAISEE1114 02:10:39.476019806   10443 security_connector.cc:694]  Failed fetching new server credentials, continuing to use previously-loaded credentials.^CTraceback (most recent call last):  File ""foo.py"", line 110, in <module>    time.sleep(100)KeyboardInterrupt$```* make the config fetcher always return a `1`:```$ python foo.py server 1>/dev/nullERROR:root:Error fetching certificate config: certificate config must be of type grpc.ServerCertificateConfigE1114 02:11:23.706952551   10474 security_connector.cc:694]  Failed fetching new server credentials, continuing to use previously-loaded credentials.^CTraceback (most recent call last):  File ""foo.py"", line 111, in <module>    time.sleep(100)KeyboardInterrupt$```",
1170852,cauthu,https://api.github.com/repos/grpc/grpc/pulls/13188,150726696,2017-11-14T03:01:42Z,src/python/grpcio/grpc/_cython/_cygrpc/server.pyx.pxi,"@@ -17,6 +17,36 @@ cimport cpython import time  +cdef grpc_ssl_certificate_config_reload_status _server_cert_config_fetcher_wrapper(+        void* user_data, grpc_ssl_server_certificate_config **config) with gil:+  # We are not catching any exception here, because cython will+  # happily catch and ignore it, and will log for us, and also the+  # core lib will continue as if the cert has not changed, which is a+  # reasonable behavior.","ok so it's probably error on my part that the logging messages did not show up in stderr during the test while they did when i ran programs outside the test: it might have been because i needed to remove `py27` (and then having to recreate it with `virtualenv py27`) before running the tests; otherwise the tests wouldn't pick up the change that i made to add the `logging.exception()` call.now that i've done that--ensure the tests use the updated code--i can see the expected error messages, e.g.:```D1114 03:00:13.398917976    5456 security_connector.cc:688]  No change in SSL server credentials.ERROR:root:Error fetching certificate config: certificate config must be of type grpc.ServerCertificateConfig, not listE1114 03:00:13.428699928    5456 security_connector.cc:694]  Failed fetching new server credentials, continuing to use previously-loaded credentials.Unexpected successes: []Test failureFAILED: py27.test.unit._server_ssl_cert_config_test.ServerSSLCertReloadTestWithClientAuth [ret=1, pid=5412, time=1.4sec]```",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,150898412,2017-11-14T17:06:21Z,src/python/grpcio_tests/tests/unit/_server_ssl_cert_config_test.py,"@@ -263,38 +266,32 @@ def _do_common_test_recipe(self):  class ServerSSLCertConfigFetcherParamsChecks(unittest.TestCase): -    def test_params_checks(self):-        for initial_config, subsequent_config_fetcher, exc_msg in (-            (None, str, 'initial certificate config must be specified'),-            (1, '1', 'certificate config fetcher must be callable'),):-            with self.assertRaises(ValueError) as exc:-                grpc.ssl_server_credentials_dynamic_cert_config(-                    initial_config, subsequent_config_fetcher)-            self.assertEqual(exc.exception.message, exc_msg)+    def test_check_on_initial_config(self):+        with self.assertRaises(ValueError):+            grpc.ssl_server_credentials_dynamic_cert_config(None, str) +    def test_check_on_config_fetcher(self):+        with self.assertRaises(ValueError):+            grpc.ssl_server_credentials_dynamic_cert_config(1, '1') -class ServerSSLCertReloadTestWithClientAuth(_ServerSSLCertReloadTest,-                                            unittest.TestCase): -    def setUp(self):-        self._do_setUp(True)+class ServerSSLCertReloadTestWithClientAuth(_ServerSSLCertReloadTest):      def test(self):         self._do_common_test_recipe()  -class ServerSSLCertReloadTestWithoutClientAuth(_ServerSSLCertReloadTest,-                                               unittest.TestCase):+class ServerSSLCertReloadTestWithoutClientAuth(_ServerSSLCertReloadTest): -    def setUp(self):-        self._do_setUp(False)+    def __init__(self, *args, **kwargs):+        super(ServerSSLCertReloadTestWithoutClientAuth, self).__init__(*args, **kwargs)+        self.with_client_auth = False",Let's not overthink this. This is an abstract super class. How do abstract super classes ask for things from concrete subclasses? They define abstract methods and they call those abstract methods and subclasses implement those abstract methods.So define a```py@abc.abstractmethoddef with_client_auth(self):  raise NotImplementedError()```in the superclass and implement it in the subclasses?,
1170852,cauthu,https://api.github.com/repos/grpc/grpc/pulls/13188,150907724,2017-11-14T17:38:58Z,src/python/grpcio_tests/tests/unit/_server_ssl_cert_config_test.py,"@@ -263,38 +266,32 @@ def _do_common_test_recipe(self):  class ServerSSLCertConfigFetcherParamsChecks(unittest.TestCase): -    def test_params_checks(self):-        for initial_config, subsequent_config_fetcher, exc_msg in (-            (None, str, 'initial certificate config must be specified'),-            (1, '1', 'certificate config fetcher must be callable'),):-            with self.assertRaises(ValueError) as exc:-                grpc.ssl_server_credentials_dynamic_cert_config(-                    initial_config, subsequent_config_fetcher)-            self.assertEqual(exc.exception.message, exc_msg)+    def test_check_on_initial_config(self):+        with self.assertRaises(ValueError):+            grpc.ssl_server_credentials_dynamic_cert_config(None, str) +    def test_check_on_config_fetcher(self):+        with self.assertRaises(ValueError):+            grpc.ssl_server_credentials_dynamic_cert_config(1, '1') -class ServerSSLCertReloadTestWithClientAuth(_ServerSSLCertReloadTest,-                                            unittest.TestCase): -    def setUp(self):-        self._do_setUp(True)+class ServerSSLCertReloadTestWithClientAuth(_ServerSSLCertReloadTest):      def test(self):         self._do_common_test_recipe()  -class ServerSSLCertReloadTestWithoutClientAuth(_ServerSSLCertReloadTest,-                                               unittest.TestCase):+class ServerSSLCertReloadTestWithoutClientAuth(_ServerSSLCertReloadTest): -    def setUp(self):-        self._do_setUp(False)+    def __init__(self, *args, **kwargs):+        super(ServerSSLCertReloadTestWithoutClientAuth, self).__init__(*args, **kwargs)+        self.with_client_auth = False",i've gone with```def require_client_auth(self):  return True```in the base class,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,150973075,2017-11-14T21:45:44Z,src/python/grpcio/grpc/_cython/_cygrpc/credentials.pyx.pxi,"@@ -254,34 +272,81 @@ def call_credentials_metadata_plugin(CredentialsMetadataPlugin plugin):   credentials.references.append(plugin)   return credentials -def server_credentials_ssl(pem_root_certs, pem_key_cert_pairs,-                           bint force_client_auth):-  pem_root_certs = str_to_bytes(pem_root_certs)+cdef const char* _get_c_pem_root_certs(pem_root_certs):   cdef char *c_pem_root_certs = NULL-  if pem_root_certs is not None: +  if pem_root_certs is not None:     c_pem_root_certs = pem_root_certs-  pem_key_cert_pairs = list(pem_key_cert_pairs)+  return c_pem_root_certs++cdef grpc_ssl_pem_key_cert_pair* _create_c_ssl_pem_key_cert_pairs(pem_key_cert_pairs):+  # return a malloc'ed grpc_ssl_pem_key_cert_pair from a _list_ of SslPemKeyCertPair   for pair in pem_key_cert_pairs:     if not isinstance(pair, SslPemKeyCertPair):       raise TypeError(""expected pem_key_cert_pairs to be sequence of ""                       ""SslPemKeyCertPair"")+  cdef size_t c_ssl_pem_key_cert_pairs_count = len(pem_key_cert_pairs)+  cdef grpc_ssl_pem_key_cert_pair* c_ssl_pem_key_cert_pairs = NULL+  with nogil:+    c_ssl_pem_key_cert_pairs = (+      <grpc_ssl_pem_key_cert_pair *>gpr_malloc(+        sizeof(grpc_ssl_pem_key_cert_pair) * c_ssl_pem_key_cert_pairs_count))+  for i in range(c_ssl_pem_key_cert_pairs_count):+    c_ssl_pem_key_cert_pairs[i] = (+      (<SslPemKeyCertPair>pem_key_cert_pairs[i]).c_pair)+  return c_ssl_pem_key_cert_pairs++def server_credentials_ssl(pem_root_certs, pem_key_cert_pairs,+                           bint force_client_auth):+  pem_root_certs = str_to_bytes(pem_root_certs)+  pem_key_cert_pairs = list(pem_key_cert_pairs)   cdef ServerCredentials credentials = ServerCredentials()-  credentials.references.append(pem_key_cert_pairs)   credentials.references.append(pem_root_certs)+  credentials.references.append(pem_key_cert_pairs)+  cdef char * c_pem_root_certs = _get_c_pem_root_certs(pem_root_certs)   credentials.c_ssl_pem_key_cert_pairs_count = len(pem_key_cert_pairs)-  with nogil:-    credentials.c_ssl_pem_key_cert_pairs = (-        <grpc_ssl_pem_key_cert_pair *>gpr_malloc(-            sizeof(grpc_ssl_pem_key_cert_pair) *-                credentials.c_ssl_pem_key_cert_pairs_count-        ))-  for i in range(credentials.c_ssl_pem_key_cert_pairs_count):-    credentials.c_ssl_pem_key_cert_pairs[i] = (-        (<SslPemKeyCertPair>pem_key_cert_pairs[i]).c_pair)-  credentials.c_credentials = grpc_ssl_server_credentials_create(-      c_pem_root_certs, credentials.c_ssl_pem_key_cert_pairs,-      credentials.c_ssl_pem_key_cert_pairs_count,-      GRPC_SSL_REQUEST_AND_REQUIRE_CLIENT_CERTIFICATE_AND_VERIFY if force_client_auth else GRPC_SSL_DONT_REQUEST_CLIENT_CERTIFICATE,-      NULL)+  credentials.c_ssl_pem_key_cert_pairs = _create_c_ssl_pem_key_cert_pairs(pem_key_cert_pairs)+  cdef grpc_ssl_server_certificate_config *c_cert_config = NULL+  c_cert_config = grpc_ssl_server_certificate_config_create(+    c_pem_root_certs, credentials.c_ssl_pem_key_cert_pairs,+    credentials.c_ssl_pem_key_cert_pairs_count)+  cdef grpc_ssl_server_credentials_options* c_options = NULL+  # C-core assumes ownership of c_cert_config+  c_options = grpc_ssl_server_credentials_create_options_using_config(+    GRPC_SSL_REQUEST_AND_REQUIRE_CLIENT_CERTIFICATE_AND_VERIFY if force_client_auth else GRPC_SSL_DONT_REQUEST_CLIENT_CERTIFICATE,+    c_cert_config)+  # C-core assumes ownership of c_options+  credentials.c_credentials = grpc_ssl_server_credentials_create_with_options(c_options)   return credentials +def server_certificate_config_ssl(pem_root_certs, pem_key_cert_pairs):+  pem_root_certs = str_to_bytes(pem_root_certs)+  pem_key_cert_pairs = list(pem_key_cert_pairs)+  cdef ServerCertificateConfig cert_config = ServerCertificateConfig()+  cert_config.references.append(pem_root_certs)+  cert_config.references.append(pem_key_cert_pairs)+  cert_config.c_pem_root_certs = _get_c_pem_root_certs(pem_root_certs)+  cert_config.c_ssl_pem_key_cert_pairs_count = len(pem_key_cert_pairs)+  cert_config.c_ssl_pem_key_cert_pairs = _create_c_ssl_pem_key_cert_pairs(pem_key_cert_pairs)+  cert_config.c_cert_config = grpc_ssl_server_certificate_config_create(+    cert_config.c_pem_root_certs, cert_config.c_ssl_pem_key_cert_pairs,+    cert_config.c_ssl_pem_key_cert_pairs_count)+  return cert_config++def server_credentials_ssl_dynamic_cert_config(initial_cert_config,+                                               cert_config_fetcher,+                                               bint force_client_auth):+  if initial_cert_config is None:+    raise ValueError('initial certificate config must be specified')+  if not callable(cert_config_fetcher):+    raise ValueError('certificate config fetcher must be callable')+  cdef ServerCredentials credentials = ServerCredentials()+  credentials.initial_cert_config = initial_cert_config+  credentials.cert_config_fetcher = cert_config_fetcher+  cdef grpc_ssl_server_credentials_options* c_options = NULL+  c_options = grpc_ssl_server_credentials_create_options_using_config_fetcher(+    GRPC_SSL_REQUEST_AND_REQUIRE_CLIENT_CERTIFICATE_AND_VERIFY if force_client_auth else GRPC_SSL_DONT_REQUEST_CLIENT_CERTIFICATE,",This large conditional expression looks like it should be spread across three lines? We don't have a linter running on Cython code but we do try to keep it limited to seventy-nine columns wide.,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,150979279,2017-11-14T22:11:26Z,src/python/grpcio/grpc/_cython/_cygrpc/credentials.pyx.pxi,"@@ -254,34 +272,81 @@ def call_credentials_metadata_plugin(CredentialsMetadataPlugin plugin):   credentials.references.append(plugin)   return credentials -def server_credentials_ssl(pem_root_certs, pem_key_cert_pairs,-                           bint force_client_auth):-  pem_root_certs = str_to_bytes(pem_root_certs)+cdef const char* _get_c_pem_root_certs(pem_root_certs):   cdef char *c_pem_root_certs = NULL-  if pem_root_certs is not None: +  if pem_root_certs is not None:     c_pem_root_certs = pem_root_certs-  pem_key_cert_pairs = list(pem_key_cert_pairs)+  return c_pem_root_certs++cdef grpc_ssl_pem_key_cert_pair* _create_c_ssl_pem_key_cert_pairs(pem_key_cert_pairs):+  # return a malloc'ed grpc_ssl_pem_key_cert_pair from a _list_ of SslPemKeyCertPair   for pair in pem_key_cert_pairs:     if not isinstance(pair, SslPemKeyCertPair):       raise TypeError(""expected pem_key_cert_pairs to be sequence of ""                       ""SslPemKeyCertPair"")+  cdef size_t c_ssl_pem_key_cert_pairs_count = len(pem_key_cert_pairs)+  cdef grpc_ssl_pem_key_cert_pair* c_ssl_pem_key_cert_pairs = NULL+  with nogil:+    c_ssl_pem_key_cert_pairs = (+      <grpc_ssl_pem_key_cert_pair *>gpr_malloc(+        sizeof(grpc_ssl_pem_key_cert_pair) * c_ssl_pem_key_cert_pairs_count))+  for i in range(c_ssl_pem_key_cert_pairs_count):+    c_ssl_pem_key_cert_pairs[i] = (+      (<SslPemKeyCertPair>pem_key_cert_pairs[i]).c_pair)+  return c_ssl_pem_key_cert_pairs++def server_credentials_ssl(pem_root_certs, pem_key_cert_pairs,+                           bint force_client_auth):+  pem_root_certs = str_to_bytes(pem_root_certs)+  pem_key_cert_pairs = list(pem_key_cert_pairs)   cdef ServerCredentials credentials = ServerCredentials()-  credentials.references.append(pem_key_cert_pairs)   credentials.references.append(pem_root_certs)+  credentials.references.append(pem_key_cert_pairs)+  cdef char * c_pem_root_certs = _get_c_pem_root_certs(pem_root_certs)   credentials.c_ssl_pem_key_cert_pairs_count = len(pem_key_cert_pairs)-  with nogil:-    credentials.c_ssl_pem_key_cert_pairs = (-        <grpc_ssl_pem_key_cert_pair *>gpr_malloc(-            sizeof(grpc_ssl_pem_key_cert_pair) *-                credentials.c_ssl_pem_key_cert_pairs_count-        ))-  for i in range(credentials.c_ssl_pem_key_cert_pairs_count):-    credentials.c_ssl_pem_key_cert_pairs[i] = (-        (<SslPemKeyCertPair>pem_key_cert_pairs[i]).c_pair)-  credentials.c_credentials = grpc_ssl_server_credentials_create(-      c_pem_root_certs, credentials.c_ssl_pem_key_cert_pairs,-      credentials.c_ssl_pem_key_cert_pairs_count,-      GRPC_SSL_REQUEST_AND_REQUIRE_CLIENT_CERTIFICATE_AND_VERIFY if force_client_auth else GRPC_SSL_DONT_REQUEST_CLIENT_CERTIFICATE,-      NULL)+  credentials.c_ssl_pem_key_cert_pairs = _create_c_ssl_pem_key_cert_pairs(pem_key_cert_pairs)+  cdef grpc_ssl_server_certificate_config *c_cert_config = NULL+  c_cert_config = grpc_ssl_server_certificate_config_create(+    c_pem_root_certs, credentials.c_ssl_pem_key_cert_pairs,+    credentials.c_ssl_pem_key_cert_pairs_count)+  cdef grpc_ssl_server_credentials_options* c_options = NULL+  # C-core assumes ownership of c_cert_config+  c_options = grpc_ssl_server_credentials_create_options_using_config(+    GRPC_SSL_REQUEST_AND_REQUIRE_CLIENT_CERTIFICATE_AND_VERIFY if force_client_auth else GRPC_SSL_DONT_REQUEST_CLIENT_CERTIFICATE,+    c_cert_config)+  # C-core assumes ownership of c_options+  credentials.c_credentials = grpc_ssl_server_credentials_create_with_options(c_options)   return credentials +def server_certificate_config_ssl(pem_root_certs, pem_key_cert_pairs):+  pem_root_certs = str_to_bytes(pem_root_certs)+  pem_key_cert_pairs = list(pem_key_cert_pairs)+  cdef ServerCertificateConfig cert_config = ServerCertificateConfig()+  cert_config.references.append(pem_root_certs)+  cert_config.references.append(pem_key_cert_pairs)+  cert_config.c_pem_root_certs = _get_c_pem_root_certs(pem_root_certs)+  cert_config.c_ssl_pem_key_cert_pairs_count = len(pem_key_cert_pairs)+  cert_config.c_ssl_pem_key_cert_pairs = _create_c_ssl_pem_key_cert_pairs(pem_key_cert_pairs)+  cert_config.c_cert_config = grpc_ssl_server_certificate_config_create(+    cert_config.c_pem_root_certs, cert_config.c_ssl_pem_key_cert_pairs,+    cert_config.c_ssl_pem_key_cert_pairs_count)+  return cert_config++def server_credentials_ssl_dynamic_cert_config(initial_cert_config,+                                               cert_config_fetcher,+                                               bint force_client_auth):+  if initial_cert_config is None:+    raise ValueError('initial certificate config must be specified')+  if not callable(cert_config_fetcher):+    raise ValueError('certificate config fetcher must be callable')+  cdef ServerCredentials credentials = ServerCredentials()+  credentials.initial_cert_config = initial_cert_config+  credentials.cert_config_fetcher = cert_config_fetcher+  cdef grpc_ssl_server_credentials_options* c_options = NULL+  c_options = grpc_ssl_server_credentials_create_options_using_config_fetcher(+    GRPC_SSL_REQUEST_AND_REQUIRE_CLIENT_CERTIFICATE_AND_VERIFY if force_client_auth else GRPC_SSL_DONT_REQUEST_CLIENT_CERTIFICATE,","Not 1, because [we never use backslash](https://google.github.io/styleguide/pyguide.html?showone=Line_length#Line_length). Not 2, because we avoid assigning a value to a field until after determining that the value assigned to the field is the right value to assign to the field. 3 looks okay, but I was thinking more along the lines of 4:```pyc_options = grpc_ssl_server_credentials_create_options_using_config_fetcher(    GRPC_SSL_REQUEST_AND_REQUIRE_CLIENT_CERTIFICATE_AND_VERIFY    if force_client_auth else    GRPC_SSL_DONT_REQUEST_CLIENT_CERTIFICATE,    c_cert_config)```. We almost always keep to the rule ""if a conditional expression doesn't fit on one line, refactor it into a proper `if/else`"", but I think this is a reasonable place to use the embedding of the conditional expression within the function call to avoid backslash continuation or a local field.3 is okay too.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13277,151259565,2017-11-15T21:39:07Z,src/core/lib/iomgr/polling_interface.h,"@@ -0,0 +1,167 @@+/*+ *+ * Copyright 2015 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_IOMGR_POLLING_INTERFACE_H+#define GRPC_CORE_LIB_IOMGR_POLLING_INTERFACE_H++#include <grpc/support/port_platform.h>+#include <grpc/support/sync.h>+#include <grpc/support/time.h>++#include ""src/core/lib/iomgr/exec_ctx.h""++#ifndef NDEBUG+extern grpc_tracer_flag grpc_trace_fd_refcount;+#endif++namespace grpc_core {++// Forward declarations+class PollingJoin;++// A Pollable is an object that can be polled+// Polling engines derive from this interface and implement+// This interface should not be implemented outside of a polling engine+class Pollable {};++// A PollableSet is a front-end interface to Poller & PollingJoin,+// collecting common methods.+// In many situations we don't care which we're dealing with, and so this class+// serves to abstract away that detail+class PollableSet {","David and Sree and I talked.  We think this should be called PollableCollection, because it doesn't actually offer the property that each element is unique.  If you add the same Pollable to a PollableCollection twice and then remove it once, it will still be there; removing it a second time will remove it completely.(I realize that the above behavior differs by polling engine, but I think the above is true based on the semantics that this API is intended to support.)",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13411,151281586,2017-11-15T23:20:28Z,tools/interop_matrix/client_matrix.py,"@@ -64,14 +64,14 @@ def get_github_repo(lang):         'v1.6.1',         'v1.7.0',     ],-    #'python': [-        #'v1.0.x',  #Fail to run the test. #13230.-    #    'v1.1.4',-    #    'v1.2.5',-    #    'v1.3.9',-    #    'v1.4.2',-    #    'v1.6.6',-    #],+    'python': [+        'v1.0.x',  #Fail to run the test. #13230.+        'v1.1.4',+        'v1.2.5',+        'v1.3.9',+        'v1.4.2',+        'v1.6.6',",Any desire to add a `v1.7.x` tag to this list?,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13411,151281877,2017-11-15T23:21:59Z,tools/interop_matrix/testcases/python__master,"@@ -0,0 +1,20 @@+#!/bin/bash+echo ""Testing ${docker_image:=grpc_interop_python:797ca293-94e8-48d4-92e9-a4d52fcfcca9}""",It's surprising to me that fixing this problem involves adding this whole large file to the codebase - was this an inadvertent addition or does this need to be here?,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/13409,151510509,2017-11-16T19:15:00Z,test/cpp/qps/client_async.cc,"@@ -248,6 +248,17 @@ class AsyncClient : public ClientImpl<StubType, RequestType> {     ClientRpcContext* ctx = ClientRpcContext::detag(got_tag);     std::mutex* shutdown_mu = &shutdown_state_[thread_idx]->mutex;     shutdown_mu->lock();+    if (shutdown_state_[thread_idx]->shutdown) {+      ctx->TryCancel();+      delete ctx;+      while (cli_cqs_[cq_[thread_idx]]->Next(&got_tag, &ok)) {+        ctx = ClientRpcContext::detag(got_tag);+        ctx->TryCancel();","Nice catch. Since this is just duplicated code from down below, can you take it out and make it a separate function or lambda or something?",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/13226,151585006,2017-11-17T01:41:24Z,tools/flakes/detect_flakes.py,"@@ -13,92 +13,251 @@ # See the License for the specific language governing permissions and # limitations under the License. -""""""Detect new flakes introduced in the last 24h hours with respect to the-previous six days""""""+""""""Detect new flakes and create issues for them""""""  from __future__ import absolute_import from __future__ import division from __future__ import print_function  import datetime+import json+import logging import os+import pprint import sys-import logging-logging.basicConfig(format='%(asctime)s %(message)s')+import urllib2+from collections import namedtuple  gcp_utils_dir = os.path.abspath(     os.path.join(os.path.dirname(__file__), '../gcp/utils')) sys.path.append(gcp_utils_dir)  import big_query_utils -def print_table(table):-    kokoro_base_url = 'https://kokoro.corp.google.com/job/'-    for k, v in table.items():-      job_name = v[0]-      build_id = v[1]-      ts = int(float(v[2]))-      # TODO(dgq): timezone handling is wrong. We need to determine the timezone-      # of the computer running this script.-      human_ts = datetime.datetime.utcfromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S PDT')-      job_path = '{}/{}'.format('/job/'.join(job_name.split('/')), build_id)-      full_kokoro_url = kokoro_base_url + job_path-      print(""Test: {}, Timestamp: {}, url: {}\n"".format(k, human_ts, full_kokoro_url))+GH_ISSUES_URL = 'https://api.github.com/repos/grpc/grpc/issues'+KOKORO_BASE_URL = 'https://kokoro2.corp.google.com/job/'++def gh(url, data=None):","I've added an interactive prompt asking, for each newly detected failure, whether to create a new issue. They are all created under the ""infra/New Failure"" label and one can optionally assign them as well.In addition, I now also search for already existing issues that may be similar to the one being reported. The results are presented right before the interactive prompt, so one can easily determine if the new issue would be a dupe.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/13396,151742234,2017-11-17T17:24:18Z,tools/interop_matrix/ruby_v101_build_interop_patch.patch,"@@ -0,0 +1,11 @@+--- build_interop	2017-11-15 00:27:57.478490290 +0000",I think the patches belong to some subdirectory (e.g. `tools/interop_matrix/patches`  which would preferrably have a README.md) rather than directly under tools/interop_matrix.,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/13396,151744103,2017-11-17T17:33:22Z,tools/interop_matrix/create_matrix_images.py,"@@ -214,6 +214,24 @@ def cleanup(): docker_images_cleanup = [] atexit.register(cleanup) +def maybe_perform_hacks_on_git_repo(stack_base, lang, release):+  if lang != 'ruby' or release != 'v1.0.1':","I think ruby won't be the only language that will ever need this (C# v1.0.1 might be the next one), so we should make the patching work in a more organized way.Also, any patches to the dockerfiles we applied so far (to be able to build images for older releases) should really be persisted in the repo in the same way - I don't think manually hacking the dockerfiles locally and then pushing the images is something we should do.Here's what I'd suggest:the client_matrix.py should contain info about what patches to apply for given versions and the patching code here should be general and apply patches according to that list.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/13391,151775546,2017-11-17T19:53:12Z,src/core/lib/iomgr/tcp_posix.cc,"@@ -574,16 +575,27 @@ static bool tcp_flush(grpc_exec_ctx* exec_ctx, grpc_tcp* tcp,      if (sent_length < 0) {       if (errno == EAGAIN) {-        tcp->outgoing_slice_idx = unwind_slice_idx;         tcp->outgoing_byte_idx = unwind_byte_idx;+        // unref all and forget about all slices that have been written to this+        // point+        for (size_t idx = 0; idx < unwind_slice_idx; ++idx) {","I don't think so. In this case, we know sent_length < 0, so we know that nothing in the last write went out, so there should be no partial writing of a slice occurring. Plus this conditional will always return, so we won't make it to the logic that handles partial write of a slice.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/13288,151821580,2017-11-18T01:01:34Z,src/core/lib/support/manual_constructor.h,"@@ -22,12 +22,147 @@ // manually construct a region of memory with some type  #include <stddef.h>+#include <stdlib.h> #include <new> #include <type_traits> #include <utility> +#include <grpc/support/log.h>+ namespace grpc_core { +// this contains templated helpers needed to implement the ManualConstructors+// in this file.+namespace manual_ctor_impl {++// is_one_of returns true it a class, Needle, is present in a variadic list of+// classes, Haystack.+template <class Needle, class... Haystack>","hahahaha no. Something more readable and less cute. class Member, class List, something like that",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/13438,152070195,2017-11-20T18:18:43Z,src/csharp/Grpc.Microbenchmarks/Program.cs,"@@ -20,14 +20,81 @@ using Grpc.Core; using Grpc.Core.Internal; using Grpc.Core.Logging;+using CommandLine;+using CommandLine.Text;  namespace Grpc.Microbenchmarks {     class Program     {+        public enum MicrobenchmarkType+        {+            CompletionRegistry,+            PInvokeByteArray,+            SendMessage+        }++        private class BenchmarkOptions+        {+            [Option(""benchmark"", Required = true, HelpText = ""Benchmark to run"")]+            public MicrobenchmarkType Benchmark { get; set; }+        }+         public static void Main(string[] args)         {             GrpcEnvironment.SetLogger(new ConsoleLogger());+            var parserResult = Parser.Default.ParseArguments<BenchmarkOptions>(args)+                .WithNotParsed(errors => {+                    Console.WriteLine(""Supported benchmarks:"");+                    foreach (var enumValue in Enum.GetValues(typeof(MicrobenchmarkType)))+                    {+                        Console.WriteLine(""  "" + enumValue);+                    }+                    Environment.Exit(1);+                })+                .WithParsed(options =>+                {+                    switch (options.Benchmark)+                    {+                        case MicrobenchmarkType.CompletionRegistry:+                          RunCompletionRegistryBenchmark();+                          break;+                        case MicrobenchmarkType.PInvokeByteArray:+                          RunPInvokeByteArrayBenchmark();+                          break;+                        case MicrobenchmarkType.SendMessage:+                          RunSendMessageBenchmark();+                          break;+                        default:+                          throw new ArgumentException(""Unsupported benchmark."");+                    }+                });+        }++        static void RunCompletionRegistryBenchmark()","optional: Put `CompletionRegistryBenchmark`. `PInvokeByteArrayBenchmark`, and `SendMessageBenchmark` under an umbrella to de-dup these three `Run<benchmark>` functions? .... I guess we'd also need to add an unused parameter to the `CompletionRegistryBenchmark.Run`",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/13438,152073191,2017-11-20T18:31:24Z,src/csharp/Grpc.Microbenchmarks/GCStats.cs,"@@ -0,0 +1,69 @@+﻿#region Copyright notice and license++// Copyright 2015 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using Grpc.Core;+using Grpc.Core.Internal;++namespace Grpc.Microbenchmarks+{+    internal class GCStats+    {+        readonly object myLock = new object();+        GCStatsSnapshot lastSnapshot;++        public GCStats()+        {+            lastSnapshot = new GCStatsSnapshot(GC.CollectionCount(0), GC.CollectionCount(1), GC.CollectionCount(2));+        }++        public GCStatsSnapshot GetSnapshot(bool reset = false)","It looks like the `reset` functionality is unused in this PR. Will it be used elsewhere later, or can it be removed?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/13438,152075819,2017-11-20T18:41:27Z,src/csharp/Grpc.Microbenchmarks/PInvokeByteArrayBenchmark.cs,"@@ -0,0 +1,64 @@+﻿#region Copyright notice and license++// Copyright 2015 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Runtime.InteropServices;+using System.Threading;+using Grpc.Core;+using Grpc.Core.Internal;+using System.Collections.Generic;+using System.Diagnostics;++namespace Grpc.Microbenchmarks+{+    public class PInvokeByteArrayBenchmark+    {+        static readonly NativeMethods Native = NativeMethods.Get();++        public void Init()+        {+        }++        public void Cleanup()+        {+        }++        public void Run(int threadCount, int iterations, int payloadSize)+        {+            Console.WriteLine(string.Format(""PInvokeByteArrayBenchmark: threads={0}, iterations={1}, payloadSize={2}"", threadCount, iterations, payloadSize));+            var threadedBenchmark = new ThreadedBenchmark(threadCount, () => ThreadBody(iterations, payloadSize));+            threadedBenchmark.Run();+        }++        private void ThreadBody(int iterations, int payloadSize)+        {+            var payload = new byte[payloadSize];+         +            var stopwatch = Stopwatch.StartNew();+            for (int i = 0; i < iterations; i++)+            {+                var gcHandle = GCHandle.Alloc(payload, GCHandleType.Pinned);+                var payloadPtr = gcHandle.AddrOfPinnedObject();+                Native.grpcsharp_test_nop(payloadPtr);","Especially with `grpcsharp_test_nop` being similar to a no-op, is there a risk that this gets optimized away?",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/13438,152089920,2017-11-20T19:36:21Z,src/csharp/Grpc.Microbenchmarks/GCStats.cs,"@@ -0,0 +1,69 @@+﻿#region Copyright notice and license++// Copyright 2015 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using Grpc.Core;+using Grpc.Core.Internal;++namespace Grpc.Microbenchmarks+{+    internal class GCStats+    {+        readonly object myLock = new object();+        GCStatsSnapshot lastSnapshot;++        public GCStats()+        {+            lastSnapshot = new GCStatsSnapshot(GC.CollectionCount(0), GC.CollectionCount(1), GC.CollectionCount(2));+        }++        public GCStatsSnapshot GetSnapshot(bool reset = false)+        {+            lock (myLock)","the lock doesn't help in any way with the quality of data obtained from GC.CollectionCount,but it helps to make sure that our lastSnapshot + newSnapshot arithmetic will always be consistent if called from multiple threads (which can happen, considering the GC stats are ""global""). So I think it's fair to add the lock.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/13438,152091611,2017-11-20T19:42:59Z,src/csharp/Grpc.Microbenchmarks/CompletionRegistryBenchmark.cs,"@@ -0,0 +1,69 @@+﻿#region Copyright notice and license++// Copyright 2015 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Runtime.InteropServices;+using System.Threading;+using Grpc.Core;+using Grpc.Core.Internal;+using System.Collections.Generic;+using System.Diagnostics;++namespace Grpc.Microbenchmarks+{+    public class CompletionRegistryBenchmark+    {+        GrpcEnvironment environment;++        public void Init()+        {+            environment = GrpcEnvironment.AddRef();+        }++        public void Cleanup()+        {+            GrpcEnvironment.ReleaseAsync().Wait();+        }++        public void Run(int threadCount, int iterations)+        {+            Console.WriteLine(string.Format(""CompletionRegistryBenchmark: threads={0}, iterations={1}"", threadCount, iterations));+            var threadedBenchmark = new ThreadedBenchmark(threadCount, () => ThreadBody(iterations));+            threadedBenchmark.Run();+            // TODO: parametrize by number of pending completions+        }++        private void ThreadBody(int iterations)+        {+            var completionRegistry = new CompletionRegistry(environment);+            var ctx = BatchContextSafeHandle.Create();+            var completionDelegate = new OpCompletionDelegate((success) => {});+  +            var stopwatch = Stopwatch.StartNew();+            for (int i = 0; i < iterations; i++)","I think you're right that there's a theoretical change of this getting optimized away (but from running it I can see that the compiler is definitely not that clever and it behaves as expected - also the data is mostly to be looked at by human at this point and I think you'd notice if the whole thing suddenly took basically zero time). I might implement the increment logic you described, but to be fair - if the optimizer is clever and the actions in the loop are very trivial, it can guess that the counter will get incremented in each run  and only perform `counter += iteration` once - and the effect will be the same. So in a way you always have to be rely on the optimizer being ""dumb enough"" - and I observed in this case things are working fine.",
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/13454,152092477,2017-11-20T19:46:29Z,src/core/lib/iomgr/lockfree_event.h,"@@ -30,11 +30,13 @@ namespace grpc_core { class LockfreeEvent {  public:   LockfreeEvent();-  ~LockfreeEvent();    LockfreeEvent(const LockfreeEvent&) = delete;   LockfreeEvent& operator=(const LockfreeEvent&) = delete; +  void Init();","I suggest renaming these to `InitEvent` and `DestroyEvent` - otherwise, this is confusing since `ManualConstructor` also has `Init` and `Destroy` methods.(It was  very confusing to me to look at `fd_create` function and see `Init()` called two times :). One like this `foo.Init()` and the other like this: `foo->Init()` )",
8228229,kkm000,https://api.github.com/repos/grpc/grpc/pulls/13207,152094523,2017-11-20T19:54:55Z,src/csharp/Grpc.Tools.CSharp.targets,"@@ -0,0 +1,53 @@+<?xml version=""1.0""?>","I specifically avoided using any MsBuild features beyond those in v4.0. So likely the build part will work even with VS2010, if anyone is antiquated enough to still use it. The XAML object model file is required for ""new"" style .NET SDK projects within VS; without them, proto files will not show up in Visual Studio at all. Using this file has no effect on older build, as they are simply ignoring the new collection. The AvailableItems collection is another way to tell VS to show files in the tree, used for the ""old"" style .csproj, and is certainly recognized by VS2012, but I am not about of VS2010.Stand-alone SDK projects or standalone invocations of MSBuild do not recognize any of these special collections.",
8228229,kkm000,https://api.github.com/repos/grpc/grpc/pulls/13207,152099106,2017-11-20T20:13:52Z,src/csharp/Grpc.Tools.CSharp.targets,"@@ -0,0 +1,53 @@+<?xml version=""1.0""?>+<Project xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"">","Might not, as written, when they are at the different levels of a common subtree. I did keep that in mind writing these scripts, but I am sure this should be the next step; you can treat this as a proof-of-concept. This is in a way a complex matter. Ideally, we should gather all .proto files within the project, find the common root for them, and use that with one `-I` (another being the common `include` root), passing all protos to a single protoc invocation. The common root, however, is only a guess; the user should be able to specify the root explicitly. Also, this might not work if the files come from a different location, not under the project root. Another scenatio is when the user wants to compile *multiple* sets of proto files (e. g., some from another location, e.g. ../../otherproj/{x,y}.proto, some from this project. So my though is, we should ""automagically"" guess the ""default"" proto root (e. g., the project root is not a bad guess), but allow more advanced cases by batching (MsBuild term) invocations per collection of proto files. This is easily doable by using MSBuild metadata, where said metadata would explicitly provide a root for a given file. For example,```xml<ProtoBuf Include=""subdir1/this_proj_file1.proto;subdir2/this_proj_file2.proto"" /><ProtoBuf Include=""../other/other_proj_file1.proto;other_proj_file2.proto"">  <ProtoRoot>../other/</ProtoRoot></ProtoBuf>```should result in two protoc invocation: the first compiling `*/this_proj*` files with the default root (equal to the location of the .csproj file), and another with the `-I` path explicitly specified by the ProtoRoot metadata on the two other files (maybe converted to the full path in case protoc does not digest relative paths as specified).So my goal is to (1) make the compilation totally automatic by default, in line with the ""new"" MS approach (when you just put files besides .csproj, and they are picked up by the build automatically), at the same time allowing better control of proto differently-rooted ""collections"" (for the lack of a better term).Can you think of use cases that won't be covered?/cc @jskeet please comment on this one too.",
8228229,kkm000,https://api.github.com/repos/grpc/grpc/pulls/13207,152106277,2017-11-20T20:46:52Z,src/csharp/Grpc.Tools.nuspec,"@@ -2,32 +2,70 @@ <package>   <metadata>     <id>Grpc.Tools</id>","nit: it's not *just* VS integration, it's a complete integration for VS, standalone MSBuild, .NET.SDK on multiple platforms and mono (I am testing on Windows and Linux).The short answer is no, just change ""tools"" to ""build"".The long answer is, unfortunately, there is no ""old"" way to use the tools, without going through hoops and encoding explicit paths to grpc tools. The problem is, there are, again, two different ways of placing NuGet packages, one corresponding to the ""old"" (non-.NET.SDK projects), when NuGet is a separate tool. The packages are (by default) placed into the `/packages` subdirectory of the solution. This is less of a problem when packaged are libraries, as they are just added with a relative path to the project references. Here's an example from an ""old"" style project (which we currently only use, with very few exceptions):```xml    <Reference Include=""Grpc.Core, Version=1.0.0.0, Culture=neutral, PublicKeyToken=d754f35622e28bad, processorArchitecture=MSIL"">      <HintPath>..\..\packages\Grpc.Core.1.7.1\lib\net45\Grpc.Core.dll</HintPath>    </Reference>```The `<HintPath>` is a misnomer, it is the actual location where the library should be found. Of course, moving projects is a headache, and switching the target version of the framework is a double-headache (note the `\net45\` part, which might or might not work with a different framework). These are created by the NuGet extension inside Visual Studio, and quite brittle.The ""new"" build scripts integrate NuGet into the build process. So in a ""new"" style project, there is a reference to NuGet package ID only, and the build process figures out the correct library folder, if there are multiple. Here's how it looks:```xml  <ItemGroup>    <PackageReference Include=""Grpc.Core"" Version=""1.7.1"" />  </ItemGroup>```(happily, VS2017 supports that for the ""old"" projects, but I digress).The tools as packaged are hardly useful, *because they are not discoverable* by the build process. First of all, the solution-level `packages` folder is only a default. The user can change the location in his Nuget.config so that, for one example, all packages from all builds are placed under the same directory and shared. This would make the path to the tools totally disconnected from, and absolutely undiscoverable for the build. While I can think of a double-horrific hack of traversing the tree up, looking for a `package` directory, finding one (or more) that matches the `Grpc.Core.*` pattern, then maybe selecting one with the hifghest version (but oh boy, how??), this is brittle by itself and also will break with the common location for projects.Worse news is that the common location *is* actually the default in .NET.SDK projects. Here's a sample project under Linux that I used while developing these scripts (version 1.9.9.5 is just fake large version to pick the package off my local feed):```kkm@yupana:~/work/dotnet/hwapp$ cat hwapp.csproj<Project Sdk=""Microsoft.NET.Sdk"">  <PropertyGroup>    <OutputType>Exe</OutputType>    <TargetFramework>netcoreapp2.0</TargetFramework>  </PropertyGroup>  <ItemGroup>    <PackageReference Include=""Google.Protobuf"" Version=""3.4.1"" />    <PackageReference Include=""Grpc.Tools"" Version=""1.9.9.5"" />  </ItemGroup></Project>kkm@yupana:~/work/dotnet/hwapp$ dotnet nuget locals global-packages --listinfo : global-packages: /home/kkm/.nuget/packages/kkm@yupana:~/work/dotnet/hwapp$ ll /home/kkm/.nuget/packages/grpc.toolstotal 4.0Kdrwxrwxr-x 3 kkm kkm 4.0K Oct 31 17:11 1.9.9.5/```So you see where the guy is hiding. NuGet is absolutely not doing any good here; if I wanted to compile some .proto files using a script, I would much prefer to download a .tar.gz file with the tools and other required files, than trying to parse the output of `dotnet nuget locals global-packages --list` in a script (and then the problem of multiple versions does not go away).All in all, he point of this ""long answer"" exposition is to show that packaging, quite unfortunately, simply *cannot* get worse than it is. It's currently rather dysfunctional, a quite inconvenient .zip file with extra metadata stuff in it (.nuget is a .zip) that is better unpacked in a known location that pulled automatically from within a project using the tools.(As a side note, the correct way of the simplest case for tool discovery is including a .props or .targets file that sets a variable based on the predefined variable `$(MSBuildThisFileDirectory)` which is set to the location of the current, be it the root or <Import>'ed, project file. `.props` is for something that user can override in project, and `.targets` is for things we want  more control of).",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13188,152124325,2017-11-20T22:03:58Z,src/python/grpcio_tests/tests/unit/_server_ssl_cert_config_test.py,"@@ -0,0 +1,525 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""+This tests server certificate rotation support.++Here we test various aspects of gRPC Python, and in some cases C-core+by extension, support for server certificate rotation.++* ServerSSLCertReloadTestWithClientAuth: test ability to rotate+  server's SSL cert for use in future channels with clients while not+  affecting any existing channel. The server requires client+  authentication.++* ServerSSLCertReloadTestWithoutClientAuth: like+  ServerSSLCertReloadTestWithClientAuth except that the server does+  not authenticate the client.++* ServerSSLCertReloadTestCertConfigReuse: tests gRPC Python's ability+  to deal with user's reuse of ServerCertificateConfig instances.+""""""++import abc+import os+import six+import unittest+import threading+import time++from collections import namedtuple","Import only packages and modules (almost always modules!); never classes, functions, or other code elements of modules.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/13444,152181318,2017-11-21T05:15:55Z,src/csharp/Grpc.Microbenchmarks/CompletionRegistryBenchmark.cs,"@@ -52,18 +52,26 @@ private void ThreadBody(int iterations)         {             var completionRegistry = new CompletionRegistry(environment);             var ctx = BatchContextSafeHandle.Create();-            var completionDelegate = new OpCompletionDelegate((success) => {});                var stopwatch = Stopwatch.StartNew();             for (int i = 0; i < iterations; i++)             {-                completionRegistry.Register(ctx.DangerousGetHandle(), completionDelegate);+                completionRegistry.Register(ctx.Handle, ctx);                 var callback = completionRegistry.Extract(completionRegistry.LastRegisteredKey);+                // NOTE: we are not calling the callback to avoid disposing ctx.             }             stopwatch.Stop();             Console.WriteLine(""Elapsed millis: "" + stopwatch.ElapsedMilliseconds);                        ctx.Dispose();         }++        private class NopCompletionCallback : IOpCompletionCallback",nit: is `NopCompletionCallback` unused?,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/13459,152192514,2017-11-21T07:09:10Z,src/csharp/Grpc.Core.Tests/Internal/AsyncCallServerTest.cs,"@@ -107,10 +107,10 @@ public void ReadCompletionFailureClosesRequestStream()             // if a read completion's success==false, the request stream will silently finish             // and we rely on C core cancelling the call.             var moveNextTask = requestStream.MoveNext();-            fakeCall.ReceivedMessageHandler(false, null);+            fakeCall.ReceivedMessageCallback.OnReceivedMessage(false, null);","nit: inconsistent naming, `s/OnReceivedMessage/OnReceivedMessageHandler`?or maybe lose the `Handler` suffix on some of these instead?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/13459,152192623,2017-11-21T07:10:09Z,src/csharp/Grpc.Core.Tests/Internal/AsyncCallServerTest.cs,"@@ -134,10 +134,10 @@ public void WriteCompletionFailureThrows()             var responseStream = new ServerResponseStream<string, string>(asyncCallServer);              var writeTask = responseStream.WriteAsync(""request1"");-            fakeCall.SendCompletionHandler(false);+            fakeCall.SendCompletionCallback.OnSendCompletion(false);",same inconsistent naming here as above,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/13459,152192817,2017-11-21T07:11:53Z,src/csharp/Grpc.Core.Tests/Internal/AsyncCallServerTest.cs,"@@ -150,13 +150,13 @@ public void WriteAndWriteStatusCanRunConcurrently()             var writeTask = responseStream.WriteAsync(""request1"");             var writeStatusTask = asyncCallServer.SendStatusFromServerAsync(Status.DefaultSuccess, new Metadata(), null); -            fakeCall.SendCompletionHandler(true);-            fakeCall.SendStatusFromServerHandler(true);+            fakeCall.SendCompletionCallback.OnSendCompletion(true);","nit, optional: `s/OnSendCompletion/OnSendCompletionHandler`? also similar comment for `OnSendStatusFromServerCompletion` below",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/13459,152217531,2017-11-21T09:27:02Z,src/csharp/Grpc.Core/Internal/BatchContextSafeHandle.cs,"@@ -54,21 +57,26 @@ public IntPtr Handle             }         } -        public BatchCompletionDelegate CompletionCallback { get; set; }+        public void SetCompletionCallback(BatchCompletionDelegate callback, object state)+        {+            GrpcPreconditions.CheckState(completionCallbackData.Callback == null);+            GrpcPreconditions.CheckNotNull(callback, nameof(callback));+            completionCallbackData = new CompletionCallbackData(callback, state);","The only thing odd is it seems `CompletionCallbackData` is kind of a replacement for the previous closure that was created before every call to `RegisterBatchCompletion`, and though the closure is not getting alloc'd anymore, `CompletionCallbackData` still is. It seems like there should be a way for the `BatchCompletionDelegate`'s to know about the `I*Callback`'s that they're wrapping without needing for them to be supplied with one by their caller.rough idea: If the `BatchCompletionDelegate`'s were instance methods instead of static methods, then they should be able to call their own call's `I*Callback` methods without being supplied with a `state` parameter. Then, I believe those `I*Callback` methods would no longer need to be passed in to methods like e.g., `StartUnary`. I'm pretty sure that if the `CallSafeHandles` knew the `AsyncCall` that they held on to, then this could work.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/13459,152225663,2017-11-21T09:59:07Z,src/csharp/Grpc.Core/Internal/BatchContextSafeHandle.cs,"@@ -54,21 +57,26 @@ public IntPtr Handle             }         } -        public BatchCompletionDelegate CompletionCallback { get; set; }+        public void SetCompletionCallback(BatchCompletionDelegate callback, object state)+        {+            GrpcPreconditions.CheckState(completionCallbackData.Callback == null);+            GrpcPreconditions.CheckNotNull(callback, nameof(callback));+            completionCallbackData = new CompletionCallbackData(callback, state);","The difference is that `CompletionCallbackData` is a struct and hence no allocation - so this approach works (and I've verified in a microbenchmark that no allocation happens).Comments on the idea you described:- whenever the BatchCompletionDelegates point to instance methods (instead of static methods), they will somehow need to capture the value of `this` - so there necessarily needs to be an allocation. We also cannot store the BatchCompletionDelegates as instance fields (as opposed to static fields) because many of the objects (CallSafeHandle, AsyncCall, ...) are likely to be created in large quantities and wouldn't want to have that overhead when creating new calls.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/13459,152227120,2017-11-21T10:04:37Z,src/csharp/Grpc.Core.Tests/Internal/AsyncCallServerTest.cs,"@@ -107,10 +107,10 @@ public void ReadCompletionFailureClosesRequestStream()             // if a read completion's success==false, the request stream will silently finish             // and we rely on C core cancelling the call.             var moveNextTask = requestStream.MoveNext();-            fakeCall.ReceivedMessageHandler(false, null);+            fakeCall.ReceivedMessageCallback.OnReceivedMessage(false, null);","I think addressing it will also address all other ""inconsistent naming"" comment.",
8228229,kkm000,https://api.github.com/repos/grpc/grpc/pulls/13207,152314711,2017-11-21T15:45:56Z,src/csharp/Grpc.Tools.nuspec,"@@ -2,32 +2,70 @@ <package>   <metadata>     <id>Grpc.Tools</id>","To give a short answer, if someone wants for some reason to continue using Grpc.Tools this way, they will have to replace ""tools"" with ""build"" once *in addition* to the version that they have to replace with every upgrade anyway. No big deal at all.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13472,152340489,2017-11-21T17:04:06Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -548,6 +548,10 @@ static void on_resolver_result_changed_locked(grpc_exec_ctx* exec_ctx,       GRPC_RESOLVER_UNREF(exec_ctx, chand->resolver, ""channel"");       chand->resolver = nullptr;     }+    if (chand->lb_policy != nullptr) {","There are two cases in which we get to this point, as per the condition on line 539:1. The resolver scheduled the closure with an error instead of returning results in `chand->resolver_result`.2. The resolver scheduled the closure without an error and with results in `chand->resolver_result` but we were shut down (setting `chand->resolver` to null) by the time we got here.In case 1, this change is unnecessary, because the condition on line 387 will be false, so we will never set `new_lb_policy`, and the code on lines 523-536 will ensure that we have already set `chand->lb_policy` to null.In case 2, you're right that there is a potential problem here, but this fix is sub-optimal, because we will wind up creating a new LB policy which we then immediately unref.  Instead, I suggest changing line 387 to also check `&& chand->resolver != nullptr`, so that we avoid creating a new LB policy to begin with.  However, note that if `chand->resolver_result` is non-null, we still need to free it.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/13288,152371234,2017-11-21T19:01:47Z,src/core/lib/support/manual_constructor.h,"@@ -22,12 +22,147 @@ // manually construct a region of memory with some type  #include <stddef.h>+#include <stdlib.h> #include <new> #include <type_traits> #include <utility> +#include <grpc/support/log.h>+ namespace grpc_core { +// this contains templated helpers needed to implement the ManualConstructors+// in this file.+namespace manual_ctor_impl {++// is_one_of returns true it a class, Needle, is present in a variadic list of+// classes, Haystack.+template <class Needle, class... Haystack>",Done. Goofy RPC[?](https://github.com/grpc/grpc/blob/master/src/core/lib/transport/transport.cc#L212),
8228229,kkm000,https://api.github.com/repos/grpc/grpc/pulls/13207,152691320,2017-11-22T22:18:33Z,src/csharp/Grpc.Tools.nuspec,"@@ -2,32 +2,70 @@ <package>   <metadata>     <id>Grpc.Tools</id>","@jtattermusch Yes, absolutely. Inside Visual Studio, changing a .cs file from ""Build"" to ""None"" in properties makes VS generate a piece in the project file (equivalent to):```xml  <Compile Remove=""foo.cs"" />  <None Include=""foo.cs"" />```Same happens with proto files which are included by default but excluded specifically per-file.Without VS (.NET.SDK alone, e. g. on Linux) there is no need adding the `Remove`d files to `<None>` (adding to the None collection is done so that VS continues to show the file in the project tree), so you would just write, e.g.```xml  <ProtoBuf Remove=""*_test.proto"" />```to exclude a specific pattern, or, why not,```xml  <ProtoBuf Remove=""@(ProtoBuf)"" />  <ProtoBuf Include=""only_one.proto"" />```I the end, I would prefer the defaults be in step with the Microsoft vision of these projects (as I grok it), but it is naturally controllable on the level of individual files.",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/13494,152711993,2017-11-23T01:31:43Z,src/core/lib/backoff/backoff.h,"@@ -21,63 +21,85 @@  #include ""src/core/lib/iomgr/exec_ctx.h"" -#ifdef __cplusplus-extern ""C"" {-#endif--typedef struct {-  /// const:  how long to wait after the first failure before retrying-  grpc_millis initial_backoff;--  /// const: factor with which to multiply backoff after a failed retry-  double multiplier;--  /// const: amount to randomize backoffs-  double jitter;--  /// const: minimum time between retries-  grpc_millis min_connect_timeout;--  /// const: maximum time between retries-  grpc_millis max_backoff;-+namespace grpc_core {++class Backoff {",some documentation maybe about the class in general,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/13207,152913619,2017-11-24T08:12:25Z,src/csharp/Grpc.Tools.nuspec,"@@ -2,32 +2,70 @@ <package>   <metadata>     <id>Grpc.Tools</id>","Great, I think that's very acceptable, thanks for the explanation. - I think the ""way to disable"" should be part of the documentation along with the way to use.  Does having a src/csharp/Grpc.Tools/README.md sound like a good place for a some initial Grpc.Tools docs?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13472,153259375,2017-11-27T17:02:54Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -548,6 +548,10 @@ static void on_resolver_result_changed_locked(grpc_exec_ctx* exec_ctx,       GRPC_RESOLVER_UNREF(exec_ctx, chand->resolver, ""channel"");       chand->resolver = nullptr;     }+    if (chand->lb_policy != nullptr) {","> Since we are talking about avoiding deletion right after creation, should we actually check whether the client channel is shutting down at the beginning of `on_resolver_result_changed_locked()`? If the client channel is shutting down, we don't need to create the LB policy, or swap in the new values into chand. And the logic in `on_resolver_result_changed_locked()` would be easier to understand and deal with?While it's true that we don't need to swap the new values into `chand` in this case, I think we do still need to unref the previous values.  This means that most of the code on lines 492-536 needs to be executed in both the shutdown and non-shutdown cases; the only distinction between them is that in the shutdown case, the new values we swap in are null.  It doesn't really make sense to duplicate that code; instead, the idea here is that in the shutdown case, the block on lines 387-484 is not executed, which leaves all of the new values initialized to null before we run the code to swap out the values.(Also, resetting `chand->lb_policy` in particular is tricky, since we want to continue using the existing LB policy object if the LB policy name has not changed, and there are a couple of places in this function where we need to know whether or not we've created a new LB policy or are continuing to use the existing one.)I can completely understand why you suggested this.  In fact, I've had this same thought myself on a few different occasions, but every time I look at doing this, it seems like it wouldn't actually help make the logic clearer.> Another question is how we know the client channel is shutting down. The current code uses `error != GRPC_ERROR_NONE || chand->resolver == nullptr` to check and this appears at multiple locations.  I suspect we can check that at the beginning of `on_resolver_result_changed_locked()` and set the channel state into `SHUTDOWN` if needed, then use `grpc_connectivity_state_get()` afterwards. That condition only appears in two places.  The rule of three suggests that this isn't worth refactoring at this point.Also, note that `grpc_connectivity_state_get()` does an atomic operation, so it's better for performance to use local variables here.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13109,153519211,2017-11-28T15:07:31Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -56,8 +56,7 @@  /* Client channel implementation */ -grpc_tracer_flag grpc_client_channel_trace =-    GRPC_TRACER_INITIALIZER(false, ""client_channel"");+grpc_core::TraceFlag grpc_client_channel_trace(false, ""client_channel"");","I just realized that this approach violates the style guide:https://google.github.io/styleguide/cppguide.html#Static_and_Global_VariablesNoah, can you please send a follow-up PR to fix this?  Thanks!",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/13109,153532490,2017-11-28T15:48:29Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -56,8 +56,7 @@  /* Client channel implementation */ -grpc_tracer_flag grpc_client_channel_trace =-    GRPC_TRACER_INITIALIZER(false, ""client_channel"");+grpc_core::TraceFlag grpc_client_channel_trace(false, ""client_channel"");","What do you propose for fixing this? To me this seems like a case where a small violation of the style guide is worth it to avoid unneeded complexity. My idea for a fix would be to create a separate header file with all constexpr tracer definitions, and then link to that from all places where a flag is needed. ",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/13357,153615120,2017-11-28T20:33:33Z,src/core/lib/support/reference_counted.h,"@@ -0,0 +1,59 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_SUPPORT_REFERENCE_COUNTED_H+#define GRPC_CORE_LIB_SUPPORT_REFERENCE_COUNTED_H++#include <grpc/support/sync.h>++#include ""src/core/lib/debug/trace.h""+#include ""src/core/lib/support/debug_location.h""++namespace grpc_core {++class ReferenceCounted {","Suggest renaming this to ReferenceCountedWithTracing, and introducing a lower level ReferenceCounted type that doesn't carry the additional TraceFlag.My expectation is that as time goes by, we'll move more and more code from ReferenceCountedWithTracing to ReferenceCounted (as we transition away from manual reference counting)",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13357,153653354,2017-11-28T23:20:53Z,src/core/lib/support/reference_counted.h,"@@ -0,0 +1,59 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_SUPPORT_REFERENCE_COUNTED_H+#define GRPC_CORE_LIB_SUPPORT_REFERENCE_COUNTED_H++#include <grpc/support/sync.h>++#include ""src/core/lib/debug/trace.h""+#include ""src/core/lib/support/debug_location.h""++namespace grpc_core {++class ReferenceCounted {","I tried this, but I ran into two ugly problems:1. In order for the `ReferenceCountedWithTracing` class to have access to the current refcount for logging purposes, I would need to either (a) make it a friend of the parent class or (b) provide a protected method to access the current refcount.  The latter is a bit cleaner than the former, but it would mean that we're exposing implementation details into all subclasses.2. Having methods called `Ref()` and `Unref()` in the `ReferenceCountedWithTracing` class would mask the methods of the same names but with different signatures in the base class.  This would require renaming the methods in the `ReferenceCountedWithTracing` class to something like `RefWithTracing()` and `UnrefWithTracing`, which seems sub-optimal.As an alternative, I suppose I could simply have two completely unrelated classes with the same interface and functionality, but I'm not wildly enthusiastic about it.  Any suggestions on a better alternative?",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/13083,153661850,2017-11-29T00:13:36Z,src/core/lib/support/function.h,"@@ -0,0 +1,293 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_SUPPORT_FUNCTION_H+#define GRPC_CORE_LIB_SUPPORT_FUNCTION_H++#include <stddef.h>+#include <string.h>+#include <type_traits>+#include <utility>+#include ""src/core/lib/support/memory.h""++namespace grpc_core {++namespace function_impl {+static constexpr const size_t kDefaultInplaceStorage = 3 * sizeof(void*);++template <typename R, typename... Args>+struct VTable {+  void (*copy_construct)(const void* from, void* to);+  void (*move_construct)(void* from, void* to);+  void (*destruct)(void* storage);+  R (*invoke)(void* storage, Args&&... args);+};++template <typename T, typename F, bool kIsLarge>+class Traits;++template <typename R, typename... Args, typename F>+class Traits<R(Args...), F, false> {+ public:+  template <class T>+  static const VTable<R, Args...>* Construct(F&& f, T* storage) {+    static_assert(sizeof(*storage) >= sizeof(F), ""Size of storage too small"");+    new (storage) F(std::move(f));+    return &vtable_;+  }++ private:+  static void CopyConstruct(const void* from, void* to) {+    new (to) F(*static_cast<const F*>(from));+  }+  static void MoveConstruct(void* from, void* to) {+    new (to) F(std::move(*static_cast<F*>(from)));+  }+  static void Destruct(void* storage) { static_cast<F*>(storage)->~F(); }+  static R Invoke(void* storage, Args&&... args) {+    return (*static_cast<F*>(storage))(std::forward<Args>(args)...);+  }++  static const VTable<R, Args...> vtable_;+};++template <typename R, typename... Args, typename F>+const VTable<R, Args...> Traits<R(Args...), F, false>::vtable_ = {+    CopyConstruct, MoveConstruct, Destruct, Invoke};++template <typename R, typename... Args, typename F>+class Traits<R(Args...), F, true> {+ private:+  typedef UniquePtr<F> Ptr;++ public:+  static const VTable<R, Args...>* Construct(F&& f, void* storage) {+    new (storage) Ptr(New<F>(std::move(f)));+    return &vtable_;+  }++ private:+  static void CopyConstruct(const void* from, void* to) {+    new (to) Ptr(New<F>(*static_cast<const Ptr*>(from)->get()));+  }+  static void MoveConstruct(void* from, void* to) {+    new (to) Ptr(std::move(*static_cast<Ptr*>(from)));+  }+  static void Destruct(void* storage) { static_cast<Ptr*>(storage)->~Ptr(); }+  static R Invoke(void* storage, Args&&... args) {+    return (**static_cast<Ptr*>(storage))(std::forward<Args>(args)...);+  }++  static const VTable<R, Args...> vtable_;+};++template <typename R, typename... Args, typename F>+const VTable<R, Args...> Traits<R(Args...), F, true>::vtable_ = {+    CopyConstruct, MoveConstruct, Destruct, Invoke};+}++template <typename T,+          size_t kInplaceStorage = function_impl::kDefaultInplaceStorage>+class Function;++template <typename T,+          size_t kInplaceStorage = function_impl::kDefaultInplaceStorage>+class InplaceFunction;++template <typename T,+          size_t kInplaceStorage = function_impl::kDefaultInplaceStorage>+class TrivialInplaceFunction;++// Function<> is roughly a std::function work-alike+// Differences:+// - configurable inplace storage quantity... functors smaller than this incur+//   no allocation overhead, functors bigger will cause an allocation+template <typename R, typename... Args, size_t kInplaceStorage>+class Function<R(Args...), kInplaceStorage> {+ public:+  template <class F>+  Function(F&& f) {+    vtable_ =+        function_impl::Traits<R(Args...), F, (sizeof(F) > kInplaceStorage)>::+            Construct(std::forward<F>(f), &storage_);+  }++  Function(const Function& rhs) : vtable_(rhs.vtable_) {+    vtable_->copy_construct(&rhs.storage_, &storage_);+  }++  Function(Function& rhs) : vtable_(rhs.vtable_) {","Oh... so the actual problem:If I call `Function()` with a `Function&` and don't have this constructor, then this one matches best:```template <class F>Function(F&& f)```which ends up wrapping a Function around the Function and is absolutely not what we want",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/13526,153662952,2017-11-29T00:20:25Z,INSTALL.md,"@@ -106,11 +107,15 @@ Builds gRPC C and C++ with boringssl. Please note that when using Ninja, you'll still need Visual C++ (part of Visual Studio) installed to be able to compile the C/C++ sources. ```+> powershell git clone -b ((New-Object System.Net.WebClient).DownloadString(\""https://grpc.io/release\"").Trim()) https://github.com/grpc/grpc",I suggest adding `--recursive` to the initial `git clone` command instead of a separate `git submodule update --init` statement.,
14932100,adelez,https://api.github.com/repos/grpc/grpc/pulls/12771,153675433,2017-11-29T01:46:22Z,WORKSPACE,"@@ -102,3 +102,13 @@ local_repository(     name = ""com_google_absl"",     path = ""third_party/abseil-cpp"", )++http_archive(","This is the latest:http_archive(    name = ""bazel_toolchains"",    urls = [        ""https://mirror.bazel.build/github.com/bazelbuild/bazel-toolchains/archive/af4681c3d19f063f090222ec3d04108c4e0ca255.tar.gz"",        ""https://github.com/bazelbuild/bazel-toolchains/archive/af4681c3d19f063f090222ec3d04108c4e0ca255.tar.gz"",    ],    strip_prefix = ""bazel-toolchains-af4681c3d19f063f090222ec3d04108c4e0ca255"",    sha256 = ""d58bb2d6c8603f600d522b6104d6192a65339aa26cbba9f11ff5c4b36dedb928"",)",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/13058,153680351,2017-11-29T02:29:45Z,include/grpc/support/tls.h,"@@ -32,6 +32,12 @@      GPR_TLS_DECL(foo);    Thread locals always have static scope. +   Declaring a thread local class variable 'foo':+     GPR_TLS_CLASS_DECL(foo);",separate macros for class tls variables,
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/13058,153681174,2017-11-29T02:37:06Z,src/core/lib/iomgr/exec_ctx.cc,"@@ -175,3 +102,44 @@ static const grpc_closure_scheduler_vtable exec_ctx_scheduler_vtable = {     exec_ctx_run, exec_ctx_sched, ""exec_ctx""}; static grpc_closure_scheduler exec_ctx_scheduler = {&exec_ctx_scheduler_vtable}; grpc_closure_scheduler* grpc_schedule_on_exec_ctx = &exec_ctx_scheduler;++namespace grpc_core {+GPR_TLS_CLASS_DEF(ExecCtx::exec_ctx_);++void ExecCtx::GlobalInit(void) {",These cannot be inlined at the moment because of dependency on other static functions which we probably don't want to include in the class right now.,
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/13357,153694920,2017-11-29T05:08:20Z,src/core/lib/support/reference_counted.h,"@@ -0,0 +1,59 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_SUPPORT_REFERENCE_COUNTED_H+#define GRPC_CORE_LIB_SUPPORT_REFERENCE_COUNTED_H++#include <grpc/support/sync.h>++#include ""src/core/lib/debug/trace.h""+#include ""src/core/lib/support/debug_location.h""++namespace grpc_core {++class ReferenceCounted {","I think two unrelated classes is fine here. We can parameterize tests for each of them to ensure consistent behavior, and the smart pointer code is common, and arguably more important.",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/13529,153861980,2017-11-29T17:40:40Z,include/grpc++/server_builder.h,"@@ -55,30 +55,93 @@ class ServerBuilder {   ServerBuilder();   ~ServerBuilder(); -  /// Options for synchronous servers.-  enum SyncServerOption {-    NUM_CQS,         ///< Number of completion queues.-    MIN_POLLERS,     ///< Minimum number of polling threads.-    MAX_POLLERS,     ///< Maximum number of polling threads.-    CQ_TIMEOUT_MSEC  ///< Completion queue timeout in milliseconds.-  };+  //////////////////////////////////////////////////////////////////////////////+  // Primary API's++  /// Return a running server which is ready for processing calls.+  /// Before calling, one typically needs to ensure that:+  ///  1. a service is registered - so that the server knows what to serve+  ///     (via RegisterService, or RegisterAsyncGenericService)","I might be weird but...Given the 'right' RegisterService is on screen and syntax highlighted just below here, my eye tends to see it pretty quickly.For that reason, I think it's worth calling out that there are variants here since this starts to act like a TODO list before calling this method.",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/13548,153877845,2017-11-29T18:40:42Z,INSTALL.md,"@@ -94,42 +94,51 @@ on experience with the tools involved. ### Building using CMake (RECOMMENDED)  Builds gRPC C and C++ with boringssl.-- Install [Git](https://git-scm.com/). - Install Visual Studio 2015 or 2017 (Visual C++ compiler will be used).+- Install [Git](https://git-scm.com/). - Install [CMake](https://cmake.org/download/).-- Install [Active State Perl](https://www.activestate.com/activeperl/) (`choco install activeperl`)-- Install [Ninja](https://ninja-build.org/) (`choco install ninja`)-- Install [Go](https://golang.org/dl/) (`choco install golang`)-- Install [yasm](http://yasm.tortall.net/) and add it to `PATH` (`choco install yasm`)-- Run these commands in the repo root directory--#### cmake: Using Ninja (faster build, supports boringssl's assembly optimizations).-Please note that when using Ninja, you'll still need Visual C++ (part of Visual Studio)-installed to be able to compile the C/C++ sources.+- Install [Active State Perl](https://www.activestate.com/activeperl/) (`choco install activeperl`) - *required by boringssl*+- Install [Go](https://golang.org/dl/) (`choco install golang`) - *required by boringssl*+- Install [yasm](http://yasm.tortall.net/) and add it to `PATH` (`choco install yasm`) - *required by boringssl*+- (Optional) Install [Ninja](https://ninja-build.org/) (`choco install ninja`)++#### Clone grpc sources including submodules+Before building, you need to clone the gRPC github repository and download submodules containing source code +for gRPC's dependencies (that's done by the `submodule` command). ```-> powershell git clone --recursive -b ((New-Object System.Net.WebClient).DownloadString(\""https://grpc.io/release\"").Trim()) https://github.com/grpc/grpc+> @rem You can also do just ""git clone -b THE_BRANCH_YOU_WANT https://github.com/grpc/grpc""","I feel like omitting `--recursive` in favor of explicit submodule checkout is a regression. People forget to run the submodule init and file build failed bugs, whereas if it is part of the clone command, it's harder to miss when you copy and paste the first line. ",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13336,153880086,2017-11-29T18:48:47Z,test/core/transport/chttp2/settings_timeout_test.cc,"@@ -0,0 +1,258 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>++#include <memory>+#include <thread>++#include <gtest/gtest.h>++#include ""src/core/lib/iomgr/endpoint.h""+#include ""src/core/lib/iomgr/error.h""+#include ""src/core/lib/iomgr/pollset.h""+#include ""src/core/lib/iomgr/pollset_set.h""+#include ""src/core/lib/iomgr/resolve_address.h""+#include ""src/core/lib/iomgr/tcp_client.h""+#include ""src/core/lib/slice/slice_internal.h""++#include ""test/core/util/port.h""+#include ""test/core/util/test_config.h""++namespace grpc_core {+namespace test {+namespace {++// A gRPC server, running in its own thread.+class ServerThread {+ public:+  explicit ServerThread(const char* address) : address_(address) {}++  void Start() {+    // Start server with 1-second handshake timeout.+    grpc_arg arg;+    arg.type = GRPC_ARG_INTEGER;+    arg.key = const_cast<char*>(GRPC_ARG_SERVER_HANDSHAKE_TIMEOUT_MS);+    arg.value.integer = 1000;+    grpc_channel_args args = {1, &arg};+    server_ = grpc_server_create(&args, nullptr);+    ASSERT_TRUE(grpc_server_add_insecure_http2_port(server_, address_));+    cq_ = grpc_completion_queue_create_for_next(nullptr);+    grpc_server_register_completion_queue(server_, cq_, nullptr);+    grpc_server_start(server_);+    thread_.reset(new std::thread(std::bind(&ServerThread::Serve, this)));+  }++  void Shutdown() {+    grpc_completion_queue* shutdown_cq =+        grpc_completion_queue_create_for_pluck(nullptr);+    grpc_server_shutdown_and_notify(server_, shutdown_cq, nullptr);+    GPR_ASSERT(grpc_completion_queue_pluck(shutdown_cq, nullptr,+                                           grpc_timeout_seconds_to_deadline(1),+                                           nullptr)+                   .type == GRPC_OP_COMPLETE);+    grpc_completion_queue_destroy(shutdown_cq);+    grpc_server_destroy(server_);+    grpc_completion_queue_destroy(cq_);+    thread_->join();+  }++ private:+  void Serve() {+    // The completion queue should not return anything other than shutdown.+    grpc_event ev = grpc_completion_queue_next(+        cq_, gpr_inf_future(GPR_CLOCK_MONOTONIC), nullptr);+    ASSERT_EQ(GRPC_QUEUE_SHUTDOWN, ev.type);+  }++  const char* address_;  // Do not own.+  grpc_server* server_ = nullptr;+  grpc_completion_queue* cq_ = nullptr;+  std::unique_ptr<std::thread> thread_;+};++// A TCP client that connects to the server, reads data until the server+// closes, and then terminates.+class Client {+ public:+  explicit Client(const char* server_address)+      : server_address_(server_address) {}++  void Connect() {+    grpc_exec_ctx exec_ctx = GRPC_EXEC_CTX_INIT;+    grpc_resolved_addresses* server_addresses = nullptr;+    grpc_error* error =+        grpc_blocking_resolve_address(server_address_, ""80"", &server_addresses);+    ASSERT_EQ(GRPC_ERROR_NONE, error) << grpc_error_string(error);+    ASSERT_GE(server_addresses->naddrs, 1UL);+    pollset_ = (grpc_pollset*)gpr_zalloc(grpc_pollset_size());+    grpc_pollset_init(pollset_, &mu_);+    grpc_pollset_set* pollset_set = grpc_pollset_set_create();+    grpc_pollset_set_add_pollset(&exec_ctx, pollset_set, pollset_);+    EventState state;+    grpc_tcp_client_connect(&exec_ctx, state.closure(), &endpoint_, pollset_set,+                            nullptr /* channel_args */, server_addresses->addrs,+                            1000);+    ASSERT_TRUE(PollUntilDone(+        &exec_ctx, &state,+        grpc_timespec_to_millis_round_up(gpr_inf_future(GPR_CLOCK_MONOTONIC))));+    ASSERT_EQ(GRPC_ERROR_NONE, state.error());+    grpc_pollset_set_destroy(&exec_ctx, pollset_set);+    grpc_endpoint_add_to_pollset(&exec_ctx, endpoint_, pollset_);+    grpc_resolved_addresses_destroy(server_addresses);+    grpc_exec_ctx_finish(&exec_ctx);+  }++  // Reads until an error is returned.+  // Returns false if no error is returned by the deadline.+  bool Read() {","This is C++ code, so I think it's fine to use a true-for-success semantic.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/13336,153880756,2017-11-29T18:51:11Z,test/core/transport/chttp2/settings_timeout_test.cc,"@@ -0,0 +1,258 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>++#include <memory>+#include <thread>++#include <gtest/gtest.h>++#include ""src/core/lib/iomgr/endpoint.h""+#include ""src/core/lib/iomgr/error.h""+#include ""src/core/lib/iomgr/pollset.h""+#include ""src/core/lib/iomgr/pollset_set.h""+#include ""src/core/lib/iomgr/resolve_address.h""+#include ""src/core/lib/iomgr/tcp_client.h""+#include ""src/core/lib/slice/slice_internal.h""++#include ""test/core/util/port.h""+#include ""test/core/util/test_config.h""++namespace grpc_core {+namespace test {+namespace {++// A gRPC server, running in its own thread.+class ServerThread {+ public:+  explicit ServerThread(const char* address) : address_(address) {}++  void Start() {+    // Start server with 1-second handshake timeout.+    grpc_arg arg;+    arg.type = GRPC_ARG_INTEGER;+    arg.key = const_cast<char*>(GRPC_ARG_SERVER_HANDSHAKE_TIMEOUT_MS);+    arg.value.integer = 1000;+    grpc_channel_args args = {1, &arg};+    server_ = grpc_server_create(&args, nullptr);+    ASSERT_TRUE(grpc_server_add_insecure_http2_port(server_, address_));+    cq_ = grpc_completion_queue_create_for_next(nullptr);+    grpc_server_register_completion_queue(server_, cq_, nullptr);+    grpc_server_start(server_);+    thread_.reset(new std::thread(std::bind(&ServerThread::Serve, this)));+  }++  void Shutdown() {+    grpc_completion_queue* shutdown_cq =+        grpc_completion_queue_create_for_pluck(nullptr);+    grpc_server_shutdown_and_notify(server_, shutdown_cq, nullptr);+    GPR_ASSERT(grpc_completion_queue_pluck(shutdown_cq, nullptr,+                                           grpc_timeout_seconds_to_deadline(1),+                                           nullptr)+                   .type == GRPC_OP_COMPLETE);+    grpc_completion_queue_destroy(shutdown_cq);+    grpc_server_destroy(server_);+    grpc_completion_queue_destroy(cq_);+    thread_->join();+  }++ private:+  void Serve() {+    // The completion queue should not return anything other than shutdown.+    grpc_event ev = grpc_completion_queue_next(+        cq_, gpr_inf_future(GPR_CLOCK_MONOTONIC), nullptr);+    ASSERT_EQ(GRPC_QUEUE_SHUTDOWN, ev.type);+  }++  const char* address_;  // Do not own.+  grpc_server* server_ = nullptr;+  grpc_completion_queue* cq_ = nullptr;+  std::unique_ptr<std::thread> thread_;+};++// A TCP client that connects to the server, reads data until the server+// closes, and then terminates.+class Client {+ public:+  explicit Client(const char* server_address)+      : server_address_(server_address) {}++  void Connect() {+    grpc_exec_ctx exec_ctx = GRPC_EXEC_CTX_INIT;+    grpc_resolved_addresses* server_addresses = nullptr;+    grpc_error* error =+        grpc_blocking_resolve_address(server_address_, ""80"", &server_addresses);+    ASSERT_EQ(GRPC_ERROR_NONE, error) << grpc_error_string(error);+    ASSERT_GE(server_addresses->naddrs, 1UL);+    pollset_ = (grpc_pollset*)gpr_zalloc(grpc_pollset_size());+    grpc_pollset_init(pollset_, &mu_);+    grpc_pollset_set* pollset_set = grpc_pollset_set_create();+    grpc_pollset_set_add_pollset(&exec_ctx, pollset_set, pollset_);+    EventState state;+    grpc_tcp_client_connect(&exec_ctx, state.closure(), &endpoint_, pollset_set,+                            nullptr /* channel_args */, server_addresses->addrs,+                            1000);+    ASSERT_TRUE(PollUntilDone(+        &exec_ctx, &state,+        grpc_timespec_to_millis_round_up(gpr_inf_future(GPR_CLOCK_MONOTONIC))));+    ASSERT_EQ(GRPC_ERROR_NONE, state.error());+    grpc_pollset_set_destroy(&exec_ctx, pollset_set);+    grpc_endpoint_add_to_pollset(&exec_ctx, endpoint_, pollset_);+    grpc_resolved_addresses_destroy(server_addresses);+    grpc_exec_ctx_finish(&exec_ctx);+  }++  // Reads until an error is returned.+  // Returns false if no error is returned by the deadline.+  bool Read() {","My point here is that if you are using true-for-success, then could you rename the func to ReadAndExpectFailure? Otherwise it is surprising that a function called Read() would return success upon hitting an error condition",
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/13336,153882069,2017-11-29T18:56:09Z,test/core/transport/chttp2/settings_timeout_test.cc,"@@ -0,0 +1,258 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>++#include <memory>+#include <thread>++#include <gtest/gtest.h>++#include ""src/core/lib/iomgr/endpoint.h""+#include ""src/core/lib/iomgr/error.h""+#include ""src/core/lib/iomgr/pollset.h""+#include ""src/core/lib/iomgr/pollset_set.h""+#include ""src/core/lib/iomgr/resolve_address.h""+#include ""src/core/lib/iomgr/tcp_client.h""+#include ""src/core/lib/slice/slice_internal.h""++#include ""test/core/util/port.h""+#include ""test/core/util/test_config.h""++namespace grpc_core {+namespace test {+namespace {++// A gRPC server, running in its own thread.+class ServerThread {+ public:+  explicit ServerThread(const char* address) : address_(address) {}++  void Start() {+    // Start server with 1-second handshake timeout.+    grpc_arg arg;+    arg.type = GRPC_ARG_INTEGER;+    arg.key = const_cast<char*>(GRPC_ARG_SERVER_HANDSHAKE_TIMEOUT_MS);+    arg.value.integer = 1000;+    grpc_channel_args args = {1, &arg};+    server_ = grpc_server_create(&args, nullptr);+    ASSERT_TRUE(grpc_server_add_insecure_http2_port(server_, address_));+    cq_ = grpc_completion_queue_create_for_next(nullptr);+    grpc_server_register_completion_queue(server_, cq_, nullptr);+    grpc_server_start(server_);+    thread_.reset(new std::thread(std::bind(&ServerThread::Serve, this)));+  }++  void Shutdown() {+    grpc_completion_queue* shutdown_cq =+        grpc_completion_queue_create_for_pluck(nullptr);+    grpc_server_shutdown_and_notify(server_, shutdown_cq, nullptr);+    GPR_ASSERT(grpc_completion_queue_pluck(shutdown_cq, nullptr,+                                           grpc_timeout_seconds_to_deadline(1),+                                           nullptr)+                   .type == GRPC_OP_COMPLETE);+    grpc_completion_queue_destroy(shutdown_cq);+    grpc_server_destroy(server_);+    grpc_completion_queue_destroy(cq_);+    thread_->join();+  }++ private:+  void Serve() {+    // The completion queue should not return anything other than shutdown.+    grpc_event ev = grpc_completion_queue_next(+        cq_, gpr_inf_future(GPR_CLOCK_MONOTONIC), nullptr);+    ASSERT_EQ(GRPC_QUEUE_SHUTDOWN, ev.type);+  }++  const char* address_;  // Do not own.+  grpc_server* server_ = nullptr;+  grpc_completion_queue* cq_ = nullptr;+  std::unique_ptr<std::thread> thread_;+};++// A TCP client that connects to the server, reads data until the server+// closes, and then terminates.+class Client {+ public:+  explicit Client(const char* server_address)+      : server_address_(server_address) {}++  void Connect() {+    grpc_exec_ctx exec_ctx = GRPC_EXEC_CTX_INIT;+    grpc_resolved_addresses* server_addresses = nullptr;+    grpc_error* error =+        grpc_blocking_resolve_address(server_address_, ""80"", &server_addresses);+    ASSERT_EQ(GRPC_ERROR_NONE, error) << grpc_error_string(error);+    ASSERT_GE(server_addresses->naddrs, 1UL);+    pollset_ = (grpc_pollset*)gpr_zalloc(grpc_pollset_size());+    grpc_pollset_init(pollset_, &mu_);+    grpc_pollset_set* pollset_set = grpc_pollset_set_create();+    grpc_pollset_set_add_pollset(&exec_ctx, pollset_set, pollset_);+    EventState state;+    grpc_tcp_client_connect(&exec_ctx, state.closure(), &endpoint_, pollset_set,+                            nullptr /* channel_args */, server_addresses->addrs,+                            1000);+    ASSERT_TRUE(PollUntilDone(+        &exec_ctx, &state,+        grpc_timespec_to_millis_round_up(gpr_inf_future(GPR_CLOCK_MONOTONIC))));+    ASSERT_EQ(GRPC_ERROR_NONE, state.error());+    grpc_pollset_set_destroy(&exec_ctx, pollset_set);+    grpc_endpoint_add_to_pollset(&exec_ctx, endpoint_, pollset_);+    grpc_resolved_addresses_destroy(server_addresses);+    grpc_exec_ctx_finish(&exec_ctx);+  }++  // Reads until an error is returned.+  // Returns false if no error is returned by the deadline.+  bool Read() {","Probably just a comment change right... 'returns true if read is successful, false if it failed (e.g. due to deadline expiry)'",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13336,153892725,2017-11-29T19:35:27Z,test/core/transport/chttp2/settings_timeout_test.cc,"@@ -0,0 +1,258 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>++#include <memory>+#include <thread>++#include <gtest/gtest.h>++#include ""src/core/lib/iomgr/endpoint.h""+#include ""src/core/lib/iomgr/error.h""+#include ""src/core/lib/iomgr/pollset.h""+#include ""src/core/lib/iomgr/pollset_set.h""+#include ""src/core/lib/iomgr/resolve_address.h""+#include ""src/core/lib/iomgr/tcp_client.h""+#include ""src/core/lib/slice/slice_internal.h""++#include ""test/core/util/port.h""+#include ""test/core/util/test_config.h""++namespace grpc_core {+namespace test {+namespace {++// A gRPC server, running in its own thread.+class ServerThread {+ public:+  explicit ServerThread(const char* address) : address_(address) {}++  void Start() {+    // Start server with 1-second handshake timeout.+    grpc_arg arg;+    arg.type = GRPC_ARG_INTEGER;+    arg.key = const_cast<char*>(GRPC_ARG_SERVER_HANDSHAKE_TIMEOUT_MS);+    arg.value.integer = 1000;+    grpc_channel_args args = {1, &arg};+    server_ = grpc_server_create(&args, nullptr);+    ASSERT_TRUE(grpc_server_add_insecure_http2_port(server_, address_));+    cq_ = grpc_completion_queue_create_for_next(nullptr);+    grpc_server_register_completion_queue(server_, cq_, nullptr);+    grpc_server_start(server_);+    thread_.reset(new std::thread(std::bind(&ServerThread::Serve, this)));+  }++  void Shutdown() {+    grpc_completion_queue* shutdown_cq =+        grpc_completion_queue_create_for_pluck(nullptr);+    grpc_server_shutdown_and_notify(server_, shutdown_cq, nullptr);+    GPR_ASSERT(grpc_completion_queue_pluck(shutdown_cq, nullptr,+                                           grpc_timeout_seconds_to_deadline(1),+                                           nullptr)+                   .type == GRPC_OP_COMPLETE);+    grpc_completion_queue_destroy(shutdown_cq);+    grpc_server_destroy(server_);+    grpc_completion_queue_destroy(cq_);+    thread_->join();+  }++ private:+  void Serve() {+    // The completion queue should not return anything other than shutdown.+    grpc_event ev = grpc_completion_queue_next(+        cq_, gpr_inf_future(GPR_CLOCK_MONOTONIC), nullptr);+    ASSERT_EQ(GRPC_QUEUE_SHUTDOWN, ev.type);+  }++  const char* address_;  // Do not own.+  grpc_server* server_ = nullptr;+  grpc_completion_queue* cq_ = nullptr;+  std::unique_ptr<std::thread> thread_;+};++// A TCP client that connects to the server, reads data until the server+// closes, and then terminates.+class Client {+ public:+  explicit Client(const char* server_address)+      : server_address_(server_address) {}++  void Connect() {+    grpc_exec_ctx exec_ctx = GRPC_EXEC_CTX_INIT;+    grpc_resolved_addresses* server_addresses = nullptr;+    grpc_error* error =+        grpc_blocking_resolve_address(server_address_, ""80"", &server_addresses);+    ASSERT_EQ(GRPC_ERROR_NONE, error) << grpc_error_string(error);+    ASSERT_GE(server_addresses->naddrs, 1UL);+    pollset_ = (grpc_pollset*)gpr_zalloc(grpc_pollset_size());+    grpc_pollset_init(pollset_, &mu_);+    grpc_pollset_set* pollset_set = grpc_pollset_set_create();+    grpc_pollset_set_add_pollset(&exec_ctx, pollset_set, pollset_);+    EventState state;+    grpc_tcp_client_connect(&exec_ctx, state.closure(), &endpoint_, pollset_set,+                            nullptr /* channel_args */, server_addresses->addrs,+                            1000);+    ASSERT_TRUE(PollUntilDone(+        &exec_ctx, &state,+        grpc_timespec_to_millis_round_up(gpr_inf_future(GPR_CLOCK_MONOTONIC))));+    ASSERT_EQ(GRPC_ERROR_NONE, state.error());+    grpc_pollset_set_destroy(&exec_ctx, pollset_set);+    grpc_endpoint_add_to_pollset(&exec_ctx, endpoint_, pollset_);+    grpc_resolved_addresses_destroy(server_addresses);+    grpc_exec_ctx_finish(&exec_ctx);+  }++  // Reads until an error is returned.+  // Returns false if no error is returned by the deadline.+  bool Read() {",I've tried to clean up the semantics here a bit.,
10120821,ctiller,https://api.github.com/repos/grpc/grpc/pulls/13442,153942566,2017-11-29T23:07:17Z,test/core/util/port_hermetic.cc,"@@ -0,0 +1,41 @@+/*","I made a similar complaint on the original PR, and it still stands. I think the name of this file is wrong.All of our tests should be hermetic - the name is too broad in this context to give any meaning.I'd rather see port_isolated_runtime_environment.cc or (better) shorter but with the same meaning.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/13559,153961850,2017-11-30T01:05:26Z,src/core/lib/iomgr/ev_poll_posix.cc,"@@ -1382,7 +1382,7 @@ static poll_args* get_poller_locked(struct pollfd* fds, nfds_t count) {   gpr_thd_options opt = gpr_thd_options_default();   gpr_ref(&g_cvfds.pollcount);   gpr_thd_options_set_detached(&opt);-  GPR_ASSERT(gpr_thd_new(&t_id, &run_poll, pargs, &opt));+  GPR_ASSERT(gpr_thd_new(&t_id, ""gpr_poller"", &run_poll, pargs, &opt));",@sreecha got any naming suggestions here?,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/13559,153962184,2017-11-30T01:07:51Z,src/core/lib/support/thd_posix.cc,"@@ -33,17 +33,31 @@ struct thd_arg {   void (*body)(void* arg); /* body of a thread */   void* arg;               /* argument to a thread */+  const char* name;        /* name of thread */",we should probably document that `name` can be NULL (and will be if the platform doesn't support thread naming).,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/13559,153992706,2017-11-30T06:08:39Z,src/core/lib/iomgr/timer_manager.cc,"@@ -93,7 +93,7 @@ static void start_timer_thread_and_unlock(void) {   // to leak through g_completed_threads and be freed in gc_completed_threads()   // before ""&ct->t"" is written to, causing a use-after-free.   gpr_mu_lock(&g_mu);-  gpr_thd_new(&ct->t, timer_thread, ct, &opt);+  gpr_thd_new(&ct->t, ""gpr_timer"", timer_thread, ct, &opt);",I'd go one step further here and suggest `grpc_global_timer_thread` because a `grpc_timer` is a specific structure and so it could lead to confusion as to whether the thread belongs to a specific structure or the entire library.,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/13476,153995688,2017-11-30T06:38:55Z,src/csharp/Grpc.Core/Internal/DefaultObjectPool.cs,"@@ -0,0 +1,196 @@+#region Copyright notice and license++// Copyright 2017 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Threading;+using System.Collections.Generic;+using Grpc.Core.Utils;++namespace Grpc.Core.Internal+{+    /// <summary>+    /// Pool of objects that combines a shared pool and a thread local pool.+    /// </summary>+    internal class DefaultObjectPool<T> : IObjectPool<T>+        where T : class, IDisposable+    {+        readonly object myLock = new object();+        readonly Func<T> itemFactory;++        // Queue shared between threads, access needs to be synchronized.+        readonly Queue<T> sharedQueue;+        readonly int sharedCapacity;++        readonly ThreadLocal<ThreadLocalData> threadLocalData;+        readonly int threadLocalCapacity;+        readonly int rentLimit;++        bool disposed;++        /// <summary>+        /// Initializes a new instance of <c>DefaultObjectPool</c> with given shared capacity and thread local capacity.+        /// Thread local capacity should be significantly smaller than the shared capacity as we don't guarantee immediately+        /// disposing the objects in the thread local pool after this pool is disposed (they will eventually be garbage collected+        /// after the thread that owns them has finished).+        /// On average, the shared pool will only be accessed approx. once for every <c>threadLocalCapacity / 2</c> rent or lease+        /// operations.+        /// </summary>+        public DefaultObjectPool(Func<T> itemFactory, int sharedCapacity, int threadLocalCapacity)","We can look into that in the future once we have more data. For now I'll leave as is, warmup shouldn't be big of an overhead as it only requires acquiring the shared lock once every rentLimit items.",
14932100,adelez,https://api.github.com/repos/grpc/grpc/pulls/13442,154245807,2017-12-01T01:05:34Z,WORKSPACE,"@@ -115,3 +115,13 @@ http_archive(     strip_prefix = ""abseil-cpp-cc4bed2d74f7c8717e31f9579214ab52a9c9c610"",     url = ""https://github.com/abseil/abseil-cpp/archive/cc4bed2d74f7c8717e31f9579214ab52a9c9c610.tar.gz"", )++http_archive(",We need to reference the toolchains repo for it to work.,
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/13413,154539760,2017-12-03T22:48:34Z,include/grpc++/impl/codegen/status.h,"@@ -59,6 +69,8 @@ class Status {   /// Return the (binary) error details.   // Usually it contains a serialized google.rpc.Status proto.   grpc::string error_details() const { return binary_error_details_; }+  /// Return the full fidelity error string, which includes all child errors.","Note this is an API change (with the new ctor). I think if you do not want to defer this PR, it would be better to (for now) move the two into private and add a friend function/class to get and set it and mark the new function/class experimental. The name error_string is not very clear (mainly because we already have error_message and error_details...), maybe it should be called debug_error_string? Does it only get set when there is a non-OK status?The error_string only applies to the client side, right? Maybe the new API can be on ClientContext instead...",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/13576,154684573,2017-12-04T15:42:35Z,test/cpp/qps/client_sync.cc,"@@ -182,12 +181,40 @@ class SynchronousStreamingClient : public SynchronousClient {     // don't set the value since the stream is failed and shouldn't be timed     entry->set_status(s.error_code());     if (!s.ok()) {-      gpr_log(GPR_ERROR, ""Stream %"" PRIuPTR "" received an error %s"", thread_idx,-              s.error_message().c_str());+      std::lock_guard<std::mutex> l(stream_mu_[thread_idx]);+      if (!shutdown_[thread_idx].val) {+        gpr_log(GPR_ERROR, ""Stream %"" PRIuPTR "" received an error %s"",+                thread_idx, s.error_message().c_str());+      }     }+    // Lock the stream_mu_ now because the client context could change+    std::lock_guard<std::mutex> l(stream_mu_[thread_idx]);     context_[thread_idx].~ClientContext();     new (&context_[thread_idx]) ClientContext();   }+  void OnAllStreams(std::function<bool(ClientContext*, StreamType*)> cleaner) {+    std::vector<std::thread> cleanup_threads;+    for (size_t i = 0; i < num_threads_; i++) {+      cleanup_threads.emplace_back([this, i, cleaner]() {+        std::lock_guard<std::mutex> l(stream_mu_[i]);+        if (stream_[i]) {+          shutdown_[i].val = cleaner(&context_[i], stream_[i].get());","I'm a little confused by this.  What happens if stream is not initialized by the time we call ```OnAllStreams```?  Then shutdown would never get set.  It looks like this PR addresses a race condition where we shutdown before we finish initialization, but if looks like its impossible for that to happen.",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/13603,154694734,2017-12-04T16:14:03Z,src/python/grpcio/grpc/_cython/_cygrpc/credentials.pxd.pxi,"@@ -12,20 +12,66 @@ # See the License for the specific language governing permissions and # limitations under the License. -cimport cpython++cdef class CallCredentials:++  cdef grpc_call_credentials *c(self)++  # TODO(https://github.com/grpc/grpc/issues/12531): remove.+  cdef grpc_call_credentials *c_credentials+++cdef int _get_metadata(+    void *state, grpc_auth_metadata_context context,+    grpc_credentials_plugin_metadata_cb cb, void *user_data,+    grpc_metadata creds_md[GRPC_METADATA_CREDENTIALS_PLUGIN_SYNC_MAX],+    size_t *num_creds_md, grpc_status_code *status,+    const char **error_details) with gil++cdef void _destroy(void *state) with gil+++cdef class MetadataPluginCallCredentials(CallCredentials):++  cdef readonly object _metadata_plugin+  cdef readonly bytes _name++  cdef grpc_call_credentials *c(self)+++cdef grpc_call_credentials *_composition(call_credentialses)+++cdef class CompositeCallCredentials(CallCredentials):++  cdef readonly tuple _call_credentialses++  cdef grpc_call_credentials *c(self)   cdef class ChannelCredentials: +  cdef grpc_channel_credentials *c(self)++  # TODO(https://github.com/grpc/grpc/issues/12531): remove.   cdef grpc_channel_credentials *c_credentials",Why is this still needed?It looks like it doesn't get set by any of its subclasses.  (Same with ```CallCredentials.c_credentials```),
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/13576,154725936,2017-12-04T17:59:52Z,test/cpp/qps/client_sync.cc,"@@ -182,12 +181,40 @@ class SynchronousStreamingClient : public SynchronousClient {     // don't set the value since the stream is failed and shouldn't be timed     entry->set_status(s.error_code());     if (!s.ok()) {-      gpr_log(GPR_ERROR, ""Stream %"" PRIuPTR "" received an error %s"", thread_idx,-              s.error_message().c_str());+      std::lock_guard<std::mutex> l(stream_mu_[thread_idx]);+      if (!shutdown_[thread_idx].val) {+        gpr_log(GPR_ERROR, ""Stream %"" PRIuPTR "" received an error %s"",+                thread_idx, s.error_message().c_str());+      }     }+    // Lock the stream_mu_ now because the client context could change+    std::lock_guard<std::mutex> l(stream_mu_[thread_idx]);     context_[thread_idx].~ClientContext();     new (&context_[thread_idx]) ClientContext();   }+  void OnAllStreams(std::function<bool(ClientContext*, StreamType*)> cleaner) {+    std::vector<std::thread> cleanup_threads;+    for (size_t i = 0; i < num_threads_; i++) {+      cleanup_threads.emplace_back([this, i, cleaner]() {+        std::lock_guard<std::mutex> l(stream_mu_[i]);+        if (stream_[i]) {+          shutdown_[i].val = cleaner(&context_[i], stream_[i].get());",Sounds good. My original intention was to make this a general map-operation-on-stream but there is no need for such generality now (or possibly ever). Changed.,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/13632,154786990,2017-12-04T21:54:06Z,src/core/ext/transport/inproc/inproc_transport.cc,"@@ -670,6 +678,12 @@ static void op_state_machine(grpc_exec_ctx* exec_ctx, void* arg,           nullptr);       s->recv_initial_md_op->payload->recv_initial_metadata           .recv_initial_metadata->deadline = s->deadline;+      if (s->recv_initial_md_op->payload->recv_initial_metadata+              .trailing_metadata_available != nullptr) {+        *s->recv_initial_md_op->payload->recv_initial_metadata+            .trailing_metadata_available =+                other != nullptr && other->send_trailing_md_op != nullptr;",Can I request a set of parens around the contents of line 685?  Line 683-684 is so long that it is easy to misparse this.,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13633,154834381,2017-12-05T02:45:35Z,src/python/grpcio/grpc/_server.py,"@@ -591,7 +591,13 @@ def _handle_call(rpc_event, generic_handlers, thread_pool,     if not rpc_event.success:         return None, None     if rpc_event.request_call_details.method is not None:-        method_handler = _find_method_handler(rpc_event, generic_handlers)+        try:+            method_handler = _find_method_handler(rpc_event, generic_handlers)+        except Exception as e:  # pylint: disable=broad-except",Name the Exception `exception`.,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13633,154834481,2017-12-05T02:46:34Z,src/python/grpcio/grpc/_server.py,"@@ -591,7 +591,13 @@ def _handle_call(rpc_event, generic_handlers, thread_pool,     if not rpc_event.success:         return None, None     if rpc_event.request_call_details.method is not None:-        method_handler = _find_method_handler(rpc_event, generic_handlers)+        try:+            method_handler = _find_method_handler(rpc_event, generic_handlers)+        except Exception as e:  # pylint: disable=broad-except+            details = 'Exception servicing handler: {}'.format(e)+            logging.exception(details)",Isn't the whole point of `logging.exception` that it logs the stack trace for you? @kpayson64: are you saying that the code in its current form does not log the full stack trace?,
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/13633,155020941,2017-12-05T17:35:38Z,src/python/grpcio/grpc/_server.py,"@@ -591,7 +591,13 @@ def _handle_call(rpc_event, generic_handlers, thread_pool,     if not rpc_event.success:         return None, None     if rpc_event.request_call_details.method is not None:-        method_handler = _find_method_handler(rpc_event, generic_handlers)+        try:+            method_handler = _find_method_handler(rpc_event, generic_handlers)+        except Exception as e:  # pylint: disable=broad-except+            details = 'Exception servicing handler: {}'.format(e)+            logging.exception(details)",Looks like it.  I had assumed that string-formatting the exception wouldn't output the full stack trace.,
17460127,y-zeng,https://api.github.com/repos/grpc/grpc/pulls/13647,155338604,2017-12-06T19:36:08Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -643,16 +643,22 @@ static void start_transport_op_locked(grpc_exec_ctx* exec_ctx, void* arg,     op->connectivity_state = nullptr;   } -  if (op->send_ping != nullptr) {+  if (op->send_ping.on_initiate != nullptr || op->send_ping.on_ack != nullptr) {     if (chand->lb_policy == nullptr) {       GRPC_CLOSURE_SCHED(-          exec_ctx, op->send_ping,+          exec_ctx, op->send_ping.on_initiate,",It's probably safe to schedule a null closure: https://github.com/grpc/grpc/blob/master/src/core/lib/iomgr/closure.h#L292,
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/13663,155384468,2017-12-06T22:46:50Z,test/cpp/end2end/client_lb_end2end_test.cc,"@@ -573,15 +573,28 @@ TEST_F(ClientLbEnd2endTest, RoundRobinReresolve) {     CheckRpcSendOk();   }   // Kill all servers+  gpr_log(GPR_INFO, ""****** ABOUT TO KILL SERVERS *******"");   for (size_t i = 0; i < servers_.size(); ++i) {     servers_[i]->Shutdown(false);   }-  // Client request should fail.-  CheckRpcSendFailure();+  gpr_log(GPR_INFO, ""****** SERVERS KILLED *******"");+  gpr_log(GPR_INFO, ""****** SENDING DOOMED REQUESTS *******"");+  // Client requests should fail. Send enough to tickle all subchannels.+  for (size_t i = 0; i < servers_.size(); ++i) CheckRpcSendFailure();+  gpr_log(GPR_INFO, ""****** DOOMED REQUESTS SENT *******"");   // Bring servers back up on the same port (we aren't recreating the channel).+  gpr_log(GPR_INFO, ""****** RESTARTING SERVERS *******"");   StartServers(kNumServers, ports);-  // Client request should succeed.-  CheckRpcSendOk();+  gpr_log(GPR_INFO, ""****** SERVERS RESTARTED *******"");+  gpr_log(GPR_INFO, ""****** SENDING REQUEST TO SUCCEED *******"");+  // Client request should eventually (but still fairly soon) succeed.+  bool call_succeeded = false;","Suggest changing line 591 to line 597 to```gpr_timespec deadline = grpc_timeout_seconds_to_deadline(5);while (gpr_time_cmp(deadline, gpr_now(GPR_CLOCK_MONOTONIC)) > 0) {  if (SendRpc().ok()) break;}GPR_ASSERT(gpr_time_cmp(deadline, gpr_now(GPR_CLOCK_MONOTONIC)) > 0);```",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/13663,155403778,2017-12-07T00:45:55Z,test/cpp/end2end/client_lb_end2end_test.cc,"@@ -573,15 +573,28 @@ TEST_F(ClientLbEnd2endTest, RoundRobinReresolve) {     CheckRpcSendOk();   }   // Kill all servers+  gpr_log(GPR_INFO, ""****** ABOUT TO KILL SERVERS *******"");   for (size_t i = 0; i < servers_.size(); ++i) {     servers_[i]->Shutdown(false);   }-  // Client request should fail.-  CheckRpcSendFailure();+  gpr_log(GPR_INFO, ""****** SERVERS KILLED *******"");+  gpr_log(GPR_INFO, ""****** SENDING DOOMED REQUESTS *******"");+  // Client requests should fail. Send enough to tickle all subchannels.+  for (size_t i = 0; i < servers_.size(); ++i) CheckRpcSendFailure();+  gpr_log(GPR_INFO, ""****** DOOMED REQUESTS SENT *******"");   // Bring servers back up on the same port (we aren't recreating the channel).+  gpr_log(GPR_INFO, ""****** RESTARTING SERVERS *******"");   StartServers(kNumServers, ports);-  // Client request should succeed.-  CheckRpcSendOk();+  gpr_log(GPR_INFO, ""****** SERVERS RESTARTED *******"");+  gpr_log(GPR_INFO, ""****** SENDING REQUEST TO SUCCEED *******"");+  // Client request should eventually (but still fairly soon) succeed.+  bool call_succeeded = false;","Done, kinda. I saved the value of `now` separately. Otherwise the condition inside the assert isn't exactly equivalent to the one in the `while`.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/13670,155428950,2017-12-07T04:34:48Z,src/core/ext/filters/client_channel/backup_poller.cc,"@@ -95,6 +95,8 @@ static void g_poller_unref(grpc_exec_ctx* exec_ctx) {                                             p, grpc_schedule_on_exec_ctx));     gpr_mu_unlock(p->pollset_mu);     grpc_timer_cancel(exec_ctx, &p->polling_timer);+  } else {+    gpr_mu_unlock(&g_poller_mu);",wouldn't you have to unconditionally unlock?,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/13521,155449815,2017-12-07T07:50:18Z,src/csharp/Grpc.Microbenchmarks/SendMessageBenchmark.cs,"@@ -52,7 +52,7 @@ public void Run(int threadCount, int iterations, int payloadSize)          private void ThreadBody(int iterations, int payloadSize)         {-            var completionRegistry = new CompletionRegistry(environment, () => environment.BatchContextPool.Lease());+            var completionRegistry = new CompletionRegistry(environment, () => environment.BatchContextPool.Lease(), () => RequestCallContextSafeHandle.Create());","it looks a little strange how this is using `RequestCallContextSafeHandle.Create()` without the pool, even though it doesn't matter and is unused.Replace `() => RequestCallContextSafeHandle.Create()` with something like `() => null` for clarity?",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13667,155631245,2017-12-07T20:25:34Z,src/python/grpcio/grpc/__init__.py,"@@ -858,6 +858,21 @@ def set_details(self, details):     """"""         raise NotImplementedError() +    @abc.abstractmethod+    def abort(self, code, details):+        """"""Terminates the current RPC with a non-OK by raising an exception+    status code.++    The code and details passed as arguments will supercede the existing ones.","This should be eight spaces in from the left edge. `pyformat` wasn't able to correctly adjust our doc strings when we jumped from two-space indents to four-space indents, but take a look at the way I recently cleaned up the credentials classes' doc strings as an example.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13667,155632585,2017-12-07T20:30:54Z,src/python/grpcio_tests/tests/unit/_metadata_code_details_test.py,"@@ -363,6 +380,102 @@ def testCustomCodeStreamStream(self):         self.assertIs(_NON_OK_CODE, exception_context.exception.code())         self.assertEqual(_DETAILS, exception_context.exception.details()) +    def testAbortedUnaryUnary(self):+        self._servicer.set_code(_NON_OK_CODE)+        self._servicer.set_details(_DETAILS)+        self._servicer.set_call_abort()++        with self.assertRaises(grpc.RpcError) as exception_context:+            self._unary_unary.with_call(object(), metadata=_CLIENT_METADATA)++        self.assertTrue(+            test_common.metadata_transmitted(+                _CLIENT_METADATA, self._servicer.received_client_metadata()))+        self.assertTrue(+            test_common.metadata_transmitted(+                _SERVER_INITIAL_METADATA,+                exception_context.exception.initial_metadata()))+        self.assertTrue(+            test_common.metadata_transmitted(+                _SERVER_TRAILING_METADATA,+                exception_context.exception.trailing_metadata()))+        self.assertIs(_NON_OK_CODE, exception_context.exception.code())+        self.assertEqual(_DETAILS, exception_context.exception.details())++    def testAbortedUnaryStream(self):+        self._servicer.set_code(_NON_OK_CODE)+        self._servicer.set_details(_DETAILS)+        self._servicer.set_call_abort()++        call = self._unary_stream(+            _SERIALIZED_REQUEST, metadata=_CLIENT_METADATA)+        received_initial_metadata = call.initial_metadata()+        with self.assertRaises(grpc.RpcError):+            for _ in call:+                pass++        self.assertTrue(+            test_common.metadata_transmitted(+                _CLIENT_METADATA, self._servicer.received_client_metadata()))+        self.assertTrue(+            test_common.metadata_transmitted(_SERVER_INITIAL_METADATA,+                                             received_initial_metadata))+        self.assertTrue(+            test_common.metadata_transmitted(_SERVER_TRAILING_METADATA,+                                             call.trailing_metadata()))+        self.assertIs(_NON_OK_CODE, call.code())+        self.assertEqual(_DETAILS, call.details())++    def testAbortedStreamUnary(self):+        self._servicer.set_code(_NON_OK_CODE)+        self._servicer.set_details(_DETAILS)+        self._servicer.set_call_abort()++        with self.assertRaises(grpc.RpcError) as exception_context:+            self._stream_unary.with_call(+                iter([_SERIALIZED_REQUEST] * test_constants.STREAM_LENGTH),+                metadata=_CLIENT_METADATA)++        self.assertTrue(+            test_common.metadata_transmitted(+                _CLIENT_METADATA, self._servicer.received_client_metadata()))+        self.assertTrue(+            test_common.metadata_transmitted(+                _SERVER_INITIAL_METADATA,+                exception_context.exception.initial_metadata()))+        self.assertTrue(+            test_common.metadata_transmitted(+                _SERVER_TRAILING_METADATA,+                exception_context.exception.trailing_metadata()))+        self.assertIs(_NON_OK_CODE, exception_context.exception.code())+        self.assertEqual(_DETAILS, exception_context.exception.details())++    def testAbortedStreamStream(self):+        self._servicer.set_code(_NON_OK_CODE)+        self._servicer.set_details(_DETAILS)+        self._servicer.set_call_abort()++        call = self._stream_stream(+            iter([object()] * test_constants.STREAM_LENGTH),+            metadata=_CLIENT_METADATA)+        received_initial_metadata = call.initial_metadata()+        with self.assertRaises(grpc.RpcError) as exception_context:+            for _ in call:",Just `next(call)` or `list(call)` here too?,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13667,155632875,2017-12-07T20:32:16Z,src/python/grpcio_tests/tests/unit/_metadata_code_details_test.py,"@@ -363,6 +380,102 @@ def testCustomCodeStreamStream(self):         self.assertIs(_NON_OK_CODE, exception_context.exception.code())         self.assertEqual(_DETAILS, exception_context.exception.details()) +    def testAbortedUnaryUnary(self):+        self._servicer.set_code(_NON_OK_CODE)+        self._servicer.set_details(_DETAILS)+        self._servicer.set_call_abort()++        with self.assertRaises(grpc.RpcError) as exception_context:+            self._unary_unary.with_call(object(), metadata=_CLIENT_METADATA)++        self.assertTrue(+            test_common.metadata_transmitted(+                _CLIENT_METADATA, self._servicer.received_client_metadata()))+        self.assertTrue(+            test_common.metadata_transmitted(+                _SERVER_INITIAL_METADATA,+                exception_context.exception.initial_metadata()))+        self.assertTrue(+            test_common.metadata_transmitted(+                _SERVER_TRAILING_METADATA,+                exception_context.exception.trailing_metadata()))+        self.assertIs(_NON_OK_CODE, exception_context.exception.code())+        self.assertEqual(_DETAILS, exception_context.exception.details())++    def testAbortedUnaryStream(self):+        self._servicer.set_code(_NON_OK_CODE)+        self._servicer.set_details(_DETAILS)+        self._servicer.set_call_abort()++        call = self._unary_stream(+            _SERIALIZED_REQUEST, metadata=_CLIENT_METADATA)+        received_initial_metadata = call.initial_metadata()+        with self.assertRaises(grpc.RpcError):+            for _ in call:","`next(call)`? Or if you need to exhaust the entire iterator, `list(call)`?",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/13667,155635175,2017-12-07T20:42:40Z,src/python/grpcio/grpc/__init__.py,"@@ -858,6 +858,21 @@ def set_details(self, details):     """"""         raise NotImplementedError() +    @abc.abstractmethod+    def abort(self, code, details):+        """"""Terminates the current RPC with a non-OK by raising an exception+    status code.++    The code and details passed as arguments will supercede the existing ones.++    Args:+      code: A StatusCode object to be sent to the client. It should not be OK.+      details: An arbitrary string to be sent to the client upon completion.++    Raises:+      Exception: An exception is always raised to signal the abortion the RPC.+    """"""+",Thanks for catching this! Must have accidentally deleted it at some point.,
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/13667,155635393,2017-12-07T20:43:39Z,src/python/grpcio_tests/tests/unit/_metadata_code_details_test.py,"@@ -67,6 +68,9 @@ def unary_unary(self, request, context):             self._received_client_metadata = context.invocation_metadata()             context.send_initial_metadata(_SERVER_INITIAL_METADATA)             context.set_trailing_metadata(_SERVER_TRAILING_METADATA)+            if self._call_abort:+                context.abort(self._code, self._details)+                return",I want to ensure we don't accidentally fall through and set_code and set_details causing the test to unintentionally pass.,
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/13672,155696322,2017-12-08T03:11:58Z,src/python/grpcio/grpc/_cython/_cygrpc/metadata.pyx.pxi,"@@ -0,0 +1,64 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import collections++_Metadatum = collections.namedtuple('_Metadatum', ('key', 'value',))+++cdef void _c_metadata(metadata, size_t *c_count, grpc_metadata **c_metadata):+ import logging+ try:+  if metadata is None:+    c_count[0] = 0+    c_metadata[0] = NULL+  else:+    metadatum_count = len(metadata)+    if metadatum_count == 0:+      c_count[0] = 0+      c_metadata[0] = NULL+    else:+      c_count[0] = metadatum_count+      c_metadata[0] = <grpc_metadata *>gpr_malloc(+          metadatum_count * sizeof(grpc_metadata))+      for index, (key, value) in enumerate(metadata):+        encoded_key = _encode(key)+        encoded_value = value if encoded_key[-4:] == b'-bin' else _encode(value)+        c_metadata[0][index].key = _slice_from_bytes(encoded_key)+        c_metadata[0][index].value = _slice_from_bytes(encoded_value)+ except Exception as e:+  logging.exception('Huh? Metadata was ""%s""!', metadata)+++cdef void _un_c_metadata(int count, grpc_metadata *c_metadata):",Can we call this delete_c_metadata?  I needed to look at the function to get a sense of what it did.,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13667,155712625,2017-12-08T06:45:17Z,src/python/grpcio_tests/tests/unit/_metadata_code_details_test.py,"@@ -67,6 +68,9 @@ def unary_unary(self, request, context):             self._received_client_metadata = context.invocation_metadata()             context.send_initial_metadata(_SERVER_INITIAL_METADATA)             context.set_trailing_metadata(_SERVER_TRAILING_METADATA)+            if self._call_abort:+                context.abort(self._code, self._details)+                return","`raise ValueError('Unreachable statement reached in _Servicer!')`? If we were in the test case instance we'd call `unittest.TestCase.fail`, but we're not, so an exception's just as good.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13667,155713138,2017-12-08T06:50:03Z,src/python/grpcio_tests/tests/unit/_metadata_code_details_test.py,"@@ -363,6 +380,102 @@ def testCustomCodeStreamStream(self):         self.assertIs(_NON_OK_CODE, exception_context.exception.code())         self.assertEqual(_DETAILS, exception_context.exception.details()) +    def testAbortedUnaryUnary(self):+        self._servicer.set_code(_NON_OK_CODE)+        self._servicer.set_details(_DETAILS)+        self._servicer.set_call_abort()++        with self.assertRaises(grpc.RpcError) as exception_context:+            self._unary_unary.with_call(object(), metadata=_CLIENT_METADATA)++        self.assertTrue(+            test_common.metadata_transmitted(+                _CLIENT_METADATA, self._servicer.received_client_metadata()))+        self.assertTrue(+            test_common.metadata_transmitted(+                _SERVER_INITIAL_METADATA,+                exception_context.exception.initial_metadata()))+        self.assertTrue(+            test_common.metadata_transmitted(+                _SERVER_TRAILING_METADATA,+                exception_context.exception.trailing_metadata()))+        self.assertIs(_NON_OK_CODE, exception_context.exception.code())+        self.assertEqual(_DETAILS, exception_context.exception.details())++    def testAbortedUnaryStream(self):+        self._servicer.set_code(_NON_OK_CODE)+        self._servicer.set_details(_DETAILS)+        self._servicer.set_call_abort()++        call = self._unary_stream(+            _SERIALIZED_REQUEST, metadata=_CLIENT_METADATA)+        received_initial_metadata = call.initial_metadata()+        with self.assertRaises(grpc.RpcError):+            for _ in call:","Now that I reread this old code: because the test calls `self._servicer.set_call_abort()` before even invoking the RPC, the response iterator will raise with the very first attempt to read a message. So in this circumstance `next(call)` is guaranteed to raise an exception, and we needn't have the test exhaust the response iterator.Correct me if I'm introducing a race condition and flaky test? No one likes flaky tests.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13672,155714548,2017-12-08T07:04:52Z,src/python/grpcio/grpc/_cython/_cygrpc/metadata.pyx.pxi,"@@ -0,0 +1,64 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import collections++_Metadatum = collections.namedtuple('_Metadatum', ('key', 'value',))+++cdef void _c_metadata(metadata, size_t *c_count, grpc_metadata **c_metadata):+ import logging+ try:+  if metadata is None:+    c_count[0] = 0+    c_metadata[0] = NULL+  else:+    metadatum_count = len(metadata)+    if metadatum_count == 0:+      c_count[0] = 0",I feel similarly but I don't think it's a workaround. I think it might actually be the way Cython code is supposed to be written; Cython flatly suggests doing so with the message `a starred assignment target must be in a list or tuple - maybe you meant to use an index assignment: var[0] = ...` when I try to write it with the `*` operator.,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13672,155715618,2017-12-08T07:15:44Z,src/python/grpcio/grpc/_cython/_cygrpc/metadata.pyx.pxi,"@@ -0,0 +1,64 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import collections++_Metadatum = collections.namedtuple('_Metadatum', ('key', 'value',))+++cdef void _c_metadata(metadata, size_t *c_count, grpc_metadata **c_metadata):+ import logging+ try:+  if metadata is None:+    c_count[0] = 0+    c_metadata[0] = NULL+  else:+    metadatum_count = len(metadata)+    if metadatum_count == 0:+      c_count[0] = 0+      c_metadata[0] = NULL+    else:+      c_count[0] = metadatum_count+      c_metadata[0] = <grpc_metadata *>gpr_malloc(+          metadatum_count * sizeof(grpc_metadata))+      for index, (key, value) in enumerate(metadata):+        encoded_key = _encode(key)+        encoded_value = value if encoded_key[-4:] == b'-bin' else _encode(value)+        c_metadata[0][index].key = _slice_from_bytes(encoded_key)+        c_metadata[0][index].value = _slice_from_bytes(encoded_value)+ except Exception as e:+  logging.exception('Huh? Metadata was ""%s""!', metadata)+++cdef void _un_c_metadata(int count, grpc_metadata *c_metadata):","[I thought I had a good joke going](https://www.google.com/search?q=unsee&tbm=isch), but... okay. How's `_release_c_metadata`?",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/13667,155824383,2017-12-08T16:58:04Z,src/python/grpcio_tests/tests/unit/_metadata_code_details_test.py,"@@ -67,6 +68,9 @@ def unary_unary(self, request, context):             self._received_client_metadata = context.invocation_metadata()             context.send_initial_metadata(_SERVER_INITIAL_METADATA)             context.set_trailing_metadata(_SERVER_TRAILING_METADATA)+            if self._call_abort:+                context.abort(self._code, self._details)+                return","The problem is that raising *any* exception will be caught by server logic and we end up with a similar mode that may make our tests pass even if abort didn't do anything. I don't think there's a perfect way (without keeping a TestCase reference in the servicer) to handle it (even returning None is prone to that behavior, but I prefer doing something vastly different than raising (cause that's what `.abort()` does).",
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/13413,155849361,2017-12-08T18:58:21Z,include/grpc++/impl/codegen/client_context.h,"@@ -348,6 +348,13 @@ class ClientContext {   /// Applications never need to call this method.   grpc_call* c_call() { return call_; } +  /// EXPERIMENTAL debugging API+  ///+  /// if status is not ok() for an RPC, this will return a detailed string+  /// of the gRPC Core error that led to the failure. It should not be relied+  /// upon for anything other than gaining more debug data in failure cases.+  grpc::string debug_error_string() const { return debug_error_string_; }",Sorry I was talking about string_ref in https://github.com/grpc/grpc/blob/94e676e10f8c739289924b8458a246699e3623ce/include/grpc%2B%2B/impl/codegen/string_ref.h#L41But I guess a string is fine too...,
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/13562,155894747,2017-12-08T22:55:10Z,test/core/bad_ssl/server_common.cc,"@@ -28,19 +29,23 @@  * configured to cause some failure case in the SSL connection path.  */ +// In some distros, gflags is in the namespace google, and in some others,+// in gflags. This hack is enabling us to find both.+namespace google {}","Rather than duplicate this in all of the files, use a common headers that has this comment and namespace hack",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/13226,156130196,2017-12-11T16:47:34Z,tools/failures/detect_new_failures.py,"@@ -0,0 +1,259 @@+#!/usr/bin/env python+# Copyright 2015 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++""""""Detect new flakes and create issues for them""""""++from __future__ import absolute_import+from __future__ import division+from __future__ import print_function++import datetime+import json+import logging+import os+import pprint+import sys+import urllib+import urllib2+from collections import namedtuple++gcp_utils_dir = os.path.abspath(+    os.path.join(os.path.dirname(__file__), '../gcp/utils'))+sys.path.append(gcp_utils_dir)++import big_query_utils++GH_ISSUE_CREATION_URL = 'https://api.github.com/repos/grpc/grpc/issues'+GH_ISSUE_SEARCH_URL = 'https://api.github.com/search/issues'+KOKORO_BASE_URL = 'https://kokoro2.corp.google.com/job/'++def gh(url, data=None):+  request = urllib2.Request(url, data=data)+  assert TOKEN+  request.add_header('Authorization', 'token {}'.format(TOKEN))+  if data:+    request.add_header('Content-type', 'application/json')+  response = urllib2.urlopen(request)+  if 200 <= response.getcode() < 300:+    return json.loads(response.read())+  else:+    raise ValueError('Error ({}) accessing {}'.format(+        response.getcode(), response.geturl()))+++def search_gh_issues(search_term, status='open'):+  params = ' '.join((search_term, 'is:issue', 'is:open', 'repo:grpc/grpc'))+  qargs = urllib.urlencode({'q': params})+  url = '?'.join((GH_ISSUE_SEARCH_URL, qargs))+  response = gh(url)+  return response+++def create_gh_issue(title, body, labels, assignees=[]):+  params = {'title': title,+            'body': body,+            'labels': labels}+  if assignees:+    params['assignees'] = assignees+  data = json.dumps(params)+  response = gh(GH_ISSUE_CREATION_URL, data)+  issue_url = response['html_url']+  print('Created issue {} for {}'.format(issue_url, title))+++def build_kokoro_url(job_name, build_id):+  job_path = '{}/{}'.format('/job/'.join(job_name.split('/')), build_id)+  return KOKORO_BASE_URL + job_path+++def create_issues(new_flakes, always_create):+  for test_name, results_row in new_flakes.items():+    poll_strategy, job_name, build_id, timestamp = results_row+    url = build_kokoro_url(job_name, build_id)",nit: add a TODO that kokoro build url has only temporary lifetime and we are only using it because we don't have access to the sponge link,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/13226,156130833,2017-12-11T16:49:46Z,tools/failures/detect_new_failures.py,"@@ -0,0 +1,259 @@+#!/usr/bin/env python","nit: I'm not a bit fan of the tools/failures naming (it's yet another new directory under tools/ which is already messy enough), but if you think that's a good name then let's use it (and we can move scripts around later).",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13722,156451209,2017-12-12T18:16:50Z,examples/python/interceptors/default_value/greeter_client.py,"@@ -0,0 +1,37 @@+# Copyright 2015 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++""""""The Python implementation of the GRPC helloworld.Greeter client.""""""++from __future__ import print_function++import grpc++import helloworld_pb2+import helloworld_pb2_grpc+from default_value_client_interceptor import DefaultValueClientInterceptor as _DefaultValueClientInterceptor","[Import only packages and modules (almost always modules!); never classes, functions, or other elements of modules.](https://google.github.io/styleguide/pyguide.html?showone=Imports#Imports)",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13722,156452234,2017-12-12T18:21:06Z,examples/python/interceptors/headers/header_manipulator_client_interceptor.py,"@@ -0,0 +1,45 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++""""""Interceptor that adds headers to outgoing requests.""""""++import collections++import grpc+from generic_client_interceptor import GenericClientInterceptor as _GenericClientInterceptor++class _ClientCallDetails(+        collections.namedtuple('_ClientCallDetails',+                               ('method', 'timeout', 'metadata',+                                'credentials')), grpc.ClientCallDetails):+    pass+++class HeaderManipulatorClientInterceptor(_GenericClientInterceptor):",We've managed to avoid implementation inheritance in gRPC Python so far; why should this class be something that is a GenericClientInterceptor rather than something that has a GenericClientInterceptor?,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13722,156452317,2017-12-12T18:21:31Z,examples/python/interceptors/headers/header_manipulator_client_interceptor.py,"@@ -0,0 +1,45 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++""""""Interceptor that adds headers to outgoing requests.""""""++import collections++import grpc+from generic_client_interceptor import GenericClientInterceptor as _GenericClientInterceptor++class _ClientCallDetails(+        collections.namedtuple('_ClientCallDetails',+                               ('method', 'timeout', 'metadata',+                                'credentials')), grpc.ClientCallDetails):+    pass+++class HeaderManipulatorClientInterceptor(_GenericClientInterceptor):",Abstraction violation: a module-public class's super classes must also be public.,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13722,156453167,2017-12-12T18:24:32Z,examples/python/interceptors/headers/generic_client_interceptor.py,"@@ -0,0 +1,55 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++""""""Base class for interceptors that operate on all RPC types.""""""++import grpc+++class GenericClientInterceptor(grpc.UnaryUnaryClientInterceptor,+                               grpc.UnaryStreamClientInterceptor,+                               grpc.StreamUnaryClientInterceptor,+                               grpc.StreamStreamClientInterceptor):++    def intercept_call(self, client_call_details, request_iterator, request_streaming, response_streaming):+        return client_call_details, request_iterator, None++    def intercept_unary_unary(self, continuation, client_call_details, request):+        new_details, new_request_iterator, postprocess = self.intercept_call(client_call_details, iter((request,)), False, False)+        response = continuation(new_details, next(new_request_iterator))+        if postprocess:+            return next(postprocess((response,)))+        return response++    def intercept_unary_stream(self, continuation, client_call_details, request):+        new_details, new_request_iterator, postprocess = self.intercept_call(client_call_details, iter((request,)), False, True)+        response_iterator = continuation(new_details, new_request_iterator)+        if postprocess:+            return postprocess(response_iterator)+        return response_iterator++    def intercept_stream_unary(self, continuation, client_call_details, request_iterator):+        new_details, new_request_iterator, postprocess = self.intercept_call(client_call_details, request_iterator, True, False)+        response = continuation(new_details, next(new_request_iterator))+        if postprocess:+            return next(postprocess(iter((response,))))+        return response++    def intercept_stream_stream(self, continuation, client_call_details, request_iterator):+        new_details, new_request_iterator, postprocess = self.intercept_call(client_call_details, request_iterator, True, True)+        response_iterator = continuation(new_details, new_request_iterator)+        if postprocess:+            return postprocess(response_iterator)+        return response_iterator","Tuck this into an `else:` (assumming ""`return <conditional expression>`"" doesn't fit on a single line).",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13722,156453787,2017-12-12T18:26:37Z,src/python/grpcio/grpc/_interceptor.py,"@@ -0,0 +1,315 @@+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Implementation of gRPC Python interceptors.""""""++import collections+import sys++import grpc+++class _ServicePipeline(object):++    def __init__(self, interceptors):+        self.interceptors = tuple(interceptors)++    def _continuation(self, thunk, index):+        return lambda context: self._intercept_at(thunk, index, context)++    def _intercept_at(self, thunk, index, context):+        if index < len(self.interceptors):+            interceptor = self.interceptors[index]+            thunk = self._continuation(thunk, index + 1)+            return interceptor.intercept_service(thunk, context)+        return thunk(context)++    def execute(self, thunk, context):+        return self._intercept_at(thunk, 0, context)+++def service_pipeline(interceptors):+    if interceptors:",`return <conditional expression>` since it fits on a single line.,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13728,156455789,2017-12-12T18:33:40Z,tools/distrib/yapf_code.sh,"@@ -20,8 +20,10 @@ cd ""$(dirname ""${0}"")/../..""  DIRS=(     'src/python'+    'examples/python'","This list is only two entries long so far, but please keep it alphabetized.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/13733,156516286,2017-12-12T22:36:29Z,test/cpp/thread_manager/thread_manager_test.cc,"@@ -31,8 +31,14 @@ namespace grpc { class ThreadManagerTest final : public grpc::ThreadManager {",Can I suggest renaming this struct to MockThreadManager since that's what this essentially is?,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/13733,156519501,2017-12-12T22:52:32Z,include/grpc++/server.h,"@@ -136,12 +136,17 @@ class Server final : public ServerInterface, private GrpcLibraryCodegen {   /// completion queue (in param sync_server_cqs) to use for listening to   /// incoming requests (used only in case of sync server)   ///+  /// \param max_threads The maximum number of threads per server completion+  /// queue (i.e number of polling threads and the number of threads executing+  /// the RPC handlers)+  ///","This is an API extension and has to be something that we are permanently ok with. As such, can I suggest going through the gRFC process here? I know that this is a long-standing feature request, but there are possibly other ways of doing this and also providing other benefits without going through this particular API extension. For example, there are other variants of the feature request (#12472, #12737) that maybe could get handled by a unified path or at the core level instead of the C++ level. Additionally, the PR in progress (#13697) will have a side effect of generating a recoverable RESOURCE_EXHAUSTED status instead of exception when we are out of threads.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/13671,156803620,2017-12-13T22:23:29Z,test/cpp/end2end/grpclb_end2end_test.cc,"@@ -442,7 +442,7 @@ class GrpclbEnd2endTest : public ::testing::Test {    void WaitForBackend(size_t backend_idx) {     do {-      CheckRpcSendOk();+      SendRpc();",This is relaxed because now we have a situation where we need to keep checking while no backends are available for a long time and a call may fail due to timeout.But I think this won't affect any correctness. Because this method is used to wait for a backend until it's available. Checking the `request_count` is sufficient.,
520669,dhermes,https://api.github.com/repos/grpc/grpc/pulls/13578,157076530,2017-12-14T22:12:50Z,src/python/grpcio/grpc/_channel.py,"@@ -728,7 +731,10 @@ def stop_channel_spin(timeout):  # pylint: disable=unused-argument                     call.cancel()      channel_spin_thread = _common.CleanupThread(-        stop_channel_spin, target=channel_spin)+        stop_channel_spin,+        target=channel_spin,+        name='Thread-gRPC-StopChannelSpin',","@nathanielmanistaatgoogle This should probably be named `Thread-gRPC-ChannelSpin`, when I wrote it I didn't realize that the `target` was more relevant than the cleanup (this thread doesn't even get returned, so for someone to call `.join()` on it, they'd have to grab it from `threading.enumerate()` or similar).FWIW I'm not entirely sure which channel is being spun or why.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/13798,157264592,2017-12-15T18:11:24Z,include/grpc/impl/codegen/grpc_types.h,"@@ -390,6 +390,12 @@ typedef enum grpc_call_error {    GRPC_INITIAL_METADATA_WAIT_FOR_READY_EXPLICITLY_SET | \    GRPC_INITIAL_METADATA_CORKED | GRPC_WRITE_THROUGH) +/* Minimum and maximum protocol accepted versions. */","Good point.I'm wondering where to put these in the src tree now though. A couple of ideas:* added to [src/core/tsi/gts_transport_security.h](https://github.com/grpc/grpc/blob/master/src/core/tsi/gts_transport_security.h)* added to [src/core/ext/filters/client_channel/client_channel.h](https://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/client_channel.h)* in it's own header file, perhaps under `src/core/tsi`what do you think?",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/13815,157635656,2017-12-19T00:15:22Z,include/grpc++/impl/codegen/method_handler_impl.h,"@@ -27,6 +27,25 @@ namespace grpc {  namespace internal {++// Invoke the method handler, fill in the status, and+// return whether or not we finished safely (without an exception).+// Note that exception handling is 0-cost in most compiler/library+// implementations (except when an exception is actually thrown),+// so this process doesn't require additional overhead in the common case.+// Additionally, we don't need to return if we caught an exception or not;+// the handling is the same in either case.+template <class F>+Status CatchingFunctionHandler(F&& callable) {+  try {+    return callable();","Sure, I was starting to question whether this should be considered an API breaker since it no longer allows compiling with ""-fno-exceptions"". Preprocessor guarding would avoid that issue as well.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/13494,157819203,2017-12-19T17:18:09Z,src/core/lib/iomgr/tcp_client_posix.cc,"@@ -227,6 +226,7 @@ static void on_writable(void* acp, grpc_error* error) {     error = grpc_error_set_str(error, GRPC_ERROR_STR_TARGET_ADDRESS,                                grpc_slice_from_copied_string(ac->addr_str));   }+  gpr_mu_unlock(&ac->mu);","Nit: this is probably fine, but another way to do this would be to grab the copied slice from `ac->addr_str` right after `done = (--ac->refs == 0)` but before unlocking. Still safe since `ac->addr_str` data we have to protect here, and this way we don't hold the lock for some non-trivial error manipulations",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/13815,157822290,2017-12-19T17:29:13Z,build.yaml,"@@ -4913,7 +4926,6 @@ configs:     DEFINES: NDEBUG   dbg:     CPPFLAGS: -O0-    CXXFLAGS: -fno-exceptions",is `CatchingFunctionHandler` enough to guarantee we won't accidentally introduce exceptions in the code?,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/13815,157829818,2017-12-19T18:00:44Z,build.yaml,"@@ -4913,7 +4926,6 @@ configs:     DEFINES: NDEBUG   dbg:     CPPFLAGS: -O0-    CXXFLAGS: -fno-exceptions","No, it's not. It's only one small piece of exception safety. This is specifically to make sure that exceptions in user code called by the sync server don't crash the server. This is the one code path by which we're calling user code.That said, it relates to the line above only in that we can't even use exception-related features with that command-line flag in place. The code works fine either way, so do you think that the default should be to keep -fno-exceptions and then tell users that if they want to have exceptions they need to remove that line? Or perhaps make a different build target that allows exceptions?",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/13815,157830067,2017-12-19T18:01:46Z,test/cpp/end2end/exception_test.cc,"@@ -0,0 +1,120 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <exception>+#include <memory>++#include <grpc++/channel.h>+#include <grpc++/client_context.h>+#include <grpc++/server.h>+#include <grpc++/server_builder.h>+#include <grpc++/server_context.h>+#include <grpc/impl/codegen/port_platform.h>++#include ""src/proto/grpc/testing/echo.grpc.pb.h""+#include ""test/core/util/test_config.h""++#include <gtest/gtest.h>++namespace grpc {+namespace testing {++const char* kErrorMessage = ""This service caused an exception"";++#if GRPC_ALLOW_EXCEPTIONS+class ExceptingServiceImpl : public ::grpc::testing::EchoTestService::Service {+ public:+  Status Echo(ServerContext* server_context, const EchoRequest* request,+              EchoResponse* response) override {+    throw - 1;+  }+  Status RequestStream(ServerContext* context,+                       ServerReader<EchoRequest>* reader,+                       EchoResponse* response) override {+    throw ServiceException();+  }++ private:+  class ServiceException final : public std::exception {+   public:+    ServiceException() {}++   private:+    const char* what() const noexcept override { return kErrorMessage; }+  };+};++class ExceptionTest : public ::testing::Test {+ protected:+  ExceptionTest() {}++  void SetUp() override {+    ServerBuilder builder;+    builder.RegisterService(&service_);+    server_ = builder.BuildAndStart();+  }++  void TearDown() override { server_->Shutdown(); }++  void ResetStub() {+    channel_ = server_->InProcessChannel(ChannelArguments());+    stub_ = grpc::testing::EchoTestService::NewStub(channel_);+  }++  std::shared_ptr<Channel> channel_;+  std::unique_ptr<grpc::testing::EchoTestService::Stub> stub_;+  std::unique_ptr<Server> server_;+  ExceptingServiceImpl service_;+};++TEST_F(ExceptionTest, Unary) {+  ResetStub();+  EchoRequest request;+  EchoResponse response;+  request.set_message(""test"");+  ClientContext context;++  Status s = stub_->Echo(&context, request, &response);+  EXPECT_FALSE(s.ok());+  EXPECT_EQ(s.error_code(), StatusCode::UNKNOWN);","In this case, the error_message is coming from the gRPC library since there was no `what()`, so I thought that it would be fragile to actually put in an expectation about it.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/13824,157877075,2017-12-19T21:16:28Z,tools/run_tests/run_tests.py,"@@ -379,14 +379,18 @@ def test_specs(self):                             if not test: continue                             cmdline = [binary, '--benchmark_filter=%s$' % test                                       ] + target['args']+                            timeout_seconds = _DEFAULT_TIMEOUT_SECONDS * timeout_scaling",as a side note: The way the timeouts are set for C/C++ tests is not transparent at all and there is no easy way to see what a timeout for a given test (and configuration) would be - I updated timeouts for several tests in the past and it was always a big pain (and it was difficult to check if it was done correctly). I think we will continue having problems with setting test timeout until we do some cleanup a figure out a better approach for this.,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/13824,157877329,2017-12-19T21:17:36Z,tools/run_tests/run_tests.py,"@@ -379,14 +379,18 @@ def test_specs(self):                             if not test: continue                             cmdline = [binary, '--benchmark_filter=%s$' % test                                       ] + target['args']+                            timeout_seconds = _DEFAULT_TIMEOUT_SECONDS * timeout_scaling",The source for the timeout seems to be here: https://github.com/grpc/grpc/blob/1c4d410c109157bfe924144bc777e57169d5c1e3/build.yaml#L3689,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/13815,157879239,2017-12-19T21:25:20Z,build.yaml,"@@ -4913,7 +4926,6 @@ configs:     DEFINES: NDEBUG   dbg:     CPPFLAGS: -O0-    CXXFLAGS: -fno-exceptions","I was thinking about users using an already compiled version of gRPC. In that case, the user should be ok and able to use exceptions in her application code regardless of whether gRPC has been compiled with `-fno-exceptions`. Now, if the user is compiling everything -incluiding gRPC- from source, then she'd have to create a separate target (or remove that line, given that she's willing to get dirty compiling everything anyway). In general I think erring on the side of caution is best, that is, leaving `-fno-exceptions` there.On this vein, but going the opposite direction, [this post](https://blog.mozilla.org/nnethercote/2011/01/18/the-dangers-of-fno-exceptions/) presents the dangers of disallowing exceptions on code that may use the std lib. I'm sure you were aware of that already, but just in case. ",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/13494,157880967,2017-12-19T21:32:12Z,src/core/lib/iomgr/tcp_client_posix.cc,"@@ -224,10 +228,12 @@ static void on_writable(void* acp, grpc_error* error) {     gpr_free(error_descr);     gpr_free(desc);     error = grpc_error_set_str(error, GRPC_ERROR_STR_TARGET_ADDRESS,-                               grpc_slice_from_copied_string(ac->addr_str));+                               addr_str_slice);+    grpc_slice_unref(addr_str_slice);","You are right, but how would I know `grpc_error_set_str` takes ownership? There's no documentation. Still, I'd to keep the unref, makes ""sense"" as a pattern, and it's more robust if the way the slice is used is later changed to something that doesn't take ownership.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/13815,157891245,2017-12-19T22:18:24Z,build.yaml,"@@ -4913,7 +4926,6 @@ configs:     DEFINES: NDEBUG   dbg:     CPPFLAGS: -O0-    CXXFLAGS: -fno-exceptions","tldr: I advocate omitting `-fno-exceptions` from the OSS default buildSo the issue is that some level of catching was exactly what has been requested in #13706 (and before that #9795). Users are writing method handlers for their sync servers, and those method handlers call other things. Our original pushback was that if users call functions that throw exceptions, then they should be responsible for catching any possible exceptions that are thrown (and gRPC can keep on building with `-fno-exceptions`). However, that is an impractical pushback because it violates POLA: something called from gRPC (the user's method handler) can end up crashing the gRPC server. Users may or may not even know if the code they are calling has exceptions if the exception is thrown 20 levels deep in the stack.Believe me, I am not a fan of exception-based programming. `exception_test` in this PR is the first time I have ever `throw`n in 20+ years of writing C++ code. But it's more important to keep the server alive even if it means sacrificing some purity. Note that `googletest` has [related behavior](https://github.com/google/googletest/blob/7b6561c56e353100aca8458d7bc49c4e0119bae8/googletest/docs/AdvancedGuide.md#disabling-catching-test-thrown-exceptions): the default behavior is that if a test throws an exception, `googletest` catches the exception and marks the test failed but doesn't kill the executable.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13578,158382304,2017-12-21T21:26:31Z,src/python/grpcio/grpc/_server.py,"@@ -773,7 +776,11 @@ def cleanup_server(timeout):                 _stop(state, timeout).wait()          thread = _common.CleanupThread(-            cleanup_server, target=_serve, args=(state,))+            cleanup_server,+            target=_serve,+            args=(state,),+            name='Thread-gRPC-CleanupServer',",If we're consistently naming threads after targets: `Thread-gRPC-_serve`?This is the thread that drives gRPC Core on the service-side and does all the work of serving RPCs except for the running of application code (which is done in the thread pool supplied by the application).,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/13900,159343518,2018-01-03T00:12:15Z,src/core/lib/surface/completion_queue.cc,"@@ -780,10 +780,11 @@ typedef struct {   bool first_loop; } cq_is_finished_arg; -class ExecCtxNext : public grpc_core::ExecCtx {+class ExecCtxNext final : public grpc_core::ExecCtx {",why does this class (and `ExecCtxPluck`) need be final? Do these changes still belong to this PR?,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/13932,160017499,2018-01-06T04:40:01Z,src/core/ext/filters/client_channel/subchannel.h,"@@ -73,6 +73,34 @@ typedef struct grpc_subchannel_key grpc_subchannel_key; #define GRPC_SUBCHANNEL_REF_EXTRA_ARGS #endif +class grpc_connected_subchannel : public grpc_core::RefCountedWithTracing {","Yes, we may want to rename the class to follow C++ class naming conventions.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/13911,160017505,2018-01-06T04:40:16Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc,"@@ -306,6 +306,54 @@ static void add_pending_ping(pending_ping** root, grpc_closure* on_initiate,  */ typedef struct rr_connectivity_data rr_connectivity_data; +typedef struct glb_lb_call_data {","just a suggestion: you may want to take this opportunity to turn this into a C++ class, inheriting from [RefCountedWithTracing](https://github.com/grpc/grpc/blob/master/src/core/lib/support/ref_counted.h#L67). That's what I've done in my subchannel refactoring PR (see [here](https://github.com/grpc/grpc/pull/13932/files#diff-4ae77ab90fbeb7fc0f5dba398b2b63afR76))",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13805,160175017,2018-01-08T15:42:10Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc,"@@ -1019,13 +1019,13 @@ static void glb_shutdown_locked(grpc_lb_policy* pol) {     grpc_call_cancel(lb_call, nullptr);     /* lb_on_server_status_received will pick up the cancel and clean up */   }-  if (glb_policy->retry_timer_active) {+  if (glb_policy->retry_timer_callback_pending) {     grpc_timer_cancel(&glb_policy->lb_call_retry_timer);-    glb_policy->retry_timer_active = false;+    glb_policy->retry_timer_callback_pending = false;","As I think we discussed in another PR, we should not be setting any of these values to false outside of the timer callback function itself.  Let's go ahead and make that change as part of this PR, so that the semantics are clear.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/13676,160548117,2018-01-09T22:55:38Z,src/core/lib/support/vector.h,"@@ -19,13 +19,93 @@ #ifndef GRPC_CORE_LIB_SUPPORT_VECTOR_H #define GRPC_CORE_LIB_SUPPORT_VECTOR_H -#include ""absl/container/inlined_vector.h""+#include <cassert>+ #include ""src/core/lib/support/memory.h""  namespace grpc_core { +// NOTE: We eventually want to use absl::InlinedVector here.  However,+// there are currently build problems that prevent us from using absl.+// In the interim, we define a custom implementation as a place-holder,+// with the intent to eventually replace this with the absl+// implementation.+//+// This place-holder implementation does not implement the full set of+// functionality from the absl version; it has just the methods that we+// currently happen to need in gRPC.  If additional functionality is+// needed before this gets replaced with the absl version, it can be+// added, with the following proviso:+//+// ANY METHOD ADDED HERE MUST COMPLY WITH THE INTERFACE IN THE absl+// IMPLEMENTATION!+//+// TODO(ctiller, nnoble, roth): Replace this with absl::InlinedVector+// once we integrate absl into the gRPC build system in a usable way. template <typename T, size_t N>-using InlinedVector = absl::InlinedVector<T, N, Allocator<T>>;+class InlinedVector {+ public:+  InlinedVector() {}+  ~InlinedVector() {+    for (size_t i = 0; i < size_ && i < N; ++i) {+      T& value = *reinterpret_cast<T*>(inline_ + i);+      value.~T();+    }+    if (size_ > N) {  // Avoid subtracting two signed values.+      for (size_t i = 0; i < size_ - N; ++i) {+        dynamic_[i].~T();+      }+    }+    gpr_free(dynamic_);+  }++  // For now, we do not support copying.+  InlinedVector(const InlinedVector&) = delete;+  InlinedVector& operator=(const InlinedVector&) = delete;++  T& operator[](size_t offset) {+    assert(offset < size_);+    if (offset < N) {+      return *reinterpret_cast<T*>(inline_ + offset);+    } else {+      return dynamic_[offset - N];+    }+  }++  template <typename... Args>+  void emplace_back(Args&&... args) {+    if (size_ < N) {+      new (&inline_[size_]) T(std::forward<Args>(args)...);",We can't use `new`. Prefer [this](https://github.com/grpc/grpc/blob/0ea629c61ec70a35075e800bc3f85651f00e746f/src/core/lib/support/memory.h#L30). Idem for line 85 and 92 below.,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/13282,160758827,2018-01-10T18:21:35Z,src/core/lib/iomgr/timer_interface.h,"@@ -0,0 +1,116 @@+/*+ *+ * Copyright 2015 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_IOMGR_TIMER_H+#define GRPC_CORE_LIB_IOMGR_TIMER_H++#include ""src/core/lib/iomgr/port.h""++#include <grpc/support/port_platform.h>+#include <grpc/support/time.h>+#include <type_traits>+#include ""src/core/lib/iomgr/exec_ctx.h""+#include ""src/core/lib/iomgr/iomgr.h""++namespace grpc_core {++// Storage type for Timer: see comment on Timer declaration below+static constexpr size_t kMaxTimerSize = 6 * sizeof(void*);+typedef std::aligned_storage<kMaxTimerSize>::type TimerStorage;++// Abstract singleton interface for implementing timer engines+class TimerEngine {+ public:+  // There's a single global TimerEngine+  static TimerEngine* Get();++  // Initialize *timer. When expired or canceled, closure will be called with+  // error set to indicate if it expired (GRPC_ERROR_NONE) or was canceled+  // (GRPC_ERROR_CANCELLED). timer_cb is guaranteed to be called exactly once,+  // and application code should check the error to determine how it was+  // invoked. The application callback is also responsible for maintaining+  // information about when to free up any user-level state+  virtual void Init(grpc_exec_ctx* exec_ctx, TimerStorage* timer,+                    grpc_millis deadline, grpc_closure* on_complete) = 0;++  // Note that there is no timer destroy function. This is because the+  // timer is a one-time occurrence with a guarantee that the callback will+  // be called exactly once, either at expiration or cancellation. Thus, all+  // the internal timer event management state is destroyed just before+  // that callback is invoked. If the user has additional state associated with+  // the timer, the user is responsible for determining when it is safe to+  // destroy that state.++  // Cancel a timer.+  // There are three cases:+  // 1. We normally cancel the timer+  // 2. The timer has already run+  // 3. We can't cancel the timer because it is ""in flight"".+  //+  // In all of these cases, the cancellation is still considered successful.+  // They are essentially distinguished in that the timer_cb will be run+  // exactly once from either the cancellation (with error GRPC_ERROR_CANCELLED)+  // or from the activation (with error GRPC_ERROR_NONE).+  //+  // Note carefully that the callback function MAY occur in the same callstack+  // as grpc_timer_cancel. It's expected that most timers will be cancelled+  // (their primary use is to implement deadlines), and so this code is+  // optimized such that cancellation costs as little as possible. Making+  // callbacks run inline matches this aim.+  //+  // Requires: cancel() must happen after init() on a given timer+  virtual void Cancel(grpc_exec_ctx* exec_ctx, TimerStorage* timer) = 0;++  // Check for timers to be run, and run them.+  // Return FIRED if timer callbacks were executed, CHECKED_AND_EMPTY if timers+  // were checked but none were ready, and NOT_CHECKED if checks were skipped.+  // If next is non-null, TRY to update *next with the next running timer IF+  // that timer occurs before *next current value. *next is never guaranteed to+  // be updated on any given execution; however, with high probability at least+  // one thread in the system will see an update at any time slice.+  enum class CheckResult { NOT_CHECKED, CHECKED_AND_EMPTY, FIRED };+  virtual void CheckTimers(grpc_exec_ctx* exec_ctx, grpc_millis* next) = 0;++  // Consume a kick received by TimerManager::Kick+  virtual void ConsumeKick() = 0;+};++// Concrete Timer instance class. To allow this type to avoid memory allocation+// even though the TimerEngine is abstract, we pre-size some storage memory and+// just pass that through (via inlined functions) to the TimerEngine+// implementation that's in use.+class Timer {+ public:+  Timer(grpc_exec_ctx* exec_ctx, grpc_millis deadline,+        grpc_closure* on_complete) {+    TimerEngine::Get()->Init(exec_ctx, &storage_, deadline, on_complete);",Resolution: we can deal with this by having the alarm use a ManualConstructor on the timer that it wraps. That keeps the complexity in alarm rather than in timer.,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/13957,160771543,2018-01-10T19:11:59Z,src/csharp/Grpc.Core/Channel.cs,"@@ -130,27 +130,33 @@ public ChannelState State         // cached handler for watch connectivity state         static readonly BatchCompletionDelegate WatchConnectivityStateHandler = (success, ctx, state) =>         {-            var tcs = (TaskCompletionSource<object>) state;-            if (success)-            {-                tcs.SetResult(null);-            }-            else-            {-                tcs.SetCanceled();-            }+            var tcs = (TaskCompletionSource<bool>) state;+            tcs.SetResult(success);         };          /// <summary>         /// Returned tasks completes once channel state has become different from          /// given lastObservedState.          /// If deadline is reached or and error occurs, returned task is cancelled.         /// </summary>-        public Task WaitForStateChangedAsync(ChannelState lastObservedState, DateTime? deadline = null)+        public async Task WaitForStateChangedAsync(ChannelState lastObservedState, DateTime? deadline = null)+        {+            var result = await WaitForStateChangedInternalAsync(lastObservedState, deadline).ConfigureAwait(false);+            if (!result)+            {+                throw new TaskCanceledException(""Reached deadline."");","Not certain here, but this causes the background watcher to loop to break out and finish as soon as one of the 1 second state-change-deadlines is reached, no?",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/13289,160787300,2018-01-10T20:15:05Z,src/core/ext/transport/chttp2/transport/chttp2_transport.cc,"@@ -232,6 +232,9 @@ void grpc_chttp2_ref_transport(grpc_chttp2_transport* t) { gpr_ref(&t->refs); }  static const grpc_transport_vtable* get_vtable(void); +// -1 == unset, 0 == disabled, 1 == enabled+static gpr_atm flow_control_enabled = -1;","should be `(gpr_atm)-1` for consistency with other uses, or better `flow_control_enabled(-1)`... but that said: why is this being done this way? It's either on or off. If you need to figure out which of those conditions it should be, that should be done in the `grpc_chttp2_plugin_init` function, not the `init_transport` function which gets invoked on each new channel. Then it could just be a global `bool` and not a `gpr_atm`",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/13883,160789300,2018-01-10T20:24:51Z,src/core/lib/channel/channel_tracer.cc,"@@ -0,0 +1,327 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/core/lib/channel/channel_tracer.h""+#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>+#include <grpc/support/useful.h>+#include <stdlib.h>+#include <string.h>++#include ""src/core/lib/iomgr/error.h""+#include ""src/core/lib/slice/slice_internal.h""+#include ""src/core/lib/support/object_registry.h""+#include ""src/core/lib/support/string.h""+#include ""src/core/lib/surface/channel.h""+#include ""src/core/lib/transport/connectivity_state.h""++grpc_core::DebugOnlyTraceFlag grpc_trace_channel_tracer_refcount(+    false, ""channel_tracer_refcount"");++// One node of tracing data+typedef struct grpc_trace_node {+  grpc_slice data;+  grpc_error* error;+  gpr_timespec time_created;+  grpc_connectivity_state connectivity_state;+  struct grpc_trace_node* next;++  // the tracer object for the (sub)channel that this trace node refers to.+  grpc_channel_tracer* referenced_tracer;+} grpc_trace_node;++/* the channel tracing object */+struct grpc_channel_tracer {","would it make sense to convert this into a class, and bring the related functions inside it? Bring it under the grpc_core namespace maybe.",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/13965,160861870,2018-01-11T04:14:05Z,src/python/grpcio_tests/tests/unit/_metadata_code_details_test.py,"@@ -302,26 +302,33 @@ def testSuccessfulStreamStream(self):         self.assertEqual(_DETAILS, response_iterator_call.details())      def testAbortedUnaryUnary(self):-        self._servicer.set_code(_NON_OK_CODE)-        self._servicer.set_details(_DETAILS)-        self._servicer.set_abort_call()--        with self.assertRaises(grpc.RpcError) as exception_context:-            self._unary_unary.with_call(object(), metadata=_CLIENT_METADATA)--        self.assertTrue(-            test_common.metadata_transmitted(-                _CLIENT_METADATA, self._servicer.received_client_metadata()))-        self.assertTrue(-            test_common.metadata_transmitted(-                _SERVER_INITIAL_METADATA,-                exception_context.exception.initial_metadata()))-        self.assertTrue(-            test_common.metadata_transmitted(-                _SERVER_TRAILING_METADATA,-                exception_context.exception.trailing_metadata()))-        self.assertIs(_NON_OK_CODE, exception_context.exception.code())-        self.assertEqual(_DETAILS, exception_context.exception.details())+        # calling abort should always fail an RPC, even for ""invalid"" codes+        server_codes = [_NON_OK_CODE, 3, grpc.StatusCode.OK]",Please make this and the next line tuples instead of lists,
675151,evanj,https://api.github.com/repos/grpc/grpc/pulls/13965,160999724,2018-01-11T16:17:26Z,src/python/grpcio/grpc/_server.py,"@@ -278,6 +278,9 @@ def set_trailing_metadata(self, trailing_metadata):             self._state.trailing_metadata = trailing_metadata      def abort(self, code, details):+        # treat OK like other invalid arguments: fail the RPC+        if code == grpc.StatusCode.OK:+            code = grpc.StatusCode.UNKNOWN","I've added it as `logging.warning`. I could not find any other places in gRPC Python that log anything other than `logging.exception`, so I hope that makes sense.",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/13965,161340548,2018-01-12T22:29:05Z,src/python/grpcio_tests/tests/unit/_metadata_code_details_test.py,"@@ -302,99 +307,125 @@ def testSuccessfulStreamStream(self):         self.assertEqual(_DETAILS, response_iterator_call.details())      def testAbortedUnaryUnary(self):-        self._servicer.set_code(_NON_OK_CODE)-        self._servicer.set_details(_DETAILS)-        self._servicer.set_abort_call()--        with self.assertRaises(grpc.RpcError) as exception_context:-            self._unary_unary.with_call(object(), metadata=_CLIENT_METADATA)--        self.assertTrue(-            test_common.metadata_transmitted(-                _CLIENT_METADATA, self._servicer.received_client_metadata()))-        self.assertTrue(-            test_common.metadata_transmitted(-                _SERVER_INITIAL_METADATA,-                exception_context.exception.initial_metadata()))-        self.assertTrue(-            test_common.metadata_transmitted(-                _SERVER_TRAILING_METADATA,-                exception_context.exception.trailing_metadata()))-        self.assertIs(_NON_OK_CODE, exception_context.exception.code())-        self.assertEqual(_DETAILS, exception_context.exception.details())+        test_cases = zip(_ABORT_CODES, _EXPECTED_CLIENT_CODES)+        for abort_code, expected_code in test_cases:+            self._servicer.set_code(abort_code)+            self._servicer.set_details(_DETAILS)+            self._servicer.set_abort_call()++            with self.assertRaises(grpc.RpcError) as exception_context:+                self._unary_unary.with_call(object(), metadata=_CLIENT_METADATA)++            self.assertTrue(+                test_common.metadata_transmitted(+                    _CLIENT_METADATA,+                    self._servicer.received_client_metadata()))+            self.assertTrue(+                test_common.metadata_transmitted(+                    _SERVER_INITIAL_METADATA,+                    exception_context.exception.initial_metadata()))+            self.assertTrue(+                test_common.metadata_transmitted(+                    _SERVER_TRAILING_METADATA,+                    exception_context.exception.trailing_metadata()))+            self.assertIs(expected_code, exception_context.exception.code())+            expected_details = _DETAILS+            if abort_code == grpc.StatusCode.OK: expected_details = ''",I think a better way to do this might be to hardcode the actual expected detail value and zip it alongside other values in the for loop,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/13984,161902728,2018-01-16T22:14:22Z,src/core/lib/support/orphanable.h,"@@ -0,0 +1,166 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_SUPPORT_ORPHANABLE_H+#define GRPC_CORE_LIB_SUPPORT_ORPHANABLE_H++#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include <memory>++#include ""src/core/lib/debug/trace.h""+#include ""src/core/lib/support/abstract.h""+#include ""src/core/lib/support/debug_location.h""+#include ""src/core/lib/support/memory.h""++namespace grpc_core {++// A base class for orphanable objects.+class Orphanable {+ public:+  // Gives up ownership of the object.  The implementation must arrange+  // to destroy the object without further interaction from the caller.+  virtual void Orphan() GRPC_ABSTRACT;++  // Not copyable or movable.+  Orphanable(const Orphanable&) = delete;+  Orphanable& operator=(const Orphanable&) = delete;++  GRPC_ABSTRACT_BASE_CLASS++ protected:+  Orphanable() {}+  virtual ~Orphanable() {}+};++template <typename T>+class OrphanableDelete {+ public:+  void operator()(T* p) { p->Orphan(); }+};++template <typename T, typename Deleter = OrphanableDelete<T>>+using OrphanablePtr = std::unique_ptr<T, Deleter>;",according to https://github.com/grpc/proposal/blob/master/L6-allow-c%2B%2B-in-grpc-core.md we shouldn't be using `std::unique_ptr` directly.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/13984,161914263,2018-01-16T23:08:49Z,src/core/lib/support/orphanable.h,"@@ -0,0 +1,166 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_SUPPORT_ORPHANABLE_H+#define GRPC_CORE_LIB_SUPPORT_ORPHANABLE_H++#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include <memory>++#include ""src/core/lib/debug/trace.h""+#include ""src/core/lib/support/abstract.h""+#include ""src/core/lib/support/debug_location.h""+#include ""src/core/lib/support/memory.h""++namespace grpc_core {++// A base class for orphanable objects.+class Orphanable {+ public:+  // Gives up ownership of the object.  The implementation must arrange+  // to destroy the object without further interaction from the caller.+  virtual void Orphan() GRPC_ABSTRACT;++  // Not copyable or movable.+  Orphanable(const Orphanable&) = delete;+  Orphanable& operator=(const Orphanable&) = delete;++  GRPC_ABSTRACT_BASE_CLASS++ protected:+  Orphanable() {}+  virtual ~Orphanable() {}+};++template <typename T>+class OrphanableDelete {+ public:+  void operator()(T* p) { p->Orphan(); }+};++template <typename T, typename Deleter = OrphanableDelete<T>>+using OrphanablePtr = std::unique_ptr<T, Deleter>;","The intent of that is that code outside of lib/support will use the abstractions provided by lib/support instead of directly using things provided in the standard library.  But code in lib/support can use things provided by the standard library as long as we don't introduce a run-time dependency.  In the case of `std::unique_ptr<>`, the only part that would impose a run-time dependency is the deleter, which we're overriding here.Note that we do already define `grpc_core::UniquePtr<>`, which is basically defined as `std::unique_ptr<>` with a deleter that calls `gpr_free()`:https://github.com/grpc/grpc/blob/master/src/core/lib/support/memory.h#L51",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/14046,162141959,2018-01-17T18:41:48Z,test/core/end2end/dualstack_socket_test.cc,"@@ -169,7 +169,7 @@ void test_connect(const char* server_host, const char* client_host, int port,   } else {     /* Give up faster when failure is expected.        BUG: Setting this to 1000 reveals a memory leak (b/18608927). */-    deadline = ms_from_now(1500);+    deadline = ms_from_now(3000);",wouldn't we want to use https://github.com/grpc/grpc/blob/3538efb53bd6d3bfca91aa50db7a6e1b97b9c855/test/core/util/test_config.h#L34 ?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/14051,162199628,2018-01-17T22:33:34Z,src/core/lib/gpr++/README.md,"@@ -0,0 +1,16 @@+# GPR++ - Google Portable Runtime for C++++The files in this directory contain various utility code for C++ code.+None of this code is gRPC-specific; anything here may also be useful+for other open source projects written in C++.++Note that this is one of the few places in src/core where we allow+the use of portability macros.++Note that this is the only place in src/core where we allow","As per our conversation, we can't use either libc++ or libstdc++ right now.  But we can use things from `std::` as long as we're careful to only use template code that does not require linking against either of those libraries.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/14042,162276863,2018-01-18T08:39:18Z,tools/internal_ci/helper_scripts/prepare_build_macos_rc,"@@ -50,7 +50,10 @@ fi set +ex  # rvm script is very verbose and exits with errorcode source $HOME/.rvm/scripts/rvm set -e  # rvm commands are very verbose-rvm use ruby-2.4+rvm install 2.5.0",how long does this take?   It will slow down all our mac builds. It might make sense to request installing ruby 2.5 by the kokoro team also so we don't have to do this forever.,
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/14071,162429314,2018-01-18T18:28:49Z,tools/distrib/build_ruby_environment_macos.sh,"@@ -49,8 +49,9 @@ MAKE=""make -j8""  for v in 2.5.0 2.4.0 2.3.0 2.2.2 2.1.6 2.0.0-p645 ; do   ccache -c-  rake -f $CROSS_RUBY cross-ruby VERSION=$v HOST=x86_64-darwin11+  rake -f ""$CROSS_RUBY"" cross-ruby VERSION=""$v"" HOST=x86_64-darwin11 MAKE=""$MAKE""","That was the bugfix I was alluding to: I think it is needed, otherwise the MAKE= above is useless. The nested script tries to read MAKE environment but it is effectively unset since it is not exported.",
5120183,jcanizales,https://api.github.com/repos/grpc/grpc/pulls/13935,162500761,2018-01-18T23:30:17Z,test/cpp/GRPCCppTests/generic/generic.mm,"@@ -0,0 +1,244 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#import <XCTest/XCTest.h>++#include <sstream>++#include <grpc++/channel.h>+#include <grpc++/client_context.h>+#include <grpc++/create_channel.h>+#include <grpc++/generic/async_generic_service.h>+#include <grpc++/generic/generic_stub.h>+#include <grpc++/server.h>+#include <grpc++/server_builder.h>+#include <grpc++/server_context.h>+#include <grpc++/support/slice.h>+#include <grpc/grpc.h>+#include <grpc/support/thd.h>+#include <grpc/support/time.h>++#include ""test/core/util/port.h""+#include ""test/core/util/test_config.h""++using std::chrono::system_clock;+using namespace grpc;++void* tag(int i) { return (void*)(intptr_t)i; }++static grpc_slice merge_slices(grpc_slice* slices, size_t nslices) {",Move this and the next function to a shared test-util library? We can't be the only ones with a need for it.,
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/13935,162504254,2018-01-18T23:53:10Z,gRPC-C++.podspec,"@@ -0,0 +1,679 @@+# This file has been automatically generated from a template file.+# Please make modifications to `templates/gRPC-C++.podspec.template`+# instead. This file can be regenerated from the template by running+# `tools/buildgen/generate_projects.sh`.++# gRPC C++ CocoaPods podspec+#+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+++Pod::Spec.new do |s|+  s.name     = 'gRPC-C++'+  # TODO (mxyan): use version that match gRPC version when pod is stabilized+  # version = '1.9.0-dev'+  version = '0.0.1'+  s.version  = version+  s.summary  = 'gRPC C++ library'",I think 'library' is fine?,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/13290,162556135,2018-01-19T08:00:05Z,templates/CMakeLists.txt.template,"@@ -161,6 +162,9 @@   include(cmake/gflags.cmake)   include(cmake/benchmark.cmake) +  include_directories(<%text>${CMAKE_CURRENT_SOURCE_DIR}/third_party/address_sorting</%text>)","you shouldn't use `include_directories` as it adds the include blindly to all targets and that's a bad practice (and also it is redundant with adding to target_include_directories).The clean way to do this is:add cmake/address_sorting.cmake  (because you are adding a third party dependency, it deserves a separate file). The file should probably look similar to other cmake/*.cmake files  and should define `_gRPC_ADDRESS_SORTING_LIBRARIES`  (the library to depend on) and   `_gRPC_ADDRESS_SORTING_INCLUDE_DIR` (I did a cleanup recently so that all the third_party deps use the same style), which will be added to target_include_directories.  That way, the entire configuration and build of address_sorting is contained in a separate cmake file and the rest of the cmake builds just uses the variables defined there.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/13290,162558641,2018-01-19T08:16:38Z,third_party/address_sorting/address_sorting.c,"@@ -0,0 +1,369 @@+/*	$NetBSD: getaddrinfo.c,v 1.82 2006/03/25 12:09:40 rpaulo Exp $	*/","The PR seems to indicated that address_sorting will be a submodule (e.g. linking to some other git repo), which it is not - the code in imported in our repository actually.That actually matters for cmake, because depending if this is an actual third_party dependency  or just imported code changes the way thing should be done in CMakeLists.txtif this is an actual ""separate library"", then what I suggested in the previous comment holds.If not (which seems to be the case), then you can just define a cmake target address_sorting (and you're doing that) and if that target is properly configured, you don't need to deal with the include directories at all - cmake will do that automatically for you.Also, the dependency on address_sorting (defined in build.yaml) shouldn't require extra changes in the CMakeLists.txt - the right address_sorting target should be generated automatically and it should be added as a dependency where needed (based on the info from build.yaml file).",
20046617,jakobr-google,https://api.github.com/repos/grpc/grpc/pulls/14120,163028148,2018-01-22T18:37:39Z,templates/tools/dockerfile/interoptest/grpc_interop_dart/build_interop.sh.template,"@@ -0,0 +1,28 @@+%YAML 1.2+--- |+  #!/bin/bash+  # Copyright 2017 gRPC authors.+  #+  # Licensed under the Apache License, Version 2.0 (the ""License"");+  # you may not use this file except in compliance with the License.+  # You may obtain a copy of the License at+  #+  #     http://www.apache.org/licenses/LICENSE-2.0+  #+  # Unless required by applicable law or agreed to in writing, software+  # distributed under the License is distributed on an ""AS IS"" BASIS,+  # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+  # See the License for the specific language governing permissions and+  # limitations under the License.+  #+  # Builds Dart interop server and client in a base image.+  set -e++  mkdir -p /var/local/git+  git clone /var/local/jenkins/grpc-dart /var/local/git/grpc-dart++  # copy service account keys if available+  cp -r /var/local/jenkins/service_account $HOME || true++  cd /var/local/git/grpc-dart/interop+  /usr/lib/dart/bin/pub get","It uses the code from the checked out repo, yes. Interop’s pubspec.yaml has a path dependency for grpc: https://github.com/dart-lang/grpc-dart/blob/master/interop/pubspec.yaml",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/13883,163093624,2018-01-22T22:53:18Z,src/core/lib/channel/channel_tracer.cc,"@@ -0,0 +1,275 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/core/lib/channel/channel_tracer.h""+#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>+#include <grpc/support/useful.h>+#include <stdlib.h>+#include <string.h>++#include ""src/core/lib/iomgr/error.h""+#include ""src/core/lib/slice/slice_internal.h""+#include ""src/core/lib/support/memory.h""+#include ""src/core/lib/support/object_registry.h""+#include ""src/core/lib/support/string.h""+#include ""src/core/lib/surface/channel.h""+#include ""src/core/lib/transport/connectivity_state.h""++namespace grpc_core {++struct TraceEvent {",should we call it a class if it has a constructor?,
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/13883,163111289,2018-01-23T00:20:40Z,src/core/lib/channel/channel_tracer.cc,"@@ -0,0 +1,275 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/core/lib/channel/channel_tracer.h""+#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>+#include <grpc/support/useful.h>+#include <stdlib.h>+#include <string.h>++#include ""src/core/lib/iomgr/error.h""+#include ""src/core/lib/slice/slice_internal.h""+#include ""src/core/lib/support/memory.h""+#include ""src/core/lib/support/object_registry.h""+#include ""src/core/lib/support/string.h""+#include ""src/core/lib/surface/channel.h""+#include ""src/core/lib/transport/connectivity_state.h""++namespace grpc_core {++struct TraceEvent {+  TraceEvent(grpc_slice data, grpc_error* error,+             grpc_connectivity_state connectivity_state,+             ChannelTracer* referenced_tracer)+      : data_(data),+        error_(error),+        connectivity_state_(connectivity_state),+        next_(nullptr) {+    referenced_tracer_ = referenced_tracer ? referenced_tracer->Ref() : nullptr;+    time_created_ = gpr_now(GPR_CLOCK_REALTIME);+  }+  grpc_slice data_;+  grpc_error* error_;+  gpr_timespec time_created_;+  grpc_connectivity_state connectivity_state_;+  TraceEvent* next_;+  // the tracer object for the (sub)channel that this trace node refers to.+  ChannelTracer* referenced_tracer_;+};++ChannelTracer::ChannelTracer(size_t max_nodes)+    : channel_uuid_(-1),+      num_nodes_logged_(0),+      list_size_(0),+      max_list_size_(max_nodes),+      head_trace_(0),+      tail_trace_(0) {+  if (!max_list_size_) return;  // tracing is disabled if max_nodes == 0+  gpr_mu_init(&tracer_mu_);+  gpr_ref_init(&refs_, 1);+  channel_uuid_ = grpc_object_registry_register_object(+      this, GRPC_OBJECT_REGISTRY_CHANNEL_TRACER);+  max_list_size_ = max_nodes;+  time_created_ = gpr_now(GPR_CLOCK_REALTIME);+}++ChannelTracer* ChannelTracer::Ref() {+  if (!max_list_size_) return nullptr;  // tracing is disabled if max_nodes == 0+  gpr_ref(&refs_);+  return this;+}++void ChannelTracer::FreeNode(TraceEvent* node) {+  GRPC_ERROR_UNREF(node->error_);+  if (node->referenced_tracer_) {+    node->referenced_tracer_->Unref();+  }+  grpc_slice_unref_internal(node->data_);+  gpr_free(node);+}++void ChannelTracer::Unref() {+  if (!max_list_size_) return;  // tracing is disabled if max_nodes == 0+  if (gpr_unref(&refs_)) {+    TraceEvent* it = head_trace_;+    while (it != nullptr) {+      TraceEvent* to_free = it;+      it = it->next_;+      FreeNode(to_free);+    }+    gpr_mu_destroy(&tracer_mu_);+  }+}++intptr_t ChannelTracer::GetUuid() { return channel_uuid_; }++void ChannelTracer::AddTrace(grpc_slice data, grpc_error* error,+                             grpc_connectivity_state connectivity_state,+                             ChannelTracer* referenced_tracer) {+  if (!max_list_size_) return;  // tracing is disabled if max_nodes == 0+  ++num_nodes_logged_;+  // create and fill up the new node+  TraceEvent* new_trace_node =+      New<TraceEvent>(data, error, connectivity_state, referenced_tracer);+  // first node case+  if (head_trace_ == nullptr) {+    head_trace_ = tail_trace_ = new_trace_node;+  }+  // regular node add case+  else {+    tail_trace_->next_ = new_trace_node;+    tail_trace_ = tail_trace_->next_;+  }+  ++list_size_;+  // maybe garbage collect the end+  if (list_size_ > max_list_size_) {+    TraceEvent* to_free = head_trace_;+    head_trace_ = head_trace_->next_;+    FreeNode(to_free);+    --list_size_;+  }+}++// returns an allocated string that represents tm according to RFC-3339.+static char* fmt_time(gpr_timespec tm) {+  char buffer[35];+  struct tm* tm_info = localtime((const time_t*)&tm.tv_sec);+  strftime(buffer, sizeof(buffer), ""%Y-%m-%dT%H:%M:%S"", tm_info);+  char* full_time_str;+  gpr_asprintf(&full_time_str, ""%s.%09dZ"", buffer, tm.tv_nsec);+  return full_time_str;+}++class ChannelTracerRenderer {+ public:+  ChannelTracerRenderer(ChannelTracer* tracer, bool recursive)+      : current_tracer_(tracer),+        recursive_(recursive),+        seen_tracers_(nullptr),+        size_(0),+        cap_(0) {}++  char* Run() {+    grpc_json* json = grpc_json_create(GRPC_JSON_OBJECT);+    AddSeenTracer(current_tracer_);+    RecursivelyPopulateJson(json);+    gpr_free(seen_tracers_);+    char* json_str = grpc_json_dump_to_string(json, 1);+    grpc_json_destroy(json);+    return json_str;+  }++ private:+  void AddSeenTracer(ChannelTracer* newly_seen) {+    if (size_ >= cap_) {+      cap_ = GPR_MAX(5 * sizeof(newly_seen), 3 * cap_ / 2);+      seen_tracers_ = (ChannelTracer**)gpr_realloc(seen_tracers_, cap_);+    }+    seen_tracers_[size_++] = newly_seen;+  }++  bool TracerAlreadySeen(ChannelTracer* tracer) {+    for (size_t i = 0; i < size_; ++i) {+      if (seen_tracers_[i] == tracer) return true;+    }+    return false;+  }++  void RecursivelyPopulateJson(grpc_json* json) {+    grpc_json* channel_data = grpc_json_create_child(+        nullptr, json, ""channelData"", nullptr, GRPC_JSON_OBJECT, false);+    grpc_json* children = nullptr;+    if (recursive_) {+      children = grpc_json_create_child(channel_data, json, ""children"", nullptr,+                                        GRPC_JSON_ARRAY, false);+    }+    PopulateTracer(channel_data, children);+  }++  void PopulateTracer(grpc_json* channel_data, grpc_json* children) {","Looks functionally correct. not sure if this part is just for testing, but if it's more permanent, then variables need a bit of renaming or just more documentation. child, children, nodes are a bit confusing :D",
17460127,y-zeng,https://api.github.com/repos/grpc/grpc/pulls/13594,163119997,2018-01-23T01:18:47Z,src/core/ext/filters/max_age/max_age_filter.cc,"@@ -85,26 +91,97 @@ struct channel_data {   grpc_connectivity_state connectivity_state;   /* Number of active calls */   gpr_atm call_count;+  /* 'idle_state' holds the states of max_idle_timer and channel idleness.+      It can contain one of the following values:+     +--------------------------------+----------------+---------++     |           idle_state           | max_idle_timer | channel |+     +--------------------------------+----------------+---------++     | MAX_IDLE_STATE_INIT            | unset          | busy    |+     | MAX_IDLE_STATE_TIMER_SET       | set, valid     | idle    |+     | MAX_IDLE_STATE_SEEN_EXIT_IDLE  | set, invalid   | busy    |+     | MAX_IDLE_STATE_SEEN_ENTER_IDLE | set, invalid   | idle    |+     +--------------------------------+----------------+---------+++     max_idle_timer will not be cancelled (unless the channel is shutting down).+     If the timer callback is called when the max_idle_timer is valid (i.e.+     idle_state is MAX_IDLE_STATE_TIMER_SET), the channel will be closed due to+     idleness, otherwise the channel won't be changed.++     State transitions:++         MAX_IDLE_STATE_INIT <-------3------ MAX_IDLE_STATE_SEEN_EXIT_IDLE+              ^    |                              ^     ^    |+              |    |                              |     |    |+              1    2     +-----------4------------+     6    7+              |    |     |                              |    |+              |    v     |                              |    v+       MAX_IDLE_STATE_TIMER_SET <----5------ MAX_IDLE_STATE_SEEN_ENTER_IDLE++     For 1, 3, 5 :  See max_idle_timer_cb() function+     For 2, 7    :  See decrease_call_count() function+     For 4, 6    :  See increase_call_count() function */+  gpr_atm idle_state;+  /* Time when the channel finished its last outstanding call, in grpc_millis */+  gpr_atm last_enter_idle_time_millis; }; }  // namespace  /* Increase the nubmer of active calls. Before the increasement, if there are no    calls, the max_idle_timer should be cancelled. */ static void increase_call_count(channel_data* chand) {+  /* Exit idle */   if (gpr_atm_full_fetch_add(&chand->call_count, 1) == 0) {-    grpc_timer_cancel(&chand->max_idle_timer);+    while (true) {+      gpr_atm idle_state = gpr_atm_acq_load(&chand->idle_state);+      switch (idle_state) {+        case MAX_IDLE_STATE_TIMER_SET:+          /* max_idle_timer_cb may have already set idle_state to+             MAX_IDLE_STATE_INIT, in this case, we don't need to set it to+             MAX_IDLE_STATE_SEEN_EXIT_IDLE */+          gpr_atm_rel_cas(&chand->idle_state, MAX_IDLE_STATE_TIMER_SET,+                          MAX_IDLE_STATE_SEEN_EXIT_IDLE);+          return;+        case MAX_IDLE_STATE_SEEN_ENTER_IDLE:+          gpr_atm_rel_store(&chand->idle_state, MAX_IDLE_STATE_SEEN_EXIT_IDLE);+          return;+        default:+          /* try again */+          break;+      }+    }   } }  /* Decrease the nubmer of active calls. After the decrement, if there are no    calls, the max_idle_timer should be started. */ static void decrease_call_count(channel_data* chand) {+  /* Enter idle */   if (gpr_atm_full_fetch_add(&chand->call_count, -1) == 1) {-    GRPC_CHANNEL_STACK_REF(chand->channel_stack, ""max_age max_idle_timer"");-    grpc_timer_init(-        &chand->max_idle_timer,-        grpc_core::ExecCtx::Get()->Now() + chand->max_connection_idle,-        &chand->close_max_idle_channel);+    gpr_atm_no_barrier_store(&chand->last_enter_idle_time_millis,","Thanks a lot for the review!The `MAX_IDLE_STATE_TIMER_SET` branch is using `grpc_core::ExecCtx::Get()->Now()` inside `grpc_timer_init()` as `last_enter_idle_time_millis`. This stored `last_enter_idle_time_millis` is prepared for the `MAX_IDLE_STATE_SEEN_EXIT_IDLE` branch.By setting it beforehand and using the release semantic, we can make sure if a thread sees `MAX_IDLE_STATE_SEEN_ENTER_IDLE`, it must see the correct `last_enter_idle_time_millis`.",
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/14010,163131969,2018-01-23T02:52:59Z,src/cpp/thread_manager/thread_manager.h,"@@ -144,8 +144,7 @@ class ThreadManager {       thread_creator_;   std::function<void(gpr_thd_id)> thread_joiner_; -  std::mutex list_mu_;",Could you clarify why mutex is removed?  (I see that you are using `mu_` for list operations as well - I am ok with this change but I want to know if you did it for simplifying code (and perhaps reducing mutex acquisitions) or was this actually redundant ?,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14010,163153229,2018-01-23T06:20:26Z,src/cpp/thread_manager/thread_manager.h,"@@ -144,8 +144,7 @@ class ThreadManager {       thread_creator_;   std::function<void(gpr_thd_id)> thread_joiner_; -  std::mutex list_mu_;","My main goal was to avoid error-proneness; having 2 locks in the same object makes it more confusing, IMO, as to when the object is really locked. I would prefer having a coarse-grain lock unless it is a provable negative impact, and given the scope of the list_mu operations, I just didn't see that being likely to be substantial.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14010,163153456,2018-01-23T06:22:36Z,src/cpp/server/server_cc.cc,"@@ -338,28 +338,27 @@ class Server::SyncRequestThreadManager : public ThreadManager {   }    void Shutdown() override {-    ThreadManager::Shutdown();     server_cq_->Shutdown();+    ThreadManager::Shutdown();   }    void Wait() override {-    ThreadManager::Wait();     // Drain any pending items from the queue     void* tag;     bool ok;     while (server_cq_->Next(&tag, &ok)) {       // Do nothing     }+    ThreadManager::Wait();   }    void Start() {     if (!sync_requests_.empty()) {+      Initialize();  // ThreadManager's Initialize()","I thought that it didn't look nice to have requests being set up before there was an initialized thread manager ready to catch them. Additionally, just like the working of constructors, I thought that from a stylistic point of view, the base class should be prepared for action before the derived class starts its action.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14010,163153576,2018-01-23T06:23:53Z,src/cpp/server/server_cc.cc,"@@ -338,28 +338,27 @@ class Server::SyncRequestThreadManager : public ThreadManager {   }    void Shutdown() override {-    ThreadManager::Shutdown();     server_cq_->Shutdown();+    ThreadManager::Shutdown();",Stylistic reasons; I wanted to see the derived class's shutdown actions being done before the base class's. This is purely stylistic here as these just initiate shutdown actions and there does not need to be any ordering.,
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/13883,163313067,2018-01-23T17:12:00Z,src/core/lib/channel/channel_tracer.cc,"@@ -0,0 +1,275 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/core/lib/channel/channel_tracer.h""+#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>+#include <grpc/support/useful.h>+#include <stdlib.h>+#include <string.h>++#include ""src/core/lib/iomgr/error.h""+#include ""src/core/lib/slice/slice_internal.h""+#include ""src/core/lib/support/memory.h""+#include ""src/core/lib/support/object_registry.h""+#include ""src/core/lib/support/string.h""+#include ""src/core/lib/surface/channel.h""+#include ""src/core/lib/transport/connectivity_state.h""++namespace grpc_core {++struct TraceEvent {+  TraceEvent(grpc_slice data, grpc_error* error,+             grpc_connectivity_state connectivity_state,+             ChannelTracer* referenced_tracer)+      : data_(data),+        error_(error),+        connectivity_state_(connectivity_state),+        next_(nullptr) {+    referenced_tracer_ = referenced_tracer ? referenced_tracer->Ref() : nullptr;+    time_created_ = gpr_now(GPR_CLOCK_REALTIME);+  }+  grpc_slice data_;+  grpc_error* error_;+  gpr_timespec time_created_;+  grpc_connectivity_state connectivity_state_;+  TraceEvent* next_;+  // the tracer object for the (sub)channel that this trace node refers to.+  ChannelTracer* referenced_tracer_;+};++ChannelTracer::ChannelTracer(size_t max_nodes)+    : channel_uuid_(-1),+      num_nodes_logged_(0),+      list_size_(0),+      max_list_size_(max_nodes),+      head_trace_(0),+      tail_trace_(0) {+  if (!max_list_size_) return;  // tracing is disabled if max_nodes == 0+  gpr_mu_init(&tracer_mu_);+  gpr_ref_init(&refs_, 1);+  channel_uuid_ = grpc_object_registry_register_object(+      this, GRPC_OBJECT_REGISTRY_CHANNEL_TRACER);+  max_list_size_ = max_nodes;+  time_created_ = gpr_now(GPR_CLOCK_REALTIME);+}++ChannelTracer* ChannelTracer::Ref() {+  if (!max_list_size_) return nullptr;  // tracing is disabled if max_nodes == 0+  gpr_ref(&refs_);+  return this;+}++void ChannelTracer::FreeNode(TraceEvent* node) {+  GRPC_ERROR_UNREF(node->error_);+  if (node->referenced_tracer_) {+    node->referenced_tracer_->Unref();+  }+  grpc_slice_unref_internal(node->data_);+  gpr_free(node);+}++void ChannelTracer::Unref() {+  if (!max_list_size_) return;  // tracing is disabled if max_nodes == 0+  if (gpr_unref(&refs_)) {+    TraceEvent* it = head_trace_;+    while (it != nullptr) {+      TraceEvent* to_free = it;+      it = it->next_;+      FreeNode(to_free);+    }+    gpr_mu_destroy(&tracer_mu_);+  }+}++intptr_t ChannelTracer::GetUuid() { return channel_uuid_; }++void ChannelTracer::AddTrace(grpc_slice data, grpc_error* error,+                             grpc_connectivity_state connectivity_state,+                             ChannelTracer* referenced_tracer) {+  if (!max_list_size_) return;  // tracing is disabled if max_nodes == 0+  ++num_nodes_logged_;+  // create and fill up the new node+  TraceEvent* new_trace_node =+      New<TraceEvent>(data, error, connectivity_state, referenced_tracer);+  // first node case+  if (head_trace_ == nullptr) {+    head_trace_ = tail_trace_ = new_trace_node;+  }+  // regular node add case+  else {+    tail_trace_->next_ = new_trace_node;+    tail_trace_ = tail_trace_->next_;+  }+  ++list_size_;+  // maybe garbage collect the end+  if (list_size_ > max_list_size_) {+    TraceEvent* to_free = head_trace_;+    head_trace_ = head_trace_->next_;+    FreeNode(to_free);+    --list_size_;+  }+}++// returns an allocated string that represents tm according to RFC-3339.+static char* fmt_time(gpr_timespec tm) {+  char buffer[35];+  struct tm* tm_info = localtime((const time_t*)&tm.tv_sec);+  strftime(buffer, sizeof(buffer), ""%Y-%m-%dT%H:%M:%S"", tm_info);+  char* full_time_str;+  gpr_asprintf(&full_time_str, ""%s.%09dZ"", buffer, tm.tv_nsec);+  return full_time_str;+}++class ChannelTracerRenderer {+ public:+  ChannelTracerRenderer(ChannelTracer* tracer, bool recursive)+      : current_tracer_(tracer),+        recursive_(recursive),+        seen_tracers_(nullptr),+        size_(0),+        cap_(0) {}++  char* Run() {+    grpc_json* json = grpc_json_create(GRPC_JSON_OBJECT);+    AddSeenTracer(current_tracer_);+    RecursivelyPopulateJson(json);+    gpr_free(seen_tracers_);+    char* json_str = grpc_json_dump_to_string(json, 1);+    grpc_json_destroy(json);+    return json_str;+  }++ private:+  void AddSeenTracer(ChannelTracer* newly_seen) {+    if (size_ >= cap_) {+      cap_ = GPR_MAX(5 * sizeof(newly_seen), 3 * cap_ / 2);+      seen_tracers_ = (ChannelTracer**)gpr_realloc(seen_tracers_, cap_);+    }+    seen_tracers_[size_++] = newly_seen;+  }++  bool TracerAlreadySeen(ChannelTracer* tracer) {+    for (size_t i = 0; i < size_; ++i) {+      if (seen_tracers_[i] == tracer) return true;+    }+    return false;+  }++  void RecursivelyPopulateJson(grpc_json* json) {+    grpc_json* channel_data = grpc_json_create_child(+        nullptr, json, ""channelData"", nullptr, GRPC_JSON_OBJECT, false);+    grpc_json* children = nullptr;+    if (recursive_) {+      children = grpc_json_create_child(channel_data, json, ""children"", nullptr,+                                        GRPC_JSON_ARRAY, false);+    }+    PopulateTracer(channel_data, children);+  }++  void PopulateTracer(grpc_json* channel_data, grpc_json* children) {",I took a stab at adding more comments and renaming a few variables. Let me know if you think it is sufficient,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/14146,163403677,2018-01-23T22:55:41Z,src/core/lib/gprpp/inlined_vector.h,"@@ -100,7 +89,27 @@ class InlinedVector {    size_t size() const { return size_; } +  void clear() {+    destroy_elements();+    dynamic_ = nullptr;+    size_ = 0;+    dynamic_capacity_ = 0;","with this change, that'd be two places where initialization of member variables happen. If new ones are added to the class, we'd have to remember adding them here. I suggest creating a private aux method to initialize the three member variables, to be invoked here and in the constructor.",
22083734,matt-kwong,https://api.github.com/repos/grpc/grpc/pulls/14169,163664262,2018-01-24T20:10:17Z,tools/internal_ci/linux/grpc_tsan_on_foundry.sh,"@@ -0,0 +1,87 @@+Skip to content",Assuming lines 1-18 are accidentally included :),
22083734,matt-kwong,https://api.github.com/repos/grpc/grpc/pulls/14169,163664329,2018-01-24T20:10:37Z,tools/internal_ci/linux/grpc_tsan_on_foundry.sh,"@@ -0,0 +1,87 @@+Skip to content+This repository+Search+Pull requests+Issues+Marketplace+Explore+ @adelez+ Sign out+ Unwatch 889+  Star 13,284  Fork 2,893 grpc/grpc+ Code  Issues 865  Pull requests 256  Projects 3  Wiki  Insights+Branch: master Find file Copy pathgrpc/tools/internal_ci/linux/grpc_bazel_on_foundry_opt.sh+54a7040  on Dec 14, 2017+@apolcyn apolcyn Move more special cases in bazel build to the .bzl files+2 contributors @apolcyn @adelez+RawBlameHistory    +57 lines (50 sloc)  2.14 KB+#!/usr/bin/env bash+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++set -ex++# A temporary solution to give Kokoro credentials. +# The file name 4321_grpc-testing-service needs to match auth_credential in +# the build config.+mkdir -p ${KOKORO_KEYSTORE_DIR}+cp ${KOKORO_GFILE_DIR}/GrpcTesting-d0eeee2db331.json ${KOKORO_KEYSTORE_DIR}/4321_grpc-testing-service++mkdir -p /tmpfs/tmp/bazel-canary+ln -f ""${KOKORO_GFILE_DIR}/bazel-canary"" /tmpfs/tmp/bazel-canary/bazel+chmod 755 ""${KOKORO_GFILE_DIR}/bazel-canary""+export PATH=""/tmpfs/tmp/bazel-canary:${PATH}""+# This should show /tmpfs/tmp/bazel-canary/bazel+which bazel+chmod +x ""${KOKORO_GFILE_DIR}/bazel_wrapper.py""++# change to grpc repo root+cd $(dirname $0)/../../..++source tools/internal_ci/helper_scripts/prepare_build_linux_rc++""${KOKORO_GFILE_DIR}/bazel_wrapper.py"" \+  --host_jvm_args=-Dbazel.DigestFunction=SHA1 \+  test --jobs=""50"" \+  --test_timeout=""300,450,1200,3600"" \+  --test_output=errors  \+  --verbose_failures=true  \+  --keep_going  \+  --remote_accept_cached=true  \+  --spawn_strategy=remote  \+  --remote_local_fallback=false  \+  --remote_timeout=3600  \+  --strategy=Javac=remote  \+  --strategy=Closure=remote  \+  --genrule_strategy=remote  \+  --experimental_strict_action_env=true \+  --experimental_remote_platform_override='properties:{name:""container-image"" value:""docker://gcr.io/asci-toolchain/nosla-debian8-clang-fl@sha256:496193842f61c9494be68bd624e47c74d706cabf19a693c4653ffe96a97e43e3"" }' \+  --crosstool_top=@com_github_bazelbuild_bazeltoolchains//configs/debian8_clang/0.2.0/bazel_0.7.0:toolchain \+  --define GRPC_PORT_ISOLATED_RUNTIME=1 \+  --copt=-fsanitize=thread \+  --linkopt=-fsanitize=thread \+  -- //test/...+© 2018 GitHub, Inc.",These are also accidentally included?,
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/14136,163942526,2018-01-25T19:22:09Z,test/core/memory_usage/server.cc,"@@ -287,19 +288,22 @@ int main(int argc, char** argv) {                 send_status(&calls[k]);               }             }-          // no break here since we want to continue to case-          // FLING_SERVER_SEND_STATUS_SNAPSHOT to destroy the snapshot call+            cleanup_snapshot_call = 1;","Actually, we are using something different throughout the codebase:https://github.com/grpc/grpc/search?utf8=%E2%9C%93&q=fallthrough&type=Using the comment `/* fallthrough */` is the portable way to do this, and should be recognized by all compilers. We have banned the attribute usage for the reason you are describing, of course. But in locations such as https://github.com/grpc/grpc/blob/9db1691c85a720ec661266dcdcc2cbf20f7146f2/src/core/ext/transport/chttp2/transport/hpack_parser.cc#L1263 for example we do routinely use that to avoid the error.",
14932100,adelez,https://api.github.com/repos/grpc/grpc/pulls/14183,163988678,2018-01-25T22:34:40Z,tools/internal_ci/linux/grpc_tsan_on_foundry.sh,"@@ -38,7 +38,7 @@ source tools/internal_ci/helper_scripts/prepare_build_linux_rc ""${KOKORO_GFILE_DIR}/bazel_wrapper.py"" \   --host_jvm_args=-Dbazel.DigestFunction=SHA1 \   test --jobs=""50"" \-  --test_timeout=""300,450,1200,3600"" \+  --test_timeout=""1500,1500,1500,3600"" \","They correspond to short, moderate, long and external tests.",
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/14191,164013992,2018-01-26T01:14:43Z,test/core/bad_client/tests/duplicate_header.cc,"@@ -0,0 +1,131 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""test/core/bad_client/bad_client.h""++#include <string.h>++#include <grpc/grpc.h>++#include ""src/core/lib/surface/server.h""+#include ""test/core/end2end/cq_verifier.h""++#define PFX_STR                      \+  ""PRI * HTTP/2.0\r\n\r\nSM\r\n\r\n"" \+  ""\x00\x00\x00\x04\x00\x00\x00\x00\x00"" /* settings frame */++#define HEADER_STR                                                         \+  ""\x00\x00\xc9\x01\x04\x00\x00\x00\x01"" /* headers: generated from        \+                                            simple_request.headers in this \+                                            directory */                   \+  ""\x10\x05:path\x08/foo/bar""                                              \+  ""\x10\x07:scheme\x04http""                                                \+  ""\x10\x07:method\x04POST""                                                \+  ""\x10\x0a:authority\x09localhost""                                        \+  ""\x10\x0c""                                                               \+  ""content-type\x10""                                                       \+  ""application/grpc""                                                       \+  ""\x10\x14grpc-accept-encoding\x15""                                       \+  ""deflate,identity,gzip""                                                  \+  ""\x10\x02te\x08trailers""                                                 \+  ""\x10\x0auser-agent\""bad-client grpc-c/0.12.0.0 (linux)""++#define PAYLOAD_STR                      \+  ""\x00\x00\x20\x00\x00\x00\x00\x00\x01"" \+  ""\x00\x00\x00\x00""++static void* tag(intptr_t t) { return (void*)t; }++static void verifier(grpc_server* server, grpc_completion_queue* cq,+                     void* registered_method) {+  grpc_call_error error;+  grpc_call* s;+  grpc_call_details call_details;+  grpc_byte_buffer* request_payload_recv = nullptr;+  grpc_op* op;+  grpc_op ops[6];+  cq_verifier* cqv = cq_verifier_create(cq);+  grpc_metadata_array request_metadata_recv;+  int was_cancelled = 2;++  grpc_call_details_init(&call_details);+  grpc_metadata_array_init(&request_metadata_recv);++  error = grpc_server_request_call(server, &s, &call_details,+                                   &request_metadata_recv, cq, cq, tag(101));+  GPR_ASSERT(GRPC_CALL_OK == error);+  CQ_EXPECT_COMPLETION(cqv, tag(101), 1);+  cq_verify(cqv);++  GPR_ASSERT(0 == grpc_slice_str_cmp(call_details.host, ""localhost""));+  GPR_ASSERT(0 == grpc_slice_str_cmp(call_details.method, ""/foo/bar""));++  memset(ops, 0, sizeof(ops));+  op = ops;+  op->op = GRPC_OP_SEND_INITIAL_METADATA;+  op->data.send_initial_metadata.count = 0;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  op->op = GRPC_OP_RECV_MESSAGE;+  op->data.recv_message.recv_message = &request_payload_recv;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  error = grpc_call_start_batch(s, ops, (size_t)(op - ops), tag(102), nullptr);+  GPR_ASSERT(GRPC_CALL_OK == error);++  CQ_EXPECT_COMPLETION(cqv, tag(102), 1);+  cq_verify(cqv);++  memset(ops, 0, sizeof(ops));+  op = ops;+  op->op = GRPC_OP_RECV_CLOSE_ON_SERVER;+  op->data.recv_close_on_server.cancelled = &was_cancelled;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  op->op = GRPC_OP_SEND_STATUS_FROM_SERVER;+  op->data.send_status_from_server.trailing_metadata_count = 0;+  op->data.send_status_from_server.status = GRPC_STATUS_UNIMPLEMENTED;+  grpc_slice status_details = grpc_slice_from_static_string(""xyz"");+  op->data.send_status_from_server.status_details = &status_details;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  error = grpc_call_start_batch(s, ops, (size_t)(op - ops), tag(103), nullptr);+  GPR_ASSERT(GRPC_CALL_OK == error);++  CQ_EXPECT_COMPLETION(cqv, tag(103), 1);++  grpc_metadata_array_destroy(&request_metadata_recv);+  grpc_call_details_destroy(&call_details);+  grpc_call_unref(s);+  cq_verifier_destroy(cqv);+}++int main(int argc, char** argv) {+  grpc_test_init(argc, argv);+  grpc_init();++  /* Verify that sending multiple headers doesn't segfault */+  GRPC_RUN_BAD_CLIENT_TEST(verifier, nullptr,+                           PFX_STR HEADER_STR HEADER_STR PAYLOAD_STR, 0);",That's not a bad idea.,
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/14177,164030247,2018-01-26T03:56:46Z,src/core/lib/iomgr/ev_epollex_linux.cc,"@@ -677,6 +679,11 @@ static grpc_error* pollset_kick_all(grpc_pollset* pollset) { static void pollset_init(grpc_pollset* pollset, gpr_mu** mu) {   gpr_mu_init(&pollset->mu);   pollset->active_pollable = POLLABLE_REF(g_empty_pollable, ""pollset"");+  pollset->kicked_without_poller = false;+  pollset->shutdown_closure = nullptr;+  pollset->already_shutdown = false;","Oh..I think I understand. Since `shutdown_closure == nullptr` can mean that the pollset is new or already shutdown , you added `already_shutdown` to disambiguate that. Makes sense.Resetting them to their default states is not strictly necessary but I am ok with doing this. Ignore my previous comment. Thanks.",
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/14191,164216644,2018-01-26T20:39:21Z,src/core/lib/surface/call.cc,"@@ -1101,6 +1101,7 @@ static grpc_stream_compression_algorithm decode_stream_compression( static void publish_app_metadata(grpc_call* call, grpc_metadata_batch* b,                                  int is_trailing) {   if (b->list.count == 0) return;+  if (is_trailing && call->buffered_metadata[1] == nullptr) return;","Right, this is a temporary bandaid. We want to actually return a 400 from within chttp2, but ""stop the bleeding first"".",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/14197,164221493,2018-01-26T21:04:16Z,src/core/lib/gpr/host_port.h,"@@ -16,8 +16,8 @@  *  */ -#ifndef GRPC_SUPPORT_HOST_PORT_H-#define GRPC_SUPPORT_HOST_PORT_H+#ifndef GRPC_CORE_LIB_GPR_HOST_PORT_H+#define GRPC_CORE_LIB_GPR_HOST_PORT_H  #include <grpc/support/port_platform.h> ","extern ""C"" should no longer be required ",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/14228,164620135,2018-01-30T01:44:33Z,test/core/client_channel/resolvers/dns_resolver_test.cc,"@@ -16,23 +16,46 @@  *","After talking to Yuchen, I've learnt that `resolve_address_test.cc` is a much better place for testing. I'll port these changes there tomorrow. The idea will the the same though: a chain of callbacks that will verify the behavior.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/14112,164886049,2018-01-30T21:37:05Z,test/core/bad_client/bad_client.h,"@@ -28,30 +28,65 @@ #define GRPC_BAD_CLIENT_REGISTERED_METHOD ""/registered/bar"" #define GRPC_BAD_CLIENT_REGISTERED_HOST ""localhost"" +/* The server side validator function to run */ typedef void (*grpc_bad_client_server_side_validator)(grpc_server* server,                                                       grpc_completion_queue* cq,                                                       void* registered_method); -// Returns false if we need to read more data.+/* Returns false if we need to read more data. */ typedef bool (*grpc_bad_client_client_stream_validator)(-    grpc_slice_buffer* incoming);+    grpc_slice_buffer* incoming, void* arg);++struct grpc_bad_client_arg {+  grpc_bad_client_client_stream_validator client_validator;+  void* client_validator_arg;+  const char* client_payload;+  size_t client_payload_length;+};  #define GRPC_BAD_CLIENT_DISCONNECT 1 #define GRPC_BAD_CLIENT_LARGE_REQUEST 2  /* Test runner.--   Create a server, and send client_payload to it as bytes from a client.-   Execute server_validator in a separate thread to assert that the bytes are-   handled as expected. */+ *+ * Create a server, and for each arg in \a args send client_payload. For each+ * payload, run client_validator to make sure that the response is as expected.+ * Also execute \a server_validator in a separate thread to assert that the+ * bytes are handled as expected.+ */ void grpc_run_bad_client_test(     grpc_bad_client_server_side_validator server_validator,-    grpc_bad_client_client_stream_validator client_validator,-    const char* client_payload, size_t client_payload_length, uint32_t flags);+    grpc_bad_client_arg args[], int num_args, uint32_t flags);++/* A hack to let old tests work as before. In these tests, instead of an array,","Slick hack, but might be worth just changing all of the existing bad clients to use your new validation syntax for consistency sake. There are not too many bad clients. I don't feel strongly about this though, so up to you.",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/14112,164911405,2018-01-30T23:26:44Z,test/core/bad_client/bad_client.cc,"@@ -62,136 +69,172 @@ static void server_setup_transport(void* ts, grpc_transport* transport) {                               grpc_server_get_channel_args(a->server)); } -static void read_done(void* arg, grpc_error* error) {+/* Sets the read_done event */+static void set_read_done(void* arg, grpc_error* error) {   gpr_event* read_done = (gpr_event*)arg;   gpr_event_set(read_done, (void*)1); } -void grpc_run_bad_client_test(-    grpc_bad_client_server_side_validator server_validator,-    grpc_bad_client_client_stream_validator client_validator,-    const char* client_payload, size_t client_payload_length, uint32_t flags) {-  grpc_endpoint_pair sfd;-  thd_args a;-  gpr_thd_id id;-  char* hex;-  grpc_transport* transport;-  grpc_slice slice =-      grpc_slice_from_copied_buffer(client_payload, client_payload_length);-  grpc_slice_buffer outgoing;-  grpc_closure done_write_closure;-  grpc_core::ExecCtx exec_ctx;-  grpc_completion_queue* shutdown_cq;+/* shutdown client */+static void shutdown_client(grpc_endpoint** client_fd) {+  if (*client_fd != nullptr) {+    grpc_endpoint_shutdown(+        *client_fd, GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Forced Disconnect""));+    grpc_endpoint_destroy(*client_fd);+    grpc_core::ExecCtx::Get()->Flush();+    *client_fd = nullptr;+  }+} -  if (client_payload_length < 4 * 1024) {-    hex = gpr_dump(client_payload, client_payload_length,+/* Runs client side validator */+void grpc_run_client_side_validator(grpc_bad_client_arg* arg, uint32_t flags,","Currently, there are two uses for flags.One, to indicate that the client should disconnect before the validator runs.Second, to indicate that the client is going to write too much data which might not finish writing even after the validator returns. This ends up requiring a forceful shutdown after validator runs, so  we can avoid a SEGFAULT.I've updated the comments and the if condition to reflect the change.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/14224,164921730,2018-01-31T00:24:38Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -400,33 +400,29 @@ static void pf_connectivity_changed_locked(void* arg, grpc_error* error) {       p->latest_pending_subchannel_list = nullptr;       grpc_connectivity_state_set(           &p->state_tracker, GRPC_CHANNEL_TRANSIENT_FAILURE,-          GRPC_ERROR_REF(error), ""selected_not_ready+switch_to_update"");+          GRPC_ERROR_REF(error), ""selected_not_ready+switch_to_update"", false);     } else {-      // TODO(juanlishen): we re-resolve when the selected subchannel goes to-      // TRANSIENT_FAILURE because we used to shut down in this case before-      // re-resolution is introduced. But we need to investigate whether we-      // really want to take any action instead of waiting for the selected-      // subchannel reconnecting.-      GPR_ASSERT(sd->curr_connectivity_state != GRPC_CHANNEL_SHUTDOWN);-      if (sd->curr_connectivity_state == GRPC_CHANNEL_TRANSIENT_FAILURE) {-        // If the selected channel goes bad, request a re-resolution.+      // A subchannel can be in TRANSIENT_FAILURE only before it's connected.+      GPR_ASSERT(sd->curr_connectivity_state != GRPC_CHANNEL_TRANSIENT_FAILURE);","Before this PR, the subchannel will report `TRANSIENT_FAILURE` both when it fails to connect or disconnects. Now it reports `TRANSIENT_FAILURE` when it fails to connect, and `SHUTDOWN` when it disconnects. But it doesn't affect the behavior of this code block. Before this PR, the selected subchannel will only be in `TRANSIENT_FAILURE` if it disconnects. Now, the selected subchannel will only be in `SHUTDOWN` if it disconnects. Either way, disconnection is the only condition for PF to re-resolve.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/14236,165161928,2018-01-31T19:30:55Z,test/cpp/microbenchmarks/bm_fullstack_trickle.cc,"@@ -204,9 +206,14 @@ class TrickledCHTTP2 : public EndpointPairFixture {   gpr_timespec start_ = gpr_now(GPR_CLOCK_MONOTONIC);    grpc_endpoint_pair MakeEndpoints(size_t kilobits) {+    stats_ = grpc_passthru_endpoint_stats_create();  // is there a better way to","Not sure I understand what you mean.I need to pass MakeEndpoints to the base class constructor and in the body of this class' constructor it's too late for doing that.- grpc_endpoint_pair  is an ""abstract"" struct, so later extracting the stats from it (after EndpointPairFixture is constructed and knowing it's an passthru_endpoint) wouldn't work either.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14221,165463865,2018-02-01T19:33:17Z,src/core/lib/gprpp/ref_counted_ptr.h,"@@ -71,6 +71,12 @@ class RefCountedPtr {     value_ = value;   } +  T* release() {","Please add a comment for this function to indicate that it is a stopgap measure until all code is written in C++; release is not idiomatic for shared_ptr, unlike the other components of this class.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/14276,165649338,2018-02-02T13:53:04Z,src/php/bin/run_tests.sh,"@@ -24,3 +24,9 @@ source ./determine_extension_dir.sh export DYLD_LIBRARY_PATH=$root/libs/$config php $extension_dir -d max_execution_time=300 $(which phpunit) -v --debug \   ../tests/unit_tests++export ZEND_DONT_UNLOAD_MODULES=1+export USE_ZEND_ALLOC=0+valgrind --error-exitcode=10 --leak-check=yes php $extension_dir -d max_execution_time=300 \","how long does this take to execute?To be honest I'm not a fan of  piggybacking on an existing test suite like this. Ideally, this would be a separate test suite that would clearly indicate it's php with valgrind (e.g. we have separate sanitizers for C/C++) and we'd have the ability to run in separately if we needed to (e.g. because it might take long to execute or if we just wanted to reorganize tests if we wanted to). Also, running 2 test suite one by one in a shell script has some disadvantages  - e.g. it's hard to navigate the test results (and it's easy to miss things) and also the second suite won't run at all if the first one fails. So I'm somewhat against this (but not strongly). If you believe there's a big value in the addition and you're willing to take the burden of maintenance (once we restruture the tests it might be harder to run stuff in this fashion) - or risk removing the suite if it become imcompatible with the way we run tests in the future, I'm probably ok with this.",
28968539,ZhouyihaiDing,https://api.github.com/repos/grpc/grpc/pulls/14276,165723040,2018-02-02T18:32:40Z,src/php/bin/run_tests.sh,"@@ -24,3 +24,9 @@ source ./determine_extension_dir.sh export DYLD_LIBRARY_PATH=$root/libs/$config php $extension_dir -d max_execution_time=300 $(which phpunit) -v --debug \   ../tests/unit_tests++export ZEND_DONT_UNLOAD_MODULES=1+export USE_ZEND_ALLOC=0+valgrind --error-exitcode=10 --leak-check=yes php $extension_dir -d max_execution_time=300 \","Thank you for the help!It take about 4s-5s to finish. I use [protobuf's php tests](https://github.com/google/protobuf/blob/master/php/tests/test.sh#L27) as reference and my idea is that if the unit tests fail, valgrind will report wrong leak information, so it is better not to run. I can add a flag for this script to choose which one to run.Valgrind is just a short term solution. I am planning to use asan, tsan from clang the same as current infrastructure in C-core in the final.I am trying to figure out asan tests in gRPC repo, can you offer me some suggestions? Like script to tests with asan locally? I am using PR running asan for ruby: https://github.com/grpc/grpc/pull/11580 as reference.I can delete valgrind and change it to asan in this PR directly so there is no need to change these two later.",
22083734,matt-kwong,https://api.github.com/repos/grpc/grpc/pulls/14282,165732577,2018-02-02T19:09:07Z,tools/internal_ci/linux/grpc_full_performance_release.sh,"@@ -0,0 +1,59 @@+#!/usr/bin/env bash+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+set -ex++# Enter the gRPC repo root+cd $(dirname $0)/../../..++source tools/internal_ci/helper_scripts/prepare_build_linux_perf_multilang_rc++# run 8core client vs 8core server+tools/run_tests/run_performance_tests.py \","Yup, a separate pool should be made for the drivers with a limit of only 1 active workers. I was considering adding a 2nd set of server/clients, but I don't think we not data being generated that frequently. We'll need a 2nd set if we decide to add the full sweep benchmark (Craig has said that it hasn't been used in months and will likely stay unused for the foreseeable future). ",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14323,166190757,2018-02-06T05:32:32Z,include/grpc++/impl/codegen/completion_queue.h,"@@ -111,12 +111,76 @@ class CompletionQueue : private GrpcLibraryCodegen {    /// Tri-state return for AsyncNext: SHUTDOWN, GOT_EVENT, TIMEOUT.   enum NextStatus {-    SHUTDOWN,   ///< The completion queue has been shutdown.+    SHUTDOWN,   ///< The completion queue has been shutdown and fully-drained     GOT_EVENT,  ///< Got a new event; \a tag will be filled in with its                 ///< associated value; \a ok indicating its success.     TIMEOUT     ///< deadline was reached.   }; +  /// Read from the queue, blocking until an event is available or the queue is+  /// shutting down.+  ///+  /// \param tag[out] Updated to point to the read event's tag.+  /// \param ok[out] true if read a successful event, false otherwise.+  ///+  /// Successful here means that this operation was performed validly+  ///+  /// Server-side request an RPC: ok indicates that the RPC has indeed+  /// been started. If it is false, the server has been Shutdown+  /// before this particular call got matched to an incoming RPC. This+  /// is actually the case that you were interested in, but I've gone+  /// ahead and documented the other cases below.+  ///+  /// Client-side start an RPC: ok indicates that the RPC is going to+  /// go to the wire. If it is false, it not going to the wire. This+  /// would happen if the channel is either permanently broken or+  /// transiently broken but with the fail-fast option.+  ///+  /// Client-side Write, Client-side WritesDone, Server-side Write,+  /// Server-side Finish, Server-side SendInitialMetadata (which is+  /// typically included in Write or Finish when not done explicitly):+  /// ok means that the data/metadata/status/etc is going to go to the+  /// wire. If it is false, it not going to the wire because the call+  /// is already dead (i.e., canceled, deadline expired, other side+  /// dropped the channel, etc).+  ///+  /// Client-side Read, Server-side Read, Client-side+  /// RecvInitialMetadata (which is typically included in Read if not+  /// done explicitly): ok indicates whether there is a valid message+  /// that got read. If not, you know that there are certainly no more+  /// messages that can ever be read from this stream.","So, that's not exactly true in all the cases listed above. If a server-side Read fails, it could be that the client has already done a Writes-Done. The server can still do a write if it wants to. But you're right about the client-side operations; if they fail, the client won't be able to push further on either side since the server doesn't have a half-close concept.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/13207,166590673,2018-02-07T11:30:59Z,src/csharp/.gitignore,"@@ -1,15 +1,17 @@-*.xproj.user *.userprefs-*.csproj.user+*.user","same as above, please refrain for fixing nits  in this big PR.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/13207,166592561,2018-02-07T11:39:27Z,examples/csharp/helloworld-from-cli/Greeter/Greeter.csproj,"@@ -1,18 +1,14 @@-﻿<Project Sdk=""Microsoft.NET.Sdk"">+<Project Sdk=""Microsoft.NET.Sdk"">    <PropertyGroup>-    <AssemblyTitle>Greeter</AssemblyTitle>-    <TargetFrameworks>netcoreapp1.0</TargetFrameworks>-    <DebugType>portable</DebugType>-    <AssemblyName>Greeter</AssemblyName>-    <PackageId>Greeter</PackageId>+    <TargetFramework>netcoreapp1.0</TargetFramework>   </PropertyGroup>    <ItemGroup>-    <PackageReference Include=""Google.Protobuf"" Version=""3.5.0"" />-    <PackageReference Include=""Google.Protobuf.Tools"" Version=""3.5.0"" />-    <PackageReference Include=""Grpc"" Version=""1.8.0"" />-    <PackageReference Include=""Grpc.Tools"" Version=""1.8.0"" />+    <PackageReference Include=""Grpc"" Version=""1.10.0"" />","We can't make the example depend on a non-existent version of Grpc (even though the grpc.io page leads our examples in the release branch, I assume many users are looking for examples in the master branch.Here's what I'd suggest:1. Let's create a separate PR for changes to the examples (assuming that the ""new"" Grpc.Tools package already exists).2. Let's remove all the changes to example from this PR and focus on just the changes to Grpc.ToolsThe examples and Grpc.Tools are in a way independent - once can easily generate the Grpc.Tools nugets from one PR and then test it on modified examples in the other PR.The example PR should be only merged once the first modified version of Grpc.Tools is actually released.",
22083734,matt-kwong,https://api.github.com/repos/grpc/grpc/pulls/13904,166787930,2018-02-07T23:15:50Z,templates/CMakeLists.txt.template,"@@ -91,7 +91,11 @@     set(gRPC_INSTALL_default OFF)   endif()   set(gRPC_INSTALL <%text>${gRPC_INSTALL_default}</%text> CACHE BOOL-      ""Generate installation target: gRPC_ZLIB_PROVIDER, gRPC_CARES_PROVIDER, gRPC_SSL_PROVIDER and gRPC_PROTOBUF_PROVIDER must all be \""package\"""")+      ""Generate 'install' target"")++  # Providers for third-party dependencies (gRPC_*_PROVIDER properties):",This comment block is duplicated below,
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/14394,167324708,2018-02-09T19:31:58Z,INSTALL.md,"@@ -70,6 +70,15 @@ automatically try and compile the `protoc` in third_party if you cloned the repository recursively and it detects that you don't already have it installed. +If it hasn't been installed, you can run the following commands to install it.++```sh+$ cd grpc/third_party/protobuf+$ sudo make install   # 'make' should have been run by core grpc+```++Alternatively, you can download `protoc` binaries from",I suggest leaving this out. Version conflict between installed protoc and protobuf submodule has been a big source of confusion and unnecessary issues get filed.,
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/14404,167729104,2018-02-13T00:24:57Z,test/cpp/qps/qps_json_driver.cc,"@@ -86,6 +86,7 @@ static std::unique_ptr<ScenarioResult> RunAndReport(const Scenario& scenario,   result->mutable_scenario()->CopyFrom(scenario);    GetReporter()->ReportQPS(*result);+  GetReporter()->ReportAttemptedQPS(*result);","It doesn't need to be logged I guess, but it does need to exist in the ReportSummary proto. This is to match internal behavior for the Stubby benchmarking system.Both sent the report protos to a Result Server, which is responsible for writing the data somewhere where perfkit can read it (for internal dashboards).Ultimate goal is to be able to dashboard open loop scenarios",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14439,168619809,2018-02-15T21:53:23Z,src/core/lib/iomgr/ev_poll_posix.cc,"@@ -1437,9 +1444,24 @@ static void cache_destroy_locked(poll_args* args) {     poll_cache.free_pollers = args->next;   } +  // Now move this args to the dead poller list for later join+  if (poll_cache.dead_pollers != nullptr) {+    poll_cache.dead_pollers->prev = args;+  }+  args->prev = nullptr;+  args->next = poll_cache.dead_pollers;   gpr_free(args);",So is there anything else that can own args once it hits the freelist? I guess I'm not seeing the shared ownership here though I need to look more carefully.,
17325098,makdharma,https://api.github.com/repos/grpc/grpc/pulls/14433,168629179,2018-02-15T22:32:37Z,src/core/ext/transport/cronet/transport/cronet_transport.cc,"@@ -624,14 +653,21 @@ static void on_response_trailers_received(   for (size_t i = 0; i < trailers->count; i++) {     CRONET_LOG(GPR_DEBUG, ""trailer key=%s, value=%s"", trailers->headers[i].key,                trailers->headers[i].value);+    grpc_slice key = grpc_slice_intern(+        grpc_slice_from_static_string(trailers->headers[i].key));+    grpc_slice value;+    if (grpc_is_binary_header(key)) {",This code seems duplicated with header processing. Create a separate function and use in both places?,
17325098,makdharma,https://api.github.com/repos/grpc/grpc/pulls/14433,168629422,2018-02-15T22:33:40Z,src/core/ext/transport/cronet/transport/cronet_transport.cc,"@@ -214,6 +216,26 @@ void grpc_cronet_stream_unref(stream_obj* s) { grpc_stream_unref(s->refcount); }  static enum e_op_result execute_stream_op(struct op_and_state* oas); +static const size_t tail_xtra[4] = {0, 0, 1, 2};",Is this code (infering length) copied from chttps? Any way to avoid duplication?,
547926,dcow,https://api.github.com/repos/grpc/grpc/pulls/14387,168899189,2018-02-16T23:59:58Z,src/core/lib/security/transport/security_connector.cc,"@@ -704,18 +704,31 @@ static void ssl_server_add_handshakers(grpc_server_security_connector* sc, }  static int ssl_host_matches_name(const tsi_peer* peer, const char* peer_name) {-  char* allocated_name = nullptr;+  char* allocated_host = nullptr;+  char* allocated_addr = nullptr;   int r;    if (strchr(peer_name, ':') != nullptr) {     char* ignored_port;-    gpr_split_host_port(peer_name, &allocated_name, &ignored_port);+    gpr_split_host_port(peer_name, &allocated_host, &ignored_port);     gpr_free(ignored_port);-    peer_name = allocated_name;+    peer_name = allocated_host;     if (!peer_name) return 0;   }++  /* IPv6 non-global zone-id should not be included in comparisons. */+  const char* percent = strchr(peer_name, '%');",@pmarks-net re allocation: I didn't want to modify `allocated_name` from `grpc_split_host_port` but now that you mention it I can't think of anything bad about that approach and the fewer allocations the better. Thanks!,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12613,169389926,2018-02-20T17:05:57Z,src/csharp/Grpc.Core.Tests/Interceptors/ClientInterceptorTest.cs,"@@ -0,0 +1,132 @@+#region Copyright notice and license++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Generic;+using System.Linq;+using System.Threading;+using System.Threading.Tasks;+using Grpc.Core;+using Grpc.Core.Interceptors;+using Grpc.Core.Internal;+using Grpc.Core.Utils;+using Grpc.Core.Tests;+using NUnit.Framework;++namespace Grpc.Core.Interceptors.Tests+{+    public class ClientInterceptorTest+    {+        const string Host = ""127.0.0.1"";++        [Test]+        public void AddRequestHeaderInClientInterceptor()+        {+            const string HeaderKey = ""x-client-interceptor"";+            const string HeaderValue = ""hello-world"";+            var helper = new MockServiceHelper(Host);+            helper.UnaryHandler = new UnaryServerMethod<string, string>((request, context) =>+            {+                var interceptorHeader = context.RequestHeaders.Last(m => (m.Key == HeaderKey)).Value;+                Assert.AreEqual(interceptorHeader, HeaderValue);+                return Task.FromResult(""PASS"");+            });+            var server = helper.GetServer();+            server.Start();+            var callInvoker = helper.GetChannel().Intercept(metadata =>+            {+                metadata.Add(new Metadata.Entry(HeaderKey, HeaderValue));+                return metadata;+            });+            Assert.AreEqual(""PASS"", callInvoker.BlockingUnaryCall(new Method<string, string>(MethodType.Unary, MockServiceHelper.ServiceName, ""Unary"", Marshallers.StringMarshaller, Marshallers.StringMarshaller), Host, new CallOptions().WithHeaders(new Metadata()), """"));","is the new CallOptions().WithHeaders(new Metadata()) really needed here? If so, is there a problem  when calling a client stub's client.FooBarMethod(request, new CallOptions()) overload with metadata not set? (which should really work fine).",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12613,169402154,2018-02-20T17:46:35Z,src/csharp/Grpc.Core/Internal/ServerCallHandler.cs,"@@ -147,9 +163,20 @@ public ServerStreamingServerCallHandler(Method<TRequest, TResponse> method, Serv             }             await finishedTask.ConfigureAwait(false);         }+++        IServerCallHandler IInterceptableCallHandler.Intercept(Interceptor interceptor)+        {+            if (interceptor == null)",nit: isn't GrpcPreconditions.CheckNotNull(interceptor) better? Why would someone pass a null interceptor?,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12613,169406108,2018-02-20T17:59:59Z,src/csharp/Grpc.Core/Interceptors/CallInvokerExtensions.cs,"@@ -0,0 +1,171 @@+#region Copyright notice and license++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Linq;+using Grpc.Core.Utils;++namespace Grpc.Core.Interceptors+{+    /// <summary>+    /// Extends the CallInvoker class to provide the interceptor facility on the client side.+    /// This is an EXPERIMENTAL API.+    /// </summary>+    public static class CallInvokerExtensions+    {+        /// <summary>+        /// Decorates an underlying <see cref=""Grpc.Core.CallInvoker"" /> to+        /// intercept calls through a given interceptor.+        /// </summary>+        private class InterceptingCallInvoker : CallInvoker+        {+            readonly CallInvoker invoker;+            readonly Interceptor interceptor;++            /// <summary>+            /// Creates a new instance of <see cref=""Grpc.Core.Interceptors.CallInvokerExtensions.InterceptingCallInvoker"" />+            /// with the given underlying invoker and interceptor instances.+            /// </summary>+            public InterceptingCallInvoker(CallInvoker invoker, Interceptor interceptor)+            {+                this.invoker = GrpcPreconditions.CheckNotNull(invoker, ""invoker"");+                this.interceptor = GrpcPreconditions.CheckNotNull(interceptor, ""interceptor"");+            }++            /// <summary>+            /// Intercepts a simple blocking call with the registered interceptor.+            /// </summary>+            public override TResponse BlockingUnaryCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request)+            {+                return interceptor.BlockingUnaryCall(+                    request,+                    new ClientInterceptorContext<TRequest, TResponse>(method, host, options),+                    (req, ctx) => invoker.BlockingUnaryCall(ctx.Method, ctx.Host, ctx.Options, req));+            }++            /// <summary>+            /// Intercepts a simple asynchronous call with the registered interceptor.+            /// </summary>+            public override AsyncUnaryCall<TResponse> AsyncUnaryCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request)+            {+                return interceptor.AsyncUnaryCall(+                    request,+                    new ClientInterceptorContext<TRequest, TResponse>(method, host, options),+                    (req, ctx) => invoker.AsyncUnaryCall(ctx.Method, ctx.Host, ctx.Options, req));+            }++            /// <summary>+            /// Intercepts an asynchronous server streaming call with the registered interceptor.+            /// </summary>+            public override AsyncServerStreamingCall<TResponse> AsyncServerStreamingCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request)+            {+                return interceptor.AsyncServerStreamingCall(+                    request,+                    new ClientInterceptorContext<TRequest, TResponse>(method, host, options),+                    (req, ctx) => invoker.AsyncServerStreamingCall(ctx.Method, ctx.Host, ctx.Options, req));+            }++            /// <summary>+            /// Intercepts an asynchronous client streaming call with the registered interceptor.+            /// </summary>+            public override AsyncClientStreamingCall<TRequest, TResponse> AsyncClientStreamingCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options)+            {+                return interceptor.AsyncClientStreamingCall(+                    new ClientInterceptorContext<TRequest, TResponse>(method, host, options),+                    ctx => invoker.AsyncClientStreamingCall(ctx.Method, ctx.Host, ctx.Options));+            }++            /// <summary>+            /// Intercepts an asynchronous duplex streaming call with the registered interceptor.+            /// </summary>+            public override AsyncDuplexStreamingCall<TRequest, TResponse> AsyncDuplexStreamingCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options)+            {+                return interceptor.AsyncDuplexStreamingCall(+                    new ClientInterceptorContext<TRequest, TResponse>(method, host, options),+                    ctx => invoker.AsyncDuplexStreamingCall(ctx.Method, ctx.Host, ctx.Options));+            }+        }++        private class MetadataInterceptor : GenericInterceptor+        {+            readonly Func<Metadata, Metadata> interceptor;++            /// <summary>+            /// Creates a new instance of MetadataInterceptor given the specified interceptor function.+            /// </summary>+            public MetadataInterceptor(Func<Metadata, Metadata> interceptor)+            {+                this.interceptor = GrpcPreconditions.CheckNotNull(interceptor, ""interceptor"");+            }++            protected override ClientCallArbitrator<TRequest, TResponse> InterceptCall<TRequest, TResponse>(ClientInterceptorContext<TRequest, TResponse> context, bool clientStreaming, bool serverStreaming, TRequest request)+            {+                return new ClientCallArbitrator<TRequest, TResponse>+                {+                    Context = new ClientInterceptorContext<TRequest, TResponse>(context.Method, context.Host, context.Options.WithHeaders(interceptor(context.Options.Headers)))+                };+            }+        }++        /// <summary>+        /// Returns a <see cref=""Grpc.Core.CallInvoker"" /> instance that intercepts+        /// the invoker with the given interceptor.+        /// </summary>+        /// <param name=""invoker"">The underlying invoker to intercept.</param>+        /// <param name=""interceptor"">The metadata interceptor to intercept calls to the invoker with.</param>+        public static CallInvoker Intercept(this CallInvoker invoker, Func<Metadata, Metadata> interceptor)","I think more documentation explanation is needed  in terms of what's the meaning of Func<Metadata, Metadata> - it's not explained anywhere in the public API.Also, it refers to request headers, right?",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12613,169406953,2018-02-20T18:03:01Z,src/csharp/Grpc.Core/Interceptors/CallInvokerExtensions.cs,"@@ -0,0 +1,171 @@+#region Copyright notice and license++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Linq;+using Grpc.Core.Utils;++namespace Grpc.Core.Interceptors+{+    /// <summary>+    /// Extends the CallInvoker class to provide the interceptor facility on the client side.+    /// This is an EXPERIMENTAL API.+    /// </summary>+    public static class CallInvokerExtensions+    {+        /// <summary>+        /// Decorates an underlying <see cref=""Grpc.Core.CallInvoker"" /> to+        /// intercept calls through a given interceptor.+        /// </summary>+        private class InterceptingCallInvoker : CallInvoker+        {+            readonly CallInvoker invoker;+            readonly Interceptor interceptor;++            /// <summary>+            /// Creates a new instance of <see cref=""Grpc.Core.Interceptors.CallInvokerExtensions.InterceptingCallInvoker"" />+            /// with the given underlying invoker and interceptor instances.+            /// </summary>+            public InterceptingCallInvoker(CallInvoker invoker, Interceptor interceptor)+            {+                this.invoker = GrpcPreconditions.CheckNotNull(invoker, ""invoker"");+                this.interceptor = GrpcPreconditions.CheckNotNull(interceptor, ""interceptor"");+            }++            /// <summary>+            /// Intercepts a simple blocking call with the registered interceptor.+            /// </summary>+            public override TResponse BlockingUnaryCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request)+            {+                return interceptor.BlockingUnaryCall(+                    request,+                    new ClientInterceptorContext<TRequest, TResponse>(method, host, options),+                    (req, ctx) => invoker.BlockingUnaryCall(ctx.Method, ctx.Host, ctx.Options, req));+            }++            /// <summary>+            /// Intercepts a simple asynchronous call with the registered interceptor.+            /// </summary>+            public override AsyncUnaryCall<TResponse> AsyncUnaryCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request)+            {+                return interceptor.AsyncUnaryCall(+                    request,+                    new ClientInterceptorContext<TRequest, TResponse>(method, host, options),+                    (req, ctx) => invoker.AsyncUnaryCall(ctx.Method, ctx.Host, ctx.Options, req));+            }++            /// <summary>+            /// Intercepts an asynchronous server streaming call with the registered interceptor.+            /// </summary>+            public override AsyncServerStreamingCall<TResponse> AsyncServerStreamingCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request)+            {+                return interceptor.AsyncServerStreamingCall(+                    request,+                    new ClientInterceptorContext<TRequest, TResponse>(method, host, options),+                    (req, ctx) => invoker.AsyncServerStreamingCall(ctx.Method, ctx.Host, ctx.Options, req));+            }++            /// <summary>+            /// Intercepts an asynchronous client streaming call with the registered interceptor.+            /// </summary>+            public override AsyncClientStreamingCall<TRequest, TResponse> AsyncClientStreamingCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options)+            {+                return interceptor.AsyncClientStreamingCall(+                    new ClientInterceptorContext<TRequest, TResponse>(method, host, options),+                    ctx => invoker.AsyncClientStreamingCall(ctx.Method, ctx.Host, ctx.Options));+            }++            /// <summary>+            /// Intercepts an asynchronous duplex streaming call with the registered interceptor.+            /// </summary>+            public override AsyncDuplexStreamingCall<TRequest, TResponse> AsyncDuplexStreamingCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options)+            {+                return interceptor.AsyncDuplexStreamingCall(+                    new ClientInterceptorContext<TRequest, TResponse>(method, host, options),+                    ctx => invoker.AsyncDuplexStreamingCall(ctx.Method, ctx.Host, ctx.Options));+            }+        }++        private class MetadataInterceptor : GenericInterceptor+        {+            readonly Func<Metadata, Metadata> interceptor;++            /// <summary>+            /// Creates a new instance of MetadataInterceptor given the specified interceptor function.+            /// </summary>+            public MetadataInterceptor(Func<Metadata, Metadata> interceptor)+            {+                this.interceptor = GrpcPreconditions.CheckNotNull(interceptor, ""interceptor"");+            }++            protected override ClientCallArbitrator<TRequest, TResponse> InterceptCall<TRequest, TResponse>(ClientInterceptorContext<TRequest, TResponse> context, bool clientStreaming, bool serverStreaming, TRequest request)+            {+                return new ClientCallArbitrator<TRequest, TResponse>+                {+                    Context = new ClientInterceptorContext<TRequest, TResponse>(context.Method, context.Host, context.Options.WithHeaders(interceptor(context.Options.Headers)))+                };+            }+        }++        /// <summary>+        /// Returns a <see cref=""Grpc.Core.CallInvoker"" /> instance that intercepts+        /// the invoker with the given interceptor.+        /// </summary>+        /// <param name=""invoker"">The underlying invoker to intercept.</param>+        /// <param name=""interceptor"">The metadata interceptor to intercept calls to the invoker with.</param>+        public static CallInvoker Intercept(this CallInvoker invoker, Func<Metadata, Metadata> interceptor)+        {+            return new InterceptingCallInvoker(invoker, new MetadataInterceptor(interceptor));+        }++        /// <summary>+        /// Returns a <see cref=""Grpc.Core.CallInvoker"" /> instance that intercepts+        /// the invoker with the given interceptor.+        /// </summary>+        /// <param name=""invoker"">The underlying invoker to intercept.</param>+        /// <param name=""interceptor"">The interceptor to intercept calls to the invoker with.</param>+        public static CallInvoker Intercept(this CallInvoker invoker, Interceptor interceptor)+        {+            return new InterceptingCallInvoker(invoker, interceptor);+        }++        /// <summary>+        /// Returns a <see cref=""Grpc.Core.CallInvoker"" /> instance that intercepts+        /// the invoker with the given interceptors.+        /// </summary>+        /// <param name=""invoker"">The channel to intercept.</param>+        /// <param name=""interceptors"">+        /// An array of interceptors to intercept the calls to the invoker with.+        /// Control is passed to the interceptors in the order specified.+        /// </param>+        public static CallInvoker Intercept(this CallInvoker invoker, params Interceptor[] interceptors)+        {+            if (interceptors == null)",GrpcPreconditions.CheckNotNull() instead of silently accepting null.,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12613,169665145,2018-02-21T15:04:37Z,src/csharp/Grpc.Core/Interceptors/Interceptor.cs,"@@ -0,0 +1,281 @@+#region Copyright notice and license++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Reflection;+using System.Threading.Tasks;+using Grpc.Core.Internal;++namespace Grpc.Core.Interceptors+{+    /// <summary>+    /// Carries along the context associated with intercepted invocations on the client side.+    /// This is an EXPERIMENTAL API.+    /// </summary>+    public class ClientInterceptorContext<TRequest, TResponse>",This class should be in a separate file. ClientInterceptorContext.cs,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12613,169671715,2018-02-21T15:23:07Z,src/csharp/Grpc.Core/Interceptors/GenericInterceptor.cs,"@@ -0,0 +1,449 @@+#region Copyright notice and license++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Threading;+using System.Threading.Tasks;+using Grpc.Core.Internal;++namespace Grpc.Core.Interceptors+{+    /// <summary>+    /// Provides a base class for generic interceptor implementations that raises+    /// events and hooks to control the RPC lifecycle.+    /// </summary>+    public abstract class GenericInterceptor : Interceptor+    {+        /// <summary>+        /// Provides hooks through which an invocation should be intercepted.+        /// </summary>+        public sealed class ClientCallArbitrator<TRequest, TResponse>+            where TRequest : class+            where TResponse : class+        {+            internal ClientCallArbitrator<TRequest, TResponse> Freeze()+            {+                return (ClientCallArbitrator<TRequest, TResponse>)MemberwiseClone();+            }+            /// <summary>+            /// Override the context for the outgoing invocation.+            /// </summary>+            public ClientInterceptorContext<TRequest, TResponse> Context { get; set; }+            /// <summary>+            /// Override the request for the outgoing invocation for non-client-streaming invocations.+            /// </summary>+            public TRequest UnaryRequest { get; set; }+            /// <summary>+            /// Delegate that intercepts a response from a non-server-streaming invocation and optionally overrides it.+            /// </summary>+            public Func<TResponse, TResponse> OnUnaryResponse { get; set; }+            /// <summary>+            /// Delegate that intercepts each request message for a client-streaming invocation and optionally overrides each message.+            /// </summary>+            public Func<TRequest, TRequest> OnRequestMessage { get; set; }+            /// <summary>+            /// Delegate that intercepts each response message for a server-streaming invocation and optionally overrides each message.+            /// </summary>+            public Func<TResponse, TResponse> OnResponseMessage { get; set; }+            /// <summary>+            /// Callback that gets invoked when response stream is finished.+            /// </summary>+            public Action OnResponseStreamEnd { get; set; }+            /// <summary>+            /// Callback that gets invoked when request stream is finished.+            /// </summary>+            public Action OnRequestStreamEnd { get; set; }+        }++        /// <summary>+        /// Intercepts an outgoing call from the client side.+        /// Derived classes that intend to intercept outgoing invocations from the client side should+        /// override this and return the appropriate hooks in the form of a ClientCallArbitrator instance.+        /// </summary>+        /// <param name=""context"">The context of the outgoing invocation.</param>+        /// <param name=""clientStreaming"">True if the invocation is client-streaming.</param>+        /// <param name=""serverStreaming"">True if the invocation is server-streaming.</param>+        /// <param name=""request"">The request message for client-unary invocations, null otherwise.</param>+        /// <typeparam name=""TRequest"">Request message type for the current invocation.</typeparam>+        /// <typeparam name=""TResponse"">Response message type for the current invocation.</typeparam>+        /// <returns>+        /// The derived class should return an instance of ClientCallArbitrator to control the trajectory+        /// as they see fit, or null if it does not intend to pursue the invocation any further.+        /// </returns>+        protected virtual ClientCallArbitrator<TRequest, TResponse> InterceptCall<TRequest, TResponse>(ClientInterceptorContext<TRequest, TResponse> context, bool clientStreaming, bool serverStreaming, TRequest request)+            where TRequest : class+            where TResponse : class+        {+            return null;+        }++        /// <summary>+        /// Provides hooks through which a server-side handler should be intercepted.+        /// </summary>+        public sealed class ServerCallArbitrator<TRequest, TResponse>",should the arbitrator classes really be nested under GenericInterceptor?,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12613,169678752,2018-02-21T15:42:05Z,src/csharp/Grpc.Core/Interceptors/GenericInterceptor.cs,"@@ -0,0 +1,449 @@+#region Copyright notice and license++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Threading;+using System.Threading.Tasks;+using Grpc.Core.Internal;++namespace Grpc.Core.Interceptors+{+    /// <summary>+    /// Provides a base class for generic interceptor implementations that raises+    /// events and hooks to control the RPC lifecycle.+    /// </summary>+    public abstract class GenericInterceptor : Interceptor","If I understand that correctly, the GenericInterceptor is basically an ""advanced interceptor"" that allows you to define hooks for various events in the call's lifecycle.  It also not necessarily an integral part or the Interceptor API, it's basically a useful implementation that allows you to define advanced interceptor behavior easily (users could provide their own implementation of GenericInterceptor if they wanted to, right?).If so, then I think the interceptor functionality should come in two parts:1. the ""core"" interceptor API that is simple and provides the basis for implementation of all interceptors (and advanced behavior might be difficult do pull off, but possible).2. add-on functionality like GenericInterceptor (it's good that we have a proof of concept, but fine tuning the complex code might that a little longer).Would it make sense to only review the basic interceptor API and provide GenericInterceptor in a followup PR?",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12613,169685403,2018-02-21T16:00:09Z,src/csharp/Grpc.Core/ServerServiceDefinition.cs,"@@ -45,6 +48,28 @@ private ServerServiceDefinition(Dictionary<string, IServerCallHandler> callHandl             }         } +        /// <summary>+        /// Returns a <see cref=""Grpc.Core.ServerServiceDefinition"" /> instance that+        /// intercepts calls to the underlying service handler via the given interceptor.+        /// This is an EXPERIMENTAL API.+        /// </summary>+        /// <param name=""interceptor"">The interceptor to register on service.</param>+        public ServerServiceDefinition Intercept(Interceptor interceptor)","a general thought on the Intercept(interceptor) methods:there's a distinction between  the act of registering an interceptor    and   actually intercepting the call. In this PR, we are using  ""Intercept"" in the sense of ""register interceptor"", but the name ""intercept"" might have the feel of actually intercepting something.  Would renaming ""InterceptWith(interceptor)"" be clearer for the users? What does the Java API do here?I dont' feel strongly about this, just wanted discuss the idea a bit.",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/12613,169693764,2018-02-21T16:23:11Z,src/csharp/Grpc.Core/Interceptors/Interceptor.cs,"@@ -0,0 +1,281 @@+#region Copyright notice and license++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Reflection;+using System.Threading.Tasks;+using Grpc.Core.Internal;++namespace Grpc.Core.Interceptors+{+    /// <summary>+    /// Carries along the context associated with intercepted invocations on the client side.+    /// This is an EXPERIMENTAL API.+    /// </summary>+    public class ClientInterceptorContext<TRequest, TResponse>+        where TRequest : class+        where TResponse : class+    {+        /// <summary>+        /// Creates a new instance of <see cref=""Grpc.Core.Interceptors.ClientInterceptorContext{TRequest, TResponse}"" />+        /// with the specified method, host, and call options.+        /// </summary>+        /// <param name=""method"">A <see cref=""Grpc.Core.Method{TRequest, TResponse}""/> object representing the method to be invoked.</param>+        /// <param name=""host"">The host to dispatch the current call to.</param>+        /// <param name=""options"">A <see cref=""Grpc.Core.CallOptions""/> instance containing the call options of the current call.</param>++        public ClientInterceptorContext(Method<TRequest, TResponse> method, string host, CallOptions options)+        {+            Method = method;+            Host = host;+            Options = options;+        }++        /// <summary>+        /// Gets the <see cref=""Grpc.Core.Method{TRequest, TResponse}""/> representing+        /// the method to be invoked.+        /// </summary>+        public Method<TRequest, TResponse> Method { get; }++        /// <summary>+        /// Gets the host that the currect invocation will be dispatched to.+        /// </summary>+        public string Host { get; }++        /// <summary>+        /// Gets the <see cref=""Grpc.Core.CallOptions""/> structure representing the+        /// call options associated with the current invocation.+        /// </summary>+        public CallOptions Options { get; }+    }++    /// <summary>+    /// Serves as the base class for gRPC interceptors.+    /// This is an EXPERIMENTAL API.+    /// </summary>+    public abstract class Interceptor+    {+        /// <summary>+        /// Represents a continuation for intercepting simple blocking invocations.+        /// </summary>+        /// <typeparam name=""TRequest"">Request message type for this invocation.</typeparam>+        /// <typeparam name=""TResponse"">Response message type for this invocation.</typeparam>+        /// <param name=""request"">The request value to continue the invocation with.</param>+        /// <param name=""context"">+        /// The <see cref=""Grpc.Core.Interceptors.ClientInterceptorContext{TRequest, TResponse}""/>+        /// instance to pass to the next step in the invocation process.+        /// </param>+        public delegate TResponse BlockingUnaryCallContinuation<TRequest, TResponse>(TRequest request, ClientInterceptorContext<TRequest, TResponse> context)","Yes, I think so. It is only really used by the derived classes of GenericInterceptor and therefore always in scope when you derive a class.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/14450,169705775,2018-02-21T16:57:11Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -475,8 +382,8 @@ static void on_resolver_result_changed_locked(void* arg, grpc_error* error) {       service_config_json =           gpr_strdup(grpc_channel_arg_get_string(channel_arg));       if (service_config_json != nullptr) {-        grpc_service_config* service_config =-            grpc_service_config_create(service_config_json);+        grpc_core::UniquePtr<grpc_core::ServiceConfig> service_config =",nit: calling the constructor avoids temporary rvalues that may be created when using the = syntax.,
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/12613,169737637,2018-02-21T18:41:56Z,src/csharp/Grpc.Core/Interceptors/GenericInterceptor.cs,"@@ -0,0 +1,449 @@+#region Copyright notice and license++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Threading;+using System.Threading.Tasks;+using Grpc.Core.Internal;++namespace Grpc.Core.Interceptors+{+    /// <summary>+    /// Provides a base class for generic interceptor implementations that raises+    /// events and hooks to control the RPC lifecycle.+    /// </summary>+    public abstract class GenericInterceptor : Interceptor","Yes, but learning from Python, I feel like a standard `GenericInterceptor` being part of our library is valuable, as without it, most interceptors will be much more verbose to write. We can move it to the tests or examples now and maybe add it in a future implementation, but that will possibly fragment other interceptor libraries that will be written on top of it (which is probably fine). (for some reason Github shifted my comments between posts!)",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/12613,169760130,2018-02-21T19:59:00Z,src/csharp/Grpc.Core/Interceptors/CallInvokerExtensions.cs,"@@ -0,0 +1,171 @@+#region Copyright notice and license++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Linq;+using Grpc.Core.Utils;++namespace Grpc.Core.Interceptors+{+    /// <summary>+    /// Extends the CallInvoker class to provide the interceptor facility on the client side.+    /// This is an EXPERIMENTAL API.+    /// </summary>+    public static class CallInvokerExtensions+    {+        /// <summary>+        /// Decorates an underlying <see cref=""Grpc.Core.CallInvoker"" /> to+        /// intercept calls through a given interceptor.+        /// </summary>+        private class InterceptingCallInvoker : CallInvoker+        {+            readonly CallInvoker invoker;+            readonly Interceptor interceptor;++            /// <summary>+            /// Creates a new instance of <see cref=""Grpc.Core.Interceptors.CallInvokerExtensions.InterceptingCallInvoker"" />+            /// with the given underlying invoker and interceptor instances.+            /// </summary>+            public InterceptingCallInvoker(CallInvoker invoker, Interceptor interceptor)+            {+                this.invoker = GrpcPreconditions.CheckNotNull(invoker, ""invoker"");+                this.interceptor = GrpcPreconditions.CheckNotNull(interceptor, ""interceptor"");+            }++            /// <summary>+            /// Intercepts a simple blocking call with the registered interceptor.+            /// </summary>+            public override TResponse BlockingUnaryCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request)+            {+                return interceptor.BlockingUnaryCall(+                    request,+                    new ClientInterceptorContext<TRequest, TResponse>(method, host, options),","Thinking about it, making it a struct is probably a better idea. It should be small enough and it is easier to avoid perf issues with the struct than a class down the road. Done.",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/12613,169760390,2018-02-21T19:59:56Z,src/csharp/Grpc.Core/ServerServiceDefinition.cs,"@@ -45,6 +48,28 @@ private ServerServiceDefinition(Dictionary<string, IServerCallHandler> callHandl             }         } +        /// <summary>+        /// Returns a <see cref=""Grpc.Core.ServerServiceDefinition"" /> instance that+        /// intercepts calls to the underlying service handler via the given interceptor.+        /// This is an EXPERIMENTAL API.+        /// </summary>+        /// <param name=""interceptor"">The interceptor to register on service.</param>+        public ServerServiceDefinition Intercept(Interceptor interceptor)","Java has `withInterceptor`, but I think it is pretty clear and more concise and C#y as is. The type of the receiver class should make it clear to the user what the operation being done is (i.e. Channel).",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/12613,169760742,2018-02-21T20:01:13Z,src/csharp/Grpc.Core/Interceptors/GenericInterceptor.cs,"@@ -0,0 +1,449 @@+#region Copyright notice and license++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Threading;+using System.Threading.Tasks;+using Grpc.Core.Internal;++namespace Grpc.Core.Interceptors+{+    /// <summary>+    /// Provides a base class for generic interceptor implementations that raises+    /// events and hooks to control the RPC lifecycle.+    /// </summary>+    public abstract class GenericInterceptor : Interceptor","I have turned `GenericInterceptor` into an internal class for now, as it simplifies our own internal interceptor uses (for Metadata and in ClientBase), but it is good to leave it out for now as it will be a major API-stability commitment.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12613,169898461,2018-02-22T09:33:58Z,src/csharp/Grpc.Core/Interceptors/CallInvokerExtensions.cs,"@@ -0,0 +1,195 @@+#region Copyright notice and license++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Linq;+using Grpc.Core.Utils;++namespace Grpc.Core.Interceptors+{+    /// <summary>+    /// Extends the CallInvoker class to provide the interceptor facility on the client side.+    /// This is an EXPERIMENTAL API.+    /// </summary>+    public static class CallInvokerExtensions+    {+        /// <summary>+        /// Decorates an underlying <see cref=""Grpc.Core.CallInvoker"" /> to+        /// intercept calls through a given interceptor.+        /// </summary>+        private class InterceptingCallInvoker : CallInvoker+        {+            readonly CallInvoker invoker;+            readonly Interceptor interceptor;++            /// <summary>+            /// Creates a new instance of <see cref=""Grpc.Core.Interceptors.CallInvokerExtensions.InterceptingCallInvoker"" />+            /// with the given underlying invoker and interceptor instances.+            /// </summary>+            public InterceptingCallInvoker(CallInvoker invoker, Interceptor interceptor)+            {+                this.invoker = GrpcPreconditions.CheckNotNull(invoker, ""invoker"");+                this.interceptor = GrpcPreconditions.CheckNotNull(interceptor, ""interceptor"");+            }++            /// <summary>+            /// Intercepts a simple blocking call with the registered interceptor.+            /// </summary>+            public override TResponse BlockingUnaryCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request)+            {+                return interceptor.BlockingUnaryCall(+                    request,+                    new ClientInterceptorContext<TRequest, TResponse>(method, host, options),+                    (req, ctx) => invoker.BlockingUnaryCall(ctx.Method, ctx.Host, ctx.Options, req));+            }++            /// <summary>+            /// Intercepts a simple asynchronous call with the registered interceptor.+            /// </summary>+            public override AsyncUnaryCall<TResponse> AsyncUnaryCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request)+            {+                return interceptor.AsyncUnaryCall(+                    request,+                    new ClientInterceptorContext<TRequest, TResponse>(method, host, options),+                    (req, ctx) => invoker.AsyncUnaryCall(ctx.Method, ctx.Host, ctx.Options, req));+            }++            /// <summary>+            /// Intercepts an asynchronous server streaming call with the registered interceptor.+            /// </summary>+            public override AsyncServerStreamingCall<TResponse> AsyncServerStreamingCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options, TRequest request)+            {+                return interceptor.AsyncServerStreamingCall(+                    request,+                    new ClientInterceptorContext<TRequest, TResponse>(method, host, options),+                    (req, ctx) => invoker.AsyncServerStreamingCall(ctx.Method, ctx.Host, ctx.Options, req));+            }++            /// <summary>+            /// Intercepts an asynchronous client streaming call with the registered interceptor.+            /// </summary>+            public override AsyncClientStreamingCall<TRequest, TResponse> AsyncClientStreamingCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options)+            {+                return interceptor.AsyncClientStreamingCall(+                    new ClientInterceptorContext<TRequest, TResponse>(method, host, options),+                    ctx => invoker.AsyncClientStreamingCall(ctx.Method, ctx.Host, ctx.Options));+            }++            /// <summary>+            /// Intercepts an asynchronous duplex streaming call with the registered interceptor.+            /// </summary>+            public override AsyncDuplexStreamingCall<TRequest, TResponse> AsyncDuplexStreamingCall<TRequest, TResponse>(Method<TRequest, TResponse> method, string host, CallOptions options)+            {+                return interceptor.AsyncDuplexStreamingCall(+                    new ClientInterceptorContext<TRequest, TResponse>(method, host, options),+                    ctx => invoker.AsyncDuplexStreamingCall(ctx.Method, ctx.Host, ctx.Options));+            }+        }++        private class MetadataInterceptor : GenericInterceptor+        {+            readonly Func<Metadata, Metadata> interceptor;++            /// <summary>+            /// Creates a new instance of MetadataInterceptor given the specified interceptor function.+            /// </summary>+            public MetadataInterceptor(Func<Metadata, Metadata> interceptor)+            {+                this.interceptor = GrpcPreconditions.CheckNotNull(interceptor, ""interceptor"");+            }++            protected override ClientCallHooks<TRequest, TResponse> InterceptCall<TRequest, TResponse>(ClientInterceptorContext<TRequest, TResponse> context, bool clientStreaming, bool serverStreaming, TRequest request)+            {+                var metadata = context.Options.Headers ?? new Metadata();+                return new ClientCallHooks<TRequest, TResponse>+                {+                    ContextOverride = new ClientInterceptorContext<TRequest, TResponse>(context.Method, context.Host, context.Options.WithHeaders(interceptor(metadata))),+                };+            }+        }++        /// <summary>+        /// Returns a <see cref=""Grpc.Core.CallInvoker"" /> instance that intercepts+        /// the invoker with the given interceptor.+        /// </summary>+        /// <param name=""invoker"">The underlying invoker to intercept.</param>+        /// <param name=""interceptor"">+        /// An interceptor delegate that takes the request metadata to be sent with an outgoing call+        /// and returns a <see cref=""Grpc.Core.Metadata"" /> instance that will replace the existing+        /// invocation metadata.+        /// </param>+        /// <remarks>+        /// Multiple interceptors can be added on top of each other by calling","nit:  you can't actually use  Intercept(a,b,c)  when you're passing Func<Metadata, Metadata>  as an interceptor, so the comment is a bit misleading.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12613,169900846,2018-02-22T09:43:25Z,src/csharp/Grpc.Core.Tests/Interceptors/ClientInterceptorTest.cs,"@@ -0,0 +1,166 @@+#region Copyright notice and license++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Generic;+using System.Linq;+using System.Text;+using System.Threading;+using System.Threading.Tasks;+using Grpc.Core;+using Grpc.Core.Interceptors;+using Grpc.Core.Internal;+using Grpc.Core.Utils;+using Grpc.Core.Tests;+using NUnit.Framework;++namespace Grpc.Core.Interceptors.Tests+{+    public class ClientInterceptorTest+    {+        const string Host = ""127.0.0.1"";++        [Test]+        public void AddRequestHeaderInClientInterceptor()+        {+            const string HeaderKey = ""x-client-interceptor"";+            const string HeaderValue = ""hello-world"";+            var helper = new MockServiceHelper(Host);+            helper.UnaryHandler = new UnaryServerMethod<string, string>((request, context) =>+            {+                var interceptorHeader = context.RequestHeaders.Last(m => (m.Key == HeaderKey)).Value;+                Assert.AreEqual(interceptorHeader, HeaderValue);+                return Task.FromResult(""PASS"");+            });+            var server = helper.GetServer();+            server.Start();+            var callInvoker = helper.GetChannel().Intercept(metadata =>+            {+                metadata = metadata ?? new Metadata();+                metadata.Add(new Metadata.Entry(HeaderKey, HeaderValue));+                return metadata;+            });+            Assert.AreEqual(""PASS"", callInvoker.BlockingUnaryCall(new Method<string, string>(MethodType.Unary, MockServiceHelper.ServiceName, ""Unary"", Marshallers.StringMarshaller, Marshallers.StringMarshaller), Host, new CallOptions(), """"));+        }++        private class CallbackInterceptor : GenericInterceptor","nit: code style: I tend to put the  private classes after all the instance methods as they are basically ""helpers"" (and the tests is what you should see first when reading the file).",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12613,169904825,2018-02-22T09:57:39Z,src/csharp/Grpc.Core/Interceptors/CallInvokerExtensions.cs,"@@ -0,0 +1,195 @@+#region Copyright notice and license++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Linq;+using Grpc.Core.Utils;++namespace Grpc.Core.Interceptors+{+    /// <summary>+    /// Extends the CallInvoker class to provide the interceptor facility on the client side.+    /// This is an EXPERIMENTAL API.+    /// </summary>+    public static class CallInvokerExtensions+    {+        /// <summary>+        /// Decorates an underlying <see cref=""Grpc.Core.CallInvoker"" /> to+        /// intercept calls through a given interceptor.+        /// </summary>+        private class InterceptingCallInvoker : CallInvoker","I do think ""InterceptingCallInvoker"" is a legitimate top-level internal class (it actually used to be one before this PR) and should not be nested.  Overall, I feel like this PR uses class nesting a bit too much (which harms readability and requires an extra refactoring step in case I needed to reuse some of the classes that are now nested. such nested classes are also harder to discover which can lead to unwanted code duplication). Nested classes are a useful concept for some things (and some of your uses I agree with), but should not be used universally.Some guidelines on using nested types: https://msdn.microsoft.com/en-us/library/tdz1bea9(v=vs.71).aspxCan you make InterceptingCallInvoker a top-level internal class?",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/12613,169925454,2018-02-22T11:17:25Z,src/csharp/Grpc.Core/Interceptors/Interceptor.cs,"@@ -0,0 +1,406 @@+#region Copyright notice and license++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Reflection;+using System.Threading.Tasks;+using Grpc.Core.Internal;++namespace Grpc.Core.Interceptors+{+    /// <summary>+    /// Serves as the base class for gRPC interceptors.+    /// This is an EXPERIMENTAL API.+    /// </summary>+    public abstract class Interceptor",Is there a specific reason why to have only a single Interceptor class  for both server and client?Another option would be to have Interceptor and ServerInterceptor classes and each would be only be defining interception methods that are server-specific and client specific?  It's hard for me to imagine a scenario where I would use the same interceptor for both server and client.,
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/12613,169984533,2018-02-22T15:01:38Z,src/csharp/Grpc.Core/Interceptors/Interceptor.cs,"@@ -0,0 +1,406 @@+#region Copyright notice and license++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Reflection;+using System.Threading.Tasks;+using Grpc.Core.Internal;++namespace Grpc.Core.Interceptors+{+    /// <summary>+    /// Serves as the base class for gRPC interceptors.+    /// This is an EXPERIMENTAL API.+    /// </summary>+    public abstract class Interceptor","Because it is an abstract class rather than interface, I deliberately decided to merge the two interfaces into one. The overhead is minimal and it will allow one class to implement both sides, which is nice, if you are a library author for example, and provide a tracing or logging interceptor, you expose one class to the user that they register on both sides. If you want, you can implement only one side, but if we went with two base classes, there was no way to consolidate them into one implementation.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/14450,170013866,2018-02-22T16:24:57Z,src/core/lib/slice/slice_hash_table.h,"@@ -17,52 +17,186 @@ #ifndef GRPC_CORE_LIB_SLICE_SLICE_HASH_TABLE_H #define GRPC_CORE_LIB_SLICE_SLICE_HASH_TABLE_H -#include ""src/core/lib/transport/metadata.h""+#include <string.h> -/** Hash table implementation.- *- * This implementation uses open addressing- * (https://en.wikipedia.org/wiki/Open_addressing) with linear- * probing (https://en.wikipedia.org/wiki/Linear_probing).- *- * The keys are \a grpc_slice objects.  The values are arbitrary pointers- * with a common destroy function.- *- * Hash tables are intentionally immutable, to avoid the need for locking.- */+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>++#include ""src/core/lib/gpr/useful.h""+#include ""src/core/lib/gprpp/ref_counted.h""+#include ""src/core/lib/gprpp/ref_counted_ptr.h""+#include ""src/core/lib/slice/slice_internal.h""++/// Hash table implementation.+///+/// This implementation uses open addressing+/// (https://en.wikipedia.org/wiki/Open_addressing) with linear+/// probing (https://en.wikipedia.org/wiki/Linear_probing).+///+/// The keys are \a grpc_slice objects.  The values are arbitrary pointers+/// with a common destroy function.+///+/// Hash tables are intentionally immutable, to avoid the need for locking.++namespace grpc_core {++template <typename T>+class SliceHashTable : public RefCounted<SliceHashTable<T>> {+ public:+  struct Entry {+    grpc_slice key;+    T value;  // Must not be null.+  };++  // Function for comparing values.+  // TODO(roth): Eliminate this and the Cmp() method from this API once+  // grpc_channel_args is redesigned to require that keys are unique.+  typedef int (*ValueCmp)(const T&, const T&);++  /// Creates a new hash table of containing \a entries, which is an array+  /// of length \a num_entries.  Takes ownership of all keys and values in \a+  /// entries.  If not NULL, \a value_cmp will be used to compare values in+  /// the context of \a Cmp(). If NULL, raw pointer (\a GPR_ICMP) comparison+  /// will be used.+  static RefCountedPtr<SliceHashTable> Create(size_t num_entries,+                                              Entry* entries,+                                              ValueCmp value_cmp);++  /// Returns the value from the table associated with \a key.+  /// Returns null if \a key is not found.+  const T& Get(const grpc_slice key) const;++  /// Compares \a a vs. \a b.+  /// A table is considered ""smaller"" (resp. ""greater"") if:+  ///  - GPR_ICMP(a->value_cmp, b->value_cmp) < 1 (resp. > 1),+  ///  - else, it contains fewer (resp. more) entries,+  ///  - else, if strcmp(a_key, b_key) < 1 (resp. > 1),+  ///  - else, if value_cmp(a_value, b_value) < 1 (resp. > 1).+  static int Cmp(const SliceHashTable& a, const SliceHashTable& b);++ private:+  // So New() can call our private ctor.+  template <typename T2, typename... Args>+  friend T2* New(Args&&... args);++  SliceHashTable(size_t num_entries, Entry* entries, ValueCmp value_cmp);+  virtual ~SliceHashTable();++  static bool IsEmpty(Entry* entry) { return entry->value == T(); }++  void Add(grpc_slice key, T& value);++  // Default value comparison function, if none specified by caller.+  static int DefaultValueCmp(const T& a, const T& b) { return GPR_ICMP(a, b); }++  const ValueCmp value_cmp_;+  const size_t size_;+  size_t max_num_probes_;+  Entry* entries_;+  T empty_value_;+};++//+// implementation -- no user-serviceable parts below+//++template <typename T>+RefCountedPtr<SliceHashTable<T>> SliceHashTable<T>::Create(size_t num_entries,+                                                           Entry* entries,+                                                           ValueCmp value_cmp) {+  return MakeRefCounted<SliceHashTable<T>>(num_entries, entries, value_cmp);+}++template <typename T>+SliceHashTable<T>::SliceHashTable(size_t num_entries, Entry* entries,+                                  ValueCmp value_cmp)+    : value_cmp_(value_cmp),+      // Keep load factor low to improve performance of lookups.+      size_(num_entries * 2),+      max_num_probes_(0) {+  entries_ = static_cast<Entry*>(gpr_zalloc(sizeof(Entry) * size_));+  for (size_t i = 0; i < num_entries; ++i) {+    Entry* entry = &entries[i];+    Add(entry->key, entry->value);+  }+}++template <typename T>+SliceHashTable<T>::~SliceHashTable() {+  for (size_t i = 0; i < size_; ++i) {+    Entry* entry = &entries_[i];+    if (!IsEmpty(entry)) {+      grpc_slice_unref_internal(entry->key);+      entry->value.~T();+    }+  }+  gpr_free(entries_);+}++template <typename T>+void SliceHashTable<T>::Add(grpc_slice key, T& value) {+  GPR_ASSERT(value != nullptr);+  const size_t hash = grpc_slice_hash(key);+  for (size_t offset = 0; offset < size_; ++offset) {+    const size_t idx = (hash + offset) % size_;+    if (IsEmpty(&entries_[idx])) {+      entries_[idx].key = key;+      entries_[idx].value = std::move(value);+      // Keep track of the maximum number of probes needed, since this+      // provides an upper bound for lookups.+      if (offset > max_num_probes_) max_num_probes_ = offset;+      return;+    }+  }+  GPR_ASSERT(false);  // Table should never be full.+}++template <typename T>+const T& SliceHashTable<T>::Get(const grpc_slice key) const {+  const size_t hash = grpc_slice_hash(key);+  // We cap the number of probes at the max number recorded when+  // populating the table.+  for (size_t offset = 0; offset <= max_num_probes_; ++offset) {+    const size_t idx = (hash + offset) % size_;+    if (IsEmpty(&entries_[idx])) break;+    if (grpc_slice_eq(entries_[idx].key, key)) {+      return entries_[idx].value;+    }+  }+  return empty_value_;  // Not found.","I don't think this is robust. The default value for T is certainly a valid value. Get's return is ambiguous. It's not as elegant, but perhaps we want to return a `const T*`, which unlike a reference, is nullable.",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/14490,170155222,2018-02-23T02:51:53Z,src/compiler/objective_c_plugin.cc,"@@ -30,11 +30,58 @@ using ::google::protobuf::compiler::objectivec::     IsProtobufLibraryBundledProtoFile; using ::google::protobuf::compiler::objectivec::ProtobufLibraryFrameworkName; +namespace {++inline ::grpc::string LocalImport(const ::grpc::string &import) {+  return ::grpc::string(""#import \"""" + import + ""\""\n"");+}++inline ::grpc::string SystemImport(const ::grpc::string &import) {+  return ::grpc::string(""#import <"" + import + "">\n"");+}++inline ::grpc::string PreprocIf(const ::grpc::string& condition,+                                const ::grpc::string& if_true) {+  return ::grpc::string(""#if "" + condition + ""\n"" + if_true + ""#endif\n"");","Would appreciate a favor to check if the condition macro is defined, and regard it as 0 if not.",
16251184,nallohki,https://api.github.com/repos/grpc/grpc/pulls/14490,170178564,2018-02-23T07:00:31Z,src/compiler/objective_c_plugin.cc,"@@ -30,11 +30,58 @@ using ::google::protobuf::compiler::objectivec::     IsProtobufLibraryBundledProtoFile; using ::google::protobuf::compiler::objectivec::ProtobufLibraryFrameworkName; +namespace {++inline ::grpc::string LocalImport(const ::grpc::string &import) {+  return ::grpc::string(""#import \"""" + import + ""\""\n"");+}++inline ::grpc::string SystemImport(const ::grpc::string &import) {+  return ::grpc::string(""#import <"" + import + "">\n"");+}++inline ::grpc::string PreprocIf(const ::grpc::string& condition,+                                const ::grpc::string& if_true) {+  return ::grpc::string(""#if "" + condition + ""\n"" + if_true + ""#endif\n"");+}++inline ::grpc::string PreprocIfElse(const ::grpc::string& condition,+                                    const ::grpc::string& if_true,+                                    const ::grpc::string& if_false) {+  return ::grpc::string(""#if "" + condition + ""\n"" ++                        if_true + ""#else\n"" + if_false + ""#endif\n"");+}++inline ::grpc::string ImportProtoHeaders(+    const grpc::protobuf::FileDescriptor* dep,+    const char *indent) {+  ::grpc::string header = grpc_objective_c_generator::MessageHeaderName(dep);++  if (!IsProtobufLibraryBundledProtoFile(dep)) {+    return indent + LocalImport(header);+  }++  ::grpc::string base_name = header;+  grpc_generator::StripPrefix(&base_name, ""google/protobuf/"");+  // create the import code snippet+  ::grpc::string framework_header =+      ::grpc::string(ProtobufLibraryFrameworkName) + ""/"" + base_name;++  static const ::grpc::string kFrameworkImportsCondition =+      ""GPB_USE_PROTOBUF_FRAMEWORK_IMPORTS"";+  return PreprocIfElse(kFrameworkImportsCondition,+                       indent + SystemImport(framework_header),+                       indent + LocalImport(header));+}++}  // namespace+ class ObjectiveCGrpcGenerator : public grpc::protobuf::compiler::CodeGenerator {  public:   ObjectiveCGrpcGenerator() {}   virtual ~ObjectiveCGrpcGenerator() {} + public:",A change got omitted in my pull request.  I placed the constants to the class level and added a private: here.,
547926,dcow,https://api.github.com/repos/grpc/grpc/pulls/14387,170397698,2018-02-24T00:06:20Z,src/core/lib/security/transport/security_connector.cc,"@@ -704,18 +704,31 @@ static void ssl_server_add_handshakers(grpc_server_security_connector* sc, }  static int ssl_host_matches_name(const tsi_peer* peer, const char* peer_name) {-  char* allocated_name = nullptr;+  char* allocated_host = nullptr;+  char* allocated_addr = nullptr;   int r;    if (strchr(peer_name, ':') != nullptr) {     char* ignored_port;-    gpr_split_host_port(peer_name, &allocated_name, &ignored_port);+    gpr_split_host_port(peer_name, &allocated_host, &ignored_port);     gpr_free(ignored_port);-    peer_name = allocated_name;+    peer_name = allocated_host;     if (!peer_name) return 0;   }++  /* IPv6 non-global zone-id should not be included in comparisons. */+  const char* percent = strchr(peer_name, '%');",> Does gRPC work well with self-signed certificates?Yep! You can specify your own list of root trust anchors. We are self-issuing certificates during our provisioning stage and compiling the trust roots for use in our application layer (which uses gRPC). I have verified that with this fix I'm able to connect to a service on one of my hosts via its link-local address without explicitly overriding the expected host name.,
4578188,pmarks-net,https://api.github.com/repos/grpc/grpc/pulls/14387,170407054,2018-02-24T02:13:18Z,src/core/lib/security/transport/security_connector.cc,"@@ -704,18 +704,31 @@ static void ssl_server_add_handshakers(grpc_server_security_connector* sc, }  static int ssl_host_matches_name(const tsi_peer* peer, const char* peer_name) {-  char* allocated_name = nullptr;+  char* allocated_host = nullptr;+  char* allocated_addr = nullptr;   int r;    if (strchr(peer_name, ':') != nullptr) {     char* ignored_port;-    gpr_split_host_port(peer_name, &allocated_name, &ignored_port);+    gpr_split_host_port(peer_name, &allocated_host, &ignored_port);     gpr_free(ignored_port);-    peer_name = allocated_name;+    peer_name = allocated_host;     if (!peer_name) return 0;   }++  /* IPv6 non-global zone-id should not be included in comparisons. */+  const char* percent = strchr(peer_name, '%');","Okay, this approach LGTM if you've found an environment where it's useful.But the code should be a lot simpler.  I would delete the `strchr(peer_name, ':') != nullptr` check, and call `gpr_split_host_port()` unconditionally.  Then you'll always have a mutable `allocated_host`, and you can just replace `'%'` with `'\0'` as needed.",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/14490,170694516,2018-02-26T18:47:26Z,src/compiler/objective_c_plugin.cc,"@@ -91,15 +125,13 @@ class ObjectiveCGrpcGenerator : public grpc::protobuf::compiler::CodeGenerator {       return true;     } +    auto OmitIf = [](const ::grpc::string& s, const ::grpc::string& v) {","The name `OmitIf` of this function is a little bit confusing. Something like `InvertedIf` sounds better to me.In fact to make it cleaner, I think it might make sense to have `PreprocIf`, `PreprocIfNot`, `PreprocIfElse`, `PreprocIfNotElse`, remove the parameter `PreprocConditionFlag` from these functions, and always enable `kCheckIfDefined`.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14516,170764524,2018-02-26T22:57:40Z,src/core/lib/slice/weak_slice_hash_table.h,"@@ -0,0 +1,133 @@+/*+ * Copyright 2016 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ */++#ifndef GRPC_CORE_LIB_SLICE_WEAK_SLICE_HASH_TABLE_H+#define GRPC_CORE_LIB_SLICE_WEAK_SLICE_HASH_TABLE_H++#include <grpc/support/port_platform.h>++#include ""src/core/lib/gprpp/memory.h""+#include ""src/core/lib/gprpp/ref_counted.h""+#include ""src/core/lib/gprpp/ref_counted_ptr.h""+#include ""src/core/lib/slice/slice_internal.h""++/// Weak hash table implementation.+///+/// This entries in this table are weak: an entry may be removed at any time due+/// to a number of reasons: memory pressure, hash collisions, etc.","Can you just call it SliceCache then? In this case, being a HashTable is an implementation detail, but the semantic interface is essentially that of a cache.",
24657604,wcevans,https://api.github.com/repos/grpc/grpc/pulls/14517,170780521,2018-02-27T00:22:18Z,include/grpcpp/impl/codegen/completion_queue.h,"@@ -165,11 +165,7 @@ class CompletionQueue : private GrpcLibraryCodegen {   ///   /// \return true if got an event, false if the queue is fully drained and   ///         shut down.-  bool Next(void** tag, bool* ok) {-    return (AsyncNextInternal(tag, ok,-                              g_core_codegen_interface->gpr_inf_future(-                                  GPR_CLOCK_REALTIME)) != SHUTDOWN);-  }+  virtual bool Next(void** tag, bool* ok);","Do we really want to eat a virtual dispatch on CompletionQueue::Next()? This is part of every single gRPC user's datapath. If you want to allow multiple CompletionQueue implementations, consider allowing the user to avoid the virtual dispatch by providing a subclass that is final.",
24657604,wcevans,https://api.github.com/repos/grpc/grpc/pulls/14517,171037074,2018-02-27T19:21:19Z,include/grpcpp/impl/codegen/completion_queue.h,"@@ -165,11 +165,7 @@ class CompletionQueue : private GrpcLibraryCodegen {   ///   /// \return true if got an event, false if the queue is fully drained and   ///         shut down.-  bool Next(void** tag, bool* ok) {-    return (AsyncNextInternal(tag, ok,-                              g_core_codegen_interface->gpr_inf_future(-                                  GPR_CLOCK_REALTIME)) != SHUTDOWN);-  }+  virtual bool Next(void** tag, bool* ok);","I am a little concerned that CQ::Next() can no longer be inlined even for a minimal implementation of gRPC, but I suppose that FDO solves this problem for anyone who would care. I concede.",
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/14459,171044629,2018-02-27T19:46:47Z,src/core/lib/iomgr/ev_poll_posix.cc,"@@ -1439,7 +1446,30 @@ static void cache_destroy_locked(poll_args* args) {     poll_cache.free_pollers = args->next;   } -  gpr_free(args);+  // Now move this args to the dead poller list for later join+  if (poll_cache.dead_pollers != nullptr) {+    poll_cache.dead_pollers->prev = args;+  }+  args->prev = nullptr;+  args->next = poll_cache.dead_pollers;+  poll_cache.dead_pollers = args;+}++static void cache_harvest_locked() {+  while (poll_cache.dead_pollers) {+    poll_args* args = poll_cache.dead_pollers;+    poll_cache.dead_pollers = poll_cache.dead_pollers->next;+    // Keep the list consistent in case new dead pollers get added when we+    // release the lock below to wait on joining+    if (poll_cache.dead_pollers) {+      poll_cache.dead_pollers->prev = nullptr;+    }+    gpr_cv_signal(&args->harvest);+    gpr_cv_wait(&args->join, &g_cvfds.mu, gpr_inf_future(GPR_CLOCK_MONOTONIC));+    args->poller_thd.Join();+    args->poller_thd.~Thread();","I have seen this pattern  of `Join` followed by `~Thread()` in many places. Would it help to add a parameter to `Join` so that it calls `~Thread()`  instead of making two explicit calls ? A tangential point:Somehow calling ~Thread() explicitly feels a bit inconvenient to me :) ..I have rarely seen this pattern. Also from a readability perspective (of someone like me who is not super familiar with C++) ,  calling `~Foo()` mentally registers as the memory of the object of type `Foo` as also being destroyed; but that is not the case here; We are merely invoking the destructor (and not freeing any memory. The actual freeing of memory happens when the structure containing this thd is destroyed).. So might I suggest creating another helper function called like `TearDown` or `Finish` or something like that and put whatever code you have in `~Thead()` in that function?  (Then `~Thead()` (and perhaps `Join()` can simply call `TearDown()`).",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/14542,171068681,2018-02-27T21:16:05Z,tools/internal_ci/linux/grpc_asan_on_foundry.sh,"@@ -0,0 +1,61 @@+#!/usr/bin/env bash+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++set -ex++# A temporary solution to give Kokoro credentials. +# The file name 4321_grpc-testing-service needs to match auth_credential in +# the build config.+# TODO: Use keystore.+mkdir -p ${KOKORO_KEYSTORE_DIR}+cp ${KOKORO_GFILE_DIR}/GrpcTesting-d0eeee2db331.json ${KOKORO_KEYSTORE_DIR}/4321_grpc-testing-service++mkdir -p /tmpfs/tmp/bazel-canary","It'd be better to use `mktemp -d` to avoid naming conflicts. That command creates the temp dir and returns its name, so you'd store it in a variable and use that throughout this file, instead of hardcoding `/tmpfs/...`",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/14483,171073281,2018-02-27T21:32:46Z,src/core/tsi/ssl_session_cache.h,"@@ -0,0 +1,113 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_TSI_SSL_SESSION_CACHE_H+#define GRPC_CORE_TSI_SSL_SESSION_CACHE_H++#include <grpc/support/port_platform.h>++#include <list>",gRPC core cannot use standard C++ libraries. The rational is explained athttps://github.com/grpc/proposal/blob/master/L6-allow-c%2B%2B-in-grpc-core.mdIt seems that your code does not really use this library. please delete.,
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/14483,171073394,2018-02-27T21:33:06Z,src/core/tsi/ssl_session_cache.h,"@@ -0,0 +1,113 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_TSI_SSL_SESSION_CACHE_H+#define GRPC_CORE_TSI_SSL_SESSION_CACHE_H++#include <grpc/support/port_platform.h>++#include <list>+#include <unordered_map>","Sam as above, do not use unordered_map. It seems that your code does not really use this library. please delete.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14459,171089846,2018-02-27T22:34:05Z,src/core/lib/gprpp/thd_posix.cc,"@@ -0,0 +1,196 @@+/*+ *+ * Copyright 2015 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++/* Posix implementation for gpr threads. */++#include <grpc/support/port_platform.h>++#ifdef GPR_POSIX_SYNC++#include ""src/core/lib/gprpp/thd.h""++#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>+#include <grpc/support/thd_id.h>+#include <pthread.h>+#include <stdlib.h>+#include <string.h>++#include ""src/core/lib/gpr/fork.h""+#include ""src/core/lib/gpr/useful.h""++namespace grpc_core {+namespace {+gpr_mu g_mu;+gpr_cv g_cv;+int g_thread_count;+int g_awaiting_threads;++struct thd_arg {+  Thread* thread;+  void (*body)(void* arg); /* body of a thread */+  void* arg;               /* argument to a thread */+  const char* name;        /* name of thread. Can be nullptr. */+};++/*****************************************+ * Only used when fork support is enabled+ */++void inc_thd_count() {+  if (grpc_fork_support_enabled()) {+    gpr_mu_lock(&g_mu);+    g_thread_count++;+    gpr_mu_unlock(&g_mu);+  }+}++void dec_thd_count() {+  if (grpc_fork_support_enabled()) {+    gpr_mu_lock(&g_mu);+    g_thread_count--;+    if (g_awaiting_threads && g_thread_count == 0) {+      gpr_cv_signal(&g_cv);+    }+    gpr_mu_unlock(&g_mu);+  }+}++}  // namespace++Thread::Thread(const char* thd_name, void (*thd_body)(void* arg), void* arg,+               bool* success)+    : real_(true), alive_(false), started_(false), joined_(false) {+  gpr_mu_init(&mu_);+  gpr_cv_init(&ready_);+  pthread_attr_t attr;+  /* don't use gpr_malloc as we may cause an infinite recursion with+   * the profiling code */+  thd_arg* a = static_cast<thd_arg*>(malloc(sizeof(*a)));+  GPR_ASSERT(a != nullptr);+  a->thread = this;+  a->body = thd_body;+  a->arg = arg;+  a->name = thd_name;+  inc_thd_count();++  GPR_ASSERT(pthread_attr_init(&attr) == 0);+  GPR_ASSERT(pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_JOINABLE) == 0);++  pthread_t p;+  alive_ = (pthread_create(&p, &attr,+                           [](void* v) -> void* {+                             thd_arg a = *static_cast<thd_arg*>(v);+                             free(v);+                             if (a.name != nullptr) {+#if GPR_APPLE_PTHREAD_NAME+                               /* Apple supports 64 characters, and will+                                * truncate if it's longer. */+                               pthread_setname_np(a.name);+#elif GPR_LINUX_PTHREAD_NAME+                               /* Linux supports 16 characters max, and will+                                * error if it's longer. */+                               char buf[16];+                               size_t buf_len = GPR_ARRAY_SIZE(buf) - 1;+                               strncpy(buf, a.name, buf_len);+                               buf[buf_len] = '\0';+                               pthread_setname_np(pthread_self(), buf);+#endif  // GPR_APPLE_PTHREAD_NAME+                             }++                             gpr_mu_lock(&a.thread->mu_);+                             if (!a.thread->started_) {+                               gpr_cv_wait(&a.thread->ready_, &a.thread->mu_,+                                           gpr_inf_future(GPR_CLOCK_MONOTONIC));+                             }+                             gpr_mu_unlock(&a.thread->mu_);++                             (*a.body)(a.arg);+                             dec_thd_count();+                             return nullptr;+                           },+                           a) == 0);++  if (success != nullptr) {+    *success = alive_;+  }++  id_ = gpr_thd_id(p);+  GPR_ASSERT(pthread_attr_destroy(&attr) == 0);++  if (!alive_) {+    /* don't use gpr_free, as this was allocated using malloc (see above) */+    free(a);+    dec_thd_count();+  }+}++Thread::~Thread() {+  if (!alive_) {+    // This thread never existed, so nothing to do+  } else {+    GPR_ASSERT(joined_);+  }+  if (real_) {+    gpr_mu_destroy(&mu_);+    gpr_cv_destroy(&ready_);+  }+}++void Thread::Start() {+  gpr_mu_lock(&mu_);+  if (alive_) {+    started_ = true;+    gpr_cv_signal(&ready_);+  }+  gpr_mu_unlock(&mu_);+}++void Thread::Join() {+  if (alive_) {+    pthread_join(pthread_t(id_), nullptr);+  }+  joined_ = true;+}++void Thread::Init() {+  gpr_mu_init(&g_mu);+  gpr_cv_init(&g_cv);+  g_thread_count = 0;+  g_awaiting_threads = 0;+}++bool Thread::AwaitAll(gpr_timespec deadline) {+  gpr_mu_lock(&g_mu);+  g_awaiting_threads = 1;+  int res = 0;+  if (g_thread_count > 0) {",Not for this one; note that this one has a deadline.,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14459,171094282,2018-02-27T22:52:45Z,src/core/lib/iomgr/ev_poll_posix.cc,"@@ -1439,7 +1446,30 @@ static void cache_destroy_locked(poll_args* args) {     poll_cache.free_pollers = args->next;   } -  gpr_free(args);+  // Now move this args to the dead poller list for later join+  if (poll_cache.dead_pollers != nullptr) {+    poll_cache.dead_pollers->prev = args;+  }+  args->prev = nullptr;+  args->next = poll_cache.dead_pollers;+  poll_cache.dead_pollers = args;+}++static void cache_harvest_locked() {+  while (poll_cache.dead_pollers) {+    poll_args* args = poll_cache.dead_pollers;+    poll_cache.dead_pollers = poll_cache.dead_pollers->next;+    // Keep the list consistent in case new dead pollers get added when we+    // release the lock below to wait on joining+    if (poll_cache.dead_pollers) {+      poll_cache.dead_pollers->prev = nullptr;+    }+    gpr_cv_signal(&args->harvest);+    gpr_cv_wait(&args->join, &g_cvfds.mu, gpr_inf_future(GPR_CLOCK_MONOTONIC));+    args->poller_thd.Join();+    args->poller_thd.~Thread();","So right now we use manual destruction only in cases where we're a member of a struct that is allocated by `gpr_malloc` and released by `gpr_free`. Once these move to a real class allocated by `New` and freed by `Delete`, the actual destructor will just get called.",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/14483,171106439,2018-02-27T23:56:46Z,src/core/tsi/ssl_transport_security.h,"@@ -132,6 +145,7 @@ tsi_result tsi_create_ssl_server_handshaker_factory(     size_t num_key_cert_pairs, const char* pem_client_root_certs,     int force_client_auth, const char* cipher_suites,     const char** alpn_protocols, uint16_t num_alpn_protocols,+    const char* stek_key, size_t stek_key_size,",How about renaming stek_key to session_ticket_key?,
83361,euroelessar,https://api.github.com/repos/grpc/grpc/pulls/14483,171125870,2018-02-28T02:05:11Z,test/core/tsi/ssl_transport_security_test.cc,"@@ -558,6 +581,42 @@ void ssl_tsi_test_do_round_trip_odd_buffer_size() {   } } +void ssl_tsi_test_do_handshake_session_cache() {+  tsi_ssl_session_cache* session_cache = tsi_ssl_session_cache_create_lru(16);++  char stek[48];++  auto do_handshake = [&stek, session_cache](bool session_reused) {+    tsi_test_fixture* fixture = ssl_tsi_test_fixture_create();+    ssl_tsi_test_fixture* ssl_fixture =+        reinterpret_cast<ssl_tsi_test_fixture*>(fixture);+    ssl_fixture->server_name_indication =+        const_cast<char*>(""waterzooi.test.google.be"");+    ssl_fixture->stek = stek;+    ssl_fixture->stek_size = 48;+    ssl_fixture->session_cache = session_cache;+    ssl_fixture->session_reused = session_reused;+    tsi_test_do_round_trip(&ssl_fixture->base);+    tsi_test_fixture_destroy(fixture);+  };+",At this moment tsi test framework re-creates new handshaker factory and handshaker for every round trip and doesn't allow re-usage of factory between handshakes. This means that new session ticket is regenerated every time effectively making ticket caching useless.Should I refactor tsi test framework in this cl to allow re-usage of the same handshaker factory between different handshakes?,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/14556,171452836,2018-03-01T03:06:13Z,test/cpp/end2end/grpclb_end2end_test.cc,"@@ -191,6 +192,13 @@ class BalancerServiceImpl : public BalancerService {         shutdown_(false) {}    Status BalanceLoad(ServerContext* context, Stream* stream) override {+    for (const auto& entry : context->client_metadata()) {","I've verified that the balancer would receive call creds metadata if `grpclb_channel_secure.cc` didn't call `grpc_channel_credentials_duplicate_without_call_credentials`. This is because the [server_auth_filter only removes metadata if the channel creds provide a processor](https://github.com/grpc/grpc/blob/master/src/core/lib/security/transport/server_auth_filter.cc#L169), but the fake credentials don't.I spent quite a bit of time trying to come up with a way to have a negative test, but short of having a mock for `grpclb_channel_secure.cc` that would not remove the call creds, I don't know how to put together a negative test.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/13634,171751268,2018-03-02T02:22:24Z,src/ruby/spec/pb/package_with_underscore/checker_spec.rb,"@@ -0,0 +1,60 @@+# Copyright 2016 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++require 'open3'+require 'tmpdir'++def can_run_codegen_check+  system('which grpc_ruby_plugin') && system('which protoc')+end++describe 'Ping protobuf code generation' do+  if !can_run_codegen_check","I'd like to remove this conditional test run before merging, since as is it looks like this will only be run manually.I suggest editing [build_ruby.sh](https://github.com/grpc/grpc/blob/master/tools/run_tests/helper_scripts/build_ruby.sh#L25) to run something like:```make grpc_ruby_plugin -j8```.... in order to get the protoc and grpc_ruby_plugin executables available for the test.This test can then find `protoc` and `grpc_ruby_plugin` under `bins/{opt,dbg}/protobuf/protoc` and `bins/{opt,dbg}/grpc_ruby_plugin` (the test will want to use those excutables directly).....note that `opt` vs. `dbg` will be set ultimately by the `-c` argument to `tools/run_tests/run_tests.py`, and it should be available in the `CONFIG` environment variable when this test is running.thanks for your work on this so far!",
1803137,connorjacobsen,https://api.github.com/repos/grpc/grpc/pulls/13634,171994376,2018-03-03T00:15:03Z,src/ruby/spec/pb/package_with_underscore/checker_spec.rb,"@@ -0,0 +1,60 @@+# Copyright 2016 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++require 'open3'+require 'tmpdir'++def can_run_codegen_check+  system('which grpc_ruby_plugin') && system('which protoc')+end++describe 'Ping protobuf code generation' do+  if !can_run_codegen_check","Is the protobuf code generation example group from https://github.com/grpc/grpc/blob/master/src/ruby/spec/pb/health/checker_spec.rb a good example to use for this spec?And newb question, how do I ensure that my protos are built ahead of time like the `health_services_pb` service found at https://github.com/grpc/grpc/blob/master/src/ruby/spec/pb/health/checker_spec.rb#39? I'm guessing I have to do a little more work than just adding the `make` line, right?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/13634,171996924,2018-03-03T00:43:12Z,src/ruby/spec/pb/package_with_underscore/checker_spec.rb,"@@ -0,0 +1,60 @@+# Copyright 2016 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++require 'open3'+require 'tmpdir'++def can_run_codegen_check+  system('which grpc_ruby_plugin') && system('which protoc')+end++describe 'Ping protobuf code generation' do+  if !can_run_codegen_check","`make grpc_ruby_plugin` would just build the `protoc` and `grpc_ruby_plugin` binaries from the current state of the repo, and make them available for the test; it wouldn't generate the `_pb.rb` files, if that's what your asking.I suggest then invoking those binaries during the test, to generate `_pb.rb` files ""under test"" with something along the lines of:```bins/{opt,dbg}/protobuf/protoc \    --plugin=protoc-gen-grpc=bins/{opt,dbg}/grpc_ruby_plugin \    --ruby_out=<temp testdir> \    --grpc_out=<temp testdir>    src/proto/grpc/testing/package_with_underscore/service.proto \    src/proto/grpc/testing/package_with_underscore/data.proto```Not sure if that answers your question?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/13634,171999882,2018-03-03T01:21:43Z,src/proto/grpc/testing/package_with_underscore/service.proto,"@@ -0,0 +1,23 @@+// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++syntax = ""proto3"";++package grpc.testing.package_with_underscore.service;++import ""src/proto/grpc/testing/package_with_underscore/data.proto"";++service MyService {+  rpc TestOne(data.Request) returns data.Response {}","nit: `data.Response` needs to be wrapped in paranthesis, <i>I think</i> (if this is this compiling for you I'd be itnerested to know :))",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/14610,172695422,2018-03-06T23:25:50Z,templates/test/cpp/naming/resolver_component_tests_defs.include,"@@ -41,10 +43,10 @@ echo ""Local DNS server started. PID: $DNS_SERVER_PID"" # Health check local DNS server TCP and UDP ports for ((i=0;i<30;i++)); do-  echo ""Retry health-check DNS query to local DNS server over tcp and udp""+  echo ""Retry health-check local DNS server by attempting a DNS query and TCP handshake""   RETRY=0-  dig A health-check-local-dns-server-is-alive.resolver-tests.grpctestingexp. @localhost -p ""$FLAGS_test_dns_server_port"" +tries=1 +timeout=1 | grep '123.123.123.123' || RETRY=1-  dig A health-check-local-dns-server-is-alive.resolver-tests.grpctestingexp. @localhost -p ""$FLAGS_test_dns_server_port"" +tries=1 +timeout=1 +tcp | grep '123.123.123.123' || RETRY=1+  $FLAGS_test_dns_resolver_bin_path -s 127.0.0.1 -p ""$FLAGS_test_dns_server_port"" -n health-check-local-dns-server-is-alive.resolver-tests.grpctestingexp. -t 1 | grep '123.123.123.123' || RETRY=1",Note the test is already broken under ipv6-only as is (https://github.com/grpc/grpc/blob/master/test/cpp/naming/resolver_component_tests_runner.sh#L168),
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/14610,172696038,2018-03-06T23:28:59Z,test/cpp/naming/test_dns_resolver.py,"@@ -0,0 +1,48 @@+#!/usr/bin/env python2.7+# Copyright 2015 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++""""""Makes DNS queries for A records to specified servers""""""++import argparse+import signal+import twisted.internet.task as task+import twisted.names.client as client++def main():+  argp = argparse.ArgumentParser(description='Make DNS queries for A records')+  argp.add_argument('-s', '--server_host', default='127.0.0.1', type=str,+                    help='Host for DNS server to listen on for TCP and UDP.')+  argp.add_argument('-p', '--server_port', default=53, type=int,+                    help='Port that the DNS server is listening on.')+  argp.add_argument('-n', '--qname', default=None, type=str,+                    help=('Name of the record to query for. '))+  argp.add_argument('-t', '--timeout', default=1, type=int,+                    help=('Force process exit after this number of seconds.'))+  args = argp.parse_args()+  signal.alarm(args.timeout)+  def OnResolverResultAvailable(result):+    answers, authority, additional = result+    for a in answers:+      print(a.payload)","My personal argument :)  is that the `test_` prefix in the name of this utility is consistent with `test_` prefix being in the name of the already-existing [test_dns_server](https://github.com/grpc/grpc/blob/master/test/cpp/naming/test_dns_server.py) that's in this directory. I could definitely rename both of those to have e.g, `util` in the name, or be under a `util` directory though. WDYT?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/14605,172761473,2018-03-07T07:46:34Z,templates/src/csharp/Grpc.Core/Internal/NativeMethods.Generated.cs.template,"@@ -0,0 +1,233 @@+%YAML 1.2+--- |+  <%+    native_method_signatures = [+      'void grpcsharp_init()',+      'void grpcsharp_shutdown()',+      'IntPtr grpcsharp_version_string()  // returns not-owned const char*',+      '',+      'BatchContextSafeHandle grpcsharp_batch_context_create()',+      'IntPtr grpcsharp_batch_context_recv_initial_metadata(BatchContextSafeHandle ctx)',+      'IntPtr grpcsharp_batch_context_recv_message_length(BatchContextSafeHandle ctx)',+      'void grpcsharp_batch_context_recv_message_to_buffer(BatchContextSafeHandle ctx, byte[] buffer, UIntPtr bufferLen)',+      'StatusCode grpcsharp_batch_context_recv_status_on_client_status(BatchContextSafeHandle ctx)',+      'IntPtr grpcsharp_batch_context_recv_status_on_client_details(BatchContextSafeHandle ctx, out UIntPtr detailsLength)',+      'IntPtr grpcsharp_batch_context_recv_status_on_client_trailing_metadata(BatchContextSafeHandle ctx)',+      'int grpcsharp_batch_context_recv_close_on_server_cancelled(BatchContextSafeHandle ctx)',+      'void grpcsharp_batch_context_reset(BatchContextSafeHandle ctx)',+      'void grpcsharp_batch_context_destroy(IntPtr ctx)',+      '',+      'RequestCallContextSafeHandle grpcsharp_request_call_context_create()',+      'CallSafeHandle grpcsharp_request_call_context_call(RequestCallContextSafeHandle ctx)',+      'IntPtr grpcsharp_request_call_context_method(RequestCallContextSafeHandle ctx, out UIntPtr methodLength)',+      'IntPtr grpcsharp_request_call_context_host(RequestCallContextSafeHandle ctx, out UIntPtr hostLength)',+      'Timespec grpcsharp_request_call_context_deadline(RequestCallContextSafeHandle ctx)',+      'IntPtr grpcsharp_request_call_context_request_metadata(RequestCallContextSafeHandle ctx)',+      'void grpcsharp_request_call_context_reset(RequestCallContextSafeHandle ctx)',+      'void grpcsharp_request_call_context_destroy(IntPtr ctx)',+      '',+      'CallCredentialsSafeHandle grpcsharp_composite_call_credentials_create(CallCredentialsSafeHandle creds1, CallCredentialsSafeHandle creds2)',+      'void grpcsharp_call_credentials_release(IntPtr credentials)',+      '',+      'CallError grpcsharp_call_cancel(CallSafeHandle call)',+      'CallError grpcsharp_call_cancel_with_status(CallSafeHandle call, StatusCode status, string description)',+      'CallError grpcsharp_call_start_unary(CallSafeHandle call, BatchContextSafeHandle ctx, byte[] sendBuffer, UIntPtr sendBufferLen, WriteFlags writeFlags, MetadataArraySafeHandle metadataArray, CallFlags metadataFlags)',+      'CallError grpcsharp_call_start_client_streaming(CallSafeHandle call, BatchContextSafeHandle ctx, MetadataArraySafeHandle metadataArray, CallFlags metadataFlags)',+      'CallError grpcsharp_call_start_server_streaming(CallSafeHandle call, BatchContextSafeHandle ctx, byte[] sendBuffer, UIntPtr sendBufferLen, WriteFlags writeFlags, MetadataArraySafeHandle metadataArray, CallFlags metadataFlags)',+      'CallError grpcsharp_call_start_duplex_streaming(CallSafeHandle call, BatchContextSafeHandle ctx, MetadataArraySafeHandle metadataArray, CallFlags metadataFlags)',+      'CallError grpcsharp_call_send_message(CallSafeHandle call, BatchContextSafeHandle ctx, byte[] sendBuffer, UIntPtr sendBufferLen, WriteFlags writeFlags, int sendEmptyInitialMetadata)',+      'CallError grpcsharp_call_send_close_from_client(CallSafeHandle call, BatchContextSafeHandle ctx)',+      'CallError grpcsharp_call_send_status_from_server(CallSafeHandle call, BatchContextSafeHandle ctx, StatusCode statusCode, byte[] statusMessage, UIntPtr statusMessageLen, MetadataArraySafeHandle metadataArray, int sendEmptyInitialMetadata, byte[] optionalSendBuffer, UIntPtr optionalSendBufferLen, WriteFlags writeFlags)',+      'CallError grpcsharp_call_recv_message(CallSafeHandle call, BatchContextSafeHandle ctx)',+      'CallError grpcsharp_call_recv_initial_metadata(CallSafeHandle call, BatchContextSafeHandle ctx)',+      'CallError grpcsharp_call_start_serverside(CallSafeHandle call, BatchContextSafeHandle ctx)',+      'CallError grpcsharp_call_send_initial_metadata(CallSafeHandle call, BatchContextSafeHandle ctx, MetadataArraySafeHandle metadataArray)',+      'CallError grpcsharp_call_set_credentials(CallSafeHandle call, CallCredentialsSafeHandle credentials)',+      'CStringSafeHandle grpcsharp_call_get_peer(CallSafeHandle call)',+      'void grpcsharp_call_destroy(IntPtr call)',+      '',+      'ChannelArgsSafeHandle grpcsharp_channel_args_create(UIntPtr numArgs)',+      'void grpcsharp_channel_args_set_string(ChannelArgsSafeHandle args, UIntPtr index, string key, string value)',+      'void grpcsharp_channel_args_set_integer(ChannelArgsSafeHandle args, UIntPtr index, string key, int value)',+      'void grpcsharp_channel_args_destroy(IntPtr args)',+      '',+      'void grpcsharp_override_default_ssl_roots(string pemRootCerts)',+      'ChannelCredentialsSafeHandle grpcsharp_ssl_credentials_create(string pemRootCerts, string keyCertPairCertChain, string keyCertPairPrivateKey)',+      'ChannelCredentialsSafeHandle grpcsharp_composite_channel_credentials_create(ChannelCredentialsSafeHandle channelCreds, CallCredentialsSafeHandle callCreds)',+      'void grpcsharp_channel_credentials_release(IntPtr credentials)',+      '',+      'ChannelSafeHandle grpcsharp_insecure_channel_create(string target, ChannelArgsSafeHandle channelArgs)',+      'ChannelSafeHandle grpcsharp_secure_channel_create(ChannelCredentialsSafeHandle credentials, string target, ChannelArgsSafeHandle channelArgs)',+      'CallSafeHandle grpcsharp_channel_create_call(ChannelSafeHandle channel, CallSafeHandle parentCall, ContextPropagationFlags propagationMask, CompletionQueueSafeHandle cq, string method, string host, Timespec deadline)',+      'ChannelState grpcsharp_channel_check_connectivity_state(ChannelSafeHandle channel, int tryToConnect)',+      'void grpcsharp_channel_watch_connectivity_state(ChannelSafeHandle channel, ChannelState lastObservedState, Timespec deadline, CompletionQueueSafeHandle cq, BatchContextSafeHandle ctx)',+      'CStringSafeHandle grpcsharp_channel_get_target(ChannelSafeHandle call)',+      'void grpcsharp_channel_destroy(IntPtr channel)',+      '',+      'int grpcsharp_sizeof_grpc_event()',+      '',+      'CompletionQueueSafeHandle grpcsharp_completion_queue_create_async()',+      'CompletionQueueSafeHandle grpcsharp_completion_queue_create_sync()',+      'void grpcsharp_completion_queue_shutdown(CompletionQueueSafeHandle cq)',+      'CompletionQueueEvent grpcsharp_completion_queue_next(CompletionQueueSafeHandle cq)',+      'CompletionQueueEvent grpcsharp_completion_queue_pluck(CompletionQueueSafeHandle cq, IntPtr tag)',+      'void grpcsharp_completion_queue_destroy(IntPtr cq)',+      '',+      'void gprsharp_free(IntPtr ptr)',+      '',+      'MetadataArraySafeHandle grpcsharp_metadata_array_create(UIntPtr capacity)',+      'void grpcsharp_metadata_array_add(MetadataArraySafeHandle array, string key, byte[] value, UIntPtr valueLength)',+      'UIntPtr grpcsharp_metadata_array_count(IntPtr metadataArray)',+      'IntPtr grpcsharp_metadata_array_get_key(IntPtr metadataArray, UIntPtr index, out UIntPtr keyLength)',+      'IntPtr grpcsharp_metadata_array_get_value(IntPtr metadataArray, UIntPtr index, out UIntPtr valueLength)',+      'void grpcsharp_metadata_array_destroy_full(IntPtr array)',+      '',+      'void grpcsharp_redirect_log(GprLogDelegate callback)',+      '',+      'CallCredentialsSafeHandle grpcsharp_metadata_credentials_create_from_plugin(NativeMetadataInterceptor interceptor)',+      'void grpcsharp_metadata_credentials_notify_from_plugin(IntPtr callbackPtr, IntPtr userData, MetadataArraySafeHandle metadataArray, StatusCode statusCode, string errorDetails)',+      '',+      'ServerCredentialsSafeHandle grpcsharp_ssl_server_credentials_create(string pemRootCerts, string[] keyCertPairCertChainArray, string[] keyCertPairPrivateKeyArray, UIntPtr numKeyCertPairs, int forceClientAuth)',+      'void grpcsharp_server_credentials_release(IntPtr credentials)',+      '',+      'ServerSafeHandle grpcsharp_server_create(ChannelArgsSafeHandle args)',+      'void grpcsharp_server_register_completion_queue(ServerSafeHandle server, CompletionQueueSafeHandle cq)',+      'int grpcsharp_server_add_insecure_http2_port(ServerSafeHandle server, string addr)',+      'int grpcsharp_server_add_secure_http2_port(ServerSafeHandle server, string addr, ServerCredentialsSafeHandle creds)',+      'void grpcsharp_server_start(ServerSafeHandle server)',+      'CallError grpcsharp_server_request_call(ServerSafeHandle server, CompletionQueueSafeHandle cq, RequestCallContextSafeHandle ctx)',+      'void grpcsharp_server_cancel_all_calls(ServerSafeHandle server)',+      'void grpcsharp_server_shutdown_and_notify_callback(ServerSafeHandle server, CompletionQueueSafeHandle cq, BatchContextSafeHandle ctx)',+      'void grpcsharp_server_destroy(IntPtr server)',+      '',+      'AuthContextSafeHandle grpcsharp_call_auth_context(CallSafeHandle call)',+      'IntPtr grpcsharp_auth_context_peer_identity_property_name(AuthContextSafeHandle authContext)  // returns const char*',+      'AuthContextSafeHandle.NativeAuthPropertyIterator grpcsharp_auth_context_property_iterator(AuthContextSafeHandle authContext)',+      'IntPtr grpcsharp_auth_property_iterator_next(ref AuthContextSafeHandle.NativeAuthPropertyIterator iterator)  // returns const auth_property*',+      'void grpcsharp_auth_context_release(IntPtr authContext)',+      '',+      'Timespec gprsharp_now(ClockType clockType)',+      'Timespec gprsharp_inf_future(ClockType clockType)',+      'Timespec gprsharp_inf_past(ClockType clockType)',+      '',+      'Timespec gprsharp_convert_clock_type(Timespec t, ClockType targetClock)',+      'int gprsharp_sizeof_timespec()',+      '',+      'CallError grpcsharp_test_callback([MarshalAs(UnmanagedType.FunctionPtr)] NativeCallbackTestDelegate callback)',+      'IntPtr grpcsharp_test_nop(IntPtr ptr)',+      'void grpcsharp_test_override_method(string methodName, string variant)',+    ]+    +    import re+    native_methods = []+    for signature in native_method_signatures:+      if not signature:",nit: what's the purpose of the empty strings in that list? Can this logic be removed?,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/14605,172765313,2018-03-07T08:10:47Z,templates/src/csharp/Grpc.Core/Internal/NativeMethods.Generated.cs.template,"@@ -0,0 +1,233 @@+%YAML 1.2+--- |+  <%+    native_method_signatures = [+      'void grpcsharp_init()',+      'void grpcsharp_shutdown()',+      'IntPtr grpcsharp_version_string()  // returns not-owned const char*',+      '',+      'BatchContextSafeHandle grpcsharp_batch_context_create()',+      'IntPtr grpcsharp_batch_context_recv_initial_metadata(BatchContextSafeHandle ctx)',+      'IntPtr grpcsharp_batch_context_recv_message_length(BatchContextSafeHandle ctx)',+      'void grpcsharp_batch_context_recv_message_to_buffer(BatchContextSafeHandle ctx, byte[] buffer, UIntPtr bufferLen)',+      'StatusCode grpcsharp_batch_context_recv_status_on_client_status(BatchContextSafeHandle ctx)',+      'IntPtr grpcsharp_batch_context_recv_status_on_client_details(BatchContextSafeHandle ctx, out UIntPtr detailsLength)',+      'IntPtr grpcsharp_batch_context_recv_status_on_client_trailing_metadata(BatchContextSafeHandle ctx)',+      'int grpcsharp_batch_context_recv_close_on_server_cancelled(BatchContextSafeHandle ctx)',+      'void grpcsharp_batch_context_reset(BatchContextSafeHandle ctx)',+      'void grpcsharp_batch_context_destroy(IntPtr ctx)',+      '',+      'RequestCallContextSafeHandle grpcsharp_request_call_context_create()',+      'CallSafeHandle grpcsharp_request_call_context_call(RequestCallContextSafeHandle ctx)',+      'IntPtr grpcsharp_request_call_context_method(RequestCallContextSafeHandle ctx, out UIntPtr methodLength)',+      'IntPtr grpcsharp_request_call_context_host(RequestCallContextSafeHandle ctx, out UIntPtr hostLength)',+      'Timespec grpcsharp_request_call_context_deadline(RequestCallContextSafeHandle ctx)',+      'IntPtr grpcsharp_request_call_context_request_metadata(RequestCallContextSafeHandle ctx)',+      'void grpcsharp_request_call_context_reset(RequestCallContextSafeHandle ctx)',+      'void grpcsharp_request_call_context_destroy(IntPtr ctx)',+      '',+      'CallCredentialsSafeHandle grpcsharp_composite_call_credentials_create(CallCredentialsSafeHandle creds1, CallCredentialsSafeHandle creds2)',+      'void grpcsharp_call_credentials_release(IntPtr credentials)',+      '',+      'CallError grpcsharp_call_cancel(CallSafeHandle call)',+      'CallError grpcsharp_call_cancel_with_status(CallSafeHandle call, StatusCode status, string description)',+      'CallError grpcsharp_call_start_unary(CallSafeHandle call, BatchContextSafeHandle ctx, byte[] sendBuffer, UIntPtr sendBufferLen, WriteFlags writeFlags, MetadataArraySafeHandle metadataArray, CallFlags metadataFlags)',+      'CallError grpcsharp_call_start_client_streaming(CallSafeHandle call, BatchContextSafeHandle ctx, MetadataArraySafeHandle metadataArray, CallFlags metadataFlags)',+      'CallError grpcsharp_call_start_server_streaming(CallSafeHandle call, BatchContextSafeHandle ctx, byte[] sendBuffer, UIntPtr sendBufferLen, WriteFlags writeFlags, MetadataArraySafeHandle metadataArray, CallFlags metadataFlags)',+      'CallError grpcsharp_call_start_duplex_streaming(CallSafeHandle call, BatchContextSafeHandle ctx, MetadataArraySafeHandle metadataArray, CallFlags metadataFlags)',+      'CallError grpcsharp_call_send_message(CallSafeHandle call, BatchContextSafeHandle ctx, byte[] sendBuffer, UIntPtr sendBufferLen, WriteFlags writeFlags, int sendEmptyInitialMetadata)',+      'CallError grpcsharp_call_send_close_from_client(CallSafeHandle call, BatchContextSafeHandle ctx)',+      'CallError grpcsharp_call_send_status_from_server(CallSafeHandle call, BatchContextSafeHandle ctx, StatusCode statusCode, byte[] statusMessage, UIntPtr statusMessageLen, MetadataArraySafeHandle metadataArray, int sendEmptyInitialMetadata, byte[] optionalSendBuffer, UIntPtr optionalSendBufferLen, WriteFlags writeFlags)',+      'CallError grpcsharp_call_recv_message(CallSafeHandle call, BatchContextSafeHandle ctx)',+      'CallError grpcsharp_call_recv_initial_metadata(CallSafeHandle call, BatchContextSafeHandle ctx)',+      'CallError grpcsharp_call_start_serverside(CallSafeHandle call, BatchContextSafeHandle ctx)',+      'CallError grpcsharp_call_send_initial_metadata(CallSafeHandle call, BatchContextSafeHandle ctx, MetadataArraySafeHandle metadataArray)',+      'CallError grpcsharp_call_set_credentials(CallSafeHandle call, CallCredentialsSafeHandle credentials)',+      'CStringSafeHandle grpcsharp_call_get_peer(CallSafeHandle call)',+      'void grpcsharp_call_destroy(IntPtr call)',+      '',+      'ChannelArgsSafeHandle grpcsharp_channel_args_create(UIntPtr numArgs)',+      'void grpcsharp_channel_args_set_string(ChannelArgsSafeHandle args, UIntPtr index, string key, string value)',+      'void grpcsharp_channel_args_set_integer(ChannelArgsSafeHandle args, UIntPtr index, string key, int value)',+      'void grpcsharp_channel_args_destroy(IntPtr args)',+      '',+      'void grpcsharp_override_default_ssl_roots(string pemRootCerts)',+      'ChannelCredentialsSafeHandle grpcsharp_ssl_credentials_create(string pemRootCerts, string keyCertPairCertChain, string keyCertPairPrivateKey)',+      'ChannelCredentialsSafeHandle grpcsharp_composite_channel_credentials_create(ChannelCredentialsSafeHandle channelCreds, CallCredentialsSafeHandle callCreds)',+      'void grpcsharp_channel_credentials_release(IntPtr credentials)',+      '',+      'ChannelSafeHandle grpcsharp_insecure_channel_create(string target, ChannelArgsSafeHandle channelArgs)',+      'ChannelSafeHandle grpcsharp_secure_channel_create(ChannelCredentialsSafeHandle credentials, string target, ChannelArgsSafeHandle channelArgs)',+      'CallSafeHandle grpcsharp_channel_create_call(ChannelSafeHandle channel, CallSafeHandle parentCall, ContextPropagationFlags propagationMask, CompletionQueueSafeHandle cq, string method, string host, Timespec deadline)',+      'ChannelState grpcsharp_channel_check_connectivity_state(ChannelSafeHandle channel, int tryToConnect)',+      'void grpcsharp_channel_watch_connectivity_state(ChannelSafeHandle channel, ChannelState lastObservedState, Timespec deadline, CompletionQueueSafeHandle cq, BatchContextSafeHandle ctx)',+      'CStringSafeHandle grpcsharp_channel_get_target(ChannelSafeHandle call)',+      'void grpcsharp_channel_destroy(IntPtr channel)',+      '',+      'int grpcsharp_sizeof_grpc_event()',+      '',+      'CompletionQueueSafeHandle grpcsharp_completion_queue_create_async()',+      'CompletionQueueSafeHandle grpcsharp_completion_queue_create_sync()',+      'void grpcsharp_completion_queue_shutdown(CompletionQueueSafeHandle cq)',+      'CompletionQueueEvent grpcsharp_completion_queue_next(CompletionQueueSafeHandle cq)',+      'CompletionQueueEvent grpcsharp_completion_queue_pluck(CompletionQueueSafeHandle cq, IntPtr tag)',+      'void grpcsharp_completion_queue_destroy(IntPtr cq)',+      '',+      'void gprsharp_free(IntPtr ptr)',+      '',+      'MetadataArraySafeHandle grpcsharp_metadata_array_create(UIntPtr capacity)',+      'void grpcsharp_metadata_array_add(MetadataArraySafeHandle array, string key, byte[] value, UIntPtr valueLength)',+      'UIntPtr grpcsharp_metadata_array_count(IntPtr metadataArray)',+      'IntPtr grpcsharp_metadata_array_get_key(IntPtr metadataArray, UIntPtr index, out UIntPtr keyLength)',+      'IntPtr grpcsharp_metadata_array_get_value(IntPtr metadataArray, UIntPtr index, out UIntPtr valueLength)',+      'void grpcsharp_metadata_array_destroy_full(IntPtr array)',+      '',+      'void grpcsharp_redirect_log(GprLogDelegate callback)',+      '',+      'CallCredentialsSafeHandle grpcsharp_metadata_credentials_create_from_plugin(NativeMetadataInterceptor interceptor)',+      'void grpcsharp_metadata_credentials_notify_from_plugin(IntPtr callbackPtr, IntPtr userData, MetadataArraySafeHandle metadataArray, StatusCode statusCode, string errorDetails)',+      '',+      'ServerCredentialsSafeHandle grpcsharp_ssl_server_credentials_create(string pemRootCerts, string[] keyCertPairCertChainArray, string[] keyCertPairPrivateKeyArray, UIntPtr numKeyCertPairs, int forceClientAuth)',+      'void grpcsharp_server_credentials_release(IntPtr credentials)',+      '',+      'ServerSafeHandle grpcsharp_server_create(ChannelArgsSafeHandle args)',+      'void grpcsharp_server_register_completion_queue(ServerSafeHandle server, CompletionQueueSafeHandle cq)',+      'int grpcsharp_server_add_insecure_http2_port(ServerSafeHandle server, string addr)',+      'int grpcsharp_server_add_secure_http2_port(ServerSafeHandle server, string addr, ServerCredentialsSafeHandle creds)',+      'void grpcsharp_server_start(ServerSafeHandle server)',+      'CallError grpcsharp_server_request_call(ServerSafeHandle server, CompletionQueueSafeHandle cq, RequestCallContextSafeHandle ctx)',+      'void grpcsharp_server_cancel_all_calls(ServerSafeHandle server)',+      'void grpcsharp_server_shutdown_and_notify_callback(ServerSafeHandle server, CompletionQueueSafeHandle cq, BatchContextSafeHandle ctx)',+      'void grpcsharp_server_destroy(IntPtr server)',+      '',+      'AuthContextSafeHandle grpcsharp_call_auth_context(CallSafeHandle call)',+      'IntPtr grpcsharp_auth_context_peer_identity_property_name(AuthContextSafeHandle authContext)  // returns const char*',+      'AuthContextSafeHandle.NativeAuthPropertyIterator grpcsharp_auth_context_property_iterator(AuthContextSafeHandle authContext)',+      'IntPtr grpcsharp_auth_property_iterator_next(ref AuthContextSafeHandle.NativeAuthPropertyIterator iterator)  // returns const auth_property*',+      'void grpcsharp_auth_context_release(IntPtr authContext)',+      '',+      'Timespec gprsharp_now(ClockType clockType)',+      'Timespec gprsharp_inf_future(ClockType clockType)',+      'Timespec gprsharp_inf_past(ClockType clockType)',+      '',+      'Timespec gprsharp_convert_clock_type(Timespec t, ClockType targetClock)',+      'int gprsharp_sizeof_timespec()',+      '',+      'CallError grpcsharp_test_callback([MarshalAs(UnmanagedType.FunctionPtr)] NativeCallbackTestDelegate callback)',+      'IntPtr grpcsharp_test_nop(IntPtr ptr)',+      'void grpcsharp_test_override_method(string methodName, string variant)',+    ]+    +    import re+    native_methods = []+    for signature in native_method_signatures:+      if not signature:+        continue+      match = re.match('([^ ]+) +([A-Za-z0-9_]+)\\((.*)\\)(.*)', signature)+      native_methods.append({'name': match.group(2), 'returntype': match.group(1), 'params': match.group(3), 'comment': match.group(4)})+    +  +    #native_methods = [+    #  {'name': 'grpcsharp_init', 'returntype': 'void', 'params': ''},+    #  {'name': 'grpcsharp_server_request_call', 'returntype': 'CallError', 'params': 'ServerSafeHandle server, CompletionQueueSafeHandle cq, RequestCallContextSafeHandle ctx'},+    #]+  %>+  #region Copyright notice and license+  +  // Copyright 2015 gRPC authors.+  //+  // Licensed under the Apache License, Version 2.0 (the ""License"");+  // you may not use this file except in compliance with the License.+  // You may obtain a copy of the License at+  //+  //     http://www.apache.org/licenses/LICENSE-2.0+  //+  // Unless required by applicable law or agreed to in writing, software+  // distributed under the License is distributed on an ""AS IS"" BASIS,+  // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+  // See the License for the specific language governing permissions and+  // limitations under the License.+  +  #endregion+  +  using System;+  using System.Collections.Concurrent;+  using System.Diagnostics;+  using System.IO;+  using System.Reflection;+  using System.Runtime.InteropServices;+  using System.Threading;+  +  using Grpc.Core.Logging;+  using Grpc.Core.Utils;+  +  namespace Grpc.Core.Internal+  {+      internal partial class NativeMethods+      {+          #region Native methods+          +          % for method in native_methods:+          public readonly Delegates.${method['name']}_delegate ${method['name']};+          % endfor++          #endregion+  +          public NativeMethods(UnmanagedLibrary library)+          {+              % for method in native_methods:+              this.${method['name']} = GetMethodDelegate<Delegates.${method['name']}_delegate>(library);+              % endfor+          }+          +          public NativeMethods(DllImportsFromStaticLib unusedInstance)","nit: can we use different method names to differentiate the different types of `NativeMethod` instantion, rather than differing signatures? Perhaps use a some sort of `NativeMethod` factory?",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/14605,172905202,2018-03-07T16:39:59Z,templates/src/csharp/Grpc.Core/Internal/NativeMethods.Generated.cs.template,"@@ -0,0 +1,233 @@+%YAML 1.2+--- |+  <%+    native_method_signatures = [+      'void grpcsharp_init()',","Yes, that would be nice but would require some extra logic that could end up being quite complex (as the mapping of signatures in not always straightforward). One day I might add this, but for now leaving as is because this change is not removing any preexisting check.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/14605,172906136,2018-03-07T16:42:57Z,templates/src/csharp/Grpc.Core/Internal/NativeMethods.Generated.cs.template,"@@ -0,0 +1,233 @@+%YAML 1.2+--- |+  <%+    native_method_signatures = [+      'void grpcsharp_init()',+      'void grpcsharp_shutdown()',+      'IntPtr grpcsharp_version_string()  // returns not-owned const char*',+      '',+      'BatchContextSafeHandle grpcsharp_batch_context_create()',+      'IntPtr grpcsharp_batch_context_recv_initial_metadata(BatchContextSafeHandle ctx)',+      'IntPtr grpcsharp_batch_context_recv_message_length(BatchContextSafeHandle ctx)',+      'void grpcsharp_batch_context_recv_message_to_buffer(BatchContextSafeHandle ctx, byte[] buffer, UIntPtr bufferLen)',+      'StatusCode grpcsharp_batch_context_recv_status_on_client_status(BatchContextSafeHandle ctx)',+      'IntPtr grpcsharp_batch_context_recv_status_on_client_details(BatchContextSafeHandle ctx, out UIntPtr detailsLength)',+      'IntPtr grpcsharp_batch_context_recv_status_on_client_trailing_metadata(BatchContextSafeHandle ctx)',+      'int grpcsharp_batch_context_recv_close_on_server_cancelled(BatchContextSafeHandle ctx)',+      'void grpcsharp_batch_context_reset(BatchContextSafeHandle ctx)',+      'void grpcsharp_batch_context_destroy(IntPtr ctx)',+      '',+      'RequestCallContextSafeHandle grpcsharp_request_call_context_create()',+      'CallSafeHandle grpcsharp_request_call_context_call(RequestCallContextSafeHandle ctx)',+      'IntPtr grpcsharp_request_call_context_method(RequestCallContextSafeHandle ctx, out UIntPtr methodLength)',+      'IntPtr grpcsharp_request_call_context_host(RequestCallContextSafeHandle ctx, out UIntPtr hostLength)',+      'Timespec grpcsharp_request_call_context_deadline(RequestCallContextSafeHandle ctx)',+      'IntPtr grpcsharp_request_call_context_request_metadata(RequestCallContextSafeHandle ctx)',+      'void grpcsharp_request_call_context_reset(RequestCallContextSafeHandle ctx)',+      'void grpcsharp_request_call_context_destroy(IntPtr ctx)',+      '',+      'CallCredentialsSafeHandle grpcsharp_composite_call_credentials_create(CallCredentialsSafeHandle creds1, CallCredentialsSafeHandle creds2)',+      'void grpcsharp_call_credentials_release(IntPtr credentials)',+      '',+      'CallError grpcsharp_call_cancel(CallSafeHandle call)',+      'CallError grpcsharp_call_cancel_with_status(CallSafeHandle call, StatusCode status, string description)',+      'CallError grpcsharp_call_start_unary(CallSafeHandle call, BatchContextSafeHandle ctx, byte[] sendBuffer, UIntPtr sendBufferLen, WriteFlags writeFlags, MetadataArraySafeHandle metadataArray, CallFlags metadataFlags)',+      'CallError grpcsharp_call_start_client_streaming(CallSafeHandle call, BatchContextSafeHandle ctx, MetadataArraySafeHandle metadataArray, CallFlags metadataFlags)',+      'CallError grpcsharp_call_start_server_streaming(CallSafeHandle call, BatchContextSafeHandle ctx, byte[] sendBuffer, UIntPtr sendBufferLen, WriteFlags writeFlags, MetadataArraySafeHandle metadataArray, CallFlags metadataFlags)',+      'CallError grpcsharp_call_start_duplex_streaming(CallSafeHandle call, BatchContextSafeHandle ctx, MetadataArraySafeHandle metadataArray, CallFlags metadataFlags)',+      'CallError grpcsharp_call_send_message(CallSafeHandle call, BatchContextSafeHandle ctx, byte[] sendBuffer, UIntPtr sendBufferLen, WriteFlags writeFlags, int sendEmptyInitialMetadata)',+      'CallError grpcsharp_call_send_close_from_client(CallSafeHandle call, BatchContextSafeHandle ctx)',+      'CallError grpcsharp_call_send_status_from_server(CallSafeHandle call, BatchContextSafeHandle ctx, StatusCode statusCode, byte[] statusMessage, UIntPtr statusMessageLen, MetadataArraySafeHandle metadataArray, int sendEmptyInitialMetadata, byte[] optionalSendBuffer, UIntPtr optionalSendBufferLen, WriteFlags writeFlags)',+      'CallError grpcsharp_call_recv_message(CallSafeHandle call, BatchContextSafeHandle ctx)',+      'CallError grpcsharp_call_recv_initial_metadata(CallSafeHandle call, BatchContextSafeHandle ctx)',+      'CallError grpcsharp_call_start_serverside(CallSafeHandle call, BatchContextSafeHandle ctx)',+      'CallError grpcsharp_call_send_initial_metadata(CallSafeHandle call, BatchContextSafeHandle ctx, MetadataArraySafeHandle metadataArray)',+      'CallError grpcsharp_call_set_credentials(CallSafeHandle call, CallCredentialsSafeHandle credentials)',+      'CStringSafeHandle grpcsharp_call_get_peer(CallSafeHandle call)',+      'void grpcsharp_call_destroy(IntPtr call)',+      '',+      'ChannelArgsSafeHandle grpcsharp_channel_args_create(UIntPtr numArgs)',+      'void grpcsharp_channel_args_set_string(ChannelArgsSafeHandle args, UIntPtr index, string key, string value)',+      'void grpcsharp_channel_args_set_integer(ChannelArgsSafeHandle args, UIntPtr index, string key, int value)',+      'void grpcsharp_channel_args_destroy(IntPtr args)',+      '',+      'void grpcsharp_override_default_ssl_roots(string pemRootCerts)',+      'ChannelCredentialsSafeHandle grpcsharp_ssl_credentials_create(string pemRootCerts, string keyCertPairCertChain, string keyCertPairPrivateKey)',+      'ChannelCredentialsSafeHandle grpcsharp_composite_channel_credentials_create(ChannelCredentialsSafeHandle channelCreds, CallCredentialsSafeHandle callCreds)',+      'void grpcsharp_channel_credentials_release(IntPtr credentials)',+      '',+      'ChannelSafeHandle grpcsharp_insecure_channel_create(string target, ChannelArgsSafeHandle channelArgs)',+      'ChannelSafeHandle grpcsharp_secure_channel_create(ChannelCredentialsSafeHandle credentials, string target, ChannelArgsSafeHandle channelArgs)',+      'CallSafeHandle grpcsharp_channel_create_call(ChannelSafeHandle channel, CallSafeHandle parentCall, ContextPropagationFlags propagationMask, CompletionQueueSafeHandle cq, string method, string host, Timespec deadline)',+      'ChannelState grpcsharp_channel_check_connectivity_state(ChannelSafeHandle channel, int tryToConnect)',+      'void grpcsharp_channel_watch_connectivity_state(ChannelSafeHandle channel, ChannelState lastObservedState, Timespec deadline, CompletionQueueSafeHandle cq, BatchContextSafeHandle ctx)',+      'CStringSafeHandle grpcsharp_channel_get_target(ChannelSafeHandle call)',+      'void grpcsharp_channel_destroy(IntPtr channel)',+      '',+      'int grpcsharp_sizeof_grpc_event()',+      '',+      'CompletionQueueSafeHandle grpcsharp_completion_queue_create_async()',+      'CompletionQueueSafeHandle grpcsharp_completion_queue_create_sync()',+      'void grpcsharp_completion_queue_shutdown(CompletionQueueSafeHandle cq)',+      'CompletionQueueEvent grpcsharp_completion_queue_next(CompletionQueueSafeHandle cq)',+      'CompletionQueueEvent grpcsharp_completion_queue_pluck(CompletionQueueSafeHandle cq, IntPtr tag)',+      'void grpcsharp_completion_queue_destroy(IntPtr cq)',+      '',+      'void gprsharp_free(IntPtr ptr)',+      '',+      'MetadataArraySafeHandle grpcsharp_metadata_array_create(UIntPtr capacity)',+      'void grpcsharp_metadata_array_add(MetadataArraySafeHandle array, string key, byte[] value, UIntPtr valueLength)',+      'UIntPtr grpcsharp_metadata_array_count(IntPtr metadataArray)',+      'IntPtr grpcsharp_metadata_array_get_key(IntPtr metadataArray, UIntPtr index, out UIntPtr keyLength)',+      'IntPtr grpcsharp_metadata_array_get_value(IntPtr metadataArray, UIntPtr index, out UIntPtr valueLength)',+      'void grpcsharp_metadata_array_destroy_full(IntPtr array)',+      '',+      'void grpcsharp_redirect_log(GprLogDelegate callback)',+      '',+      'CallCredentialsSafeHandle grpcsharp_metadata_credentials_create_from_plugin(NativeMetadataInterceptor interceptor)',+      'void grpcsharp_metadata_credentials_notify_from_plugin(IntPtr callbackPtr, IntPtr userData, MetadataArraySafeHandle metadataArray, StatusCode statusCode, string errorDetails)',+      '',+      'ServerCredentialsSafeHandle grpcsharp_ssl_server_credentials_create(string pemRootCerts, string[] keyCertPairCertChainArray, string[] keyCertPairPrivateKeyArray, UIntPtr numKeyCertPairs, int forceClientAuth)',+      'void grpcsharp_server_credentials_release(IntPtr credentials)',+      '',+      'ServerSafeHandle grpcsharp_server_create(ChannelArgsSafeHandle args)',+      'void grpcsharp_server_register_completion_queue(ServerSafeHandle server, CompletionQueueSafeHandle cq)',+      'int grpcsharp_server_add_insecure_http2_port(ServerSafeHandle server, string addr)',+      'int grpcsharp_server_add_secure_http2_port(ServerSafeHandle server, string addr, ServerCredentialsSafeHandle creds)',+      'void grpcsharp_server_start(ServerSafeHandle server)',+      'CallError grpcsharp_server_request_call(ServerSafeHandle server, CompletionQueueSafeHandle cq, RequestCallContextSafeHandle ctx)',+      'void grpcsharp_server_cancel_all_calls(ServerSafeHandle server)',+      'void grpcsharp_server_shutdown_and_notify_callback(ServerSafeHandle server, CompletionQueueSafeHandle cq, BatchContextSafeHandle ctx)',+      'void grpcsharp_server_destroy(IntPtr server)',+      '',+      'AuthContextSafeHandle grpcsharp_call_auth_context(CallSafeHandle call)',+      'IntPtr grpcsharp_auth_context_peer_identity_property_name(AuthContextSafeHandle authContext)  // returns const char*',+      'AuthContextSafeHandle.NativeAuthPropertyIterator grpcsharp_auth_context_property_iterator(AuthContextSafeHandle authContext)',+      'IntPtr grpcsharp_auth_property_iterator_next(ref AuthContextSafeHandle.NativeAuthPropertyIterator iterator)  // returns const auth_property*',+      'void grpcsharp_auth_context_release(IntPtr authContext)',+      '',+      'Timespec gprsharp_now(ClockType clockType)',+      'Timespec gprsharp_inf_future(ClockType clockType)',+      'Timespec gprsharp_inf_past(ClockType clockType)',+      '',+      'Timespec gprsharp_convert_clock_type(Timespec t, ClockType targetClock)',+      'int gprsharp_sizeof_timespec()',+      '',+      'CallError grpcsharp_test_callback([MarshalAs(UnmanagedType.FunctionPtr)] NativeCallbackTestDelegate callback)',+      'IntPtr grpcsharp_test_nop(IntPtr ptr)',+      'void grpcsharp_test_override_method(string methodName, string variant)',+    ]+    +    import re+    native_methods = []+    for signature in native_method_signatures:+      if not signature:+        continue+      match = re.match('([^ ]+) +([A-Za-z0-9_]+)\\((.*)\\)(.*)', signature)+      native_methods.append({'name': match.group(2), 'returntype': match.group(1), 'params': match.group(3), 'comment': match.group(4)})+    +  +    #native_methods = [+    #  {'name': 'grpcsharp_init', 'returntype': 'void', 'params': ''},+    #  {'name': 'grpcsharp_server_request_call', 'returntype': 'CallError', 'params': 'ServerSafeHandle server, CompletionQueueSafeHandle cq, RequestCallContextSafeHandle ctx'},+    #]+  %>+  #region Copyright notice and license+  +  // Copyright 2015 gRPC authors.+  //+  // Licensed under the Apache License, Version 2.0 (the ""License"");+  // you may not use this file except in compliance with the License.+  // You may obtain a copy of the License at+  //+  //     http://www.apache.org/licenses/LICENSE-2.0+  //+  // Unless required by applicable law or agreed to in writing, software+  // distributed under the License is distributed on an ""AS IS"" BASIS,+  // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+  // See the License for the specific language governing permissions and+  // limitations under the License.+  +  #endregion+  +  using System;+  using System.Collections.Concurrent;+  using System.Diagnostics;+  using System.IO;+  using System.Reflection;+  using System.Runtime.InteropServices;+  using System.Threading;+  +  using Grpc.Core.Logging;+  using Grpc.Core.Utils;+  +  namespace Grpc.Core.Internal+  {+      internal partial class NativeMethods+      {+          #region Native methods+          +          % for method in native_methods:+          public readonly Delegates.${method['name']}_delegate ${method['name']};+          % endfor++          #endregion+  +          public NativeMethods(UnmanagedLibrary library)+          {+              % for method in native_methods:+              this.${method['name']} = GetMethodDelegate<Delegates.${method['name']}_delegate>(library);+              % endfor+          }+          +          public NativeMethods(DllImportsFromStaticLib unusedInstance)","I was trying to avoid this, but if you wanted to have a factory method, you need a constructor anyway to inititialize all the readonly fields - so having a factory methods would only add a lot of generated code (and we would still need to have some way to disambiguate the constructors).IMHO What we have is the best I could do at the moment and it's internal code (and despite the small hack I'd say it's sufficiently clear). But I'm open to better ideas ;-)",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/14610,173003166,2018-03-07T22:16:05Z,templates/test/cpp/naming/resolver_component_tests_defs.include,"@@ -41,10 +43,10 @@ echo ""Local DNS server started. PID: $DNS_SERVER_PID"" # Health check local DNS server TCP and UDP ports for ((i=0;i<30;i++)); do-  echo ""Retry health-check DNS query to local DNS server over tcp and udp""+  echo ""Retry health-check local DNS server by attempting a DNS query and TCP handshake""   RETRY=0-  dig A health-check-local-dns-server-is-alive.resolver-tests.grpctestingexp. @localhost -p ""$FLAGS_test_dns_server_port"" +tries=1 +timeout=1 | grep '123.123.123.123' || RETRY=1-  dig A health-check-local-dns-server-is-alive.resolver-tests.grpctestingexp. @localhost -p ""$FLAGS_test_dns_server_port"" +tries=1 +timeout=1 +tcp | grep '123.123.123.123' || RETRY=1+  $FLAGS_test_dns_resolver_bin_path -s 127.0.0.1 -p ""$FLAGS_test_dns_server_port"" -n health-check-local-dns-server-is-alive.resolver-tests.grpctestingexp. -t 1 | grep '123.123.123.123' || RETRY=1","As I understand, the problem is that the DNS server which this script (`$FLAGS_test_dns_resolver_bin_path`) is querying is currently binding to the ipv4 `INADDR_ANY` address ([this python library call to start listening on a port](https://github.com/grpc/grpc/blob/master/test/cpp/naming/test_dns_server.py#L103) uses that by default, [configured around here](https://github.com/twisted/twisted/blob/trunk/src/twisted/internet/tcp.py#L973).So this `$FLAGS_test_dns_resolver_bin_path` script I believe needs to set it's target address to `127.0.0.1` to be sure to reach it. The same problem exists for the gRPC [test binary](https://github.com/grpc/grpc/blob/master/test/cpp/naming/resolver_component_tests_runner.sh#L168). Neither of these clients can resolve `localhost` too, so I think that fixing this `broken-under ipv6-only` situation for this test would require conditionally checking ipv6 availability for both of the clients and the server.Would we be ok filing a bug about this test's ipv6-only brokenness and fixing in a separate PR?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/14605,173098556,2018-03-08T09:06:00Z,templates/src/csharp/Grpc.Core/Internal/NativeMethods.Generated.cs.template,"@@ -0,0 +1,233 @@+%YAML 1.2+--- |+  <%+    native_method_signatures = [+      'void grpcsharp_init()',+      'void grpcsharp_shutdown()',+      'IntPtr grpcsharp_version_string()  // returns not-owned const char*',+      '',+      'BatchContextSafeHandle grpcsharp_batch_context_create()',+      'IntPtr grpcsharp_batch_context_recv_initial_metadata(BatchContextSafeHandle ctx)',+      'IntPtr grpcsharp_batch_context_recv_message_length(BatchContextSafeHandle ctx)',+      'void grpcsharp_batch_context_recv_message_to_buffer(BatchContextSafeHandle ctx, byte[] buffer, UIntPtr bufferLen)',+      'StatusCode grpcsharp_batch_context_recv_status_on_client_status(BatchContextSafeHandle ctx)',+      'IntPtr grpcsharp_batch_context_recv_status_on_client_details(BatchContextSafeHandle ctx, out UIntPtr detailsLength)',+      'IntPtr grpcsharp_batch_context_recv_status_on_client_trailing_metadata(BatchContextSafeHandle ctx)',+      'int grpcsharp_batch_context_recv_close_on_server_cancelled(BatchContextSafeHandle ctx)',+      'void grpcsharp_batch_context_reset(BatchContextSafeHandle ctx)',+      'void grpcsharp_batch_context_destroy(IntPtr ctx)',+      '',+      'RequestCallContextSafeHandle grpcsharp_request_call_context_create()',+      'CallSafeHandle grpcsharp_request_call_context_call(RequestCallContextSafeHandle ctx)',+      'IntPtr grpcsharp_request_call_context_method(RequestCallContextSafeHandle ctx, out UIntPtr methodLength)',+      'IntPtr grpcsharp_request_call_context_host(RequestCallContextSafeHandle ctx, out UIntPtr hostLength)',+      'Timespec grpcsharp_request_call_context_deadline(RequestCallContextSafeHandle ctx)',+      'IntPtr grpcsharp_request_call_context_request_metadata(RequestCallContextSafeHandle ctx)',+      'void grpcsharp_request_call_context_reset(RequestCallContextSafeHandle ctx)',+      'void grpcsharp_request_call_context_destroy(IntPtr ctx)',+      '',+      'CallCredentialsSafeHandle grpcsharp_composite_call_credentials_create(CallCredentialsSafeHandle creds1, CallCredentialsSafeHandle creds2)',+      'void grpcsharp_call_credentials_release(IntPtr credentials)',+      '',+      'CallError grpcsharp_call_cancel(CallSafeHandle call)',+      'CallError grpcsharp_call_cancel_with_status(CallSafeHandle call, StatusCode status, string description)',+      'CallError grpcsharp_call_start_unary(CallSafeHandle call, BatchContextSafeHandle ctx, byte[] sendBuffer, UIntPtr sendBufferLen, WriteFlags writeFlags, MetadataArraySafeHandle metadataArray, CallFlags metadataFlags)',+      'CallError grpcsharp_call_start_client_streaming(CallSafeHandle call, BatchContextSafeHandle ctx, MetadataArraySafeHandle metadataArray, CallFlags metadataFlags)',+      'CallError grpcsharp_call_start_server_streaming(CallSafeHandle call, BatchContextSafeHandle ctx, byte[] sendBuffer, UIntPtr sendBufferLen, WriteFlags writeFlags, MetadataArraySafeHandle metadataArray, CallFlags metadataFlags)',+      'CallError grpcsharp_call_start_duplex_streaming(CallSafeHandle call, BatchContextSafeHandle ctx, MetadataArraySafeHandle metadataArray, CallFlags metadataFlags)',+      'CallError grpcsharp_call_send_message(CallSafeHandle call, BatchContextSafeHandle ctx, byte[] sendBuffer, UIntPtr sendBufferLen, WriteFlags writeFlags, int sendEmptyInitialMetadata)',+      'CallError grpcsharp_call_send_close_from_client(CallSafeHandle call, BatchContextSafeHandle ctx)',+      'CallError grpcsharp_call_send_status_from_server(CallSafeHandle call, BatchContextSafeHandle ctx, StatusCode statusCode, byte[] statusMessage, UIntPtr statusMessageLen, MetadataArraySafeHandle metadataArray, int sendEmptyInitialMetadata, byte[] optionalSendBuffer, UIntPtr optionalSendBufferLen, WriteFlags writeFlags)',+      'CallError grpcsharp_call_recv_message(CallSafeHandle call, BatchContextSafeHandle ctx)',+      'CallError grpcsharp_call_recv_initial_metadata(CallSafeHandle call, BatchContextSafeHandle ctx)',+      'CallError grpcsharp_call_start_serverside(CallSafeHandle call, BatchContextSafeHandle ctx)',+      'CallError grpcsharp_call_send_initial_metadata(CallSafeHandle call, BatchContextSafeHandle ctx, MetadataArraySafeHandle metadataArray)',+      'CallError grpcsharp_call_set_credentials(CallSafeHandle call, CallCredentialsSafeHandle credentials)',+      'CStringSafeHandle grpcsharp_call_get_peer(CallSafeHandle call)',+      'void grpcsharp_call_destroy(IntPtr call)',+      '',+      'ChannelArgsSafeHandle grpcsharp_channel_args_create(UIntPtr numArgs)',+      'void grpcsharp_channel_args_set_string(ChannelArgsSafeHandle args, UIntPtr index, string key, string value)',+      'void grpcsharp_channel_args_set_integer(ChannelArgsSafeHandle args, UIntPtr index, string key, int value)',+      'void grpcsharp_channel_args_destroy(IntPtr args)',+      '',+      'void grpcsharp_override_default_ssl_roots(string pemRootCerts)',+      'ChannelCredentialsSafeHandle grpcsharp_ssl_credentials_create(string pemRootCerts, string keyCertPairCertChain, string keyCertPairPrivateKey)',+      'ChannelCredentialsSafeHandle grpcsharp_composite_channel_credentials_create(ChannelCredentialsSafeHandle channelCreds, CallCredentialsSafeHandle callCreds)',+      'void grpcsharp_channel_credentials_release(IntPtr credentials)',+      '',+      'ChannelSafeHandle grpcsharp_insecure_channel_create(string target, ChannelArgsSafeHandle channelArgs)',+      'ChannelSafeHandle grpcsharp_secure_channel_create(ChannelCredentialsSafeHandle credentials, string target, ChannelArgsSafeHandle channelArgs)',+      'CallSafeHandle grpcsharp_channel_create_call(ChannelSafeHandle channel, CallSafeHandle parentCall, ContextPropagationFlags propagationMask, CompletionQueueSafeHandle cq, string method, string host, Timespec deadline)',+      'ChannelState grpcsharp_channel_check_connectivity_state(ChannelSafeHandle channel, int tryToConnect)',+      'void grpcsharp_channel_watch_connectivity_state(ChannelSafeHandle channel, ChannelState lastObservedState, Timespec deadline, CompletionQueueSafeHandle cq, BatchContextSafeHandle ctx)',+      'CStringSafeHandle grpcsharp_channel_get_target(ChannelSafeHandle call)',+      'void grpcsharp_channel_destroy(IntPtr channel)',+      '',+      'int grpcsharp_sizeof_grpc_event()',+      '',+      'CompletionQueueSafeHandle grpcsharp_completion_queue_create_async()',+      'CompletionQueueSafeHandle grpcsharp_completion_queue_create_sync()',+      'void grpcsharp_completion_queue_shutdown(CompletionQueueSafeHandle cq)',+      'CompletionQueueEvent grpcsharp_completion_queue_next(CompletionQueueSafeHandle cq)',+      'CompletionQueueEvent grpcsharp_completion_queue_pluck(CompletionQueueSafeHandle cq, IntPtr tag)',+      'void grpcsharp_completion_queue_destroy(IntPtr cq)',+      '',+      'void gprsharp_free(IntPtr ptr)',+      '',+      'MetadataArraySafeHandle grpcsharp_metadata_array_create(UIntPtr capacity)',+      'void grpcsharp_metadata_array_add(MetadataArraySafeHandle array, string key, byte[] value, UIntPtr valueLength)',+      'UIntPtr grpcsharp_metadata_array_count(IntPtr metadataArray)',+      'IntPtr grpcsharp_metadata_array_get_key(IntPtr metadataArray, UIntPtr index, out UIntPtr keyLength)',+      'IntPtr grpcsharp_metadata_array_get_value(IntPtr metadataArray, UIntPtr index, out UIntPtr valueLength)',+      'void grpcsharp_metadata_array_destroy_full(IntPtr array)',+      '',+      'void grpcsharp_redirect_log(GprLogDelegate callback)',+      '',+      'CallCredentialsSafeHandle grpcsharp_metadata_credentials_create_from_plugin(NativeMetadataInterceptor interceptor)',+      'void grpcsharp_metadata_credentials_notify_from_plugin(IntPtr callbackPtr, IntPtr userData, MetadataArraySafeHandle metadataArray, StatusCode statusCode, string errorDetails)',+      '',+      'ServerCredentialsSafeHandle grpcsharp_ssl_server_credentials_create(string pemRootCerts, string[] keyCertPairCertChainArray, string[] keyCertPairPrivateKeyArray, UIntPtr numKeyCertPairs, int forceClientAuth)',+      'void grpcsharp_server_credentials_release(IntPtr credentials)',+      '',+      'ServerSafeHandle grpcsharp_server_create(ChannelArgsSafeHandle args)',+      'void grpcsharp_server_register_completion_queue(ServerSafeHandle server, CompletionQueueSafeHandle cq)',+      'int grpcsharp_server_add_insecure_http2_port(ServerSafeHandle server, string addr)',+      'int grpcsharp_server_add_secure_http2_port(ServerSafeHandle server, string addr, ServerCredentialsSafeHandle creds)',+      'void grpcsharp_server_start(ServerSafeHandle server)',+      'CallError grpcsharp_server_request_call(ServerSafeHandle server, CompletionQueueSafeHandle cq, RequestCallContextSafeHandle ctx)',+      'void grpcsharp_server_cancel_all_calls(ServerSafeHandle server)',+      'void grpcsharp_server_shutdown_and_notify_callback(ServerSafeHandle server, CompletionQueueSafeHandle cq, BatchContextSafeHandle ctx)',+      'void grpcsharp_server_destroy(IntPtr server)',+      '',+      'AuthContextSafeHandle grpcsharp_call_auth_context(CallSafeHandle call)',+      'IntPtr grpcsharp_auth_context_peer_identity_property_name(AuthContextSafeHandle authContext)  // returns const char*',+      'AuthContextSafeHandle.NativeAuthPropertyIterator grpcsharp_auth_context_property_iterator(AuthContextSafeHandle authContext)',+      'IntPtr grpcsharp_auth_property_iterator_next(ref AuthContextSafeHandle.NativeAuthPropertyIterator iterator)  // returns const auth_property*',+      'void grpcsharp_auth_context_release(IntPtr authContext)',+      '',+      'Timespec gprsharp_now(ClockType clockType)',+      'Timespec gprsharp_inf_future(ClockType clockType)',+      'Timespec gprsharp_inf_past(ClockType clockType)',+      '',+      'Timespec gprsharp_convert_clock_type(Timespec t, ClockType targetClock)',+      'int gprsharp_sizeof_timespec()',+      '',+      'CallError grpcsharp_test_callback([MarshalAs(UnmanagedType.FunctionPtr)] NativeCallbackTestDelegate callback)',+      'IntPtr grpcsharp_test_nop(IntPtr ptr)',+      'void grpcsharp_test_override_method(string methodName, string variant)',+    ]+    +    import re+    native_methods = []+    for signature in native_method_signatures:+      if not signature:+        continue+      match = re.match('([^ ]+) +([A-Za-z0-9_]+)\\((.*)\\)(.*)', signature)+      native_methods.append({'name': match.group(2), 'returntype': match.group(1), 'params': match.group(3), 'comment': match.group(4)})+    +  +    #native_methods = [+    #  {'name': 'grpcsharp_init', 'returntype': 'void', 'params': ''},+    #  {'name': 'grpcsharp_server_request_call', 'returntype': 'CallError', 'params': 'ServerSafeHandle server, CompletionQueueSafeHandle cq, RequestCallContextSafeHandle ctx'},+    #]+  %>+  #region Copyright notice and license+  +  // Copyright 2015 gRPC authors.+  //+  // Licensed under the Apache License, Version 2.0 (the ""License"");+  // you may not use this file except in compliance with the License.+  // You may obtain a copy of the License at+  //+  //     http://www.apache.org/licenses/LICENSE-2.0+  //+  // Unless required by applicable law or agreed to in writing, software+  // distributed under the License is distributed on an ""AS IS"" BASIS,+  // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+  // See the License for the specific language governing permissions and+  // limitations under the License.+  +  #endregion+  +  using System;+  using System.Collections.Concurrent;+  using System.Diagnostics;+  using System.IO;+  using System.Reflection;+  using System.Runtime.InteropServices;+  using System.Threading;+  +  using Grpc.Core.Logging;+  using Grpc.Core.Utils;+  +  namespace Grpc.Core.Internal+  {+      internal partial class NativeMethods+      {+          #region Native methods+          +          % for method in native_methods:+          public readonly Delegates.${method['name']}_delegate ${method['name']};+          % endfor++          #endregion+  +          public NativeMethods(UnmanagedLibrary library)+          {+              % for method in native_methods:+              this.${method['name']} = GetMethodDelegate<Delegates.${method['name']}_delegate>(library);+              % endfor+          }+          +          public NativeMethods(DllImportsFromStaticLib unusedInstance)","Yeah this is definitely a minor issue :) but one other idea as an optional suggestion:instead of `class type`s, perhaps`DllImportsFromSharedLib` and `DllImportsFromSharedLib` could be constant variables of class `DllImportsFromLib`? Maybe `DllImportsFromLib` could then take a constructor param for the `ImportName` field and there could be a `NativeMethods(DllImportsFromLib)`that could be passed those instances, which might de-dupe a few lines from the template code.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/14605,173130712,2018-03-08T11:19:37Z,templates/src/csharp/Grpc.Core/Internal/NativeMethods.Generated.cs.template,"@@ -0,0 +1,233 @@+%YAML 1.2+--- |+  <%+    native_method_signatures = [+      'void grpcsharp_init()',+      'void grpcsharp_shutdown()',+      'IntPtr grpcsharp_version_string()  // returns not-owned const char*',+      '',+      'BatchContextSafeHandle grpcsharp_batch_context_create()',+      'IntPtr grpcsharp_batch_context_recv_initial_metadata(BatchContextSafeHandle ctx)',+      'IntPtr grpcsharp_batch_context_recv_message_length(BatchContextSafeHandle ctx)',+      'void grpcsharp_batch_context_recv_message_to_buffer(BatchContextSafeHandle ctx, byte[] buffer, UIntPtr bufferLen)',+      'StatusCode grpcsharp_batch_context_recv_status_on_client_status(BatchContextSafeHandle ctx)',+      'IntPtr grpcsharp_batch_context_recv_status_on_client_details(BatchContextSafeHandle ctx, out UIntPtr detailsLength)',+      'IntPtr grpcsharp_batch_context_recv_status_on_client_trailing_metadata(BatchContextSafeHandle ctx)',+      'int grpcsharp_batch_context_recv_close_on_server_cancelled(BatchContextSafeHandle ctx)',+      'void grpcsharp_batch_context_reset(BatchContextSafeHandle ctx)',+      'void grpcsharp_batch_context_destroy(IntPtr ctx)',+      '',+      'RequestCallContextSafeHandle grpcsharp_request_call_context_create()',+      'CallSafeHandle grpcsharp_request_call_context_call(RequestCallContextSafeHandle ctx)',+      'IntPtr grpcsharp_request_call_context_method(RequestCallContextSafeHandle ctx, out UIntPtr methodLength)',+      'IntPtr grpcsharp_request_call_context_host(RequestCallContextSafeHandle ctx, out UIntPtr hostLength)',+      'Timespec grpcsharp_request_call_context_deadline(RequestCallContextSafeHandle ctx)',+      'IntPtr grpcsharp_request_call_context_request_metadata(RequestCallContextSafeHandle ctx)',+      'void grpcsharp_request_call_context_reset(RequestCallContextSafeHandle ctx)',+      'void grpcsharp_request_call_context_destroy(IntPtr ctx)',+      '',+      'CallCredentialsSafeHandle grpcsharp_composite_call_credentials_create(CallCredentialsSafeHandle creds1, CallCredentialsSafeHandle creds2)',+      'void grpcsharp_call_credentials_release(IntPtr credentials)',+      '',+      'CallError grpcsharp_call_cancel(CallSafeHandle call)',+      'CallError grpcsharp_call_cancel_with_status(CallSafeHandle call, StatusCode status, string description)',+      'CallError grpcsharp_call_start_unary(CallSafeHandle call, BatchContextSafeHandle ctx, byte[] sendBuffer, UIntPtr sendBufferLen, WriteFlags writeFlags, MetadataArraySafeHandle metadataArray, CallFlags metadataFlags)',+      'CallError grpcsharp_call_start_client_streaming(CallSafeHandle call, BatchContextSafeHandle ctx, MetadataArraySafeHandle metadataArray, CallFlags metadataFlags)',+      'CallError grpcsharp_call_start_server_streaming(CallSafeHandle call, BatchContextSafeHandle ctx, byte[] sendBuffer, UIntPtr sendBufferLen, WriteFlags writeFlags, MetadataArraySafeHandle metadataArray, CallFlags metadataFlags)',+      'CallError grpcsharp_call_start_duplex_streaming(CallSafeHandle call, BatchContextSafeHandle ctx, MetadataArraySafeHandle metadataArray, CallFlags metadataFlags)',+      'CallError grpcsharp_call_send_message(CallSafeHandle call, BatchContextSafeHandle ctx, byte[] sendBuffer, UIntPtr sendBufferLen, WriteFlags writeFlags, int sendEmptyInitialMetadata)',+      'CallError grpcsharp_call_send_close_from_client(CallSafeHandle call, BatchContextSafeHandle ctx)',+      'CallError grpcsharp_call_send_status_from_server(CallSafeHandle call, BatchContextSafeHandle ctx, StatusCode statusCode, byte[] statusMessage, UIntPtr statusMessageLen, MetadataArraySafeHandle metadataArray, int sendEmptyInitialMetadata, byte[] optionalSendBuffer, UIntPtr optionalSendBufferLen, WriteFlags writeFlags)',+      'CallError grpcsharp_call_recv_message(CallSafeHandle call, BatchContextSafeHandle ctx)',+      'CallError grpcsharp_call_recv_initial_metadata(CallSafeHandle call, BatchContextSafeHandle ctx)',+      'CallError grpcsharp_call_start_serverside(CallSafeHandle call, BatchContextSafeHandle ctx)',+      'CallError grpcsharp_call_send_initial_metadata(CallSafeHandle call, BatchContextSafeHandle ctx, MetadataArraySafeHandle metadataArray)',+      'CallError grpcsharp_call_set_credentials(CallSafeHandle call, CallCredentialsSafeHandle credentials)',+      'CStringSafeHandle grpcsharp_call_get_peer(CallSafeHandle call)',+      'void grpcsharp_call_destroy(IntPtr call)',+      '',+      'ChannelArgsSafeHandle grpcsharp_channel_args_create(UIntPtr numArgs)',+      'void grpcsharp_channel_args_set_string(ChannelArgsSafeHandle args, UIntPtr index, string key, string value)',+      'void grpcsharp_channel_args_set_integer(ChannelArgsSafeHandle args, UIntPtr index, string key, int value)',+      'void grpcsharp_channel_args_destroy(IntPtr args)',+      '',+      'void grpcsharp_override_default_ssl_roots(string pemRootCerts)',+      'ChannelCredentialsSafeHandle grpcsharp_ssl_credentials_create(string pemRootCerts, string keyCertPairCertChain, string keyCertPairPrivateKey)',+      'ChannelCredentialsSafeHandle grpcsharp_composite_channel_credentials_create(ChannelCredentialsSafeHandle channelCreds, CallCredentialsSafeHandle callCreds)',+      'void grpcsharp_channel_credentials_release(IntPtr credentials)',+      '',+      'ChannelSafeHandle grpcsharp_insecure_channel_create(string target, ChannelArgsSafeHandle channelArgs)',+      'ChannelSafeHandle grpcsharp_secure_channel_create(ChannelCredentialsSafeHandle credentials, string target, ChannelArgsSafeHandle channelArgs)',+      'CallSafeHandle grpcsharp_channel_create_call(ChannelSafeHandle channel, CallSafeHandle parentCall, ContextPropagationFlags propagationMask, CompletionQueueSafeHandle cq, string method, string host, Timespec deadline)',+      'ChannelState grpcsharp_channel_check_connectivity_state(ChannelSafeHandle channel, int tryToConnect)',+      'void grpcsharp_channel_watch_connectivity_state(ChannelSafeHandle channel, ChannelState lastObservedState, Timespec deadline, CompletionQueueSafeHandle cq, BatchContextSafeHandle ctx)',+      'CStringSafeHandle grpcsharp_channel_get_target(ChannelSafeHandle call)',+      'void grpcsharp_channel_destroy(IntPtr channel)',+      '',+      'int grpcsharp_sizeof_grpc_event()',+      '',+      'CompletionQueueSafeHandle grpcsharp_completion_queue_create_async()',+      'CompletionQueueSafeHandle grpcsharp_completion_queue_create_sync()',+      'void grpcsharp_completion_queue_shutdown(CompletionQueueSafeHandle cq)',+      'CompletionQueueEvent grpcsharp_completion_queue_next(CompletionQueueSafeHandle cq)',+      'CompletionQueueEvent grpcsharp_completion_queue_pluck(CompletionQueueSafeHandle cq, IntPtr tag)',+      'void grpcsharp_completion_queue_destroy(IntPtr cq)',+      '',+      'void gprsharp_free(IntPtr ptr)',+      '',+      'MetadataArraySafeHandle grpcsharp_metadata_array_create(UIntPtr capacity)',+      'void grpcsharp_metadata_array_add(MetadataArraySafeHandle array, string key, byte[] value, UIntPtr valueLength)',+      'UIntPtr grpcsharp_metadata_array_count(IntPtr metadataArray)',+      'IntPtr grpcsharp_metadata_array_get_key(IntPtr metadataArray, UIntPtr index, out UIntPtr keyLength)',+      'IntPtr grpcsharp_metadata_array_get_value(IntPtr metadataArray, UIntPtr index, out UIntPtr valueLength)',+      'void grpcsharp_metadata_array_destroy_full(IntPtr array)',+      '',+      'void grpcsharp_redirect_log(GprLogDelegate callback)',+      '',+      'CallCredentialsSafeHandle grpcsharp_metadata_credentials_create_from_plugin(NativeMetadataInterceptor interceptor)',+      'void grpcsharp_metadata_credentials_notify_from_plugin(IntPtr callbackPtr, IntPtr userData, MetadataArraySafeHandle metadataArray, StatusCode statusCode, string errorDetails)',+      '',+      'ServerCredentialsSafeHandle grpcsharp_ssl_server_credentials_create(string pemRootCerts, string[] keyCertPairCertChainArray, string[] keyCertPairPrivateKeyArray, UIntPtr numKeyCertPairs, int forceClientAuth)',+      'void grpcsharp_server_credentials_release(IntPtr credentials)',+      '',+      'ServerSafeHandle grpcsharp_server_create(ChannelArgsSafeHandle args)',+      'void grpcsharp_server_register_completion_queue(ServerSafeHandle server, CompletionQueueSafeHandle cq)',+      'int grpcsharp_server_add_insecure_http2_port(ServerSafeHandle server, string addr)',+      'int grpcsharp_server_add_secure_http2_port(ServerSafeHandle server, string addr, ServerCredentialsSafeHandle creds)',+      'void grpcsharp_server_start(ServerSafeHandle server)',+      'CallError grpcsharp_server_request_call(ServerSafeHandle server, CompletionQueueSafeHandle cq, RequestCallContextSafeHandle ctx)',+      'void grpcsharp_server_cancel_all_calls(ServerSafeHandle server)',+      'void grpcsharp_server_shutdown_and_notify_callback(ServerSafeHandle server, CompletionQueueSafeHandle cq, BatchContextSafeHandle ctx)',+      'void grpcsharp_server_destroy(IntPtr server)',+      '',+      'AuthContextSafeHandle grpcsharp_call_auth_context(CallSafeHandle call)',+      'IntPtr grpcsharp_auth_context_peer_identity_property_name(AuthContextSafeHandle authContext)  // returns const char*',+      'AuthContextSafeHandle.NativeAuthPropertyIterator grpcsharp_auth_context_property_iterator(AuthContextSafeHandle authContext)',+      'IntPtr grpcsharp_auth_property_iterator_next(ref AuthContextSafeHandle.NativeAuthPropertyIterator iterator)  // returns const auth_property*',+      'void grpcsharp_auth_context_release(IntPtr authContext)',+      '',+      'Timespec gprsharp_now(ClockType clockType)',+      'Timespec gprsharp_inf_future(ClockType clockType)',+      'Timespec gprsharp_inf_past(ClockType clockType)',+      '',+      'Timespec gprsharp_convert_clock_type(Timespec t, ClockType targetClock)',+      'int gprsharp_sizeof_timespec()',+      '',+      'CallError grpcsharp_test_callback([MarshalAs(UnmanagedType.FunctionPtr)] NativeCallbackTestDelegate callback)',+      'IntPtr grpcsharp_test_nop(IntPtr ptr)',+      'void grpcsharp_test_override_method(string methodName, string variant)',+    ]+    +    import re+    native_methods = []+    for signature in native_method_signatures:+      if not signature:+        continue+      match = re.match('([^ ]+) +([A-Za-z0-9_]+)\\((.*)\\)(.*)', signature)+      native_methods.append({'name': match.group(2), 'returntype': match.group(1), 'params': match.group(3), 'comment': match.group(4)})+    +  +    #native_methods = [+    #  {'name': 'grpcsharp_init', 'returntype': 'void', 'params': ''},+    #  {'name': 'grpcsharp_server_request_call', 'returntype': 'CallError', 'params': 'ServerSafeHandle server, CompletionQueueSafeHandle cq, RequestCallContextSafeHandle ctx'},+    #]+  %>+  #region Copyright notice and license+  +  // Copyright 2015 gRPC authors.+  //+  // Licensed under the Apache License, Version 2.0 (the ""License"");+  // you may not use this file except in compliance with the License.+  // You may obtain a copy of the License at+  //+  //     http://www.apache.org/licenses/LICENSE-2.0+  //+  // Unless required by applicable law or agreed to in writing, software+  // distributed under the License is distributed on an ""AS IS"" BASIS,+  // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+  // See the License for the specific language governing permissions and+  // limitations under the License.+  +  #endregion+  +  using System;+  using System.Collections.Concurrent;+  using System.Diagnostics;+  using System.IO;+  using System.Reflection;+  using System.Runtime.InteropServices;+  using System.Threading;+  +  using Grpc.Core.Logging;+  using Grpc.Core.Utils;+  +  namespace Grpc.Core.Internal+  {+      internal partial class NativeMethods+      {+          #region Native methods+          +          % for method in native_methods:+          public readonly Delegates.${method['name']}_delegate ${method['name']};+          % endfor++          #endregion+  +          public NativeMethods(UnmanagedLibrary library)+          {+              % for method in native_methods:+              this.${method['name']} = GetMethodDelegate<Delegates.${method['name']}_delegate>(library);+              % endfor+          }+          +          public NativeMethods(DllImportsFromStaticLib unusedInstance)","That wouldn't work because the methods with [DllImport] attribute needs to be static - so passing anything to the constructor won't help. I think the duplication here can't really be avoided (unless we want to use reflection to set all the delegates), which is also why I decided to use codegeneration here.",
30242850,aamitdb,https://api.github.com/repos/grpc/grpc/pulls/14639,173171401,2018-03-08T14:23:34Z,src/python/grpcio/grpc/_interceptor.py,"@@ -133,23 +185,35 @@ def __init__(self, thunk, method, interceptor):         self._interceptor = interceptor      def __call__(self, request, timeout=None, metadata=None, credentials=None):-        call_future = self.future(+        response, ignored_call = self.with_call(             request,             timeout=timeout,             metadata=metadata,             credentials=credentials)-        return call_future.result()+        return response      def with_call(self, request, timeout=None, metadata=None, credentials=None):-        call_future = self.future(-            request,-            timeout=timeout,-            metadata=metadata,-            credentials=credentials)-        return call_future.result(), call_future+        client_call_details = _ClientCallDetails(self._method, timeout,+                                                 metadata, credentials) -    def future(self, request, timeout=None, metadata=None, credentials=None):+        def continuation(new_details, request):+            new_method, new_timeout, new_metadata, new_credentials = (+                _unwrap_client_call_details(new_details, client_call_details))+            try:+                response, call = self._thunk(new_method).with_call(+                    request,+                    timeout=new_timeout,+                    metadata=new_metadata,+                    credentials=new_credentials)+                return _UnaryOutcome(response, call)+            except Exception as exception:  # pylint:disable=broad-except","If I am understanding things correctly, I think this might incorrectly swallow RpcError codes. `with_call` raises on non-OK RPC termination and then _FailureOutcome sets the `code()` to internal, rather than the original RpcCode.The approach I went with is catching `RpcError` (which when raised from `with_call` is actually a _Rendezvous/Call/Future) and returning that. In my tests this keeps the same API for interceptors, that `continuation(call_details,request)` returns a Call/Future which they can inspect/replace and if the interceptor does nothing but call the continuation then its the same as if there is no interceptor. ```def install_monkeypatches():    import sys    import grpc._interceptor    from grpc._interceptor import _ClientCallDetails, _LocalFailure    def blocking_unary_with_call(self, request, timeout=None, metadata=None, credentials=None):        def continuation(client_call_details, request):            channel = self._thunk(client_call_details.method)            try:                resp, call = channel.with_call(request,                                               timeout=client_call_details.timeout,                                               metadata=client_call_details.metadata,                                               credentials=client_call_details.credentials)                return call            except grpc.RpcError as e:                return e        client_call_details = _ClientCallDetails(self._method, timeout,                                                 metadata, credentials)        try:            resp = self._interceptor.intercept_unary_unary(                continuation, client_call_details, request)        except Exception as exception:  # pylint:disable=broad-except            resp = _LocalFailure(exception, sys.exc_info()[2])        return resp.result(), resp    grpc._interceptor._UnaryUnaryMultiCallable.with_call = blocking_unary_with_call    def blocking_unary_call(self, request, timeout=None, metadata=None, credentials=None):        resp, call = self.with_call(request,                                    timeout=timeout,                                    metadata=metadata,                                    credentials=credentials)        return resp    grpc._interceptor._UnaryUnaryMultiCallable.__call__ = blocking_unary_call```",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/14639,173210818,2018-03-08T16:24:27Z,src/python/grpcio/grpc/_interceptor.py,"@@ -133,23 +185,35 @@ def __init__(self, thunk, method, interceptor):         self._interceptor = interceptor      def __call__(self, request, timeout=None, metadata=None, credentials=None):-        call_future = self.future(+        response, ignored_call = self.with_call(             request,             timeout=timeout,             metadata=metadata,             credentials=credentials)-        return call_future.result()+        return response      def with_call(self, request, timeout=None, metadata=None, credentials=None):-        call_future = self.future(-            request,-            timeout=timeout,-            metadata=metadata,-            credentials=credentials)-        return call_future.result(), call_future+        client_call_details = _ClientCallDetails(self._method, timeout,+                                                 metadata, credentials) -    def future(self, request, timeout=None, metadata=None, credentials=None):+        def continuation(new_details, request):+            new_method, new_timeout, new_metadata, new_credentials = (+                _unwrap_client_call_details(new_details, client_call_details))+            try:+                response, call = self._thunk(new_method).with_call(+                    request,+                    timeout=new_timeout,+                    metadata=new_metadata,+                    credentials=new_credentials)+                return _UnaryOutcome(response, call)+            except Exception as exception:  # pylint:disable=broad-except","You are correct; special casing `RpcError` before the board-exception-handler will fix that situation. For the record, the rationale behind broad-exception-handling (which should not really happen except for `RpcError` and throwing your own exceptions should be considered a programming error) is to isolate the programming defects between interceptors and handlers so that the behavior becomes more deterministic.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14517,173520108,2018-03-09T17:49:59Z,include/grpcpp/server.h,"@@ -175,6 +153,31 @@ class Server final : public ServerInterface, private GrpcLibraryCodegen {   /// \param num_cqs How many completion queues does \a cqs hold.   void Start(ServerCompletionQueue** cqs, size_t num_cqs) override; +  grpc_server* server() override { return server_; };","Having this be protected is concerning, for the reason that this means that this is adding an API that exposes gRPC core structures. I'm busy in #14648 trying to remove any APIs that expose gRPC core structures (since they're technically not really API anyway). I thought your plan was to not use gRPC core structures in your derived classes anyway?",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14517,173521874,2018-03-09T17:57:18Z,test/cpp/codegen/codegen_test_minimal.cc,"@@ -16,9 +16,14 @@  *  */ +#include <grpcpp/impl/codegen/completion_queue.h> #include <gtest/gtest.h>  namespace grpc {++// Unused implementation for the virtual ""Next"" method.+bool CompletionQueue::Next(void** tag, bool* ok) { return false; }",@dgquintas : does this feel kosher to you? We need a mechanism to allow the use of codegen headers without crapping out on linker errors now that we're using `virtual` members for some classes that get used in codegen. Can you comment on this?,
17325098,makdharma,https://api.github.com/repos/grpc/grpc/pulls/14517,173532009,2018-03-09T18:38:10Z,include/grpcpp/server.h,"@@ -175,6 +153,31 @@ class Server final : public ServerInterface, private GrpcLibraryCodegen {   /// \param num_cqs How many completion queues does \a cqs hold.   void Start(ServerCompletionQueue** cqs, size_t num_cqs) override; +  grpc_server* server() override { return server_; };","The plan is to not use gRPC core structures unless it makes sense and avoids duplication. This is currently the only instance of using core (so we can reuse the channel creation, connection opening etc).",
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/14615,173540885,2018-03-09T19:12:08Z,src/core/lib/security/security_connector/security_connector.cc,"@@ -465,12 +465,10 @@ static bool fake_channel_check_call_host(grpc_channel_security_connector* sc,                                          grpc_error** error) {   grpc_fake_channel_security_connector* c =       reinterpret_cast<grpc_fake_channel_security_connector*>(sc);-  if (c->is_lb_channel) {-    // TODO(dgq): verify that the host (ie, authority header) matches that of-    // the LB, as opposed to that of the backends.-  } else {-    // TODO(dgq): verify that the host (ie, authority header) matches that of-    // the backend, not the LB's.+  if (c->is_lb_channel && strcmp(host, c->target) != 0) {+    gpr_log(GPR_ERROR, ""Authority (host) '%s' != Target '%s' for an LB call"",+            host, c->target);+    abort();","It seems in grpclb usecase, those two are always the same, so we are fine. But In generic usecase, I think if a caller specifies a different host info from c->target to grpc_channel_create_call(), we should fail check_call_host(), or find a way to do another secure naming check on the host info. My question is, is it possible (or is there any usecase) that a client creates a channel to a gRPC service (by specifying a target info), and he can also call grpc_channel_create_call() during the operation to modify the host info? ",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14647,173545392,2018-03-09T19:29:11Z,src/core/lib/gpr/fork.cc,"@@ -69,10 +84,104 @@ void grpc_fork_support_init() {   if (override_fork_support_enabled != -1) {     fork_support_enabled = override_fork_support_enabled;   }+  if (fork_support_enabled) {+    g_fork_state = (fork_state*)gpr_malloc(sizeof(fork_state));+    gpr_mu_init(&g_fork_state->mu);+    gpr_cv_init(&g_fork_state->thd_cv);+    gpr_cv_init(&g_fork_state->exec_ctx_cv);+    gpr_atm_no_barrier_store(&g_fork_state->exec_ctx_count, 2);+    g_fork_state->thd_count = 0;+    g_fork_state->awaiting_threads = false;+  }+}++void grpc_fork_support_destroy() {+  if (g_fork_state) {+    gpr_mu_destroy(&g_fork_state->mu);+    gpr_cv_destroy(&g_fork_state->thd_cv);+    gpr_cv_destroy(&g_fork_state->exec_ctx_cv);+    gpr_free(g_fork_state);+    g_fork_state = nullptr;+  }+}++void grpc_fork_inc_thd_count() {+  if (g_fork_state) {+    gpr_mu_lock(&g_fork_state->mu);+    g_fork_state->thd_count++;+    gpr_mu_unlock(&g_fork_state->mu);+  }+}++void grpc_fork_dec_thd_count() {+  if (g_fork_state) {+    gpr_mu_lock(&g_fork_state->mu);+    g_fork_state->thd_count--;+    if (g_fork_state->awaiting_threads && g_fork_state->thd_count == 0) {+      gpr_cv_signal(&g_fork_state->thd_cv);+    }+    gpr_mu_unlock(&g_fork_state->mu);+  }+}++void grpc_fork_await_thds() {+  if (g_fork_state) {+    gpr_mu_lock(&g_fork_state->mu);+    g_fork_state->awaiting_threads = true;+    gpr_cv_wait(&g_fork_state->thd_cv, &g_fork_state->mu,","We shouldn't ever have a `cv_wait` without a controlling boolean. It should always be of the form```cppwhile (!done_) {  gpr_cv_wait(&done_cv_, &mu_, gpr_inf_future....);}```and on the other side```cppgpr_mu_lock(&mu_);done_ = true;gpr_cv_signal_(&done_cv_);gpr_mu_unlock(&mu_);```The reason is twofold. First, `cv_wait` can have spurious wakeups because of interrupts, etc. Second, if you don't check if the condition is already true before waiting, you might have already missed the signal.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14647,173546469,2018-03-09T19:33:38Z,src/core/lib/gprpp/thd_posix.cc,"@@ -180,27 +152,6 @@ Thread::Thread(const char* thd_name, void (*thd_body)(void* arg), void* arg,     *success = outcome;   } }--void Thread::Init() {",These methods should also be removed from `thd.h` and `thd_windows.cc` if they're no longer part of the thread management API.,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/14615,173565197,2018-03-09T20:54:38Z,src/core/lib/security/security_connector/security_connector.cc,"@@ -465,12 +465,10 @@ static bool fake_channel_check_call_host(grpc_channel_security_connector* sc,                                          grpc_error** error) {   grpc_fake_channel_security_connector* c =       reinterpret_cast<grpc_fake_channel_security_connector*>(sc);-  if (c->is_lb_channel) {-    // TODO(dgq): verify that the host (ie, authority header) matches that of-    // the LB, as opposed to that of the backends.-  } else {-    // TODO(dgq): verify that the host (ie, authority header) matches that of-    // the backend, not the LB's.+  if (c->is_lb_channel && strcmp(host, c->target) != 0) {+    gpr_log(GPR_ERROR, ""Authority (host) '%s' != Target '%s' for an LB call"",+            host, c->target);+    abort();","Right now, several tests perform a host override when creating calls (see [here](https://github.com/grpc/grpc/blob/59ea0ae3ebcca0aef5a15c5aa5b4d27b7f3fc9c4/test/core/end2end/tests/cancel_after_round_trip.cc#L153), for example). For all tests run under [`h2_fakesec.cc`](https://github.com/grpc/grpc/blob/master/test/core/end2end/fixtures/h2_fakesec.cc), which simply plugs in the fake security, this will make `fake_channel_check_call_host()` fail. Given that the tests use ""foo.test.google.fr:1234"" as the call host override but the actual target will be something like ""localhost:34253"", I can only think of passing the call host override expectation to the fake security connector when creating it.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/14517,173593972,2018-03-09T23:27:18Z,include/grpcpp/server.h,"@@ -175,6 +153,31 @@ class Server final : public ServerInterface, private GrpcLibraryCodegen {   /// \param num_cqs How many completion queues does \a cqs hold.   void Start(ServerCompletionQueue** cqs, size_t num_cqs) override; +  grpc_server* server() override { return server_; };","Without having looked deeply into the details, using inheritance for code reuse is usually an anti-patter. Favor composition over inheritance for this.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/14615,173608691,2018-03-10T02:32:12Z,test/core/end2end/tests/default_host.cc,"@@ -216,10 +218,9 @@ static void test_invoke_simple_request(grpc_end2end_test_config config) { }  void default_host(grpc_end2end_test_config config) {-  if ((config.feature_mask & FEATURE_MASK_SUPPORTS_HOSTNAME_VERIFICATION) == 0)-    return;-  if ((config.feature_mask & FEATURE_MASK_SUPPORTS_DELAYED_CONNECTION) == 0)+  if ((config.feature_mask & FEATURE_MASK_SUPPORTS_PER_CALL_CREDENTIALS) != 0) {","note that this test wasn't being run for ANY test fixture (all of them support `FEATURE_MASK_SUPPORTS_HOSTNAME_VERIFICATION`). Right now, the only exception is h2_oauth and h2_ssl_proxy, as they require extra support that this test doesn't provide.In any case, it's now run for all other test fixtures. In particular, it validates the right authority header behavior for direct channels when run under the h2_sockpair fixture, for example.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14517,173888528,2018-03-12T17:49:19Z,include/grpcpp/server.h,"@@ -175,6 +153,31 @@ class Server final : public ServerInterface, private GrpcLibraryCodegen {   /// \param num_cqs How many completion queues does \a cqs hold.   void Start(ServerCompletionQueue** cqs, size_t num_cqs) override; +  grpc_server* server() override { return server_; };",The issue was a desire to slip in a changed server in a variant library without requiring any application changes.,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14517,173888970,2018-03-12T17:50:31Z,include/grpcpp/server_builder.h,"@@ -210,15 +210,43 @@ class ServerBuilder {   /// doc/workarounds.md.   ServerBuilder& EnableWorkaround(grpc_workaround_list id); - private:-  friend class ::grpc::testing::ServerBuilderPluginTest;-+ protected:   struct Port {     grpc::string addr;     std::shared_ptr<ServerCredentials> creds;     int* selected_port;   }; +  typedef std::unique_ptr<grpc::string> HostString;+  struct NamedService {+    explicit NamedService(Service* s) : service(s) {}+    NamedService(const grpc::string& h, Service* s)+        : host(new grpc::string(h)), service(s) {}+    HostString host;+    Service* service;+  };++  std::vector<Port> ports() { return ports_; }++  std::vector<std::reference_wrapper<NamedService>> services() {",This has just become API. Needs a gRFC or mark it experimental if you intend to deprecate it later.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/14556,173910914,2018-03-12T18:59:21Z,test/cpp/end2end/grpclb_end2end_test.cc,"@@ -191,6 +192,9 @@ class BalancerServiceImpl : public BalancerService {         shutdown_(false) {}    Status BalanceLoad(ServerContext* context, Stream* stream) override {+    // Balancer shouldn't receive the call credentials metadata.",Let's also check that the backends *do* receive this metadata key.,
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/14599,173973081,2018-03-12T22:59:56Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/dns_resolver_ares.cc,"@@ -440,6 +440,27 @@ class AresDnsResolverFactory : public ResolverFactory {  }  // namespace grpc_core +extern grpc_address_resolver_vtable* grpc_resolve_address_impl;+static grpc_address_resolver_vtable* default_resolver;++static void resolve_address_ares(const char* addr, const char* default_port,+                                 grpc_pollset_set* interested_parties,+                                 grpc_closure* on_done,+                                 grpc_resolved_addresses** addrs) {+  grpc_resolve_address_ares(addr, default_port, interested_parties, on_done,+                            addrs);+}++static grpc_error* blocking_resolve_address_ares(+    const char* name, const char* default_port,+    grpc_resolved_addresses** addresses) {+  return default_resolver->blocking_resolve_address(name, default_port,","The old mechanism for overriding the blocking resolver API relied on setting:https://github.com/grpc/grpc/blob/master/src/core/lib/iomgr/resolve_address_posix.cc#L189The ares resolver only ever used to override the async resolver API:https://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/resolver/dns/c_ares/dns_resolver_ares.cc#L453 This should not be a change in behavior.  AFAICT, the ares resolver always used the default blocking resolve address implementation. ",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14517,174008393,2018-03-13T03:31:32Z,include/grpcpp/server.h,"@@ -175,6 +153,31 @@ class Server final : public ServerInterface, private GrpcLibraryCodegen {   /// \param num_cqs How many completion queues does \a cqs hold.   void Start(ServerCompletionQueue** cqs, size_t num_cqs) override; +  grpc_server* server() override { return server_; };","Additionally, although this is moving the code from `private` to `protected`, it doesn't actually change anything because the base-class has it as `protected`. So this is not an issue.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/14599,174149277,2018-03-13T14:24:36Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/dns_resolver_ares.cc,"@@ -440,6 +440,27 @@ class AresDnsResolverFactory : public ResolverFactory {  }  // namespace grpc_core +extern grpc_address_resolver_vtable* grpc_resolve_address_impl;+static grpc_address_resolver_vtable* default_resolver;++static void resolve_address_ares(const char* addr, const char* default_port,+                                 grpc_pollset_set* interested_parties,+                                 grpc_closure* on_done,+                                 grpc_resolved_addresses** addrs) {+  grpc_resolve_address_ares(addr, default_port, interested_parties, on_done,+                            addrs);+}++static grpc_error* blocking_resolve_address_ares(+    const char* name, const char* default_port,+    grpc_resolved_addresses** addresses) {+  return default_resolver->blocking_resolve_address(name, default_port,","The reason that we did not previously override the blocking resolve address function is that the default blocking resolver address function simply calls the async version via the executor.I think this relationship would be clearer if the DNS resolver API were in C++, because we could provide the blocking version in the base class and then simply not override it in the ares-specific subclass.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/14556,174179006,2018-03-13T15:38:43Z,test/cpp/end2end/grpclb_end2end_test.cc,"@@ -125,12 +125,20 @@ class CountedService : public ServiceType { using BackendService = CountedService<TestServiceImpl>; using BalancerService = CountedService<LoadBalancer::Service>; +const char g_kCallCredsMdKey[] = ""Balancer should not ..."";+const char g_kCallCredsMdValue[] = ""... receive me"";+ class BackendServiceImpl : public BackendService {  public:   BackendServiceImpl() {}    Status Echo(ServerContext* context, const EchoRequest* request,               EchoResponse* response) override {+    // Backend should receive the call credentials metadata.+    auto call_credentials_entry =+        context->client_metadata().find(g_kCallCredsMdKey);+    EXPECT_NE(call_credentials_entry, context->client_metadata().end());","This should probably be `ASSERT_NE()`, because if the check fails, the next line will cause a crash.If `ASSERT_NE()` won't work in this context, then you can just wrap the next line in a `if (call_credentials_entry != context->client_metadata().end())` conditional.",
17325098,makdharma,https://api.github.com/repos/grpc/grpc/pulls/14517,174203686,2018-03-13T16:45:11Z,include/grpcpp/server.h,"@@ -200,8 +202,9 @@ class Server final : public ServerInterface, private GrpcLibraryCodegen {   /// the \a sync_server_cqs)   std::vector<std::unique_ptr<SyncRequestThreadManager>> sync_req_mgrs_; -  // Sever status+  // Server status   std::mutex mu_;+  // Server status",my bad. done.,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14680,174643985,2018-03-14T23:54:06Z,test/cpp/end2end/async_end2end_test.cc,"@@ -486,7 +486,7 @@ TEST_P(AsyncEnd2endTest, DoThenAsyncNextRpc) {   auto recv_resp_ptr = &recv_response;   auto status_ptr = &recv_status;   send_response.set_message(recv_request.message());-  auto lambda_3 = [&, this, resp_writer_ptr, send_response]() {+  auto lambda_3 = [&, resp_writer_ptr, send_response]() {     resp_writer_ptr->Finish(send_response, Status::OK, tag(3));","Actually, this one is bad for another reason. We really shouldn't have anonymous captures.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/14716,174651603,2018-03-15T00:49:07Z,bazel/grpc_build_system.bzl,"@@ -57,24 +57,17 @@ def _maybe_update_cc_library_hdrs(hdrs):       ret.append(h)   return ret -def _maybe_update_cc_library_defines(name):-  ret = []-  if name == ""alts_proto"":","double checking, the generated output no longer needs `PB_FIELD_16BIT=1` ?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/13634,174687030,2018-03-15T06:29:35Z,src/ruby/spec/pb/package_with_underscore/checker_spec.rb,"@@ -0,0 +1,50 @@+# Copyright 2016 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++require 'open3'+require 'tmpdir'++describe 'Package with underscore protobuf code generation' do+  it 'should have the same content as created by code generation' do+    root_dir = File.join(File.dirname(__FILE__), '..', '..', '..', '..', '..')+    pb_dir = File.join(root_dir, 'src', 'ruby', 'spec', 'pb')++    bins_sub_dir = ENV['DEBUG'].nil? ? 'opt' : 'dbg'",it looks like you're checking the wrong environment variable here. Change `DEBUG` to `CONFIG` and this should work (see https://github.com/grpc/grpc/blob/master/tools/run_tests/run_tests.py#L142)FYI one way to run this test both configs locally is by running`tools/run_tests/run_tests.py -l ruby -c dbg`and `tools/run_tests/run_tests.py -l ruby -c opt`,
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/14722,174944876,2018-03-15T21:55:19Z,src/core/tsi/ssl_transport_security.h,"@@ -77,9 +92,9 @@ typedef struct {      where a parameter is invalid.  */ tsi_result tsi_create_ssl_client_handshaker_factory(     const tsi_ssl_pem_key_cert_pair* pem_key_cert_pair,-    const char* pem_root_certs, const char* cipher_suites,-    const char** alpn_protocols, uint16_t num_alpn_protocols,-    tsi_ssl_client_handshaker_factory** factory);+    const char* pem_root_certs, const ssl_root_certs_store* root_store,",I would actually prefer that we don't change this *public* API. What would be nice is to have `tsi_create_ssl_client_handhaker_factory_with_options` using an option struct with the existing params (+ the store) and deprecate the old one.,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/14680,174947312,2018-03-15T22:06:18Z,test/core/gprpp/inlined_vector_test.cc,"@@ -87,14 +87,14 @@ TEST(InlinedVectorTest, ClearAndRepopulate) { }  TEST(InlinedVectorTest, ConstIndexOperator) {-  const int kNumElements = 10;+  constexpr int kNumElements = 10;   InlinedVector<int, 5> v;   EXPECT_EQ(0UL, v.size());   for (int i = 0; i < kNumElements; ++i) {     v.push_back(i);     EXPECT_EQ(i + 1UL, v.size());   }-  auto const_func = [kNumElements](const InlinedVector<int, 5>& v) {+  auto const_func = [](const InlinedVector<int, 5>& v) {","Here's a quick way to play with it: https://godbolt.org/g/cepeMR You can choose clang 5.0 as well, adding the flags `-std=c++11 -Wunused-lambda-capture -Werror`",
961599,murgatroid99,https://api.github.com/repos/grpc/grpc/pulls/14728,175170709,2018-03-16T17:59:23Z,tools/interop_matrix/client_matrix.py,"@@ -200,7 +200,15 @@ def should_build_docker_interop_image_from_release_tag(lang):         {             'v1.6.6': None         },-        #{'v1.7.1': None}, Failing tests+        {+            'v1.7.2': None","yes, I just verified that all three of those versions are in the GCR tag list.",
35056280,srini100,https://api.github.com/repos/grpc/grpc/pulls/14650,175297585,2018-03-18T17:55:13Z,src/objective-c/NetworkBehavior.md,"@@ -0,0 +1,45 @@+",Suggest renaming the doc to NetworkTransitionBehavior.md,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/14561,175465513,2018-03-19T14:59:25Z,src/python/grpcio/grpc/_cython/_cygrpc/grpc_gevent.pyx,"@@ -0,0 +1,452 @@+# Copyright 2018 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+# distutils: language=c++++cimport cpython+from libc cimport string+from libc.stdlib cimport malloc, free+import errno+gevent_g = None+gevent_socket = None+gevent_hub = None+gevent_event = None++cdef grpc_error* grpc_error_none():+  return <grpc_error*>0++cdef grpc_error* socket_error(str syscall, str err):+  error_str = ""{} failed: {}"".format(syscall, err)+  error_bytes = str_to_bytes(error_str)+  return grpc_socket_error(error_bytes)++cdef resolved_addr_to_tuple(grpc_resolved_address* address):+  cdef char* res_str+  port = grpc_sockaddr_get_port(address)+  str_len = grpc_sockaddr_to_string(&res_str, address, 0) +  byte_str = _decode(<bytes>res_str[:str_len])+  if byte_str.endswith(':' + str(port)):+    byte_str = byte_str[:(0 - len(str(port)) - 1)]+  byte_str = byte_str.lstrip('[')+  byte_str = byte_str.rstrip(']')+  byte_str = '{}'.format(byte_str)+  return (byte_str, port)++cdef sockaddr_to_tuple(const grpc_sockaddr* address, size_t length):+  cdef grpc_resolved_address c_addr+  string.memcpy(<void*>c_addr.addr, <void*> address, length)+  c_addr.len = length+  return resolved_addr_to_tuple(&c_addr)++cdef sockaddr_is_ipv4(const grpc_sockaddr* address, size_t length):+  cdef grpc_resolved_address c_addr+  string.memcpy(<void*>c_addr.addr, <void*> address, length)+  c_addr.len = length+  return grpc_sockaddr_get_uri_scheme(&c_addr) == b'ipv4'++cdef grpc_resolved_addresses* tuples_to_resolvaddr(tups):+  cdef grpc_resolved_addresses* addresses+  tups_set = set([(tup[4][0], tup[4][1]) for tup in tups])+  addresses = <grpc_resolved_addresses*> malloc(sizeof(grpc_resolved_addresses))+  addresses.naddrs = len(tups_set)+  addresses.addrs = <grpc_resolved_address*> malloc(sizeof(grpc_resolved_address) * len(tups_set))+  i = 0+  for tup in set(tups_set):+    hostname = str_to_bytes(tup[0])+    grpc_string_to_sockaddr(&addresses.addrs[i], hostname, tup[1])+    i += 1+  return addresses++def _spawn_greenlet(*args):+  greenlet = gevent_g.spawn(*args)++###############################+### socket implementation ###+###############################++cdef class SocketWrapper:+  def __cinit__(self):+    self.sockopts = []+    self.socket = None+    self.c_socket = NULL+    self.c_buffer = NULL+    self.len = 0++cdef grpc_error* socket_init(grpc_custom_socket* socket, int domain) with gil:+  sw = SocketWrapper()+  sw.c_socket = socket+  sw.sockopts = []+  cpython.Py_INCREF(sw)+  # Python doesn't support AF_UNSPEC sockets, so we defer creation until+  # bind/connect when we know what type of socket we need+  sw.socket = None+  sw.closed = False+  sw.accepting_socket = NULL+  socket.impl = <void*>sw+  return grpc_error_none()++cdef socket_connect_async_cython(SocketWrapper socket_wrapper, addr_tuple):+  try:+    socket_wrapper.socket.connect(addr_tuple)+    socket_wrapper.connect_cb(<grpc_custom_socket*>socket_wrapper.c_socket,+                              grpc_error_none())+  except IOError as e:","`as io_error:` - it's true that the IOError is an Exception, but its being an exception is the least interesting true thing about it.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/14561,175466613,2018-03-19T15:02:01Z,src/python/grpcio/grpc/_cython/_cygrpc/grpc_gevent.pyx,"@@ -0,0 +1,452 @@+# Copyright 2018 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+# distutils: language=c++++cimport cpython+from libc cimport string+from libc.stdlib cimport malloc, free+import errno+gevent_g = None+gevent_socket = None+gevent_hub = None+gevent_event = None++cdef grpc_error* grpc_error_none():+  return <grpc_error*>0++cdef grpc_error* socket_error(str syscall, str err):+  error_str = ""{} failed: {}"".format(syscall, err)+  error_bytes = str_to_bytes(error_str)+  return grpc_socket_error(error_bytes)++cdef resolved_addr_to_tuple(grpc_resolved_address* address):+  cdef char* res_str+  port = grpc_sockaddr_get_port(address)+  str_len = grpc_sockaddr_to_string(&res_str, address, 0) +  byte_str = _decode(<bytes>res_str[:str_len])+  if byte_str.endswith(':' + str(port)):+    byte_str = byte_str[:(0 - len(str(port)) - 1)]+  byte_str = byte_str.lstrip('[')+  byte_str = byte_str.rstrip(']')+  byte_str = '{}'.format(byte_str)+  return (byte_str, port)++cdef sockaddr_to_tuple(const grpc_sockaddr* address, size_t length):+  cdef grpc_resolved_address c_addr+  string.memcpy(<void*>c_addr.addr, <void*> address, length)+  c_addr.len = length+  return resolved_addr_to_tuple(&c_addr)++cdef sockaddr_is_ipv4(const grpc_sockaddr* address, size_t length):+  cdef grpc_resolved_address c_addr+  string.memcpy(<void*>c_addr.addr, <void*> address, length)+  c_addr.len = length+  return grpc_sockaddr_get_uri_scheme(&c_addr) == b'ipv4'++cdef grpc_resolved_addresses* tuples_to_resolvaddr(tups):+  cdef grpc_resolved_addresses* addresses+  tups_set = set([(tup[4][0], tup[4][1]) for tup in tups])+  addresses = <grpc_resolved_addresses*> malloc(sizeof(grpc_resolved_addresses))+  addresses.naddrs = len(tups_set)+  addresses.addrs = <grpc_resolved_address*> malloc(sizeof(grpc_resolved_address) * len(tups_set))+  i = 0+  for tup in set(tups_set):+    hostname = str_to_bytes(tup[0])+    grpc_string_to_sockaddr(&addresses.addrs[i], hostname, tup[1])+    i += 1+  return addresses++def _spawn_greenlet(*args):+  greenlet = gevent_g.spawn(*args)++###############################+### socket implementation ###+###############################++cdef class SocketWrapper:+  def __cinit__(self):+    self.sockopts = []+    self.socket = None+    self.c_socket = NULL+    self.c_buffer = NULL+    self.len = 0++cdef grpc_error* socket_init(grpc_custom_socket* socket, int domain) with gil:+  sw = SocketWrapper()+  sw.c_socket = socket+  sw.sockopts = []+  cpython.Py_INCREF(sw)+  # Python doesn't support AF_UNSPEC sockets, so we defer creation until+  # bind/connect when we know what type of socket we need+  sw.socket = None+  sw.closed = False+  sw.accepting_socket = NULL+  socket.impl = <void*>sw+  return grpc_error_none()++cdef socket_connect_async_cython(SocketWrapper socket_wrapper, addr_tuple):+  try:+    socket_wrapper.socket.connect(addr_tuple)+    socket_wrapper.connect_cb(<grpc_custom_socket*>socket_wrapper.c_socket,+                              grpc_error_none())+  except IOError as e:+    socket_wrapper.connect_cb(<grpc_custom_socket*>socket_wrapper.c_socket,+                              socket_error(""connect"", str(e)))+  g_event.set()++def socket_connect_async(socket_wrapper, addr_tuple):+  socket_connect_async_cython(socket_wrapper, addr_tuple)++cdef void socket_connect(grpc_custom_socket* socket, const grpc_sockaddr* addr,+                         size_t addr_len,+                         grpc_custom_connect_callback cb) with gil:+  py_socket = None+  socket_wrapper = <SocketWrapper>socket.impl+  socket_wrapper.connect_cb = cb+  addr_tuple = sockaddr_to_tuple(addr, addr_len)+  if sockaddr_is_ipv4(addr, addr_len):+      py_socket = gevent_socket.socket(gevent_socket.AF_INET)+  else:+      py_socket = gevent_socket.socket(gevent_socket.AF_INET6)+  applysockopts(py_socket)+  socket_wrapper.socket = py_socket+  _spawn_greenlet(socket_connect_async, socket_wrapper, addr_tuple)++cdef void socket_destroy(grpc_custom_socket* socket) with gil:+  cpython.Py_DECREF(<SocketWrapper>socket.impl)++cdef void socket_shutdown(grpc_custom_socket* socket) with gil:+  try:+    (<SocketWrapper>socket.impl).socket.shutdown(gevent_socket.SHUT_RDWR)+  except IOError as e:+    if e.errno == errno.ENOTCONN:+      pass+    else:+      raise e++cdef void socket_close(grpc_custom_socket* socket,+                       grpc_custom_close_callback cb) with gil:+  socket_wrapper = (<SocketWrapper>socket.impl)+  if socket_wrapper.socket is not None:+    socket_wrapper.socket.close()+    socket_wrapper.closed = True+    socket_wrapper.close_cb = cb+    # Delay the close callback until the accept() call has picked it up+    if socket_wrapper.accepting_socket != NULL:+      return+  socket_wrapper.close_cb(socket)++def socket_sendmsg(socket, write_bytes):+  try:+    return socket.sendmsg(write_bytes)+  except AttributeError:+    # sendmsg not available on all Pythons/Platforms+    return socket.send(b''.join(write_bytes))++cdef socket_write_async_cython(SocketWrapper socket_wrapper, write_bytes):+  try:+    while write_bytes:+      ret = socket_sendmsg(socket_wrapper.socket, write_bytes)",`ret` is always a bad identifier name even when it is used for the return value of the behavior in which it is located... but even that's not the case for this `ret`. What's a better name for this?,
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/14483,175490441,2018-03-19T16:04:24Z,src/core/tsi/ssl_session.h,"@@ -0,0 +1,73 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_TSI_SSL_SESSION_H+#define GRPC_CORE_TSI_SSL_SESSION_H++#include <grpc/support/port_platform.h>++#include <grpc/slice.h>++extern ""C"" {+#include <openssl/ssl.h>","TSI header should not depend on ssl.h. TSI header also needs to be in C API. Therefore, please write in C. This is similar to the transport_security_interface.h.E.g., ```typedef struct tsi_ssl_cached_session tsi_ssl_cached_session;tsi_ssl_cached_session_create();...tsi_ssl_cached_session_destroy(tsi_ssl_cached_session self);```In ssl_session_boringssl.cc and ssl_session_openssl.cc implementations, you can still use c++. Later, you can write a wrapper to plumb the c++ implementation in the C interface.",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/14483,175496281,2018-03-19T16:21:48Z,src/core/tsi/ssl_session_cache.h,"@@ -0,0 +1,93 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_TSI_SSL_SESSION_CACHE_H+#define GRPC_CORE_TSI_SSL_SESSION_CACHE_H++#include <grpc/support/port_platform.h>++#include <grpc/slice.h>+#include <grpc/support/sync.h>++extern ""C"" {+#include <openssl/ssl.h>","Same ssl_session.h, please keep this header in C and make it independent of ssl.h.Basically, you can merge this file into ssl_session_cache.cc. But define C header here.```typedef struct tsi_ssl_session_lru_cache tsi_ssl_session_lru_cache；typedef struct tsi_ssl_session_ptr tsi_ssl_session_ptr;tsi_ssl_session_lru_cache tsi_ssl_session_lru_cache_create(size_t capacity);size_t tsi_ssl_session_lru_cache_size(tsi_ssl_session_lru_cache* cache);void tsi_ssl_session_lru_cache_put(tsi_ssl_session_lru_cache* cache, ...);tsi_ssl_session_lru_cache tsi_ssl_session_lru_cache_get(const char* key);void tsi_ssl_session_lru_cache_destroy(tsi_ssl_session_lru_cache* cache);```",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/14483,175501574,2018-03-19T16:37:13Z,src/core/tsi/ssl_transport_security.h,"@@ -132,6 +138,7 @@ tsi_result tsi_create_ssl_server_handshaker_factory(     size_t num_key_cert_pairs, const char* pem_client_root_certs,     int force_client_auth, const char* cipher_suites,     const char** alpn_protocols, uint16_t num_alpn_protocols,+    const char* session_ticket_key, size_t session_ticket_key_size,","Same as tsi_create_ssl_client_handshaker_factory. Let us not change tsi_create_ssl_server_handshaker_factory and tsi_create_ssl_server_handshaker_factory_ex. Keep them as it is (for backward compatibility). We can mark as deprecate if need.Create a new `tsi_create_ssl_server_handshaker_factory_with_options(tsi_ssl_server_handshaker_options* options, tsi_ssl_server_handshaker_factory** factory);`",
83361,euroelessar,https://api.github.com/repos/grpc/grpc/pulls/14483,175513393,2018-03-19T17:10:06Z,include/grpc/grpc_security.h,"@@ -100,6 +100,25 @@ GRPCAPI void grpc_auth_context_add_cstring_property(grpc_auth_context* ctx, GRPCAPI int grpc_auth_context_set_peer_identity_property_name(     grpc_auth_context* ctx, const char* name); +/** --- SSL Session Cache. ---++    A SSL session cache object represents a way to cache client sessions+    between connections. Only ticket-based resumption is supported. */++typedef struct grpc_ssl_session_cache grpc_ssl_session_cache;++/** Create LRU cache for client-side SSL sessions with the given capacity.+    If capacity is < 1, a default capacity is used instead. */+GRPCAPI grpc_ssl_session_cache* grpc_ssl_session_cache_create_lru(","LRU is one of the possible cache implementations, I'm leaving free space open to define other data structures at later point of time, e.g. for user-defined implementations, shared-memory-based ones, etc.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/14755,175699510,2018-03-20T09:29:27Z,tools/interop_matrix/client_matrix.py,"@@ -293,3 +293,21 @@ def should_build_docker_interop_image_from_release_tag(lang):         },     ], }++# This matrix lists the version of testcases to use for a release. As new",Any good reason why isn't this data part of the LANG_RELEASE_MATRIX  data structure? It seems to me that this is exactly the data that belongs in it - so I don't understand why we are introducing an adhoc data structure TESTCASES_VERSION_MATRIX.,
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/14541,176264485,2018-03-21T22:52:44Z,include/grpcpp/impl/codegen/proto_buffer_reader.h,"@@ -0,0 +1,136 @@+/*+ *+ * Copyright 2015 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPCPP_IMPL_CODEGEN_PROTO_BUFFER_READER_H+#define GRPCPP_IMPL_CODEGEN_PROTO_BUFFER_READER_H++#include <type_traits>++#include <grpc/impl/codegen/byte_buffer_reader.h>+#include <grpc/impl/codegen/grpc_types.h>+#include <grpc/impl/codegen/slice.h>+#include <grpcpp/impl/codegen/byte_buffer.h>+#include <grpcpp/impl/codegen/config_protobuf.h>+#include <grpcpp/impl/codegen/core_codegen_interface.h>+#include <grpcpp/impl/codegen/serialization_traits.h>+#include <grpcpp/impl/codegen/status.h>++namespace grpc {++extern CoreCodegenInterface* g_core_codegen_interface;++/// An implementation of the ZeroCopyInputStream interface that uses+/// \a grpc::ByteBuffer as the source of bytes from which to read.+///+/// Read more about ZeroCopyInputStream interface here:+/// https://developers.google.com/protocol-buffers/docs/reference/cpp/google.protobuf.io.zero_copy_stream#ZeroCopyInputStream+///+/// This is use to deserialize a contiguous stream of bytes into a Proto+/// message. It may be inherited from to provide user application specific+/// optimizations.+class GrpcProtoBufferReader : public ::grpc::protobuf::io::ZeroCopyInputStream {+ public:+  /// Constructs buffer reader from \a buffer. Will set status to non ok if+  /// \a buffer is invalid (the internal buffer has not been initialized).+  explicit GrpcProtoBufferReader(ByteBuffer* buffer)+      : byte_count_(0), backup_count_(0), status_() {+    if (!buffer->Valid() ||+        !g_core_codegen_interface->grpc_byte_buffer_reader_init(+            &reader_, buffer->c_buffer())) {+      status_ = Status(StatusCode::INTERNAL,","That makes sense to me. @vjpai, do you agree with this stylistically?",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/14788,176276243,2018-03-22T00:01:14Z,bazel/grpc_build_system.bzl,"@@ -108,7 +108,7 @@ def grpc_proto_library(name, srcs = [], deps = [], well_known_protos = False,     generate_mock = generate_mock,   ) -def grpc_cc_test(name, srcs = [], deps = [], external_deps = [], args = [], data = [], uses_polling = True, language = ""C++""):+def grpc_cc_test(name, srcs = [], deps = [], external_deps = [], args = [], data = [], uses_polling = True, language = ""C++"", size = ""medium""):","it seems ""small"" may be a better default. From the docs:> Unittests are considered ""small"", integration tests ""medium"", and end-to-end tests ""large"" or ""enormous"". Blaze uses the size to determine a default timeout (which can be overridden using the ""timeout"" attribute) and the amount of resources that have to be acquired for the test to run. The mapping of test size to resource is currently:",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/14788,176276446,2018-03-22T00:02:35Z,test/core/util/grpc_fuzzer.bzl,"@@ -23,6 +23,7 @@ def grpc_fuzzer(name, corpus, srcs = [], deps = [], **kwargs):     external_deps = [       'gtest',     ],+    size = ""enormous"",","out of curiosity, are they really that large? https://docs.bazel.build/versions/master/be/common-definitions.html#test.size indicates that that'd require 800 MB of memory. Maybe we want to use ""timeout"" instead of ""size""? See https://docs.bazel.build/versions/master/be/common-definitions.html#test.timeout",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14795,176430696,2018-03-22T14:04:19Z,tools/profiling/latency_profile/profile_analyzer.py,"@@ -184,24 +184,24 @@ def finish(self):  def percentile(N, percent, key=lambda x: x):     """"""-    Find the percentile of a list of values.+    Find the percentile of an already sorted list of values. -    @parameter N - is a list of values. Note N MUST BE already sorted.-    @parameter percent - a float value from 0.0 to 1.0.+    @parameter N - is a list of values. MUST be already sorted.+    @parameter percent - a float value from [0.0,1.0].     @parameter key - optional key function to compute value from each element of N.      @return - the percentile of the values     """"""     if not N:         return None-    k = (len(N) - 1) * percent-    f = math.floor(k)-    c = math.ceil(k)-    if f == c:-        return key(N[int(k)])-    d0 = key(N[int(f)]) * (c - k)-    d1 = key(N[int(c)]) * (k - f)-    return d0 + d1+    idx = (len(N) - 1) * percent+    idx_floor = math.floor(idx)+    idx_ceil = math.ceil(idx)+    if idx_floor != idx_ceil:+        # interpolate the nearest element values+        return (key(N[int(idx_floor)]) * (idx_ceil - idx) ++                key(N[int(idx_ceil)]) * (idx - idx_floor))+    return key(N[int(idx)])","You can eliminate idx_floor, idx_ceil, and the if condition altogether if you do:return key(N[int(idx)]) + (idx - int(idx)) * (key(N[int(idx)+1]) - key(N[int(idx)]))",
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/14784,176490455,2018-03-22T16:41:49Z,bazel/cc_grpc_library.bzl,"@@ -16,7 +16,7 @@ def cc_grpc_library(name, srcs, deps, proto_only, well_known_protos, generate_mo         protos       use_external: When True the grpc deps are prefixed with //external. This         allows grpc to be used as a dependency in other bazel projects.-      generate_mock: When true GMOCk code for client stub is generated.+      generate_mocks: When true GMOCk code for client stub is generated.","Updated comments, the mocking library is called ""Google Mock"" in OSS.",
14932100,adelez,https://api.github.com/repos/grpc/grpc/pulls/14788,176508036,2018-03-22T17:32:47Z,bazel/grpc_build_system.bzl,"@@ -108,7 +108,7 @@ def grpc_proto_library(name, srcs = [], deps = [], well_known_protos = False,     generate_mock = generate_mock,   ) -def grpc_cc_test(name, srcs = [], deps = [], external_deps = [], args = [], data = [], uses_polling = True, language = ""C++""):+def grpc_cc_test(name, srcs = [], deps = [], external_deps = [], args = [], data = [], uses_polling = True, language = ""C++"", size = ""medium""):","I used medium as the default value because because that's what Bazel doc says, so that's the size used by all tests currently. I wonder what it actually implies if the stated size is larger than the actual one?",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/14801,176794935,2018-03-23T16:40:51Z,src/python/grpcio/grpc/_cython/_cygrpc/call.pyx.pxi,"@@ -30,9 +30,12 @@ cdef class Call:         tag, operations, self if retain_self else None)     batch_operation_tag.prepare()     cpython.Py_INCREF(batch_operation_tag)-    return grpc_call_start_batch(+    cdef grpc_call_error error+    with nogil:+      error = grpc_call_start_batch(","nit:  We should be able to just ```return``` out of the ```with``` statement, so we don't need to store ```error``` in a temporary variable (unless cython doesn't support that syntax, in which case disregard).",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/14387,177170862,2018-03-26T17:23:31Z,test/core/security/security_connector_test.cc,"@@ -28,6 +28,7 @@ #include ""src/core/lib/gpr/string.h"" #include ""src/core/lib/gpr/tmpfile.h"" #include ""src/core/lib/security/context/security_context.h""+#include ""src/core/lib/security/security_connector/security_connector.cc""","Please don't include .cc file in the header. You can make ssl_host_matches_name() a non-static function, and add the function declaration at security_connector.h, on the section of ""exposed for testing only"".https://github.com/grpc/grpc/blob/master/src/core/lib/security/security_connector/security_connector.h#L245In the future, security_connector will be re-written in C++, we will have better way of testing through mock testing class.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14819,177521580,2018-03-27T18:13:35Z,src/core/lib/gprpp/fixed_capacity_vector.h,"@@ -0,0 +1,106 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_GPRPP_FIXED_CAPACITY_VECTOR_H+#define GRPC_CORE_LIB_GPRPP_FIXED_CAPACITY_VECTOR_H++#include <grpc/support/port_platform.h>++#include <cassert>++#include ""src/core/lib/gprpp/memory.h""++namespace grpc_core {++// This is similar to std::vector<>, except that its capacity is fixed at+// construction time.  This allows allocating the entire vector in a+// single memory allocation.++// TODO(roth): This interface does not currently implement all methods+// supported by STL containers (e.g., iterators).  Those can be added as+// needed.++template <typename T>+class FixedCapacityVector {+ public:+  static UniquePtr<FixedCapacityVector> Create(size_t capacity) {+    // Allocate space for both this object and the elements.+    FixedCapacityVector* v = static_cast<FixedCapacityVector*>(+        gpr_malloc(sizeof(FixedCapacityVector) + (capacity * sizeof(T))));","So FixedCapacityVector is likely to have size 8, which would make the actual data located here to be on an offset of 8 relative to the 16-aligned block returned by malloc. Is there any situation where the actual data array needs to be 16-aligned?",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/14830,177659156,2018-03-28T07:27:42Z,examples/android/helloworld/app/CMakeLists.txt,"@@ -26,6 +26,10 @@ add_library(libgpr STATIC IMPORTED) set_target_properties(libgpr PROPERTIES IMPORTED_LOCATION   ${GRPC_BUILD_DIR}/libgpr.a) +add_library(libaddress_sorting STATIC IMPORTED)","Needing to do this is an indication of  the this CMakeLists.txt being flawed. In this particular case, I think here's what's wrong:- you include grpc sources using add_subdirectory()  (that itself is one of the fair approaches)- grpc's CMakeLists.txt defines grpc targets  (I think here they would be referred to as e.g. `gRPC::libgrpc`), but you are not using them- you are defining your own imported targets  (by using `libgrpc STATIC IMPORTED` and specifying the file path). That way, the metadata of the original grpc targets is not preserved (e.g. the imported targets don't know what their dependencies are, so you need to re-define all of them manually and include them in the helloworld targets)- I think this should be fixable by getting rid of all the imported targets, and using the `gRPC::xyz`  and `protobuf::xyz` targets instead.  ",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/14830,177659738,2018-03-28T07:30:01Z,examples/android/helloworld/app/CMakeLists.txt,"@@ -113,6 +117,7 @@ target_include_directories(grpc-helloworld target_link_libraries(grpc-helloworld   libgrpc++","replace by `grpc::libgrpc++` and get rid of all the explicit dependencies.I think the `grpc::`  is the ""project name"" from here: https://github.com/grpc/grpc/blob/d9ec9068c7e7b38379229ea10b6b55d43e8dc549/CMakeLists.txt#L31",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/14822,177970749,2018-03-29T07:19:16Z,test/distrib/cpp/run_distrib_test_cmake_as_externalproject.sh,"@@ -0,0 +1,41 @@+#!/bin/bash+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++set -ex++cd ""$(dirname ""$0"")/../../..""++echo ""deb http://ftp.debian.org/debian jessie-backports main"" | tee /etc/apt/sources.list.d/jessie-backports.list+apt-get update+apt-get install -t jessie-backports -y libssl-dev++# To increase the confidence that gRPC installation works without depending on+# too many submodules unnecessarily, just wipe out contents of most submodules+# before starting the test.+rm -r third_party/abseil-cpp/* || true+rm -r third_party/benchmark/* || true+rm -r third_party/bloaty/* || true+rm -r third_party/boringssl/* || true+rm -r third_party/boringssl-with-bazel/* || true+rm -r third_party/gflags/* || true+rm -r third_party/googletest/* || true++# Build helloworld example using cmake superbuild+cd examples/cpp/helloworld/cmake_externalproject+mkdir -p cmake/build+cd cmake/build+cmake ../..+make","It is not so simple, the distribtests there can be up to 6 parallel jobs being built at the same time -> which could end up clogging the VM. I'll keep this in mind once optimizing overall runtime of our tests.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12434,178130366,2018-03-29T17:39:54Z,doc/connectivity-semantics-and-api.md,"@@ -28,7 +28,10 @@ through TLS handshake (or equivalent) and all subsequent attempt to communicate have succeeded (or are pending without any known failure ).  TRANSIENT_FAILURE: There has been some transient failure (such as a TCP 3-way-handshake timing out or a socket error). Channels in this state will eventually+handshake timing out or a socket error). New RPCs should, by default, fail","I see your point, but I think we can improve the wording here without adding too much complexity.  For example, how about changing ""New RPCs"" to ""New RPCs that encounter these errors""?  That way, we're making it clear that this state indicates these kinds of failures and that these failures cause certain behavior for RPCs, without actually explicitly tying the RPC behavior to the state.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/14864,178153386,2018-03-29T19:04:54Z,examples/cpp/helloworld/CMakeLists.txt,"@@ -27,22 +27,55 @@ else()   add_definitions(-D_WIN32_WINNT=0x600) endif() -# Find Protobuf installation-# Looks for protobuf-config.cmake file installed by Protobuf's cmake installation.-set(protobuf_MODULE_COMPATIBLE TRUE)-find_package(Protobuf CONFIG REQUIRED)-message(STATUS ""Using protobuf ${protobuf_VERSION}"")+if(GRPC_AS_SUBMODULE)+  # One way to build a projects that uses gRPC is to just include the+  # entire gRPC project tree via ""add_subdirectory"".+  # This approach is very simple to use, but the are some potential+  # disadvantages:+  # * it includes gRPC's CMakeLists.txt directly into your build script+  #   without and that can make gRPC's internal setting interfere with your+  #   own build.+  # * depending on what's installed on your system, the contents of submodules+  #   in gRPC's third_party/* might need to be available (and there might be+  #   additional prerequisites required to build them). Consider using+  #   the gRPC_*_PROVIDER options to fine-tune the expected behavior.+  #+  # A more robust approach to add dependency on gRPC is using+  # cmake's ExternalProject_Add (see cmake_externalproject/CMakeLists.txt).+  +  # Include the gRPC's cmake build (normally grpc source code would live+  # in a git submodule called ""third_party/grpc"", but this example lives in+  # the same repository as gRPC sources, so we just look a few directories up)+  add_subdirectory(../../.. ${CMAKE_CURRENT_BINARY_DIR}/grpc EXCLUDE_FROM_ALL)+  message(STATUS ""Using gRPC via add_subdirectory."")+  +  # After using add_subdirectory, we can now use the grpc targets directly from+  # this build.+  set(_PROTOBUF_LIBPROTOBUF libprotobuf)+  set(_PROTOBUF_PROTOC $<TARGET_FILE:protoc>)+  set(_GRPC_GRPCPP_UNSECURE grpc++_unsecure)+  set(_GRPC_CPP_PLUGIN_EXECUTABLE $<TARGET_FILE:grpc_cpp_plugin>)+else()+  # This branch assumes that gRPC and all its dependencies are already installed+  # on this system, so they can be located by find_package().++  # Find Protobuf installation+  # Looks for protobuf-config.cmake file installed by Protobuf's cmake installation.+  set(protobuf_MODULE_COMPATIBLE TRUE)+  find_package(Protobuf CONFIG REQUIRED)+  message(STATUS ""Using protobuf ${protobuf_VERSION}"") -set(_PROTOBUF_LIBPROTOBUF protobuf::libprotobuf)-set(_PROTOBUF_PROTOC $<TARGET_FILE:protobuf::protoc>)+  set(_PROTOBUF_LIBPROTOBUF protobuf::libprotobuf)",nit: can the```set(_PROTOBUF_LIBPROTOBUF libprotobuf)set(_PROTOBUF_PROTOC $<TARGET_FILE:protoc>)set(_GRPC_GRPCPP_UNSECURE grpc++_unsecure)set(_GRPC_CPP_PLUGIN_EXECUTABLE $<TARGET_FILE:grpc_cpp_plugin>)```be de-duped from the each of the conditional branches here?,
35056280,srini100,https://api.github.com/repos/grpc/grpc/pulls/12434,178483579,2018-04-02T03:50:01Z,doc/connectivity-semantics-and-api.md,"@@ -28,7 +28,10 @@ through TLS handshake (or equivalent) and all subsequent attempt to communicate have succeeded (or are pending without any known failure ).  TRANSIENT_FAILURE: There has been some transient failure (such as a TCP 3-way-handshake timing out or a socket error). Channels in this state will eventually+handshake timing out or a socket error). New RPCs will fail immediately with+status UNAVAILABLE, but implementations may support options like",Add a similar sentence to explain what happens to new RPCs when channel is in CONNECTING state.,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14883,178603800,2018-04-02T17:55:02Z,include/grpcpp/impl/codegen/byte_buffer.h,"@@ -98,6 +100,7 @@ class ByteBuffer final {   private:   friend class SerializationTraits<ByteBuffer, void>;+  friend class ServerInterface;",I believe that this line is not an API change since ServerInterface is a class fully-defined internally and friendship is not inherited. No objections to that line.,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14883,178604173,2018-04-02T17:56:21Z,include/grpcpp/impl/codegen/server_interface.h,"@@ -185,13 +186,17 @@ class ServerInterface : public internal::CallHook {           notification_cq_(notification_cq),           tag_(tag),           request_(request) {-      IssueRequest(registered_method, &payload_, notification_cq);+      IssueRequest(registered_method, payload_.c_buffer_ptr(), notification_cq);","Can you change that to the polymorphic `bbuf_ptr` instead of `c_buffer_ptr` ? We should deprecate the latter soon, and the former allows us to define `IssueRequest` differently without additional changes.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14883,178604576,2018-04-02T17:57:43Z,include/grpcpp/impl/codegen/server_interface.h,"@@ -219,7 +224,7 @@ class ServerInterface : public internal::CallHook {     ServerCompletionQueue* const notification_cq_;     void* const tag_;     Message* const request_;-    grpc_byte_buffer* payload_;+    ByteBuffer payload_;","This again is not an API change, IMO. Although it is changing a protected data member which could technically be viewed by a subclass, it was actually a style violation to have protected data members (as opposed to methods) at all (and that'll be fixed by #14648). As a result, they're not considered API. So this is fine too.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14541,178688351,2018-04-03T00:50:35Z,test/cpp/util/byte_buffer_test.cc,"@@ -27,6 +28,9 @@ #include <gtest/gtest.h>  namespace grpc {++static internal::GrpcLibraryInitializer g_gli_initializer;",Was there a reason to move all of the implementation of slice and bytebuffer into the headers? I assume that that is why there is an explicit initializer in the test. It looks a little awkward to have a library initializer in a test like this,
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/14541,178856571,2018-04-03T15:03:55Z,test/cpp/util/byte_buffer_test.cc,"@@ -27,6 +28,9 @@ #include <gtest/gtest.h>  namespace grpc {++static internal::GrpcLibraryInitializer g_gli_initializer;","My reason for moving those implementations to headers was to make it reachable from codegen. There is a test, codegen_test_minimal, that is designed to ensure that cogegen doesn't pull in dependancies on grpc++. I initially had linker errors on that test, and inlining some of the slice and byte_buffer implementation seemed to be the best and cleanest fix.The c implementations can hide behind core_codegen_interface, but we have no such mechanism for c++",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/14919,178979511,2018-04-03T22:24:07Z,src/core/lib/iomgr/tcp_custom.h,"@@ -62,8 +62,7 @@ typedef struct grpc_socket_vtable {                              const grpc_sockaddr* addr, int* len);   grpc_error* (*getsockname)(grpc_custom_socket* socket,                              const grpc_sockaddr* addr, int* len);-  grpc_error* (*setsockopt)(grpc_custom_socket* socket, int level, int optname,-                            const void* optval, uint32_t optlen);+  grpc_error* (*setsockopt)(grpc_custom_socket* socket);","This seems reasonable for now.This will also have to be changed in ```src/python/grpcio/grpc/_cython/_cygrpc/grpc_gevent.pyx``` and ```src/python/grpcio/grpc/_cython/_cygrpc/grpc_gevent.pxd```I think the long term fix for removing this would be to just set it in the ```bind()``` or ```listen()``` function, and remove this from the API altogether. ",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/14933,179248446,2018-04-04T18:57:58Z,tools/internal_ci/helper_scripts/prepare_build_macos_rc,"@@ -35,6 +35,17 @@ sudo systemsetup -settimezone America/Los_Angeles sudo systemsetup -setusingnetworktime on date +# See https://github.com/grpc/grpc/issues/14815","The comments around this code should be clear that this is a _temporary_ workaround, right?",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/13207,179392864,2018-04-05T08:54:15Z,src/csharp/Grpc.Tools/Common.cs,"@@ -0,0 +1,105 @@+#region Copyright notice and license++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.IO;+using System.Runtime.CompilerServices;+using System.Runtime.InteropServices;+using System.Security;++[assembly: InternalsVisibleTo(""Grpc.Tools.Tests"")]++namespace Grpc.Tools {+  // Metadata names that we refer to often.+  static class Metadata {+    // On output dependency lists.+    public static string kSource = ""Source"";+    // On ProtoBuf items.+    public static string kProtoRoot = ""ProtoRoot"";+    public static string kOutputDir = ""OutputDir"";+    public static string kGrpcServices = ""GrpcServices"";+    public static string kGrpcOutputDir = ""GrpcOutputDir"";+  };++  // A few flags used to control the behavior under various platforms.+  internal static class Platform {+    public enum OsKind { Unknown, Windows, Linux, MacOsX };+    public static readonly OsKind Os;++    public enum CpuKind { Unknown, X86, X64 };+    public static readonly CpuKind Cpu;++    // This is not necessarily true, but good enough. BCL lacks a per-FS+    // API to determine file case sensitivity.+    public static bool IsFsCaseInsensitive => Os == OsKind.Windows;+    public static bool IsWindows => Os == OsKind.Windows;++    static Platform() {","we already have similar code in https://github.com/grpc/grpc/blob/master/src/csharp/Grpc.Core/Internal/PlatformApis.cs.Can we reuse that code / stay consistent in terms of implementation? (we probably don't want to add a dependency on Grpc.Core, but perhaps we could just include the source file in Grpc.Tools (seems better than copypasting the code).",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/13207,179398465,2018-04-05T09:15:28Z,src/csharp/Grpc.Tools/Grpc.Tools.csproj,"@@ -0,0 +1,95 @@+<Project Sdk=""Microsoft.NET.Sdk"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"">++  <Import Project=""..\Grpc.Core\Version.csproj.include"" />++  <PropertyGroup>+    <AssemblyName>Protobuf.MSBuild</AssemblyName>+    <Version>$(GrpcCsharpVersion)</Version>+    <!-- If changing targets, change also paths in Google.Protobuf.Tools.targets. -->+    <TargetFrameworks>netstandard1.3;net40</TargetFrameworks>+  </PropertyGroup>++  <PropertyGroup Label=""Asset root folders. TODO(kkm): Change with package separation."">+    <!-- TODO(kkm): Rework whole section when splitting packages.  -->+    <!-- GRPC: ../../third_party/protobuf/src/google/protobuf/  -->+    <!-- GPB:  ../src/google/protobuf/ -->+    <Assets_ProtoInclude>../../../third_party/protobuf/src/google/protobuf/</Assets_ProtoInclude>++    <!-- GPB:  protoc\ -->+    <!-- GRPC: protoc_plugins\protoc_ -->+    <Assets_ProtoCompiler>../protoc_plugins/protoc_</Assets_ProtoCompiler>++    <!-- GRPC: protoc_plugins\ -->+    <Assets_GrpcPlugins>../protoc_plugins/</Assets_GrpcPlugins>+  </PropertyGroup>++  <PropertyGroup>+    <_NetStandard>False</_NetStandard>+    <_NetStandard Condition="" $(TargetFramework.StartsWith('netstandard')) or $(TargetFramework.StartsWith('netcore')) "">True</_NetStandard>++    <!-- So we do not hardcode an exact version into #if's. -->+    <DefineConstants Condition=""$(_NetStandard)"">$(DefineConstants);NETSTANDARD</DefineConstants>","you only use the ""NETSTANDARD"" define once in the whole PR. probably not worth introducing additional complexity to the MSBUILD file because of that, I'd just use NETSTANDARD1_3 in the code",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/13207,179400641,2018-04-05T09:22:51Z,src/csharp/build_packages_dotnetcli.sh,"@@ -38,8 +38,8 @@ dotnet pack --configuration Release Grpc.Core.Testing --output ../../../artifact dotnet pack --configuration Release Grpc.Auth --output ../../../artifacts dotnet pack --configuration Release Grpc.HealthCheck --output ../../../artifacts dotnet pack --configuration Release Grpc.Reflection --output ../../../artifacts+dotnet pack --configuration Release Grpc.Tools --output ../../../artifacts",~~looks like it's not possible to build  Grpc.Tools  on linux because of the net40 dependency. So should we remove it from here and add a comment/TODO mentioning that instead?~~ (update: you can actually fix the linux build by including `..\Grpc.Core\Common.csproj.include` like all the other csproj files).,
10605667,chwarr,https://api.github.com/repos/grpc/grpc/pulls/14955,179581887,2018-04-05T19:52:32Z,src/core/lib/iomgr/tcp_windows.cc,"@@ -51,6 +52,120 @@ #define GRPC_FIONBIO FIONBIO #endif +/** fixed_slice_pool */++typedef struct fixed_slice_pool_node fixed_slice_pool_node;++typedef struct {+  gpr_mu mu;+  gpr_refcount refs;+  size_t size;+  gpr_atm count;+  size_t max_count;+  fixed_slice_pool_node* front;+} fixed_slice_pool;++struct fixed_slice_pool_node {+  grpc_slice_refcount base;+  gpr_refcount refs;+  fixed_slice_pool* pool;+  fixed_slice_pool_node* next;+};++static void fixed_slice_pool_ref(fixed_slice_pool* pool) {+  gpr_ref(&pool->refs);+}++static void fixed_slice_pool_unref(fixed_slice_pool* pool) {+  if (gpr_unref(&pool->refs)) {+    gpr_mu_lock(&pool->mu);+    fixed_slice_pool_node* front = pool->front;+    while (front) {+      fixed_slice_pool_node* n = front;+      front = n->next;+      gpr_free(n);+    }+    gpr_mu_unlock(&pool->mu);+    gpr_mu_destroy(&pool->mu);+  }+}++static void fixed_slice_pool_slice_ref(void* p) {+  fixed_slice_pool_node* n = static_cast<fixed_slice_pool_node*>(p);+  gpr_ref(&n->refs);+}++static void fixed_slice_pool_slice_unref(void* p) {+  fixed_slice_pool_node* n = static_cast<fixed_slice_pool_node*>(p);+  fixed_slice_pool* pool = n->pool;+  if (gpr_unref(&n->refs)) {+    gpr_mu_lock(&pool->mu);+    n->next = pool->front;+    pool->front = n;+    gpr_mu_unlock(&pool->mu);+    fixed_slice_pool_unref(pool);+  }+}++static const grpc_slice_refcount_vtable fixed_slice_pool_vtable = {+    fixed_slice_pool_slice_ref, fixed_slice_pool_slice_unref,+    grpc_slice_default_eq_impl, grpc_slice_default_hash_impl};++static void fixed_slice_pool_init(fixed_slice_pool* pool, size_t size,+                                  size_t max_count) {+  gpr_mu_init(&pool->mu);+  gpr_ref_init(&pool->refs, 1);+  pool->size = size;+  pool->front = nullptr;+  pool->count = 0;+  pool->max_count = max_count;+}++static void fixed_slice_pool_destroy(fixed_slice_pool* pool) {+  fixed_slice_pool_unref(pool);+}++static fixed_slice_pool_node* fixed_slice_pool_take_node(+    fixed_slice_pool* pool) {+  fixed_slice_pool_node* n = nullptr;+  if (pool->front) {+    gpr_mu_lock(&pool->mu);+    if (pool->front) {+      n = pool->front;+      pool->front = pool->front->next;+    }+    gpr_mu_unlock(&pool->mu);+  }+  if (!n) {+    if (gpr_atm_full_fetch_add(&pool->count, 1) >= pool->max_count) {+      gpr_atm_full_fetch_add(&pool->count, -1);+      return nullptr;+    }+    n = static_cast<fixed_slice_pool_node*>(+        gpr_malloc(sizeof(fixed_slice_pool_node) + pool->size));","Do we need to worry about the alignment of the buffer that we allocate along with the node? (E.g., do we need to add some slack space to make sure that the `pool->size` bytes start are aligned?)",
10605667,chwarr,https://api.github.com/repos/grpc/grpc/pulls/14955,179582012,2018-04-05T19:53:03Z,src/core/lib/iomgr/tcp_windows.cc,"@@ -51,6 +52,120 @@ #define GRPC_FIONBIO FIONBIO #endif +/** fixed_slice_pool */++typedef struct fixed_slice_pool_node fixed_slice_pool_node;++typedef struct {+  gpr_mu mu;+  gpr_refcount refs;+  size_t size;+  gpr_atm count;+  size_t max_count;+  fixed_slice_pool_node* front;+} fixed_slice_pool;++struct fixed_slice_pool_node {+  grpc_slice_refcount base;+  gpr_refcount refs;+  fixed_slice_pool* pool;+  fixed_slice_pool_node* next;+};++static void fixed_slice_pool_ref(fixed_slice_pool* pool) {+  gpr_ref(&pool->refs);+}++static void fixed_slice_pool_unref(fixed_slice_pool* pool) {+  if (gpr_unref(&pool->refs)) {+    gpr_mu_lock(&pool->mu);+    fixed_slice_pool_node* front = pool->front;+    while (front) {+      fixed_slice_pool_node* n = front;+      front = n->next;+      gpr_free(n);+    }+    gpr_mu_unlock(&pool->mu);+    gpr_mu_destroy(&pool->mu);+  }+}++static void fixed_slice_pool_slice_ref(void* p) {+  fixed_slice_pool_node* n = static_cast<fixed_slice_pool_node*>(p);+  gpr_ref(&n->refs);+}++static void fixed_slice_pool_slice_unref(void* p) {+  fixed_slice_pool_node* n = static_cast<fixed_slice_pool_node*>(p);+  fixed_slice_pool* pool = n->pool;+  if (gpr_unref(&n->refs)) {+    gpr_mu_lock(&pool->mu);+    n->next = pool->front;+    pool->front = n;+    gpr_mu_unlock(&pool->mu);+    fixed_slice_pool_unref(pool);+  }+}++static const grpc_slice_refcount_vtable fixed_slice_pool_vtable = {+    fixed_slice_pool_slice_ref, fixed_slice_pool_slice_unref,+    grpc_slice_default_eq_impl, grpc_slice_default_hash_impl};++static void fixed_slice_pool_init(fixed_slice_pool* pool, size_t size,+                                  size_t max_count) {+  gpr_mu_init(&pool->mu);+  gpr_ref_init(&pool->refs, 1);+  pool->size = size;+  pool->front = nullptr;+  pool->count = 0;+  pool->max_count = max_count;+}++static void fixed_slice_pool_destroy(fixed_slice_pool* pool) {+  fixed_slice_pool_unref(pool);+}++static fixed_slice_pool_node* fixed_slice_pool_take_node(+    fixed_slice_pool* pool) {+  fixed_slice_pool_node* n = nullptr;+  if (pool->front) {+    gpr_mu_lock(&pool->mu);+    if (pool->front) {+      n = pool->front;+      pool->front = pool->front->next;+    }+    gpr_mu_unlock(&pool->mu);+  }+  if (!n) {+    if (gpr_atm_full_fetch_add(&pool->count, 1) >= pool->max_count) {+      gpr_atm_full_fetch_add(&pool->count, -1);+      return nullptr;+    }+    n = static_cast<fixed_slice_pool_node*>(+        gpr_malloc(sizeof(fixed_slice_pool_node) + pool->size));","There's an outside possibility that this addition will overflow if the pool size is very, very, very large. I'd check how/whether this is handled elsewhere in the code base an follow suit.",
10605667,chwarr,https://api.github.com/repos/grpc/grpc/pulls/14955,179583131,2018-04-05T19:57:24Z,src/core/lib/iomgr/tcp_windows.cc,"@@ -51,6 +52,120 @@ #define GRPC_FIONBIO FIONBIO #endif +/** fixed_slice_pool */++typedef struct fixed_slice_pool_node fixed_slice_pool_node;","Since this is just in the implementation of the core C library, [C++ can be used](https://github.com/grpc/proposal/blob/master/L6-allow-c%2B%2B-in-grpc-core.md) if that makes the implementation easier. See the limitations in the linked proposal for more details.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14541,179652953,2018-04-06T03:28:18Z,test/cpp/util/byte_buffer_test.cc,"@@ -27,6 +28,9 @@ #include <gtest/gtest.h>  namespace grpc {++static internal::GrpcLibraryInitializer g_gli_initializer;","But I guess my question was what changed in codegen. The classes that you made public already existed in codegen as internal:: , so was it that the functions used by those classes changed, or something else?",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/14986,180139526,2018-04-09T15:45:44Z,src/core/lib/debug/trace.cc,"@@ -55,7 +55,7 @@ bool TraceFlagList::Set(const char* name, bool enabled) {         found = true;       }     }-    if (!found) {+    if (!found && strcmp(name, """")) {",The strcmp uses in this function could be decomposed into a separate function with clear naming so that the code is easier to read,
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/14986,180202973,2018-04-09T19:24:56Z,src/core/lib/debug/trace.cc,"@@ -55,7 +55,7 @@ bool TraceFlagList::Set(const char* name, bool enabled) {         found = true;       }     }-    if (!found) {+    if (!found && strcmp(name, """")) {","Also, I found the style guideline where I was taught to not wrap library calls without changing functionality: http://umich.edu/~eecs381/handouts/C_Coding_Standards.pdfThis is from a C class I took in college :)",
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/13342,180539798,2018-04-10T19:22:02Z,src/php/lib/Grpc/BaseStub.php,"@@ -197,17 +203,244 @@ private function _validate_and_normalize_metadata($metadata)             if (!preg_match('/^[A-Za-z\d_-]+$/', $key)) {                 throw new \InvalidArgumentException(                     'Metadata keys must be nonempty strings containing only '.-                    'alphanumeric characters, hyphens and underscores');+                    'alphanumeric characters, hyphens and underscores'+                );             }             $metadata_copy[strtolower($key)] = $value;         }          return $metadata_copy;     } +    /**+     * Create a function which can be used to create UnaryCall+     *+     * @param Channel|InterceptorChannel   $channel+     * @param callable $deserialize A function that deserializes the response+     *+     * @return \Closure+     */+    private function _GrpcUnaryUnary($channel, $deserialize)+    {+        return function ($method, $argument, array $metadata = [], array $options = []) use ($channel, $deserialize) {+            $call = new UnaryCall(+                $channel,+                $method,+                $deserialize,+                $options+            );+            $jwt_aud_uri = $this->_get_jwt_aud_uri($method);+            if (is_callable($this->update_metadata)) {+                $metadata = call_user_func(+                    $this->update_metadata,+                    $metadata,+                    $jwt_aud_uri+                );+            }+            $metadata = $this->_validate_and_normalize_metadata(+                $metadata+            );+            $call->start($argument, $metadata, $options);+            return $call;+        };+    }++    /**+     * Create a function which can be used to create ServerStreamingCall+     *+     * @param Channel|InterceptorChannel   $channel+     * @param callable $deserialize A function that deserializes the response+     *+     * @return \Closure+     */+    private function _GrpcStreamUnary($channel, $deserialize)+    {+        return function ($method, array $metadata = [], array $options = []) use ($channel, $deserialize) {+            $call = new ClientStreamingCall(+                $channel,+                $method,+                $deserialize,+                $options+            );+            $jwt_aud_uri = $this->_get_jwt_aud_uri($method);+            if (is_callable($this->update_metadata)) {+                $metadata = call_user_func(+                    $this->update_metadata,+                    $metadata,+                    $jwt_aud_uri+                );+            }+            $metadata = $this->_validate_and_normalize_metadata(+                $metadata+            );+            $call->start($metadata);+            return $call;+        };+    }++    /**+     * Create a function which can be used to create ClientStreamingCall+     *+     * @param Channel|InterceptorChannel   $channel+     * @param callable $deserialize A function that deserializes the response+     *+     * @return \Closure+     */+    private function _GrpcUnaryStream($channel, $deserialize)+    {+        return function ($method, $argument, array $metadata = [], array $options = []) use ($channel, $deserialize) {+            $call = new ServerStreamingCall(+                $channel,+                $method,+                $deserialize,+                $options+            );+            $jwt_aud_uri = $this->_get_jwt_aud_uri($method);+            if (is_callable($this->update_metadata)) {+                $metadata = call_user_func(+                    $this->update_metadata,+                    $metadata,+                    $jwt_aud_uri+                );+            }+            $metadata = $this->_validate_and_normalize_metadata(+                $metadata+            );+            $call->start($argument, $metadata, $options);+            return $call;+        };+    }++    /**+     * Create a function which can be used to create BidiStreamingCall+     *+     * @param Channel|InterceptorChannel   $channel+     * @param callable $deserialize A function that deserializes the response+     *+     * @return \Closure+     */+    private function _GrpcStreamStream($channel, $deserialize)+    {+        return function ($method, array $metadata = [], array $options = []) use ($channel ,$deserialize) {+            $call = new BidiStreamingCall(+                $channel,+                $method,+                $deserialize,+                $options+            );+            $jwt_aud_uri = $this->_get_jwt_aud_uri($method);+            if (is_callable($this->update_metadata)) {+                $metadata = call_user_func(+                    $this->update_metadata,+                    $metadata,+                    $jwt_aud_uri+                );+            }+            $metadata = $this->_validate_and_normalize_metadata(+                $metadata+            );+            $call->start($metadata);++            return $call;+        };+    }++    /**+     * Create a function which can be used to create UnaryCall+     *+     * @param Channel|InterceptorChannel   $channel+     * @param callable $deserialize A function that deserializes the response+     *+     * @return \Closure+     */+    private function _UnaryUnaryCallFactory($channel, $deserialize)+    {+        if (is_a($channel, 'Grpc\InterceptorChannel')) {+            return function ($method, $argument, array $metadata = [], array $options = []) use ($channel, $deserialize) {",Some of these lines may be too long.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/14954,180786017,2018-04-11T14:58:44Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -994,26 +995,54 @@ static void maybe_cache_send_ops_for_batch(call_data* calld,   } } +// Frees cached send_initial_metadata.+static void free_cached_send_initial_metadata(grpc_call_element* elem) {","I deliberately pulled them apart, because I wanted to do the same logging whether they are called from `free_cached_send_op_data_after_commit()` or `free_cached_send_op_data_for_completed_batch()`.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/14954,180831357,2018-04-11T17:14:15Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -994,26 +995,54 @@ static void maybe_cache_send_ops_for_batch(call_data* calld,   } } +// Frees cached send_initial_metadata.+static void free_cached_send_initial_metadata(grpc_call_element* elem) {","My main concern is that you are passing in grpc_call_elem, then casting to channel_data and call_data every time. For free_cached_send_message, the casts happen every iteration of the loop. I'd suggest passing in channel_data and call_data and doing the casts before this series of calls",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/14954,180833942,2018-04-11T17:23:30Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -2072,6 +2132,30 @@ static void start_batch_in_call_combiner(void* arg, grpc_error* ignored) {   grpc_subchannel_call_process_op(subchannel_call, batch); } +// Adds a closure to closures that will execute batch in the call combiner.+static void add_closure_for_subchannel_batch(+    call_data* calld, grpc_transport_stream_op_batch* batch,+    closure_to_execute* closures, size_t* num_closures) {+  batch->handler_private.extra_arg = calld->subchannel_call;+  GRPC_CLOSURE_INIT(&batch->handler_private.closure,+                    start_batch_in_call_combiner, batch,+                    grpc_schedule_on_exec_ctx);+  closure_to_execute* closure = &closures[(*num_closures)++];+  closure->closure = &batch->handler_private.closure;+  closure->error = GRPC_ERROR_NONE;+  // If the tracer is enabled, we log a more detailed message, which","Sorry, maybe bringing up flagz was a bad example since flags change fundamental state of the program. Tracers should not change any state, they should just do logging. That is why I don't like the value of a tracer to change whether a string is dynamically allocated or not.I know sometimes tracing causes allocation, like anytime `grpc_transport_stream_op_batch_string` is called, but in those cases, the memory is freed in the same block that the tracing is occurring in.I suggest either logging all you need right here, then freeing, or if you really want this string held longer, then consider wrapping in NDEBUG block, like we do in other places where tracing incurs additional overhead ([closure tracing](https://github.com/grpc/grpc/blob/master/src/core/lib/iomgr/closure.h?utf8=%E2%9C%93#L94) for example)",
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/15020,180879101,2018-04-11T19:57:35Z,src/core/lib/iomgr/udp_server.cc,"@@ -597,44 +623,67 @@ int grpc_udp_server_add_port(grpc_udp_server* s,   }    s->handler_factory = handler_factory;-  /* Treat :: or 0.0.0.0 as a family-agnostic wildcard. */-  if (grpc_sockaddr_is_wildcard(addr, &port)) {-    grpc_sockaddr_make_wildcards(port, &wild4, &wild6);+  for (size_t i = 0; i < num_listeners; ++i) {+    /* Treat :: or 0.0.0.0 as a family-agnostic wildcard. */+    if (grpc_sockaddr_is_wildcard(addr, &port)) {+      grpc_sockaddr_make_wildcards(port, &wild4, &wild6);++      /* Try listening on IPv6 first. */+      addr = &wild6;+      // TODO(rjshade): Test and propagate the returned grpc_error*:+      GRPC_ERROR_UNREF(grpc_create_dualstack_socket_using_factory(+          s->socket_factory, addr, SOCK_DGRAM, IPPROTO_UDP, &dsmode, &fd));+      allocated_port1 =+          add_socket_to_server(s, fd, addr, rcv_buf_size, snd_buf_size);+      if (fd >= 0 && dsmode == GRPC_DSMODE_DUALSTACK) {+        if (port == 0) {+          /* This is the first time to bind to |addr|. If its port is still+           * wildcard port, update |addr| with the ephermeral port returned by+           * kernel. Thus |addr| can have a specific port in following+           * iterations. */+          grpc_sockaddr_set_port(addr, allocated_port1);+          port = allocated_port1;+        } else if (allocated_port1 >= 0) {+          /* The following sucessfully created socket should have same port as+           * the first one. */+          GPR_ASSERT(port == allocated_port1);+        }+        continue;+      }++      /* If we didn't get a dualstack socket, also listen on 0.0.0.0. */+      if (port == 0 && allocated_port1 > 0) {+        /* |port| hasn't been assigned to an emphemeral port yet, |wild4| must+         * have a wildcard port. Update it with the emphemeral port created+         * during binding.*/+        grpc_sockaddr_set_port(&wild4, allocated_port1);+        port = allocated_port1;+      }+      addr = &wild4;+    }",I understand what the function was originally trying to do: It is creating either one dual-stack socket or two sockets (one IPV6 and IPV4) or just one IPv4 socket.  Now you added functionality to do that `num_listener` number of times. It makes the code a bit tricky and detailed comments would help,
28968539,ZhouyihaiDing,https://api.github.com/repos/grpc/grpc/pulls/14991,181219087,2018-04-12T20:55:13Z,src/php/ext/grpc/channel.c,"@@ -572,6 +651,8 @@ GRPC_STARTUP_FUNCTION(channel) {   gpr_mu_init(&global_persistent_list_mu);   le_plink = zend_register_list_destructors_ex(       NULL, php_grpc_channel_plink_dtor, ""Persistent Channel"", module_number);+  zend_hash_init_ex(&grpc_persistent_list, 20, NULL,","I think it's just initiate size. It can resize dynamically.When I set it to 2, the list still can be added to ten or more.",
28968539,ZhouyihaiDing,https://api.github.com/repos/grpc/grpc/pulls/14991,181221898,2018-04-12T21:06:04Z,src/php/ext/grpc/channel.c,"@@ -572,6 +651,8 @@ GRPC_STARTUP_FUNCTION(channel) {   gpr_mu_init(&global_persistent_list_mu);   le_plink = zend_register_list_destructors_ex(       NULL, php_grpc_channel_plink_dtor, ""Persistent Channel"", module_number);+  zend_hash_init_ex(&grpc_persistent_list, 20, NULL,","I was just referring [other people's code](https://github.com/php/php-src/blob/a7fe2570d3ce6915d4ea85c62c0f880ddc225ba7/Zend/zend_list.c#L220), choose a random number. 20 sound's like a good number for the max number of persistent channels which I am going to set as default.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/15049,181253238,2018-04-12T23:46:00Z,include/grpcpp/impl/codegen/proto_utils.h,"@@ -96,9 +96,17 @@ Status GenericDeserialize(ByteBuffer* buffer, grpc::protobuf::Message* msg) {   return result; } -// this is needed so the following class does not conflict with protobuf+// This is needed so the following class does not conflict with protobuf // serializers that utilize internal-only tools. #ifdef GRPC_OPEN_SOURCE_PROTO++// These allow other Google projects that exist internally and in OSS (cough +// cough TensorFlow) to utilize certain internal optimization (cough cough +// Cord) that should be open sourced soon (sniff sneeze Abseil) clearing this+// whole mess up.+typedef GrpcProtoBufferWriter GrpcMaybeCordProtoBufferWriter;+typedef GrpcProtoBufferWriter GrpcMaybeCordProtoBufferReader;","This entire block is already `ifdef`-ed out in google3 to support teams seamlessly picking up internal version of SerializationTraits. And I figure we could do the same for the  ProtoBuffer helper classes. I am sure that they have their own #defines, but I feel like this is something that validly falls in our court.It's a little more than convenience IMO. TF is the first use case of a google3/OSS project using more than SerializationTraits, since they now use these helper classes. These shims let TF just use `GrpcMaybeCordProtoBufferWriter`. Then in OSS, it picks up `GrpcProtoBufferWriter`, an in google3 (via internal only files), they will pick up the Cord version of the class. I think since we support this opacity with SerializationTraits, we can with the helper classes too.",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/15069,182271120,2018-04-17T23:27:15Z,src/core/lib/iomgr/tcp_cfstream.mm,"@@ -0,0 +1,422 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/support/port_platform.h>+#include ""src/core/lib/iomgr/port.h""++#ifdef GRPC_CFSTREAM_ENDPOINT++#import <Foundation/Foundation.h>++#include <grpc/slice_buffer.h>+#include <grpc/support/alloc.h>+#include <grpc/support/string_util.h>++#include ""src/core/lib/gpr/string.h""+#include ""src/core/lib/iomgr/closure.h""+#include ""src/core/lib/iomgr/endpoint.h""+#include ""src/core/lib/iomgr/error_apple.h""+#include ""src/core/lib/iomgr/lockfree_event.h""+#include ""src/core/lib/slice/slice_internal.h""+#include ""src/core/lib/slice/slice_string_helpers.h""++grpc_core::TraceFlag grpc_tcp_trace(false, ""tcp"");++typedef struct {+  grpc_endpoint base;+  gpr_refcount refcount;++  CFReadStreamRef readStream;+  CFWriteStreamRef writeStream;++  grpc_closure* readCB;+  grpc_closure* writeCB;+  grpc_slice_buffer* readSlices;+  grpc_slice_buffer* writeSlices;++  ::grpc_core::LockfreeEvent readEvent;+  ::grpc_core::LockfreeEvent writeEvent;+  grpc_closure readAction;+  grpc_closure writeAction;+  CFStreamEventType readType;++  char* peerString;+  grpc_resource_user* resourceUser;+  grpc_resource_user_slice_allocator sliceAllocator;+} CFStreamTCP;++static void TCPFree(CFStreamTCP* tcp) {+  grpc_resource_user_unref(tcp->resourceUser);+  CFRelease(tcp->readStream);+  CFRelease(tcp->writeStream);+  tcp->readEvent.DestroyEvent();+  gpr_free(tcp->peerString);+  gpr_free(tcp);+}++#ifndef NDEBUG+#define TCP_REF(tcp, reason) tcp_ref((tcp), (reason), __FILE__, __LINE__)+#define TCP_UNREF(tcp, reason) tcp_unref((tcp), (reason), __FILE__, __LINE__)+static void tcp_unref(CFStreamTCP* tcp, const char* reason, const char* file, int line) {+  if (grpc_tcp_trace.enabled()) {+    gpr_atm val = gpr_atm_no_barrier_load(&tcp->refcount.count);+    gpr_log(file, line, GPR_LOG_SEVERITY_DEBUG, ""TCP unref %p : %s %"" PRIdPTR "" -> %"" PRIdPTR, tcp,+            reason, val, val - 1);+  }+  if (gpr_unref(&tcp->refcount)) {+    TCPFree(tcp);+  }+}+static void tcp_ref(CFStreamTCP* tcp, const char* reason, const char* file, int line) {+  if (grpc_tcp_trace.enabled()) {+    gpr_atm val = gpr_atm_no_barrier_load(&tcp->refcount.count);+    gpr_log(file, line, GPR_LOG_SEVERITY_DEBUG, ""TCP   ref %p : %s %"" PRIdPTR "" -> %"" PRIdPTR, tcp,+            reason, val, val + 1);+  }+  gpr_ref(&tcp->refcount);+}+#else+#define TCP_REF(tcp, reason) tcp_ref((tcp))+#define TCP_UNREF(tcp, reason) tcp_unref((tcp))+static void tcp_unref(grpc_tcp* tcp) {+  if (gpr_unref(&tcp->refcount)) {+    tcp_free(tcp);+  }+}+static void tcp_ref(grpc_tcp* tcp) { gpr_ref(&tcp->refcount); }+#endif++static void CallReadCB(CFStreamTCP* tcp, grpc_error* error) {+  if (grpc_tcp_trace.enabled()) {+    gpr_log(GPR_DEBUG, ""TCP:%p call_read_cb %p %p:%p"", tcp, tcp->readCB, tcp->readCB->cb,+            tcp->readCB->cb_arg);+    size_t i;+    const char* str = grpc_error_string(error);+    gpr_log(GPR_DEBUG, ""read: error=%s"", str);++    for (i = 0; i < tcp->readSlices->count; i++) {+      char* dump = grpc_dump_slice(tcp->readSlices->slices[i], GPR_DUMP_HEX | GPR_DUMP_ASCII);+      gpr_log(GPR_DEBUG, ""READ %p (peer=%s): %s"", tcp, tcp->peerString, dump);+      gpr_free(dump);+    }+  }+  grpc_closure* cb = tcp->readCB;+  tcp->readCB = nullptr;+  tcp->readSlices = nullptr;+  GRPC_CLOSURE_RUN(cb, error);+}++static void CallWriteCB(CFStreamTCP* tcp, grpc_error* error) {+  if (grpc_tcp_trace.enabled()) {+    gpr_log(GPR_DEBUG, ""TCP:%p call_write_cb %p %p:%p"", tcp, tcp->writeCB, tcp->writeCB->cb,+            tcp->writeCB->cb_arg);+    const char* str = grpc_error_string(error);+    gpr_log(GPR_DEBUG, ""write: error=%s"", str);+  }+  grpc_closure* cb = tcp->writeCB;+  tcp->writeCB = nullptr;+  tcp->writeSlices = nullptr;+  GRPC_CLOSURE_RUN(cb, error);+}++static void ReadAction(void* arg, grpc_error* error) {+  CFStreamTCP* tcp = static_cast<CFStreamTCP*>(arg);+  GPR_ASSERT(tcp->readCB != nullptr);+  CFStreamStatus status = CFReadStreamGetStatus(tcp->readStream);+  if (status == kCFStreamStatusAtEnd) {+    CFReadStreamClose(tcp->readStream);+    grpc_slice_buffer_reset_and_unref_internal(tcp->readSlices);+    CallReadCB(tcp, GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Stream closed""));+    // No need to specify an error because it is impossible to have a pending notify in+    // tcp->read_event at this time.+    tcp->readEvent.SetShutdown(GRPC_ERROR_NONE);+    TCP_UNREF(tcp, ""read"");+  } else if (status == kCFStreamStatusError || error != GRPC_ERROR_NONE) {+    grpc_slice_buffer_reset_and_unref_internal(tcp->readSlices);+    if (status == kCFStreamStatusError) {+      CFErrorRef streamError = CFReadStreamCopyError(tcp->readStream);+      GPR_ASSERT(streamError != NULL);+      CFReadStreamClose(tcp->readStream);+      CallReadCB(tcp, GRPC_ERROR_CREATE_FROM_CFERROR(streamError, ""Stream error""));+      CFRelease(streamError);+    } else {+      CallReadCB(tcp, GRPC_ERROR_REF(error));+    }+    // No need to specify an error because it is impossible to have a pending notify in+    // tcp->read_event at this time.+    tcp->readEvent.SetShutdown(GRPC_ERROR_NONE);+    TCP_UNREF(tcp, ""read"");+  } else if (status == kCFStreamStatusClosed) {+    grpc_slice_buffer_reset_and_unref_internal(tcp->readSlices);+    CallReadCB(tcp, error);+    TCP_UNREF(tcp, ""read"");+  } else {+    grpc_slice* slice = &tcp->readSlices->slices[tcp->readSlices->count - 1];+    GPR_ASSERT(CFReadStreamHasBytesAvailable(tcp->readStream));+    CFIndex readSize = CFReadStreamRead(tcp->readStream, GRPC_SLICE_START_PTR(*slice),+                                        GRPC_TCP_DEFAULT_READ_SLICE_SIZE);+    if (readSize == -1) {+      grpc_slice_buffer_reset_and_unref_internal(tcp->readSlices);+      CFErrorRef streamError = CFReadStreamCopyError(tcp->readStream);+      CallReadCB(tcp, GRPC_ERROR_CREATE_FROM_CFERROR(streamError, ""Read error""));+      CFRelease(streamError);+      TCP_UNREF(tcp, ""read"");+    } else if (readSize == 0) {+      // Reset the read notification+      tcp->readEvent.NotifyOn(&tcp->readAction);+    } else {+      if (readSize < GRPC_TCP_DEFAULT_READ_SLICE_SIZE) {+        grpc_slice_buffer_trim_end(tcp->readSlices, GRPC_TCP_DEFAULT_READ_SLICE_SIZE - readSize,+                                   nullptr);+      }+      CallReadCB(tcp, GRPC_ERROR_NONE);+      TCP_UNREF(tcp, ""read"");+    }+  }+}++static void WriteAction(void* arg, grpc_error* error) {+  CFStreamTCP* tcp = static_cast<CFStreamTCP*>(arg);+  GPR_ASSERT(tcp->writeCB != nullptr);+  CFStreamStatus status = CFWriteStreamGetStatus(tcp->writeStream);+  if (status == kCFStreamStatusAtEnd) {+    CFWriteStreamClose(tcp->writeStream);+    grpc_slice_buffer_reset_and_unref_internal(tcp->writeSlices);+    CallWriteCB(tcp, GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Stream closed""));+    tcp->writeEvent.SetShutdown(GRPC_ERROR_NONE);+    TCP_UNREF(tcp, ""write"");+  } else if (status == kCFStreamStatusError || error != GRPC_ERROR_NONE) {+    grpc_slice_buffer_reset_and_unref_internal(tcp->writeSlices);+    if (status == kCFStreamStatusError) {+      CFErrorRef streamError = CFWriteStreamCopyError(tcp->writeStream);+      CFWriteStreamClose(tcp->writeStream);+      CallWriteCB(tcp, GRPC_ERROR_CREATE_FROM_CFERROR(streamError, ""Stream error""));+      CFRelease(streamError);+    } else {+      CallWriteCB(tcp, GRPC_ERROR_REF(error));+    }+    tcp->writeEvent.SetShutdown(GRPC_ERROR_NONE);+    TCP_UNREF(tcp, ""write"");+  } else if (status == kCFStreamStatusClosed) {+    grpc_slice_buffer_reset_and_unref_internal(tcp->writeSlices);+    CallWriteCB(tcp, error);+    TCP_UNREF(tcp, ""write"");+  } else {+    GPR_ASSERT(CFWriteStreamCanAcceptBytes(tcp->writeStream));+    grpc_slice slice = grpc_slice_buffer_take_first(tcp->writeSlices);+    size_t slice_len = GRPC_SLICE_LENGTH(slice);+    CFIndex writeSize =+        CFWriteStreamWrite(tcp->writeStream, GRPC_SLICE_START_PTR(slice), slice_len);+    if (writeSize == -1) {+      grpc_slice_buffer_reset_and_unref_internal(tcp->writeSlices);+      CFErrorRef streamError = CFWriteStreamCopyError(tcp->writeStream);+      CallWriteCB(tcp, GRPC_ERROR_CREATE_FROM_CFERROR(streamError, ""write failed.""));+      CFRelease(streamError);+      TCP_UNREF(tcp, ""write"");+    } else {+      if (writeSize < GRPC_SLICE_LENGTH(slice)) {+        grpc_slice_buffer_undo_take_first(tcp->writeSlices,+                                          grpc_slice_sub(slice, writeSize, slice_len));+      }+      if (tcp->writeSlices->length > 0) {+        tcp->writeEvent.NotifyOn(&tcp->writeAction);+      } else {+        CallWriteCB(tcp, GRPC_ERROR_NONE);+        TCP_UNREF(tcp, ""write"");+      }++      if (grpc_tcp_trace.enabled()) {+        grpc_slice trace_slice = slice;+        if (writeSize < GRPC_SLICE_LENGTH(slice)) {+          trace_slice = grpc_slice_sub(slice, 0, writeSize);+        }+        char* dump = grpc_dump_slice(trace_slice, GPR_DUMP_HEX | GPR_DUMP_ASCII);+        gpr_log(GPR_DEBUG, ""WRITE %p (peer=%s): %s"", tcp, tcp->peerString, dump);+        gpr_free(dump);+        if (writeSize < GRPC_SLICE_LENGTH(slice)) {+          grpc_slice_unref(trace_slice);+        }+      }+    }+    grpc_slice_unref(slice);+  }+}++static void ReadCallback(CFReadStreamRef stream, CFStreamEventType type, void* clientCallBackInfo) {+  CFStreamTCP* tcp = static_cast<CFStreamTCP*>(clientCallBackInfo);+  TCP_REF(tcp, ""read callback"");+  dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{+    gpr_log(GPR_DEBUG, ""TCP:%p readCallback (%p, %lu, %p)"", tcp, stream, type, clientCallBackInfo);","I thought about that too but I tend to leave it concurrent. Read path and write path are relatively independent; at this time I do not see down side to execute them at the same time. As to logging, I think the order of callbacks does not matter that much in this scenario. We simply log the time when the callback gets processes by gRPC subsystem.",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/15069,182275619,2018-04-17T23:58:36Z,src/core/lib/iomgr/tcp_client_cfstream.mm,"@@ -0,0 +1,282 @@++/*+ *+ * Copyright 2016 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/support/port_platform.h>+#include ""src/core/lib/iomgr/port.h""++#ifdef GRPC_CFSTREAM_ASYNC_CONNECT++#include <Foundation/Foundation.h>++#include <string.h>++#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include <netinet/in.h>++#include ""src/core/ext/filters/client_channel/subchannel.h""+#include ""src/core/ext/filters/client_channel/uri_parser.h""++#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/gpr/host_port.h""+#include ""src/core/lib/iomgr/closure.h""+#include ""src/core/lib/iomgr/error.h""+#include ""src/core/lib/iomgr/error_apple.h""+#include ""src/core/lib/iomgr/sockaddr_utils.h""+#include ""src/core/lib/iomgr/tcp_cfstream.h""+#include ""src/core/lib/iomgr/tcp_client.h""+#include ""src/core/lib/iomgr/timer.h""+#include ""src/core/lib/iomgr/timer_generic.h""++extern grpc_core::TraceFlag grpc_tcp_trace;++typedef struct CFStreamTCPConnect {+  gpr_mu mu;++  CFReadStreamRef readStream;+  CFWriteStreamRef writeStream;++  grpc_timer alarm;+  grpc_closure onAlarm;++  bool readStreamOpen;+  bool writeStreamOpen;+  bool failed;++  grpc_closure* closure;+  grpc_endpoint** endpoint;+  int refs;+  char* addrName;+  grpc_resource_quota* resourceQuota;+} CFStreamTCPConnect;++static void TCPConnectCleanup(CFStreamTCPConnect* connect) {+  grpc_resource_quota_unref_internal(connect->resourceQuota);+  CFRelease(connect->readStream);+  CFRelease(connect->writeStream);+  gpr_mu_destroy(&connect->mu);+  gpr_free(connect->addrName);+  gpr_free(connect);+}++static void OnAlarm(void* arg, grpc_error* error) {+  CFStreamTCPConnect* connect = static_cast<CFStreamTCPConnect*>(arg);+  if (grpc_tcp_trace.enabled()) {+    gpr_log(GPR_DEBUG, ""CLIENT_CONNECT :%p on_alarm, error:%p"", connect, error);+  }+  gpr_mu_lock(&connect->mu);+  grpc_closure* closure = connect->closure;+  connect->closure = nil;+  const bool done = (--connect->refs == 0);+  gpr_mu_unlock(&connect->mu);+  // Only schedule a callback once, by either on_timer or on_connected. The first one issues+  // callback while the second one does cleanup.+  if (done) {+    TCPConnectCleanup(connect);+  } else {+    grpc_error* error = GRPC_ERROR_CREATE_FROM_STATIC_STRING(""connect() timed out"");+    GRPC_CLOSURE_SCHED(closure, error);+  }+}++static void MaybeOnConnected(CFStreamTCPConnect* connect, bool setReadOpen, bool setWriteOpen,+                             bool failed) {+  gpr_mu_lock(&connect->mu);+  if (setReadOpen) {+    connect->readStreamOpen = true;+  }+  if (setWriteOpen) {+    connect->writeStreamOpen = true;+  }+  if (failed) {+    connect->failed = true;+  }++  if (grpc_tcp_trace.enabled()) {+    gpr_log(GPR_DEBUG, ""CLIENT_CONNECT :%p read_open:%d write_open:%d, failed:%d"", connect,+            connect->readStreamOpen, connect->writeStreamOpen, connect->failed);+  }+  const bool connectedOrFailed = (connect->readStreamOpen && connect->writeStreamOpen);+  if (connectedOrFailed) {+    CFErrorRef error = NULL;+    if (connect->failed) {+      error = CFReadStreamCopyError(connect->readStream);+      if (error == NULL) {+        error = CFWriteStreamCopyError(connect->writeStream);+      }+      GPR_ASSERT(error != NULL);+    }++    grpc_timer_cancel(&connect->alarm);++    grpc_closure* closure = connect->closure;+    connect->closure = nil;++    bool done = (--connect->refs == 0);+    grpc_endpoint** endpoint = connect->endpoint;+    gpr_mu_unlock(&connect->mu);+    // Only schedule a callback once, by either on_timer or on_connected. The first one issues+    // callback while the second one does cleanup.+    if (done) {+      TCPConnectCleanup(connect);+    } else if (error != NULL) {+      grpc_error* transError = GRPC_ERROR_CREATE_FROM_CFERROR(error, ""connect() failed."");+      GRPC_CLOSURE_SCHED(closure, transError);+    } else {+      *endpoint = grpc_tcp_create(connect->readStream, connect->writeStream, connect->addrName,+                                  connect->resourceQuota);+      GRPC_CLOSURE_SCHED(closure, GRPC_ERROR_NONE);+    }+    if (error != NULL) {+      CFRelease(error);+    }+  } else {+    gpr_mu_unlock(&connect->mu);+  }+}++static void ReadCallback(CFReadStreamRef stream, CFStreamEventType type, void* clientCallBackInfo) {+  CFStreamTCPConnect* connect = static_cast<CFStreamTCPConnect*>(clientCallBackInfo);+  dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{+    grpc_core::ExecCtx exec_ctx;+    switch (type) {+      case kCFStreamEventOpenCompleted:+      case kCFStreamEventErrorOccurred:+        MaybeOnConnected(connect, true, false, type == kCFStreamEventErrorOccurred);+        break;+      case kCFStreamEventHasBytesAvailable:+      default:+        // Do nothing; handled by endpoint+        break;+    }++    if (grpc_tcp_trace.enabled()) {+      gpr_log(GPR_DEBUG, ""CLIENT_CONNECT :%p connect read callback (%p, %lu, %p)"", connect, stream,+              type, clientCallBackInfo);+    }+  });+  CFReadStreamSetClient(stream, 0, nil, nil);+}++static void WriteCallback(CFWriteStreamRef stream, CFStreamEventType type,+                          void* clientCallBackInfo) {+  CFStreamTCPConnect* connect = static_cast<CFStreamTCPConnect*>(clientCallBackInfo);+  dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{+    grpc_core::ExecCtx exec_ctx;+    switch (type) {+      case kCFStreamEventOpenCompleted:+      case kCFStreamEventErrorOccurred:+        MaybeOnConnected(connect, false, true, type == kCFStreamEventErrorOccurred);+      case kCFStreamEventCanAcceptBytes:+      default:+        // Do nothing; handled by endpoint+        break;+    }++    if (grpc_tcp_trace.enabled()) {+      gpr_log(GPR_DEBUG, ""CLIENT_CONNECT :%p connect write callback (%p, %lu, %p)"", connect, stream,+              type, clientCallBackInfo);+    }+  });+  CFWriteStreamSetClient(stream, 0, nil, nil);+}++static void ParseResolvedAddress(const grpc_resolved_address* addr, CFStringRef* host, int* port) {+  char *hostPort, *hostString, *portString;+  grpc_sockaddr_to_string(&hostPort, addr, 1);+  gpr_split_host_port(hostPort, &hostString, &portString);+  *host = CFStringCreateWithCString(NULL, hostString, kCFStringEncodingUTF8);+  gpr_free(hostString);+  gpr_free(portString);+  gpr_free(hostPort);+  *port = grpc_sockaddr_get_port(addr);+}++static void TCPClientConnectImpl(grpc_closure* closure, grpc_endpoint** ep,+                                 grpc_pollset_set* interestedParties,+                                 const grpc_channel_args* channelArgs,+                                 const grpc_resolved_address* resolvedAddr, grpc_millis deadline) {+  CFStreamTCPConnect* connect;++  connect = (CFStreamTCPConnect*)gpr_zalloc(sizeof(CFStreamTCPConnect));+  connect->closure = closure;+  connect->endpoint = ep;+  connect->addrName = grpc_sockaddr_to_uri(resolvedAddr);+  // connect->resource_quota = resource_quota;+  connect->refs = 2;  // One for the connect operation, one for the timer.+  gpr_mu_init(&connect->mu);++  if (grpc_tcp_trace.enabled()) {+    gpr_log(GPR_DEBUG, ""CLIENT_CONNECT: %s: asynchronously connecting"", connect->addrName);+  }++  grpc_resource_quota* resourceQuota = grpc_resource_quota_create(NULL);+  if (channelArgs != NULL) {+    for (size_t i = 0; i < channelArgs->num_args; i++) {+      if (0 == strcmp(channelArgs->args[i].key, GRPC_ARG_RESOURCE_QUOTA)) {+        grpc_resource_quota_unref_internal(resourceQuota);+        resourceQuota = grpc_resource_quota_ref_internal(+            (grpc_resource_quota*)channelArgs->args[i].value.pointer.p);+      }+    }+  }+  connect->resourceQuota = resourceQuota;++  CFReadStreamRef readStream;+  CFWriteStreamRef writeStream;++  CFStringRef host;+  int port;+  ParseResolvedAddress(resolvedAddr, &host, &port);+  CFStreamCreatePairWithSocketToHost(NULL, host, port, &readStream, &writeStream);+  CFRelease(host);+  connect->readStream = readStream;+  connect->writeStream = writeStream;+  CFStreamClientContext ctx = {0, static_cast<void*>(connect), nil, nil, nil};+  CFReadStreamSetClient(readStream, kCFStreamEventErrorOccurred | kCFStreamEventOpenCompleted,+                        ReadCallback, &ctx);+  CFWriteStreamSetClient(writeStream, kCFStreamEventErrorOccurred | kCFStreamEventOpenCompleted,+                         WriteCallback, &ctx);+  CFReadStreamScheduleWithRunLoop(readStream, CFRunLoopGetMain(), kCFRunLoopCommonModes);","I tend to leave it as a possible enhancement. This requires an extra dedicated thread in the background running the run-loop, which might not be ideal. I did not have much experience on this, but I do hope to understand how bad it would be if we just dispatch a block in this callback.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15090,182463539,2018-04-18T15:10:36Z,src/core/lib/channel/handshaker.cc,"@@ -22,11 +22,15 @@  #include <grpc/support/alloc.h> #include <grpc/support/log.h>+#include <grpc/support/string_util.h>  #include ""src/core/lib/channel/channel_args.h"" #include ""src/core/lib/channel/handshaker.h""+#include ""src/core/lib/debug/trace.h"" #include ""src/core/lib/iomgr/timer.h"" +grpc_core::TraceFlag grpc_handshaker_trace(false, ""handshaker"");","I'm sure it would work, but I don't know why it would be necessary.  In general, DebugOnlyTraceFlag is for cases where enabling the tracer imposes a large amount of overhead that we don't want in opt builds (e.g., things like ref-count tracing, which occurs a *lot*).  That's not the case here, so there's no reason not to allow this tracer even in opt builds.",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/15085,182573450,2018-04-18T21:21:46Z,test/cpp/interop/client_helper.cc,"@@ -104,7 +105,8 @@ std::shared_ptr<Channel> CreateChannelForTestCase(   }   if (FLAGS_custom_credentials_type.empty()) {     return CreateTestChannel(host_port, FLAGS_server_host_override,-                             FLAGS_use_tls, !FLAGS_use_test_ca, creds);+                             FLAGS_use_alts, FLAGS_use_tls, !FLAGS_use_test_ca,","For internal method, instead of passing two flags use_alts and use_tls which may conflict each other, define enum {TLS, ALTS, INSECURE} and use transport_security as a function parameter. The caller will convert flag into correct transport_security value.",
1581151,stephanemoore,https://api.github.com/repos/grpc/grpc/pulls/15069,182594988,2018-04-18T23:08:57Z,src/core/lib/iomgr/tcp_client_cfstream.mm,"@@ -0,0 +1,282 @@++/*+ *+ * Copyright 2016 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/support/port_platform.h>+#include ""src/core/lib/iomgr/port.h""++#ifdef GRPC_CFSTREAM_ASYNC_CONNECT++#include <Foundation/Foundation.h>++#include <string.h>++#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include <netinet/in.h>++#include ""src/core/ext/filters/client_channel/subchannel.h""+#include ""src/core/ext/filters/client_channel/uri_parser.h""++#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/gpr/host_port.h""+#include ""src/core/lib/iomgr/closure.h""+#include ""src/core/lib/iomgr/error.h""+#include ""src/core/lib/iomgr/error_apple.h""+#include ""src/core/lib/iomgr/sockaddr_utils.h""+#include ""src/core/lib/iomgr/tcp_cfstream.h""+#include ""src/core/lib/iomgr/tcp_client.h""+#include ""src/core/lib/iomgr/timer.h""+#include ""src/core/lib/iomgr/timer_generic.h""++extern grpc_core::TraceFlag grpc_tcp_trace;++typedef struct CFStreamTCPConnect {+  gpr_mu mu;++  CFReadStreamRef readStream;+  CFWriteStreamRef writeStream;++  grpc_timer alarm;+  grpc_closure onAlarm;++  bool readStreamOpen;+  bool writeStreamOpen;+  bool failed;++  grpc_closure* closure;+  grpc_endpoint** endpoint;+  int refs;+  char* addrName;+  grpc_resource_quota* resourceQuota;+} CFStreamTCPConnect;++static void TCPConnectCleanup(CFStreamTCPConnect* connect) {+  grpc_resource_quota_unref_internal(connect->resourceQuota);+  CFRelease(connect->readStream);+  CFRelease(connect->writeStream);+  gpr_mu_destroy(&connect->mu);+  gpr_free(connect->addrName);+  gpr_free(connect);+}++static void OnAlarm(void* arg, grpc_error* error) {+  CFStreamTCPConnect* connect = static_cast<CFStreamTCPConnect*>(arg);+  if (grpc_tcp_trace.enabled()) {+    gpr_log(GPR_DEBUG, ""CLIENT_CONNECT :%p on_alarm, error:%p"", connect, error);+  }+  gpr_mu_lock(&connect->mu);+  grpc_closure* closure = connect->closure;+  connect->closure = nil;+  const bool done = (--connect->refs == 0);+  gpr_mu_unlock(&connect->mu);+  // Only schedule a callback once, by either on_timer or on_connected. The first one issues+  // callback while the second one does cleanup.+  if (done) {+    TCPConnectCleanup(connect);+  } else {+    grpc_error* error = GRPC_ERROR_CREATE_FROM_STATIC_STRING(""connect() timed out"");+    GRPC_CLOSURE_SCHED(closure, error);+  }+}++static void MaybeOnConnected(CFStreamTCPConnect* connect, bool setReadOpen, bool setWriteOpen,+                             bool failed) {+  gpr_mu_lock(&connect->mu);+  if (setReadOpen) {+    connect->readStreamOpen = true;+  }+  if (setWriteOpen) {+    connect->writeStreamOpen = true;+  }+  if (failed) {+    connect->failed = true;+  }++  if (grpc_tcp_trace.enabled()) {+    gpr_log(GPR_DEBUG, ""CLIENT_CONNECT :%p read_open:%d write_open:%d, failed:%d"", connect,+            connect->readStreamOpen, connect->writeStreamOpen, connect->failed);+  }+  const bool connectedOrFailed = (connect->readStreamOpen && connect->writeStreamOpen);+  if (connectedOrFailed) {+    CFErrorRef error = NULL;+    if (connect->failed) {+      error = CFReadStreamCopyError(connect->readStream);+      if (error == NULL) {+        error = CFWriteStreamCopyError(connect->writeStream);+      }+      GPR_ASSERT(error != NULL);+    }++    grpc_timer_cancel(&connect->alarm);++    grpc_closure* closure = connect->closure;+    connect->closure = nil;++    bool done = (--connect->refs == 0);+    grpc_endpoint** endpoint = connect->endpoint;+    gpr_mu_unlock(&connect->mu);+    // Only schedule a callback once, by either on_timer or on_connected. The first one issues+    // callback while the second one does cleanup.+    if (done) {+      TCPConnectCleanup(connect);+    } else if (error != NULL) {+      grpc_error* transError = GRPC_ERROR_CREATE_FROM_CFERROR(error, ""connect() failed."");+      GRPC_CLOSURE_SCHED(closure, transError);+    } else {+      *endpoint = grpc_tcp_create(connect->readStream, connect->writeStream, connect->addrName,+                                  connect->resourceQuota);+      GRPC_CLOSURE_SCHED(closure, GRPC_ERROR_NONE);+    }+    if (error != NULL) {+      CFRelease(error);+    }+  } else {+    gpr_mu_unlock(&connect->mu);+  }+}++static void ReadCallback(CFReadStreamRef stream, CFStreamEventType type, void* clientCallBackInfo) {+  CFStreamTCPConnect* connect = static_cast<CFStreamTCPConnect*>(clientCallBackInfo);+  dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{+    grpc_core::ExecCtx exec_ctx;+    switch (type) {+      case kCFStreamEventOpenCompleted:+      case kCFStreamEventErrorOccurred:+        MaybeOnConnected(connect, true, false, type == kCFStreamEventErrorOccurred);+        break;+      case kCFStreamEventHasBytesAvailable:+      default:+        // Do nothing; handled by endpoint+        break;+    }++    if (grpc_tcp_trace.enabled()) {+      gpr_log(GPR_DEBUG, ""CLIENT_CONNECT :%p connect read callback (%p, %lu, %p)"", connect, stream,+              type, clientCallBackInfo);+    }+  });+  CFReadStreamSetClient(stream, 0, nil, nil);+}++static void WriteCallback(CFWriteStreamRef stream, CFStreamEventType type,+                          void* clientCallBackInfo) {+  CFStreamTCPConnect* connect = static_cast<CFStreamTCPConnect*>(clientCallBackInfo);+  dispatch_async(dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT, 0), ^{+    grpc_core::ExecCtx exec_ctx;+    switch (type) {+      case kCFStreamEventOpenCompleted:+      case kCFStreamEventErrorOccurred:+        MaybeOnConnected(connect, false, true, type == kCFStreamEventErrorOccurred);+      case kCFStreamEventCanAcceptBytes:+      default:+        // Do nothing; handled by endpoint+        break;+    }++    if (grpc_tcp_trace.enabled()) {+      gpr_log(GPR_DEBUG, ""CLIENT_CONNECT :%p connect write callback (%p, %lu, %p)"", connect, stream,+              type, clientCallBackInfo);+    }+  });+  CFWriteStreamSetClient(stream, 0, nil, nil);+}++static void ParseResolvedAddress(const grpc_resolved_address* addr, CFStringRef* host, int* port) {+  char *hostPort, *hostString, *portString;+  grpc_sockaddr_to_string(&hostPort, addr, 1);+  gpr_split_host_port(hostPort, &hostString, &portString);+  *host = CFStringCreateWithCString(NULL, hostString, kCFStringEncodingUTF8);+  gpr_free(hostString);+  gpr_free(portString);+  gpr_free(hostPort);+  *port = grpc_sockaddr_get_port(addr);+}++static void TCPClientConnectImpl(grpc_closure* closure, grpc_endpoint** ep,+                                 grpc_pollset_set* interestedParties,+                                 const grpc_channel_args* channelArgs,+                                 const grpc_resolved_address* resolvedAddr, grpc_millis deadline) {+  CFStreamTCPConnect* connect;++  connect = (CFStreamTCPConnect*)gpr_zalloc(sizeof(CFStreamTCPConnect));+  connect->closure = closure;+  connect->endpoint = ep;+  connect->addrName = grpc_sockaddr_to_uri(resolvedAddr);+  // connect->resource_quota = resource_quota;+  connect->refs = 2;  // One for the connect operation, one for the timer.+  gpr_mu_init(&connect->mu);++  if (grpc_tcp_trace.enabled()) {+    gpr_log(GPR_DEBUG, ""CLIENT_CONNECT: %s: asynchronously connecting"", connect->addrName);+  }++  grpc_resource_quota* resourceQuota = grpc_resource_quota_create(NULL);+  if (channelArgs != NULL) {+    for (size_t i = 0; i < channelArgs->num_args; i++) {+      if (0 == strcmp(channelArgs->args[i].key, GRPC_ARG_RESOURCE_QUOTA)) {+        grpc_resource_quota_unref_internal(resourceQuota);+        resourceQuota = grpc_resource_quota_ref_internal(+            (grpc_resource_quota*)channelArgs->args[i].value.pointer.p);+      }+    }+  }+  connect->resourceQuota = resourceQuota;++  CFReadStreamRef readStream;+  CFWriteStreamRef writeStream;++  CFStringRef host;+  int port;+  ParseResolvedAddress(resolvedAddr, &host, &port);+  CFStreamCreatePairWithSocketToHost(NULL, host, port, &readStream, &writeStream);+  CFRelease(host);+  connect->readStream = readStream;+  connect->writeStream = writeStream;+  CFStreamClientContext ctx = {0, static_cast<void*>(connect), nil, nil, nil};+  CFReadStreamSetClient(readStream, kCFStreamEventErrorOccurred | kCFStreamEventOpenCompleted,+                        ReadCallback, &ctx);+  CFWriteStreamSetClient(writeStream, kCFStreamEventErrorOccurred | kCFStreamEventOpenCompleted,+                         WriteCallback, &ctx);+  CFReadStreamScheduleWithRunLoop(readStream, CFRunLoopGetMain(), kCFRunLoopCommonModes);",How complex is it to move this work off of the main thread? Is it worth doing the evaluation of the overhead of performing the block dispatch on the main thread or is it easier to just go ahead and refactor to avoid the block dispatch from the main thread? My gut says that the latter is less work.,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/15113,182782905,2018-04-19T15:14:02Z,src/python/grpcio_tests/tests/testing/_client_application.py,"@@ -215,30 +215,6 @@ def infinite_request_iterator():         return _UNSATISFACTORY_OUTCOME  -def run(scenario, channel):",Why this change? Just dropping unused code?,
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/15130,183111118,2018-04-20T16:57:01Z,test/core/tsi/alts/fake_handshaker/fake_handshaker_server.cc,"@@ -0,0 +1,259 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <memory>+#include <sstream>+#include <string>++#include <gflags/gflags.h>+#include <grpc/grpc.h>+#include <grpc/support/log.h>+#include <grpcpp/impl/codegen/async_stream.h>+#include <grpcpp/security/server_credentials.h>+#include <grpcpp/server.h>+#include <grpcpp/server_builder.h>+#include <grpcpp/server_context.h>++#include ""test/core/tsi/alts/fake_handshaker/handshaker.grpc.pb.h""+#include ""test/core/tsi/alts/fake_handshaker/handshaker.pb.h""+#include ""test/core/tsi/alts/fake_handshaker/transport_security_common.pb.h""+#include ""test/cpp/util/test_config.h""++DEFINE_int32(handshaker_port, 55056,+             ""TCP port on which the fake handshaker server listens to."");++// Fake handshake messages.+constexpr char kClientInitFrame[] = ""ClientInit"";+constexpr char kServerFrame[] = ""ServerInitAndFinished"";+constexpr char kClientFinishFrame[] = ""ClientFinished"";+// Error messages.+constexpr char kInvalidFrameError[] = ""Invalid input frame."";+constexpr char kWrongStateError[] = ""Wrong handshake state."";++namespace grpc {+namespace gcp {++// FakeHandshakeService implements a fake handshaker service using a fake key+// exchange protocol. The fake key exchange protocol is a 3-message protocol:+// - Client first sends ClientInit message to Server.+// - Server then sends ServerInitAndFinished message back to Client.+// - Client finally sends ClientFinished message to Server.+// It is thread-safe.+class FakeHandshakerService : public HandshakerService::Service {+ public:+  Status DoHandshake(+      ServerContext* server_context,+      ServerReaderWriter<HandshakerResp, HandshakerReq>* stream) override {+    Status status;+    HandshakerContext context;+    HandshakerReq request;+    HandshakerResp response;+    gpr_log(GPR_DEBUG, ""Start a new handshake."");+    while (stream->Read(&request)) {+      status = ProcessRequest(&context, request, &response);+      if (!status.ok()) return WriteErrorResponse(stream, status);+      stream->Write(response);+      if (context.state == COMPLETED) return Status::OK;+    }+    return Status::OK;+  }++ private:+  enum HandshakeState { INITIAL, STARTED, SENT, COMPLETED };++  struct HandshakerContext {+    bool is_client = true;+    HandshakeState state = INITIAL;+  };++  Status ProcessRequest(HandshakerContext* context,+                        const HandshakerReq& request,+                        HandshakerResp* response) {+    GPR_ASSERT(context != nullptr && response != nullptr);+    response->Clear();+    if (request.has_client_start()) {+      gpr_log(GPR_DEBUG, ""Process client start request."");+      return ProcessClientStart(context, request.client_start(), response);+    } else if (request.has_server_start()) {+      gpr_log(GPR_DEBUG, ""Process server start request."");+      return ProcessServerStart(context, request.server_start(), response);+    } else if (request.has_next()) {+      gpr_log(GPR_DEBUG, ""Process next request."");+      return ProcessNext(context, request.next(), response);+    }+    return Status(StatusCode::INVALID_ARGUMENT, ""Request is empty."");+  }++  Status ProcessClientStart(HandshakerContext* context,+                            const StartClientHandshakeReq& request,+                            HandshakerResp* response) {+    GPR_ASSERT(context != nullptr && response != nullptr);+    // Checks request.+    if (context->state != INITIAL) {+      return Status(StatusCode::FAILED_PRECONDITION, kWrongStateError);+    }+    if (request.application_protocols_size() == 0) {+      return Status(StatusCode::INVALID_ARGUMENT,+                    ""At least one application protocol needed."");+    }+    if (request.record_protocols_size() == 0) {+      return Status(StatusCode::INVALID_ARGUMENT,+                    ""At least one record protocol needed."");+    }+    // Sets response.+    response->set_out_frames(kClientInitFrame);+    response->set_bytes_consumed(0);+    response->mutable_status()->set_code(StatusCode::OK);+    // Updates handshaker context.+    context->is_client = true;+    context->state = SENT;+    return Status::OK;+  }++  Status ProcessServerStart(HandshakerContext* context,+                            const StartServerHandshakeReq& request,+                            HandshakerResp* response) {+    GPR_ASSERT(context != nullptr && response != nullptr);+    // Checks request.+    if (context->state != INITIAL) {+      return Status(StatusCode::FAILED_PRECONDITION, kWrongStateError);+    }+    if (request.application_protocols_size() == 0) {+      return Status(StatusCode::INVALID_ARGUMENT,+                    ""At least one application protocol needed."");+    }+    if (request.handshake_parameters().size() == 0) {+      return Status(StatusCode::INVALID_ARGUMENT,+                    ""At least one set of handshake parameters needed."");+    }+    // Sets response.+    if (request.in_bytes().empty()) {+      // start_server request does not have in_bytes.+      response->set_bytes_consumed(0);+      context->state = STARTED;+    } else {+      // start_server request has in_bytes.+      if (request.in_bytes() == kClientInitFrame) {+        response->set_out_frames(kServerFrame);+        response->set_bytes_consumed(strlen(kClientInitFrame));+        context->state = SENT;+      } else {+        return Status(StatusCode::UNKNOWN, kInvalidFrameError);","IIRC, in real handshaker service, if the `in_bytes` server provided is incomplete, it still returns OK status together with empty `out_frames`. Don't we also need to consider that case?",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/15130,183155090,2018-04-20T19:59:53Z,test/core/tsi/alts/fake_handshaker/fake_handshaker_server.cc,"@@ -0,0 +1,259 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <memory>+#include <sstream>+#include <string>++#include <gflags/gflags.h>+#include <grpc/grpc.h>+#include <grpc/support/log.h>+#include <grpcpp/impl/codegen/async_stream.h>+#include <grpcpp/security/server_credentials.h>+#include <grpcpp/server.h>+#include <grpcpp/server_builder.h>+#include <grpcpp/server_context.h>++#include ""test/core/tsi/alts/fake_handshaker/handshaker.grpc.pb.h""+#include ""test/core/tsi/alts/fake_handshaker/handshaker.pb.h""+#include ""test/core/tsi/alts/fake_handshaker/transport_security_common.pb.h""+#include ""test/cpp/util/test_config.h""++DEFINE_int32(handshaker_port, 55056,+             ""TCP port on which the fake handshaker server listens to."");++// Fake handshake messages.+constexpr char kClientInitFrame[] = ""ClientInit"";+constexpr char kServerFrame[] = ""ServerInitAndFinished"";+constexpr char kClientFinishFrame[] = ""ClientFinished"";+// Error messages.+constexpr char kInvalidFrameError[] = ""Invalid input frame."";+constexpr char kWrongStateError[] = ""Wrong handshake state."";++namespace grpc {+namespace gcp {++// FakeHandshakeService implements a fake handshaker service using a fake key+// exchange protocol. The fake key exchange protocol is a 3-message protocol:+// - Client first sends ClientInit message to Server.+// - Server then sends ServerInitAndFinished message back to Client.+// - Client finally sends ClientFinished message to Server.+// It is thread-safe.+class FakeHandshakerService : public HandshakerService::Service {+ public:+  Status DoHandshake(+      ServerContext* server_context,+      ServerReaderWriter<HandshakerResp, HandshakerReq>* stream) override {+    Status status;+    HandshakerContext context;+    HandshakerReq request;+    HandshakerResp response;+    gpr_log(GPR_DEBUG, ""Start a new handshake."");+    while (stream->Read(&request)) {+      status = ProcessRequest(&context, request, &response);+      if (!status.ok()) return WriteErrorResponse(stream, status);+      stream->Write(response);+      if (context.state == COMPLETED) return Status::OK;+    }+    return Status::OK;+  }++ private:+  enum HandshakeState { INITIAL, STARTED, SENT, COMPLETED };++  struct HandshakerContext {+    bool is_client = true;+    HandshakeState state = INITIAL;+  };++  Status ProcessRequest(HandshakerContext* context,+                        const HandshakerReq& request,+                        HandshakerResp* response) {+    GPR_ASSERT(context != nullptr && response != nullptr);+    response->Clear();+    if (request.has_client_start()) {+      gpr_log(GPR_DEBUG, ""Process client start request."");+      return ProcessClientStart(context, request.client_start(), response);+    } else if (request.has_server_start()) {+      gpr_log(GPR_DEBUG, ""Process server start request."");+      return ProcessServerStart(context, request.server_start(), response);+    } else if (request.has_next()) {+      gpr_log(GPR_DEBUG, ""Process next request."");+      return ProcessNext(context, request.next(), response);+    }+    return Status(StatusCode::INVALID_ARGUMENT, ""Request is empty."");+  }++  Status ProcessClientStart(HandshakerContext* context,+                            const StartClientHandshakeReq& request,+                            HandshakerResp* response) {+    GPR_ASSERT(context != nullptr && response != nullptr);+    // Checks request.+    if (context->state != INITIAL) {+      return Status(StatusCode::FAILED_PRECONDITION, kWrongStateError);+    }+    if (request.application_protocols_size() == 0) {+      return Status(StatusCode::INVALID_ARGUMENT,+                    ""At least one application protocol needed."");+    }+    if (request.record_protocols_size() == 0) {+      return Status(StatusCode::INVALID_ARGUMENT,+                    ""At least one record protocol needed."");+    }+    // Sets response.+    response->set_out_frames(kClientInitFrame);+    response->set_bytes_consumed(0);+    response->mutable_status()->set_code(StatusCode::OK);+    // Updates handshaker context.+    context->is_client = true;+    context->state = SENT;+    return Status::OK;+  }++  Status ProcessServerStart(HandshakerContext* context,+                            const StartServerHandshakeReq& request,+                            HandshakerResp* response) {+    GPR_ASSERT(context != nullptr && response != nullptr);+    // Checks request.+    if (context->state != INITIAL) {+      return Status(StatusCode::FAILED_PRECONDITION, kWrongStateError);+    }+    if (request.application_protocols_size() == 0) {+      return Status(StatusCode::INVALID_ARGUMENT,+                    ""At least one application protocol needed."");+    }+    if (request.handshake_parameters().size() == 0) {+      return Status(StatusCode::INVALID_ARGUMENT,+                    ""At least one set of handshake parameters needed."");+    }+    // Sets response.+    if (request.in_bytes().empty()) {+      // start_server request does not have in_bytes.+      response->set_bytes_consumed(0);+      context->state = STARTED;","Yes. Depending implementation, sometimes server may start handshake (sending start_server request to handshaker service) without receive any data from client yet. In such case, we allow request's incoming bytes to be empty.",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/15130,183156447,2018-04-20T20:05:31Z,test/core/tsi/alts/fake_handshaker/fake_handshaker_server.cc,"@@ -0,0 +1,259 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <memory>+#include <sstream>+#include <string>++#include <gflags/gflags.h>+#include <grpc/grpc.h>+#include <grpc/support/log.h>+#include <grpcpp/impl/codegen/async_stream.h>+#include <grpcpp/security/server_credentials.h>+#include <grpcpp/server.h>+#include <grpcpp/server_builder.h>+#include <grpcpp/server_context.h>++#include ""test/core/tsi/alts/fake_handshaker/handshaker.grpc.pb.h""+#include ""test/core/tsi/alts/fake_handshaker/handshaker.pb.h""+#include ""test/core/tsi/alts/fake_handshaker/transport_security_common.pb.h""+#include ""test/cpp/util/test_config.h""++DEFINE_int32(handshaker_port, 55056,+             ""TCP port on which the fake handshaker server listens to."");++// Fake handshake messages.+constexpr char kClientInitFrame[] = ""ClientInit"";+constexpr char kServerFrame[] = ""ServerInitAndFinished"";+constexpr char kClientFinishFrame[] = ""ClientFinished"";+// Error messages.+constexpr char kInvalidFrameError[] = ""Invalid input frame."";+constexpr char kWrongStateError[] = ""Wrong handshake state."";++namespace grpc {+namespace gcp {++// FakeHandshakeService implements a fake handshaker service using a fake key+// exchange protocol. The fake key exchange protocol is a 3-message protocol:+// - Client first sends ClientInit message to Server.+// - Server then sends ServerInitAndFinished message back to Client.+// - Client finally sends ClientFinished message to Server.+// It is thread-safe.+class FakeHandshakerService : public HandshakerService::Service {+ public:+  Status DoHandshake(+      ServerContext* server_context,+      ServerReaderWriter<HandshakerResp, HandshakerReq>* stream) override {+    Status status;+    HandshakerContext context;+    HandshakerReq request;+    HandshakerResp response;+    gpr_log(GPR_DEBUG, ""Start a new handshake."");+    while (stream->Read(&request)) {+      status = ProcessRequest(&context, request, &response);+      if (!status.ok()) return WriteErrorResponse(stream, status);+      stream->Write(response);+      if (context.state == COMPLETED) return Status::OK;+    }+    return Status::OK;+  }++ private:+  enum HandshakeState { INITIAL, STARTED, SENT, COMPLETED };++  struct HandshakerContext {+    bool is_client = true;+    HandshakeState state = INITIAL;+  };++  Status ProcessRequest(HandshakerContext* context,+                        const HandshakerReq& request,+                        HandshakerResp* response) {+    GPR_ASSERT(context != nullptr && response != nullptr);+    response->Clear();+    if (request.has_client_start()) {+      gpr_log(GPR_DEBUG, ""Process client start request."");+      return ProcessClientStart(context, request.client_start(), response);+    } else if (request.has_server_start()) {+      gpr_log(GPR_DEBUG, ""Process server start request."");+      return ProcessServerStart(context, request.server_start(), response);+    } else if (request.has_next()) {+      gpr_log(GPR_DEBUG, ""Process next request."");+      return ProcessNext(context, request.next(), response);+    }+    return Status(StatusCode::INVALID_ARGUMENT, ""Request is empty."");+  }++  Status ProcessClientStart(HandshakerContext* context,+                            const StartClientHandshakeReq& request,+                            HandshakerResp* response) {+    GPR_ASSERT(context != nullptr && response != nullptr);+    // Checks request.+    if (context->state != INITIAL) {+      return Status(StatusCode::FAILED_PRECONDITION, kWrongStateError);+    }+    if (request.application_protocols_size() == 0) {+      return Status(StatusCode::INVALID_ARGUMENT,+                    ""At least one application protocol needed."");+    }+    if (request.record_protocols_size() == 0) {+      return Status(StatusCode::INVALID_ARGUMENT,+                    ""At least one record protocol needed."");+    }+    // Sets response.+    response->set_out_frames(kClientInitFrame);+    response->set_bytes_consumed(0);+    response->mutable_status()->set_code(StatusCode::OK);+    // Updates handshaker context.+    context->is_client = true;+    context->state = SENT;+    return Status::OK;+  }++  Status ProcessServerStart(HandshakerContext* context,+                            const StartServerHandshakeReq& request,+                            HandshakerResp* response) {+    GPR_ASSERT(context != nullptr && response != nullptr);+    // Checks request.+    if (context->state != INITIAL) {+      return Status(StatusCode::FAILED_PRECONDITION, kWrongStateError);+    }+    if (request.application_protocols_size() == 0) {+      return Status(StatusCode::INVALID_ARGUMENT,+                    ""At least one application protocol needed."");+    }+    if (request.handshake_parameters().size() == 0) {+      return Status(StatusCode::INVALID_ARGUMENT,+                    ""At least one set of handshake parameters needed."");+    }+    // Sets response.+    if (request.in_bytes().empty()) {+      // start_server request does not have in_bytes.+      response->set_bytes_consumed(0);+      context->state = STARTED;+    } else {+      // start_server request has in_bytes.+      if (request.in_bytes() == kClientInitFrame) {+        response->set_out_frames(kServerFrame);+        response->set_bytes_consumed(strlen(kClientInitFrame));+        context->state = SENT;+      } else {+        return Status(StatusCode::UNKNOWN, kInvalidFrameError);","It is true that real ALTS handshaker service handles framing, i.e., if client or server sends a partial frame to handshaker service, it would be OK. Handshaker service will keep the partial frame and construct a full frame when data are ready. In this fake handshaker, we don't make such assumption. If handshake bytes are broken into two packets during network transit, thus become two requests, the fake handshaker will return error. ",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/14879,183160595,2018-04-20T20:25:00Z,src/python/grpcio_tests/tests/unit/_auth_context_test.py,"@@ -140,6 +140,71 @@ def testSecureClientCert(self):         self.assertSequenceEqual([b'*.test.google.com'],                                  auth_ctx['x509_common_name']) +    def _do_one_shot_client_rpc(self, channel_creds, channel_options, port,+                                expect_session_reused):+        # Initial connect has no session to resume+        channel = grpc.secure_channel(+            'localhost:{}'.format(port), channel_creds, options=channel_options)+        response = channel.unary_unary(_UNARY_UNARY)(_REQUEST)+        auth_data = pickle.loads(response)+        self.assertEqual(expect_session_reused,+                         auth_data[_AUTH_CTX]['ssl_session_reused'])++    def _start_secure_server(self):","No use of ""self"" parameter - what about this behavior earns it promotion to instance-scope?",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/15138,183205917,2018-04-21T09:51:17Z,src/csharp/Grpc.Core/NativeDeps.Mac.csproj.include,"@@ -1,13 +1,5 @@ <Project>   <ItemGroup>-    <!-- We are relying on run_tests.py to build grpc_csharp_ext with the right bitness","Nope, this is only for grpc developers to be able to build locally.The rules for the nuget package that will get applied on net45 are here: https://github.com/grpc/grpc/blob/master/src/csharp/Grpc.Core/Grpc.Core.targetsFTR The packaging of grpc_csharp_ext into the nuget package is here:https://github.com/grpc/grpc/blob/d100b5cfba3575d466329650137d3c9dd8a75cde/src/csharp/Grpc.Core/Grpc.Core.csproj#L23",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/15132,183440959,2018-04-23T15:38:22Z,src/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pxd.pxi,"@@ -13,10 +13,16 @@ # limitations under the License.  +cdef grpc_event _next(grpc_completion_queue *c_completion_queue, deadline)+++cdef _interpret_event(grpc_event c_event)++ cdef class CompletionQueue:",Is this class used anymore?,
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/15132,183445910,2018-04-23T15:52:40Z,src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi,"@@ -14,82 +14,579 @@  cimport cpython +import collections+import threading++_INTERNAL_CALL_ERROR_MESSAGE_FORMAT = (+    'Internal gRPC call error %d. ' ++    'Please report to https://github.com/grpc/grpc/issues')+++cdef str _call_error_metadata(metadata):+  return 'metadata was invalid: %s' % metadata+++cdef str _call_error_no_metadata(c_call_error):+  return _INTERNAL_CALL_ERROR_MESSAGE_FORMAT % c_call_error+++cdef str _call_error(c_call_error, metadata):+  if c_call_error == GRPC_CALL_ERROR_INVALID_METADATA:+    return _call_error_metadata(metadata)+  else:+    return _call_error_no_metadata(c_call_error)+++cdef _check_call_error_no_metadata(c_call_error):+  if c_call_error != GRPC_CALL_OK:+    return _INTERNAL_CALL_ERROR_MESSAGE_FORMAT % c_call_error+  else:+    return None+++cdef _check_and_raise_call_error_no_metadata(c_call_error):+  error = _check_call_error_no_metadata(c_call_error)+  if error is not None:+    raise ValueError(error)+++cdef _check_call_error(c_call_error, metadata):+  if c_call_error == GRPC_CALL_ERROR_INVALID_METADATA:+    return _call_error_metadata(metadata)+  else:+    return _check_call_error_no_metadata(c_call_error)+++cdef void _raise_call_error_no_metadata(c_call_error) except *:+  raise ValueError(_call_error_no_metadata(c_call_error))+++cdef void _raise_call_error(c_call_error, metadata) except *:+  raise ValueError(_call_error(c_call_error, metadata))+++cdef class _CompletionQueueState:++  def __cinit__(self):+    self.nexting = False+    self.illegitimate = set()+    self.events = {}+++cdef _destroy_c_completion_queue(_CompletionQueueState completion_queue_state):+  grpc_completion_queue_shutdown(completion_queue_state.c_completion_queue)+  grpc_completion_queue_destroy(completion_queue_state.c_completion_queue)+++cdef class _CallState:++  def __cinit__(self):+    self.due = set()+++cdef class _ChannelState:++  def __cinit__(+      self, call_completion_queue_state, connectivity_completion_queue_state):+    self.condition = threading.Condition()+    self.open = True+    self.integrated_call_states = {}+    self.call_completion_queue_state = call_completion_queue_state+    self.segregated_call_states = {}+    self.connectivity_due = set()+    self.connectivity_completion_queue_state = connectivity_completion_queue_state+++cdef tuple _operate(grpc_call *c_call, object operations, object user_tag):+  cdef _BatchOperationTag tag = _BatchOperationTag(user_tag, operations, None)+  tag.prepare()+  cpython.Py_INCREF(tag)+  cdef grpc_call_error c_call_error = grpc_call_start_batch(+      c_call, tag.c_ops, tag.c_nops, <cpython.PyObject *>tag, NULL)+  return c_call_error, tag+++cdef object _operate_from_integrated_call(+    _ChannelState channel_state, _CallState call_state, object operations,+    object user_tag):+  cdef grpc_call_error c_call_error+  cdef _BatchOperationTag tag+  with channel_state.condition:+    if call_state.due:+      c_call_error, tag = _operate(call_state.c_call, operations, user_tag)+      if c_call_error == GRPC_CALL_OK:+        call_state.due.add(tag)+        channel_state.integrated_call_states[tag] = call_state+        return True+      else:+        _raise_call_error_no_metadata(c_call_error)+    else:+      return False+++cdef object _operate_from_segregated_call(+    _ChannelState channel_state, _CallState call_state, object operations,+    object user_tag):+  cdef grpc_call_error c_call_error+  cdef _BatchOperationTag tag+  with channel_state.condition:+    if call_state.due:+      c_call_error, tag = _operate(call_state.c_call, operations, user_tag)+      if c_call_error == GRPC_CALL_OK:+        call_state.due.add(tag)+        return True+      else:+        _raise_call_error_no_metadata(c_call_error)+    else:+      return False+++cdef _cancel(+    _ChannelState channel_state, _CallState call_state, grpc_status_code code,+    str details):+  cdef grpc_call_error c_call_error+  with channel_state.condition:+    if call_state.due:+      c_call_error = grpc_call_cancel_with_status(+          call_state.c_call, code, _encode(details), NULL)+      _check_and_raise_call_error_no_metadata(c_call_error)+++cdef BatchOperationEvent _next_call_event(+    _ChannelState channel_state, _CompletionQueueState completion_queue_state,+    on_success):+  with channel_state.condition:+    while True:+      try:+        return completion_queue_state.events.popitem()[1]+      except KeyError:+        if completion_queue_state.nexting:+          channel_state.condition.wait()+        else:+          completion_queue_state.nexting = True+          break+  while True:+    try:+      tag, event = _latent_event(+          completion_queue_state.c_completion_queue, None)+    except:+      with channel_state.condition:+        completion_queue_state.nexting = False+        channel_state.condition.notify_all()+      raise+    else:+      with channel_state.condition:+        try:+          completion_queue_state.illegitimate.remove(tag)+        except KeyError:+          completion_queue_state.nexting = False+          on_success(tag)+          channel_state.condition.notify_all()+          return event+++# TODO(https://github.com/grpc/grpc/issues/14569): This could be a lot simpler.+cdef void _call(+    _ChannelState channel_state, _CallState call_state,+    _CompletionQueueState completion_queue_state, on_failure,+    on_success, int flags, method, host, object deadline,+    CallCredentials credentials, object operationses_and_user_tags,+    object metadata) except *:+  """"""Invokes an RPC.++  Args:+    channel_state: A _ChannelState with its ""open"" attribute set to True. RPCs+      may not be invoked on a closed channel.+    call_state: An empty _CallState to be altered (specifically assigned a+      c_call and having its due set populated) if the RPC invocation is+      successful.+    completion_queue_state: A _CompletionQueueState for the completion queue to+      be used for the call's operations.+    on_failure: A behavior to be called if attempting to start operations for+      the call fails. If called the behavior will be called while holding the+      channel_state condition and passed the tags associated with operations+      that were successfully started for the call.+    on_success: A behavior to be called if attempting to start operations for+      the call succeeds. If called the behavior will be called while holding the+      channel_state condition and passed the tags associated with operations+      that were successfully started for the call.+    flags: Flags to be passed to gRPC Core as part of call creation.+    method: The fully-qualified name of the RPC method being invoked.+    host: A ""host"" string to be passed to gRPC Core as part of call creation.+    deadline: A float for the deadline of the RPC, or None if the RPC is to have+      no deadline.+    credentials: A _CallCredentials for the RPC or None.+    operationses_and_user_tags: A sequence of length-two sequences the first+      element of which is a sequence of Operations and the second element of+      which is an object to be used as a tag. A SendInitialMetadataOperation+      must be present in this value.+    metadata: The metadata for this call.+  """"""+  cdef grpc_slice method_slice+  cdef grpc_slice host_slice+  cdef grpc_slice *host_slice_ptr+  cdef grpc_call_credentials *c_call_credentials+  cdef grpc_call_error c_call_error+  cdef tuple error_and_wrapper_tag+  cdef _BatchOperationTag wrapper_tag+  with channel_state.condition:+    if channel_state.open:+      method_slice = _slice_from_bytes(method)+      if host is None:+        host_slice_ptr = NULL+      else:+        host_slice = _slice_from_bytes(host)+        host_slice_ptr = &host_slice+      call_state.c_call = grpc_channel_create_call(+          channel_state.c_channel, NULL, flags,+          completion_queue_state.c_completion_queue, method_slice,+          host_slice_ptr, _timespec_from_time(deadline), NULL)+      grpc_slice_unref(method_slice)+      if host_slice_ptr:+        grpc_slice_unref(host_slice)+      if credentials is not None:+        c_call_credentials = credentials.c()+        c_call_error = grpc_call_set_credentials(+            call_state.c_call, c_call_credentials)+        grpc_call_credentials_release(c_call_credentials)+        if c_call_error != GRPC_CALL_OK:+          grpc_call_unref(call_state.c_call)+          _raise_call_error_no_metadata(c_call_error)+      started_tags = set()+      for operations, user_tag in operationses_and_user_tags:+        c_call_error, tag = _operate(call_state.c_call, operations, user_tag)+        if c_call_error == GRPC_CALL_OK:+          started_tags.add(tag)+        else:+          grpc_call_cancel(call_state.c_call, NULL)+          grpc_call_unref(call_state.c_call)+          completion_queue_state.illegitimate.update(started_tags)+          on_failure(started_tags)+          _raise_call_error(c_call_error, metadata)+      else:+        call_state.due = started_tags+        on_success(started_tags)+    else:+      raise ValueError('Cannot invoke RPC on closed channel!')++cdef void _process_integrated_call_tag(+    _ChannelState state, _BatchOperationTag tag) except *:+  cdef _CallState call_state = state.integrated_call_states.pop(tag)+  call_state.due.remove(tag)+  if not call_state.due:+    grpc_call_unref(call_state.c_call)+","How would you feel about setting call_state.c_call = NULL here?Once we unref the call it is unsafe to access, but if we end up violating that (here or down the road), I'm concerned that it might be difficult to sniff out because we have no-idea how long the c-core will keep the call alive.",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/15132,183456422,2018-04-23T16:24:33Z,src/python/grpcio/grpc/_cython/_cygrpc/channel.pxd.pxi,"@@ -13,9 +13,76 @@ # limitations under the License.  +cdef _check_call_error_no_metadata(c_call_error)+++cdef _check_and_raise_call_error_no_metadata(c_call_error)+++cdef _check_call_error(c_call_error, metadata)+++cdef class _CompletionQueueState:++  cdef grpc_completion_queue *c_completion_queue+  # A boolean indicating that some thread is currently executing a+  # grpc_completion_queue_next on the completion queue.+  cdef object nexting+  # A set of _Tags associated with operations that failed ""internally to cygrpc""+  # and should not be delivered across the cygrpc API.+  # TODO(https://github.com/grpc/grpc/issues/14569): This should be eliminable.+  cdef set illegitimate+  # A collections.MutableMapping from _Tags to events. The events stored here+  # will ultimately be delivered across the cygrpc API.+  cdef dict events","I really don't like this backchannel of maintaining a list of completions (events) to deliver to the user.That is what the completion queue does, and this seems to complicate that.AFAICT, this is useful for adding a filter between user-returnable events and cq-next events, but I suspect that can be done in an easier fashion.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/14879,183789475,2018-04-24T16:01:29Z,src/python/grpcio_tests/tests/unit/_auth_context_test.py,"@@ -140,6 +140,71 @@ def testSecureClientCert(self):         self.assertSequenceEqual([b'*.test.google.com'],                                  auth_ctx['x509_common_name']) +    def _do_one_shot_client_rpc(self, channel_creds, channel_options, port,+                                expect_session_reused):+        # Initial connect has no session to resume+        channel = grpc.secure_channel(+            'localhost:{}'.format(port), channel_creds, options=channel_options)+        response = channel.unary_unary(_UNARY_UNARY)(_REQUEST)+        auth_data = pickle.loads(response)+        self.assertEqual(expect_session_reused,+                         auth_data[_AUTH_CTX]['ssl_session_reused'])++    def _start_secure_server(self):",Never use `staticmethod` voluntarily; only ever use it to interoperate with ill-willed code that forces its use upon you. [Why isn't this just a module-scope module-private helper function? What about it earns it promotion into the class?](https://www.youtube.com/watch?v=aOEfIrC07XA&t=10m18s),
1471472,wenbozhu,https://api.github.com/repos/grpc/grpc/pulls/15160,183815114,2018-04-24T17:21:55Z,src/proto/grpc/extension/extension.proto,"@@ -0,0 +1,59 @@+// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++syntax = ""proto3"";++package grpc.extension;++message ExtensionConfig {+  repeated ClientChannelConfig client_channel = 1;+}++message ClientChannelConfig {+  // A list of connection targets which use this channel config.+  repeated string target = 1;+  // The max number of channels in the pool, shared among the given list of targets.+  uint32 max_num_of_channels = 2;+  // The channel affinity configurations.+  repeated AffinityConfig affinity = 1001;+}++message AffinityConfig {+  enum Command {+    BOUND = 0;+    BIND = 1;+    UNBIND = 2;+  }++  // A selector an be a fully qualified name of an API element, or a wildcard+  // pattern ending with .*, such as foo.bar.A, foo.bar.*.+  // The rules are evaluated sequentially, and the first one wins.+  string selector = 1;+  // The affinity command applies on the selected API elements.+  // bound:+  //   The annotated method will be required to bound to an existing session to+  // execute the RPC. The corresponding <path> will be used to find the affinity+  // key from the request message.+  // bind:+  //   The annotated method will establish the channel affinity with the channel+  // which is used to execute the RPC. The corresponding <path> will be used to+  // find the affinity key from the response message.+  // unbind:+  //   The annotated method will remove the channel affinity with the channel+  // which is used to execute the RPC. The corresponding <path> will be used to+  // find the affinity key from the request message.+  Command command = 2;+  // The path of the affinity key in the request/response proto.+  string path = 3;",consider renaming this .. and provide an example (as a path to a proto field).,
14932100,adelez,https://api.github.com/repos/grpc/grpc/pulls/15059,183852412,2018-04-24T19:28:33Z,tools/run_tests/run_interop_tests.py,"@@ -1477,19 +1465,14 @@ def aggregate_http2_results(stdout):     http2_server_test_cases = (_HTTP2_SERVER_TEST_CASES                                if args.http2_server_interop else []) -    report_utils.render_interop_html_report(-        set([str(l) for l in languages]), servers, _TEST_CASES,-        _AUTH_TEST_CASES, _HTTP2_TEST_CASES, http2_server_test_cases, resultset,-        num_failures, args.cloud_to_prod_auth or args.cloud_to_prod,-        args.prod_servers, args.http2_interop)-     if num_failures:         sys.exit(1)     else:         sys.exit(0) except Exception as e:     print('exception occurred:')     traceback.print_exc(file=sys.stdout)+    sys.exit(1)","Kokoro will shows success even if there's an error. The effect on cleanup will be the same as the case without exception, right?",
5348297,summerxyt,https://api.github.com/repos/grpc/grpc/pulls/14793,183859439,2018-04-24T19:54:35Z,src/cpp/server/load_reporter/load_data_store.h,"@@ -0,0 +1,321 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_SRC_CPP_SERVER_LOAD_REPORTER_LOAD_DATA_STORE_H+#define GRPC_SRC_CPP_SERVER_LOAD_REPORTER_LOAD_DATA_STORE_H++#include <grpc/support/port_platform.h>++#include <memory>+#include <set>+#include <unordered_map>++#include <grpc/support/log.h>+#include <grpcpp/impl/codegen/config.h>++namespace grpc {+namespace load_reporter {++constexpr char kInvalidLbId[] = ""<INVALID_LBID_238dsb234890rb>"";+constexpr uint8_t kLbIdLen = 8;++// The load data storage is organized in hierarchy. The LoadDataStore is the+// top-level data store. In LoadDataStore, for each host we keep a+// PerHostStore, in which for each balancer we keep a PerBalancerStore. Each+// PerBalancerStore maintains a map of load records, mapping from LoadRecordKey+// to LoadRecordValue. The LoadRecordValue contains a map of customized call+// metrics, mapping from a call metric name to the CallMetricValue.++// The value of a customized call metric.+class CallMetricValue {+ public:+  explicit CallMetricValue(uint64_t count = 0, double total = 0)+      : count_(count), total_(total) {}++  void MergeFrom(CallMetricValue other) {+    count_ += other.count_;+    total_ += other.total_;+  }++  // Getters.+  uint64_t count() const { return count_; }+  double total() const { return total_; }++ private:+  uint64_t count_ = 0;+  double total_ = 0;+};++// The key of a load record.+class LoadRecordKey {+ public:+  explicit LoadRecordKey(grpc::string lb_id, grpc::string lb_tag,+                         grpc::string user_id, grpc::string client_ip_hex)+      : lb_id_(std::move(lb_id)),+        lb_tag_(std::move(lb_tag)),+        user_id_(std::move(user_id)),+        client_ip_hex_(std::move(client_ip_hex)) {}++  grpc::string ToString() const {+    return ""[lb_id_="" + lb_id_ + "", lb_tag_="" + lb_tag_ ++           "", user_id_="" + user_id_ + "", client_ip_hex_="" + client_ip_hex_ ++           ""]"";+  }++  bool operator==(const LoadRecordKey& other) const {+    return lb_id_ == other.lb_id_ && lb_tag_ == other.lb_tag_ &&+           user_id_ == other.user_id_ && client_ip_hex_ == other.client_ip_hex_;+  }++  // Getters.+  const grpc::string& lb_id() const { return lb_id_; }+  const grpc::string& lb_tag() const { return lb_tag_; }+  const grpc::string& user_id() const { return user_id_; }+  const grpc::string& client_ip_hex() const { return client_ip_hex_; }++  struct Hasher {+    size_t operator()(const LoadRecordKey& k) const {+      return std::hash<grpc::string>()(k.lb_id_) ^+             std::hash<grpc::string>()(k.lb_tag_) ^+             std::hash<grpc::string>()(k.user_id_) ^+             std::hash<grpc::string>()(k.client_ip_hex_);+    }+  };++ private:+  grpc::string lb_id_;+  grpc::string lb_tag_;+  grpc::string user_id_;+  grpc::string client_ip_hex_;+};++// The value of a load record.+class LoadRecordValue {+ public:+  explicit LoadRecordValue(uint64_t start_count = 0, uint64_t ok_count = 0,+                           uint64_t error_count = 0, double bytes_sent = 0,+                           double bytes_recv = 0, double latency_ms = 0)+      : start_count_(start_count),+        ok_count_(ok_count),+        error_count_(error_count),+        bytes_sent_(bytes_sent),+        bytes_recv_(bytes_recv),+        latency_ms_(latency_ms) {}++  void MergeFrom(const LoadRecordValue& other) {+    start_count_ += other.start_count_;+    ok_count_ += other.ok_count_;+    error_count_ += other.error_count_;+    bytes_sent_ += other.bytes_sent_;+    bytes_recv_ += other.bytes_recv_;+    latency_ms_ += other.latency_ms_;+    for (const auto& p : other.call_metrics_) {+      const grpc::string& key = p.first;+      const CallMetricValue& value = p.second;+      call_metrics_[key].MergeFrom(value);+    }+  }++  int64_t GetNumCallsInProgressDelta() const {+    return static_cast<int64_t>(start_count_ - ok_count_ - error_count_);+  }++  grpc::string ToString() const {+    return ""[start_count_="" + grpc::to_string(start_count_) ++           "", ok_count_="" + grpc::to_string(ok_count_) ++           "", error_count_="" + grpc::to_string(error_count_) ++           "", bytes_sent_="" + grpc::to_string(bytes_sent_) ++           "", bytes_recv_="" + grpc::to_string(bytes_recv_) ++           "", latency_ms_="" + grpc::to_string(latency_ms_) + ""]"";+  }++  bool InsertCallMetric(const grpc::string& metric_name,+                        const CallMetricValue& metric_value) {+    return call_metrics_.insert({metric_name, metric_value}).second;+  }++  // Getters.+  uint64_t start_count() const { return start_count_; }+  uint64_t ok_count() const { return ok_count_; }+  uint64_t error_count() const { return error_count_; }+  double bytes_sent() const { return bytes_sent_; }+  double bytes_recv() const { return bytes_recv_; }+  double latency_ms() const { return latency_ms_; }+  const std::unordered_map<grpc::string, CallMetricValue>& call_metrics()+      const {+    return call_metrics_;+  }++ private:+  uint64_t start_count_ = 0;+  uint64_t ok_count_ = 0;+  uint64_t error_count_ = 0;+  double bytes_sent_ = 0;+  double bytes_recv_ = 0;+  double latency_ms_ = 0;+  std::unordered_map<grpc::string, CallMetricValue> call_metrics_;+};++// Stores the data associated with a particular LB ID.+class PerBalancerStore {+ public:+  using LoadRecordMap =+      std::unordered_map<LoadRecordKey, LoadRecordValue, LoadRecordKey::Hasher>;++  PerBalancerStore(grpc::string lb_id, grpc::string load_key)+      : lb_id_(std::move(lb_id)), load_key_(std::move(load_key)) {}++  // Merge a load record with the given key and value if the store is not+  // suspended.+  void MergeRow(const LoadRecordKey& key, const LoadRecordValue& value);++  bool IsSuspended() const { return suspended_; }++  void Suspend();++  void Resume();++  bool IsNumCallsInProgressChangedSinceLastReport() const {+    return num_calls_in_progress_ != last_reported_num_calls_in_progress_;+  }++  uint64_t GetNumCallsInProgressForReport();++  grpc::string ToString() {+    return ""[PerBalancerStore lb_id_="" + lb_id_ + "" load_key_="" + load_key_ ++           ""]"";+  }++  void ClearLoadRecordMap() { load_record_map_.clear(); }++  // Getters.+  const grpc::string& lb_id() const { return lb_id_; }+  const grpc::string& load_key() const { return load_key_; }+  const LoadRecordMap& load_record_map() const { return load_record_map_; }++ private:+  grpc::string lb_id_;+  // TODO(juanlishen): Use bytestring protobuf type?+  grpc::string load_key_;+  LoadRecordMap load_record_map_;+  uint64_t num_calls_in_progress_ = 0;+  uint64_t last_reported_num_calls_in_progress_ = 0;+  bool suspended_ = false;+};++// Stores the data associated with a particular host.+class PerHostStore {+ public:+  // When a report stream is created, a PerBalancerStore is created for the+  // LB ID (guaranteed unique) associated with that stream. If it is the only+  // active store, adopt all the orphaned stores. If it is the first created+  // store, adopt the store of kInvalidLbId.+  void ReportStreamCreated(const grpc::string& lb_id,+                           const grpc::string& load_key);++  // When a report stream is closed, the PerBalancerStores assigned to the+  // associate LB ID need to be re-assigned to other active balancers,+  // ideally with the same load key. If there is no active balancer, we have+  // to suspend those stores and drop the incoming load data until they are+  // resumed.+  void ReportStreamClosed(const grpc::string& lb_id);++  PerBalancerStore* FindPerBalancerStore(const grpc::string& lb_id) const;++  // Returns null if lb_id is not found.+  const std::set<PerBalancerStore*>* GetAssignedStores(+      const grpc::string& lb_id) const;++ private:+  // Creates a PerBalancerStore for the given LB ID, assigns the store to+  // itself, and records the LB ID to the load key.+  void InternalAddLb(const grpc::string& lb_id, const grpc::string& load_key);++  void AssignOrphanedStore(PerBalancerStore* orphaned_store,+                           const grpc::string& new_receiver);++  std::unordered_map<grpc::string, std::set<grpc::string>>+      load_key_to_receiving_lb_ids_;++  // Key: LB ID. The key set includes all the LB IDs that have been+  // allocated for reporting streams so far.+  // Value: the unique pointer to the PerBalancerStore of the LB ID.+  std::unordered_map<grpc::string, std::unique_ptr<PerBalancerStore>>+      per_balancer_stores_;++  // Key: LB ID. The key set includes the LB IDs of the balancers that are+  // currently receiving report.+  // Value: the set of raw pointers to the PerBalancerStores assigned to the LB+  // ID. Note that the sets in assigned_stores_ form a division of the value set+  // of per_balancer_stores_.+  std::unordered_map<grpc::string, std::set<PerBalancerStore*>>+      assigned_stores_;+};++// Two-level bookkeeper of all the load data.+// Note: We never remove any store objects from this class, as per the+// current spec. That's because premature removal of the store objects+// may lead to loss of critical information, e.g., mapping from lb_id to+// load_key, and the number of in-progress calls. Such loss will cause+// information inconsistency when the balancer is re-connected. Keeping+// all the stores should be fine for PerHostStore, since we assume there+// should only be a few hostnames. But it's a potential problem for+// PerBalancerStore.+class LoadDataStore {+ public:+  PerBalancerStore* FindPerBalancerStore(const grpc::string& hostname,+                                         const grpc::string& lb_id) const;++  // Returns null if hostname or lb_id is not found.+  const std::set<PerBalancerStore*>* GetAssignedStores(const string& hostname,",I dislike the interface returns a raw pointer. You can return std::set<> or add comment saying the returned pointer points to the underlying data structure and the caller has no need to delete the pointer.,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/14894,183900929,2018-04-24T22:39:31Z,src/core/lib/iomgr/timer_generic.cc,"@@ -404,15 +420,22 @@ static void timer_init(grpc_timer* timer, grpc_millis deadline,   if (is_first_timer) {     gpr_mu_lock(&g_shared_mutables.mu);     if (grpc_timer_trace.enabled()) {-      gpr_log(GPR_DEBUG, ""  .. old shard min_deadline=%"" PRIdPTR,+      gpr_log(GPR_DEBUG, ""  .. old shard min_deadline=%"" PRId64,               shard->min_deadline);     }     if (deadline < shard->min_deadline) {-      gpr_atm old_min_deadline = g_shard_queue[0]->min_deadline;+      grpc_millis old_min_deadline = g_shard_queue[0]->min_deadline;       shard->min_deadline = deadline;       note_deadline_change(shard);       if (shard->shard_queue_index == 0 && deadline < old_min_deadline) {+#if GPR_ARCH_64         gpr_atm_no_barrier_store(&g_shared_mutables.min_timer, deadline);","Now that deadline and other uses are grpc_millis, shouldn't there be a static_cast or something to gpr_atm in these cases? Since the arguments to atm_store/load are supposed to be gpr_atm afaik.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/15156,184134918,2018-04-25T16:59:23Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/dns_resolver_ares.cc,"@@ -363,6 +363,7 @@ void AresDnsResolver::OnResolvedLocked(void* arg, grpc_error* error) { }  void AresDnsResolver::MaybeStartResolvingLocked() {+  if (have_next_resolution_timer_) return;","I prefer either of the following methods to fix the conflict of an incoming re-resolution and the existing timer.1.  We can choose to keep the existing timer.The re-resolution request will be immediately fed the cached results. But we don't start resolving until the existing timer fires.2. We can choose to service the re-resolution request as soon as possible.If we are not in cooldown, just cancel the existing timer and start resolving.If we are in cooldown, cancel the existing timer and start a new timer according to the cooldown ending point. This will always make the timer fire earlier because the cooldown interval is 1s and the initial backoff interval is also 1s. With the current fix, we will still start resolving as long as we are not in cooldown, no matter there is a pending timer or not. But my opinion is that there is no need for the pending timer to exist if we have already start resolving. But I'm fine with the current fix if we need to address the issue quickly. ",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/14387,184169360,2018-04-25T18:50:10Z,src/core/lib/security/security_connector/security_connector.h,"@@ -244,6 +244,9 @@ tsi_peer tsi_shallow_peer_from_ssl_auth_context(     const grpc_auth_context* auth_context); void tsi_shallow_peer_destruct(tsi_peer* peer); ",sorry I was not clear. Please delete line 246 & 247.ssl_host_matches_name belongs to functions that are testing only.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/14387,184216308,2018-04-25T21:49:20Z,src/core/lib/security/security_connector/security_connector.h,"@@ -243,6 +243,7 @@ grpc_auth_context* tsi_ssl_peer_to_auth_context(const tsi_peer* peer); tsi_peer tsi_shallow_peer_from_ssl_auth_context(     const grpc_auth_context* auth_context); void tsi_shallow_peer_destruct(tsi_peer* peer);+int ssl_host_matches_name(const tsi_peer* peer, const char* peer_name);","@jiangtaoli2016's team owns the TSI API, so he can speak to whether he wants this in that namespace.Note that the existing `tsi_*` functions in this header file are IMHO either incorrectly named or else are in the wrong place.  If they are actually part of TSI, they belong somewhere in `src/core/tsi`; otherwise, they should be named with a `grpc_` prefix instead of a `tsi_` prefix.  But this is a pre-existing problem, not something you should need to fix in this PR.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/15196,184485229,2018-04-26T18:17:22Z,src/cpp/server/load_reporter/load_reporter.cc,"@@ -0,0 +1,396 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <iomanip>+#include <sstream>++#include ""src/cpp/server/load_reporter/get_cpu_stats.h""+#include ""src/cpp/server/load_reporter/load_reporter.h""+#include ""src/cpp/server/load_reporter/util.h""++namespace grpc {+namespace load_reporter {++using ::opencensus::stats::Aggregation::Count;+using ::opencensus::stats::Aggregation::Sum;+using ::opencensus::stats::AggregationWindow::Delta;+using ::opencensus::stats::SetAggregationWindow;+using ::opencensus::stats::View;+using ::opencensus::stats::ViewData;+using ::opencensus::stats::ViewDescriptor;++std::pair<uint64_t, uint64_t> CpuStatsProviderDefaultImpl::GetCpuStats() {+  return get_cpu_stats();+}++CensusViewProviderDefaultImpl::CensusViewProviderDefaultImpl() {+  // One view related to starting a call.+  auto vd_start_count =+      ViewDescriptor()+          .set_name(grpc::string(kViewPath) + grpc::string(kViewStartCount))+          .set_measure(grpc::string(kMeasurePath) ++                       grpc::string(kMeasureStartCount))+          .set_aggregation(Count())+          .add_column(""token"")+          .add_column(""host"")+          .add_column(""user_id"")+          .set_description(+              ""Delta count of calls started broken down by <token, host, ""+              ""user_id>."");+  SetAggregationWindow(Delta(), &vd_start_count);+  view_map_.insert({kViewStartCount, View(vd_start_count)});+  // Four views related to ending a call.+  auto vd_end_count =+      ViewDescriptor()+          .set_name(grpc::string(kViewPath) + grpc::string(kViewEndCount))+          .set_measure(grpc::string(kMeasurePath) ++                       grpc::string(kMeasureEndBytesSent))+          .set_aggregation(Count())+          .add_column(""token"")+          .add_column(""host"")+          .add_column(""user_id"")+          .add_column(""status"")+          .set_description(+              ""Delta count of calls ended broken down by <token, host, ""+              ""user_id, status>."");+  SetAggregationWindow(Delta(), &vd_end_count);+  view_map_.insert({kViewEndCount, View(vd_end_count)});+  auto vd_end_bytes_sent =+      ViewDescriptor()+          .set_name(grpc::string(kViewPath) + grpc::string(kViewEndBytesSent))+          .set_measure(grpc::string(kMeasurePath) ++                       grpc::string(kMeasureEndBytesSent))+          .set_aggregation(Sum())+          .add_column(""token"")+          .add_column(""host"")+          .add_column(""user_id"")+          .add_column(""status"")+          .set_description(+              ""Delta sum of bytes sent broken down by <token, host, user_id, ""+              ""status>."");+  SetAggregationWindow(Delta(), &vd_end_bytes_sent);+  view_map_.insert({kViewEndBytesSent, View(vd_end_bytes_sent)});+  auto vd_end_bytes_received =+      ViewDescriptor()+          .set_name(grpc::string(kViewPath) ++                    grpc::string(kViewEndBytesReceived))+          .set_measure(grpc::string(kMeasurePath) ++                       grpc::string(kMeasureEndBytesReceived))+          .set_aggregation(Sum())+          .add_column(""token"")+          .add_column(""host"")+          .add_column(""user_id"")+          .add_column(""status"")+          .set_description(+              ""Delta sum of bytes received broken down by <token, host, ""+              ""user_id, status>."");+  SetAggregationWindow(Delta(), &vd_end_bytes_received);+  view_map_.insert({kViewEndBytesReceived, View(vd_end_bytes_received)});+  auto vd_end_latency_ms =+      ViewDescriptor()+          .set_name(grpc::string(kViewPath) + grpc::string(kViewEndLatencyMs))+          .set_measure(grpc::string(kMeasurePath) ++                       grpc::string(kMeasureEndLatencyMs))+          .set_aggregation(Sum())+          .add_column(""token"")+          .add_column(""host"")+          .add_column(""user_id"")+          .add_column(""status"")+          .set_description(+              ""Delta sum of latency in ms broken down by <token, host, ""+              ""user_id, status>."");+  SetAggregationWindow(Delta(), &vd_end_latency_ms);+  view_map_.insert({kViewEndLatencyMs, View(vd_end_latency_ms)});+  // Two views related to other call metrics.+  auto vd_metric_call_count =+      ViewDescriptor()+          .set_name(grpc::string(kViewPath) ++                    grpc::string(kViewOtherCallMetricCount))+          .set_measure(grpc::string(kMeasurePath) ++                       grpc::string(kMeasureOtherCallMetric))+          .set_aggregation(Count())+          .add_column(""token"")+          .add_column(""host"")+          .add_column(""user_id"")+          .add_column(""metric_name"")+          .set_description(+              ""Delta count of calls broken down by <token, host, user_id, ""+              ""metric_name>."");+  SetAggregationWindow(Delta(), &vd_metric_call_count);+  view_map_.insert({kViewOtherCallMetricCount, View(vd_metric_call_count)});+  auto vd_metric_value = ViewDescriptor()+                             .set_name(grpc::string(kViewPath) ++                                       grpc::string(kViewOtherCallMetricValue))+                             .set_measure(grpc::string(kMeasurePath) ++                                          grpc::string(kMeasureOtherCallMetric))+                             .set_aggregation(Sum())+                             .add_column(""token"")+                             .add_column(""host"")+                             .add_column(""user_id"")+                             .add_column(""metric_name"")+                             .set_description(+                                 ""Delta sum of call metric value broken down ""+                                 ""by <token, host, user_id, metric_name>."");+  SetAggregationWindow(Delta(), &vd_metric_value);+  view_map_.insert({kViewOtherCallMetricValue, View(vd_metric_value)});+}++CensusViewProvider::ViewDataMap CensusViewProviderDefaultImpl::FetchViewData() {",@isturdy This is how I fetch the data.,
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/15205,184569331,2018-04-27T00:56:45Z,src/core/lib/iomgr/closure.h,"@@ -253,8 +253,8 @@ inline void grpc_closure_run(grpc_closure* c, grpc_error* error) {     c->file_initiated = file;     c->line_initiated = line;     c->run = true;+    GPR_ASSERT(c->cb != nullptr);",How do we know that c->cb being null isn't a fatal condition?,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/15211,184698947,2018-04-27T14:11:16Z,.github/ISSUE_TEMPLATE.md,"@@ -1,12 +1,12 @@-Please answer these questions before submitting your issue. - -### Should this be an issue in the gRPC issue tracker?- -Create new issues for bugs and feature requests. An issue needs to be actionable. General gRPC discussions and usage questions belong to:-- [grpc.io mailing list](https://groups.google.com/forum/#!forum/grpc-io)-- [StackOverflow, with `grpc` tag](http://stackoverflow.com/questions/tagged/grpc)- -*Please don't double post your questions in more locations; we are monitoring both channels, and the time spent de-duplicating questions is better spent answering more user questions.*+<!--++This form is for bug reports and feature requests ONLY!+For general questions and troubleshooting, please ask/look for answers here:+- grpc.io mailing list: https://groups.google.com/forum/#!forum/grpc-io+- StackOverflow, with ""grpc"" tag: http://stackoverflow.com/questions/tagged/grpc++Issues specific to *grpc-java*, *grpc-go*, *grpc-node*, *grpc-dart*, *grpc-web* should be created in the repository they belong to (e.g. https://github.com/grpc/grpc-LANGUAGE/issues/new)",I didn't want to take up too much space by explicitly listing 5 longish links.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15200,184701435,2018-04-27T14:19:14Z,src/core/lib/iomgr/combiner.cc,"@@ -343,6 +345,39 @@ static void combiner_finally_exec(grpc_closure* closure, grpc_error* error) {   grpc_closure_list_append(&lock->final_list, closure, error); } +static void combiner_run(grpc_closure* closure, grpc_error* error) {+#ifndef NDEBUG+  closure->scheduled = false;+  grpc_combiner* lock = COMBINER_FROM_CLOSURE_SCHEDULER(closure, scheduler);+  GRPC_COMBINER_TRACE(gpr_log(+      GPR_DEBUG,+      ""Combiner:%p grpc_combiner_run closure:%p created [%s:%d] run [%s:%d]"",+      lock, closure, closure->file_created, closure->line_created,+      closure->file_initiated, closure->line_initiated));+  GPR_ASSERT(grpc_core::ExecCtx::Get()->combiner_data()->active_combiner ==","I do like the idea of providing closure_run() semantics for combiner closures, but I think I'd want this check even in non-debug builds.  Otherwise, we would be blind to bugs where we call closure_run() on a combiner closure while not actually holding the lock.Could we make this cheaper by using a thread-local variable to cache the fact that we're currently holding the combiner in between closure executions?  I'm not that familiar with thread-local variables, but if they're cheaper than atomics, then this might be a performance win, even for the closure_sched() case.Actually, this makes me realize that there might be another problem here: If we switch to using closure_run() instead of closure_sched() by default, then what happens if we are currently running in the combiner and then call closure_run() on a closure that is *not* scheduled on the combiner?  Do we have a way to automatically yield the combiner at that point?  If not, we probably need to figure out a way to do that.",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/15132,184740378,2018-04-27T16:33:49Z,src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi,"@@ -14,82 +14,445 @@  cimport cpython +import collections",Seems to be unused.,
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/15132,184740982,2018-04-27T16:36:36Z,src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi,"@@ -14,82 +14,445 @@  cimport cpython +import collections+import threading++_INTERNAL_CALL_ERROR_MESSAGE_FORMAT = (+    'Internal gRPC call error %d. ' ++    'Please report to https://github.com/grpc/grpc/issues')+++cdef str _call_error_metadata(metadata):+  return 'metadata was invalid: %s' % metadata+++cdef str _call_error_no_metadata(c_call_error):+  return _INTERNAL_CALL_ERROR_MESSAGE_FORMAT % c_call_error+++cdef str _call_error(c_call_error, metadata):+  if c_call_error == GRPC_CALL_ERROR_INVALID_METADATA:+    return _call_error_metadata(metadata)+  else:+    return _call_error_no_metadata(c_call_error)+++cdef _check_call_error_no_metadata(c_call_error):","Nit: Should this be ""invalid_metadata"" instead of ""no_metadata""?",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/15132,184743427,2018-04-27T16:46:12Z,src/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi,"@@ -20,6 +20,59 @@ import time cdef int _INTERRUPT_CHECK_PERIOD_MS = 200  +cdef grpc_event _next(grpc_completion_queue *c_completion_queue, deadline):+  cdef gpr_timespec c_increment+  cdef gpr_timespec c_timeout+  cdef gpr_timespec c_deadline+  c_increment = gpr_time_from_millis(_INTERRUPT_CHECK_PERIOD_MS, GPR_TIMESPAN)+  if deadline is None:+    c_deadline = gpr_inf_future(GPR_CLOCK_REALTIME)+  else:+    c_deadline = _timespec_from_time(deadline)++  with nogil:+    while True:+      c_timeout = gpr_time_add(gpr_now(GPR_CLOCK_REALTIME), c_increment)+      if gpr_time_cmp(c_timeout, c_deadline) > 0:+        c_timeout = c_deadline+      c_event = grpc_completion_queue_next(c_completion_queue, c_timeout, NULL)+      if (c_event.type != GRPC_QUEUE_TIMEOUT or+          gpr_time_cmp(c_timeout, c_deadline) == 0):+        break++      # Handle any signals+      with gil:+        cpython.PyErr_CheckSignals()+  return c_event+++cdef _interpret_event(grpc_event c_event):+  cdef _Tag tag+  if c_event.type == GRPC_QUEUE_TIMEOUT:+    # NOTE(nathaniel): For now we coopt ConnectivityEvent here.+    return None, ConnectivityEvent(GRPC_QUEUE_TIMEOUT, False, None)+  elif c_event.type == GRPC_QUEUE_SHUTDOWN:+    # NOTE(nathaniel): For now we coopt ConnectivityEvent here.+    return None, ConnectivityEvent(GRPC_QUEUE_SHUTDOWN, False, None)+  else:+    tag = <_Tag>c_event.tag+    # We receive event tags only after they've been inc-ref'd elsewhere in+    # the code.+    cpython.Py_DECREF(tag)+    return tag, tag.event(c_event)+++cdef _immediate_event(grpc_completion_queue *c_completion_queue):",Is this now unused?,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/15132,184777194,2018-04-27T18:52:43Z,src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi,"@@ -14,82 +14,445 @@  cimport cpython +import collections+import threading++_INTERNAL_CALL_ERROR_MESSAGE_FORMAT = (+    'Internal gRPC call error %d. ' ++    'Please report to https://github.com/grpc/grpc/issues')+++cdef str _call_error_metadata(metadata):+  return 'metadata was invalid: %s' % metadata+++cdef str _call_error_no_metadata(c_call_error):+  return _INTERNAL_CALL_ERROR_MESSAGE_FORMAT % c_call_error+++cdef str _call_error(c_call_error, metadata):+  if c_call_error == GRPC_CALL_ERROR_INVALID_METADATA:+    return _call_error_metadata(metadata)+  else:+    return _call_error_no_metadata(c_call_error)+++cdef _check_call_error_no_metadata(c_call_error):","The ""no"" here means ""metadata isn't involved, so don't bother exploring whether or not the error is an invalid metadata error"". Would you like a comment here?",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/15205,184789793,2018-04-27T19:48:36Z,src/core/lib/iomgr/closure.h,"@@ -253,8 +253,8 @@ inline void grpc_closure_run(grpc_closure* c, grpc_error* error) {     c->file_initiated = file;     c->line_initiated = line;     c->run = true;+    GPR_ASSERT(c->cb != nullptr);",It IS a fatal condition. But it's going to be due to a programmer error. I don't mind placing this out of the debug block either. A couple clock cycles should not be that bad.,
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/15181,185029597,2018-04-30T15:57:35Z,doc/command_line_tool.md,"@@ -38,15 +38,27 @@ In order to build the grpc command line tool from a fresh clone of the grpc repository, you need to run the following command to update submodules:  ```-git submodule update --init+$ git submodule update --init ```-+---+### Unix user You also need to have the gflags library installed on your system. On Linux systems, gflags can be installed with the following command:  ```-sudo apt-get install libgflags-dev+$ sudo apt-get install libgflags-dev+```++### OSX user+This is a C++ CLI, and you need gflags to build it.+```+$ brew install gflags+```+You need to have automake installed on your system.","This can be removed, as it's already covered in the installation instructions at https://github.com/grpc/grpc/blob/master/INSTALL.md, which are linked to at the start of this section as pre-requisites.",
22083734,matt-kwong,https://api.github.com/repos/grpc/grpc/pulls/15175,185148044,2018-05-01T00:49:49Z,tools/run_tests/performance/build_performance.sh,"@@ -55,6 +55,9 @@ do   ""csharp"")     python tools/run_tests/run_tests.py -l ""$language"" -c ""$CONFIG"" --build_only -j 8 --compiler coreclr     ;;+  ""node""|""node_purejs"")+    tools/run_tests/performance/build_performance_node.sh","```[CXX]     Compiling test/cpp/end2end/test_service_impl.cc[CXX]     Compiling test/cpp/util/byte_buffer_proto_helper.cc[CXX]     Compiling test/cpp/util/channel_trace_proto_helper.cc2018-04-30 21:51:35,996 TIMEOUT: remote_host_build.grpc-kokoro-performance-client-8core [pid=6354, time=909.1sec]```It looks like it's timing out when trying to prepare the remote workers. I suspect this is simply because of the added overhead of building Node and not any actual issue. Is there anything that can be done here to speed up building Node?We can also increase the timeout. [`build_timeout`](https://github.com/grpc/grpc/blob/master/tools/run_tests/run_performance_tests.py#L250) and [`local_build_timeout`](https://github.com/grpc/grpc/blob/master/tools/run_tests/run_performance_tests.py#L252) can be combined to be `build_timeout = 30 * 60` since it's timing out when building on remote hosts. This [reference](https://github.com/grpc/grpc/blob/master/tools/run_tests/run_performance_tests.py#L272) will also need to be updated. ",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/15200,185157960,2018-05-01T02:39:50Z,src/core/lib/iomgr/combiner.cc,"@@ -343,6 +345,39 @@ static void combiner_finally_exec(grpc_closure* closure, grpc_error* error) {   grpc_closure_list_append(&lock->final_list, closure, error); } +static void combiner_run(grpc_closure* closure, grpc_error* error) {+#ifndef NDEBUG+  closure->scheduled = false;+  grpc_combiner* lock = COMBINER_FROM_CLOSURE_SCHEDULER(closure, scheduler);+  GRPC_COMBINER_TRACE(gpr_log(+      GPR_DEBUG,+      ""Combiner:%p grpc_combiner_run closure:%p created [%s:%d] run [%s:%d]"",+      lock, closure, closure->file_created, closure->line_created,+      closure->file_initiated, closure->line_initiated));+  GPR_ASSERT(grpc_core::ExecCtx::Get()->combiner_data()->active_combiner ==",I could also let combiner_run fallback on combiner_exec if the condition is not satisfied instead of asserting out.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15200,185242820,2018-05-01T15:03:36Z,src/core/lib/iomgr/combiner.cc,"@@ -343,6 +345,39 @@ static void combiner_finally_exec(grpc_closure* closure, grpc_error* error) {   grpc_closure_list_append(&lock->final_list, closure, error); } +static void combiner_run(grpc_closure* closure, grpc_error* error) {+#ifndef NDEBUG+  closure->scheduled = false;+  grpc_combiner* lock = COMBINER_FROM_CLOSURE_SCHEDULER(closure, scheduler);+  GRPC_COMBINER_TRACE(gpr_log(+      GPR_DEBUG,+      ""Combiner:%p grpc_combiner_run closure:%p created [%s:%d] run [%s:%d]"",+      lock, closure, closure->file_created, closure->line_created,+      closure->file_initiated, closure->line_initiated));+  GPR_ASSERT(grpc_core::ExecCtx::Get()->combiner_data()->active_combiner ==","I think that as long as we have separate `GRPC_CLOSURE_RUN()` and `GRPC_CLOSURE_SCHED()` calls and require callers to choose the right one, then we should make this an assertion to ensure that all callers are doing the right thing.  However, if we ever decided to switch to a model where we combine the two calls and expect the implementation to do the right thing based on the scheduler, then we could have the implementation switch dynamically.",
961599,murgatroid99,https://api.github.com/repos/grpc/grpc/pulls/15175,185276719,2018-05-01T17:16:38Z,tools/run_tests/performance/build_performance.sh,"@@ -55,6 +55,9 @@ do   ""csharp"")     python tools/run_tests/run_tests.py -l ""$language"" -c ""$CONFIG"" --build_only -j 8 --compiler coreclr     ;;+  ""node""|""node_purejs"")+    tools/run_tests/performance/build_performance_node.sh",The comments in that file seem to indicate that the `local_build_timeout` needs to be longer than the `build_timeout`. So does it make more sense to increase both?,
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/15221,185338234,2018-05-01T21:23:28Z,test/core/security/alts_credentials_fuzzer.cc,"@@ -0,0 +1,149 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <string.h>++#include <grpc/grpc.h>+#include <grpc/grpc_security.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>+#include ""test/core/util/memory_counters.h""++#include ""src/core/lib/gpr/env.h""+#include ""src/core/lib/security/credentials/alts/alts_credentials.h""+#include ""src/core/lib/security/credentials/alts/check_gcp_environment.h""+#include ""src/core/lib/security/credentials/alts/grpc_alts_credentials_options.h""++// Logging+bool squelch = true;+bool leak_check = true;++static void dont_log(gpr_log_func_args* args) {}++typedef struct {","the following struct, read_byte, read_string are the same as in test/core/end2end/fuzzers/api_fuzzer.ccmaybe create a common library?",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/15254,185668818,2018-05-02T23:38:54Z,src/python/grpcio/grpc/__init__.py,"@@ -926,6 +930,15 @@ def stream_stream(self,         """"""         raise NotImplementedError() +    @abc.abstractmethod+    def close(self):","Please document it as idempotent: ""closing a closed channel is a no-op"" or something along that line.  This is important because it is not just a feature to advertise, but to restrict all the implementers to ensure this method is indeed idempotent. ",
28968539,ZhouyihaiDing,https://api.github.com/repos/grpc/grpc/pulls/15218,185963815,2018-05-03T23:35:47Z,src/php/ext/grpc/channel.c,"@@ -445,52 +561,51 @@ PHP_METHOD(Channel, watchConnectivityState) {   RETURN_BOOL(event.success); } +/**+ * Get the status the channel is usable or not+ * @return bool If the Channel is closed before, return false.+ */+PHP_METHOD(Channel, isValid) {",I will delete this unused method.,
28968539,ZhouyihaiDing,https://api.github.com/repos/grpc/grpc/pulls/15218,186156766,2018-05-04T17:42:12Z,src/php/ext/grpc/channel.c,"@@ -518,20 +603,137 @@ static void php_grpc_channel_plink_dtor(php_grpc_zend_resource *rsrc     return;   }   if (le->channel != NULL) {-    gpr_mu_lock(&le->channel->mu);-    if (le->channel->wrapped != NULL) {-      grpc_channel_destroy(le->channel->wrapped);-      free(le->channel->args_hashstr);-      le->channel->wrapped = NULL;-      le->channel->target = NULL;-      le->channel->args_hashstr = NULL;-      free(le->channel->key);-      le->channel->key = NULL;-    }-    gpr_mu_unlock(&le->channel->mu);+    php_grpc_channel_unref(le->channel);+    le->channel = NULL;+  }+  free(le);+  le = NULL;+}++// A destructor associated with each list entry from the target_bound map+static void php_grpc_target_bound_dtor(php_grpc_zend_resource *rsrc+                                        TSRMLS_DC) {+  target_bound_le_t *le = (target_bound_le_t *) rsrc->ptr;+  if (le == NULL) {+    return;   }+  free(le);+  le = NULL;+}++#ifdef GRPC_PHP_DEBUG","It will only be compiled when the user set `enable-tests`:`./configure --enable-tests`Without setting it, the original tests can still pass, but need to exclude the new added tests by excluding them. The command is```php $extension_dir -d max_execution_time=300 $(which phpunit) -v --debug \  ../tests/unit_tests --exclude-group persistent_list_bound_tests ../tests/unit_tests```",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/15274,186171068,2018-05-04T18:04:09Z,include/grpc/grpc_security.h,"@@ -163,6 +164,12 @@ typedef struct {   const char* cert_chain; } grpc_ssl_pem_key_cert_pair; +typedef struct {+    int (*verify_peer_callback)(const char*, const char*, void*);","Please give proper comments about this struct. Instead of `int (*verify_peer_callback)(const char*, const char*, void*)`, use e.g., `int (*verify_peer_callback)(const char* target_name, const char* peer_pem, void* userdata)`and explain each parameter and return value.Also I assume this callback is blocking, right?",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/15274,186180338,2018-05-04T18:39:32Z,include/grpc/grpc_security.h,"@@ -176,7 +183,7 @@ typedef struct {      not have such a key/cert pair. */ GRPCAPI grpc_channel_credentials* grpc_ssl_credentials_create(     const char* pem_root_certs, grpc_ssl_pem_key_cert_pair* pem_key_cert_pair,-    void* reserved);+    verify_peer_options* verify_options, void* reserved);",Also add a comment about this new parameter.,
1009310,JackOfMostTrades,https://api.github.com/repos/grpc/grpc/pulls/15274,186217036,2018-05-04T20:49:06Z,include/grpc/grpc_security.h,"@@ -163,6 +164,12 @@ typedef struct {   const char* cert_chain; } grpc_ssl_pem_key_cert_pair; +typedef struct {+    int (*verify_peer_callback)(const char*, const char*, void*);","Yes, the callback is blocking. I added that clarification (along with a bunch of other detail) to comments.",
28968539,ZhouyihaiDing,https://api.github.com/repos/grpc/grpc/pulls/15218,186228142,2018-05-04T21:39:49Z,src/php/ext/grpc/channel.c,"@@ -162,6 +166,72 @@ void generate_sha1_str(char *sha1str, char *str, php_grpc_int len) {   make_sha1_digest(sha1str, digest); } +bool php_grpc_persistent_list_delete_unused_channel(char* target, target_bound_le_t* target_bound_status){+  char *key = NULL;+  zval *data;+  int key_type;+  PHP_GRPC_HASH_FOREACH_STR_KEY_VAL_START(&grpc_persistent_list, key, key_type, data)+    if (key_type != HASH_KEY_IS_STRING || key == NULL) {+      zend_throw_exception(spl_ce_InvalidArgumentException,+                           ""args keys must be strings"", 1 TSRMLS_CC);+      return FAILURE;+    }+    php_grpc_zend_resource *rsrc  = (php_grpc_zend_resource*) PHP_GRPC_HASH_VALPTR_TO_VAL(data)+    if (rsrc == NULL) {+      break;+    }+    channel_persistent_le_t* le = rsrc->ptr;+    // Find the channel sharing the same target.+    if (strcmp(le->channel->target, target) == 0) {+      // ref_count=1 means that only the map holds the reference to the channel.+      if(le->channel->ref_count == 1) {+        php_grpc_delete_persistent_list_entry(le->channel->key,","Inside `php_grpc_delete_persistent_list_entry`, it will call  [php_grpc_zend_hash_del](https://github.com/grpc/grpc/pull/15218/files/591fd4657130e335e0ae91747b2190498752a3e7#diff-f942bdda09aac4a837cef783506850f0R593), which will call the handler [`php_grpc_channel_plink_dtor`](https://github.com/grpc/grpc/blob/master/src/php/ext/grpc/channel.c#L514) to remove the map element.The [`unref`](https://github.com/grpc/grpc/pull/15218/files#diff-f942bdda09aac4a837cef783506850f0R579) is called inside the handler.The same as `ref` is called inside `create_channel` function, where the real channel is created.",
28968539,ZhouyihaiDing,https://api.github.com/repos/grpc/grpc/pulls/15218,186230347,2018-05-04T21:53:15Z,src/php/ext/grpc/channel.c,"@@ -162,6 +166,72 @@ void generate_sha1_str(char *sha1str, char *str, php_grpc_int len) {   make_sha1_digest(sha1str, digest); } +bool php_grpc_persistent_list_delete_unused_channel(char* target, target_bound_le_t* target_bound_status){+  char *key = NULL;+  zval *data;+  int key_type;+  PHP_GRPC_HASH_FOREACH_STR_KEY_VAL_START(&grpc_persistent_list, key, key_type, data)+    if (key_type != HASH_KEY_IS_STRING || key == NULL) {",In PHP5: [PHP_GRPC_HASH_FOREACH_STR_KEY_VAL_START](https://github.com/grpc/grpc/blob/master/src/php/ext/grpc/php7_wrapper.h#L86)In PHP7: [PHP_GRPC_HASH_FOREACH_STR_KEY_VAL_START](https://github.com/grpc/grpc/blob/master/src/php/ext/grpc/php7_wrapper.h#L86:9),
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/15200,186236766,2018-05-04T22:38:23Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -3242,7 +3242,7 @@ static void on_external_watch_complete_locked(void* arg, grpc_error* error) {                            ""external_connectivity_watcher"");   external_connectivity_watcher_list_remove(w->chand, w);   gpr_free(w);-  GRPC_CLOSURE_RUN(follow_up, GRPC_ERROR_REF(error));+  GRPC_CLOSURE_SCHED(follow_up, GRPC_ERROR_REF(error));",https://github.com/grpc/grpc/blob/fec4b30d9a94cb6700bfe92ab50a3eccb9ebf128/src/core/ext/filters/client_channel/channel_connectivity.cc#L221is one place where the closure being run is not initialized for the combiner. (This change was actually motivated by test failures which led to debugging and thereby modifying it.),
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/15221,186236950,2018-05-04T22:39:52Z,test/core/security/alts_credentials_fuzzer.cc,"@@ -0,0 +1,149 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <string.h>++#include <grpc/grpc.h>+#include <grpc/grpc_security.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>+#include ""test/core/util/memory_counters.h""++#include ""src/core/lib/gpr/env.h""+#include ""src/core/lib/security/credentials/alts/alts_credentials.h""+#include ""src/core/lib/security/credentials/alts/check_gcp_environment.h""+#include ""src/core/lib/security/credentials/alts/grpc_alts_credentials_options.h""++// Logging+bool squelch = true;+bool leak_check = true;++static void dont_log(gpr_log_func_args* args) {}++typedef struct {",Done. A common library fuzzer_util is created at test/core/util/.,
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/15218,186244925,2018-05-04T23:59:45Z,src/php/ext/grpc/channel.c,"@@ -162,6 +166,72 @@ void generate_sha1_str(char *sha1str, char *str, php_grpc_int len) {   make_sha1_digest(sha1str, digest); } +bool php_grpc_persistent_list_delete_unused_channel(char* target, target_bound_le_t* target_bound_status){+  char *key = NULL;+  zval *data;+  int key_type;+  PHP_GRPC_HASH_FOREACH_STR_KEY_VAL_START(&grpc_persistent_list, key, key_type, data)+    if (key_type != HASH_KEY_IS_STRING || key == NULL) {+      zend_throw_exception(spl_ce_InvalidArgumentException,+                           ""args keys must be strings"", 1 TSRMLS_CC);+      return FAILURE;+    }+    php_grpc_zend_resource *rsrc  = (php_grpc_zend_resource*) PHP_GRPC_HASH_VALPTR_TO_VAL(data)+    if (rsrc == NULL) {+      break;+    }+    channel_persistent_le_t* le = rsrc->ptr;+    // Find the channel sharing the same target.+    if (strcmp(le->channel->target, target) == 0) {+      // ref_count=1 means that only the map holds the reference to the channel.+      if(le->channel->ref_count == 1) {+        php_grpc_delete_persistent_list_entry(le->channel->key,+                                              strlen(le->channel->key)+                                              TSRMLS_CC);+        target_bound_status->current_count -= 1;+        if (target_bound_status->current_count < target_bound_status->upper_bound) {+          return true;+        }+      }+    }+  PHP_GRPC_HASH_FOREACH_END()+  return false;+}++target_bound_le_t* update_and_get_target_upper_bound(char* target, int bound) {+  php_grpc_zend_resource *rsrc;+  target_bound_le_t* target_bound_status;+  php_grpc_int key_len = strlen(target);+  if (!(PHP_GRPC_PERSISTENT_LIST_FIND(&grpc_target_upper_bound_map, target,+      key_len, rsrc))) {+    // Target is not not persisted.+    php_grpc_zend_resource new_rsrc;+    target_bound_status = malloc(sizeof(target_bound_le_t));+    if (bound == -1) {+      // If the bound is not set, use 1 as default.s+      bound = 1;+    }+    target_bound_status->upper_bound = bound;+    // Init current_count with 1. It should be add 1 when the channel is successfully+    // created and minus 1 when it is removed from the persistent list.+    target_bound_status->current_count = 0;","Just to confirm: `current_count` starts as 0, we increment and decrement when we add and remove from the persistent_list and it can never be -1 right?The `upper_bound` on the other hand has -1 as the ""uninitialized value""?",
28968539,ZhouyihaiDing,https://api.github.com/repos/grpc/grpc/pulls/15218,186246568,2018-05-05T00:28:31Z,src/php/ext/grpc/channel.c,"@@ -162,6 +166,72 @@ void generate_sha1_str(char *sha1str, char *str, php_grpc_int len) {   make_sha1_digest(sha1str, digest); } +bool php_grpc_persistent_list_delete_unused_channel(char* target, target_bound_le_t* target_bound_status){+  char *key = NULL;+  zval *data;+  int key_type;+  PHP_GRPC_HASH_FOREACH_STR_KEY_VAL_START(&grpc_persistent_list, key, key_type, data)+    if (key_type != HASH_KEY_IS_STRING || key == NULL) {+      zend_throw_exception(spl_ce_InvalidArgumentException,+                           ""args keys must be strings"", 1 TSRMLS_CC);+      return FAILURE;+    }+    php_grpc_zend_resource *rsrc  = (php_grpc_zend_resource*) PHP_GRPC_HASH_VALPTR_TO_VAL(data)+    if (rsrc == NULL) {+      break;+    }+    channel_persistent_le_t* le = rsrc->ptr;+    // Find the channel sharing the same target.+    if (strcmp(le->channel->target, target) == 0) {+      // ref_count=1 means that only the map holds the reference to the channel.+      if(le->channel->ref_count == 1) {+        php_grpc_delete_persistent_list_entry(le->channel->key,+                                              strlen(le->channel->key)+                                              TSRMLS_CC);+        target_bound_status->current_count -= 1;+        if (target_bound_status->current_count < target_bound_status->upper_bound) {+          return true;+        }+      }+    }+  PHP_GRPC_HASH_FOREACH_END()+  return false;+}++target_bound_le_t* update_and_get_target_upper_bound(char* target, int bound) {+  php_grpc_zend_resource *rsrc;+  target_bound_le_t* target_bound_status;+  php_grpc_int key_len = strlen(target);+  if (!(PHP_GRPC_PERSISTENT_LIST_FIND(&grpc_target_upper_bound_map, target,+      key_len, rsrc))) {+    // Target is not not persisted.+    php_grpc_zend_resource new_rsrc;+    target_bound_status = malloc(sizeof(target_bound_le_t));+    if (bound == -1) {+      // If the bound is not set, use 1 as default.s+      bound = 1;+    }+    target_bound_status->upper_bound = bound;+    // Init current_count with 1. It should be add 1 when the channel is successfully+    // created and minus 1 when it is removed from the persistent list.+    target_bound_status->current_count = 0;","I will add comment to it.It won't be -1. It is [incremented](https://github.com/grpc/grpc/pull/15218/files/2b5f5a7c347af10c4ced1b9e3d7aa103bc51f091#diff-f942bdda09aac4a837cef783506850f0R287) when inserting one channel into the persistent map, and [decremented](https://github.com/grpc/grpc/pull/15218/files/2b5f5a7c347af10c4ced1b9e3d7aa103bc51f091#diff-f942bdda09aac4a837cef783506850f0R191) when deleting a channel from the persistent list.`-1` is used to skip setting the upper bound part. It doesn't make sense when user set the upper_bound to a value less than 0, thus only update the the upper_bound when a positive number is set. And `upper_bound` can be any negative value to indicate as ""uninitialized value"".",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/15301,186624597,2018-05-08T06:07:09Z,templates/tools/dockerfile/clang_update.include,"@@ -1,28 +1,34 @@ #================= # Update clang to a version with improved tsan and fuzzing capabilities -RUN apt-get update && apt-get -y install python cmake && apt-get clean+RUN apt-get update && apt-get -y install python && apt-get clean -RUN git clone -n -b release_38 http://llvm.org/git/llvm.git && ${'\\'}-  cd llvm && git checkout ad57503 && cd ..-RUN git clone -n -b release_38 http://llvm.org/git/clang.git && ${'\\'}-  cd clang && git checkout ad2c56e && cd ..-RUN git clone -n -b release_38 http://llvm.org/git/compiler-rt.git && ${'\\'}-  cd compiler-rt && git checkout 3176922 && cd ..-RUN git clone -n -b release_38 ${'\\'}+RUN git clone -n -b release_50 http://llvm.org/git/llvm.git && ${'\\'}",nit: I am not a fan of building clang from source - it takes long time and brings some unnecessary clutter with it. Have we looked for binary distribution of clang?,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/15275,186633124,2018-05-08T06:59:50Z,tools/run_tests/performance/scenario_result_schema.json,"@@ -890,6 +890,31 @@         ""name"": ""core_http2_send_flowctl_per_write_99p"",          ""type"": ""FLOAT""       }, +      {",please note that adding more stats requires  running tools/run_tests/performance/patch_scenario_results_schema.py --bq_result_table on all datatests mentioned in https://github.com/grpc/grpc/blob/master/tools/internal_ci/linux/grpc_full_performance_release.sh and https://github.com/grpc/grpc/blob/master/tools/internal_ci/linux/grpc_full_performance_master.sh.prior to submit.(otherwise uploading of full benchmark results will get broken).,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/15251,186789050,2018-05-08T16:30:51Z,tools/internal_ci/linux/grpc_bazel_on_foundry_base.sh,"@@ -57,6 +57,8 @@ source tools/internal_ci/helper_scripts/prepare_build_linux_rc  if [ ""$UPLOAD_TEST_RESULTS"" != """" ] then+  # Sleep to let ResultStore finish writing results before querying",is there a risk of writing partial test results if result store takes longer or is this binary (result present / results not present -> error)?,
25475261,StilesCrisis,https://api.github.com/repos/grpc/grpc/pulls/15323,187178385,2018-05-09T21:15:05Z,test/core/json/json_test.cc,"@@ -107,6 +107,8 @@ static testing_pair testing_pairs[] = {     {"""", nullptr},     /* Testing extra characters after end of parsing. */     {""{},"", nullptr},+    /* Testing bad containers. */+    {""{\""x\"":}"", nullptr},",move to line 121 to be with the existing bad-container tests,
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/14870,187423844,2018-05-10T18:49:39Z,doc/fork_support.md,"@@ -0,0 +1,49 @@+# Background #++In Python multithreading is ineffective at concurrency for CPU bound tasks+due to the GIL.+(global interpreter lock).  Users use multiprocessing, subprocess, +and concurrent.futures.ProcessPoolExecutor, to work around the GIL.","nit: no comma after `ProcessPoolExecutor`, and we may not want this to read like an exhausive list (e.g., ""Users use libraries such as..."")",
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/14870,187425305,2018-05-10T18:54:58Z,doc/fork_support.md,"@@ -0,0 +1,49 @@+# Background #++In Python multithreading is ineffective at concurrency for CPU bound tasks+due to the GIL.+(global interpreter lock).  Users use multiprocessing, subprocess, +and concurrent.futures.ProcessPoolExecutor, to work around the GIL.+These modules call fork() underneath the hood. Various issues have+been reported when using these modules with gRPC Python.+Historically, we didn't support forking in gRPC, but some users seem+to be doing fine until their code started to break on version 1.6.  This was+likely caused by the addition of background c-threads and a background+Python thread.++# Current Status #+## 1.7 ##+A pthread_atfork() handler was added in 1.7 to automatically shut down+the background c-threads when fork was called.  This does not shut down the+background Python thread, so users could not have any open channels when+forking().++## 1.9 ##+A regression was noted in cases where users are doing fork/exec. This+was due to pthread_atfork() handler that was added in 1.7 to partially+support forking in gRPC. A deadlock can happen when pthread_atfork+handler is running, and an application thread is calling into gRPC.+We have provided a workaround for this issue by allowing users to turn +off the handler using env flag ```GRPC_ENABLE_FORK_SUPPORT=False```.+This should be set whenever a user expects to always call exec+immediately following fork.  It will disable the fork handlers.++## 1.11 ##+The background Python thread was removed entirely.  This allows forking+after creating a channel.  However, the channel cannot be used by both the+parent and child process after the fork.  Additionaly, the process should+not fork if there are any active RPCs on the channel.++# Future Work #+## 1.13 ##+The workaround when using fork/exec by setting+```GRPC_ENABLE_FORK_SUPPORT=False``` should no longer be needed.  Now the fork+handlers are automatically not run when multiple threads are calling+into gRPC.+++## 1.1x ##+We would like to support forking and using the channel from both the parent","I don't think we plan to support using the same channel in both parent and child, at least not now - rather, we want to support forking with active channels and active RPCs in the parent, with the child able to establish new (independent) gRPC connections. I'm going to file a new issue to track our plans for fork support, so it may be appropriate to drop this `1.1x` section entirely from this doc and just replace it with a link to the tracking issue.",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/14870,187444054,2018-05-10T20:06:42Z,doc/fork_support.md,"@@ -0,0 +1,49 @@+# Background #++In Python multithreading is ineffective at concurrency for CPU bound tasks+due to the GIL.+(global interpreter lock).  Users use multiprocessing, subprocess, +and concurrent.futures.ProcessPoolExecutor, to work around the GIL.+These modules call fork() underneath the hood. Various issues have+been reported when using these modules with gRPC Python.+Historically, we didn't support forking in gRPC, but some users seem+to be doing fine until their code started to break on version 1.6.  This was+likely caused by the addition of background c-threads and a background+Python thread.++# Current Status #+## 1.7 ##+A pthread_atfork() handler was added in 1.7 to automatically shut down+the background c-threads when fork was called.  This does not shut down the+background Python thread, so users could not have any open channels when+forking().++## 1.9 ##+A regression was noted in cases where users are doing fork/exec. This+was due to pthread_atfork() handler that was added in 1.7 to partially+support forking in gRPC. A deadlock can happen when pthread_atfork+handler is running, and an application thread is calling into gRPC.+We have provided a workaround for this issue by allowing users to turn +off the handler using env flag ```GRPC_ENABLE_FORK_SUPPORT=False```.+This should be set whenever a user expects to always call exec+immediately following fork.  It will disable the fork handlers.++## 1.11 ##+The background Python thread was removed entirely.  This allows forking+after creating a channel.  However, the channel cannot be used by both the","1.Deadlocks and or corrupted wire data.  Added a comment.2.I think so, as long as the channel is not used in the parent process.  I've made that explicit, (do not use channel before fork).3.The environment variable is still required using fork/exec.  It will no longer be required in 1.13.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/15315,187744486,2018-05-11T22:09:37Z,include/grpcpp/impl/codegen/byte_buffer.h,"@@ -96,6 +96,11 @@ class ByteBuffer final {   /// Dump (read) the buffer contents into \a slices.   Status Dump(std::vector<Slice>* slices) const; +  /// Returns true is buffer only holds one slice.","I had to add ```#include <grpcpp/impl/codegen/config_protobuf.h>```to byte_buffer.h, so I could add the friend declaration```  template <class ProtoBufferReader, class T>  friend Status GenericDeserialize(ByteBuffer* buffer,                                   grpc::protobuf::Message* msg);```Is that ok? or does it bring in proto deps? ByteBuffer should be usable w/o proto depsAlso, I tried to fwd decl it with:```namespace protobuf {  class Message}```but that caused all sorts of errors",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/15356,188033395,2018-05-14T17:24:11Z,examples/ruby/grpc-demo.gemspec,"@@ -18,6 +18,7 @@ Gem::Specification.new do |s|   s.platform      = Gem::Platform::RUBY    s.add_dependency 'grpc', '~> 1.0'+  s.add_dependency 'googleauth', '>= 0.5.1', '< 0.7'","This mostly seems like a good change to have. I'm wondering about this line though - if there are users that would be ""broken"" by grpc-ruby no longer having this dependency.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/14879,188038152,2018-05-14T17:40:09Z,src/python/grpcio/grpc/_cython/_cygrpc/credentials.pxd.pxi,"@@ -57,6 +57,16 @@ cdef class ChannelCredentials:   cdef grpc_channel_credentials *c_credentials  +cdef class SSLSessionCache:++  cdef grpc_ssl_session_cache *_cache+++cdef class SSLSessionCacheLRU(SSLSessionCache):","Drop this? An empty class is always a code smell, and there should probably be only one Cython-layer class per Core object type anyways.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/14879,188039089,2018-05-14T17:43:18Z,src/python/grpcio_tests/tests/unit/_auth_context_test.py,"@@ -140,6 +154,57 @@ def testSecureClientCert(self):         self.assertSequenceEqual([b'*.test.google.com'],                                  auth_ctx['x509_common_name']) +    def _do_one_shot_client_rpc(self, channel_creds, channel_options, port,+                                expect_session_reused):+        channel = grpc.secure_channel(+            'localhost:{}'.format(port), channel_creds, options=channel_options)+        response = channel.unary_unary(_UNARY_UNARY)(_REQUEST)+        auth_data = pickle.loads(response)+        self.assertEqual(expect_session_reused,+                         auth_data[_AUTH_CTX]['ssl_session_reused'])++    def testSSLSessionCacheLRU(self):","Should this feature be tested in a different test class or different test module? It looks like it shares some stuff with auth context, but does it share enough?",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/15280,188130309,2018-05-14T23:43:28Z,src/core/lib/debug/stats.h,"@@ -35,13 +35,20 @@ extern grpc_stats_data* grpc_stats_per_cpu_storage; #define GRPC_THREAD_STATS_DATA() \   (&grpc_stats_per_cpu_storage[grpc_core::ExecCtx::Get()->starting_cpu()]) ","(which is a circular dependency). This can be separated into a separate file though which seems like an overkill. This check shouldn't snowball any further, but if you feel strongly about this, it can be done.",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/15280,188130503,2018-05-14T23:44:52Z,src/core/lib/debug/stats.h,"@@ -35,13 +35,20 @@ extern grpc_stats_data* grpc_stats_per_cpu_storage; #define GRPC_THREAD_STATS_DATA() \   (&grpc_stats_per_cpu_storage[grpc_core::ExecCtx::Get()->starting_cpu()]) ","I don't feel strongly about this.  If there is a dependency issue making this difficult, then I'm fine with it as is.",
5616899,ganmacs,https://api.github.com/repos/grpc/grpc/pulls/15356,188146137,2018-05-15T01:52:14Z,examples/ruby/grpc-demo.gemspec,"@@ -18,6 +18,7 @@ Gem::Specification.new do |s|   s.platform      = Gem::Platform::RUBY    s.add_dependency 'grpc', '~> 1.0'+  s.add_dependency 'googleauth', '>= 0.5.1', '< 0.7'",Move googleauth gem dependency to development dependency.  What do you think?https://github.com/grpc/grpc/pull/15356/commits/fd7c4d5f06219b9979412d2242b3f4c1074dbbff,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15383,188417262,2018-05-15T19:59:23Z,src/core/lib/channel/handshaker.cc,"@@ -220,8 +220,14 @@ static bool call_next_handshaker_locked(grpc_handshake_manager* mgr,   // callback.  Otherwise, call the next handshaker.   if (error != GRPC_ERROR_NONE || mgr->shutdown || mgr->args.exit_early ||       mgr->index == mgr->count) {+    if (error == GRPC_ERROR_NONE && mgr->shutdown) {",The handshaker can also be shut down internally if the timeout expires:https://github.com/grpc/grpc/blob/master/src/core/lib/channel/handshaker.cc#L265,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13689,188452373,2018-05-15T22:13:03Z,src/python/grpcio/grpc/_channel.py,"@@ -374,13 +376,20 @@ def details(self):                 self._state.condition.wait()             return _common.decode(self._state.details) +    def debug_error_string(self):+        with self._state.condition:+            while self._state.debug_error_string is None:+                self._state.condition.wait()+            return _common.decode(self._state.debug_error_string)+     def _repr(self):         with self._state.condition:             if self._state.code is None:                 return '<_Rendezvous object of in-flight RPC>'             else:-                return '<_Rendezvous of RPC that terminated with ({}, {})>'.format(-                    self._state.code, _common.decode(self._state.details))+                return '<_Rendezvous of RPC that terminated with ({}, {}, {})>'.format(","Three is one value too many to just toss into an unlabeled tuple - reform this so that the code is labeled as the code, the details are labeled as the details, and the debug error string is labeled as the debug error string?Consider doing this in an extracted helper function?How long are debug error strings expected to be? Should this representation contain newlines?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15402,188649503,2018-05-16T14:36:34Z,src/core/lib/surface/call.cc,"@@ -67,6 +67,10 @@  #define MAX_SEND_EXTRA_METADATA_COUNT 3 +// These estimates are used to create arena for the first call.+#define ESTIMATED_BATCH_CONTROL_COUNT 5","Where does this number come from?  Do we have any data on the average number of batches per call?  If the goal here is to ensure that we always have enough space for all batches, then shouldn't we just use `MAX_CONCURRENT_BATCHES` instead?More generally, I am concerned that we may be optimizing for the wrong case here.  While this change may benefit the specific use case of a service that has one streaming call per channel, unary RPCs are far more common than streaming, and unary RPCs typically have only 1-2 batches.  Will the hysteresis code ensure that we don't allocate more memory than we need after a few RPCs in the unary case?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15402,188649762,2018-05-16T14:37:16Z,src/core/lib/surface/call.cc,"@@ -67,6 +67,10 @@  #define MAX_SEND_EXTRA_METADATA_COUNT 3 +// These estimates are used to create arena for the first call.+#define ESTIMATED_BATCH_CONTROL_COUNT 5+#define ESTIMATED_MDELEM_COUNT 10",Similar question here: Where does this number come from?  Do we have any data on the average number of metadata elements we need to allocate per call?,
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/13689,188684093,2018-05-16T16:09:09Z,src/python/grpcio/grpc/_channel.py,"@@ -374,13 +376,20 @@ def details(self):                 self._state.condition.wait()             return _common.decode(self._state.details) +    def debug_error_string(self):+        with self._state.condition:+            while self._state.debug_error_string is None:+                self._state.condition.wait()+            return _common.decode(self._state.debug_error_string)+     def _repr(self):         with self._state.condition:             if self._state.code is None:                 return '<_Rendezvous object of in-flight RPC>'             else:-                return '<_Rendezvous of RPC that terminated with ({}, {})>'.format(-                    self._state.code, _common.decode(self._state.details))+                return '<_Rendezvous of RPC that terminated with ({}, {}, {})>'.format(","Ok now I have it in a state where the final output looks like:```<_Rendezvous of RPC that terminated with:	status = ""StatusCode.UNKNOWN""	details = ""Exception calling application: ""	debug_error_string = ""{""created"":""@1526486784.413014692"",""description"":""Error received from peer"",""file"":""third_party/grpc/src/core/lib/surface/call.cc"",""file_line"":1076,""grpc_message"":""Exception calling application: "",""grpc_status"":2}"">```Is this good? If now, what output would you like to see, and I will make the changes. Could we import json, or is that not a dependency we want? The debug_error_string will be JSON formatted",
17325098,makdharma,https://api.github.com/repos/grpc/grpc/pulls/15069,188719775,2018-05-16T18:04:16Z,src/objective-c/GRPCClient/private/GRPCCompletionQueue.m,"@@ -33,7 +41,9 @@ + (instancetype)completionQueue {  - (instancetype)init {   if ((self = [super init])) {-    _unmanagedQueue = grpc_completion_queue_create_for_next(NULL);+    _unmanagedQueue = grpc_completion_queue_create(+        grpc_completion_queue_factory_lookup(&kCompletionQueueAttr), &kCompletionQueueAttr, NULL);+    //_unmanagedQueue = grpc_completion_queue_create_for_next(NULL);",delete unused code.,
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/15402,188777619,2018-05-16T21:25:00Z,src/core/lib/surface/call.cc,"@@ -67,6 +67,10 @@  #define MAX_SEND_EXTRA_METADATA_COUNT 3 +// These estimates are used to create arena for the first call.+#define ESTIMATED_BATCH_CONTROL_COUNT 5+#define ESTIMATED_MDELEM_COUNT 10","From the log, I see 11 mdelem allocated. I learned that the number of metadata (without any user-defined ones) is stable, so I think a rough estimate by this sample is fine. It might be safer to use a slightly larger number like 16, especially when each mdelem is just 32B.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/13689,188977633,2018-05-17T14:26:25Z,src/python/grpcio/grpc/_channel.py,"@@ -374,13 +387,24 @@ def details(self):                 self._state.condition.wait()             return _common.decode(self._state.details) +    def debug_error_string(self):+        with self._state.condition:+            while self._state.debug_error_string is None:+                self._state.condition.wait()+            return _common.decode(self._state.debug_error_string)+     def _repr(self):         with self._state.condition:             if self._state.code is None:                 return '<_Rendezvous object of in-flight RPC>'             else:-                return '<_Rendezvous of RPC that terminated with ({}, {})>'.format(-                    self._state.code, _common.decode(self._state.details))+                if self._state.code == grpc.StatusCode.OK:",Use `is` and `is not` when checking whether or not a field is assigned to a singleton object.,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/14879,189094638,2018-05-17T20:42:33Z,src/python/grpcio/grpc/_cython/_cygrpc/credentials.pxd.pxi,"@@ -57,6 +57,11 @@ cdef class ChannelCredentials:   cdef grpc_channel_credentials *c_credentials  +cdef class SSLSessionCacheLRU:","What's ""LRU"" about this class? All it contains is a `grpc_ssl_session_cache`?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/15356,189159782,2018-05-18T04:17:20Z,examples/ruby/grpc-demo.gemspec,"@@ -18,6 +18,7 @@ Gem::Specification.new do |s|   s.platform      = Gem::Platform::RUBY    s.add_dependency 'grpc', '~> 1.0'+  s.add_dependency 'googleauth', '>= 0.5.1', '< 0.7'","AFAIK moving `googleauth` to be a development dependency won't eliminate the risk that this breaks people that are relying on `googleauth` being in there transitive dependencies (I haven't actually verified this is an issue yet, but I'm just a little skiddish about this).",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/15356,189422612,2018-05-19T02:35:48Z,examples/ruby/grpc-demo.gemspec,"@@ -18,6 +18,7 @@ Gem::Specification.new do |s|   s.platform      = Gem::Platform::RUBY    s.add_dependency 'grpc', '~> 1.0'+  s.add_dependency 'googleauth', '>= 0.5.1', '< 0.7'","Though its definitely possible that we wouldn't even break anyone by this, maybe it would be useful to file an issue along the lines of ""grpc-ruby can drop its googleauth dependency, all in favor?"", and then wait for a little bit to see if there's any input. ",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/15438,189663503,2018-05-21T17:50:24Z,tools/internal_ci/helper_scripts/delete_nonartifacts.sh,"@@ -0,0 +1,27 @@+#!/usr/bin/env bash+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++set -ex++# change to grpc repo root+cd $(dirname $0)/../../..","Please [quote obsessively](https://github.com/anordal/shellharden/blob/master/how_to_do_things_safely_in_bash.md) (running [`shellcheck`](https://www.shellcheck.net/) on the script is a helpful guide):```bashcd ""$(dirname ""$0"")/../../..""```",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/15356,189691591,2018-05-21T19:38:11Z,examples/ruby/grpc-demo.gemspec,"@@ -19,5 +19,6 @@ Gem::Specification.new do |s|    s.add_dependency 'grpc', '~> 1.0' -  s.add_development_dependency 'bundler', '~> 1.7'+  s.add_development_dependency 'bundler',    '~> 1.7'+  s.add_development_dependency 'googleauth', '>= 0.5.1', '< 0.7'",why is `googleauth` being added as a development dependency here?,
22083734,matt-kwong,https://api.github.com/repos/grpc/grpc/pulls/15499,189755770,2018-05-22T01:27:33Z,tools/dockerfile/test/cxx_jessie_x64/Dockerfile,"@@ -12,7 +12,7 @@ # See the License for the specific language governing permissions and # limitations under the License. -FROM debian:jessie+FROM gcr.io/cloud-marketplace/google/rbe-debian8@sha256:496193842f61c9494be68bd624e47c74d706cabf19a693c4653ffe96a97e43e3","https://github.com/grpc/grpc/blob/master/tools/run_tests/run_tests.py#L526We actually use the current Jessie Dockerfile for clang3.5. clang3.5 is installed in https://github.com/grpc/grpc/blob/master/tools/dockerfile/test/cxx_jessie_x64/Dockerfile#L73, so we at least have to keep that version of clang, but I'm fine with removing the version installed from source.Before updating my PR, since I forgot to remove clang, are you ok with the name `cxx_rbe_jessie_x64` or do you think `cxx_sanitizers_x64` is better?",
5616899,ganmacs,https://api.github.com/repos/grpc/grpc/pulls/15356,189759226,2018-05-22T01:53:23Z,examples/ruby/grpc-demo.gemspec,"@@ -19,5 +19,6 @@ Gem::Specification.new do |s|    s.add_dependency 'grpc', '~> 1.0' -  s.add_development_dependency 'bundler', '~> 1.7'+  s.add_development_dependency 'bundler',    '~> 1.7'+  s.add_development_dependency 'googleauth', '>= 0.5.1', '< 0.7'",Becuase googleauth is used by pubsub demo project I moved in examples/ruby directory.Is it better to add a  production dependency by using`add_dependency`?,
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/15504,189778277,2018-05-22T05:05:47Z,src/core/lib/iomgr/ev_epollex_linux.cc,"@@ -767,6 +768,10 @@ static int poll_deadline_to_millis_timeout(grpc_millis millis) { }  static void fd_become_readable(grpc_fd* fd, grpc_pollset* notifier) {+  if (grpc_latency_estimator_trace.enabled()) {+    gpr_log(GPR_INFO, ""latency_estimator:server_inbound_reading:start"");",don't we need to disambiguate if we are a client or server process? Else how will this interact correctly with the post processor?,
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/15504,189780769,2018-05-22T05:30:57Z,src/core/lib/iomgr/ev_epollex_linux.cc,"@@ -767,6 +768,10 @@ static int poll_deadline_to_millis_timeout(grpc_millis millis) { }  static void fd_become_readable(grpc_fd* fd, grpc_pollset* notifier) {+  if (grpc_latency_estimator_trace.enabled()) {+    gpr_log(GPR_INFO, ""latency_estimator:server_inbound_reading:start"");","I could modify the post processor to have a client and server mode. So when it's in client mode, it throws out all the server-related log statements. Maybe the right thing to do at this point is to define where we want to put the start and end markers for each leg of an rpc? And perhaps that will solve the disambiguation problem just by nature of where the markers are. ",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15460,189935647,2018-05-22T15:00:42Z,doc/PROTOCOL-SEMANTICS.md,"@@ -0,0 +1,221 @@+# gRPC semantics++gRPC has many features, but the most fundamental core is the ability to perform+RPCs. The goal of this document is defining the semantics of gRPC's RPCs.++## Channels++Most implementations will have Channel and Server concepts. A Channel is a+virtual connection to an endpoint, capable of sending RPCs. Channel is ""virtual""+because the Channel is free to have zero or many actual connections. A Channel+is free to determine which actual endpoints to use and may change it every RPC,+permitting client-side load balancing. A Server would be capable of receiving+incoming connections and receiving RPCs.++A ""connection"" is not a gRPC semantic concept and thus users should not assume a+correlation between connections and RPCs. Although, practically, users should be+aware of the common restriction that RPCs are unable to survive longer than the+connection on which they exist.++The exact details of how the communication is performed and higher level+abstractions can change when necessary and are thus not a focus for this+document. Although implementations SHOULD support the [HTTP/2+transport](PROTOCOL-HTTP2.md) to provide a basis for interoperability.++## Methods++An RPC is performed on a Method. The Method has a name, defines the intended+operation, the message types involved with the RPC, and the cardinality of+those messages.  It does not define the endpoint to send the RPC to; this is+normally handled by the Channel.++A Method's intended operation is just normal documentation describing what a+Method does, intended for a developer. gRPC itself is not generally aware of the+intended operation.++A Method has a request message type and a separate response message type. gRPC+is only aware of these types well enough to serialize and deserialize them. They+are largely considered ""binary blobs"" to gRPC itself.","Instead of ""binary blobs"", how about ""opaque byte sequences""?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15460,189939807,2018-05-22T15:11:35Z,doc/PROTOCOL-SEMANTICS.md,"@@ -0,0 +1,221 @@+# gRPC semantics++gRPC has many features, but the most fundamental core is the ability to perform+RPCs. The goal of this document is defining the semantics of gRPC's RPCs.++## Channels++Most implementations will have Channel and Server concepts. A Channel is a+virtual connection to an endpoint, capable of sending RPCs. Channel is ""virtual""+because the Channel is free to have zero or many actual connections. A Channel+is free to determine which actual endpoints to use and may change it every RPC,+permitting client-side load balancing. A Server would be capable of receiving+incoming connections and receiving RPCs.++A ""connection"" is not a gRPC semantic concept and thus users should not assume a+correlation between connections and RPCs. Although, practically, users should be+aware of the common restriction that RPCs are unable to survive longer than the+connection on which they exist.++The exact details of how the communication is performed and higher level+abstractions can change when necessary and are thus not a focus for this+document. Although implementations SHOULD support the [HTTP/2+transport](PROTOCOL-HTTP2.md) to provide a basis for interoperability.++## Methods++An RPC is performed on a Method. The Method has a name, defines the intended+operation, the message types involved with the RPC, and the cardinality of+those messages.  It does not define the endpoint to send the RPC to; this is+normally handled by the Channel.++A Method's intended operation is just normal documentation describing what a+Method does, intended for a developer. gRPC itself is not generally aware of the+intended operation.++A Method has a request message type and a separate response message type. gRPC+is only aware of these types well enough to serialize and deserialize them. They+are largely considered ""binary blobs"" to gRPC itself.++A Method's request and response each have a cardinality: either one (""unary""),+or zero to many (a ""stream""). This produces four possible configurations which,+for convenience, each have a name:++|                       | **unary response** | **streaming response** |+| --------------------- | ------------------ | ---------------------- |+| **unary request**     | unary              | server-streaming       |+| **streaming request** | client-streaming   | bidirectional (bidi)   |++While we use the term ""method,"" pedantically it is closer to ""function"" as it is+not object oriented and there is no ""receiver"" involved (the `this` variable in+many languages) other than the destination machine. gRPC is based on message+passing, not object orientation.++Related Methods are typically grouped into a Service. To gRPC, a Service is a+group of methods that tend to be implemented together and that all share the+Service's namespace. A Service is a higher-level abstraction and may not be+present explicitly in all implementations. However, the namespace provided by a+Service is a core distinguishing feature of its Methods; if two Methods have the+same name but exist in different Services they must be considered distinct and+not be confused. A Method name including its Service namespace prefix with a ""/""+separator is a ""full method name"".++## Calls++RPCs, or ""Calls,"" are initiated by a client to a server, typically via a+Channel. The initiation is with Request Headers, within which the client","Instead of using terms like ""Request Headers"" and ""Trailers"", which are used in HTTP/2, let's use the semantic names we use in gRPC: initial metadata and trailing metadata.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15460,189945501,2018-05-22T15:25:22Z,doc/PROTOCOL-SEMANTICS.md,"@@ -0,0 +1,221 @@+# gRPC semantics++gRPC has many features, but the most fundamental core is the ability to perform+RPCs. The goal of this document is defining the semantics of gRPC's RPCs.++## Channels++Most implementations will have Channel and Server concepts. A Channel is a+virtual connection to an endpoint, capable of sending RPCs. Channel is ""virtual""+because the Channel is free to have zero or many actual connections. A Channel+is free to determine which actual endpoints to use and may change it every RPC,+permitting client-side load balancing. A Server would be capable of receiving+incoming connections and receiving RPCs.++A ""connection"" is not a gRPC semantic concept and thus users should not assume a+correlation between connections and RPCs. Although, practically, users should be+aware of the common restriction that RPCs are unable to survive longer than the+connection on which they exist.++The exact details of how the communication is performed and higher level+abstractions can change when necessary and are thus not a focus for this+document. Although implementations SHOULD support the [HTTP/2+transport](PROTOCOL-HTTP2.md) to provide a basis for interoperability.++## Methods++An RPC is performed on a Method. The Method has a name, defines the intended+operation, the message types involved with the RPC, and the cardinality of+those messages.  It does not define the endpoint to send the RPC to; this is+normally handled by the Channel.++A Method's intended operation is just normal documentation describing what a+Method does, intended for a developer. gRPC itself is not generally aware of the+intended operation.++A Method has a request message type and a separate response message type. gRPC+is only aware of these types well enough to serialize and deserialize them. They+are largely considered ""binary blobs"" to gRPC itself.++A Method's request and response each have a cardinality: either one (""unary""),+or zero to many (a ""stream""). This produces four possible configurations which,+for convenience, each have a name:++|                       | **unary response** | **streaming response** |+| --------------------- | ------------------ | ---------------------- |+| **unary request**     | unary              | server-streaming       |+| **streaming request** | client-streaming   | bidirectional (bidi)   |++While we use the term ""method,"" pedantically it is closer to ""function"" as it is+not object oriented and there is no ""receiver"" involved (the `this` variable in+many languages) other than the destination machine. gRPC is based on message+passing, not object orientation.++Related Methods are typically grouped into a Service. To gRPC, a Service is a+group of methods that tend to be implemented together and that all share the+Service's namespace. A Service is a higher-level abstraction and may not be+present explicitly in all implementations. However, the namespace provided by a+Service is a core distinguishing feature of its Methods; if two Methods have the+same name but exist in different Services they must be considered distinct and+not be confused. A Method name including its Service namespace prefix with a ""/""+separator is a ""full method name"".++## Calls++RPCs, or ""Calls,"" are initiated by a client to a server, typically via a+Channel. The initiation is with Request Headers, within which the client+indicates the method to be run by its Full Method Name. The Call is gracefully+completed when the server responds with Trailers, which contains a Status+communicating the success or failure of the RPC. Note that on the server there+is a period of time between when the server application responds with a Trailers+and when that Trailers is actually sent; the Call is only truly complete when+the Trailers is sent. Similarly, on the client there is a period between the+gRPC implementation receiving the Trailers and when the application receives the+Trailers; the Call is only truly complete when the Trailers is received by the+application.++Calls may terminate early by being ""cancelled."" Implementations must allow+clients to cancel Calls, but cancellations may occur in other ways like I/O+failures. A cancellation appears as a Trailers to clients and is a special state+on servers. Cancellation is an abrupt killing of the Call; inbound and outbound+buffered data should be cleared. Cancellation trumps graceful completion; if the+client gRPC implementation received the Trailers before the cancellation, yet+the client application has not received the Trailers, then cancellation+generally should win. No auxilary information is included in cancellation+signals between the client and server. Server implementations may fail a Call+and respond with Trailers while claiming to the server application that the Call+was cancelled.++There may be multiple servers that _could_ have received the Call (as is common+for load balancing), but only a single server may process an individual Call.+Calls are assumed to be non-idempotent and may not be ""replayed"" except for when+gRPC is explicitly informed it is safe to do so.++Calls are natively two independent streams (i.e., full duplex bidirectional) of+Messages. The streams are each started with Headers. The end of the request+stream is delimited by Half Close. The end of the response stream is delimited+by Trailers. Messages may exist between the Headers and the end of the stream.+Headers, Messages, Half Close, and Trailers are the units of communication and,+absent the Call's termination, will be communicated to the remote without+the need to send further units on the stream. However, see the optimizations+permitted for unary Calls below.++The two independent streams are each unidirectional and do not provide any+information in the reverse direction other than Flow Control. Flow Control+is a signal from the receiver to the sender to temporarily pause sending+additional messages to avoid excessive buffering. Flow Control only applies to+messages, but since streams are in-order Half Close or Trailers may be delayed+waiting for message Flow Control in the same stream. No message receipt+acknowledgement information is provided. However applications may use messages+for such signals, as a response naturally acknowledges its request. Note in+particular that there is no provision for the server application to not know+whether the client application received a unary Call's response or a streaming+Call's Status.++Unary Calls may be optimized to be half-duplex and treat each stream as a single+communication unit. That is, on the client a unary Call may be delayed from+being sent until the Half Close is ready to be sent and on the server the+response may be delayed until the Trailers is ready.++Unary Calls that terminate with a Status Code of OK must contain a response+message. Unary Calls that terminate with a Status Code other than OK do not need+a response message, and at the implementation's discretion the response message+may be discarded if present.++## Status++A Status contains a ""code"" and a ""description"". The Status Description is a+human-readable Unicode string for developer debugging. The Status Code is a+value from a pre-defined list of such codes. While Status Code is best+communicated to users by its name, it commonly is treated as an integer+internally, and so each code has a numeric value.++The valid Status Codes are:","This list feels like it should be in its own doc.  I thought we already had one, but the closest I see is https://github.com/grpc/grpc/blob/master/doc/statuscodes.md, which doesn't show this list directly.  How about either (a) adding this list to that doc or (b) creating a separate doc with this list, and then changing this section to be a link to that doc?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15460,189945803,2018-05-22T15:26:03Z,doc/PROTOCOL-SEMANTICS.md,"@@ -0,0 +1,221 @@+# gRPC semantics++gRPC has many features, but the most fundamental core is the ability to perform+RPCs. The goal of this document is defining the semantics of gRPC's RPCs.++## Channels++Most implementations will have Channel and Server concepts. A Channel is a+virtual connection to an endpoint, capable of sending RPCs. Channel is ""virtual""+because the Channel is free to have zero or many actual connections. A Channel+is free to determine which actual endpoints to use and may change it every RPC,+permitting client-side load balancing. A Server would be capable of receiving+incoming connections and receiving RPCs.++A ""connection"" is not a gRPC semantic concept and thus users should not assume a+correlation between connections and RPCs. Although, practically, users should be+aware of the common restriction that RPCs are unable to survive longer than the+connection on which they exist.++The exact details of how the communication is performed and higher level+abstractions can change when necessary and are thus not a focus for this+document. Although implementations SHOULD support the [HTTP/2+transport](PROTOCOL-HTTP2.md) to provide a basis for interoperability.++## Methods++An RPC is performed on a Method. The Method has a name, defines the intended+operation, the message types involved with the RPC, and the cardinality of+those messages.  It does not define the endpoint to send the RPC to; this is+normally handled by the Channel.++A Method's intended operation is just normal documentation describing what a+Method does, intended for a developer. gRPC itself is not generally aware of the+intended operation.++A Method has a request message type and a separate response message type. gRPC+is only aware of these types well enough to serialize and deserialize them. They+are largely considered ""binary blobs"" to gRPC itself.++A Method's request and response each have a cardinality: either one (""unary""),+or zero to many (a ""stream""). This produces four possible configurations which,+for convenience, each have a name:++|                       | **unary response** | **streaming response** |+| --------------------- | ------------------ | ---------------------- |+| **unary request**     | unary              | server-streaming       |+| **streaming request** | client-streaming   | bidirectional (bidi)   |++While we use the term ""method,"" pedantically it is closer to ""function"" as it is+not object oriented and there is no ""receiver"" involved (the `this` variable in+many languages) other than the destination machine. gRPC is based on message+passing, not object orientation.++Related Methods are typically grouped into a Service. To gRPC, a Service is a+group of methods that tend to be implemented together and that all share the+Service's namespace. A Service is a higher-level abstraction and may not be+present explicitly in all implementations. However, the namespace provided by a+Service is a core distinguishing feature of its Methods; if two Methods have the+same name but exist in different Services they must be considered distinct and+not be confused. A Method name including its Service namespace prefix with a ""/""+separator is a ""full method name"".++## Calls++RPCs, or ""Calls,"" are initiated by a client to a server, typically via a+Channel. The initiation is with Request Headers, within which the client+indicates the method to be run by its Full Method Name. The Call is gracefully+completed when the server responds with Trailers, which contains a Status+communicating the success or failure of the RPC. Note that on the server there+is a period of time between when the server application responds with a Trailers+and when that Trailers is actually sent; the Call is only truly complete when+the Trailers is sent. Similarly, on the client there is a period between the+gRPC implementation receiving the Trailers and when the application receives the+Trailers; the Call is only truly complete when the Trailers is received by the+application.++Calls may terminate early by being ""cancelled."" Implementations must allow+clients to cancel Calls, but cancellations may occur in other ways like I/O+failures. A cancellation appears as a Trailers to clients and is a special state+on servers. Cancellation is an abrupt killing of the Call; inbound and outbound+buffered data should be cleared. Cancellation trumps graceful completion; if the+client gRPC implementation received the Trailers before the cancellation, yet+the client application has not received the Trailers, then cancellation+generally should win. No auxilary information is included in cancellation+signals between the client and server. Server implementations may fail a Call+and respond with Trailers while claiming to the server application that the Call+was cancelled.++There may be multiple servers that _could_ have received the Call (as is common+for load balancing), but only a single server may process an individual Call.+Calls are assumed to be non-idempotent and may not be ""replayed"" except for when+gRPC is explicitly informed it is safe to do so.++Calls are natively two independent streams (i.e., full duplex bidirectional) of+Messages. The streams are each started with Headers. The end of the request+stream is delimited by Half Close. The end of the response stream is delimited+by Trailers. Messages may exist between the Headers and the end of the stream.+Headers, Messages, Half Close, and Trailers are the units of communication and,+absent the Call's termination, will be communicated to the remote without+the need to send further units on the stream. However, see the optimizations+permitted for unary Calls below.++The two independent streams are each unidirectional and do not provide any+information in the reverse direction other than Flow Control. Flow Control+is a signal from the receiver to the sender to temporarily pause sending+additional messages to avoid excessive buffering. Flow Control only applies to+messages, but since streams are in-order Half Close or Trailers may be delayed+waiting for message Flow Control in the same stream. No message receipt+acknowledgement information is provided. However applications may use messages+for such signals, as a response naturally acknowledges its request. Note in+particular that there is no provision for the server application to not know+whether the client application received a unary Call's response or a streaming+Call's Status.++Unary Calls may be optimized to be half-duplex and treat each stream as a single+communication unit. That is, on the client a unary Call may be delayed from+being sent until the Half Close is ready to be sent and on the server the+response may be delayed until the Trailers is ready.++Unary Calls that terminate with a Status Code of OK must contain a response+message. Unary Calls that terminate with a Status Code other than OK do not need+a response message, and at the implementation's discretion the response message+may be discarded if present.++## Status++A Status contains a ""code"" and a ""description"". The Status Description is a",Do we want to say something about the binary error details that can be passed via metadata?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15460,189946326,2018-05-22T15:27:17Z,doc/PROTOCOL-SEMANTICS.md,"@@ -0,0 +1,221 @@+# gRPC semantics++gRPC has many features, but the most fundamental core is the ability to perform+RPCs. The goal of this document is defining the semantics of gRPC's RPCs.++## Channels++Most implementations will have Channel and Server concepts. A Channel is a+virtual connection to an endpoint, capable of sending RPCs. Channel is ""virtual""+because the Channel is free to have zero or many actual connections. A Channel+is free to determine which actual endpoints to use and may change it every RPC,+permitting client-side load balancing. A Server would be capable of receiving+incoming connections and receiving RPCs.++A ""connection"" is not a gRPC semantic concept and thus users should not assume a+correlation between connections and RPCs. Although, practically, users should be+aware of the common restriction that RPCs are unable to survive longer than the+connection on which they exist.++The exact details of how the communication is performed and higher level+abstractions can change when necessary and are thus not a focus for this+document. Although implementations SHOULD support the [HTTP/2+transport](PROTOCOL-HTTP2.md) to provide a basis for interoperability.++## Methods++An RPC is performed on a Method. The Method has a name, defines the intended+operation, the message types involved with the RPC, and the cardinality of+those messages.  It does not define the endpoint to send the RPC to; this is+normally handled by the Channel.++A Method's intended operation is just normal documentation describing what a+Method does, intended for a developer. gRPC itself is not generally aware of the+intended operation.++A Method has a request message type and a separate response message type. gRPC+is only aware of these types well enough to serialize and deserialize them. They+are largely considered ""binary blobs"" to gRPC itself.++A Method's request and response each have a cardinality: either one (""unary""),+or zero to many (a ""stream""). This produces four possible configurations which,+for convenience, each have a name:++|                       | **unary response** | **streaming response** |+| --------------------- | ------------------ | ---------------------- |+| **unary request**     | unary              | server-streaming       |+| **streaming request** | client-streaming   | bidirectional (bidi)   |++While we use the term ""method,"" pedantically it is closer to ""function"" as it is+not object oriented and there is no ""receiver"" involved (the `this` variable in+many languages) other than the destination machine. gRPC is based on message+passing, not object orientation.++Related Methods are typically grouped into a Service. To gRPC, a Service is a+group of methods that tend to be implemented together and that all share the+Service's namespace. A Service is a higher-level abstraction and may not be+present explicitly in all implementations. However, the namespace provided by a+Service is a core distinguishing feature of its Methods; if two Methods have the+same name but exist in different Services they must be considered distinct and+not be confused. A Method name including its Service namespace prefix with a ""/""+separator is a ""full method name"".++## Calls++RPCs, or ""Calls,"" are initiated by a client to a server, typically via a+Channel. The initiation is with Request Headers, within which the client+indicates the method to be run by its Full Method Name. The Call is gracefully+completed when the server responds with Trailers, which contains a Status+communicating the success or failure of the RPC. Note that on the server there+is a period of time between when the server application responds with a Trailers+and when that Trailers is actually sent; the Call is only truly complete when+the Trailers is sent. Similarly, on the client there is a period between the+gRPC implementation receiving the Trailers and when the application receives the+Trailers; the Call is only truly complete when the Trailers is received by the+application.++Calls may terminate early by being ""cancelled."" Implementations must allow+clients to cancel Calls, but cancellations may occur in other ways like I/O+failures. A cancellation appears as a Trailers to clients and is a special state+on servers. Cancellation is an abrupt killing of the Call; inbound and outbound+buffered data should be cleared. Cancellation trumps graceful completion; if the+client gRPC implementation received the Trailers before the cancellation, yet+the client application has not received the Trailers, then cancellation+generally should win. No auxilary information is included in cancellation+signals between the client and server. Server implementations may fail a Call+and respond with Trailers while claiming to the server application that the Call+was cancelled.++There may be multiple servers that _could_ have received the Call (as is common+for load balancing), but only a single server may process an individual Call.+Calls are assumed to be non-idempotent and may not be ""replayed"" except for when+gRPC is explicitly informed it is safe to do so.++Calls are natively two independent streams (i.e., full duplex bidirectional) of+Messages. The streams are each started with Headers. The end of the request+stream is delimited by Half Close. The end of the response stream is delimited+by Trailers. Messages may exist between the Headers and the end of the stream.+Headers, Messages, Half Close, and Trailers are the units of communication and,+absent the Call's termination, will be communicated to the remote without+the need to send further units on the stream. However, see the optimizations+permitted for unary Calls below.++The two independent streams are each unidirectional and do not provide any+information in the reverse direction other than Flow Control. Flow Control+is a signal from the receiver to the sender to temporarily pause sending+additional messages to avoid excessive buffering. Flow Control only applies to+messages, but since streams are in-order Half Close or Trailers may be delayed+waiting for message Flow Control in the same stream. No message receipt+acknowledgement information is provided. However applications may use messages+for such signals, as a response naturally acknowledges its request. Note in+particular that there is no provision for the server application to not know+whether the client application received a unary Call's response or a streaming+Call's Status.++Unary Calls may be optimized to be half-duplex and treat each stream as a single+communication unit. That is, on the client a unary Call may be delayed from+being sent until the Half Close is ready to be sent and on the server the+response may be delayed until the Trailers is ready.++Unary Calls that terminate with a Status Code of OK must contain a response+message. Unary Calls that terminate with a Status Code other than OK do not need+a response message, and at the implementation's discretion the response message+may be discarded if present.++## Status++A Status contains a ""code"" and a ""description"". The Status Description is a+human-readable Unicode string for developer debugging. The Status Code is a+value from a pre-defined list of such codes. While Status Code is best+communicated to users by its name, it commonly is treated as an integer+internally, and so each code has a numeric value.++The valid Status Codes are:++| Num | Name                |+| --- | ------------------- |+| 0   | OK                  |+| 1   | CANCELLED           |+| 2   | UNKNOWN             |+| 3   | INVALID_ARGUMENT    |+| 4   | DEADLINE_EXCEEDED   |+| 5   | NOT_FOUND           |+| 6   | ALREADY_EXISTS      |+| 7   | PERMISSION_DENIED   |+| 8   | RESOURCE_EXHAUSTED  |+| 9   | FAILED_PRECONDITION |+| 10  | ABORTED             |+| 11  | OUT_OF_RANGE        |+| 12  | UNIMPLEMENTED       |+| 13  | INTERNAL            |+| 14  | UNAVAILABLE         |+| 15  | DATA_LOSS           |+| 16  | UNAUTHENTICATED     |++Using the OK Status Code for a Call may only be decided by server applications.+Library implementations must not ""fabricate"" an OK Status Code; it may only+communicate an OK Status Code that was provided to it. While there may be+additional restrictions on Status Code usage like those detailed in+[statuscodes.md](statuscodes.md), those restrictions are more to provide a+cohesive experience instead of a core, fundamental requirement.++## Metadata++Metadata has keys with associated values. Each key can have multiple values.+Keys are unordered, but values for a key are ordered. Keys are case insensitive,+and commonly canonicalized by making lower case. APIs are permitted to require a+canonical representation and that representation may be different than the+""lower case"" representation mentioned here. A key can be for ASCII or binary+values. If a key is for binary values, its name must be suffixed with ""-bin"".","Is the ""-bin"" requirement a core part of the semantic protocol, or an implementation detail related to the HTTP/2 transport?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15460,189947447,2018-05-22T15:30:17Z,doc/PROTOCOL-SEMANTICS.md,"@@ -0,0 +1,221 @@+# gRPC semantics++gRPC has many features, but the most fundamental core is the ability to perform+RPCs. The goal of this document is defining the semantics of gRPC's RPCs.++## Channels++Most implementations will have Channel and Server concepts. A Channel is a+virtual connection to an endpoint, capable of sending RPCs. Channel is ""virtual""+because the Channel is free to have zero or many actual connections. A Channel+is free to determine which actual endpoints to use and may change it every RPC,+permitting client-side load balancing. A Server would be capable of receiving+incoming connections and receiving RPCs.++A ""connection"" is not a gRPC semantic concept and thus users should not assume a+correlation between connections and RPCs. Although, practically, users should be+aware of the common restriction that RPCs are unable to survive longer than the+connection on which they exist.++The exact details of how the communication is performed and higher level+abstractions can change when necessary and are thus not a focus for this+document. Although implementations SHOULD support the [HTTP/2+transport](PROTOCOL-HTTP2.md) to provide a basis for interoperability.++## Methods++An RPC is performed on a Method. The Method has a name, defines the intended+operation, the message types involved with the RPC, and the cardinality of+those messages.  It does not define the endpoint to send the RPC to; this is+normally handled by the Channel.++A Method's intended operation is just normal documentation describing what a+Method does, intended for a developer. gRPC itself is not generally aware of the+intended operation.++A Method has a request message type and a separate response message type. gRPC+is only aware of these types well enough to serialize and deserialize them. They+are largely considered ""binary blobs"" to gRPC itself.++A Method's request and response each have a cardinality: either one (""unary""),+or zero to many (a ""stream""). This produces four possible configurations which,+for convenience, each have a name:++|                       | **unary response** | **streaming response** |+| --------------------- | ------------------ | ---------------------- |+| **unary request**     | unary              | server-streaming       |+| **streaming request** | client-streaming   | bidirectional (bidi)   |++While we use the term ""method,"" pedantically it is closer to ""function"" as it is+not object oriented and there is no ""receiver"" involved (the `this` variable in+many languages) other than the destination machine. gRPC is based on message+passing, not object orientation.++Related Methods are typically grouped into a Service. To gRPC, a Service is a+group of methods that tend to be implemented together and that all share the+Service's namespace. A Service is a higher-level abstraction and may not be+present explicitly in all implementations. However, the namespace provided by a+Service is a core distinguishing feature of its Methods; if two Methods have the+same name but exist in different Services they must be considered distinct and+not be confused. A Method name including its Service namespace prefix with a ""/""+separator is a ""full method name"".++## Calls++RPCs, or ""Calls,"" are initiated by a client to a server, typically via a+Channel. The initiation is with Request Headers, within which the client+indicates the method to be run by its Full Method Name. The Call is gracefully+completed when the server responds with Trailers, which contains a Status+communicating the success or failure of the RPC. Note that on the server there+is a period of time between when the server application responds with a Trailers+and when that Trailers is actually sent; the Call is only truly complete when+the Trailers is sent. Similarly, on the client there is a period between the+gRPC implementation receiving the Trailers and when the application receives the+Trailers; the Call is only truly complete when the Trailers is received by the+application.++Calls may terminate early by being ""cancelled."" Implementations must allow+clients to cancel Calls, but cancellations may occur in other ways like I/O+failures. A cancellation appears as a Trailers to clients and is a special state+on servers. Cancellation is an abrupt killing of the Call; inbound and outbound+buffered data should be cleared. Cancellation trumps graceful completion; if the+client gRPC implementation received the Trailers before the cancellation, yet+the client application has not received the Trailers, then cancellation+generally should win. No auxilary information is included in cancellation+signals between the client and server. Server implementations may fail a Call+and respond with Trailers while claiming to the server application that the Call+was cancelled.++There may be multiple servers that _could_ have received the Call (as is common+for load balancing), but only a single server may process an individual Call.+Calls are assumed to be non-idempotent and may not be ""replayed"" except for when+gRPC is explicitly informed it is safe to do so.++Calls are natively two independent streams (i.e., full duplex bidirectional) of+Messages. The streams are each started with Headers. The end of the request+stream is delimited by Half Close. The end of the response stream is delimited+by Trailers. Messages may exist between the Headers and the end of the stream.+Headers, Messages, Half Close, and Trailers are the units of communication and,+absent the Call's termination, will be communicated to the remote without+the need to send further units on the stream. However, see the optimizations+permitted for unary Calls below.++The two independent streams are each unidirectional and do not provide any+information in the reverse direction other than Flow Control. Flow Control+is a signal from the receiver to the sender to temporarily pause sending+additional messages to avoid excessive buffering. Flow Control only applies to+messages, but since streams are in-order Half Close or Trailers may be delayed+waiting for message Flow Control in the same stream. No message receipt+acknowledgement information is provided. However applications may use messages+for such signals, as a response naturally acknowledges its request. Note in+particular that there is no provision for the server application to not know+whether the client application received a unary Call's response or a streaming+Call's Status.++Unary Calls may be optimized to be half-duplex and treat each stream as a single+communication unit. That is, on the client a unary Call may be delayed from+being sent until the Half Close is ready to be sent and on the server the+response may be delayed until the Trailers is ready.++Unary Calls that terminate with a Status Code of OK must contain a response+message. Unary Calls that terminate with a Status Code other than OK do not need+a response message, and at the implementation's discretion the response message+may be discarded if present.++## Status++A Status contains a ""code"" and a ""description"". The Status Description is a+human-readable Unicode string for developer debugging. The Status Code is a+value from a pre-defined list of such codes. While Status Code is best+communicated to users by its name, it commonly is treated as an integer+internally, and so each code has a numeric value.++The valid Status Codes are:++| Num | Name                |+| --- | ------------------- |+| 0   | OK                  |+| 1   | CANCELLED           |+| 2   | UNKNOWN             |+| 3   | INVALID_ARGUMENT    |+| 4   | DEADLINE_EXCEEDED   |+| 5   | NOT_FOUND           |+| 6   | ALREADY_EXISTS      |+| 7   | PERMISSION_DENIED   |+| 8   | RESOURCE_EXHAUSTED  |+| 9   | FAILED_PRECONDITION |+| 10  | ABORTED             |+| 11  | OUT_OF_RANGE        |+| 12  | UNIMPLEMENTED       |+| 13  | INTERNAL            |+| 14  | UNAVAILABLE         |+| 15  | DATA_LOSS           |+| 16  | UNAUTHENTICATED     |++Using the OK Status Code for a Call may only be decided by server applications.+Library implementations must not ""fabricate"" an OK Status Code; it may only+communicate an OK Status Code that was provided to it. While there may be+additional restrictions on Status Code usage like those detailed in+[statuscodes.md](statuscodes.md), those restrictions are more to provide a+cohesive experience instead of a core, fundamental requirement.++## Metadata++Metadata has keys with associated values. Each key can have multiple values.+Keys are unordered, but values for a key are ordered. Keys are case insensitive,+and commonly canonicalized by making lower case. APIs are permitted to require a+canonical representation and that representation may be different than the+""lower case"" representation mentioned here. A key can be for ASCII or binary+values. If a key is for binary values, its name must be suffixed with ""-bin"".+Otherwise it is for ASCII values.++ASCII values are discouraged from having leading or trailing whitespace. If such+a value contains leading or trailing whitespace, the whitespace may be stripped.+Multiple ASCII values for the same key may be joined together with "","" (a comma)",Is this really part of the semantic protocol?  I don't think I was aware of this.  I suspect we're not doing anything like this in C-core.,
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/15504,189994360,2018-05-22T17:50:18Z,src/core/lib/iomgr/ev_epollex_linux.cc,"@@ -767,6 +768,10 @@ static int poll_deadline_to_millis_timeout(grpc_millis millis) { }  static void fd_become_readable(grpc_fd* fd, grpc_pollset* notifier) {+  if (grpc_latency_estimator_trace.enabled()) {+    gpr_log(GPR_INFO, ""latency_estimator:server_inbound_reading:start"");","@ncteisen Had a discussion offline and decided it's ok to leave the log statements where they are now, as long as it's consistent between runs. I think modifying the post processor to have the two separate modes should work as a quick solution.",
2811396,ejona86,https://api.github.com/repos/grpc/grpc/pulls/15460,190000742,2018-05-22T18:10:30Z,doc/PROTOCOL-SEMANTICS.md,"@@ -0,0 +1,221 @@+# gRPC semantics++gRPC has many features, but the most fundamental core is the ability to perform+RPCs. The goal of this document is defining the semantics of gRPC's RPCs.++## Channels++Most implementations will have Channel and Server concepts. A Channel is a+virtual connection to an endpoint, capable of sending RPCs. Channel is ""virtual""+because the Channel is free to have zero or many actual connections. A Channel+is free to determine which actual endpoints to use and may change it every RPC,+permitting client-side load balancing. A Server would be capable of receiving+incoming connections and receiving RPCs.++A ""connection"" is not a gRPC semantic concept and thus users should not assume a+correlation between connections and RPCs. Although, practically, users should be+aware of the common restriction that RPCs are unable to survive longer than the+connection on which they exist.++The exact details of how the communication is performed and higher level+abstractions can change when necessary and are thus not a focus for this+document. Although implementations SHOULD support the [HTTP/2+transport](PROTOCOL-HTTP2.md) to provide a basis for interoperability.++## Methods++An RPC is performed on a Method. The Method has a name, defines the intended+operation, the message types involved with the RPC, and the cardinality of+those messages.  It does not define the endpoint to send the RPC to; this is+normally handled by the Channel.++A Method's intended operation is just normal documentation describing what a+Method does, intended for a developer. gRPC itself is not generally aware of the+intended operation.++A Method has a request message type and a separate response message type. gRPC+is only aware of these types well enough to serialize and deserialize them. They+are largely considered ""binary blobs"" to gRPC itself.++A Method's request and response each have a cardinality: either one (""unary""),+or zero to many (a ""stream""). This produces four possible configurations which,+for convenience, each have a name:++|                       | **unary response** | **streaming response** |+| --------------------- | ------------------ | ---------------------- |+| **unary request**     | unary              | server-streaming       |+| **streaming request** | client-streaming   | bidirectional (bidi)   |++While we use the term ""method,"" pedantically it is closer to ""function"" as it is","But that state is effectively global state to the process. From the view point of an external caller, it's a function. This paragraph is important because many well-known RPC systems are OO (at least Java's RMI, CORBA, DCOM, DCE/RPC, REST, Cap’n Proto, dbus, and Android's Binder; SOAP is the main thing missing from that list). As in, you get a server-side object and then call methods on it. Those methods could return other objects for you to call more methods on. Objects can implement interfaces, etc.",
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/15418,190004607,2018-05-22T18:22:10Z,src/core/ext/transport/chttp2/transport/hpack_encoder.h,"@@ -29,7 +29,8 @@ #include ""src/core/lib/transport/transport.h""  #define GRPC_CHTTP2_HPACKC_NUM_FILTERS 256-#define GRPC_CHTTP2_HPACKC_NUM_VALUES 256+#define GRPC_CHTTP2_HPACKC_NUM_VALUES_BITS 6",Please add a comment that this should be no larger than 8.,
2811396,ejona86,https://api.github.com/repos/grpc/grpc/pulls/15460,190031586,2018-05-22T19:52:28Z,doc/PROTOCOL-SEMANTICS.md,"@@ -0,0 +1,221 @@+# gRPC semantics++gRPC has many features, but the most fundamental core is the ability to perform+RPCs. The goal of this document is defining the semantics of gRPC's RPCs.++## Channels++Most implementations will have Channel and Server concepts. A Channel is a+virtual connection to an endpoint, capable of sending RPCs. Channel is ""virtual""+because the Channel is free to have zero or many actual connections. A Channel+is free to determine which actual endpoints to use and may change it every RPC,+permitting client-side load balancing. A Server would be capable of receiving+incoming connections and receiving RPCs.++A ""connection"" is not a gRPC semantic concept and thus users should not assume a+correlation between connections and RPCs. Although, practically, users should be+aware of the common restriction that RPCs are unable to survive longer than the+connection on which they exist.++The exact details of how the communication is performed and higher level+abstractions can change when necessary and are thus not a focus for this+document. Although implementations SHOULD support the [HTTP/2+transport](PROTOCOL-HTTP2.md) to provide a basis for interoperability.++## Methods++An RPC is performed on a Method. The Method has a name, defines the intended+operation, the message types involved with the RPC, and the cardinality of+those messages.  It does not define the endpoint to send the RPC to; this is+normally handled by the Channel.++A Method's intended operation is just normal documentation describing what a+Method does, intended for a developer. gRPC itself is not generally aware of the+intended operation.++A Method has a request message type and a separate response message type. gRPC+is only aware of these types well enough to serialize and deserialize them. They+are largely considered ""binary blobs"" to gRPC itself.++A Method's request and response each have a cardinality: either one (""unary""),+or zero to many (a ""stream""). This produces four possible configurations which,+for convenience, each have a name:++|                       | **unary response** | **streaming response** |+| --------------------- | ------------------ | ---------------------- |+| **unary request**     | unary              | server-streaming       |+| **streaming request** | client-streaming   | bidirectional (bidi)   |++While we use the term ""method,"" pedantically it is closer to ""function"" as it is+not object oriented and there is no ""receiver"" involved (the `this` variable in+many languages) other than the destination machine. gRPC is based on message+passing, not object orientation.++Related Methods are typically grouped into a Service. To gRPC, a Service is a+group of methods that tend to be implemented together and that all share the+Service's namespace. A Service is a higher-level abstraction and may not be+present explicitly in all implementations. However, the namespace provided by a+Service is a core distinguishing feature of its Methods; if two Methods have the+same name but exist in different Services they must be considered distinct and+not be confused. A Method name including its Service namespace prefix with a ""/""+separator is a ""full method name"".++## Calls++RPCs, or ""Calls,"" are initiated by a client to a server, typically via a+Channel. The initiation is with Request Headers, within which the client","Getting the terminology right will be interesting.So I wasn't using the HTTP/2 terms here. These were the gRPC terms. Note also I wasn't referring to just Metadata here. Request Headers contains the Full Method Name, and that's not part of any Metadata. Similarly the Trailers contains the Status, which is not part of Metadata. See the ABNF at the end. I do need to improve this part some to make it more clear what contains what; I'm relying on the ABNF a bit too much right now. I've made changes that may improve that.Java does not have ""initial metadata"", nor does Go. It's just ""headers"" (""header"" in Go) of type Metadata. We've had discussions in the past where ""initial metadata"" was confusing, because it isn't necessarily present (I know there's some API confusion between ""empty"" and ""not present""). Only Trailers is guaranteed to be present.",
2811396,ejona86,https://api.github.com/repos/grpc/grpc/pulls/15460,190032450,2018-05-22T19:55:39Z,doc/PROTOCOL-SEMANTICS.md,"@@ -0,0 +1,221 @@+# gRPC semantics++gRPC has many features, but the most fundamental core is the ability to perform+RPCs. The goal of this document is defining the semantics of gRPC's RPCs.++## Channels++Most implementations will have Channel and Server concepts. A Channel is a+virtual connection to an endpoint, capable of sending RPCs. Channel is ""virtual""+because the Channel is free to have zero or many actual connections. A Channel+is free to determine which actual endpoints to use and may change it every RPC,+permitting client-side load balancing. A Server would be capable of receiving+incoming connections and receiving RPCs.++A ""connection"" is not a gRPC semantic concept and thus users should not assume a+correlation between connections and RPCs. Although, practically, users should be+aware of the common restriction that RPCs are unable to survive longer than the+connection on which they exist.++The exact details of how the communication is performed and higher level+abstractions can change when necessary and are thus not a focus for this+document. Although implementations SHOULD support the [HTTP/2+transport](PROTOCOL-HTTP2.md) to provide a basis for interoperability.++## Methods++An RPC is performed on a Method. The Method has a name, defines the intended+operation, the message types involved with the RPC, and the cardinality of+those messages.  It does not define the endpoint to send the RPC to; this is+normally handled by the Channel.++A Method's intended operation is just normal documentation describing what a+Method does, intended for a developer. gRPC itself is not generally aware of the+intended operation.++A Method has a request message type and a separate response message type. gRPC+is only aware of these types well enough to serialize and deserialize them. They+are largely considered ""binary blobs"" to gRPC itself.++A Method's request and response each have a cardinality: either one (""unary""),+or zero to many (a ""stream""). This produces four possible configurations which,+for convenience, each have a name:++|                       | **unary response** | **streaming response** |+| --------------------- | ------------------ | ---------------------- |+| **unary request**     | unary              | server-streaming       |+| **streaming request** | client-streaming   | bidirectional (bidi)   |++While we use the term ""method,"" pedantically it is closer to ""function"" as it is+not object oriented and there is no ""receiver"" involved (the `this` variable in+many languages) other than the destination machine. gRPC is based on message+passing, not object orientation.++Related Methods are typically grouped into a Service. To gRPC, a Service is a+group of methods that tend to be implemented together and that all share the+Service's namespace. A Service is a higher-level abstraction and may not be+present explicitly in all implementations. However, the namespace provided by a+Service is a core distinguishing feature of its Methods; if two Methods have the+same name but exist in different Services they must be considered distinct and+not be confused. A Method name including its Service namespace prefix with a ""/""+separator is a ""full method name"".++## Calls++RPCs, or ""Calls,"" are initiated by a client to a server, typically via a+Channel. The initiation is with Request Headers, within which the client+indicates the method to be run by its Full Method Name. The Call is gracefully+completed when the server responds with Trailers, which contains a Status+communicating the success or failure of the RPC. Note that on the server there+is a period of time between when the server application responds with a Trailers+and when that Trailers is actually sent; the Call is only truly complete when+the Trailers is sent. Similarly, on the client there is a period between the+gRPC implementation receiving the Trailers and when the application receives the+Trailers; the Call is only truly complete when the Trailers is received by the+application.++Calls may terminate early by being ""cancelled."" Implementations must allow+clients to cancel Calls, but cancellations may occur in other ways like I/O+failures. A cancellation appears as a Trailers to clients and is a special state+on servers. Cancellation is an abrupt killing of the Call; inbound and outbound+buffered data should be cleared. Cancellation trumps graceful completion; if the+client gRPC implementation received the Trailers before the cancellation, yet+the client application has not received the Trailers, then cancellation+generally should win. No auxilary information is included in cancellation+signals between the client and server. Server implementations may fail a Call+and respond with Trailers while claiming to the server application that the Call+was cancelled.++There may be multiple servers that _could_ have received the Call (as is common","Done. That also helps to move the ""two independent streams"" paragraph higher, since I want to keep cancellation together with the rest of the call lifecycle paragraph.",
2811396,ejona86,https://api.github.com/repos/grpc/grpc/pulls/15460,190033738,2018-05-22T20:00:16Z,doc/PROTOCOL-SEMANTICS.md,"@@ -0,0 +1,221 @@+# gRPC semantics++gRPC has many features, but the most fundamental core is the ability to perform+RPCs. The goal of this document is defining the semantics of gRPC's RPCs.++## Channels++Most implementations will have Channel and Server concepts. A Channel is a+virtual connection to an endpoint, capable of sending RPCs. Channel is ""virtual""+because the Channel is free to have zero or many actual connections. A Channel+is free to determine which actual endpoints to use and may change it every RPC,+permitting client-side load balancing. A Server would be capable of receiving+incoming connections and receiving RPCs.++A ""connection"" is not a gRPC semantic concept and thus users should not assume a+correlation between connections and RPCs. Although, practically, users should be+aware of the common restriction that RPCs are unable to survive longer than the+connection on which they exist.++The exact details of how the communication is performed and higher level+abstractions can change when necessary and are thus not a focus for this+document. Although implementations SHOULD support the [HTTP/2+transport](PROTOCOL-HTTP2.md) to provide a basis for interoperability.++## Methods++An RPC is performed on a Method. The Method has a name, defines the intended+operation, the message types involved with the RPC, and the cardinality of+those messages.  It does not define the endpoint to send the RPC to; this is+normally handled by the Channel.++A Method's intended operation is just normal documentation describing what a+Method does, intended for a developer. gRPC itself is not generally aware of the+intended operation.++A Method has a request message type and a separate response message type. gRPC+is only aware of these types well enough to serialize and deserialize them. They+are largely considered ""binary blobs"" to gRPC itself.++A Method's request and response each have a cardinality: either one (""unary""),+or zero to many (a ""stream""). This produces four possible configurations which,+for convenience, each have a name:++|                       | **unary response** | **streaming response** |+| --------------------- | ------------------ | ---------------------- |+| **unary request**     | unary              | server-streaming       |+| **streaming request** | client-streaming   | bidirectional (bidi)   |++While we use the term ""method,"" pedantically it is closer to ""function"" as it is+not object oriented and there is no ""receiver"" involved (the `this` variable in+many languages) other than the destination machine. gRPC is based on message+passing, not object orientation.++Related Methods are typically grouped into a Service. To gRPC, a Service is a+group of methods that tend to be implemented together and that all share the+Service's namespace. A Service is a higher-level abstraction and may not be+present explicitly in all implementations. However, the namespace provided by a+Service is a core distinguishing feature of its Methods; if two Methods have the+same name but exist in different Services they must be considered distinct and+not be confused. A Method name including its Service namespace prefix with a ""/""+separator is a ""full method name"".++## Calls++RPCs, or ""Calls,"" are initiated by a client to a server, typically via a+Channel. The initiation is with Request Headers, within which the client+indicates the method to be run by its Full Method Name. The Call is gracefully+completed when the server responds with Trailers, which contains a Status+communicating the success or failure of the RPC. Note that on the server there+is a period of time between when the server application responds with a Trailers+and when that Trailers is actually sent; the Call is only truly complete when+the Trailers is sent. Similarly, on the client there is a period between the+gRPC implementation receiving the Trailers and when the application receives the+Trailers; the Call is only truly complete when the Trailers is received by the+application.++Calls may terminate early by being ""cancelled."" Implementations must allow+clients to cancel Calls, but cancellations may occur in other ways like I/O+failures. A cancellation appears as a Trailers to clients and is a special state+on servers. Cancellation is an abrupt killing of the Call; inbound and outbound+buffered data should be cleared. Cancellation trumps graceful completion; if the+client gRPC implementation received the Trailers before the cancellation, yet+the client application has not received the Trailers, then cancellation+generally should win. No auxilary information is included in cancellation+signals between the client and server. Server implementations may fail a Call+and respond with Trailers while claiming to the server application that the Call+was cancelled.++There may be multiple servers that _could_ have received the Call (as is common+for load balancing), but only a single server may process an individual Call.+Calls are assumed to be non-idempotent and may not be ""replayed"" except for when+gRPC is explicitly informed it is safe to do so.++Calls are natively two independent streams (i.e., full duplex bidirectional) of+Messages. The streams are each started with Headers. The end of the request+stream is delimited by Half Close. The end of the response stream is delimited+by Trailers. Messages may exist between the Headers and the end of the stream.+Headers, Messages, Half Close, and Trailers are the units of communication and,+absent the Call's termination, will be communicated to the remote without+the need to send further units on the stream. However, see the optimizations+permitted for unary Calls below.++The two independent streams are each unidirectional and do not provide any+information in the reverse direction other than Flow Control. Flow Control+is a signal from the receiver to the sender to temporarily pause sending+additional messages to avoid excessive buffering. Flow Control only applies to+messages, but since streams are in-order Half Close or Trailers may be delayed+waiting for message Flow Control in the same stream. No message receipt+acknowledgement information is provided. However applications may use messages+for such signals, as a response naturally acknowledges its request. Note in+particular that there is no provision for the server application to not know+whether the client application received a unary Call's response or a streaming+Call's Status.++Unary Calls may be optimized to be half-duplex and treat each stream as a single+communication unit. That is, on the client a unary Call may be delayed from+being sent until the Half Close is ready to be sent and on the server the+response may be delayed until the Trailers is ready.++Unary Calls that terminate with a Status Code of OK must contain a response+message. Unary Calls that terminate with a Status Code other than OK do not need+a response message, and at the implementation's discretion the response message+may be discarded if present.++## Status++A Status contains a ""code"" and a ""description"". The Status Description is a","I considered having something about ""use metadata for more detailed error information."" But it was too much of ""this is how you use the system"" which doesn't fit as well with the spec.I had considered binary error details to be a protobuf thing. We should have more conversations about how it fits in. The biggest question is how does the client know what format the binary error details are in. Is that a property of the method? Unfortunately even if only considering ""protobuf"" we wouldn't know the format. Since we've allowed ourselves the opportunity to still use the JSON-encoded-protobuf and Content-Type does not apply to headers it could be quite ambiguous what format it is. Earlier I had that it would always be google.rpc.Status in binary proto encoding.",
2811396,ejona86,https://api.github.com/repos/grpc/grpc/pulls/15460,190034116,2018-05-22T20:01:37Z,doc/PROTOCOL-SEMANTICS.md,"@@ -0,0 +1,221 @@+# gRPC semantics++gRPC has many features, but the most fundamental core is the ability to perform+RPCs. The goal of this document is defining the semantics of gRPC's RPCs.++## Channels++Most implementations will have Channel and Server concepts. A Channel is a+virtual connection to an endpoint, capable of sending RPCs. Channel is ""virtual""+because the Channel is free to have zero or many actual connections. A Channel+is free to determine which actual endpoints to use and may change it every RPC,+permitting client-side load balancing. A Server would be capable of receiving+incoming connections and receiving RPCs.++A ""connection"" is not a gRPC semantic concept and thus users should not assume a+correlation between connections and RPCs. Although, practically, users should be+aware of the common restriction that RPCs are unable to survive longer than the+connection on which they exist.++The exact details of how the communication is performed and higher level+abstractions can change when necessary and are thus not a focus for this+document. Although implementations SHOULD support the [HTTP/2+transport](PROTOCOL-HTTP2.md) to provide a basis for interoperability.++## Methods++An RPC is performed on a Method. The Method has a name, defines the intended+operation, the message types involved with the RPC, and the cardinality of+those messages.  It does not define the endpoint to send the RPC to; this is+normally handled by the Channel.++A Method's intended operation is just normal documentation describing what a+Method does, intended for a developer. gRPC itself is not generally aware of the+intended operation.++A Method has a request message type and a separate response message type. gRPC+is only aware of these types well enough to serialize and deserialize them. They+are largely considered ""binary blobs"" to gRPC itself.++A Method's request and response each have a cardinality: either one (""unary""),+or zero to many (a ""stream""). This produces four possible configurations which,+for convenience, each have a name:++|                       | **unary response** | **streaming response** |+| --------------------- | ------------------ | ---------------------- |+| **unary request**     | unary              | server-streaming       |+| **streaming request** | client-streaming   | bidirectional (bidi)   |++While we use the term ""method,"" pedantically it is closer to ""function"" as it is+not object oriented and there is no ""receiver"" involved (the `this` variable in+many languages) other than the destination machine. gRPC is based on message+passing, not object orientation.++Related Methods are typically grouped into a Service. To gRPC, a Service is a+group of methods that tend to be implemented together and that all share the+Service's namespace. A Service is a higher-level abstraction and may not be+present explicitly in all implementations. However, the namespace provided by a+Service is a core distinguishing feature of its Methods; if two Methods have the+same name but exist in different Services they must be considered distinct and+not be confused. A Method name including its Service namespace prefix with a ""/""+separator is a ""full method name"".++## Calls++RPCs, or ""Calls,"" are initiated by a client to a server, typically via a+Channel. The initiation is with Request Headers, within which the client+indicates the method to be run by its Full Method Name. The Call is gracefully+completed when the server responds with Trailers, which contains a Status+communicating the success or failure of the RPC. Note that on the server there+is a period of time between when the server application responds with a Trailers+and when that Trailers is actually sent; the Call is only truly complete when+the Trailers is sent. Similarly, on the client there is a period between the+gRPC implementation receiving the Trailers and when the application receives the+Trailers; the Call is only truly complete when the Trailers is received by the+application.++Calls may terminate early by being ""cancelled."" Implementations must allow+clients to cancel Calls, but cancellations may occur in other ways like I/O+failures. A cancellation appears as a Trailers to clients and is a special state+on servers. Cancellation is an abrupt killing of the Call; inbound and outbound+buffered data should be cleared. Cancellation trumps graceful completion; if the+client gRPC implementation received the Trailers before the cancellation, yet+the client application has not received the Trailers, then cancellation+generally should win. No auxilary information is included in cancellation+signals between the client and server. Server implementations may fail a Call+and respond with Trailers while claiming to the server application that the Call+was cancelled.++There may be multiple servers that _could_ have received the Call (as is common+for load balancing), but only a single server may process an individual Call.+Calls are assumed to be non-idempotent and may not be ""replayed"" except for when+gRPC is explicitly informed it is safe to do so.++Calls are natively two independent streams (i.e., full duplex bidirectional) of+Messages. The streams are each started with Headers. The end of the request+stream is delimited by Half Close. The end of the response stream is delimited+by Trailers. Messages may exist between the Headers and the end of the stream.+Headers, Messages, Half Close, and Trailers are the units of communication and,+absent the Call's termination, will be communicated to the remote without+the need to send further units on the stream. However, see the optimizations+permitted for unary Calls below.++The two independent streams are each unidirectional and do not provide any+information in the reverse direction other than Flow Control. Flow Control+is a signal from the receiver to the sender to temporarily pause sending+additional messages to avoid excessive buffering. Flow Control only applies to+messages, but since streams are in-order Half Close or Trailers may be delayed+waiting for message Flow Control in the same stream. No message receipt+acknowledgement information is provided. However applications may use messages+for such signals, as a response naturally acknowledges its request. Note in+particular that there is no provision for the server application to not know+whether the client application received a unary Call's response or a streaming+Call's Status.++Unary Calls may be optimized to be half-duplex and treat each stream as a single+communication unit. That is, on the client a unary Call may be delayed from+being sent until the Half Close is ready to be sent and on the server the+response may be delayed until the Trailers is ready.++Unary Calls that terminate with a Status Code of OK must contain a response+message. Unary Calls that terminate with a Status Code other than OK do not need+a response message, and at the implementation's discretion the response message+may be discarded if present.++## Status++A Status contains a ""code"" and a ""description"". The Status Description is a+human-readable Unicode string for developer debugging. The Status Code is a+value from a pre-defined list of such codes. While Status Code is best+communicated to users by its name, it commonly is treated as an integer+internally, and so each code has a numeric value.++The valid Status Codes are:","I agree it needs to be its own doc, but that's a good amount of work. There's no descriptions listed anywhere, for instance. I do need OK, CANCELLED, and DEADLINE_EXCEEDED to be defined, though. I'd like to just consider that a TODO of sorts; if and when such a document exists, this document can be updated.",
2811396,ejona86,https://api.github.com/repos/grpc/grpc/pulls/15460,190034589,2018-05-22T20:03:15Z,doc/PROTOCOL-SEMANTICS.md,"@@ -0,0 +1,221 @@+# gRPC semantics++gRPC has many features, but the most fundamental core is the ability to perform+RPCs. The goal of this document is defining the semantics of gRPC's RPCs.++## Channels++Most implementations will have Channel and Server concepts. A Channel is a+virtual connection to an endpoint, capable of sending RPCs. Channel is ""virtual""+because the Channel is free to have zero or many actual connections. A Channel+is free to determine which actual endpoints to use and may change it every RPC,+permitting client-side load balancing. A Server would be capable of receiving+incoming connections and receiving RPCs.++A ""connection"" is not a gRPC semantic concept and thus users should not assume a+correlation between connections and RPCs. Although, practically, users should be+aware of the common restriction that RPCs are unable to survive longer than the+connection on which they exist.++The exact details of how the communication is performed and higher level+abstractions can change when necessary and are thus not a focus for this+document. Although implementations SHOULD support the [HTTP/2+transport](PROTOCOL-HTTP2.md) to provide a basis for interoperability.++## Methods++An RPC is performed on a Method. The Method has a name, defines the intended+operation, the message types involved with the RPC, and the cardinality of+those messages.  It does not define the endpoint to send the RPC to; this is+normally handled by the Channel.++A Method's intended operation is just normal documentation describing what a+Method does, intended for a developer. gRPC itself is not generally aware of the+intended operation.++A Method has a request message type and a separate response message type. gRPC+is only aware of these types well enough to serialize and deserialize them. They+are largely considered ""binary blobs"" to gRPC itself.++A Method's request and response each have a cardinality: either one (""unary""),+or zero to many (a ""stream""). This produces four possible configurations which,+for convenience, each have a name:++|                       | **unary response** | **streaming response** |+| --------------------- | ------------------ | ---------------------- |+| **unary request**     | unary              | server-streaming       |+| **streaming request** | client-streaming   | bidirectional (bidi)   |++While we use the term ""method,"" pedantically it is closer to ""function"" as it is+not object oriented and there is no ""receiver"" involved (the `this` variable in+many languages) other than the destination machine. gRPC is based on message+passing, not object orientation.++Related Methods are typically grouped into a Service. To gRPC, a Service is a+group of methods that tend to be implemented together and that all share the+Service's namespace. A Service is a higher-level abstraction and may not be+present explicitly in all implementations. However, the namespace provided by a+Service is a core distinguishing feature of its Methods; if two Methods have the+same name but exist in different Services they must be considered distinct and+not be confused. A Method name including its Service namespace prefix with a ""/""+separator is a ""full method name"".++## Calls++RPCs, or ""Calls,"" are initiated by a client to a server, typically via a+Channel. The initiation is with Request Headers, within which the client+indicates the method to be run by its Full Method Name. The Call is gracefully+completed when the server responds with Trailers, which contains a Status+communicating the success or failure of the RPC. Note that on the server there+is a period of time between when the server application responds with a Trailers+and when that Trailers is actually sent; the Call is only truly complete when+the Trailers is sent. Similarly, on the client there is a period between the+gRPC implementation receiving the Trailers and when the application receives the+Trailers; the Call is only truly complete when the Trailers is received by the+application.++Calls may terminate early by being ""cancelled."" Implementations must allow+clients to cancel Calls, but cancellations may occur in other ways like I/O+failures. A cancellation appears as a Trailers to clients and is a special state+on servers. Cancellation is an abrupt killing of the Call; inbound and outbound+buffered data should be cleared. Cancellation trumps graceful completion; if the+client gRPC implementation received the Trailers before the cancellation, yet+the client application has not received the Trailers, then cancellation+generally should win. No auxilary information is included in cancellation+signals between the client and server. Server implementations may fail a Call+and respond with Trailers while claiming to the server application that the Call+was cancelled.++There may be multiple servers that _could_ have received the Call (as is common+for load balancing), but only a single server may process an individual Call.+Calls are assumed to be non-idempotent and may not be ""replayed"" except for when+gRPC is explicitly informed it is safe to do so.++Calls are natively two independent streams (i.e., full duplex bidirectional) of+Messages. The streams are each started with Headers. The end of the request+stream is delimited by Half Close. The end of the response stream is delimited+by Trailers. Messages may exist between the Headers and the end of the stream.+Headers, Messages, Half Close, and Trailers are the units of communication and,+absent the Call's termination, will be communicated to the remote without+the need to send further units on the stream. However, see the optimizations+permitted for unary Calls below.++The two independent streams are each unidirectional and do not provide any+information in the reverse direction other than Flow Control. Flow Control+is a signal from the receiver to the sender to temporarily pause sending+additional messages to avoid excessive buffering. Flow Control only applies to+messages, but since streams are in-order Half Close or Trailers may be delayed+waiting for message Flow Control in the same stream. No message receipt+acknowledgement information is provided. However applications may use messages+for such signals, as a response naturally acknowledges its request. Note in+particular that there is no provision for the server application to not know+whether the client application received a unary Call's response or a streaming+Call's Status.++Unary Calls may be optimized to be half-duplex and treat each stream as a single+communication unit. That is, on the client a unary Call may be delayed from+being sent until the Half Close is ready to be sent and on the server the+response may be delayed until the Trailers is ready.++Unary Calls that terminate with a Status Code of OK must contain a response+message. Unary Calls that terminate with a Status Code other than OK do not need+a response message, and at the implementation's discretion the response message+may be discarded if present.++## Status++A Status contains a ""code"" and a ""description"". The Status Description is a+human-readable Unicode string for developer debugging. The Status Code is a+value from a pre-defined list of such codes. While Status Code is best+communicated to users by its name, it commonly is treated as an integer+internally, and so each code has a numeric value.++The valid Status Codes are:++| Num | Name                |+| --- | ------------------- |+| 0   | OK                  |+| 1   | CANCELLED           |+| 2   | UNKNOWN             |+| 3   | INVALID_ARGUMENT    |+| 4   | DEADLINE_EXCEEDED   |+| 5   | NOT_FOUND           |+| 6   | ALREADY_EXISTS      |+| 7   | PERMISSION_DENIED   |+| 8   | RESOURCE_EXHAUSTED  |+| 9   | FAILED_PRECONDITION |+| 10  | ABORTED             |+| 11  | OUT_OF_RANGE        |+| 12  | UNIMPLEMENTED       |+| 13  | INTERNAL            |+| 14  | UNAVAILABLE         |+| 15  | DATA_LOSS           |+| 16  | UNAUTHENTICATED     |++Using the OK Status Code for a Call may only be decided by server applications.+Library implementations must not ""fabricate"" an OK Status Code; it may only+communicate an OK Status Code that was provided to it. While there may be+additional restrictions on Status Code usage like those detailed in+[statuscodes.md](statuscodes.md), those restrictions are more to provide a+cohesive experience instead of a core, fundamental requirement.++## Metadata++Metadata has keys with associated values. Each key can have multiple values.+Keys are unordered, but values for a key are ordered. Keys are case insensitive,+and commonly canonicalized by making lower case. APIs are permitted to require a+canonical representation and that representation may be different than the+""lower case"" representation mentioned here. A key can be for ASCII or binary+values. If a key is for binary values, its name must be suffixed with ""-bin"".","I thought it was pretty core in all of our APIs. The name is semantically important and ""foo"" and ""foo-bin"" are not equivalent. No API is auto-appending the ""-bin"". Now the detail about base64-encoding ""-bin"" values is HTTP/2-specific and not included.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/15356,190114419,2018-05-23T03:36:57Z,examples/ruby/grpc-demo.gemspec,"@@ -19,5 +19,6 @@ Gem::Specification.new do |s|    s.add_dependency 'grpc', '~> 1.0' -  s.add_development_dependency 'bundler', '~> 1.7'+  s.add_development_dependency 'bundler',    '~> 1.7'+  s.add_development_dependency 'googleauth', '>= 0.5.1', '< 0.7'","The moving of the pubsub files is perhaps nice to have but isn't a necessary part of removing the `googleauth` production dependency (unless I'm missing something). Can we please revert those changes from this PR and keep this PR focused on dropping the `googleauth` dependency. Otherwise, I'm worried that, e.g., the change to the examples gemspec here might confuse people by appearing to be a new burden that the dropping of googleauth places on users.",
5616899,ganmacs,https://api.github.com/repos/grpc/grpc/pulls/15356,190251882,2018-05-23T13:46:28Z,examples/ruby/grpc-demo.gemspec,"@@ -19,5 +19,6 @@ Gem::Specification.new do |s|    s.add_dependency 'grpc', '~> 1.0' -  s.add_development_dependency 'bundler', '~> 1.7'+  s.add_development_dependency 'bundler',    '~> 1.7'+  s.add_development_dependency 'googleauth', '>= 0.5.1', '< 0.7'","I believe in it's a necessary change because pubsub files use googleauth gem at [here](https://github.com/grpc/grpc/blob/master/src/ruby/bin/apis/pubsub_demo.rb#L35).pubsub files depend on googleauth and are included in grpc-ruby since grpc.gemspec specify at [here](https://github.com/grpc/grpc/blob/master/grpc.gemspec#L20).If I leave it as it is, a situaction which  grpc-ruby doesn't depend on googleauth gem although it includes pubsub files depending on googleauth gem would cause.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/15356,190473869,2018-05-24T06:05:27Z,examples/ruby/grpc-demo.gemspec,"@@ -19,5 +19,6 @@ Gem::Specification.new do |s|    s.add_dependency 'grpc', '~> 1.0' -  s.add_development_dependency 'bundler', '~> 1.7'+  s.add_development_dependency 'bundler',    '~> 1.7'+  s.add_development_dependency 'googleauth', '>= 0.5.1', '< 0.7'","I see, you're right this feels like it belongs in a samples directory. I want to circle back to this after checking offline about the origin of these files (I'm actually not sure what/if they're used for now).Also, is it possible to move these samples into its own subdirectory if `examples/ruby`?thanks",
25474919,kumudt,https://api.github.com/repos/grpc/grpc/pulls/12100,190475501,2018-05-24T06:16:55Z,src/ruby/lib/grpc/generic/rpc_desc.rb,"@@ -47,43 +47,85 @@ def unmarshal_proc(target)       proc { |o| unmarshal_class.method(unmarshal_method).call(o) }     end -    def handle_request_response(active_call, mth)+    def handle_request_response(active_call, mth, inter_ctx)       req = active_call.read_unary_request-      resp = mth.call(req, active_call.single_req_view)-      active_call.server_unary_response(-        resp, trailing_metadata: active_call.output_metadata)+      call = active_call.single_req_view++      inter_ctx.intercept!(+        :request_response,+        method: mth,+        call: call,+        request: req+      ) do+        resp = mth.call(req, call)+        active_call.server_unary_response(","Hi @splittingred Is there any reason why the active_call is sending the response within the yield block? As of now, yield's return value inside a middleware is nil. Looks like the response is sent as soon as the handler method is invoked and the middlewares cannot even read the response.But, the design document seemed like we can catch the response in the middlewares. Has the design changed keeping the security aspect in mind?Also, just to make my understanding clear, the server interceptors as of now can only modify the response metadata. Am I right?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/15356,190658698,2018-05-24T16:54:59Z,examples/ruby/grpc-demo.gemspec,"@@ -19,5 +19,6 @@ Gem::Specification.new do |s|    s.add_dependency 'grpc', '~> 1.0' -  s.add_development_dependency 'bundler', '~> 1.7'+  s.add_development_dependency 'bundler',    '~> 1.7'+  s.add_development_dependency 'googleauth', '>= 0.5.1', '< 0.7'","My main goal is wondering if we can use a different gemspec file, so as to avoid adding a `googoelauth` dependency for the existing ""route guide"" and ""greeter"" examples, which don't need it.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/15480,190768637,2018-05-25T01:01:22Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -2624,59 +2624,133 @@ static void pick_done(void* arg, grpc_error* error) {   } } +static void maybe_add_call_to_channel_interested_parties_locked(+    grpc_call_element* elem) {+  channel_data* chand = static_cast<channel_data*>(elem->channel_data);+  call_data* calld = static_cast<call_data*>(elem->call_data);+  if (!calld->pollent_added_to_interested_parties) {+    calld->pollent_added_to_interested_parties = true;+    grpc_polling_entity_add_to_pollset_set(calld->pollent,+                                           chand->interested_parties);+  }+}++static void maybe_del_call_from_channel_interested_parties_locked(+    grpc_call_element* elem) {+  channel_data* chand = static_cast<channel_data*>(elem->channel_data);+  call_data* calld = static_cast<call_data*>(elem->call_data);+  if (calld->pollent_added_to_interested_parties) {+    calld->pollent_added_to_interested_parties = false;+    grpc_polling_entity_del_from_pollset_set(calld->pollent,+                                             chand->interested_parties);+  }+}+ // Invoked when a pick is completed to leave the client_channel combiner // and continue processing in the call combiner.+// If needed, removes the call's polling entity from chand->interested_parties. static void pick_done_locked(grpc_call_element* elem, grpc_error* error) {   call_data* calld = static_cast<call_data*>(elem->call_data);+  maybe_del_call_from_channel_interested_parties_locked(elem);   GRPC_CLOSURE_INIT(&calld->pick_closure, pick_done, elem,                     grpc_schedule_on_exec_ctx);   GRPC_CLOSURE_SCHED(&calld->pick_closure, error); } -// A wrapper around pick_done_locked() that is used in cases where-// either (a) the pick was deferred pending a resolver result or (b) the-// pick was done asynchronously.  Removes the call's polling entity from-// chand->interested_parties before invoking pick_done_locked().-static void async_pick_done_locked(grpc_call_element* elem, grpc_error* error) {-  channel_data* chand = static_cast<channel_data*>(elem->channel_data);-  call_data* calld = static_cast<call_data*>(elem->call_data);-  grpc_polling_entity_del_from_pollset_set(calld->pollent,-                                           chand->interested_parties);-  pick_done_locked(elem, error);-}+namespace grpc_core { -// Note: This runs under the client_channel combiner, but will NOT be-// holding the call combiner.-static void pick_callback_cancel_locked(void* arg, grpc_error* error) {-  grpc_call_element* elem = static_cast<grpc_call_element*>(arg);-  channel_data* chand = static_cast<channel_data*>(elem->channel_data);-  call_data* calld = static_cast<call_data*>(elem->call_data);-  // Note: chand->lb_policy may have changed since we started our pick,-  // in which case we will be cancelling the pick on a policy other than-  // the one we started it on.  However, this will just be a no-op.-  if (error != GRPC_ERROR_NONE && chand->lb_policy != nullptr) {+// Performs subchannel pick via LB policy.+class LbPicker {","why bother creating a class having all its methods be static? It's also not used outside of this file, so the control of the visibility of the methods is also of little use. I think an anonymous namespace containing regular functions would serve the same purpose in a simpler way.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/15538,191007756,2018-05-25T20:55:35Z,src/core/ext/filters/http/server/http_server_filter.cc,"@@ -266,49 +260,55 @@ static grpc_error* server_filter_incoming_metadata(grpc_call_element* elem,   return error; } -static void hs_on_recv(void* user_data, grpc_error* err) {+static void recv_initial_metadata_ready(void* user_data, grpc_error* err) {","Nit, but can you keep something in the func names that shows this to be from http server file? I have future plans to change all static functions to have unique names with a linter to enforce. flamegraphs do not show file metadata, so if we see a `recv_initial_metadata_ready`, we don't know which filter it came from",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15538,191013096,2018-05-25T21:26:58Z,src/core/ext/filters/http/server/http_server_filter.cc,"@@ -266,49 +260,55 @@ static grpc_error* server_filter_incoming_metadata(grpc_call_element* elem,   return error; } -static void hs_on_recv(void* user_data, grpc_error* err) {+static void recv_initial_metadata_ready(void* user_data, grpc_error* err) {","Done.Note that this problem will go away when we convert the filter API to C++, since the filter class will be part of the reported function name.",
8295100,davidt99,https://api.github.com/repos/grpc/grpc/pulls/14557,191256979,2018-05-28T18:33:30Z,src/python/grpcio/grpc/_channel.py,"@@ -24,6 +24,8 @@ from grpc._cython import cygrpc from grpc.framework.foundation import callable_util +_LOGGER = logging.getLogger(__name__)","The logger name should be lower case, Upper case should only be used when naming a constant, and the logger is not a constant.",
8295100,davidt99,https://api.github.com/repos/grpc/grpc/pulls/14557,191264340,2018-05-28T19:46:24Z,src/python/grpcio/grpc/_channel.py,"@@ -24,6 +24,8 @@ from grpc._cython import cygrpc from grpc.framework.foundation import callable_util +_LOGGER = logging.getLogger(__name__)","IMO, a constant is a simple immutable object i.e int, string, date, etc and not a complex object such as logger. The logger instance's properties and variables can be changed in any time when configuring python's logging. I'm not expecting this kind of behavior from a constant.",
28968539,ZhouyihaiDing,https://api.github.com/repos/grpc/grpc/pulls/15479,191594184,2018-05-29T22:30:10Z,src/php/.php_cs.dist,"@@ -0,0 +1,19 @@+<?php++$finder = PhpCsFixer\Finder::create()+    ->exclude('bin')+    ->exclude('ext')+    ->exclude('tests/data')+    ->exclude('tests/qps/generated_code')+    ->in(__DIR__)+;++return PhpCsFixer\Config::create()",Thanks for the pull request!What do you think about changing the settings to [this config](https://github.com/GoogleCloudPlatform/php-docs-samples/blob/master/.php_cs.dist)? I think we are using this format rules.,
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/15196,191609569,2018-05-29T23:58:55Z,src/cpp/server/load_reporter/util.h,"@@ -0,0 +1,106 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_SRC_CPP_SERVER_LOAD_REPORTER_UTIL_H+#define GRPC_SRC_CPP_SERVER_LOAD_REPORTER_UTIL_H++#include ""opencensus/stats/stats.h""++namespace grpc {+namespace load_reporter {++constexpr char kCallStatusOk[] = ""OK"";+constexpr char kCallStatusServerError[] = ""5XX"";+constexpr char kCallStatusClientError[] = ""4XX"";++constexpr char kTagKeyToken[] = ""token"";+constexpr char kTagKeyHost[] = ""host"";+constexpr char kTagKeyUserId[] = ""user_id"";+constexpr char kTagKeyStatus[] = ""status"";+constexpr char kTagKeyMetricName[] = ""metric_name"";++constexpr char kMeasureStartCount[] = ""grpc.io/lb/start_count"";+constexpr char kMeasureEndCount[] = ""grpc.io/lb/end_count"";+constexpr char kMeasureEndBytesSent[] = ""grpc.io/lb/bytes_sent"";+constexpr char kMeasureEndBytesReceived[] = ""grpc.io/lb/bytes_received"";+constexpr char kMeasureEndLatencyMs[] = ""grpc.io/lb/latency_ms"";+constexpr char kMeasureOtherCallMetric[] = ""grpc.io/lb/other_call_metric"";++constexpr char kViewStartCount[] = ""grpc.io/lb_view/start_count"";+constexpr char kViewEndCount[] = ""grpc.io/lb_view/end_count"";+constexpr char kViewEndBytesSent[] = ""grpc.io/lb_view/bytes_sent"";+constexpr char kViewEndBytesReceived[] = ""grpc.io/lb_view/bytes_received"";+constexpr char kViewEndLatencyMs[] = ""grpc.io/lb_view/latency_ms"";+constexpr char kViewOtherCallMetricCount[] =+    ""grpc.io/lb_view/other_call_metric_count"";+constexpr char kViewOtherCallMetricValue[] =+    ""grpc.io/lb_view/other_call_metric_value"";++// Measures.++::opencensus::stats::MeasureInt64 GetMeasureStartCount() {+  static const ::opencensus::stats::MeasureInt64 start_count =",According to the style guide https://google.github.io/styleguide/cppguide.html#Static_and_Global_Variables this static variable is forbidden. But this is the recommended style from the OpenCensus [example](https://github.com/census-instrumentation/opencensus-cpp/blob/13e95557eaa03fdcfbafb1a005298b03353ff34d/opencensus/stats/examples/view_and_recording_example.cc#L30). @isturdy  So I'm wondering if there is any recommended way to get the measures and the tags without violating the style guide.,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/15577,191905379,2018-05-30T20:06:19Z,third_party/nanopb/pb.h,"@@ -22,7 +22,7 @@ /* #define PB_MAX_REQUIRED_FIELDS 256 */  /* Add support for tag numbers > 255 and fields larger than 255 bytes. */-/* #define PB_FIELD_16BIT 1 */+#define PB_FIELD_16BIT 1","We cannot modify this file. The contents of `third_party/` are managed as git submodules.It shouldn't be needed either. For bazel, we already have it enabled ([relevant change](https://github.com/grpc/grpc/pull/14716/files)). Similarly for `make`-based build systems we already have this defined via compiler args: https://github.com/grpc/grpc/blob/63476cfa5409c6deedffed03a47bbbcb96f17334/templates/Makefile.template#L224",
704028,deeglaze,https://api.github.com/repos/grpc/grpc/pulls/15577,191930505,2018-05-30T21:34:38Z,third_party/nanopb/pb.h,"@@ -22,7 +22,7 @@ /* #define PB_MAX_REQUIRED_FIELDS 256 */  /* Add support for tag numbers > 255 and fields larger than 255 bytes. */-/* #define PB_FIELD_16BIT 1 */+#define PB_FIELD_16BIT 1","We also use Bazel, but our build's dependency on alts_proto still fails with a message saying to define PB_FIELD_16BIT. We're at release 1.11.0, so your linked change didn't seem to do the trick. Ideas?",
704028,deeglaze,https://api.github.com/repos/grpc/grpc/pulls/15577,192153247,2018-05-31T16:06:55Z,third_party/nanopb/pb.h,"@@ -22,7 +22,7 @@ /* #define PB_MAX_REQUIRED_FIELDS 256 */  /* Add support for tag numbers > 255 and fields larger than 255 bytes. */-/* #define PB_FIELD_16BIT 1 */+#define PB_FIELD_16BIT 1",Here is a rule that fails to build its alts_proto transitive dependency: https://github.com/google/asylo/blob/master/asylo/grpc/auth/core/BUILD#L35,
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/15069,192168422,2018-05-31T16:59:40Z,src/core/lib/iomgr/cfstream_handle.h,"@@ -0,0 +1,82 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++/* The CFStream handle acts as an event synchronization entity for+ * read/write/open/error/eos events happening on CFStream streams. */++#ifndef GRPC_CORE_LIB_IOMGR_CFSTREAM_HANDLE_H+#define GRPC_CORE_LIB_IOMGR_CFSTREAM_HANDLE_H++#include <grpc/support/port_platform.h>++#include ""src/core/lib/iomgr/port.h""++#ifdef GRPC_CFSTREAM+#import <CoreFoundation/CoreFoundation.h>++#include ""src/core/lib/iomgr/closure.h""+#include ""src/core/lib/iomgr/lockfree_event.h""++class CFStreamHandle final {+ public:+  static CFStreamHandle* CreateStreamSync(CFReadStreamRef read_stream,+                                          CFWriteStreamRef write_stream);+  ~CFStreamHandle();+  CFStreamHandle(const CFReadStreamRef& ref) = delete;+  CFStreamHandle(CFReadStreamRef&& ref) = delete;+  CFStreamHandle& operator=(const CFStreamHandle& rhs) = delete;++  void NotifyOnOpen(grpc_closure* closure);+  void NotifyOnRead(grpc_closure* closure);+  void NotifyOnWrite(grpc_closure* closure);+  void Shutdown(grpc_error* error);++  void Ref(const char* file = nullptr, int line = 0,+           const char* reason = nullptr);+  void Unref(const char* file = nullptr, int line = 0,+             const char* reason = nullptr);++ private:+  CFStreamHandle(CFReadStreamRef read_stream, CFWriteStreamRef write_stream);+  static void ReadCallback(CFReadStreamRef stream, CFStreamEventType type,+                           void* client_callback_info);+  static void WriteCallback(CFWriteStreamRef stream, CFStreamEventType type,+                            void* client_callback_info);+  static void* Retain(void* info);+  static void Release(void* info);++  grpc_core::LockfreeEvent open_event_;+  grpc_core::LockfreeEvent read_event_;+  grpc_core::LockfreeEvent write_event_;++  gpr_refcount refcount_;+};++#ifndef NDEBUG",(I know this isn't necessarily the pattern we've been doing so far...),
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/15069,192180876,2018-05-31T17:43:14Z,src/core/lib/iomgr/tcp_client_cfstream.cc,"@@ -0,0 +1,212 @@++/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/support/port_platform.h>++#include ""src/core/lib/iomgr/port.h""++#ifdef GRPC_CFSTREAM_CLIENT++#include <CoreFoundation/CoreFoundation.h>++#include <string.h>++#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include <netinet/in.h>++#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/gpr/host_port.h""+#include ""src/core/lib/iomgr/cfstream_handle.h""+#include ""src/core/lib/iomgr/closure.h""+#include ""src/core/lib/iomgr/endpoint_cfstream.h""+#include ""src/core/lib/iomgr/error.h""+#include ""src/core/lib/iomgr/error_apple.h""+#include ""src/core/lib/iomgr/sockaddr_utils.h""+#include ""src/core/lib/iomgr/tcp_client.h""+#include ""src/core/lib/iomgr/timer.h""++extern grpc_core::TraceFlag grpc_tcp_trace;++typedef struct CFStreamConnect {+  gpr_mu mu;+  gpr_refcount refcount;++  CFReadStreamRef read_stream;+  CFWriteStreamRef write_stream;+  CFStreamHandle* stream_sync;++  grpc_timer alarm;+  grpc_closure on_alarm;+  grpc_closure on_open;++  bool read_stream_open;+  bool write_stream_open;+  bool failed;++  grpc_closure* closure;+  grpc_endpoint** endpoint;+  int refs;+  char* addr_name;+  grpc_resource_quota* resource_quota;+} CFStreamConnect;++static void CFStreamConnectCleanup(CFStreamConnect* connect) {+  grpc_resource_quota_unref_internal(connect->resource_quota);+  CFSTREAM_SYNC_UNREF(connect->stream_sync, ""async connect clean up"");+  CFRelease(connect->read_stream);+  CFRelease(connect->write_stream);+  gpr_mu_destroy(&connect->mu);+  gpr_free(connect->addr_name);+  gpr_free(connect);+}++static void OnAlarm(void* arg, grpc_error* error) {+  CFStreamConnect* connect = static_cast<CFStreamConnect*>(arg);+  if (grpc_tcp_trace.enabled()) {+    gpr_log(GPR_DEBUG, ""CLIENT_CONNECT :%p OnAlarm, error:%p"", connect, error);+  }+  gpr_mu_lock(&connect->mu);+  grpc_closure* closure = connect->closure;+  connect->closure = nil;+  const bool done = (--connect->refs == 0);+  gpr_mu_unlock(&connect->mu);+  // Only schedule a callback once, by either on_timer or on_connected. The+  // first one issues callback while the second one does cleanup.+  if (done) {+    CFStreamConnectCleanup(connect);+  } else {+    grpc_error* error =+        GRPC_ERROR_CREATE_FROM_STATIC_STRING(""connect() timed out"");+    GRPC_CLOSURE_SCHED(closure, error);+  }+}++static void OnOpen(void* arg, grpc_error* error) {+  CFStreamConnect* connect = static_cast<CFStreamConnect*>(arg);+  if (grpc_tcp_trace.enabled()) {+    gpr_log(GPR_DEBUG, ""CLIENT_CONNECT :%p OnOpen, error:%p"", connect, error);+  }+  gpr_mu_lock(&connect->mu);+  grpc_timer_cancel(&connect->alarm);+  grpc_closure* closure = connect->closure;+  connect->closure = nil;++  bool done = (--connect->refs == 0);+  grpc_endpoint** endpoint = connect->endpoint;++  if (done) {+    gpr_mu_unlock(&connect->mu);+    CFStreamConnectCleanup(connect);+  } else {+    if (error == GRPC_ERROR_NONE) {","The ""error"" argument here seems fully unused, but isn't it used in the shutdown case ? There's nothing really special to do during shutdown ? Not even CFStreamConnectCleanup ?",
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/15069,192181128,2018-05-31T17:44:02Z,src/core/lib/iomgr/tcp_client_cfstream.cc,"@@ -0,0 +1,212 @@++/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/support/port_platform.h>++#include ""src/core/lib/iomgr/port.h""++#ifdef GRPC_CFSTREAM_CLIENT++#include <CoreFoundation/CoreFoundation.h>++#include <string.h>++#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include <netinet/in.h>++#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/gpr/host_port.h""+#include ""src/core/lib/iomgr/cfstream_handle.h""+#include ""src/core/lib/iomgr/closure.h""+#include ""src/core/lib/iomgr/endpoint_cfstream.h""+#include ""src/core/lib/iomgr/error.h""+#include ""src/core/lib/iomgr/error_apple.h""+#include ""src/core/lib/iomgr/sockaddr_utils.h""+#include ""src/core/lib/iomgr/tcp_client.h""+#include ""src/core/lib/iomgr/timer.h""++extern grpc_core::TraceFlag grpc_tcp_trace;++typedef struct CFStreamConnect {+  gpr_mu mu;+  gpr_refcount refcount;++  CFReadStreamRef read_stream;+  CFWriteStreamRef write_stream;+  CFStreamHandle* stream_sync;++  grpc_timer alarm;+  grpc_closure on_alarm;+  grpc_closure on_open;++  bool read_stream_open;+  bool write_stream_open;+  bool failed;++  grpc_closure* closure;+  grpc_endpoint** endpoint;+  int refs;+  char* addr_name;+  grpc_resource_quota* resource_quota;+} CFStreamConnect;++static void CFStreamConnectCleanup(CFStreamConnect* connect) {+  grpc_resource_quota_unref_internal(connect->resource_quota);+  CFSTREAM_SYNC_UNREF(connect->stream_sync, ""async connect clean up"");+  CFRelease(connect->read_stream);+  CFRelease(connect->write_stream);+  gpr_mu_destroy(&connect->mu);+  gpr_free(connect->addr_name);+  gpr_free(connect);+}++static void OnAlarm(void* arg, grpc_error* error) {+  CFStreamConnect* connect = static_cast<CFStreamConnect*>(arg);+  if (grpc_tcp_trace.enabled()) {+    gpr_log(GPR_DEBUG, ""CLIENT_CONNECT :%p OnAlarm, error:%p"", connect, error);+  }+  gpr_mu_lock(&connect->mu);+  grpc_closure* closure = connect->closure;+  connect->closure = nil;+  const bool done = (--connect->refs == 0);+  gpr_mu_unlock(&connect->mu);+  // Only schedule a callback once, by either on_timer or on_connected. The+  // first one issues callback while the second one does cleanup.+  if (done) {+    CFStreamConnectCleanup(connect);+  } else {+    grpc_error* error =+        GRPC_ERROR_CREATE_FROM_STATIC_STRING(""connect() timed out"");+    GRPC_CLOSURE_SCHED(closure, error);+  }+}++static void OnOpen(void* arg, grpc_error* error) {+  CFStreamConnect* connect = static_cast<CFStreamConnect*>(arg);+  if (grpc_tcp_trace.enabled()) {+    gpr_log(GPR_DEBUG, ""CLIENT_CONNECT :%p OnOpen, error:%p"", connect, error);+  }+  gpr_mu_lock(&connect->mu);+  grpc_timer_cancel(&connect->alarm);+  grpc_closure* closure = connect->closure;+  connect->closure = nil;++  bool done = (--connect->refs == 0);+  grpc_endpoint** endpoint = connect->endpoint;++  if (done) {+    gpr_mu_unlock(&connect->mu);+    CFStreamConnectCleanup(connect);+  } else {+    if (error == GRPC_ERROR_NONE) {","Or in other words, wouldn't the condition above better read `if (done || error != GRPC_ERROR_NONE)` ?",
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/15069,192181508,2018-05-31T17:45:11Z,src/core/lib/transport/transport.cc,"@@ -184,7 +184,12 @@ void grpc_transport_set_pops(grpc_transport* transport, grpc_stream* stream,              nullptr) {     transport->vtable->set_pollset_set(transport, stream, pollset_set);   } else {+#ifdef GRPC_CFSTREAM",Same remark as before - I don't like to introduce #ifdefs in the middle of code like this.,
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/15554,192189717,2018-05-31T18:12:51Z,src/objective-c/GRPCClient/private/GRPCHost.m,"@@ -126,6 +126,13 @@ - (nullable grpc_call *)unmanagedCallWithPath:(NSString *)path                         completionQueue:queue]; } +- (NSData *)dataWithNsString:(NSString *)string {",Could you change the name to something like `nullTerminatedDataWithString:`? So that people would not think why we do not use `dataUsingEncoding`.,
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/15577,192220045,2018-05-31T20:02:55Z,third_party/nanopb/pb.h,"@@ -22,7 +22,7 @@ /* #define PB_MAX_REQUIRED_FIELDS 256 */  /* Add support for tag numbers > 255 and fields larger than 255 bytes. */-/* #define PB_FIELD_16BIT 1 */+#define PB_FIELD_16BIT 1","It seems `grpc_security_enclave` directly invokes `alts_frame_protector` target in gRPC release without rebuilding the gRPC source. The nanopb flag will be passed in only if gRPC source is re-built. We had the similar problem before in the sense that gRPC directly invokes the nanopb target in its third_party directory, and our strategy was to rebuild the nanopb source in gRPC BUILD file and pass in the flag. @apolcyn, Any idea? ",
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/15577,192248753,2018-05-31T21:52:15Z,third_party/nanopb/pb.h,"@@ -22,7 +22,7 @@ /* #define PB_MAX_REQUIRED_FIELDS 256 */  /* Add support for tag numbers > 255 and fields larger than 255 bytes. */-/* #define PB_FIELD_16BIT 1 */+#define PB_FIELD_16BIT 1","@dgquintas your statement is a bit wrong - these files are a code drop, and no longer a submodule import. We CAN change these files, and maybe we should?But more importantly, nanopb is a third party dependency. It shouldn't in fact be a direct dependent of gRPC like what we're currently doing, but rather be a workspace dependent, added in https://github.com/grpc/grpc/blob/master/bazel/grpc_deps.bzl as a [local_repository](https://docs.bazel.build/versions/master/be/workspace.html#local_repository), so that dependents like asylo can bring in their own version.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/15480,192248875,2018-05-31T21:52:40Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -2776,215 +2868,164 @@ static void apply_service_config_to_call_locked(grpc_call_element* elem) {   } } -// Starts a pick on chand->lb_policy.-// Returns true if pick is completed synchronously.-static bool pick_callback_start_locked(grpc_call_element* elem) {-  channel_data* chand = static_cast<channel_data*>(elem->channel_data);+// Invoked once resolver results are available.+static void process_service_config_and_start_lb_pick_locked(+    grpc_call_element* elem) {   call_data* calld = static_cast<call_data*>(elem->call_data);-  if (grpc_client_channel_trace.enabled()) {-    gpr_log(GPR_INFO, ""chand=%p calld=%p: starting pick on lb_policy=%p"", chand,-            calld, chand->lb_policy.get());-  }   // Only get service config data on the first attempt.   if (GPR_LIKELY(calld->num_attempts_completed == 0)) {     apply_service_config_to_call_locked(elem);   }-  // If the application explicitly set wait_for_ready, use that.-  // Otherwise, if the service config specified a value for this-  // method, use that.-  //-  // The send_initial_metadata batch will be the first one in the list,-  // as set by get_batch_index() above.-  calld->pick.initial_metadata =-      calld->seen_send_initial_metadata-          ? &calld->send_initial_metadata-          : calld->pending_batches[0]-                .batch->payload->send_initial_metadata.send_initial_metadata;-  uint32_t send_initial_metadata_flags =-      calld->seen_send_initial_metadata-          ? calld->send_initial_metadata_flags-          : calld->pending_batches[0]-                .batch->payload->send_initial_metadata-                .send_initial_metadata_flags;-  const bool wait_for_ready_set_from_api =-      send_initial_metadata_flags &-      GRPC_INITIAL_METADATA_WAIT_FOR_READY_EXPLICITLY_SET;-  const bool wait_for_ready_set_from_service_config =-      calld->method_params != nullptr &&-      calld->method_params->wait_for_ready() !=-          ClientChannelMethodParams::WAIT_FOR_READY_UNSET;-  if (GPR_UNLIKELY(!wait_for_ready_set_from_api &&-                   wait_for_ready_set_from_service_config)) {-    if (calld->method_params->wait_for_ready() ==-        ClientChannelMethodParams::WAIT_FOR_READY_TRUE) {-      send_initial_metadata_flags |= GRPC_INITIAL_METADATA_WAIT_FOR_READY;-    } else {-      send_initial_metadata_flags &= ~GRPC_INITIAL_METADATA_WAIT_FOR_READY;-    }-  }-  calld->pick.initial_metadata_flags = send_initial_metadata_flags;-  GRPC_CLOSURE_INIT(&calld->pick_closure, pick_callback_done_locked, elem,-                    grpc_combiner_scheduler(chand->combiner));-  calld->pick.on_complete = &calld->pick_closure;-  GRPC_CALL_STACK_REF(calld->owning_call, ""pick_callback"");-  const bool pick_done = chand->lb_policy->PickLocked(&calld->pick);-  if (GPR_LIKELY(pick_done)) {-    // Pick completed synchronously.-    if (grpc_client_channel_trace.enabled()) {-      gpr_log(GPR_INFO, ""chand=%p calld=%p: pick completed synchronously"",-              chand, calld);-    }-    GRPC_CALL_STACK_UNREF(calld->owning_call, ""pick_callback"");-  } else {-    GRPC_CALL_STACK_REF(calld->owning_call, ""pick_callback_cancel"");-    grpc_call_combiner_set_notify_on_cancel(-        calld->call_combiner,-        GRPC_CLOSURE_INIT(&calld->pick_cancel_closure,-                          pick_callback_cancel_locked, elem,-                          grpc_combiner_scheduler(chand->combiner)));-  }-  return pick_done;+  // Start LB pick.+  grpc_core::LbPicker::StartLocked(elem); } -typedef struct {-  grpc_call_element* elem;-  bool finished;-  grpc_closure closure;-  grpc_closure cancel_closure;-} pick_after_resolver_result_args;--// Note: This runs under the client_channel combiner, but will NOT be-// holding the call combiner.-static void pick_after_resolver_result_cancel_locked(void* arg,-                                                     grpc_error* error) {-  pick_after_resolver_result_args* args =-      static_cast<pick_after_resolver_result_args*>(arg);-  if (GPR_LIKELY(args->finished)) {-    gpr_free(args);-    return;-  }-  // If we don't yet have a resolver result, then a closure for-  // pick_after_resolver_result_done_locked() will have been added to-  // chand->waiting_for_resolver_result_closures, and it may not be invoked-  // until after this call has been destroyed.  We mark the operation as-  // finished, so that when pick_after_resolver_result_done_locked()-  // is called, it will be a no-op.  We also immediately invoke-  // async_pick_done_locked() to propagate the error back to the caller.-  args->finished = true;-  grpc_call_element* elem = args->elem;-  channel_data* chand = static_cast<channel_data*>(elem->channel_data);-  call_data* calld = static_cast<call_data*>(elem->call_data);-  if (grpc_client_channel_trace.enabled()) {-    gpr_log(GPR_INFO,-            ""chand=%p calld=%p: cancelling pick waiting for resolver result"",-            chand, calld);-  }-  // Note: Although we are not in the call combiner here, we are-  // basically stealing the call combiner from the pending pick, so-  // it's safe to call async_pick_done_locked() here -- we are-  // essentially calling it here instead of calling it in-  // pick_after_resolver_result_done_locked().-  async_pick_done_locked(elem, GRPC_ERROR_CREATE_REFERENCING_FROM_STATIC_STRING(-                                   ""Pick cancelled"", &error, 1));-}--static void pick_after_resolver_result_done_locked(void* arg,-                                                   grpc_error* error) {-  pick_after_resolver_result_args* args =-      static_cast<pick_after_resolver_result_args*>(arg);-  if (GPR_UNLIKELY(args->finished)) {-    /* cancelled, do nothing */-    if (grpc_client_channel_trace.enabled()) {-      gpr_log(GPR_INFO, ""call cancelled before resolver result"");-    }-    gpr_free(args);-    return;-  }-  args->finished = true;-  grpc_call_element* elem = args->elem;-  channel_data* chand = static_cast<channel_data*>(elem->channel_data);-  call_data* calld = static_cast<call_data*>(elem->call_data);-  if (GPR_UNLIKELY(error != GRPC_ERROR_NONE)) {+namespace grpc_core {++// Handles waiting for a resolver result.+// Used only for the first call on an idle channel.+class ResolverResultWaiter {+ public:+  explicit ResolverResultWaiter(grpc_call_element* elem) : elem_(elem) {+    channel_data* chand = static_cast<channel_data*>(elem->channel_data);+    call_data* calld = static_cast<call_data*>(elem->call_data);     if (grpc_client_channel_trace.enabled()) {-      gpr_log(GPR_INFO, ""chand=%p calld=%p: resolver failed to return data"",+      gpr_log(GPR_INFO,+              ""chand=%p calld=%p: deferring pick pending resolver result"",               chand, calld);     }-    async_pick_done_locked(elem, GRPC_ERROR_REF(error));-  } else if (GPR_UNLIKELY(chand->resolver == nullptr)) {-    // Shutting down.-    if (grpc_client_channel_trace.enabled()) {-      gpr_log(GPR_INFO, ""chand=%p calld=%p: resolver disconnected"", chand,-              calld);+    // Add closure to be run when a resolver result is available.+    GRPC_CLOSURE_INIT(&closure_, &ResolverResultWaiter::DoneLocked, this,","I suggest renaming `closure_` to something more specific. For example, `done_closure_`, also given that the associated function is called `DoneLocked`.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/15577,192250952,2018-05-31T22:02:38Z,third_party/nanopb/pb.h,"@@ -22,7 +22,7 @@ /* #define PB_MAX_REQUIRED_FIELDS 256 */  /* Add support for tag numbers > 255 and fields larger than 255 bytes. */-/* #define PB_FIELD_16BIT 1 */+#define PB_FIELD_16BIT 1","@nicolasnoble ah, yes, I'm living in the past. That being said, when a long time ago we first explored options, I remember there being _reasons_ for not modifying those files. If I'm misremembering or those reasons don't apply any longer, modifying them would indeed be the easiest option. Another consideration is the need to maintain them in sync with the internal version, which comes from the internal third party version, not our own. Regarding your second point, doing that may solve all concerns, including the internal one I just mentioned. Let me try to make that change on an independent PR.",
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/15577,192251258,2018-05-31T22:04:16Z,third_party/nanopb/pb.h,"@@ -22,7 +22,7 @@ /* #define PB_MAX_REQUIRED_FIELDS 256 */  /* Add support for tag numbers > 255 and fields larger than 255 bytes. */-/* #define PB_FIELD_16BIT 1 */+#define PB_FIELD_16BIT 1","Yes to that last part, which is why I'm saying it'd make more sense to decouple the library with a local_repository import so that others might swap it with their own.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/15539,192458158,2018-06-01T17:06:35Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -1775,92 +1776,60 @@ static void recv_message_ready(void* arg, grpc_error* error) {     }     return;   }-  // Received a valid message, so commit the call.-  retry_commit(elem, retry_state);-  // Manually invoking a callback function; it does not take ownership of error.-  invoke_recv_message_callback(batch_data, error);-  GRPC_ERROR_UNREF(error);-}--//-// list of closures to execute in call combiner-//--// Represents a closure that needs to run in the call combiner as part of-// starting or completing a batch.-typedef struct {-  grpc_closure* closure;-  grpc_error* error;-  const char* reason;-  bool free_reason = false;-} closure_to_execute;--static void execute_closures_in_call_combiner(grpc_call_element* elem,-                                              const char* caller,-                                              closure_to_execute* closures,-                                              size_t num_closures) {-  channel_data* chand = static_cast<channel_data*>(elem->channel_data);-  call_data* calld = static_cast<call_data*>(elem->call_data);-  // Note that the call combiner will be yielded for each closure that-  // we schedule.  We're already running in the call combiner, so one of-  // the closures can be scheduled directly, but the others will-  // have to re-enter the call combiner.-  if (num_closures > 0) {-    if (grpc_client_channel_trace.enabled()) {-      gpr_log(GPR_INFO, ""chand=%p calld=%p: %s starting closure: %s"", chand,-              calld, caller, closures[0].reason);-    }-    GRPC_CLOSURE_SCHED(closures[0].closure, closures[0].error);-    if (closures[0].free_reason) {-      gpr_free(const_cast<char*>(closures[0].reason));-    }-    for (size_t i = 1; i < num_closures; ++i) {-      if (grpc_client_channel_trace.enabled()) {-        gpr_log(GPR_INFO,-                ""chand=%p calld=%p: %s starting closure in call combiner: %s"",-                chand, calld, caller, closures[i].reason);-      }-      GRPC_CALL_COMBINER_START(calld->call_combiner, closures[i].closure,-                               closures[i].error, closures[i].reason);-      if (closures[i].free_reason) {-        gpr_free(const_cast<char*>(closures[i].reason));-      }-    }+  // If a retry was already dispatched, that means we saw+  // recv_trailing_metadata before this, so we do nothing here.","s/recv_trailing_metadata/recv_message, right?also, flip the comment logic order, as in the last comment",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/15539,192490065,2018-06-01T19:11:24Z,src/core/ext/filters/deadline/deadline_filter.cc,"@@ -128,21 +128,25 @@ static void cancel_timer_if_needed(grpc_deadline_state* deadline_state) {   } } -// Callback run when the call is complete.-static void on_complete(void* arg, grpc_error* error) {+// Callback run when we receive trailing metadata.+static void recv_trailing_metadata_ready(void* arg, grpc_error* error) {   grpc_deadline_state* deadline_state = static_cast<grpc_deadline_state*>(arg);   cancel_timer_if_needed(deadline_state);-  // Invoke the next callback.-  GRPC_CLOSURE_RUN(deadline_state->next_on_complete, GRPC_ERROR_REF(error));+  // Invoke the original callback.+  GRPC_CLOSURE_RUN(deadline_state->original_recv_trailing_metadata_ready,+                   GRPC_ERROR_REF(error)); } -// Inject our own on_complete callback into op.-static void inject_on_complete_cb(grpc_deadline_state* deadline_state,-                                  grpc_transport_stream_op_batch* op) {-  deadline_state->next_on_complete = op->on_complete;-  GRPC_CLOSURE_INIT(&deadline_state->on_complete, on_complete, deadline_state,+// Inject our own recv_trailing_metadata_ready callback into op.+static void inject_recv_trailing_metadata_ready(+    grpc_deadline_state* deadline_state, grpc_transport_stream_op_batch* op) {+  deadline_state->original_recv_trailing_metadata_ready =+      op->payload->recv_trailing_metadata.recv_trailing_metadata_ready;","Question for my own understanding: why is the recv_trailing_metadata_ready closure inside of the payload, instead of being a field of grpc_transport_stream_op_batch, like with on_complete?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15539,192513237,2018-06-01T20:55:48Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -1598,6 +1557,59 @@ static void batch_data_unref(subchannel_batch_data* batch_data) {   } } +//+// list of closures to execute in call combiner+//++// Represents a closure that needs to run in the call combiner as part of+// starting or completing a batch.+typedef struct {+  grpc_closure* closure;+  grpc_error* error;+  const char* reason;+  bool free_reason = false;+} closure_to_execute;++static void execute_closures_in_call_combiner(grpc_call_element* elem,+                                              const char* caller,+                                              closure_to_execute* closures,+                                              size_t num_closures) {+  channel_data* chand = static_cast<channel_data*>(elem->channel_data);+  call_data* calld = static_cast<call_data*>(elem->call_data);+  // Note that the call combiner will be yielded for each closure that+  // we schedule.  We're already running in the call combiner, so one of+  // the closures can be scheduled directly, but the others will+  // have to re-enter the call combiner.+  if (num_closures > 0) {+    if (grpc_client_channel_trace.enabled()) {+      gpr_log(GPR_INFO, ""chand=%p calld=%p: %s starting closure: %s"", chand,+              calld, caller, closures[0].reason);+    }+    GRPC_CLOSURE_SCHED(closures[0].closure, closures[0].error);+    if (closures[0].free_reason) {+      gpr_free(const_cast<char*>(closures[0].reason));+    }+    for (size_t i = 1; i < num_closures; ++i) {+      if (grpc_client_channel_trace.enabled()) {+        gpr_log(GPR_INFO,+                ""chand=%p calld=%p: %s starting closure in call combiner: %s"",","This wasn't actually a new problem in this PR -- this was pre-existing code that just got moved up from further below.But in any case, I've refactored the code for running a list of closures in a call combiner, so I think this duplication has gone away.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15539,192515922,2018-06-01T21:07:27Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -1775,92 +1776,60 @@ static void recv_message_ready(void* arg, grpc_error* error) {     }     return;   }-  // Received a valid message, so commit the call.-  retry_commit(elem, retry_state);-  // Manually invoking a callback function; it does not take ownership of error.-  invoke_recv_message_callback(batch_data, error);-  GRPC_ERROR_UNREF(error);-}--//-// list of closures to execute in call combiner-//--// Represents a closure that needs to run in the call combiner as part of-// starting or completing a batch.-typedef struct {-  grpc_closure* closure;-  grpc_error* error;-  const char* reason;-  bool free_reason = false;-} closure_to_execute;--static void execute_closures_in_call_combiner(grpc_call_element* elem,-                                              const char* caller,-                                              closure_to_execute* closures,-                                              size_t num_closures) {-  channel_data* chand = static_cast<channel_data*>(elem->channel_data);-  call_data* calld = static_cast<call_data*>(elem->call_data);-  // Note that the call combiner will be yielded for each closure that-  // we schedule.  We're already running in the call combiner, so one of-  // the closures can be scheduled directly, but the others will-  // have to re-enter the call combiner.-  if (num_closures > 0) {-    if (grpc_client_channel_trace.enabled()) {-      gpr_log(GPR_INFO, ""chand=%p calld=%p: %s starting closure: %s"", chand,-              calld, caller, closures[0].reason);-    }-    GRPC_CLOSURE_SCHED(closures[0].closure, closures[0].error);-    if (closures[0].free_reason) {-      gpr_free(const_cast<char*>(closures[0].reason));-    }-    for (size_t i = 1; i < num_closures; ++i) {-      if (grpc_client_channel_trace.enabled()) {-        gpr_log(GPR_INFO,-                ""chand=%p calld=%p: %s starting closure in call combiner: %s"",-                chand, calld, caller, closures[i].reason);-      }-      GRPC_CALL_COMBINER_START(calld->call_combiner, closures[i].closure,-                               closures[i].error, closures[i].reason);-      if (closures[i].free_reason) {-        gpr_free(const_cast<char*>(closures[i].reason));-      }-    }+  // If a retry was already dispatched, that means we saw+  // recv_trailing_metadata before this, so we do nothing here.","This actually did mean recv_trailing_metadata -- the question here is whether the call has already been completed, which happens when recv_trailing_metadata returns.That having been said, your comment did make me realize that we actually need to check for this earlier in the function, so I've changed the logic and clarified the comment, both here and for recv_initial_metadata above.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15539,192516366,2018-06-01T21:09:44Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -1897,6 +1866,175 @@ static void add_closures_for_deferred_recv_callbacks(   } } +// Returns true if any op in the batch was not yet started.+// Only looks at send ops, since recv ops are always started immediately.+static bool pending_batch_is_unstarted(+    pending_batch* pending, call_data* calld,+    subchannel_call_retry_state* retry_state) {+  if (pending->batch == nullptr || pending->batch->on_complete == nullptr) {+    return false;+  }+  if (pending->batch->send_initial_metadata &&+      !retry_state->started_send_initial_metadata) {+    return true;+  }+  if (pending->batch->send_message &&+      retry_state->started_send_message_count < calld->send_messages->size()) {+    return true;+  }+  if (pending->batch->send_trailing_metadata &&+      !retry_state->started_send_trailing_metadata) {+    return true;+  }+  return false;+}++// For any pending batch containing an op that has not yet been started,+// adds the pending batch's completion closures to closures, updating+// *num_closures as needed.+static void add_closures_to_fail_unstarted_pending_batches(+    grpc_call_element* elem, subchannel_call_retry_state* retry_state,+    grpc_error* error, closure_to_execute* closures, size_t* num_closures) {+  channel_data* chand = static_cast<channel_data*>(elem->channel_data);+  call_data* calld = static_cast<call_data*>(elem->call_data);+  for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+    pending_batch* pending = &calld->pending_batches[i];+    if (pending_batch_is_unstarted(pending, calld, retry_state)) {+      if (grpc_client_channel_trace.enabled()) {+        gpr_log(GPR_INFO,+                ""chand=%p calld=%p: failing unstarted pending batch at index ""+                ""%"" PRIuPTR,+                chand, calld, i);+      }+      closure_to_execute* closure = &closures[(*num_closures)++];+      closure->closure = pending->batch->on_complete;+      closure->error = GRPC_ERROR_REF(error);+      closure->reason = ""failing on_complete for pending batch"";+      pending->batch->on_complete = nullptr;+      maybe_clear_pending_batch(elem, pending);+    }+  }+  GRPC_ERROR_UNREF(error);+}++// Intercepts recv_trailing_metadata_ready callback for retries.+// Commits the call and returns the trailing metadata up the stack.+static void recv_trailing_metadata_ready(void* arg, grpc_error* error) {+  subchannel_batch_data* batch_data = static_cast<subchannel_batch_data*>(arg);+  grpc_call_element* elem = batch_data->elem;+  channel_data* chand = static_cast<channel_data*>(elem->channel_data);+  call_data* calld = static_cast<call_data*>(elem->call_data);+  if (grpc_client_channel_trace.enabled()) {+    gpr_log(GPR_INFO,+            ""chand=%p calld=%p: got recv_trailing_metadata_ready, error=%s"",+            chand, calld, grpc_error_string(error));+  }+  subchannel_call_retry_state* retry_state =+      static_cast<subchannel_call_retry_state*>(+          grpc_connected_subchannel_call_get_parent_data(+              batch_data->subchannel_call));+  retry_state->completed_recv_trailing_metadata = true;+  // Get the call's status and check for server pushback metadata.+  grpc_status_code status = GRPC_STATUS_OK;+  grpc_mdelem* server_pushback_md = nullptr;+  if (error != GRPC_ERROR_NONE) {  // Case (a).+    grpc_error_get_status(error, calld->deadline, &status, nullptr, nullptr,+                          nullptr);+  } else {+    grpc_metadata_batch* md_batch =+        batch_data->batch.payload->recv_trailing_metadata+            .recv_trailing_metadata;+    GPR_ASSERT(md_batch->idx.named.grpc_status != nullptr);+    status =+        grpc_get_status_code_from_metadata(md_batch->idx.named.grpc_status->md);+    if (md_batch->idx.named.grpc_retry_pushback_ms != nullptr) {+      server_pushback_md = &md_batch->idx.named.grpc_retry_pushback_ms->md;+    }+  }+  if (grpc_client_channel_trace.enabled()) {+    gpr_log(GPR_INFO, ""chand=%p calld=%p: call finished, status=%s"", chand,+            calld, grpc_status_code_to_string(status));+  }+  // Check if we should retry.+  if (maybe_retry(elem, batch_data, status, server_pushback_md)) {+    // Unref batch_data for deferred recv_initial_metadata_ready or+    // recv_message_ready callbacks, if any.+    if (retry_state->recv_initial_metadata_ready_deferred_batch != nullptr) {+      batch_data_unref(batch_data);+      GRPC_ERROR_UNREF(retry_state->recv_initial_metadata_error);+    }+    if (retry_state->recv_message_ready_deferred_batch != nullptr) {+      batch_data_unref(batch_data);+      GRPC_ERROR_UNREF(retry_state->recv_message_error);+    }+    batch_data_unref(batch_data);+    return;+  }+  // Not retrying, so commit the call.+  retry_commit(elem, retry_state);+  // Construct list of closures to execute.+  // The set of possible closures we can schedule here is:+  // - the recv_trailing_metadata callback+  // - recv_initial_metadata_ready (either deferred or unstarted)+  // - recv_message_ready (either deferred or unstarted)+  // - on_complete for any unstarted batches+  closure_to_execute closures[GPR_ARRAY_SIZE(calld->pending_batches) + 3];","The comment above lists 4 bullets.  The first 3 bullets are one callback each, and the last one is a max of 6.That having been said, I think this logic was wrong; the max number here is actually just 6, because any callback covered by the first 3 bullets will not be present in the last bullet.In any case, this issue has gone away with the refactoring of the code for running a list of closures in a call combiner.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15539,192516612,2018-06-01T21:11:04Z,src/core/lib/transport/transport.cc,"@@ -211,21 +212,44 @@ void grpc_transport_stream_op_batch_finish_with_failure(   if (batch->send_message) {     batch->payload->send_message.send_message.reset();   }-  if (batch->recv_message) {-    GRPC_CALL_COMBINER_START(-        call_combiner, batch->payload->recv_message.recv_message_ready,-        GRPC_ERROR_REF(error), ""failing recv_message_ready"");+  if (batch->cancel_stream) {+    GRPC_ERROR_UNREF(batch->payload->cancel_stream.cancel_error);   }+  // Construct a list of closures to execute.+  struct ClosureToExecute {",I was thinking the same thing.  I've refactored this into a helper class.,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/15594,192683730,2018-06-04T09:48:44Z,src/php/tests/unit_tests/CallCredentials2Test.php,"@@ -35,6 +35,7 @@ public function setUp()         $this->channel = new Grpc\Channel(             'localhost:'.$this->port,             [+            'force_new' => true,",what exactly is the semantics of the force_new  argument? I'm not sure other languages have that concept.,
28968539,ZhouyihaiDing,https://api.github.com/repos/grpc/grpc/pulls/15594,192800854,2018-06-04T16:20:41Z,src/php/tests/unit_tests/CallCredentials2Test.php,"@@ -35,6 +35,7 @@ public function setUp()         $this->channel = new Grpc\Channel(             'localhost:'.$this->port,             [+            'force_new' => true,","Oh `0.0.0.0:0` to `0.0.0.0:53000` doesn't guarantee. I was trying to make every test use different port but I give up. I changed other places back but missed this one. But it doesn't influence the fix.In PHP, there is a map for `target => grpc_channel`. When creating a client channel, if the target is in the map, it will reuse the existing channel. The design is to make gRPC channel can be reuse across PHP scripts because PHP applications are short-lived.The `TIMEOUT` issue is caused by this channel reuse. PHP test framework `phpunit` is running all tests inside one process, which cause that one test can reuse the channel created by other tests and the client channel is waiting for a response never come.`force_new` forces the client to create a grpc channel and not persisting it in the map. So that each test use it's own grpc connection.I still can't reproduce `FAILED` even run 20000 times. My guess is that test use preserved port which cause the failure in certain system and conditions. But the `TIMEOUT` failure which happens easily can't be reproduced anymore.",
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/15092,192840602,2018-06-04T18:38:07Z,src/core/lib/iomgr/ev_epoll1_linux.cc,"@@ -307,7 +309,9 @@ static grpc_fd* fd_create(int fd, const char* name) {    struct epoll_event ev;   ev.events = static_cast<uint32_t>(EPOLLIN | EPOLLOUT | EPOLLET);-  ev.data.ptr = new_fd;+  /* Use the least significant bit of ev.data.ptr to store track_err. */","Also, I am wondering, how is this helpful ? (i.e storing it as a bit on data.ptr).. wouldn't accessing 'track_err' bool sufficient ? ",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/15539,192896648,2018-06-04T22:16:19Z,src/core/lib/iomgr/call_combiner.h,"@@ -109,4 +110,79 @@ void grpc_call_combiner_set_notify_on_cancel(grpc_call_combiner* call_combiner, void grpc_call_combiner_cancel(grpc_call_combiner* call_combiner,                                grpc_error* error); +namespace grpc_core {++// Helper for running a list of closures in a call combiner.+//+// Each callback running in the call combiner will eventually be","Would it be possible in a future optimization to ""know"" that the closures all need to be run under this call combiner, and then run them sequentially without having to go through the pattern of; surface yields combiner, then next closure reenters?that would eliminate the overhead of the combiner re-aquisition",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/15539,192897088,2018-06-04T22:18:27Z,src/core/lib/iomgr/call_combiner.h,"@@ -109,4 +110,79 @@ void grpc_call_combiner_set_notify_on_cancel(grpc_call_combiner* call_combiner, void grpc_call_combiner_cancel(grpc_call_combiner* call_combiner,                                grpc_error* error); +namespace grpc_core {++// Helper for running a list of closures in a call combiner.+//+// Each callback running in the call combiner will eventually be+// returned to the surface, at which point the surface will yield the+// call combiner.  So when we are running in the call combiner and have+// more than one callback to return to the surface, we need to re-enter+// the call combiner for all but one of those callbacks.+class CallCombinerClosureList {+ public:+  CallCombinerClosureList() {}++  // Adds a closure to the list.  The closure must eventually result in+  // the call combiner being yielded.+  void Add(grpc_closure* closure, grpc_error* error, const char* reason) {+    closures_.emplace_back(closure, error, reason);+  }++  // Runs all closures in the call combiner.+  //+  // If yield_call_combiner is true, then the call combiner will be yielded.+  // In this case, all but one of the closures will be scheduled via+  // CALL_COMBINER_START(), and the remaining closure will be scheduled+  // directly via GRPC_CLOSURE_SCHED(), which will eventually result in+  // yielding the call combiner.  If the list is empty, then the call+  // combiner will be yielded immediately.+  //+  // If yield_call_combiner is false, then the call combiner will not be+  // yielded.  All callbacks will be scheduled via GRPC_CALL_COMBINER_START().+  void RunClosures(grpc_call_combiner* call_combiner,","Style nit; can you split this into two public APIs? `RunClosures ` and then `RunClosuresAndYieldCallCombiner` (or something similar).Then you wouldn't have to worry about calling this like```closures.RunClosures(calld->call_combiner, true /* yield_call_combiner */);```",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/15092,193165524,2018-06-05T17:56:19Z,src/core/lib/iomgr/ev_epoll1_linux.cc,"@@ -307,7 +309,9 @@ static grpc_fd* fd_create(int fd, const char* name) {    struct epoll_event ev;   ev.events = static_cast<uint32_t>(EPOLLIN | EPOLLOUT | EPOLLET);-  ev.data.ptr = new_fd;+  /* Use the least significant bit of ev.data.ptr to store track_err. */",Accessing track_err would be a data race which is why we need to store them inside data.ptr,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15630,193190600,2018-06-05T19:19:50Z,test/cpp/microbenchmarks/bm_call_create.cc,"@@ -609,6 +617,125 @@ typedef Fixture<&grpc_server_load_reporting_filter, CHECKS_NOT_LAST> BENCHMARK_TEMPLATE(BM_IsolatedFilter, LoadReportingFilter, NoOp); BENCHMARK_TEMPLATE(BM_IsolatedFilter, LoadReportingFilter, SendEmptyMetadata); +// Test a filter's start_transport_stream_op_batch in isolation. Fixture +// specifies the filter under test (use the Fixture<> template to specify this).+template <class Fixture>+static void BM_StartTransportStreamOpBatch(benchmark::State& state) {+  TrackCounters track_counters;+  Fixture fixture;+  std::ostringstream label;++  std::vector<grpc_arg> args;+  FakeClientChannelFactory fake_client_channel_factory;+  args.push_back(grpc_client_channel_factory_create_channel_arg(+      &fake_client_channel_factory));+  args.push_back(StringArg(GRPC_ARG_SERVER_URI, ""localhost""));++  grpc_channel_args channel_args = {args.size(), &args[0]};++  std::vector<const grpc_channel_filter*> filters;+  if (fixture.filter != nullptr) {+    filters.push_back(fixture.filter);+  }++  if (fixture.flags & CHECKS_NOT_LAST) {+    // Some filters assert they are not the last in the stack, so we add a +    // dummy filter after them so they won't complain+    filters.push_back(&dummy_filter::dummy_filter);+    label << "" #has_dummy_filter"";+  } ++  grpc_core::ExecCtx exec_ctx;+  size_t channel_size = grpc_channel_stack_size(+      filters.size() == 0 ? nullptr : &filters[0], filters.size());","You can use `filters.data()` here, which will work even if it's empty.  (Although I'm not sure why we'd want to run this test in the first place if it is empty.)",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15630,193194198,2018-06-05T19:32:40Z,test/cpp/microbenchmarks/bm_call_create.cc,"@@ -609,6 +617,125 @@ typedef Fixture<&grpc_server_load_reporting_filter, CHECKS_NOT_LAST> BENCHMARK_TEMPLATE(BM_IsolatedFilter, LoadReportingFilter, NoOp); BENCHMARK_TEMPLATE(BM_IsolatedFilter, LoadReportingFilter, SendEmptyMetadata); +// Test a filter's start_transport_stream_op_batch in isolation. Fixture +// specifies the filter under test (use the Fixture<> template to specify this).+template <class Fixture>+static void BM_StartTransportStreamOpBatch(benchmark::State& state) {",It looks like this duplicates a lot of code from the existing `BM_IsolatedFilter` benchmark.  Consider refactoring to avoid duplication.Note that this issue may just go away if we switch to the approach of directly calling the filter's methods instead of constructing an entire call stack.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15630,193195170,2018-06-05T19:35:52Z,test/cpp/microbenchmarks/bm_call_create.cc,"@@ -609,6 +617,125 @@ typedef Fixture<&grpc_server_load_reporting_filter, CHECKS_NOT_LAST> BENCHMARK_TEMPLATE(BM_IsolatedFilter, LoadReportingFilter, NoOp); BENCHMARK_TEMPLATE(BM_IsolatedFilter, LoadReportingFilter, SendEmptyMetadata); +// Test a filter's start_transport_stream_op_batch in isolation. Fixture +// specifies the filter under test (use the Fixture<> template to specify this).+template <class Fixture>+static void BM_StartTransportStreamOpBatch(benchmark::State& state) {+  TrackCounters track_counters;+  Fixture fixture;+  std::ostringstream label;++  std::vector<grpc_arg> args;+  FakeClientChannelFactory fake_client_channel_factory;+  args.push_back(grpc_client_channel_factory_create_channel_arg(+      &fake_client_channel_factory));+  args.push_back(StringArg(GRPC_ARG_SERVER_URI, ""localhost""));++  grpc_channel_args channel_args = {args.size(), &args[0]};++  std::vector<const grpc_channel_filter*> filters;+  if (fixture.filter != nullptr) {+    filters.push_back(fixture.filter);+  }++  if (fixture.flags & CHECKS_NOT_LAST) {+    // Some filters assert they are not the last in the stack, so we add a +    // dummy filter after them so they won't complain+    filters.push_back(&dummy_filter::dummy_filter);+    label << "" #has_dummy_filter"";+  } ++  grpc_core::ExecCtx exec_ctx;+  size_t channel_size = grpc_channel_stack_size(+      filters.size() == 0 ? nullptr : &filters[0], filters.size());+  grpc_channel_stack* channel_stack =+      static_cast<grpc_channel_stack*>(gpr_zalloc(channel_size));+  GPR_ASSERT(GRPC_LOG_IF_ERROR(+      ""channel_stack_init"",+      grpc_channel_stack_init(1, FilterDestroy, channel_stack, &filters[0],+                              filters.size(), &channel_args,+                              fixture.flags & REQUIRES_TRANSPORT+                                  ? &dummy_transport::dummy_transport+                                  : nullptr,+                              ""CHANNEL"", channel_stack)));+  grpc_core::ExecCtx::Get()->Flush();+  grpc_call_stack* call_stack =+      static_cast<grpc_call_stack*>(gpr_zalloc(channel_stack->call_stack_size));+  grpc_millis deadline = GRPC_MILLIS_INF_FUTURE;+  gpr_timespec start_time = gpr_now(GPR_CLOCK_MONOTONIC);+  grpc_slice method = grpc_slice_from_static_string(""/foo/bar"");+  grpc_call_final_info final_info;+  grpc_call_element_args call_args;+  call_args.call_stack = call_stack;+  call_args.server_transport_data = nullptr;+  call_args.context = nullptr;+  call_args.path = method;+  call_args.start_time = start_time;+  call_args.deadline = deadline;+  const int kArenaSize = 4096;+  call_args.arena = gpr_arena_create(kArenaSize);+  GRPC_ERROR_UNREF(+        grpc_call_stack_init(channel_stack, 1, DoNothing, nullptr, &call_args));+  +  while (state.KeepRunning()) {+    GPR_TIMER_SCOPE(""BenchmarkCycle"", 0);+    /* Create new payload */+    grpc_transport_stream_op_batch_payload payload = {};+    grpc_metadata_batch metadata_batch = {};+    grpc_metadata_batch_init(&metadata_batch);+    payload.send_initial_metadata.send_initial_metadata = &metadata_batch;+    payload.send_initial_metadata.send_initial_metadata_flags = 0;+    // TODO(hcaseyal): set payload send_initial_metadata peer_string?+    payload.send_trailing_metadata.send_trailing_metadata = &metadata_batch;","Each of {send,recv}_{initial,trailing}_metadata should point to its own metadata_batch object.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15630,193195602,2018-06-05T19:37:24Z,test/cpp/microbenchmarks/bm_call_create.cc,"@@ -609,6 +617,125 @@ typedef Fixture<&grpc_server_load_reporting_filter, CHECKS_NOT_LAST> BENCHMARK_TEMPLATE(BM_IsolatedFilter, LoadReportingFilter, NoOp); BENCHMARK_TEMPLATE(BM_IsolatedFilter, LoadReportingFilter, SendEmptyMetadata); +// Test a filter's start_transport_stream_op_batch in isolation. Fixture +// specifies the filter under test (use the Fixture<> template to specify this).+template <class Fixture>+static void BM_StartTransportStreamOpBatch(benchmark::State& state) {+  TrackCounters track_counters;+  Fixture fixture;+  std::ostringstream label;++  std::vector<grpc_arg> args;+  FakeClientChannelFactory fake_client_channel_factory;+  args.push_back(grpc_client_channel_factory_create_channel_arg(+      &fake_client_channel_factory));+  args.push_back(StringArg(GRPC_ARG_SERVER_URI, ""localhost""));++  grpc_channel_args channel_args = {args.size(), &args[0]};++  std::vector<const grpc_channel_filter*> filters;+  if (fixture.filter != nullptr) {+    filters.push_back(fixture.filter);+  }++  if (fixture.flags & CHECKS_NOT_LAST) {+    // Some filters assert they are not the last in the stack, so we add a +    // dummy filter after them so they won't complain+    filters.push_back(&dummy_filter::dummy_filter);+    label << "" #has_dummy_filter"";+  } ++  grpc_core::ExecCtx exec_ctx;+  size_t channel_size = grpc_channel_stack_size(+      filters.size() == 0 ? nullptr : &filters[0], filters.size());+  grpc_channel_stack* channel_stack =+      static_cast<grpc_channel_stack*>(gpr_zalloc(channel_size));+  GPR_ASSERT(GRPC_LOG_IF_ERROR(+      ""channel_stack_init"",+      grpc_channel_stack_init(1, FilterDestroy, channel_stack, &filters[0],+                              filters.size(), &channel_args,+                              fixture.flags & REQUIRES_TRANSPORT+                                  ? &dummy_transport::dummy_transport+                                  : nullptr,+                              ""CHANNEL"", channel_stack)));+  grpc_core::ExecCtx::Get()->Flush();+  grpc_call_stack* call_stack =+      static_cast<grpc_call_stack*>(gpr_zalloc(channel_stack->call_stack_size));+  grpc_millis deadline = GRPC_MILLIS_INF_FUTURE;+  gpr_timespec start_time = gpr_now(GPR_CLOCK_MONOTONIC);+  grpc_slice method = grpc_slice_from_static_string(""/foo/bar"");+  grpc_call_final_info final_info;+  grpc_call_element_args call_args;+  call_args.call_stack = call_stack;+  call_args.server_transport_data = nullptr;+  call_args.context = nullptr;+  call_args.path = method;+  call_args.start_time = start_time;+  call_args.deadline = deadline;+  const int kArenaSize = 4096;+  call_args.arena = gpr_arena_create(kArenaSize);+  GRPC_ERROR_UNREF(+        grpc_call_stack_init(channel_stack, 1, DoNothing, nullptr, &call_args));+  +  while (state.KeepRunning()) {+    GPR_TIMER_SCOPE(""BenchmarkCycle"", 0);+    /* Create new payload */+    grpc_transport_stream_op_batch_payload payload = {};+    grpc_metadata_batch metadata_batch = {};+    grpc_metadata_batch_init(&metadata_batch);+    payload.send_initial_metadata.send_initial_metadata = &metadata_batch;+    payload.send_initial_metadata.send_initial_metadata_flags = 0;+    // TODO(hcaseyal): set payload send_initial_metadata peer_string?+    payload.send_trailing_metadata.send_trailing_metadata = &metadata_batch;+    payload.recv_initial_metadata.recv_initial_metadata = &metadata_batch;+    payload.recv_initial_metadata.recv_initial_metadata_ready = nullptr;+    // TODO(hcaseyal): set recv_initial_metadata peer_string?",The peer_string is set in send_initial_metadata on the client side and in recv_initial_metadata on the server side.  We only need to do one of the two here.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15630,193196011,2018-06-05T19:38:55Z,test/cpp/microbenchmarks/bm_call_create.cc,"@@ -609,6 +617,125 @@ typedef Fixture<&grpc_server_load_reporting_filter, CHECKS_NOT_LAST> BENCHMARK_TEMPLATE(BM_IsolatedFilter, LoadReportingFilter, NoOp); BENCHMARK_TEMPLATE(BM_IsolatedFilter, LoadReportingFilter, SendEmptyMetadata); +// Test a filter's start_transport_stream_op_batch in isolation. Fixture +// specifies the filter under test (use the Fixture<> template to specify this).+template <class Fixture>+static void BM_StartTransportStreamOpBatch(benchmark::State& state) {+  TrackCounters track_counters;+  Fixture fixture;+  std::ostringstream label;++  std::vector<grpc_arg> args;+  FakeClientChannelFactory fake_client_channel_factory;+  args.push_back(grpc_client_channel_factory_create_channel_arg(+      &fake_client_channel_factory));+  args.push_back(StringArg(GRPC_ARG_SERVER_URI, ""localhost""));++  grpc_channel_args channel_args = {args.size(), &args[0]};++  std::vector<const grpc_channel_filter*> filters;+  if (fixture.filter != nullptr) {+    filters.push_back(fixture.filter);+  }++  if (fixture.flags & CHECKS_NOT_LAST) {+    // Some filters assert they are not the last in the stack, so we add a +    // dummy filter after them so they won't complain+    filters.push_back(&dummy_filter::dummy_filter);+    label << "" #has_dummy_filter"";+  } ++  grpc_core::ExecCtx exec_ctx;+  size_t channel_size = grpc_channel_stack_size(+      filters.size() == 0 ? nullptr : &filters[0], filters.size());+  grpc_channel_stack* channel_stack =+      static_cast<grpc_channel_stack*>(gpr_zalloc(channel_size));+  GPR_ASSERT(GRPC_LOG_IF_ERROR(+      ""channel_stack_init"",+      grpc_channel_stack_init(1, FilterDestroy, channel_stack, &filters[0],+                              filters.size(), &channel_args,+                              fixture.flags & REQUIRES_TRANSPORT+                                  ? &dummy_transport::dummy_transport+                                  : nullptr,+                              ""CHANNEL"", channel_stack)));+  grpc_core::ExecCtx::Get()->Flush();+  grpc_call_stack* call_stack =+      static_cast<grpc_call_stack*>(gpr_zalloc(channel_stack->call_stack_size));+  grpc_millis deadline = GRPC_MILLIS_INF_FUTURE;+  gpr_timespec start_time = gpr_now(GPR_CLOCK_MONOTONIC);+  grpc_slice method = grpc_slice_from_static_string(""/foo/bar"");+  grpc_call_final_info final_info;+  grpc_call_element_args call_args;+  call_args.call_stack = call_stack;+  call_args.server_transport_data = nullptr;+  call_args.context = nullptr;+  call_args.path = method;+  call_args.start_time = start_time;+  call_args.deadline = deadline;+  const int kArenaSize = 4096;+  call_args.arena = gpr_arena_create(kArenaSize);+  GRPC_ERROR_UNREF(+        grpc_call_stack_init(channel_stack, 1, DoNothing, nullptr, &call_args));+  +  while (state.KeepRunning()) {+    GPR_TIMER_SCOPE(""BenchmarkCycle"", 0);+    /* Create new payload */+    grpc_transport_stream_op_batch_payload payload = {};+    grpc_metadata_batch metadata_batch = {};+    grpc_metadata_batch_init(&metadata_batch);+    payload.send_initial_metadata.send_initial_metadata = &metadata_batch;+    payload.send_initial_metadata.send_initial_metadata_flags = 0;+    // TODO(hcaseyal): set payload send_initial_metadata peer_string?+    payload.send_trailing_metadata.send_trailing_metadata = &metadata_batch;+    payload.recv_initial_metadata.recv_initial_metadata = &metadata_batch;+    payload.recv_initial_metadata.recv_initial_metadata_ready = nullptr;+    // TODO(hcaseyal): set recv_initial_metadata peer_string?+    payload.recv_message.recv_message = nullptr;+    payload.recv_message.recv_message_ready = nullptr;+    payload.recv_trailing_metadata.recv_trailing_metadata = nullptr;","If the batch includes recv_trailing_metadata, this needs to be non-null.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15630,193197299,2018-06-05T19:43:11Z,test/cpp/microbenchmarks/bm_call_create.cc,"@@ -609,6 +617,125 @@ typedef Fixture<&grpc_server_load_reporting_filter, CHECKS_NOT_LAST> BENCHMARK_TEMPLATE(BM_IsolatedFilter, LoadReportingFilter, NoOp); BENCHMARK_TEMPLATE(BM_IsolatedFilter, LoadReportingFilter, SendEmptyMetadata); +// Test a filter's start_transport_stream_op_batch in isolation. Fixture +// specifies the filter under test (use the Fixture<> template to specify this).+template <class Fixture>+static void BM_StartTransportStreamOpBatch(benchmark::State& state) {+  TrackCounters track_counters;+  Fixture fixture;+  std::ostringstream label;++  std::vector<grpc_arg> args;+  FakeClientChannelFactory fake_client_channel_factory;+  args.push_back(grpc_client_channel_factory_create_channel_arg(+      &fake_client_channel_factory));+  args.push_back(StringArg(GRPC_ARG_SERVER_URI, ""localhost""));++  grpc_channel_args channel_args = {args.size(), &args[0]};++  std::vector<const grpc_channel_filter*> filters;+  if (fixture.filter != nullptr) {+    filters.push_back(fixture.filter);+  }++  if (fixture.flags & CHECKS_NOT_LAST) {+    // Some filters assert they are not the last in the stack, so we add a +    // dummy filter after them so they won't complain+    filters.push_back(&dummy_filter::dummy_filter);+    label << "" #has_dummy_filter"";+  } ++  grpc_core::ExecCtx exec_ctx;+  size_t channel_size = grpc_channel_stack_size(+      filters.size() == 0 ? nullptr : &filters[0], filters.size());+  grpc_channel_stack* channel_stack =+      static_cast<grpc_channel_stack*>(gpr_zalloc(channel_size));+  GPR_ASSERT(GRPC_LOG_IF_ERROR(+      ""channel_stack_init"",+      grpc_channel_stack_init(1, FilterDestroy, channel_stack, &filters[0],+                              filters.size(), &channel_args,+                              fixture.flags & REQUIRES_TRANSPORT+                                  ? &dummy_transport::dummy_transport+                                  : nullptr,+                              ""CHANNEL"", channel_stack)));+  grpc_core::ExecCtx::Get()->Flush();+  grpc_call_stack* call_stack =+      static_cast<grpc_call_stack*>(gpr_zalloc(channel_stack->call_stack_size));+  grpc_millis deadline = GRPC_MILLIS_INF_FUTURE;+  gpr_timespec start_time = gpr_now(GPR_CLOCK_MONOTONIC);+  grpc_slice method = grpc_slice_from_static_string(""/foo/bar"");+  grpc_call_final_info final_info;+  grpc_call_element_args call_args;+  call_args.call_stack = call_stack;+  call_args.server_transport_data = nullptr;+  call_args.context = nullptr;+  call_args.path = method;+  call_args.start_time = start_time;+  call_args.deadline = deadline;+  const int kArenaSize = 4096;+  call_args.arena = gpr_arena_create(kArenaSize);+  GRPC_ERROR_UNREF(+        grpc_call_stack_init(channel_stack, 1, DoNothing, nullptr, &call_args));","If the batch we're testing with contains all 6 ops, then we need to construct a new call stack each time through the loop.  This is because it's not valid to send more than one of any of the {send,recv}_{initial,trailing}_metadata ops on a single call.  It's also not valid to have more than one of send_message or recv_message in flight on a single call at the same time.",
5616899,ganmacs,https://api.github.com/repos/grpc/grpc/pulls/15654,193309796,2018-06-06T07:01:04Z,src/ruby/ext/grpc/extconf.rb,"@@ -69,6 +69,10 @@  unless windows   puts 'Building internal gRPC into ' + grpc_lib_dir++  system('git submodule update --init')","> Otherwise, note you can build packages locally, and from master, by running rake gem:native from the github repo root.It would work… but I think it's not a good way to use gem.IMO, I think that it is better for grpc-ruby gem to build from any branches and commits. Because we have to wait for new features for a long time (one or two weeks), It is not good for developers  and users of grpc-ruby gem.>  I think this adds to much of a burden to rake compileWhen submodule are already updated, I think `git submodule update` doesn't fetch any more data. In any case, we need to `git submodule udpate` to build grpc-ruby, I think it's not a cost. Would you tell me what a cost is.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/15654,193522929,2018-06-06T18:56:51Z,src/ruby/ext/grpc/extconf.rb,"@@ -69,6 +69,10 @@  unless windows   puts 'Building internal gRPC into ' + grpc_lib_dir++  system('git submodule update --init')","When doing a `gem install grpc --platform ruby`, I don't think we want to do a `git submodule update --init` call while building.I'd argue that specifying a commit hash when depending on grpc from master is what we want anyways though - master is not necessarily stable, so depending on a certain commit hash can provide what's needed without the risk of picking up a bad commit.",
8228229,kkm000,https://api.github.com/repos/grpc/grpc/pulls/13207,193586913,2018-06-06T23:14:49Z,src/csharp/Grpc.Tools/Common.cs,"@@ -0,0 +1,105 @@+#region Copyright notice and license++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.IO;+using System.Runtime.CompilerServices;+using System.Runtime.InteropServices;+using System.Security;++[assembly: InternalsVisibleTo(""Grpc.Tools.Tests"")]++namespace Grpc.Tools {+  // Metadata names that we refer to often.+  static class Metadata {+    // On output dependency lists.+    public static string kSource = ""Source"";+    // On ProtoBuf items.+    public static string kProtoRoot = ""ProtoRoot"";+    public static string kOutputDir = ""OutputDir"";+    public static string kGrpcServices = ""GrpcServices"";+    public static string kGrpcOutputDir = ""GrpcOutputDir"";+  };++  // A few flags used to control the behavior under various platforms.+  internal static class Platform {+    public enum OsKind { Unknown, Windows, Linux, MacOsX };+    public static readonly OsKind Os;++    public enum CpuKind { Unknown, X86, X64 };+    public static readonly CpuKind Cpu;++    // This is not necessarily true, but good enough. BCL lacks a per-FS+    // API to determine file case sensitivity.+    public static bool IsFsCaseInsensitive => Os == OsKind.Windows;+    public static bool IsWindows => Os == OsKind.Windows;++    static Platform() {","Dependencies in MSBuild assemblies just do not work. Microsoft's own implementation includes a set of common files into each assembly.>  perhaps we could just include the source file in Grpc.ToolsNot without refactoring it significantly, because```#if NETSTANDARD1_5```and the MSBuild library is using the 1.3 API,``` [DllImport(""libc"")] static extern int uname(IntPtr buf);```Maybe safe from inside MSBuild, but I'd better not open this can of worms in this iteration. The Tools library needs only a very small subset of the PlatformApis.cs (strictly speaking, the only distinction in this library is made is between Windows and everything else).",
8228229,kkm000,https://api.github.com/repos/grpc/grpc/pulls/13207,193588058,2018-06-06T23:21:26Z,src/csharp/Grpc.Tools/DepFileUtil.cs,"@@ -0,0 +1,198 @@+#region Copyright notice and license++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Generic;+using System.IO;+using System.Text;+using Microsoft.Build.Framework;+using Microsoft.Build.Utilities;++namespace Grpc.Tools {+  internal static class DepFileUtil {+/*+   Sample dependency files. Notable features we have to deal with:+    * Slash doubling, must normalize them.+    * Spaces in file names. Cannot just ""unwrap"" the line on backslash at eof;+      rather, treat every line as containing one file name except for one with+      the ':' separator, as containing exactly two.+    * Deal with ':' also being drive letter separator (second example).++obj\Release\net45\/Foo.cs \+obj\Release\net45\/FooGrpc.cs: C:/foo/include/google/protobuf/wrappers.proto\+ C:/projects/foo/src//foo.proto++C:\projects\foo\src\./foo.grpc.pb.cc \+C:\projects\foo\src\./foo.grpc.pb.h \+C:\projects\foo\src\./foo.pb.cc \+C:\projects\foo\src\./foo.pb.h: C:/foo/include/google/protobuf/wrappers.proto\+ C:/foo/include/google/protobuf/any.proto\+ C:/foo/include/google/protobuf/source_context.proto\+ C:/foo/include/google/protobuf/type.proto\+ foo.proto+*/++    // Read file names from the dependency file to the right of ':'.+    public static string[] ReadDependencyInputs(string protoDepDir, string proto,+                                                TaskLoggingHelper log) {+      string depFilename = GetDepFilenameForProto(protoDepDir, proto);+      string[] lines = ReadDepFileLines(depFilename, false, log);+      if (lines.Length == 0) {+        return lines;+      }++      var result = new List<string>();+      bool skip = true;+      foreach (string line in lines) {+        // Start at the only line separating dependency outputs from inputs.+        int ix = skip ? FindLineSeparator(line) : -1;+        skip = skip && ix < 0;+        if (skip) continue;+        string file = ExtractFilenameFromLine(line, ix + 1, line.Length);+        if (file == """") {+          log.LogMessage(MessageImportance.Low,+    $""Skipping unparsable dependency file {depFilename}.\nLine with error: '{line}'"");+          return new string[0];+        }++        // Do not bend over backwards trying not to include a proto into its+        // own list of dependencies. Since a file is not older than self,+        // it is safe to add; this is purely a memory optimization.+        if (file != proto) {+          result.Add(file);+        }+      }+      return result.ToArray();+    }++    // Read file names from the dependency file to the left of ':'.+    public static string[] ReadDependencyOutputs(string depFilename,+                                                TaskLoggingHelper log) {+      string[] lines = ReadDepFileLines(depFilename, true, log);+      if (lines.Length == 0) {+        return lines;+      }++      var result = new List<string>();+      foreach (string line in lines) {+        int ix = FindLineSeparator(line);+        string file = ExtractFilenameFromLine(line, 0, ix >= 0 ? ix : line.Length);+        if (file == """") {+          log.LogError(""Unable to parse generated dependency file {0}.\n"" ++                       ""Line with error: '{1}'"", depFilename, line);+          return new string[0];+        }+        result.Add(file);++        // If this is the line with the separator, do not read further.+        if (ix >= 0)+          break;+      }+      return result.ToArray();+    }++    // Get complete dependency file name from directory hash and file name,+    // tucked onto protoDepDir, e. g.+    // (""out"", ""foo/file.proto"") => ""out/deadbeef12345678_file.protodep"".+    // This way, the filenames are unique but still possible to make sense of.+    public static string GetDepFilenameForProto(string protoDepDir, string proto) {","The pathname is limited to 256 characters. C# project and solution names are often on the longish side. Naturally I could recreate the directory tree structure of proto files under the cache directory in `obj/`, but doing that could lead to interesting consequences for some users. I've been there. Your call, but to me hashes seem safer overall. Not that I did that for the love of hashing. :)",
8228229,kkm000,https://api.github.com/repos/grpc/grpc/pulls/13207,193588396,2018-06-06T23:23:28Z,src/csharp/Grpc.Tools/GeneratorServices.cs,"@@ -0,0 +1,168 @@+#region Copyright notice and license++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.IO;+using System.Text;+using Microsoft.Build.Framework;+using Microsoft.Build.Utilities;++namespace Grpc.Tools {+  // Abstract class for language-specific analysis behavior, such+  // as guessing the generated files the same way protoc does.+  internal abstract class GeneratorServices {",This is where the protoc behavior of naming and placing generated files is mirrored. To handle dependency checking we need to know where the generated files are expected to be. Can you think of a better name?,
8228229,kkm000,https://api.github.com/repos/grpc/grpc/pulls/13207,193588742,2018-06-06T23:25:24Z,src/csharp/Grpc.Tools/Grpc.Tools.csproj,"@@ -0,0 +1,95 @@+<Project Sdk=""Microsoft.NET.Sdk"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"">++  <Import Project=""..\Grpc.Core\Version.csproj.include"" />++  <PropertyGroup>+    <AssemblyName>Protobuf.MSBuild</AssemblyName>+    <Version>$(GrpcCsharpVersion)</Version>+    <!-- If changing targets, change also paths in Google.Protobuf.Tools.targets. -->+    <TargetFrameworks>netstandard1.3;net40</TargetFrameworks>+  </PropertyGroup>++  <PropertyGroup Label=""Asset root folders. TODO(kkm): Change with package separation."">+    <!-- TODO(kkm): Rework whole section when splitting packages.  -->+    <!-- GRPC: ../../third_party/protobuf/src/google/protobuf/  -->+    <!-- GPB:  ../src/google/protobuf/ -->+    <Assets_ProtoInclude>../../../third_party/protobuf/src/google/protobuf/</Assets_ProtoInclude>++    <!-- GPB:  protoc\ -->+    <!-- GRPC: protoc_plugins\protoc_ -->+    <Assets_ProtoCompiler>../protoc_plugins/protoc_</Assets_ProtoCompiler>++    <!-- GRPC: protoc_plugins\ -->+    <Assets_GrpcPlugins>../protoc_plugins/</Assets_GrpcPlugins>+  </PropertyGroup>++  <PropertyGroup>+    <_NetStandard>False</_NetStandard>+    <_NetStandard Condition="" $(TargetFramework.StartsWith('netstandard')) or $(TargetFramework.StartsWith('netcore')) "">True</_NetStandard>++    <!-- So we do not hardcode an exact version into #if's. -->+    <DefineConstants Condition=""$(_NetStandard)"">$(DefineConstants);NETSTANDARD</DefineConstants>+  </PropertyGroup>++  <PropertyGroup Label=""NuGet package definition"" Condition="" '$(Configuration)' == 'Release' "">+    <GeneratePackageOnBuild>true</GeneratePackageOnBuild>+    <PackageOutputPath>../../../artifacts</PackageOutputPath>++    <!-- TODO(kkm): Change to ""build\"" after splitting. -->+    <BuildOutputTargetFolder>build\_protobuf\</BuildOutputTargetFolder>+    <DevelopmentDependency>true</DevelopmentDependency>+    <NoPackageAnalysis>true</NoPackageAnalysis>+    <PackageId>Grpc.Tools</PackageId>+    <Description>gRPC and Protocol Buffer compiler for managed C# and native C++ projects.++Add this package to a project that contains .proto files to be compiled to code.+It contains the compilers, include files and project system integration for gRPC+and Protocol buffer service description files necessary to build them on Windows,+Linux and MacOS. Managed runtime is supplied separately in the Grpc.Core package.</Description>+    <Copyright>Copyright 2018 gRPC authors</Copyright>+    <Authors>gRPC authors</Authors>+    <PackageLicenseUrl>https://github.com/grpc/grpc/blob/master/LICENSE</PackageLicenseUrl>+    <PackageProjectUrl>https://github.com/grpc/grpc</PackageProjectUrl>+    <PackageTags>gRPC RPC protocol HTTP/2</PackageTags>+  </PropertyGroup>++  <ItemGroup Label=""NuGet package assets"">+    <None Pack=""true"" PackagePath=""build\"" Include=""build\**\*.xml; build\**\*.props; build\**\*.targets;"" />++    <!-- Protobuf assets (for Google.Protobuf.Tools) -->+    <_ProtoTemp Include=""any.proto;api.proto;descriptor.proto;duration.proto;"" />",Just a temporary variable name. It is a collection that is transformed a few lines below by adding the path to it. How should I call it?,
8228229,kkm000,https://api.github.com/repos/grpc/grpc/pulls/13207,193591636,2018-06-06T23:43:44Z,src/csharp/Grpc.nuspec,"@@ -3,18 +3,17 @@   <metadata>     <id>Grpc</id>     <title>gRPC C#</title>-    <summary>C# implementation of gRPC - an RPC library and framework</summary>     <description>C# implementation of gRPC - an RPC library and framework. See project site for more info.</description>     <version>$version$</version>-    <authors>Google Inc.</authors>-    <owners>grpc-packages</owners>+    <authors>gRPC authors</authors>+    <owners>gRPC authors</owners>     <licenseUrl>https://github.com/grpc/grpc/blob/master/LICENSE</licenseUrl>     <projectUrl>https://github.com/grpc/grpc</projectUrl>     <requireLicenseAcceptance>false</requireLicenseAcceptance>-    <releaseNotes>Release $version$ of gRPC C#</releaseNotes>-    <copyright>Copyright 2015, Google Inc.</copyright>+    <copyright>Copyright 2018, gRPC authors.</copyright>     <tags>gRPC RPC Protocol HTTP/2</tags>     <dependencies>+      <dependency id=""Google.Protobuf"" version=""[3.5, 3.6)"" />","Well, I do not really know what would be a good range. In the early days of the alpha and beta releases, the protobuf version had to strictly match grpc version, as the generator APIs were changing. The nice side of limiting the range is we do not run into the problem if protobuf generator API or behavior changes. The ugly side if e. g. the user has their own generator that depends on a specific surface version. To me, the former looks more common than the latter, so I'd rather tighten the range reasonably. Just `version=""3.5` means ""version 3.5 or any later future version,"" which can be problematic if the user of the package upgrades protobuf version too far without also upgrading gRPC.3.6 would be a reasonable number as long as protobuf follows semver. You might be able to provide a more reasonable guess for the upper range than I, from your experience with the gRPC/protobuf mutual dynamics, and user bug reports. ",
8228229,kkm000,https://api.github.com/repos/grpc/grpc/pulls/13207,193592591,2018-06-06T23:50:21Z,src/csharp/Grpc.Tools/Grpc.Tools.csproj,"@@ -0,0 +1,95 @@+<Project Sdk=""Microsoft.NET.Sdk"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"">++  <Import Project=""..\Grpc.Core\Version.csproj.include"" />","`Common.csproj` enforces strong naming. If it's possible to avoid dealing with the SN in the context of MSBuild, I would. ~~The test assembly can be strong-named, that's not a problem (although I am not really aware of any reason to SN an executable).~~ Silly me, I take that back. Obviously, the test cannot reference a SN assembly cleanly.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/15654,193615221,2018-06-07T03:09:32Z,src/ruby/ext/grpc/extconf.rb,"@@ -69,6 +69,10 @@  unless windows   puts 'Building internal gRPC into ' + grpc_lib_dir++  system('git submodule update --init')","@ganmacs I took a look at what bundler currently provides, since I was thinking that this really sounded like a short coming of bundler's `git` dependency system. However, from the [bundler docks](https://bundler.io/v1.12/git.html), it looks like bundler does in fact allow one to expand submodules in their dependency declaration!I think what this PR is trying to accomplish can instead be fixed with:```gem 'grpc', :git => 'git://github.com/grpc/grpc.git', :submodules => true```in your gemspec",
13115060,rongjiecomputer,https://api.github.com/repos/grpc/grpc/pulls/15624,193956971,2018-06-08T05:40:22Z,third_party/cares/cares.BUILD,"@@ -138,10 +144,23 @@ cc_library(     copts = [         ""-D_GNU_SOURCE"",         ""-D_HAS_EXCEPTIONS=0"",-        ""-DNOMINMAX"",         ""-DHAVE_CONFIG_H"",-    ],+    ] + select({+        "":windows"": [+            ""-DNOMINMAX"",+            ""-DWIN32_LEAN_AND_MEAN"",","> what's the effect of this?I think they will cancel out each other.C-Ares add `-DWIN32_LEAN_AND_MEAN` in [`CMakeLists.txt#L169`](https://github.com/c-ares/c-ares/blob/3be1924221e1326df520f8498d704a5c4c8d0cce/CMakeLists.txt#L169), but then undef it unconditionally in [`ares_config.h.cmake#L419`](https://github.com/c-ares/c-ares/blob/3be1924221e1326df520f8498d704a5c4c8d0cce/ares_config.h.cmake#L419).`ares_config.h` is only included in `ares_setup.h`. After including `ares_config.h`, `ares_setup.h` defines `WIN32_LEAN_AND_MEAN` once again at [`ares_setup.h#L109`](https://github.com/c-ares/c-ares/blob/a5b2e99207fd12d1e9d0413f4a6cdc8d0d9bdda3/ares_setup.h#L109). (No, I have no idea why C-Ares is doing this macro dance).I think it is best we just follow what `CMakeLists.txt` does and don't think too much.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/15682,194061295,2018-06-08T13:43:26Z,.pylintrc,"@@ -75,3 +75,9 @@ disable= 	# NOTE(nathaniel): I have disputed the premise of this inspection from 	# the beginning and will continue to do so until it goes away for good. 	useless-else-on-loop,+	# NOTE(mmx): Our existing code is written to favor explicit else over","This sounds rather arbitrary; let's put it on a more solid footing:```NOTE(nathaniel): A single statement that always returns programcontrol is better than two statements the first of which sometimesreturns program control and the second of which always returnsprogram control. Probably generally, but definitely in the cases ofif:/else: and for:/else:.```. Note that this statement also covers the immediately-above suppression of `useless-else-on-loop`; the previous `NOTE` on `useless-else-on-loop` could go away were this `NOTE` attached to both suppressions.",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/15682,194088953,2018-06-08T15:09:08Z,src/python/grpcio/grpc/_server.py,"@@ -329,6 +329,7 @@ def _look_for_request(self):             request = self._state.request             self._state.request = None             return request+        raise Exception('gRPC Error: Invalid _state')","The inspection is if you are returning a value from at least one code path within a function (i.e. there exists at least one `return <expression>` statement), all code paths should be statically verifiable to return a value (analogous to ""all code paths should return a value in a non-`void` function"" analysis in Java/C#) .  I think this is a valuable verification actually, and we shouldn't turn it off, as otherwise you would be silently returning `None` in a ""non-void"" function.  I believe an explicit exception is better suited to ensure we never visit unanticipated branches.  However, I acknowledge that I'm not sure what's the best exception type to raise. (or perhaps `assert False` instead?)",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/15682,194090345,2018-06-08T15:13:32Z,src/python/grpcio_testing/grpc_testing/__init__.py,"@@ -14,9 +14,9 @@ """"""Objects for use in testing gRPC Python-using application code.""""""  import abc+import six","It complained about `six` being after `from google.protobuf...`. I suspect ""common library"" imports should appear earlier than other local ones, perhaps? This was the only warning of this category so I just fixed it without reading too much into it.",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/15682,194113564,2018-06-08T16:33:06Z,src/python/grpcio/grpc/_server.py,"@@ -329,6 +329,7 @@ def _look_for_request(self):             request = self._state.request             self._state.request = None             return request+        raise Exception('gRPC Error: Invalid _state')",Turned into `raise AssertionError()` instead. `pylint` it too dumb to recognize `assert` statements as a termination condition of the subroutine.,
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/15539,194137318,2018-06-08T18:00:59Z,src/core/lib/iomgr/call_combiner.h,"@@ -109,4 +110,83 @@ void grpc_call_combiner_set_notify_on_cancel(grpc_call_combiner* call_combiner, void grpc_call_combiner_cancel(grpc_call_combiner* call_combiner,                                grpc_error* error); +namespace grpc_core {++// Helper for running a list of closures in a call combiner.+//+// Each callback running in the call combiner will eventually be+// returned to the surface, at which point the surface will yield the+// call combiner.  So when we are running in the call combiner and have+// more than one callback to return to the surface, we need to re-enter+// the call combiner for all but one of those callbacks.+class CallCombinerClosureList {+ public:+  CallCombinerClosureList() {}++  // Adds a closure to the list.  The closure must eventually result in+  // the call combiner being yielded.+  void Add(grpc_closure* closure, grpc_error* error, const char* reason) {+    closures_.emplace_back(closure, error, reason);+  }++  // Runs all closures in the call combiner and yields the call combiner.+  //+  // All but one of the closures in the list will be scheduled via+  // GRPC_CALL_COMBINER_START(), and the remaining closure will be+  // scheduled via GRPC_CLOSURE_SCHED(), which will eventually result in+  // yielding the call combiner.  If the list is empty, then the call+  // combiner will be yielded immediately.+  void RunClosures(grpc_call_combiner* call_combiner) {+    for (size_t i = 1; i < closures_.size(); ++i) {+      auto& closure = closures_[i];+      GRPC_CALL_COMBINER_START(call_combiner, closure.closure, closure.error,+                               closure.reason);+    }+    if (closures_.size() > 0) {+      if (grpc_call_combiner_trace.enabled()) {+        gpr_log(GPR_INFO,+                ""CallCombinerClosureList executing closure while already ""+                ""holding call_combiner %p: closure=%p error=%s reason=%s"",+                call_combiner, closures_[0].closure,+                grpc_error_string(closures_[0].error), closures_[0].reason);+      }+      // This will release the call combiner.+      GRPC_CLOSURE_SCHED(closures_[0].closure, closures_[0].error);","When you say ""this"", do you mean that the first closure in this list releases the call combiner? Could you expand the comment to explain this more clearly?",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/15539,194147927,2018-06-08T18:40:22Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -1293,7 +1275,10 @@ static void maybe_clear_pending_batch(grpc_call_element* elem,        batch->payload->recv_initial_metadata.recv_initial_metadata_ready ==            nullptr) &&       (!batch->recv_message ||-       batch->payload->recv_message.recv_message_ready == nullptr)) {+       batch->payload->recv_message.recv_message_ready == nullptr) &&","Since this if statement is on the long side and needs a comment to explain it, how about refactoring it into a method, with a name that clearly describes it? are_all_batch_callbacks_scheduled_and_reset, or something like that. This is motivated by readability and to mitigate the problem of comments going stale. We could make it an inline method for performance. Please fix. ",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/15689,194179943,2018-06-08T20:59:02Z,src/python/grpcio/grpc/_server.py,"@@ -817,3 +827,10 @@ def stop(self, grace):      def __del__(self):         _stop(self._state, None)+++def create_server(thread_pool, generic_rpc_handlers, interceptors, options,",Suggestion: the arguments to this function are numerous and hard to remember. How about naming all of them?,
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/15539,194244917,2018-06-10T04:34:20Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -1751,10 +1680,18 @@ static void recv_message_ready(void* arg, grpc_error* error) {       static_cast<subchannel_call_retry_state*>(           grpc_connected_subchannel_call_get_parent_data(               batch_data->subchannel_call));+  ++retry_state->completed_recv_message_count;+  // If a retry was already dispatched, then we're not going to use the+  // result of this recv_message op, so do nothing.+  if (retry_state->retry_dispatched) {",This statement and comment look like a near-duplicate of line 1597. I think this is indicative that the code needs a refactor. We should consider this in a later PR.,
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/15539,194245762,2018-06-10T05:20:57Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -1777,133 +1714,241 @@ static void recv_message_ready(void* arg, grpc_error* error) {   }   // Received a valid message, so commit the call.   retry_commit(elem, retry_state);+  // Invoke the callback to return the result to the surface.   // Manually invoking a callback function; it does not take ownership of error.   invoke_recv_message_callback(batch_data, error);-  GRPC_ERROR_UNREF(error); }  //-// list of closures to execute in call combiner-//--// Represents a closure that needs to run in the call combiner as part of-// starting or completing a batch.-typedef struct {-  grpc_closure* closure;-  grpc_error* error;-  const char* reason;-  bool free_reason = false;-} closure_to_execute;--static void execute_closures_in_call_combiner(grpc_call_element* elem,-                                              const char* caller,-                                              closure_to_execute* closures,-                                              size_t num_closures) {-  channel_data* chand = static_cast<channel_data*>(elem->channel_data);-  call_data* calld = static_cast<call_data*>(elem->call_data);-  // Note that the call combiner will be yielded for each closure that-  // we schedule.  We're already running in the call combiner, so one of-  // the closures can be scheduled directly, but the others will-  // have to re-enter the call combiner.-  if (num_closures > 0) {-    if (grpc_client_channel_trace.enabled()) {-      gpr_log(GPR_INFO, ""chand=%p calld=%p: %s starting closure: %s"", chand,-              calld, caller, closures[0].reason);-    }-    GRPC_CLOSURE_SCHED(closures[0].closure, closures[0].error);-    if (closures[0].free_reason) {-      gpr_free(const_cast<char*>(closures[0].reason));-    }-    for (size_t i = 1; i < num_closures; ++i) {-      if (grpc_client_channel_trace.enabled()) {-        gpr_log(GPR_INFO,-                ""chand=%p calld=%p: %s starting closure in call combiner: %s"",-                chand, calld, caller, closures[i].reason);-      }-      GRPC_CALL_COMBINER_START(calld->call_combiner, closures[i].closure,-                               closures[i].error, closures[i].reason);-      if (closures[i].free_reason) {-        gpr_free(const_cast<char*>(closures[i].reason));-      }-    }-  } else {-    if (grpc_client_channel_trace.enabled()) {-      gpr_log(GPR_INFO, ""chand=%p calld=%p: no closures to run for %s"", chand,-              calld, caller);-    }-    GRPC_CALL_COMBINER_STOP(calld->call_combiner, ""no closures to run"");-  }-}--//-// on_complete callback handling+// recv_trailing_metadata handling // -// Updates retry_state to reflect the ops completed in batch_data.-static void update_retry_state_for_completed_batch(-    subchannel_batch_data* batch_data,-    subchannel_call_retry_state* retry_state) {-  if (batch_data->batch.send_initial_metadata) {-    retry_state->completed_send_initial_metadata = true;-  }-  if (batch_data->batch.send_message) {-    ++retry_state->completed_send_message_count;-  }-  if (batch_data->batch.send_trailing_metadata) {-    retry_state->completed_send_trailing_metadata = true;-  }-  if (batch_data->batch.recv_initial_metadata) {-    retry_state->completed_recv_initial_metadata = true;-  }-  if (batch_data->batch.recv_message) {-    ++retry_state->completed_recv_message_count;-  }-  if (batch_data->batch.recv_trailing_metadata) {-    retry_state->completed_recv_trailing_metadata = true;+// Adds recv_trailing_metadata_ready closure to closures.+static void add_closure_for_recv_trailing_metadata_ready(+    grpc_call_element* elem, subchannel_batch_data* batch_data,+    grpc_error* error, grpc_core::CallCombinerClosureList* closures) {+  // Find pending batch.+  pending_batch* pending = pending_batch_find(+      elem, ""invoking recv_trailing_metadata for"",+      [](grpc_transport_stream_op_batch* batch) {+        return batch->recv_trailing_metadata &&+               batch->payload->recv_trailing_metadata+                       .recv_trailing_metadata_ready != nullptr;+      });+  // If we generated the recv_trailing_metadata op internally via+  // start_internal_recv_trailing_metadata(), then there will be no+  // pending batch.+  if (pending == nullptr) {+    GRPC_ERROR_UNREF(error);+    return;   }+  // Return metadata.+  grpc_metadata_batch_move(+      &batch_data->recv_trailing_metadata,+      pending->batch->payload->recv_trailing_metadata.recv_trailing_metadata);+  // Add closure.+  closures->Add(pending->batch->payload->recv_trailing_metadata+                    .recv_trailing_metadata_ready,+                error, ""recv_trailing_metadata_ready for pending batch"");+  // Update bookkeeping.+  pending->batch->payload->recv_trailing_metadata.recv_trailing_metadata_ready =+      nullptr;+  maybe_clear_pending_batch(elem, pending); }  // Adds any necessary closures for deferred recv_initial_metadata and-// recv_message callbacks to closures, updating *num_closures as needed.+// recv_message callbacks to closures. static void add_closures_for_deferred_recv_callbacks(     subchannel_batch_data* batch_data, subchannel_call_retry_state* retry_state,-    closure_to_execute* closures, size_t* num_closures) {+    grpc_core::CallCombinerClosureList* closures) {   if (batch_data->batch.recv_trailing_metadata) {     // Add closure for deferred recv_initial_metadata_ready.     if (GPR_UNLIKELY(retry_state->recv_initial_metadata_ready_deferred_batch !=                      nullptr)) {-      closure_to_execute* closure = &closures[(*num_closures)++];-      closure->closure = GRPC_CLOSURE_INIT(-          &batch_data->recv_initial_metadata_ready,-          invoke_recv_initial_metadata_callback,-          retry_state->recv_initial_metadata_ready_deferred_batch,-          grpc_schedule_on_exec_ctx);-      closure->error = retry_state->recv_initial_metadata_error;-      closure->reason = ""resuming recv_initial_metadata_ready"";+      GRPC_CLOSURE_INIT(&batch_data->recv_initial_metadata_ready,+                        invoke_recv_initial_metadata_callback,+                        retry_state->recv_initial_metadata_ready_deferred_batch,+                        grpc_schedule_on_exec_ctx);+      closures->Add(&batch_data->recv_initial_metadata_ready,+                    retry_state->recv_initial_metadata_error,+                    ""resuming recv_initial_metadata_ready"");       retry_state->recv_initial_metadata_ready_deferred_batch = nullptr;     }     // Add closure for deferred recv_message_ready.     if (GPR_UNLIKELY(retry_state->recv_message_ready_deferred_batch !=                      nullptr)) {-      closure_to_execute* closure = &closures[(*num_closures)++];-      closure->closure = GRPC_CLOSURE_INIT(-          &batch_data->recv_message_ready, invoke_recv_message_callback,-          retry_state->recv_message_ready_deferred_batch,-          grpc_schedule_on_exec_ctx);-      closure->error = retry_state->recv_message_error;-      closure->reason = ""resuming recv_message_ready"";+      GRPC_CLOSURE_INIT(&batch_data->recv_message_ready,+                        invoke_recv_message_callback,+                        retry_state->recv_message_ready_deferred_batch,+                        grpc_schedule_on_exec_ctx);+      closures->Add(&batch_data->recv_message_ready,+                    retry_state->recv_message_error,+                    ""resuming recv_message_ready"");       retry_state->recv_message_ready_deferred_batch = nullptr;     }   } } +// Returns true if any op in the batch was not yet started.+// Only looks at send ops, since recv ops are always started immediately.+static bool pending_batch_is_unstarted(+    pending_batch* pending, call_data* calld,+    subchannel_call_retry_state* retry_state) {+  if (pending->batch == nullptr || pending->batch->on_complete == nullptr) {+    return false;+  }+  if (pending->batch->send_initial_metadata &&+      !retry_state->started_send_initial_metadata) {+    return true;+  }+  if (pending->batch->send_message &&+      retry_state->started_send_message_count < calld->send_messages->size()) {+    return true;+  }+  if (pending->batch->send_trailing_metadata &&+      !retry_state->started_send_trailing_metadata) {+    return true;+  }+  return false;+}++// For any pending batch containing an op that has not yet been started,+// adds the pending batch's completion closures to closures.+static void add_closures_to_fail_unstarted_pending_batches(+    grpc_call_element* elem, subchannel_call_retry_state* retry_state,+    grpc_error* error, grpc_core::CallCombinerClosureList* closures) {+  channel_data* chand = static_cast<channel_data*>(elem->channel_data);+  call_data* calld = static_cast<call_data*>(elem->call_data);+  for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+    pending_batch* pending = &calld->pending_batches[i];+    if (pending_batch_is_unstarted(pending, calld, retry_state)) {+      if (grpc_client_channel_trace.enabled()) {+        gpr_log(GPR_INFO,+                ""chand=%p calld=%p: failing unstarted pending batch at index ""+                ""%"" PRIuPTR,+                chand, calld, i);+      }+      closures->Add(pending->batch->on_complete, GRPC_ERROR_REF(error),+                    ""failing on_complete for pending batch"");+      pending->batch->on_complete = nullptr;+      maybe_clear_pending_batch(elem, pending);+    }+  }+  GRPC_ERROR_UNREF(error);+}++// Intercepts recv_trailing_metadata_ready callback for retries.+// Commits the call and returns the trailing metadata up the stack.+static void recv_trailing_metadata_ready(void* arg, grpc_error* error) {",This method is pretty long. Please refactor.,
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/15539,194245947,2018-06-10T05:31:37Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -1777,133 +1714,241 @@ static void recv_message_ready(void* arg, grpc_error* error) {   }   // Received a valid message, so commit the call.   retry_commit(elem, retry_state);+  // Invoke the callback to return the result to the surface.   // Manually invoking a callback function; it does not take ownership of error.   invoke_recv_message_callback(batch_data, error);-  GRPC_ERROR_UNREF(error); }  //-// list of closures to execute in call combiner-//--// Represents a closure that needs to run in the call combiner as part of-// starting or completing a batch.-typedef struct {-  grpc_closure* closure;-  grpc_error* error;-  const char* reason;-  bool free_reason = false;-} closure_to_execute;--static void execute_closures_in_call_combiner(grpc_call_element* elem,-                                              const char* caller,-                                              closure_to_execute* closures,-                                              size_t num_closures) {-  channel_data* chand = static_cast<channel_data*>(elem->channel_data);-  call_data* calld = static_cast<call_data*>(elem->call_data);-  // Note that the call combiner will be yielded for each closure that-  // we schedule.  We're already running in the call combiner, so one of-  // the closures can be scheduled directly, but the others will-  // have to re-enter the call combiner.-  if (num_closures > 0) {-    if (grpc_client_channel_trace.enabled()) {-      gpr_log(GPR_INFO, ""chand=%p calld=%p: %s starting closure: %s"", chand,-              calld, caller, closures[0].reason);-    }-    GRPC_CLOSURE_SCHED(closures[0].closure, closures[0].error);-    if (closures[0].free_reason) {-      gpr_free(const_cast<char*>(closures[0].reason));-    }-    for (size_t i = 1; i < num_closures; ++i) {-      if (grpc_client_channel_trace.enabled()) {-        gpr_log(GPR_INFO,-                ""chand=%p calld=%p: %s starting closure in call combiner: %s"",-                chand, calld, caller, closures[i].reason);-      }-      GRPC_CALL_COMBINER_START(calld->call_combiner, closures[i].closure,-                               closures[i].error, closures[i].reason);-      if (closures[i].free_reason) {-        gpr_free(const_cast<char*>(closures[i].reason));-      }-    }-  } else {-    if (grpc_client_channel_trace.enabled()) {-      gpr_log(GPR_INFO, ""chand=%p calld=%p: no closures to run for %s"", chand,-              calld, caller);-    }-    GRPC_CALL_COMBINER_STOP(calld->call_combiner, ""no closures to run"");-  }-}--//-// on_complete callback handling+// recv_trailing_metadata handling // -// Updates retry_state to reflect the ops completed in batch_data.-static void update_retry_state_for_completed_batch(-    subchannel_batch_data* batch_data,-    subchannel_call_retry_state* retry_state) {-  if (batch_data->batch.send_initial_metadata) {-    retry_state->completed_send_initial_metadata = true;-  }-  if (batch_data->batch.send_message) {-    ++retry_state->completed_send_message_count;-  }-  if (batch_data->batch.send_trailing_metadata) {-    retry_state->completed_send_trailing_metadata = true;-  }-  if (batch_data->batch.recv_initial_metadata) {-    retry_state->completed_recv_initial_metadata = true;-  }-  if (batch_data->batch.recv_message) {-    ++retry_state->completed_recv_message_count;-  }-  if (batch_data->batch.recv_trailing_metadata) {-    retry_state->completed_recv_trailing_metadata = true;+// Adds recv_trailing_metadata_ready closure to closures.+static void add_closure_for_recv_trailing_metadata_ready(+    grpc_call_element* elem, subchannel_batch_data* batch_data,+    grpc_error* error, grpc_core::CallCombinerClosureList* closures) {+  // Find pending batch.+  pending_batch* pending = pending_batch_find(+      elem, ""invoking recv_trailing_metadata for"",+      [](grpc_transport_stream_op_batch* batch) {+        return batch->recv_trailing_metadata &&+               batch->payload->recv_trailing_metadata+                       .recv_trailing_metadata_ready != nullptr;+      });+  // If we generated the recv_trailing_metadata op internally via+  // start_internal_recv_trailing_metadata(), then there will be no+  // pending batch.+  if (pending == nullptr) {+    GRPC_ERROR_UNREF(error);+    return;   }+  // Return metadata.+  grpc_metadata_batch_move(+      &batch_data->recv_trailing_metadata,+      pending->batch->payload->recv_trailing_metadata.recv_trailing_metadata);+  // Add closure.+  closures->Add(pending->batch->payload->recv_trailing_metadata+                    .recv_trailing_metadata_ready,+                error, ""recv_trailing_metadata_ready for pending batch"");+  // Update bookkeeping.+  pending->batch->payload->recv_trailing_metadata.recv_trailing_metadata_ready =+      nullptr;+  maybe_clear_pending_batch(elem, pending); }  // Adds any necessary closures for deferred recv_initial_metadata and-// recv_message callbacks to closures, updating *num_closures as needed.+// recv_message callbacks to closures. static void add_closures_for_deferred_recv_callbacks(     subchannel_batch_data* batch_data, subchannel_call_retry_state* retry_state,-    closure_to_execute* closures, size_t* num_closures) {+    grpc_core::CallCombinerClosureList* closures) {   if (batch_data->batch.recv_trailing_metadata) {     // Add closure for deferred recv_initial_metadata_ready.     if (GPR_UNLIKELY(retry_state->recv_initial_metadata_ready_deferred_batch !=                      nullptr)) {-      closure_to_execute* closure = &closures[(*num_closures)++];-      closure->closure = GRPC_CLOSURE_INIT(-          &batch_data->recv_initial_metadata_ready,-          invoke_recv_initial_metadata_callback,-          retry_state->recv_initial_metadata_ready_deferred_batch,-          grpc_schedule_on_exec_ctx);-      closure->error = retry_state->recv_initial_metadata_error;-      closure->reason = ""resuming recv_initial_metadata_ready"";+      GRPC_CLOSURE_INIT(&batch_data->recv_initial_metadata_ready,+                        invoke_recv_initial_metadata_callback,+                        retry_state->recv_initial_metadata_ready_deferred_batch,+                        grpc_schedule_on_exec_ctx);+      closures->Add(&batch_data->recv_initial_metadata_ready,+                    retry_state->recv_initial_metadata_error,+                    ""resuming recv_initial_metadata_ready"");       retry_state->recv_initial_metadata_ready_deferred_batch = nullptr;     }     // Add closure for deferred recv_message_ready.     if (GPR_UNLIKELY(retry_state->recv_message_ready_deferred_batch !=                      nullptr)) {-      closure_to_execute* closure = &closures[(*num_closures)++];-      closure->closure = GRPC_CLOSURE_INIT(-          &batch_data->recv_message_ready, invoke_recv_message_callback,-          retry_state->recv_message_ready_deferred_batch,-          grpc_schedule_on_exec_ctx);-      closure->error = retry_state->recv_message_error;-      closure->reason = ""resuming recv_message_ready"";+      GRPC_CLOSURE_INIT(&batch_data->recv_message_ready,+                        invoke_recv_message_callback,+                        retry_state->recv_message_ready_deferred_batch,+                        grpc_schedule_on_exec_ctx);+      closures->Add(&batch_data->recv_message_ready,+                    retry_state->recv_message_error,+                    ""resuming recv_message_ready"");       retry_state->recv_message_ready_deferred_batch = nullptr;     }   } } +// Returns true if any op in the batch was not yet started.+// Only looks at send ops, since recv ops are always started immediately.+static bool pending_batch_is_unstarted(+    pending_batch* pending, call_data* calld,+    subchannel_call_retry_state* retry_state) {+  if (pending->batch == nullptr || pending->batch->on_complete == nullptr) {+    return false;+  }+  if (pending->batch->send_initial_metadata &&+      !retry_state->started_send_initial_metadata) {+    return true;+  }+  if (pending->batch->send_message &&+      retry_state->started_send_message_count < calld->send_messages->size()) {+    return true;+  }+  if (pending->batch->send_trailing_metadata &&+      !retry_state->started_send_trailing_metadata) {+    return true;+  }+  return false;+}++// For any pending batch containing an op that has not yet been started,+// adds the pending batch's completion closures to closures.+static void add_closures_to_fail_unstarted_pending_batches(+    grpc_call_element* elem, subchannel_call_retry_state* retry_state,+    grpc_error* error, grpc_core::CallCombinerClosureList* closures) {+  channel_data* chand = static_cast<channel_data*>(elem->channel_data);+  call_data* calld = static_cast<call_data*>(elem->call_data);+  for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {+    pending_batch* pending = &calld->pending_batches[i];+    if (pending_batch_is_unstarted(pending, calld, retry_state)) {+      if (grpc_client_channel_trace.enabled()) {+        gpr_log(GPR_INFO,+                ""chand=%p calld=%p: failing unstarted pending batch at index ""+                ""%"" PRIuPTR,+                chand, calld, i);+      }+      closures->Add(pending->batch->on_complete, GRPC_ERROR_REF(error),+                    ""failing on_complete for pending batch"");+      pending->batch->on_complete = nullptr;+      maybe_clear_pending_batch(elem, pending);+    }+  }+  GRPC_ERROR_UNREF(error);+}++// Intercepts recv_trailing_metadata_ready callback for retries.+// Commits the call and returns the trailing metadata up the stack.+static void recv_trailing_metadata_ready(void* arg, grpc_error* error) {+  subchannel_batch_data* batch_data = static_cast<subchannel_batch_data*>(arg);+  grpc_call_element* elem = batch_data->elem;+  channel_data* chand = static_cast<channel_data*>(elem->channel_data);+  call_data* calld = static_cast<call_data*>(elem->call_data);+  if (grpc_client_channel_trace.enabled()) {+    gpr_log(GPR_INFO,+            ""chand=%p calld=%p: got recv_trailing_metadata_ready, error=%s"",+            chand, calld, grpc_error_string(error));+  }+  subchannel_call_retry_state* retry_state =+      static_cast<subchannel_call_retry_state*>(+          grpc_connected_subchannel_call_get_parent_data(+              batch_data->subchannel_call));+  retry_state->completed_recv_trailing_metadata = true;+  // Get the call's status and check for server pushback metadata.+  grpc_status_code status = GRPC_STATUS_OK;+  grpc_mdelem* server_pushback_md = nullptr;+  if (error != GRPC_ERROR_NONE) {+    grpc_error_get_status(error, calld->deadline, &status, nullptr, nullptr,+                          nullptr);+  } else {+    grpc_metadata_batch* md_batch =+        batch_data->batch.payload->recv_trailing_metadata+            .recv_trailing_metadata;+    GPR_ASSERT(md_batch->idx.named.grpc_status != nullptr);+    status =+        grpc_get_status_code_from_metadata(md_batch->idx.named.grpc_status->md);+    if (md_batch->idx.named.grpc_retry_pushback_ms != nullptr) {+      server_pushback_md = &md_batch->idx.named.grpc_retry_pushback_ms->md;+    }+  }+  if (grpc_client_channel_trace.enabled()) {+    gpr_log(GPR_INFO, ""chand=%p calld=%p: call finished, status=%s"", chand,+            calld, grpc_status_code_to_string(status));+  }+  // Check if we should retry.+  if (maybe_retry(elem, batch_data, status, server_pushback_md)) {+    // Unref batch_data for deferred recv_initial_metadata_ready or+    // recv_message_ready callbacks, if any.+    if (retry_state->recv_initial_metadata_ready_deferred_batch != nullptr) {+      batch_data_unref(batch_data);+      GRPC_ERROR_UNREF(retry_state->recv_initial_metadata_error);+    }+    if (retry_state->recv_message_ready_deferred_batch != nullptr) {+      batch_data_unref(batch_data);+      GRPC_ERROR_UNREF(retry_state->recv_message_error);+    }+    batch_data_unref(batch_data);+    return;+  }+  // Not retrying, so commit the call.+  retry_commit(elem, retry_state);+  // Construct list of closures to execute.+  grpc_core::CallCombinerClosureList closures;+  // First, add closure for recv_trailing_metadata_ready.+  add_closure_for_recv_trailing_metadata_ready(+      elem, batch_data, GRPC_ERROR_REF(error), &closures);+  // If there are deferred recv_initial_metadata_ready or recv_message_ready+  // callbacks, add them to closures.+  add_closures_for_deferred_recv_callbacks(batch_data, retry_state, &closures);+  // Add closures to fail any pending batches that have not yet been started.+  add_closures_to_fail_unstarted_pending_batches(+      elem, retry_state, GRPC_ERROR_REF(error), &closures);+  // Don't need batch_data anymore.+  batch_data_unref(batch_data);+  // Schedule all of the closures identified above.+  // Note: This will release the call combiner.+  closures.RunClosures(calld->call_combiner);+}++//+// on_complete callback handling+//++// For any pending batch completed in batch_data, adds the necessary","2 things: 1) this comment says we're adding multiple completion closures, but I only see one closure being added. 2) ""For any pending batch completed in batch_data"" is confusing. Is it supposed to add closures for multiple batches? It seems it's adding exactly zero or one closure for exactly one batch. ",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/15539,194269563,2018-06-10T20:31:23Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -2035,135 +1999,48 @@ static void on_complete(void* arg, grpc_error* error) {       static_cast<subchannel_call_retry_state*>(           grpc_connected_subchannel_call_get_parent_data(               batch_data->subchannel_call));-  // If we have previously completed recv_trailing_metadata, then the-  // call is finished.-  bool call_finished = retry_state->completed_recv_trailing_metadata;-  // Record whether we were already committed before receiving this callback.-  const bool previously_committed = calld->retry_committed;   // Update bookkeeping in retry_state.-  update_retry_state_for_completed_batch(batch_data, retry_state);-  if (call_finished) {-    if (grpc_client_channel_trace.enabled()) {-      gpr_log(GPR_INFO, ""chand=%p calld=%p: call already finished"", chand,-              calld);-    }-  } else {-    // Check if this batch finished the call, and if so, get its status.-    // The call is finished if either (a) this callback was invoked with-    // an error or (b) we receive status.-    grpc_status_code status = GRPC_STATUS_OK;-    grpc_mdelem* server_pushback_md = nullptr;-    if (GPR_UNLIKELY(error != GRPC_ERROR_NONE)) {  // Case (a).-      call_finished = true;-      grpc_error_get_status(error, calld->deadline, &status, nullptr, nullptr,-                            nullptr);-    } else if (batch_data->batch.recv_trailing_metadata) {  // Case (b).-      call_finished = true;-      grpc_metadata_batch* md_batch =-          batch_data->batch.payload->recv_trailing_metadata-              .recv_trailing_metadata;-      GPR_ASSERT(md_batch->idx.named.grpc_status != nullptr);-      status = grpc_get_status_code_from_metadata(-          md_batch->idx.named.grpc_status->md);-      if (md_batch->idx.named.grpc_retry_pushback_ms != nullptr) {-        server_pushback_md = &md_batch->idx.named.grpc_retry_pushback_ms->md;-      }-    }-    // If the call just finished, check if we should retry.-    if (call_finished) {-      if (grpc_client_channel_trace.enabled()) {-        gpr_log(GPR_INFO, ""chand=%p calld=%p: call finished, status=%s"", chand,-                calld, grpc_status_code_to_string(status));-      }-      if (maybe_retry(elem, batch_data, status, server_pushback_md)) {-        // Unref batch_data for deferred recv_initial_metadata_ready or-        // recv_message_ready callbacks, if any.-        if (batch_data->batch.recv_trailing_metadata &&-            retry_state->recv_initial_metadata_ready_deferred_batch !=-                nullptr) {-          batch_data_unref(batch_data);-          GRPC_ERROR_UNREF(retry_state->recv_initial_metadata_error);-        }-        if (batch_data->batch.recv_trailing_metadata &&-            retry_state->recv_message_ready_deferred_batch != nullptr) {-          batch_data_unref(batch_data);-          GRPC_ERROR_UNREF(retry_state->recv_message_error);-        }-        // Track number of pending subchannel send batches and determine if-        // this was the last one.-        bool last_callback_complete = false;-        if (batch_data->batch.send_initial_metadata ||-            batch_data->batch.send_message ||-            batch_data->batch.send_trailing_metadata) {-          --calld->num_pending_retriable_subchannel_send_batches;-          last_callback_complete =-              calld->num_pending_retriable_subchannel_send_batches == 0;-        }-        batch_data_unref(batch_data);-        // If we just completed the last subchannel send batch, unref the-        // call stack.-        if (last_callback_complete) {-          GRPC_CALL_STACK_UNREF(calld->owning_call, ""subchannel_send_batches"");-        }-        return;-      }-      // Not retrying, so commit the call.-      retry_commit(elem, retry_state);-    }+  if (batch_data->batch.send_initial_metadata) {+    retry_state->completed_send_initial_metadata = true;+  }+  if (batch_data->batch.send_message) {+    ++retry_state->completed_send_message_count;   }-  // If we were already committed before receiving this callback, free-  // cached data for send ops that we've just completed.  (If the call has-  // just now finished, the call to retry_commit() above will have freed all-  // cached send ops, so we don't need to do it here.)-  if (previously_committed) {+  if (batch_data->batch.send_trailing_metadata) {+    retry_state->completed_send_trailing_metadata = true;+  }+  // If the call is committed, free cached data for send ops that we've just+  // completed.+  if (calld->retry_committed) {     free_cached_send_op_data_for_completed_batch(elem, batch_data, retry_state);   }-  // Call not being retried.   // Construct list of closures to execute.","This can be done in a separate PR, but I think this logic should be factored out into a separate function. Constructing a list of closures to execute is a single concept that should have a single function. ",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/15539,194270510,2018-06-10T21:05:06Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -1192,35 +1193,24 @@ static void pending_batches_fail(grpc_call_element* elem, grpc_error* error,             ""chand=%p calld=%p: failing %"" PRIuPTR "" pending batches: %s"",             elem->channel_data, calld, num_batches, grpc_error_string(error));   }-  grpc_transport_stream_op_batch*-      batches[GPR_ARRAY_SIZE(calld->pending_batches)];-  size_t num_batches = 0;+  grpc_core::CallCombinerClosureList closures;   for (size_t i = 0; i < GPR_ARRAY_SIZE(calld->pending_batches); ++i) {     pending_batch* pending = &calld->pending_batches[i];     grpc_transport_stream_op_batch* batch = pending->batch;     if (batch != nullptr) {-      batches[num_batches++] = batch;+      batch->handler_private.extra_arg = calld;+      GRPC_CLOSURE_INIT(&batch->handler_private.closure,+                        fail_pending_batch_in_call_combiner, batch,+                        grpc_schedule_on_exec_ctx);+      closures.Add(&batch->handler_private.closure, GRPC_ERROR_REF(error),+                   ""pending_batches_fail"");       pending_batch_clear(calld, pending);     }   }-  for (size_t i = yield_call_combiner ? 1 : 0; i < num_batches; ++i) {","Oh, I see from call_combiner.h: // It requires the callback (or, in the common case where the callback// actually kicks off a chain of callbacks, the last callback in that// chain) to explicitly indicate (by calling GRPC_CALL_COMBINER_STOP())// when it is done with the action that was kicked off by the original// callback.",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/15539,194271102,2018-06-10T21:32:04Z,src/core/lib/surface/call.cc,"@@ -1538,6 +1531,19 @@ static void receiving_initial_metadata_ready(void* bctlp, grpc_error* error) {   finish_batch_step(bctl); } +static void receiving_trailing_metadata_ready(void* bctlp, grpc_error* error) {+  batch_control* bctl = static_cast<batch_control*>(bctlp);+  grpc_call* call = bctl->call;+  GRPC_CALL_COMBINER_STOP(&call->call_combiner, ""recv_trailing_metadata_ready"");+  add_batch_error(bctl, GRPC_ERROR_REF(error), false);","Where does the error get unref'd? It's okay if receiving_trailing_metadata_ready is only used as a closure, but that can't be guaranteed in its current form, and we can't guarantee that future writers of this codebase won't use this function carelessly.",
13115060,rongjiecomputer,https://api.github.com/repos/grpc/grpc/pulls/15624,194587716,2018-06-12T00:43:24Z,third_party/cares/cares.BUILD,"@@ -138,10 +144,22 @@ cc_library(     copts = [         ""-D_GNU_SOURCE"",         ""-D_HAS_EXCEPTIONS=0"",-        ""-DNOMINMAX"",         ""-DHAVE_CONFIG_H"",-    ],+    ] + select({+        "":windows"": [+            ""-DNOMINMAX"",+            ""-D_CRT_SECURE_NO_DEPRECATE"",",`NOMINMAX` is to tell `windows.h` not to define `min` and `max` macros. These two macros often cause obscure compile error if you something else with the same name.`_CRT_SECURE_NO_DEPRECATE` and `_CRT_NONSTDC_NO_DEPRECATE` are needed because MSVC is trying to deprecate perfectly normal C standard functions such as `fopen` (and ask you to use `fopen_s` instead). Even gRPC use these flags: https://github.com/grpc/grpc/blob/master/CMakeLists.txt#L99.tl;dr: We need these three flags to avoid useless warnings.,
22083734,matt-kwong,https://api.github.com/repos/grpc/grpc/pulls/15719,194590387,2018-06-12T01:05:13Z,tools/internal_ci/linux/grpc_tsan_on_foundry.sh,"@@ -16,3 +16,112 @@ export UPLOAD_TEST_RESULTS=true EXTRA_FLAGS=""--copt=-gmlt --strip=never --copt=-fsanitize=thread --linkopt=-fsanitize=thread --test_timeout=3600"" github/grpc/tools/internal_ci/linux/grpc_bazel_on_foundry_base.sh ""${EXTRA_FLAGS}""++#!/usr/bin/env bash",Copyright was accidently copy pasted in the middle of the file?,
6879942,Vizerai,https://api.github.com/repos/grpc/grpc/pulls/15070,194597831,2018-06-12T02:10:13Z,bazel/grpc_deps.bzl,"@@ -108,8 +133,8 @@ def grpc_deps():         native.new_http_archive(             name = ""com_github_google_benchmark"",             build_file = ""@com_github_grpc_grpc//third_party:benchmark.BUILD"",-            strip_prefix = ""benchmark-5b7683f49e1e9223cf9927b24f6fd3d6bd82e3f8"",-            url = ""https://github.com/google/benchmark/archive/5b7683f49e1e9223cf9927b24f6fd3d6bd82e3f8.tar.gz"",+            strip_prefix = ""benchmark-9913418d323e64a0111ca0da81388260c2bbe1e9"",+            url = ""https://github.com/google/benchmark/archive/9913418d323e64a0111ca0da81388260c2bbe1e9.tar.gz"",",There were incompatibilities with the older version of the library.,
6879942,Vizerai,https://api.github.com/repos/grpc/grpc/pulls/15070,194597836,2018-06-12T02:10:15Z,bazel/grpc_deps.bzl,"@@ -123,8 +148,8 @@ def grpc_deps():     if ""com_google_absl"" not in native.existing_rules():         native.http_archive(             name = ""com_google_absl"",-            strip_prefix = ""abseil-cpp-cc4bed2d74f7c8717e31f9579214ab52a9c9c610"",-            url = ""https://github.com/abseil/abseil-cpp/archive/cc4bed2d74f7c8717e31f9579214ab52a9c9c610.tar.gz"",+            strip_prefix = ""abseil-cpp-cd95e71df6eaf8f2a282b1da556c2cf1c9b09207"",+            url = ""https://github.com/abseil/abseil-cpp/archive/cd95e71df6eaf8f2a282b1da556c2cf1c9b09207.tar.gz"",",There were incompatibilities with the older version of the library.,
8228229,kkm000,https://api.github.com/repos/grpc/grpc/pulls/13207,194624696,2018-06-12T06:17:03Z,src/csharp/Grpc.Tools/DepFileUtil.cs,"@@ -0,0 +1,198 @@+#region Copyright notice and license++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Generic;+using System.IO;+using System.Text;+using Microsoft.Build.Framework;+using Microsoft.Build.Utilities;++namespace Grpc.Tools {+  internal static class DepFileUtil {+/*+   Sample dependency files. Notable features we have to deal with:+    * Slash doubling, must normalize them.+    * Spaces in file names. Cannot just ""unwrap"" the line on backslash at eof;+      rather, treat every line as containing one file name except for one with+      the ':' separator, as containing exactly two.+    * Deal with ':' also being drive letter separator (second example).++obj\Release\net45\/Foo.cs \+obj\Release\net45\/FooGrpc.cs: C:/foo/include/google/protobuf/wrappers.proto\+ C:/projects/foo/src//foo.proto++C:\projects\foo\src\./foo.grpc.pb.cc \+C:\projects\foo\src\./foo.grpc.pb.h \+C:\projects\foo\src\./foo.pb.cc \+C:\projects\foo\src\./foo.pb.h: C:/foo/include/google/protobuf/wrappers.proto\+ C:/foo/include/google/protobuf/any.proto\+ C:/foo/include/google/protobuf/source_context.proto\+ C:/foo/include/google/protobuf/type.proto\+ foo.proto+*/++    // Read file names from the dependency file to the right of ':'.+    public static string[] ReadDependencyInputs(string protoDepDir, string proto,+                                                TaskLoggingHelper log) {+      string depFilename = GetDepFilenameForProto(protoDepDir, proto);+      string[] lines = ReadDepFileLines(depFilename, false, log);+      if (lines.Length == 0) {+        return lines;+      }++      var result = new List<string>();+      bool skip = true;+      foreach (string line in lines) {+        // Start at the only line separating dependency outputs from inputs.+        int ix = skip ? FindLineSeparator(line) : -1;+        skip = skip && ix < 0;+        if (skip) continue;+        string file = ExtractFilenameFromLine(line, ix + 1, line.Length);+        if (file == """") {+          log.LogMessage(MessageImportance.Low,+    $""Skipping unparsable dependency file {depFilename}.\nLine with error: '{line}'"");+          return new string[0];+        }++        // Do not bend over backwards trying not to include a proto into its+        // own list of dependencies. Since a file is not older than self,+        // it is safe to add; this is purely a memory optimization.+        if (file != proto) {+          result.Add(file);+        }+      }+      return result.ToArray();+    }++    // Read file names from the dependency file to the left of ':'.+    public static string[] ReadDependencyOutputs(string depFilename,+                                                TaskLoggingHelper log) {+      string[] lines = ReadDepFileLines(depFilename, true, log);+      if (lines.Length == 0) {+        return lines;+      }++      var result = new List<string>();+      foreach (string line in lines) {+        int ix = FindLineSeparator(line);+        string file = ExtractFilenameFromLine(line, 0, ix >= 0 ? ix : line.Length);+        if (file == """") {+          log.LogError(""Unable to parse generated dependency file {0}.\n"" ++                       ""Line with error: '{1}'"", depFilename, line);+          return new string[0];+        }+        result.Add(file);++        // If this is the line with the separator, do not read further.+        if (ix >= 0)+          break;+      }+      return result.ToArray();+    }++    // Get complete dependency file name from directory hash and file name,+    // tucked onto protoDepDir, e. g.+    // (""out"", ""foo/file.proto"") => ""out/deadbeef12345678_file.protodep"".+    // This way, the filenames are unique but still possible to make sense of.+    public static string GetDepFilenameForProto(string protoDepDir, string proto) {","I am adding this commentary, and I think it makes sense to reproduce here as I tried to explain it as well as I could:> Since a project may contain proto files with the same filename but in different> directories, a unique filename for the dependency file is constructed based on the> proto file name both name and directory. The directory path can be arbitrary,> for example, it can be outside of the project, or an absolute path including> a drive letter, or a UNC network path. A name constructed from such a path by,> for example, replacing disallowed name characters with an underscore, may well> be over filesystem's allowed path length, since it will be located under the> project and solution directories, which are also some level deep from the root.> Instead of creating long and unwieldy names for these proto sources, we cache> the full path of the name without the filename, and append the filename to it,> as in e. g. ""foo/file.proto"" will yield the name ""deadbeef12345678_file"", where> ""deadbeef12345678"" is a presumed hash value of the string ""foo/"". This allows> the file names be short, unique (up to a hash collision), and still allowing> the user to guess their provenance.In other words, I need to encode distinct dependency file names of `foo.proto`, `sub1/sub2/foo.proto`, `../../../../protofiles/helloworld/hello.proto` and `\\server.company.local\fs\shared\packages\protofiles\helloword\hello.proto`. I do not want to end up with names like `__server.company.local_fs_shared_packages_protofiles_helloword_hello.protodep` because they may be arbitrarily long and just would not fit into filesystem's path length restriction when placed under `C:\users\firstname.lastname.OURDOMAIN\Documents\Visual Studio 2017\myprojects\SmartAction.SomethingLong.SomethingEvenLonger\SmartAction.SomethingLong.SomethingEvenLonger.Client\obj`. This is quite common for the last 3 path components to be like this, and may be not so rare for the rest of this not exactly very contrived path name; I have had real problems exactly like this (and my project directory is `c:\projects`, not the least *because* of this :) ). Also, they are ugly and no less clash-prone than 64-bit hashes.",
2811396,ejona86,https://api.github.com/repos/grpc/grpc/pulls/15618,195164275,2018-06-13T17:07:40Z,src/core/ext/filters/client_channel/README.md,"@@ -46,20 +46,4 @@ construction arguments for concrete grpc_subchannel instances. Naming for GRPC =============== -Names in GRPC are represented by a URI (as defined in-[RFC 3986](https://tools.ietf.org/html/rfc3986)).--The following schemes are currently supported:--dns:///host:port - dns schemes are currently supported so long as authority is-                   empty (authority based dns resolution is expected in a future-                   release)--unix:path        - the unix scheme is used to create and connect to unix domain-                   sockets - the authority must be empty, and the path-                   represents the absolute or relative path to the desired-                   socket--ipv4:host:port   - a pre-resolved ipv4 dotted decimal address/port combination--ipv6:[host]:port - a pre-resolved ipv6 address/port combination+See [/doc/naming,md](gRPC name resolution).","s/naming,md/naming.md/",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15727,195203283,2018-06-13T19:12:19Z,src/core/lib/channel/handshaker.cc,"@@ -223,18 +223,20 @@ static bool call_next_handshaker_locked(grpc_handshake_manager* mgr,       mgr->index == mgr->count) {     if (error == GRPC_ERROR_NONE && mgr->shutdown) {       error = GRPC_ERROR_CREATE_FROM_STATIC_STRING(""handshaker shutdown"");-      // TODO(roth): It is currently necessary to shutdown endpoints-      // before destroying then, even when we know that there are no-      // pending read/write callbacks.  This should be fixed, at which-      // point this can be removed.-      grpc_endpoint_shutdown(mgr->args.endpoint, GRPC_ERROR_REF(error));-      grpc_endpoint_destroy(mgr->args.endpoint);-      mgr->args.endpoint = nullptr;-      grpc_channel_args_destroy(mgr->args.args);-      mgr->args.args = nullptr;-      grpc_slice_buffer_destroy_internal(mgr->args.read_buffer);-      gpr_free(mgr->args.read_buffer);-      mgr->args.read_buffer = nullptr;+      if (mgr->args.endpoint != nullptr) {",Please add a comment explaining the race condition that we're catching here (the case you describe in the PR description).,
8228229,kkm000,https://api.github.com/repos/grpc/grpc/pulls/13207,195302745,2018-06-14T04:59:50Z,src/csharp/Grpc.Tools/Common.cs,"@@ -0,0 +1,105 @@+#region Copyright notice and license++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.IO;+using System.Runtime.CompilerServices;+using System.Runtime.InteropServices;+using System.Security;++[assembly: InternalsVisibleTo(""Grpc.Tools.Tests"")]++namespace Grpc.Tools {+  // Metadata names that we refer to often.+  static class Metadata {","Yes, ""metadata"" is the MSBuild's term. I commented it better.",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/15630,195561475,2018-06-14T20:31:39Z,test/cpp/microbenchmarks/bm_call_create.cc,"@@ -609,6 +617,125 @@ typedef Fixture<&grpc_server_load_reporting_filter, CHECKS_NOT_LAST> BENCHMARK_TEMPLATE(BM_IsolatedFilter, LoadReportingFilter, NoOp); BENCHMARK_TEMPLATE(BM_IsolatedFilter, LoadReportingFilter, SendEmptyMetadata); +// Test a filter's start_transport_stream_op_batch in isolation. Fixture +// specifies the filter under test (use the Fixture<> template to specify this).+template <class Fixture>+static void BM_StartTransportStreamOpBatch(benchmark::State& state) {","Refactoring in process. I deleted BM_IsolatedFilter benchmark and replaced it with BM_CallStackInit. It measures the same thing except I took out the part where it did some random work (either NoOp or SendEmptyMetadata). As we discussed offline, it didn't make sense to measure this random work as part of call creation cost or as part of call_stack_init.",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/15630,195581798,2018-06-14T21:47:58Z,test/cpp/microbenchmarks/bm_call_create.cc,"@@ -609,6 +617,125 @@ typedef Fixture<&grpc_server_load_reporting_filter, CHECKS_NOT_LAST> BENCHMARK_TEMPLATE(BM_IsolatedFilter, LoadReportingFilter, NoOp); BENCHMARK_TEMPLATE(BM_IsolatedFilter, LoadReportingFilter, SendEmptyMetadata); +// Test a filter's start_transport_stream_op_batch in isolation. Fixture +// specifies the filter under test (use the Fixture<> template to specify this).+template <class Fixture>+static void BM_StartTransportStreamOpBatch(benchmark::State& state) {+  TrackCounters track_counters;+  Fixture fixture;+  std::ostringstream label;++  std::vector<grpc_arg> args;+  FakeClientChannelFactory fake_client_channel_factory;+  args.push_back(grpc_client_channel_factory_create_channel_arg(+      &fake_client_channel_factory));+  args.push_back(StringArg(GRPC_ARG_SERVER_URI, ""localhost""));++  grpc_channel_args channel_args = {args.size(), &args[0]};++  std::vector<const grpc_channel_filter*> filters;+  if (fixture.filter != nullptr) {+    filters.push_back(fixture.filter);+  }++  if (fixture.flags & CHECKS_NOT_LAST) {+    // Some filters assert they are not the last in the stack, so we add a +    // dummy filter after them so they won't complain+    filters.push_back(&dummy_filter::dummy_filter);+    label << "" #has_dummy_filter"";+  } ++  grpc_core::ExecCtx exec_ctx;+  size_t channel_size = grpc_channel_stack_size(+      filters.size() == 0 ? nullptr : &filters[0], filters.size());+  grpc_channel_stack* channel_stack =+      static_cast<grpc_channel_stack*>(gpr_zalloc(channel_size));+  GPR_ASSERT(GRPC_LOG_IF_ERROR(+      ""channel_stack_init"",+      grpc_channel_stack_init(1, FilterDestroy, channel_stack, &filters[0],+                              filters.size(), &channel_args,+                              fixture.flags & REQUIRES_TRANSPORT+                                  ? &dummy_transport::dummy_transport+                                  : nullptr,+                              ""CHANNEL"", channel_stack)));+  grpc_core::ExecCtx::Get()->Flush();+  grpc_call_stack* call_stack =+      static_cast<grpc_call_stack*>(gpr_zalloc(channel_stack->call_stack_size));+  grpc_millis deadline = GRPC_MILLIS_INF_FUTURE;+  gpr_timespec start_time = gpr_now(GPR_CLOCK_MONOTONIC);+  grpc_slice method = grpc_slice_from_static_string(""/foo/bar"");+  grpc_call_final_info final_info;+  grpc_call_element_args call_args;+  call_args.call_stack = call_stack;+  call_args.server_transport_data = nullptr;+  call_args.context = nullptr;+  call_args.path = method;+  call_args.start_time = start_time;+  call_args.deadline = deadline;+  const int kArenaSize = 4096;+  call_args.arena = gpr_arena_create(kArenaSize);+  GRPC_ERROR_UNREF(+        grpc_call_stack_init(channel_stack, 1, DoNothing, nullptr, &call_args));+  +  while (state.KeepRunning()) {+    GPR_TIMER_SCOPE(""BenchmarkCycle"", 0);+    /* Create new payload */+    grpc_transport_stream_op_batch_payload payload = {};+    grpc_metadata_batch metadata_batch = {};+    grpc_metadata_batch_init(&metadata_batch);+    payload.send_initial_metadata.send_initial_metadata = &metadata_batch;+    payload.send_initial_metadata.send_initial_metadata_flags = 0;+    // TODO(hcaseyal): set payload send_initial_metadata peer_string?+    payload.send_trailing_metadata.send_trailing_metadata = &metadata_batch;+    payload.recv_initial_metadata.recv_initial_metadata = &metadata_batch;+    payload.recv_initial_metadata.recv_initial_metadata_ready = nullptr;+    // TODO(hcaseyal): set recv_initial_metadata peer_string?",Done. I now set it only in recv_initial_metadata,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/15793,196244602,2018-06-18T22:25:36Z,src/ruby/lib/grpc/generic/active_call.rb,"@@ -120,9 +120,9 @@ def send_initial_metadata(new_metadata = {})       @send_initial_md_mutex.synchronize do         return if @metadata_sent         @metadata_to_send.merge!(new_metadata)-        @metadata_tag = ActiveCall.client_invoke(@call, @metadata_to_send)         @metadata_sent = true       end+      @call.run_batch(SEND_INITIAL_METADATA => @metadata_to_send)","nit: can we minimize the change, keep the `ActiveCall.client_invoke`, and just get rid of the `@metadata_tag` var?",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/15630,196245683,2018-06-18T22:31:07Z,test/cpp/microbenchmarks/bm_filters.cc,"@@ -0,0 +1,200 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <benchmark/benchmark.h>+#include <string.h>+#include <sstream>++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/string_util.h>+#include <grpcpp/channel.h>+#include <grpcpp/support/channel_arguments.h>++#include ""src/core/ext/filters/client_channel/client_channel.h""+#include ""src/core/ext/filters/deadline/deadline_filter.h""+#include ""src/core/ext/filters/http/client/http_client_filter.h""+#include ""src/core/ext/filters/http/message_compress/message_compress_filter.h""+#include ""src/core/ext/filters/http/server/http_server_filter.h""+#include ""src/core/ext/filters/load_reporting/server_load_reporting_filter.h""+#include ""src/core/ext/filters/message_size/message_size_filter.h""+#include ""src/core/lib/gprpp/manual_constructor.h""++#include ""src/cpp/client/create_channel_internal.h""+#include ""src/proto/grpc/testing/echo.grpc.pb.h""+#include ""test/cpp/microbenchmarks/filter_helpers.h""+#include ""test/cpp/util/test_config.h""++auto& force_library_initialization = Library::get();++// Test a filter's call stack init in isolation. FilterBM, in conjunction with+// FilterFixture, specifies the filter under test (use the FilterBM<> template+// to specify this).+// Note that there is some other work being done within the benchmarking loop,+// so the result of this microbenchmark is a little bloated.+template <class FilterBM>+static void BM_CallStackInit(benchmark::State& state) {+  // Setup for benchmark+  FilterBM bm_setup;+  struct DataForFilterBM data;+  bm_setup.Setup(&data);++  // Run the benchmark+  grpc_call_final_info final_info;+  while (state.KeepRunning()) {+    GPR_TIMER_SCOPE(""BenchmarkCycle"", 0);+    GRPC_ERROR_UNREF(grpc_call_stack_init(data.channel_stack, 1, DoNothing,+                                          nullptr, &data.call_args));+    grpc_call_stack_destroy(data.call_stack, &final_info, nullptr);+    // Recreate arena every 64k iterations to avoid oom+    if (0 == (state.iterations() & 0xffff)) {+      gpr_arena_destroy(data.call_args.arena);+      data.call_args.arena = gpr_arena_create(bm_setup.kArenaSize);+    }+  }++  bm_setup.Destroy(&data, state);+}++typedef FilterFixture<nullptr, 0> NoFilter;+typedef FilterBM<NoFilter> NoFilterBM;+BENCHMARK_TEMPLATE(BM_CallStackInit, NoFilterBM);++typedef FilterFixture<&dummy_filter::dummy_filter, 0> DummyFilter;+typedef FilterBM<DummyFilter> DummyFilterBM;+BENCHMARK_TEMPLATE(BM_CallStackInit, DummyFilterBM);++typedef FilterFixture<&grpc_client_channel_filter, 0> ClientChannelFilter;+typedef FilterBM<ClientChannelFilter> ClientChannelFilterBM;+BENCHMARK_TEMPLATE(BM_CallStackInit, ClientChannelFilterBM);++typedef FilterFixture<&grpc_message_compress_filter, CHECKS_NOT_LAST>+    CompressFilter;+typedef FilterBM<CompressFilter> CompressFilterBM;+BENCHMARK_TEMPLATE(BM_CallStackInit, CompressFilterBM);++typedef FilterFixture<&grpc_client_deadline_filter, CHECKS_NOT_LAST>+    ClientDeadlineFilter;+typedef FilterBM<ClientDeadlineFilter> ClientDeadlineFilterBM;+BENCHMARK_TEMPLATE(BM_CallStackInit, ClientDeadlineFilterBM);++typedef FilterFixture<&grpc_server_deadline_filter, CHECKS_NOT_LAST>+    ServerDeadlineFilter;+typedef FilterBM<ServerDeadlineFilter> ServerDeadlineFilterBM;+BENCHMARK_TEMPLATE(BM_CallStackInit, ServerDeadlineFilterBM);++typedef FilterFixture<&grpc_http_client_filter,+                      CHECKS_NOT_LAST | REQUIRES_TRANSPORT>+    HttpClientFilter;+typedef FilterBM<HttpClientFilter> HttpClientFilterBM;+BENCHMARK_TEMPLATE(BM_CallStackInit, HttpClientFilterBM);++typedef FilterFixture<&grpc_http_server_filter, CHECKS_NOT_LAST>+    HttpServerFilter;+typedef FilterBM<HttpServerFilter> HttpServerFilterBM;+BENCHMARK_TEMPLATE(BM_CallStackInit, HttpServerFilterBM);++typedef FilterFixture<&grpc_message_size_filter, CHECKS_NOT_LAST>+    MessageSizeFilter;+typedef FilterBM<MessageSizeFilter> MessageSizeFilterBM;+BENCHMARK_TEMPLATE(BM_CallStackInit, MessageSizeFilterBM);++typedef FilterFixture<&grpc_server_load_reporting_filter, CHECKS_NOT_LAST>+    ServerLoadReportingFilter;+typedef FilterBM<ServerLoadReportingFilter> ServerLoadReportingFilterBM;+BENCHMARK_TEMPLATE(BM_CallStackInit, ServerLoadReportingFilterBM);++// Measure full filter functionality overhead, from initializing the call stack+// through running all filter callbacks.+// Note that all we do is send down all 6 ops through the filter stack; we do+// not test different combinations or subsets of ops. Thus, this test does not+// comprehensively test all the code paths of each individual filter because+// filters may take different code paths based on the combination and/or+// ordering of the ops.+template <class FilterBM>+static void BM_FullFilterFunctionality(benchmark::State& state) {+  // Setup for benchmark+  FilterBM bm_setup;+  struct DataForFilterBM data;+  bm_setup.Setup(&data);++  // Run the benchmark+  while (state.KeepRunning()) {+    GPR_TIMER_SCOPE(""BenchmarkCycle"", 0);+    // Because it's not valid to send more than one of any of the {send, recv}_+    // {initial, trailing}_metadata ops on a single call, we need to construct+    // a new call stack each time through the loop. It's also not valid to have+    // more than one of send_message or recv_message in flight on a single call+    // at the same time.+    memset(data.call_stack, 0, data.channel_stack->call_stack_size);","Another interesting data point for streaming would be pulling this out of the main loop, then only benchmarking batches with send or recv message batches.Is that the plan for this continuation of this project? I know you mentioned you had more coming.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/15630,196246639,2018-06-18T22:36:24Z,test/cpp/microbenchmarks/filter_helpers.h,"@@ -0,0 +1,371 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/core/lib/channel/channel_stack.h""+#include ""src/core/lib/channel/connected_channel.h""+#include ""src/core/lib/iomgr/call_combiner.h""+#include ""src/core/lib/profiling/timers.h""+#include ""src/core/lib/surface/channel.h""+#include ""src/core/lib/transport/transport_impl.h""++#include ""test/cpp/microbenchmarks/helpers.h""++#define CALL_ELEMS_FROM_STACK(stk)     \+  ((grpc_call_element*)((char*)(stk) + \+                        ROUND_UP_TO_ALIGNMENT_SIZE(sizeof(grpc_call_stack))))++/* Given a size, round up to the next multiple of sizeof(void*) */+#define ROUND_UP_TO_ALIGNMENT_SIZE(x) \+  (((x) + GPR_MAX_ALIGNMENT - 1u) & ~(GPR_MAX_ALIGNMENT - 1u))++static void FilterDestroy(void* arg, grpc_error* error) { gpr_free(arg); }++static void DoNothing(void* arg, grpc_error* error) {}++class FakeClientChannelFactory : public grpc_client_channel_factory {+ public:+  FakeClientChannelFactory() { vtable = &vtable_; }++ private:+  static void NoRef(grpc_client_channel_factory* factory) {}+  static void NoUnref(grpc_client_channel_factory* factory) {}+  static grpc_subchannel* CreateSubchannel(grpc_client_channel_factory* factory,+                                           const grpc_subchannel_args* args) {+    return nullptr;+  }+  static grpc_channel* CreateClientChannel(grpc_client_channel_factory* factory,+                                           const char* target,+                                           grpc_client_channel_type type,+                                           const grpc_channel_args* args) {+    return nullptr;+  }++  static const grpc_client_channel_factory_vtable vtable_;+};++const grpc_client_channel_factory_vtable FakeClientChannelFactory::vtable_ = {+    NoRef, NoUnref, CreateSubchannel, CreateClientChannel};++static grpc_arg StringArg(const char* key, const char* value) {+  grpc_arg a;+  a.type = GRPC_ARG_STRING;+  a.key = const_cast<char*>(key);+  a.value.string = const_cast<char*>(value);+  return a;+}++namespace dummy_filter {++static void StartTransportStreamOp(grpc_call_element* elem,+                                   grpc_transport_stream_op_batch* op) {}++static void StartTransportOp(grpc_channel_element* elem,+                             grpc_transport_op* op) {}++static grpc_error* InitCallElem(grpc_call_element* elem,+                                const grpc_call_element_args* args) {+  return GRPC_ERROR_NONE;+}++static void SetPollsetOrPollsetSet(grpc_call_element* elem,+                                   grpc_polling_entity* pollent) {}++static void DestroyCallElem(grpc_call_element* elem,+                            const grpc_call_final_info* final_info,+                            grpc_closure* then_sched_closure) {}++grpc_error* InitChannelElem(grpc_channel_element* elem,+                            grpc_channel_element_args* args) {+  return GRPC_ERROR_NONE;+}++void DestroyChannelElem(grpc_channel_element* elem) {}++void GetChannelInfo(grpc_channel_element* elem,+                    const grpc_channel_info* channel_info) {}++static const grpc_channel_filter dummy_filter = {StartTransportStreamOp,+                                                 StartTransportOp,+                                                 0,+                                                 InitCallElem,+                                                 SetPollsetOrPollsetSet,+                                                 DestroyCallElem,+                                                 0,+                                                 InitChannelElem,+                                                 DestroyChannelElem,+                                                 GetChannelInfo,+                                                 ""dummy_filter""};++}  // namespace dummy_filter++namespace dummy_transport {++/* Memory required for a single stream element - this is allocated by upper+   layers and initialized by the transport */+size_t sizeof_stream; /* = sizeof(transport stream) */++/* name of this transport implementation */+const char* name;++/* implementation of grpc_transport_init_stream */+int InitStream(grpc_transport* self, grpc_stream* stream,+               grpc_stream_refcount* refcount, const void* server_data,+               gpr_arena* arena) {+  return 0;+}++/* implementation of grpc_transport_set_pollset */+void SetPollset(grpc_transport* self, grpc_stream* stream,+                grpc_pollset* pollset) {}++/* implementation of grpc_transport_set_pollset */+void SetPollsetSet(grpc_transport* self, grpc_stream* stream,+                   grpc_pollset_set* pollset_set) {}++/* implementation of grpc_transport_perform_stream_op */+void PerformStreamOp(grpc_transport* self, grpc_stream* stream,+                     grpc_transport_stream_op_batch* op) {+  GRPC_CLOSURE_SCHED(op->on_complete, GRPC_ERROR_NONE);+}++/* implementation of grpc_transport_perform_op */+void PerformOp(grpc_transport* self, grpc_transport_op* op) {}++/* implementation of grpc_transport_destroy_stream */+void DestroyStream(grpc_transport* self, grpc_stream* stream,+                   grpc_closure* then_sched_closure) {}++/* implementation of grpc_transport_destroy */+void Destroy(grpc_transport* self) {}++/* implementation of grpc_transport_get_endpoint */+grpc_endpoint* GetEndpoint(grpc_transport* self) { return nullptr; }++static const grpc_transport_vtable dummy_transport_vtable = {+    0,          ""dummy_http2"", InitStream,+    SetPollset, SetPollsetSet, PerformStreamOp,+    PerformOp,  DestroyStream, Destroy,+    GetEndpoint};++static grpc_transport dummy_transport = {&dummy_transport_vtable};++}  // namespace dummy_transport++grpc_channel_args CreateFakeChannelArgs(std::vector<grpc_arg>* args,",Is this used? It looks like a duplicate of the one below,
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/15630,196247544,2018-06-18T22:40:44Z,test/cpp/microbenchmarks/filter_helpers.h,"@@ -0,0 +1,371 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/core/lib/channel/channel_stack.h""+#include ""src/core/lib/channel/connected_channel.h""+#include ""src/core/lib/iomgr/call_combiner.h""+#include ""src/core/lib/profiling/timers.h""+#include ""src/core/lib/surface/channel.h""+#include ""src/core/lib/transport/transport_impl.h""++#include ""test/cpp/microbenchmarks/helpers.h""++#define CALL_ELEMS_FROM_STACK(stk)     \+  ((grpc_call_element*)((char*)(stk) + \+                        ROUND_UP_TO_ALIGNMENT_SIZE(sizeof(grpc_call_stack))))++/* Given a size, round up to the next multiple of sizeof(void*) */+#define ROUND_UP_TO_ALIGNMENT_SIZE(x) \+  (((x) + GPR_MAX_ALIGNMENT - 1u) & ~(GPR_MAX_ALIGNMENT - 1u))++static void FilterDestroy(void* arg, grpc_error* error) { gpr_free(arg); }++static void DoNothing(void* arg, grpc_error* error) {}++class FakeClientChannelFactory : public grpc_client_channel_factory {+ public:+  FakeClientChannelFactory() { vtable = &vtable_; }++ private:+  static void NoRef(grpc_client_channel_factory* factory) {}+  static void NoUnref(grpc_client_channel_factory* factory) {}+  static grpc_subchannel* CreateSubchannel(grpc_client_channel_factory* factory,+                                           const grpc_subchannel_args* args) {+    return nullptr;+  }+  static grpc_channel* CreateClientChannel(grpc_client_channel_factory* factory,+                                           const char* target,+                                           grpc_client_channel_type type,+                                           const grpc_channel_args* args) {+    return nullptr;+  }++  static const grpc_client_channel_factory_vtable vtable_;+};++const grpc_client_channel_factory_vtable FakeClientChannelFactory::vtable_ = {+    NoRef, NoUnref, CreateSubchannel, CreateClientChannel};++static grpc_arg StringArg(const char* key, const char* value) {+  grpc_arg a;+  a.type = GRPC_ARG_STRING;+  a.key = const_cast<char*>(key);+  a.value.string = const_cast<char*>(value);+  return a;+}++namespace dummy_filter {++static void StartTransportStreamOp(grpc_call_element* elem,+                                   grpc_transport_stream_op_batch* op) {}++static void StartTransportOp(grpc_channel_element* elem,+                             grpc_transport_op* op) {}++static grpc_error* InitCallElem(grpc_call_element* elem,+                                const grpc_call_element_args* args) {+  return GRPC_ERROR_NONE;+}++static void SetPollsetOrPollsetSet(grpc_call_element* elem,+                                   grpc_polling_entity* pollent) {}++static void DestroyCallElem(grpc_call_element* elem,+                            const grpc_call_final_info* final_info,+                            grpc_closure* then_sched_closure) {}++grpc_error* InitChannelElem(grpc_channel_element* elem,+                            grpc_channel_element_args* args) {+  return GRPC_ERROR_NONE;+}++void DestroyChannelElem(grpc_channel_element* elem) {}++void GetChannelInfo(grpc_channel_element* elem,+                    const grpc_channel_info* channel_info) {}++static const grpc_channel_filter dummy_filter = {StartTransportStreamOp,+                                                 StartTransportOp,+                                                 0,+                                                 InitCallElem,+                                                 SetPollsetOrPollsetSet,+                                                 DestroyCallElem,+                                                 0,+                                                 InitChannelElem,+                                                 DestroyChannelElem,+                                                 GetChannelInfo,+                                                 ""dummy_filter""};++}  // namespace dummy_filter++namespace dummy_transport {++/* Memory required for a single stream element - this is allocated by upper+   layers and initialized by the transport */+size_t sizeof_stream; /* = sizeof(transport stream) */++/* name of this transport implementation */+const char* name;++/* implementation of grpc_transport_init_stream */+int InitStream(grpc_transport* self, grpc_stream* stream,+               grpc_stream_refcount* refcount, const void* server_data,+               gpr_arena* arena) {+  return 0;+}++/* implementation of grpc_transport_set_pollset */+void SetPollset(grpc_transport* self, grpc_stream* stream,+                grpc_pollset* pollset) {}++/* implementation of grpc_transport_set_pollset */+void SetPollsetSet(grpc_transport* self, grpc_stream* stream,+                   grpc_pollset_set* pollset_set) {}++/* implementation of grpc_transport_perform_stream_op */+void PerformStreamOp(grpc_transport* self, grpc_stream* stream,+                     grpc_transport_stream_op_batch* op) {+  GRPC_CLOSURE_SCHED(op->on_complete, GRPC_ERROR_NONE);+}++/* implementation of grpc_transport_perform_op */+void PerformOp(grpc_transport* self, grpc_transport_op* op) {}++/* implementation of grpc_transport_destroy_stream */+void DestroyStream(grpc_transport* self, grpc_stream* stream,+                   grpc_closure* then_sched_closure) {}++/* implementation of grpc_transport_destroy */+void Destroy(grpc_transport* self) {}++/* implementation of grpc_transport_get_endpoint */+grpc_endpoint* GetEndpoint(grpc_transport* self) { return nullptr; }++static const grpc_transport_vtable dummy_transport_vtable = {+    0,          ""dummy_http2"", InitStream,+    SetPollset, SetPollsetSet, PerformStreamOp,+    PerformOp,  DestroyStream, Destroy,+    GetEndpoint};++static grpc_transport dummy_transport = {&dummy_transport_vtable};++}  // namespace dummy_transport++grpc_channel_args CreateFakeChannelArgs(std::vector<grpc_arg>* args,+                                        FakeClientChannelFactory* factory) {+  args->push_back(grpc_client_channel_factory_create_channel_arg(factory));+  args->push_back(StringArg(GRPC_ARG_SERVER_URI, ""localhost""));+  return {args->size(), args->data()};+}++enum FilterFixtureFlags : uint32_t {+  CHECKS_NOT_LAST = 1,+  REQUIRES_TRANSPORT = 2,+};++template <const grpc_channel_filter* kFilter, uint32_t kFlags>+struct FilterFixture {+  const grpc_channel_filter* filter = kFilter;+  const uint32_t flags = kFlags;+};++// Generic data needed for each filter microbenchmark+struct DataForFilterBM {+  std::vector<const grpc_channel_filter*> filters;+  grpc_channel_args channel_args;+  grpc_channel_stack* channel_stack;+  grpc_call_stack* call_stack;+  grpc_call_element_args call_args;+};++template <class FilterFixture>+class FilterBM {+ public:+  FilterBM()+      : fixture(), track_counters(), label(), args(), exec_ctx(), factory() {}++  // Creates all necessary data and structures for the filter microbenchmark+  void Setup(struct DataForFilterBM* data) {+    data->channel_args = CreateFakeChannelArgs();+    MaybeAddFilterToStack(&data->filters);+    data->channel_stack =+        ConstructChannelStack(&data->filters, &data->channel_args);+    data->call_stack = static_cast<grpc_call_stack*>(+        gpr_zalloc(data->channel_stack->call_stack_size));+    SetCallArgs(&data->call_args, data->call_stack);+  }++  // Call this at the end of the benchmark for cleanup+  void Destroy(struct DataForFilterBM* data, benchmark::State& state) {+    gpr_arena_destroy(data->call_args.arena);+    grpc_channel_stack_destroy(data->channel_stack);++    gpr_free(data->channel_stack);+    gpr_free(data->call_stack);++    state.SetLabel(label.str());+    track_counters.Finish(state);+  }++  FilterFixture fixture;+  const int kArenaSize = 4096;+  TrackCounters track_counters;+  std::ostringstream label;++ private:+  // Caller is responsible for freeing the returned grpc_channel_stack*+  grpc_channel_stack* ConstructChannelStack(+      std::vector<const grpc_channel_filter*>* filters,+      grpc_channel_args* channel_args) {+    size_t channel_size =+        grpc_channel_stack_size(filters->data(), filters->size());+    grpc_channel_stack* channel_stack =+        static_cast<grpc_channel_stack*>(gpr_zalloc(channel_size));+    GPR_ASSERT(GRPC_LOG_IF_ERROR(+        ""channel_stack_init"",+        grpc_channel_stack_init(1, FilterDestroy, channel_stack,+                                filters->data(), filters->size(), channel_args,+                                fixture.flags & REQUIRES_TRANSPORT+                                    ? &dummy_transport::dummy_transport+                                    : nullptr,+                                ""CHANNEL"", channel_stack)));+    grpc_core::ExecCtx::Get()->Flush();+    return channel_stack;+  }++  grpc_channel_args CreateFakeChannelArgs() {+    args.push_back(grpc_client_channel_factory_create_channel_arg(&factory));+    args.push_back(StringArg(GRPC_ARG_SERVER_URI, ""localhost""));+    return {args.size(), args.data()};+  }++  // If the filter in FilterFixture is not null, then add it to the filter stack+  // and add a dummy filter to the appropriate place in the stack.+  void MaybeAddFilterToStack(+      std::vector<const grpc_channel_filter*>* filter_stack) {+    if (fixture.filter == nullptr) {+      return;+    }+    filter_stack->push_back(fixture.filter);+    if (fixture.flags & CHECKS_NOT_LAST) {+      // This filter cannot be last in the stack, so we must append a dummy+      // filter after it to appease it.+      filter_stack->push_back(&dummy_filter::dummy_filter);+    } else {+      // This filter must be last on the stack. In order to be consistent with+      // the other benchmarked filters, we add a dummy filter onto the stack.+      filter_stack->insert(filter_stack->begin(), &dummy_filter::dummy_filter);+    }+  }++  void SetCallArgs(grpc_call_element_args* call_args,+                   grpc_call_stack* call_stack) {+    grpc_millis deadline = GRPC_MILLIS_INF_FUTURE;+    gpr_timespec start_time = gpr_now(GPR_CLOCK_MONOTONIC);+    grpc_slice method = grpc_slice_from_static_string(""/foo/bar"");++    call_args->call_stack = call_stack;+    call_args->server_transport_data = nullptr;+    call_args->context = nullptr;+    call_args->path = method;+    call_args->start_time = start_time;+    call_args->deadline = deadline;+    call_args->arena = gpr_arena_create(kArenaSize);+  }++  std::vector<grpc_arg> args;+  grpc_core::ExecCtx exec_ctx;+  FakeClientChannelFactory factory;+};++// Generic data needed for batch payloads in these microbenchmarks+struct PayloadData {+  grpc_metadata_batch metadata_batch_send_init;+  grpc_metadata_batch metadata_batch_recv_init;+  grpc_metadata_batch metadata_batch_send_trailing;+  grpc_metadata_batch metadata_batch_recv_trailing;++  gpr_atm peer_address_atm;++  uint32_t recv_flags;++  grpc_core::OrphanablePtr<grpc_core::ByteStream> op;++  grpc_transport_stream_stats stats;++  grpc_core::ManualConstructor<grpc_core::SliceBufferByteStream>+      byte_stream_send;+  grpc_slice_buffer slice_buffer_send;+  grpc_slice_buffer slice_buffer_recv;++  grpc_transport_stream_op_batch_payload payload;+};++// Initializes the payload such that filters won't complain when we send+// all 6 ops down the filter stack+void CreatePayloadForAllOps(struct PayloadData* data) {+  grpc_transport_stream_op_batch_payload* payload = &data->payload;++  memset(data, 0, sizeof(struct PayloadData));++  grpc_metadata_batch_init(&data->metadata_batch_send_init);+  grpc_metadata_batch_init(&data->metadata_batch_recv_init);+  grpc_metadata_batch_init(&data->metadata_batch_send_trailing);+  grpc_metadata_batch_init(&data->metadata_batch_recv_trailing);+  payload->send_initial_metadata.send_initial_metadata =+      &data->metadata_batch_send_init;+  payload->send_trailing_metadata.send_trailing_metadata =+      &data->metadata_batch_send_trailing;+  payload->recv_initial_metadata.recv_initial_metadata =+      &data->metadata_batch_recv_init;+  payload->recv_trailing_metadata.recv_trailing_metadata =+      &data->metadata_batch_recv_trailing;++  payload->recv_initial_metadata.recv_flags = &data->recv_flags;+  payload->recv_initial_metadata.peer_string = &data->peer_address_atm;+  std::string peer_address_string = ""Unknown."";+  gpr_atm_rel_store(payload->recv_initial_metadata.peer_string,+                    (gpr_atm)gpr_strdup(peer_address_string.data()));+  payload->recv_message.recv_message = &data->op;++  payload->collect_stats.collect_stats = &data->stats;++  grpc_slice_buffer_init(&data->slice_buffer_send);+  data->byte_stream_send.Init(&data->slice_buffer_send, 0);+  payload->send_message.send_message.reset(data->byte_stream_send.get());++  grpc_slice_buffer_init(&data->slice_buffer_recv);+  grpc_core::SliceBufferByteStream* sbs =",This is usually allocated by the transport. Could you allocated it in the dummy transport to make this more realistic? I think that should work,
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/15630,196271406,2018-06-19T01:24:11Z,test/cpp/microbenchmarks/bm_filters.cc,"@@ -0,0 +1,200 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <benchmark/benchmark.h>+#include <string.h>+#include <sstream>++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/string_util.h>+#include <grpcpp/channel.h>+#include <grpcpp/support/channel_arguments.h>++#include ""src/core/ext/filters/client_channel/client_channel.h""+#include ""src/core/ext/filters/deadline/deadline_filter.h""+#include ""src/core/ext/filters/http/client/http_client_filter.h""+#include ""src/core/ext/filters/http/message_compress/message_compress_filter.h""+#include ""src/core/ext/filters/http/server/http_server_filter.h""+#include ""src/core/ext/filters/load_reporting/server_load_reporting_filter.h""+#include ""src/core/ext/filters/message_size/message_size_filter.h""+#include ""src/core/lib/gprpp/manual_constructor.h""++#include ""src/cpp/client/create_channel_internal.h""+#include ""src/proto/grpc/testing/echo.grpc.pb.h""+#include ""test/cpp/microbenchmarks/filter_helpers.h""+#include ""test/cpp/util/test_config.h""++auto& force_library_initialization = Library::get();++// Test a filter's call stack init in isolation. FilterBM, in conjunction with+// FilterFixture, specifies the filter under test (use the FilterBM<> template+// to specify this).+// Note that there is some other work being done within the benchmarking loop,+// so the result of this microbenchmark is a little bloated.+template <class FilterBM>+static void BM_CallStackInit(benchmark::State& state) {+  // Setup for benchmark+  FilterBM bm_setup;+  struct DataForFilterBM data;+  bm_setup.Setup(&data);++  // Run the benchmark+  grpc_call_final_info final_info;+  while (state.KeepRunning()) {+    GPR_TIMER_SCOPE(""BenchmarkCycle"", 0);+    GRPC_ERROR_UNREF(grpc_call_stack_init(data.channel_stack, 1, DoNothing,+                                          nullptr, &data.call_args));+    grpc_call_stack_destroy(data.call_stack, &final_info, nullptr);+    // Recreate arena every 64k iterations to avoid oom+    if (0 == (state.iterations() & 0xffff)) {+      gpr_arena_destroy(data.call_args.arena);+      data.call_args.arena = gpr_arena_create(bm_setup.kArenaSize);+    }+  }++  bm_setup.Destroy(&data, state);+}++typedef FilterFixture<nullptr, 0> NoFilter;+typedef FilterBM<NoFilter> NoFilterBM;+BENCHMARK_TEMPLATE(BM_CallStackInit, NoFilterBM);++typedef FilterFixture<&dummy_filter::dummy_filter, 0> DummyFilter;+typedef FilterBM<DummyFilter> DummyFilterBM;+BENCHMARK_TEMPLATE(BM_CallStackInit, DummyFilterBM);++typedef FilterFixture<&grpc_client_channel_filter, 0> ClientChannelFilter;+typedef FilterBM<ClientChannelFilter> ClientChannelFilterBM;+BENCHMARK_TEMPLATE(BM_CallStackInit, ClientChannelFilterBM);++typedef FilterFixture<&grpc_message_compress_filter, CHECKS_NOT_LAST>+    CompressFilter;+typedef FilterBM<CompressFilter> CompressFilterBM;+BENCHMARK_TEMPLATE(BM_CallStackInit, CompressFilterBM);++typedef FilterFixture<&grpc_client_deadline_filter, CHECKS_NOT_LAST>+    ClientDeadlineFilter;+typedef FilterBM<ClientDeadlineFilter> ClientDeadlineFilterBM;+BENCHMARK_TEMPLATE(BM_CallStackInit, ClientDeadlineFilterBM);++typedef FilterFixture<&grpc_server_deadline_filter, CHECKS_NOT_LAST>+    ServerDeadlineFilter;+typedef FilterBM<ServerDeadlineFilter> ServerDeadlineFilterBM;+BENCHMARK_TEMPLATE(BM_CallStackInit, ServerDeadlineFilterBM);++typedef FilterFixture<&grpc_http_client_filter,+                      CHECKS_NOT_LAST | REQUIRES_TRANSPORT>+    HttpClientFilter;+typedef FilterBM<HttpClientFilter> HttpClientFilterBM;+BENCHMARK_TEMPLATE(BM_CallStackInit, HttpClientFilterBM);++typedef FilterFixture<&grpc_http_server_filter, CHECKS_NOT_LAST>+    HttpServerFilter;+typedef FilterBM<HttpServerFilter> HttpServerFilterBM;+BENCHMARK_TEMPLATE(BM_CallStackInit, HttpServerFilterBM);++typedef FilterFixture<&grpc_message_size_filter, CHECKS_NOT_LAST>+    MessageSizeFilter;+typedef FilterBM<MessageSizeFilter> MessageSizeFilterBM;+BENCHMARK_TEMPLATE(BM_CallStackInit, MessageSizeFilterBM);++typedef FilterFixture<&grpc_server_load_reporting_filter, CHECKS_NOT_LAST>+    ServerLoadReportingFilter;+typedef FilterBM<ServerLoadReportingFilter> ServerLoadReportingFilterBM;+BENCHMARK_TEMPLATE(BM_CallStackInit, ServerLoadReportingFilterBM);++// Measure full filter functionality overhead, from initializing the call stack+// through running all filter callbacks.+// Note that all we do is send down all 6 ops through the filter stack; we do+// not test different combinations or subsets of ops. Thus, this test does not+// comprehensively test all the code paths of each individual filter because+// filters may take different code paths based on the combination and/or+// ordering of the ops.+template <class FilterBM>+static void BM_FullFilterFunctionality(benchmark::State& state) {+  // Setup for benchmark+  FilterBM bm_setup;+  struct DataForFilterBM data;+  bm_setup.Setup(&data);++  // Run the benchmark+  while (state.KeepRunning()) {+    GPR_TIMER_SCOPE(""BenchmarkCycle"", 0);+    // Because it's not valid to send more than one of any of the {send, recv}_+    // {initial, trailing}_metadata ops on a single call, we need to construct+    // a new call stack each time through the loop. It's also not valid to have+    // more than one of send_message or recv_message in flight on a single call+    // at the same time.+    memset(data.call_stack, 0, data.channel_stack->call_stack_size);+    GRPC_ERROR_UNREF(grpc_call_stack_init(data.channel_stack, 1, DoNothing,+                                          nullptr, &data.call_args));++    struct PayloadData payload;+    CreatePayloadForAllOps(&payload);++    grpc_transport_stream_op_batch batch;+    CreateBatchWithAllOps(&batch, &payload.payload);++    grpc_call_element* call_elem =+        CALL_ELEMS_FROM_STACK(data.call_args.call_stack);+    if (!data.filters.empty()) {+      bm_setup.fixture.filter->start_transport_stream_op_batch(call_elem,+                                                               &batch);+    }++    GRPC_CLOSURE_RUN(batch.on_complete, GRPC_ERROR_NONE);","The dummy transport shouldn't be invoked in these microbenchmarks because it's not added to the synthetic ""filter stack"". It only exists in these microbenchmarks because some filters need to access data in the transport. A pointer to the dummy transport gets passed in to grpc_channel_stack_init as the ""optional transport"" parameter, but that shouldn't register the dummy transport as the transport layer.",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/15630,196271455,2018-06-19T01:24:29Z,test/cpp/microbenchmarks/bm_filters.cc,"@@ -0,0 +1,200 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <benchmark/benchmark.h>+#include <string.h>+#include <sstream>++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/string_util.h>+#include <grpcpp/channel.h>+#include <grpcpp/support/channel_arguments.h>++#include ""src/core/ext/filters/client_channel/client_channel.h""+#include ""src/core/ext/filters/deadline/deadline_filter.h""+#include ""src/core/ext/filters/http/client/http_client_filter.h""+#include ""src/core/ext/filters/http/message_compress/message_compress_filter.h""+#include ""src/core/ext/filters/http/server/http_server_filter.h""+#include ""src/core/ext/filters/load_reporting/server_load_reporting_filter.h""+#include ""src/core/ext/filters/message_size/message_size_filter.h""+#include ""src/core/lib/gprpp/manual_constructor.h""++#include ""src/cpp/client/create_channel_internal.h""+#include ""src/proto/grpc/testing/echo.grpc.pb.h""+#include ""test/cpp/microbenchmarks/filter_helpers.h""+#include ""test/cpp/util/test_config.h""++auto& force_library_initialization = Library::get();++// Test a filter's call stack init in isolation. FilterBM, in conjunction with+// FilterFixture, specifies the filter under test (use the FilterBM<> template+// to specify this).+// Note that there is some other work being done within the benchmarking loop,+// so the result of this microbenchmark is a little bloated.+template <class FilterBM>+static void BM_CallStackInit(benchmark::State& state) {+  // Setup for benchmark+  FilterBM bm_setup;+  struct DataForFilterBM data;+  bm_setup.Setup(&data);","Yes, and that would require the struct DataForFilterBM to live inside FilterBM. Doing so would eliminate a few of lines of code duplication and would make it easier for the microbenchmark author to not have to worry about calling the setup / cleanup functions. The reason why I didn't do this was because each microbenchmark does a lot of direct manipulation and accessing of the stuff inside DataForFilterBM, so it felt awkward to put it inside FilterBM and claim that FilterBM owns it.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/15796,196442188,2018-06-19T14:16:07Z,tools/run_tests/run_tests.py,"@@ -1591,7 +1591,8 @@ def make_jobspec(cfg, targets, makefile='Makefile'):             jobset.JobSpec(                 [                     'cmake', '--build', '.', '--target',-                    '%s' % target, '--config', _MSBUILD_CONFIG[cfg]+                    '%s' % target, '--config', _MSBUILD_CONFIG[cfg],+                    '--', '/maxcpucount:%d' % args.jobs,",does `-- /maxcpucount:%d' imply that the argument is passed directly to msbuild?my concern is that might not work if other generators are used (e.g. Ninja).  Isn't there a standard way to set parallelism in cmake?,
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/15630,196485888,2018-06-19T16:02:17Z,test/cpp/microbenchmarks/bm_filters.cc,"@@ -0,0 +1,200 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <benchmark/benchmark.h>+#include <string.h>+#include <sstream>++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/string_util.h>+#include <grpcpp/channel.h>+#include <grpcpp/support/channel_arguments.h>++#include ""src/core/ext/filters/client_channel/client_channel.h""+#include ""src/core/ext/filters/deadline/deadline_filter.h""+#include ""src/core/ext/filters/http/client/http_client_filter.h""+#include ""src/core/ext/filters/http/message_compress/message_compress_filter.h""+#include ""src/core/ext/filters/http/server/http_server_filter.h""+#include ""src/core/ext/filters/load_reporting/server_load_reporting_filter.h""+#include ""src/core/ext/filters/message_size/message_size_filter.h""+#include ""src/core/lib/gprpp/manual_constructor.h""++#include ""src/cpp/client/create_channel_internal.h""+#include ""src/proto/grpc/testing/echo.grpc.pb.h""+#include ""test/cpp/microbenchmarks/filter_helpers.h""+#include ""test/cpp/util/test_config.h""++auto& force_library_initialization = Library::get();++// Test a filter's call stack init in isolation. FilterBM, in conjunction with+// FilterFixture, specifies the filter under test (use the FilterBM<> template+// to specify this).+// Note that there is some other work being done within the benchmarking loop,+// so the result of this microbenchmark is a little bloated.+template <class FilterBM>+static void BM_CallStackInit(benchmark::State& state) {+  // Setup for benchmark+  FilterBM bm_setup;+  struct DataForFilterBM data;+  bm_setup.Setup(&data);","Not necessarily:The ctor could look like:```template <class FilterFixture>class FilterBM { public:  FilterBM(struct DataForFilterBM* data)      : fixture(), track_counters(), label(), args(), exec_ctx(), factory() {    data->channel_args = CreateFakeChannelArgs();    // etc etc etc  }};```Then, in the benchmark:```struct DataForFilterBM data;FilterBM bm_setup(&data);```",
5195749,TeBoring,https://api.github.com/repos/grpc/grpc/pulls/15779,196497368,2018-06-19T16:38:21Z,src/php/lib/Grpc/Interceptor.php,"@@ -21,46 +21,52 @@  /**  * Represents an interceptor that intercept RPC invocations before call starts.+ * There is one proposal related to the argument $deserialize under the review.+ * The proposal link is https://github.com/grpc/proposal/pull/86.  * This is an EXPERIMENTAL API.  */ class Interceptor {     public function interceptUnaryUnary(         $method,         $argument,+        $deserialize,",Do you need to move this parameter to the end and provide a default value in order not to break existing users?,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/12656,196546597,2018-06-19T19:16:45Z,src/python/grpcio/grpc/_cython/_cygrpc/credentials.pyx.pxi,"@@ -126,28 +126,69 @@ cdef class SSLSessionCacheLRU:     grpc_shutdown()  +cdef int verify_peer_callback_wrapper(const char* servername, const char* cert, void* userdata) with gil:",How long is this line horizontally? I think you may need to line-wrap immediately after the opening parenthesis.(Sorry that we don't have an autoformatter running on our Cython code!),
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/12656,196546764,2018-06-19T19:17:23Z,src/python/grpcio/grpc/_cython/_cygrpc/credentials.pyx.pxi,"@@ -126,28 +126,69 @@ cdef class SSLSessionCacheLRU:     grpc_shutdown()  +cdef int verify_peer_callback_wrapper(const char* servername, const char* cert, void* userdata) with gil:+  if userdata == NULL:+    print(""Error! Callback function wasn't set!"")",`print`? From the Cython code? Rather than a logging statement or raising an exception?,
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/12656,196547485,2018-06-19T19:20:05Z,src/python/grpcio/grpc/_cython/_cygrpc/credentials.pyx.pxi,"@@ -126,28 +126,69 @@ cdef class SSLSessionCacheLRU:     grpc_shutdown()  +cdef int verify_peer_callback_wrapper(const char* servername, const char* cert, void* userdata) with gil:+  if userdata == NULL:+    print(""Error! Callback function wasn't set!"")+    return 1+  fn = <object>userdata+  py_servername = None+  if servername != NULL:+    py_servername = <object>servername+  py_cert = None+  if cert != NULL:+    py_cert = <object>cert+  try:+    result = fn(py_servername, py_cert)+    if result:+      return 0+    return 1+  except Exception:+    return 1+++cdef void verify_peer_callback_destruct(void *userdata) with gil:+  fn = <object>userdata",Local field doesn't justify its existence - just use `<object>user_data` on the next line.,
8943572,carl-mastrangelo,https://api.github.com/repos/grpc/grpc/pulls/15802,196580487,2018-06-19T21:13:21Z,CONCEPTS.md,"@@ -0,0 +1,63 @@+# gRPC Concepts Overview++Remote Procedure Calls (RPCs) provide a useful abstraction for building+distributed applications and services. The libraries in this repository+provide a concrete implementation of the gRPC protocol, layered over HTTP/2.+These libraries enable communication between clients and servers using any+combination of the supported languages.+++## Interface+++Developers using gRPC typically start with the description of an RPC service+(a collection of methods), and generate client and server side interfaces+which they use on the client-side and implement on the server side.++By default, gRPC uses [Protocol Buffers](https://github.com/google/protobuf) as the+Interface Definition Language (IDL) for describing both the service interface+and the structure of the payload messages. It is possible to use other+alternatives if desired.++### Surface API+Starting from an interface definition in a .proto file, gRPC provides+Protocol Compiler plugins that generate Client- and Server-side APIs.+gRPC users typically call into these APIs on the Client side and implement","nit: I would make these statements stronger, and thus avoid words like ""typically"".  While technically correct, I would claim that a reader of this page is looking to be told what to do.  Once they are more comfortable with gRPC they can branch out.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/15630,196626834,2018-06-20T01:37:57Z,test/cpp/microbenchmarks/bm_filters.cc,"@@ -0,0 +1,200 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <benchmark/benchmark.h>+#include <string.h>+#include <sstream>++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/string_util.h>+#include <grpcpp/channel.h>+#include <grpcpp/support/channel_arguments.h>++#include ""src/core/ext/filters/client_channel/client_channel.h""+#include ""src/core/ext/filters/deadline/deadline_filter.h""+#include ""src/core/ext/filters/http/client/http_client_filter.h""+#include ""src/core/ext/filters/http/message_compress/message_compress_filter.h""+#include ""src/core/ext/filters/http/server/http_server_filter.h""+#include ""src/core/ext/filters/load_reporting/server_load_reporting_filter.h""+#include ""src/core/ext/filters/message_size/message_size_filter.h""+#include ""src/core/lib/gprpp/manual_constructor.h""++#include ""src/cpp/client/create_channel_internal.h""+#include ""src/proto/grpc/testing/echo.grpc.pb.h""+#include ""test/cpp/microbenchmarks/filter_helpers.h""+#include ""test/cpp/util/test_config.h""++auto& force_library_initialization = Library::get();++// Test a filter's call stack init in isolation. FilterBM, in conjunction with+// FilterFixture, specifies the filter under test (use the FilterBM<> template+// to specify this).+// Note that there is some other work being done within the benchmarking loop,+// so the result of this microbenchmark is a little bloated.+template <class FilterBM>+static void BM_CallStackInit(benchmark::State& state) {+  // Setup for benchmark+  FilterBM bm_setup;+  struct DataForFilterBM data;+  bm_setup.Setup(&data);","Actually, now that we are talking style, any reason for the separate struct DataForFilterBM? Why couldn't all of those data be members in FilterBM? It sees like FilterBM logically owns them since it is initializing and destroying them",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/15796,196659867,2018-06-20T06:25:07Z,tools/run_tests/run_tests.py,"@@ -1590,8 +1590,15 @@ def make_jobspec(cfg, targets, makefile='Makefile'):         return [             jobset.JobSpec(                 [-                    'cmake', '--build', '.', '--target',-                    '%s' % target, '--config', _MSBUILD_CONFIG[cfg]+                    'cmake',+                    '--build',+                    '.',+                    '--target',+                    '%s' % target,+                    '--config',+                    _MSBUILD_CONFIG[cfg],+                    '--',+                    '/maxcpucount:%d' % args.jobs,",Can you reply to this question? (it got lost in sanity fixes).does `-- /maxcpucount:%d' imply that the argument is passed directly to msbuild?my concern is that might not work if other generators are used (e.g. Ninja). Isn't there a standard way to set parallelism in cmake?,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/15802,196791389,2018-06-20T14:03:29Z,README.md,"@@ -1,24 +1,77 @@-[gRPC - An RPC library and framework](http://github.com/grpc/grpc)+gRPC - An RPC library and framework =================================== +gRPC is a modern, open source, high-performance remote procedure call (RPC) framework that can run anywhere. It enables client and server applications to communicate transparently, and makes it easier to build connected systems.++<table>+  <tr>+    <td><b>Homepage:</b></td>+    <td><a href=""https://grpc.io/"">grpc.io</a></td>+  </tr>+  <tr>+    <td><b>Mailing List:</b></td>+    <td><a href=""https://groups.google.com/forum/#!forum/grpc-io"">grpc-io@googlegroups.com</a></td>+  </tr>+</table>+ [![Join the chat at https://gitter.im/grpc/grpc](https://badges.gitter.im/grpc/grpc.svg)](https://gitter.im/grpc/grpc?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge) -Copyright 2015-[The gRPC Authors](https://github.com/grpc/grpc/blob/master/AUTHORS)+# To start using gRPC++To maximize usability, gRPC supports the standard way of adding dependencies in your language of choice (if there is one).+In most languages, the gRPC runtime comes in form of a package available in your language's package manager.+For instructions on how to use the language-specific gRPC runtime in your project, please refer to these documents++ * [C++](src/cpp): follow the instructions under the `src/cpp` directory+ * [C#](src/csharp): NuGet package `Grpc`+ * [Dart](https://github.com/grpc/grpc-dart): pub package `grpc`+ * [Go](https://github.com/grpc/grpc-go): `go get google.golang.org/grpc`+ * [Java](https://github.com/grpc/grpc-java): Use JARs from Maven Central Repository+ * [Node](https://github.com/grpc/grpc-node): `npm install grpc`+ * [Objective-C](src/objective-c): Add `gRPC-ProtoRPC` dependency to podspec+ * [PHP](src/php): `pecl install grpc`+ * [Python](src/python/grpcio): `pip install grpcio`+ * [Ruby](src/ruby): `gem install grpc`+ * [WebJS](https://github.com/grpc/grpc-web): follow the grpc-web instructions++You can find per-language quickstart guides and tutorials in [Documentation section on grpc.io website](https://grpc.io/docs/). The code examples are available in the [examples](examples) directory.++# To start developing gRPC++First of all, please refer to the documentation under the `src/YOUR_LANGUAGE` directory for any language-specific instructions on how to build and how to setup your+development environment.++Different languages use different build systems. To hide the complexity of needing to build with many different build systems, we provide a portable python script that unifies+the experience of building and testing gRPC in different languages and on different platforms. -# Documentation+To build gRPC in the language of choice (e.g. `c++`, `csharp`, `php`, `python`, `ruby`, ...)+- Prepare you development environment based on language-specific+  instructions+- Run+  ```+  python tools/run_tests/run_tests.py -l YOUR_LANGUAGE --build_only","Actually, I was able to use the run_tests.py script for building on a fresh GCE instance (Debian 9) without installing any extra python module (we recently removed the implicit dependency on google-api-client-python).But I agree in general, let's check if any more dependencies are needed and add them to the docs - I was planning to do one more pass once restructuring the .md files is done.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/15802,196797513,2018-06-20T14:19:40Z,BUILDING.md,"@@ -77,48 +75,48 @@ $ cd grpc/third_party/protobuf $ sudo make install   # 'make' should have been run by core grpc ``` -# Build from Source+# Clone the repository (including submodules) -For developers who are interested to contribute, the following commands show how to compile the-gRPC C Core library.+Before building, you need to clone the gRPC github repository and download submodules containing source code +for gRPC's dependencies (that's done by the `submodule` command or `--recursive` flag). The following commands will clone the gRPC+repository at the latest stable version.++## Unix  ```sh  $ git clone -b $(curl -L https://grpc.io/release) https://github.com/grpc/grpc  $ cd grpc  $ git submodule update --init- $ make- $ [sudo] make install-```+ ```  ## Windows -There are several ways to build under Windows, of varying complexity depending-on experience with the tools involved.+```+> @rem You can also do just ""git clone --recursive -b THE_BRANCH_YOU_WANT https://github.com/grpc/grpc""+> powershell git clone --recursive -b ((New-Object System.Net.WebClient).DownloadString(\""https://grpc.io/release\"").Trim()) https://github.com/grpc/grpc+> cd grpc+> @rem To update submodules at later time, run ""git submodule update --init""+``` +# Build from source +## make (on UNIX systems) -### Building using CMake (RECOMMENDED)+From the grpc repository root+```sh+ $ make+ # WARNING: make doesn't provide an easy way to uninstall+ $ [sudo] make install+``` -Builds gRPC C and C++ with boringssl.-- Install Visual Studio 2015 or 2017 (Visual C++ compiler will be used).-- Install [Git](https://git-scm.com/).-- Install [CMake](https://cmake.org/download/).-- Install [Active State Perl](https://www.activestate.com/activeperl/) (`choco install activeperl`) - *required by boringssl*-- Install [Go](https://golang.org/dl/) (`choco install golang`) - *required by boringssl*-- Install [yasm](http://yasm.tortall.net/) and add it to `PATH` (`choco install yasm`) - *required by boringssl*-- (Optional) Install [Ninja](https://ninja-build.org/) (`choco install ninja`)+## bazel -#### Clone grpc sources including submodules-Before building, you need to clone the gRPC github repository and download submodules containing source code -for gRPC's dependencies (that's done by the `submodule` command).+From the grpc repository root ```-> @rem You can also do just ""git clone --recursive -b THE_BRANCH_YOU_WANT https://github.com/grpc/grpc""-> powershell git clone --recursive -b ((New-Object System.Net.WebClient).DownloadString(\""https://grpc.io/release\"").Trim()) https://github.com/grpc/grpc-> cd grpc-> @rem To update submodules at later time, run ""git submodule update --init""+bazel build :all",Link to our doc or a bazel doc on how to get this dependency?,
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/15630,196836293,2018-06-20T15:52:12Z,test/cpp/microbenchmarks/bm_filters.cc,"@@ -0,0 +1,200 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <benchmark/benchmark.h>+#include <string.h>+#include <sstream>++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/string_util.h>+#include <grpcpp/channel.h>+#include <grpcpp/support/channel_arguments.h>++#include ""src/core/ext/filters/client_channel/client_channel.h""+#include ""src/core/ext/filters/deadline/deadline_filter.h""+#include ""src/core/ext/filters/http/client/http_client_filter.h""+#include ""src/core/ext/filters/http/message_compress/message_compress_filter.h""+#include ""src/core/ext/filters/http/server/http_server_filter.h""+#include ""src/core/ext/filters/load_reporting/server_load_reporting_filter.h""+#include ""src/core/ext/filters/message_size/message_size_filter.h""+#include ""src/core/lib/gprpp/manual_constructor.h""++#include ""src/cpp/client/create_channel_internal.h""+#include ""src/proto/grpc/testing/echo.grpc.pb.h""+#include ""test/cpp/microbenchmarks/filter_helpers.h""+#include ""test/cpp/util/test_config.h""++auto& force_library_initialization = Library::get();++// Test a filter's call stack init in isolation. FilterBM, in conjunction with+// FilterFixture, specifies the filter under test (use the FilterBM<> template+// to specify this).+// Note that there is some other work being done within the benchmarking loop,+// so the result of this microbenchmark is a little bloated.+template <class FilterBM>+static void BM_CallStackInit(benchmark::State& state) {+  // Setup for benchmark+  FilterBM bm_setup;+  struct DataForFilterBM data;+  bm_setup.Setup(&data);","I guess they could, but like I said earlier, each microbenchmark does a lot of direct manipulation of the stuff inside DataForFilterBM. If I made those data members in FilterBM, then I should probably make getters and setters for each of those instead of just making them public data members. But that would be a lot of extra code for a few benchmarks, and since each microbenchmark ""sets"" the data members in a different way, I don't see the setters getting reused.Moreover, since each microbenchmark wants to do different things with DataForFilterBM (beyond the initial generic setup), I think the struct DataForFilterBM and how it gets set up is the concern of each benchmark. The concern of FilterBm is just convenience functionality applicable to all filter benchmarks. The options that seem best to me are either: 1) Move DataForFilterBM inside of FilterBM, and make it a public member variable so each benchmark can easily access/manipulate (I don't like this as much because I think each benchmark logically owns struct DataForFilterBM since so much manipulation of it is done in the benchmarking loop) 2) Leave things as they areLet me know what you think!",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/15630,196876194,2018-06-20T17:26:48Z,test/cpp/microbenchmarks/bm_filters.cc,"@@ -0,0 +1,200 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <benchmark/benchmark.h>+#include <string.h>+#include <sstream>++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/string_util.h>+#include <grpcpp/channel.h>+#include <grpcpp/support/channel_arguments.h>++#include ""src/core/ext/filters/client_channel/client_channel.h""+#include ""src/core/ext/filters/deadline/deadline_filter.h""+#include ""src/core/ext/filters/http/client/http_client_filter.h""+#include ""src/core/ext/filters/http/message_compress/message_compress_filter.h""+#include ""src/core/ext/filters/http/server/http_server_filter.h""+#include ""src/core/ext/filters/load_reporting/server_load_reporting_filter.h""+#include ""src/core/ext/filters/message_size/message_size_filter.h""+#include ""src/core/lib/gprpp/manual_constructor.h""++#include ""src/cpp/client/create_channel_internal.h""+#include ""src/proto/grpc/testing/echo.grpc.pb.h""+#include ""test/cpp/microbenchmarks/filter_helpers.h""+#include ""test/cpp/util/test_config.h""++auto& force_library_initialization = Library::get();++// Test a filter's call stack init in isolation. FilterBM, in conjunction with+// FilterFixture, specifies the filter under test (use the FilterBM<> template+// to specify this).+// Note that there is some other work being done within the benchmarking loop,+// so the result of this microbenchmark is a little bloated.+template <class FilterBM>+static void BM_CallStackInit(benchmark::State& state) {+  // Setup for benchmark+  FilterBM bm_setup;+  struct DataForFilterBM data;+  bm_setup.Setup(&data);",I am happy as long as you pick a version that fixes this pattern```BENCHMARK() {  SomeClass foo;  foo.setup(...);  while (state ....) {    ...  }  foo.destroy(...);}```Manual setup/destroy at the top/bottom of every function begs for constructor destructor,
1009310,JackOfMostTrades,https://api.github.com/repos/grpc/grpc/pulls/12656,196910016,2018-06-20T19:10:48Z,src/python/grpcio/grpc/_cython/_cygrpc/credentials.pyx.pxi,"@@ -126,28 +126,69 @@ cdef class SSLSessionCacheLRU:     grpc_shutdown()  +cdef int verify_peer_callback_wrapper(const char* servername, const char* cert, void* userdata) with gil:",This is matching the required signature of the new callback function. There's some details in the header [here](https://github.com/grpc/grpc/blob/master/include/grpc/grpc_security.h#L169).,
1009310,JackOfMostTrades,https://api.github.com/repos/grpc/grpc/pulls/12656,196910139,2018-06-20T19:11:18Z,src/python/grpcio/grpc/_cython/_cygrpc/credentials.pyx.pxi,"@@ -126,28 +126,69 @@ cdef class SSLSessionCacheLRU:     grpc_shutdown()  +cdef int verify_peer_callback_wrapper(const char* servername, const char* cert, void* userdata) with gil:+  if userdata == NULL:+    print(""Error! Callback function wasn't set!"")","Oof, I should be embarrassed. Changed that to raising an exception.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/15802,196919246,2018-06-20T19:46:08Z,README.md,"@@ -1,24 +1,79 @@-[gRPC - An RPC library and framework](http://github.com/grpc/grpc)+gRPC - An RPC library and framework",Will leave as is because grpc-java also uses lowercase.https://github.com/grpc/grpc-java/blob/3a58a9999e33452268d831da8c9ab61f533380b4/README.md,
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/15819,196924239,2018-06-20T20:03:43Z,test/distrib/python/test_packages.sh,"@@ -28,10 +28,12 @@ else   echo ""Testing Python source distribution""   ARCHIVES=(""$EXTERNAL_GIT_ROOT""/input_artifacts/grpcio-[0-9]*.tar.gz)   TOOLS_ARCHIVES=(""$EXTERNAL_GIT_ROOT""/input_artifacts/grpcio-tools-[0-9]*.tar.gz)-  HEALTH_ARCHIVES=(""$EXTERNAL_GIT_ROOT""/input_artifacts/grpcio-health-checking-[0-9]*.tar.gz)-  REFLECTION_ARCHIVES=(""$EXTERNAL_GIT_ROOT""/input_artifacts/grpcio-reflection-[0-9]*.tar.gz) fi +HEALTH_ARCHIVES=(""$EXTERNAL_GIT_ROOT""/input_artifacts/grpcio-health-checking-[0-9]*.tar.gz)","I think it's better to do it on both binary/source. Those are source-only packages so it wouldn't matter for them anyway, but our users might install them alongside the binary `grpcio` vs source `grpcio` and that might be a slightly different environment, (and the test is cheap), so I'd rather run it on every case.",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/15802,196986779,2018-06-21T01:16:13Z,CONTRIBUTING.md,"@@ -11,13 +11,34 @@ In order to protect both you and ourselves, you will need to sign the [Contributor License Agreement](https://identity.linuxfoundation.org/projects/cncf). -## Running tests+## Cloning the repository -Use `tools/run_tests/run_tests.py` script to run the unit tests.  See-[tools/run_tests](tools/run_tests) for how to run tests for a given language.+Before starting any development work you will need a local copy of the gRPC repository.+Please follow the instructions in [Building gRPC C++: Clone the repository](BUILDING.md#clone-the-repository-including-submodules). -Prerequisites for building and running tests are listed in-[INSTALL.md](INSTALL.md) and in `src/YOUR-LANGUAGE` (e.g. `src/csharp`)+## Building & Running tests++Different languages use different build systems. To hide the complexity+of needing to build with many different build systems, a portable python+script that unifies the experience of building and testing gRPC in different+languages and on different platforms is provided.++To build gRPC in the language of choice (e.g. `c++`, `csharp`, `php`, `python`, `ruby`, ...)+- Prepare you development environment based on language-specific instructions in `src/YOUR-LANGUAGE` directory.+- The language-specific instructions might involve installing C/C++ prerequisites listed in+  [Building gRPC C++: Prerequisites](BUILDING.md#pre-requisites) as gRPC implementations","This sentence takes a couple of reads to parse. I would break it up: ""The language-specific instructions might involve installing C/C++ prerequisites listed in Building gRPC C++: Prerequisites. This is because gRPC implementations in this repository are using the native gRPC ""core"" library internally.""",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/15796,197022707,2018-06-21T06:26:43Z,tools/run_tests/run_tests.py,"@@ -1590,8 +1590,15 @@ def make_jobspec(cfg, targets, makefile='Makefile'):         return [             jobset.JobSpec(                 [-                    'cmake', '--build', '.', '--target',-                    '%s' % target, '--config', _MSBUILD_CONFIG[cfg]+                    'cmake',+                    '--build',+                    '.',+                    '--target',+                    '%s' % target,+                    '--config',+                    _MSBUILD_CONFIG[cfg],+                    '--parallel',","I don't think we can depend on cmake 3.12+ in our build scripts, it is far too new.```Unknown argument --parallel```",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/15828,197348326,2018-06-22T06:05:29Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_ev_driver_posix.cc,"@@ -41,14 +41,15 @@ namespace grpc_core { class GrpcPolledFdPosix : public GrpcPolledFd {  public:   GrpcPolledFdPosix(ares_socket_t as, grpc_pollset_set* driver_pollset_set)-      : as_(as) {+      : as_(as), driver_pollset_set_(driver_pollset_set) {     gpr_asprintf(&name_, ""c-ares fd: %d"", (int)as);     fd_ = grpc_fd_create((int)as, name_, false);     grpc_pollset_set_add_fd(driver_pollset_set, fd_);   }    ~GrpcPolledFdPosix() {     gpr_free(name_);+    grpc_pollset_set_del_fd(driver_pollset_set_, fd_);","Yeah I agree, and my reason for thinking this is the right approach is by looking at ownership of the fd's: the `AresDnsResolver`'s pollset set is destroyed upon `AresDnsResolver` [destruction](https://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/resolver/dns/c_ares/dns_resolver_ares.cc#L166). The entire c-ares query, which creates the event driver and fd's, is protected by a [ref](https://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/resolver/dns/c_ares/dns_resolver_ares.cc#L411) that is released upon the query's completion. That completion begins [its scheduling](https://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc#L159) from a callback that's invoked during a call to `ares_process` on an fd though, and then remaining fd's in the driver's list are scheduled to be shut-down/cancelled/destroyed. So it would appear that the original `AresDnsResolver` might have been unref'd by the time that a <i>second</i> driver fd is destroyed. It seems tricky to test for this though...",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/15834,197350418,2018-06-22T06:22:37Z,src/ruby/lib/grpc/generic/active_call.rb,"@@ -325,15 +325,16 @@ def each_remote_read_then_finish       begin         loop do           resp = remote_read-          if resp.nil?  # the last response was received-            receive_and_check_status-            break-          end+          break if resp.nil?  # the last response was received","this looks mostly good to me, but I have a cosmetic nit:instead of wrapping the entire read loop in a `rescue` clause, can we instead wrap only `remote_read` in, for example, a separate function that itself has the `rescue CallError` clause? Such a function could return nil in the case that a `CallError` was raised, or when `remote_read` itself returned nil. This would be consistent with how this sort of thing is handled in the bidi call [read stream enumerable](https://github.com/grpc/grpc/blob/master/src/ruby/lib/grpc/generic/bidi_call.rb#L198).thanks!",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/15834,197511363,2018-06-22T17:14:00Z,src/ruby/lib/grpc/generic/active_call.rb,"@@ -325,15 +325,16 @@ def each_remote_read_then_finish       begin         loop do           resp = remote_read-          if resp.nil?  # the last response was received-            receive_and_check_status-            break-          end+          break if resp.nil?  # the last response was received","> I think this implementation would be more efficient than your suggestion.If the code wraps only remote_read, it calls unnecessary begin ~ rescue ~ end every remote_read.I'm not really worried about the efficiency of this method right now. And I'd much prefer to use small-scoped `begin` and `rescue` blocks rather for simplicity. If there are people complaining about the performance of this call, <i>and</i> there is a benchmark that shows that the `begin`/`rescue` block are causing a large penalty, then I'd be open to optimizations, but that's not the scenario currently :)> Please do not worry about it 😄. but, Would you give me the write permission to this repository?Our repo has a policy that requires every PR to get approved, even if you have write access.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/15841,197590730,2018-06-22T23:27:05Z,src/core/ext/filters/client_channel/subchannel_index.cc,"@@ -26,14 +26,24 @@ #include <grpc/support/alloc.h> #include <grpc/support/string_util.h> +#include ""src/core/ext/filters/client_channel/subchannel.h"" #include ""src/core/lib/avl/avl.h"" #include ""src/core/lib/channel/channel_args.h"" #include ""src/core/lib/gpr/tls.h""+#include ""src/core/lib/iomgr/exec_ctx.h""+#include ""src/core/lib/iomgr/timer.h""++// Sweeps unused subchannels every 10 seconds.","I think we need more documentation on this GC semantics: why are we doing sweeps, what are the guarantees regarding what will be collected, why we chose the given interval, etc. ",
35056280,srini100,https://api.github.com/repos/grpc/grpc/pulls/14650,197625581,2018-06-24T00:39:22Z,src/objective-c/NetworkTransitionBehavior.md,"@@ -0,0 +1,86 @@++# gRPC iOS Network Transition Behaviors+Network connectivity on an iOS device may transition between cellular, WIFI, or+no network connectivity. This document describes how these network changes+should be handled by gRPC and current known issues.++## Expected Network Transition Behaviors+The expected gRPC iOS channel and network transition behaviors are:+* Channel connection to a particular host is established at the time of+  starting the first call to the channel and remains connected for future calls+  to the same host.+* If the underlying connection to the remote host is broken, the channel is+  disconnected and enters TRANSIENT\_FAILURE state.+* A channel is broken if the channel connection is no longer viable. This+  happens when+    * The network interface is no longer available, e.g. WiFi or cellular+      interface is turned off or goes offline, airplane mode turned on, etc;+    * The underlying TCP connection is no longer valid, e.g. WiFi connects to another hotspot, cellular data switched from LTE to 4G, etc;+    * A network interface more preferable by the OS is valid, e.g. WiFi gets connected when the channel connects via cellular.+* A channel in TRANSIENT\_FAILURE state attempts reconnection on start of the+  next call to the same host, but only after a certain backoff period (see+  corresponding+  [doc](https://github.com/grpc/grpc/blob/master/doc/connection-backoff.md)).+  During the backoff period, any call to the same host will wait until the+  first of the following events occur:+    * Connection succeeded; calls will be made using this channel;+    * Conncetion failed; calls will be failed and return UNAVAILABLE status code;+    * The call's deadline is reached; the call will fail and return+      DEADLINE\_EXCEEDED status code.+","Is the backoff time reset when Connectivity Monitor sees network changes? If yes, it should be mentioned here. If no, then this can be an enhancement in future similar to what Okhttp in Java does.",
35056280,srini100,https://api.github.com/repos/grpc/grpc/pulls/14650,197625765,2018-06-24T00:55:57Z,src/objective-c/NetworkTransitionBehavior.md,"@@ -0,0 +1,86 @@++# gRPC iOS Network Transition Behaviors+Network connectivity on an iOS device may transition between cellular, WIFI, or+no network connectivity. This document describes how these network changes+should be handled by gRPC and current known issues.++## Expected Network Transition Behaviors+The expected gRPC iOS channel and network transition behaviors are:+* Channel connection to a particular host is established at the time of+  starting the first call to the channel and remains connected for future calls+  to the same host.+* If the underlying connection to the remote host is broken, the channel is+  disconnected and enters TRANSIENT\_FAILURE state.+* A channel is broken if the channel connection is no longer viable. This+  happens when+    * The network interface is no longer available, e.g. WiFi or cellular+      interface is turned off or goes offline, airplane mode turned on, etc;+    * The underlying TCP connection is no longer valid, e.g. WiFi connects to another hotspot, cellular data switched from LTE to 4G, etc;+    * A network interface more preferable by the OS is valid, e.g. WiFi gets connected when the channel connects via cellular.+* A channel in TRANSIENT\_FAILURE state attempts reconnection on start of the+  next call to the same host, but only after a certain backoff period (see+  corresponding+  [doc](https://github.com/grpc/grpc/blob/master/doc/connection-backoff.md)).+  During the backoff period, any call to the same host will wait until the+  first of the following events occur:+    * Connection succeeded; calls will be made using this channel;+    * Conncetion failed; calls will be failed and return UNAVAILABLE status code;+    * The call's deadline is reached; the call will fail and return+      DEADLINE\_EXCEEDED status code.++## Implementations+### gRPC iOS with TCP Sockets+gRPC's default implementation is to use TCP sockets for networking. It turns+out that although Apple supports this type of usage, it is [not recommended by+Apple](https://developer.apple.com/library/archive/documentation/NetworkingInternetWeb/Conceptual/NetworkingOverview/SocketsAndStreams/SocketsAndStreams.html)+and is also flawed.++#### TCP Sockets Issues+The TCP sockets on iOS is flawed in that it does not reflect the viability of+the channel connection. Particularly, we found the following issues related to+TCP sockets:+* When a TCP sockets connection is established on cellular data and WiFi+  becomes available, the TCP socket neither return an error event nor continue+  sending/receiving data on it, but still accepts write on it.+* The TCP sockets does not report certain events that happens in the+  background. When a TCP connection breaks in the background for the reason+  like WiFi connects to another hotspot, the socket neither return an error nor+  continue sending/receiving data on it, but still accepts write on it.++#### gRPC iOS resolutions+We introduced+[`ConnectivityMonitor`](https://developer.apple.com/library/archive/documentation/NetworkingInternetWeb/Conceptual/NetworkingOverview/SocketsAndStreams/SocketsAndStreams.html)+in gRPC iOS library to alleviate these issues in TCP sockets, which changes the+network transition behaviors a bit.++We classfy network connectivity state of the device into three categories based",classify,
35056280,srini100,https://api.github.com/repos/grpc/grpc/pulls/14650,197625766,2018-06-24T00:55:58Z,src/objective-c/NetworkTransitionBehavior.md,"@@ -0,0 +1,86 @@++# gRPC iOS Network Transition Behaviors+Network connectivity on an iOS device may transition between cellular, WIFI, or+no network connectivity. This document describes how these network changes+should be handled by gRPC and current known issues.++## Expected Network Transition Behaviors+The expected gRPC iOS channel and network transition behaviors are:+* Channel connection to a particular host is established at the time of+  starting the first call to the channel and remains connected for future calls+  to the same host.+* If the underlying connection to the remote host is broken, the channel is+  disconnected and enters TRANSIENT\_FAILURE state.+* A channel is broken if the channel connection is no longer viable. This+  happens when+    * The network interface is no longer available, e.g. WiFi or cellular+      interface is turned off or goes offline, airplane mode turned on, etc;+    * The underlying TCP connection is no longer valid, e.g. WiFi connects to another hotspot, cellular data switched from LTE to 4G, etc;+    * A network interface more preferable by the OS is valid, e.g. WiFi gets connected when the channel connects via cellular.+* A channel in TRANSIENT\_FAILURE state attempts reconnection on start of the+  next call to the same host, but only after a certain backoff period (see+  corresponding+  [doc](https://github.com/grpc/grpc/blob/master/doc/connection-backoff.md)).+  During the backoff period, any call to the same host will wait until the+  first of the following events occur:+    * Connection succeeded; calls will be made using this channel;+    * Conncetion failed; calls will be failed and return UNAVAILABLE status code;+    * The call's deadline is reached; the call will fail and return+      DEADLINE\_EXCEEDED status code.++## Implementations+### gRPC iOS with TCP Sockets+gRPC's default implementation is to use TCP sockets for networking. It turns+out that although Apple supports this type of usage, it is [not recommended by+Apple](https://developer.apple.com/library/archive/documentation/NetworkingInternetWeb/Conceptual/NetworkingOverview/SocketsAndStreams/SocketsAndStreams.html)+and is also flawed.++#### TCP Sockets Issues+The TCP sockets on iOS is flawed in that it does not reflect the viability of+the channel connection. Particularly, we found the following issues related to+TCP sockets:+* When a TCP sockets connection is established on cellular data and WiFi+  becomes available, the TCP socket neither return an error event nor continue+  sending/receiving data on it, but still accepts write on it.+* The TCP sockets does not report certain events that happens in the+  background. When a TCP connection breaks in the background for the reason+  like WiFi connects to another hotspot, the socket neither return an error nor+  continue sending/receiving data on it, but still accepts write on it.++#### gRPC iOS resolutions+We introduced+[`ConnectivityMonitor`](https://developer.apple.com/library/archive/documentation/NetworkingInternetWeb/Conceptual/NetworkingOverview/SocketsAndStreams/SocketsAndStreams.html)+in gRPC iOS library to alleviate these issues in TCP sockets, which changes the","Should mention the release in which it was introduced. Simplify the stmt ""We introduced ConnectivityMonitor in gRPC iOS library version 1.xx.y to address some issues with TCP sockets."" Also mention if it is enabled by default or not.",
35056280,srini100,https://api.github.com/repos/grpc/grpc/pulls/14650,197625872,2018-06-24T01:06:29Z,src/objective-c/NetworkTransitionBehavior.md,"@@ -0,0 +1,86 @@++# gRPC iOS Network Transition Behaviors+Network connectivity on an iOS device may transition between cellular, WIFI, or+no network connectivity. This document describes how these network changes+should be handled by gRPC and current known issues.++## Expected Network Transition Behaviors+The expected gRPC iOS channel and network transition behaviors are:+* Channel connection to a particular host is established at the time of+  starting the first call to the channel and remains connected for future calls+  to the same host.+* If the underlying connection to the remote host is broken, the channel is+  disconnected and enters TRANSIENT\_FAILURE state.+* A channel is broken if the channel connection is no longer viable. This+  happens when+    * The network interface is no longer available, e.g. WiFi or cellular+      interface is turned off or goes offline, airplane mode turned on, etc;+    * The underlying TCP connection is no longer valid, e.g. WiFi connects to another hotspot, cellular data switched from LTE to 4G, etc;+    * A network interface more preferable by the OS is valid, e.g. WiFi gets connected when the channel connects via cellular.+* A channel in TRANSIENT\_FAILURE state attempts reconnection on start of the+  next call to the same host, but only after a certain backoff period (see+  corresponding+  [doc](https://github.com/grpc/grpc/blob/master/doc/connection-backoff.md)).+  During the backoff period, any call to the same host will wait until the+  first of the following events occur:+    * Connection succeeded; calls will be made using this channel;+    * Conncetion failed; calls will be failed and return UNAVAILABLE status code;+    * The call's deadline is reached; the call will fail and return+      DEADLINE\_EXCEEDED status code.++## Implementations+### gRPC iOS with TCP Sockets+gRPC's default implementation is to use TCP sockets for networking. It turns+out that although Apple supports this type of usage, it is [not recommended by+Apple](https://developer.apple.com/library/archive/documentation/NetworkingInternetWeb/Conceptual/NetworkingOverview/SocketsAndStreams/SocketsAndStreams.html)+and is also flawed.++#### TCP Sockets Issues+The TCP sockets on iOS is flawed in that it does not reflect the viability of+the channel connection. Particularly, we found the following issues related to+TCP sockets:+* When a TCP sockets connection is established on cellular data and WiFi+  becomes available, the TCP socket neither return an error event nor continue+  sending/receiving data on it, but still accepts write on it.+* The TCP sockets does not report certain events that happens in the+  background. When a TCP connection breaks in the background for the reason+  like WiFi connects to another hotspot, the socket neither return an error nor+  continue sending/receiving data on it, but still accepts write on it.+","Should mention what does the user see due to these issues. Something like ""In both the situations, the call hangs until TCP timeout happens or the deadline is exceeded"".",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15879,198307118,2018-06-26T21:42:03Z,src/core/lib/security/transport/client_auth_filter.cc,"@@ -279,7 +280,7 @@ static void auth_start_transport_stream_op_batch(     GPR_ASSERT(batch->payload->context != nullptr);     if (batch->payload->context[GRPC_CONTEXT_SECURITY].value == nullptr) {       batch->payload->context[GRPC_CONTEXT_SECURITY].value =","It's not clear to me why this is being set in `start_transport_stream_op_batch()` in the first place.  Is there any reason we can't move this to `init_call_elem()`?  If we did that, there would be no need to store the arena pointer in the call data.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15873,198310338,2018-06-26T21:55:46Z,include/grpc/support/alloc.h,"@@ -61,6 +61,9 @@ GPRAPI void gpr_set_allocation_functions(gpr_allocation_functions functions); /** Return the family of allocation functions currently in effect. */ GPRAPI gpr_allocation_functions gpr_get_allocation_functions(void); +/** Equals the minimum memory alignment required by ABI from allocators. *.+#define GRPC_MINIMUM_ALIGNMENT (sizeof(uintptr_t) * 2)","This is only helpful in the case where the first thing you want in the allocation is smaller than this.  I'd really prefer a more general-purpose macro that rounds up any arbitrary size to the next alignment size, which we can use everywhere.  I think we already have something like this in a few places.  For example:https://github.com/grpc/grpc/blob/master/src/core/lib/surface/call.cc#L275",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/15879,198587414,2018-06-27T17:57:34Z,src/core/lib/security/transport/client_auth_filter.cc,"@@ -279,7 +280,7 @@ static void auth_start_transport_stream_op_batch(     GPR_ASSERT(batch->payload->context != nullptr);     if (batch->payload->context[GRPC_CONTEXT_SECURITY].value == nullptr) {       batch->payload->context[GRPC_CONTEXT_SECURITY].value =","Oops I thought this sent yesterday evening but I forgot the bus wifi wasn't working...here's my response.I'm not familiar enough with the logic of the code to know the reason, but just from code inspection, it looks like whether or not this is set is being used to decide what code path to take later on. start_transport_stream_op_batch calls on_host_checked if we're sending initial metadata. At this point, batch->cancel_stream may or may not be true, so batch->payload->context[GRPC_CONTEXT_SECURITY].value could be either nullptr or not nullptr. on_host_checked calls send_security_metadata, which checks if context[GRPC_CONTEXT_SECURITY].value is nullptr and goes down a different code path depending on that check. In particular, it skips sending the metadata altogether and just calls the next filter with grpc_call_next_op. Questions: 1) Can we set the batch's payload in init_call_elem? 2) In what cases do we want the context[GRPC_CONTEXT_SECURITY].value to be nullptr and what does it signify? And can / should the code concerning this be reorganized? The person who can probably best answer question 2 is on vacation right now.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15879,198598906,2018-06-27T18:33:43Z,src/core/lib/security/transport/client_auth_filter.cc,"@@ -279,7 +280,7 @@ static void auth_start_transport_stream_op_batch(     GPR_ASSERT(batch->payload->context != nullptr);     if (batch->payload->context[GRPC_CONTEXT_SECURITY].value == nullptr) {       batch->payload->context[GRPC_CONTEXT_SECURITY].value =","We can't set the batch's payload in `init_call_elem()`, but I don't think we need to.  We can set the call's context there, which is available in `args->context`.I don't think the current code is ever calling `send_security_metadata()` in the case where the context value has not ever been set.  The reason I say that is that the the current code sets the context value whenever the filter sees a batch that does not contain a `cancel_stream` op and the context value is not already set.  However, a `cancel_stream` op is always started in its own batch (never in the same batch with other ops).  And in order to get to `send_security_metadata()`, we have to have seen a batch with a `send_initial_metadata` op.  Since we know that batch will not have included a `cancel_stream` op, I think the context value will always be set by the time we get to `send_security_metadata()`.I think it should be safe to move the code that sets the context into `init_call_elem()`.  But we should get confirmation from the security folks.  If @jiangtaoli2016 is on vacation, ask @jboeuf (the original author of this code).",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/15879,198618115,2018-06-27T19:44:59Z,src/core/lib/security/transport/client_auth_filter.cc,"@@ -279,7 +280,7 @@ static void auth_start_transport_stream_op_batch(     GPR_ASSERT(batch->payload->context != nullptr);     if (batch->payload->context[GRPC_CONTEXT_SECURITY].value == nullptr) {       batch->payload->context[GRPC_CONTEXT_SECURITY].value =","Thanks for the response, Mark. I wasn't aware of the semantics around cancel_stream ops. @jboeuf is on vacation. @jiangtaoli2016 , are you okay with moving the code that sets the security context into init_call_elem, instead of having it in start_transport_stream_op_batch?",
10135909,dklempner,https://api.github.com/repos/grpc/grpc/pulls/15862,198664400,2018-06-27T22:50:21Z,src/core/lib/surface/init.cc,"@@ -118,71 +120,85 @@ void grpc_init(void) {   int i;   gpr_once_init(&g_basic_init, do_basic_init); -  gpr_mu_lock(&g_init_mu);-  if (++g_initializations == 1) {-    grpc_core::Fork::GlobalInit();-    grpc_fork_handlers_auto_register();-    gpr_time_init();-    grpc_stats_init();-    grpc_slice_intern_init();-    grpc_mdctx_global_init();-    grpc_channel_init_init();-    grpc_core::ChannelzRegistry::Init();-    grpc_security_pre_init();-    grpc_core::ExecCtx::GlobalInit();-    grpc_iomgr_init();-    gpr_timers_global_init();-    grpc_handshaker_factory_registry_init();-    grpc_security_init();-    for (i = 0; i < g_number_of_plugins; i++) {-      if (g_all_of_the_plugins[i].init != nullptr) {-        g_all_of_the_plugins[i].init();+  int count;+  do {+    count = gpr_atm_no_barrier_load(&g_initializations);+    if (count == 0) {+      gpr_mu_lock(&g_init_mu);+      if (!g_initialized) {+        grpc_core::Fork::GlobalInit();+        grpc_fork_handlers_auto_register();+        gpr_time_init();+        grpc_stats_init();+        grpc_slice_intern_init();+        grpc_mdctx_global_init();+        grpc_channel_init_init();+        grpc_core::ChannelzRegistry::Init();+        grpc_security_pre_init();+        grpc_core::ExecCtx::GlobalInit();+        grpc_iomgr_init();+        gpr_timers_global_init();+        grpc_handshaker_factory_registry_init();+        grpc_security_init();+        for (i = 0; i < g_number_of_plugins; i++) {+          if (g_all_of_the_plugins[i].init != nullptr) {+            g_all_of_the_plugins[i].init();+          }+        }+        /* register channel finalization AFTER all plugins, to ensure that it's+         * run at the appropriate time */+        grpc_register_security_filters();+        register_builtin_channel_init();+        grpc_tracer_init(""GRPC_TRACE"");+        /* no more changes to channel init pipelines */+        grpc_channel_init_finalize();+        grpc_iomgr_start();+        g_initialized = true;       }+      gpr_atm_no_barrier_fetch_add(&g_initializations, 1);+      gpr_mu_unlock(&g_init_mu);     }-    /* register channel finalization AFTER all plugins, to ensure that it's run-     * at the appropriate time */-    grpc_register_security_filters();-    register_builtin_channel_init();-    grpc_tracer_init(""GRPC_TRACE"");-    /* no more changes to channel init pipelines */-    grpc_channel_init_finalize();-    grpc_iomgr_start();-  }-  gpr_mu_unlock(&g_init_mu);-+  } while (!gpr_atm_no_barrier_cas(&g_initializations, count, count + 1));   GRPC_API_TRACE(""grpc_init(void)"", 0, ()); }  void grpc_shutdown(void) {   int i;   GRPC_API_TRACE(""grpc_shutdown(void)"", 0, ());-  gpr_mu_lock(&g_init_mu);-  if (--g_initializations == 0) {-    {-      grpc_core::ExecCtx exec_ctx(0);-      {-        grpc_timer_manager_set_threading(-            false);  // shutdown timer_manager thread-        grpc_executor_shutdown();-        for (i = g_number_of_plugins; i >= 0; i--) {-          if (g_all_of_the_plugins[i].destroy != nullptr) {-            g_all_of_the_plugins[i].destroy();+  int count;+  do {+    count = gpr_atm_no_barrier_load(&g_initializations);+    if (count == 1) {+      gpr_mu_lock(&g_init_mu);+      if (gpr_atm_no_barrier_fetch_add(&g_initializations, -1) == 1) {","The decrement from 1 to 0 needs acquire semantics, because it needs to observe things other threads have done to grpc globals before calling grpc_shutdown().Similarly, all the decrements *other* than the one from 1 to 0 need release semantics to pair up with that acquire.",