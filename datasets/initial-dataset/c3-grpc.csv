user_id,user_login,pull_request_url,comment_id,created_at,path,diff_hunk,content,code_smell
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/15879,198711951,2018-06-28T05:35:32Z,src/core/lib/security/transport/client_auth_filter.cc,"@@ -279,7 +280,7 @@ static void auth_start_transport_stream_op_batch(     GPR_ASSERT(batch->payload->context != nullptr);     if (batch->payload->context[GRPC_CONTEXT_SECURITY].value == nullptr) {       batch->payload->context[GRPC_CONTEXT_SECURITY].value =","@markdroth It looks like we need to access the `client_security_context` in `send_security_metadata()`, so we'll need to access it in `auth_start_transport_stream_op_batch`. Could we set the call's context in `init_call_elem()` and store it in `args->context` and then put a pointer to the context in the call data? Or is there some other way to access args->context from within `start_transport_stream_op_batch`?",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15906,198910881,2018-06-28T16:47:28Z,include/grpc/impl/codegen/grpc_types.h,"@@ -615,6 +616,9 @@ typedef struct {   /** If non-NULL, will be set to point to a string containing the    * service config used by the channel in JSON form. */   char** service_config_json;+  /** If non-NULL, Will be set to the channels connectivity state","In order for the ""if non-null"" semantic to work, the field needs to be a pointer.",OK
39999204,yetianx,https://api.github.com/repos/grpc/grpc/pulls/15853,198937165,2018-06-28T18:15:37Z,src/cpp/server/load_reporter/load_reporter_async_service_impl.h,"@@ -0,0 +1,168 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_SRC_CPP_SERVER_LOAD_REPORTER_ASYNC_SERVICE_IMPL_H+#define GRPC_SRC_CPP_SERVER_LOAD_REPORTER_ASYNC_SERVICE_IMPL_H++#include <grpc/support/port_platform.h>++#include <grpc/support/log.h>+#include <grpcpp/alarm.h>+#include <grpcpp/grpcpp.h>++#include ""src/core/lib/gprpp/ref_counted.h""+#include ""src/core/lib/gprpp/thd.h""+#include ""src/cpp/server/load_reporter/load_reporter.h""++namespace grpc {+namespace load_reporter {++// Async load reporting service. It's mainly responsible for controlling the+// procedure of incoming requests. The real business logic is handed off to the+// LoadReporter. There should be at most one instance of this service on a+// server to avoid spreading the load data into multiple places.+class LoadReporterAsyncServiceImpl+    : public grpc::lb::v1::LoadReporter::AsyncService {+ public:+  explicit LoadReporterAsyncServiceImpl(+      std::unique_ptr<ServerCompletionQueue> cq);+  ~LoadReporterAsyncServiceImpl();++  // Starts the working thread.+  void StartThread();++  // Not copyable nor movable.+  LoadReporterAsyncServiceImpl(const LoadReporterAsyncServiceImpl&) = delete;+  LoadReporterAsyncServiceImpl& operator=(const LoadReporterAsyncServiceImpl&) =+      delete;++ private:+  // Each handler takes care of one load reporting stream. It contains+  // per-stream data and it will access the members of the parent class (i.e.,+  // LoadReporterAsyncServiceImpl) for service-wide data (e.g., the load data).+  class ReportLoadHandler",The interfaces looks a little not straightforward. The code executes and/or reset func parameters to make sure there is no functor holding the shared ptr of the handler.It might be clearer if you cache those functors and make Shutdown or OnFinishDone or OnDoneNotified clear all cached functors.,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15879,198999381,2018-06-28T21:58:08Z,src/core/lib/security/transport/client_auth_filter.cc,"@@ -275,22 +275,6 @@ static void auth_start_transport_stream_op_batch(   call_data* calld = static_cast<call_data*>(elem->call_data);   channel_data* chand = static_cast<channel_data*>(elem->channel_data); -  if (!batch->cancel_stream) {-    GPR_ASSERT(batch->payload->context != nullptr);-    if (batch->payload->context[GRPC_CONTEXT_SECURITY].value == nullptr) {-      batch->payload->context[GRPC_CONTEXT_SECURITY].value =",It's passed into the filters' `init_call_elem()` here:https://github.com/grpc/grpc/blob/master/src/core/lib/surface/call.cc#L442And set in the payload batch here:https://github.com/grpc/grpc/blob/master/src/core/lib/surface/call.cc#L370,OK
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/15853,199057406,2018-06-29T05:40:08Z,src/cpp/server/load_reporter/load_reporter_async_service_impl.h,"@@ -0,0 +1,168 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_SRC_CPP_SERVER_LOAD_REPORTER_ASYNC_SERVICE_IMPL_H+#define GRPC_SRC_CPP_SERVER_LOAD_REPORTER_ASYNC_SERVICE_IMPL_H++#include <grpc/support/port_platform.h>++#include <grpc/support/log.h>+#include <grpcpp/alarm.h>+#include <grpcpp/grpcpp.h>++#include ""src/core/lib/gprpp/ref_counted.h""+#include ""src/core/lib/gprpp/thd.h""+#include ""src/cpp/server/load_reporter/load_reporter.h""++namespace grpc {+namespace load_reporter {++// Async load reporting service. It's mainly responsible for controlling the+// procedure of incoming requests. The real business logic is handed off to the+// LoadReporter. There should be at most one instance of this service on a+// server to avoid spreading the load data into multiple places.+class LoadReporterAsyncServiceImpl+    : public grpc::lb::v1::LoadReporter::AsyncService {+ public:+  explicit LoadReporterAsyncServiceImpl(+      std::unique_ptr<ServerCompletionQueue> cq);+  ~LoadReporterAsyncServiceImpl();++  // Starts the working thread.+  void StartThread();++  // Not copyable nor movable.+  LoadReporterAsyncServiceImpl(const LoadReporterAsyncServiceImpl&) = delete;+  LoadReporterAsyncServiceImpl& operator=(const LoadReporterAsyncServiceImpl&) =+      delete;++ private:+  // Each handler takes care of one load reporting stream. It contains+  // per-stream data and it will access the members of the parent class (i.e.,+  // LoadReporterAsyncServiceImpl) for service-wide data (e.g., the load data).+  class ReportLoadHandler","I have removed the func parameter, but it was only used to drop the ref. It was not a good way to do so though.It won't be safe to have a single place to drop the refs. If we prematurely drop a ref, the tag that pops out from the completion queue later will cause segfault.",OK
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/15909,199221820,2018-06-29T16:59:29Z,src/core/tsi/local_transport_security.h,"@@ -0,0 +1,54 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_TSI_LOCAL_TRANSPORT_SECURITY_H+#define GRPC_CORE_TSI_LOCAL_TRANSPORT_SECURITY_H++#include <grpc/support/port_platform.h>++#include <grpc/grpc.h>++#include ""src/core/tsi/transport_security.h""+#include ""src/core/tsi/transport_security_interface.h""++#define TSI_LOCAL_NUM_OF_PEER_PROPERTIES 1+#define TSI_LOCAL_PROCESS_ID_PEER_PROPERTY ""process_id""++/**+ * Main struct for local TSI handshaker. All APIs in the header are+ * thread-comptabile.+ */+typedef struct local_tsi_handshaker local_tsi_handshaker;++/**+ * This method creates a local TSI handshaker instance.+ *+ * - target_name: the name of the endpoint that the channel is connecting to.",Local TSI basically does nothing. We probably want to keep it as simple as possible. Consider remove this parameter.,OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/15771,199276592,2018-06-29T20:48:21Z,include/grpcpp/impl/codegen/rpc_service_method.h,"@@ -58,18 +59,57 @@ class RpcServiceMethod : public RpcMethod {   /// Takes ownership of the handler   RpcServiceMethod(const char* name, RpcMethod::RpcType type,                    MethodHandler* handler)-      : RpcMethod(name, type), server_tag_(nullptr), handler_(handler) {}+      : RpcMethod(name, type),+        server_tag_(nullptr),+        async_type_(AsyncType::UNSET),+        handler_(handler) {}++  enum class AsyncType {+    UNSET,+    ASYNC,+    RAW,+  };    void set_server_tag(void* tag) { server_tag_ = tag; }   void* server_tag() const { return server_tag_; }   /// if MethodHandler is nullptr, then this is an async method   MethodHandler* handler() const { return handler_.get(); }-  void ResetHandler() { handler_.reset(); }   void SetHandler(MethodHandler* handler) { handler_.reset(handler); }+  void SetServerAsyncType(RpcServiceMethod::AsyncType type) {+    if (async_type_ == AsyncType::UNSET) {+      // this marks this method as async+      handler_.reset();+    } else {+      // this is not an error condition, as it allows users to declare a server+      // like WithRawMethod_foo<AsyncService>. However since it+      // overwrites behavior, it should be logged.+      gpr_log(+          GPR_INFO,+          ""You are marking method %s as '%s', even though it was ""+          ""previously marked '%s'. This behavior will overwrite the original ""+          ""behavior. If you expected this then ignore this message."",+          name(), TypeToString(async_type_), TypeToString(type));+    }+    async_type_ = type;+  }   private:   void* server_tag_;+  RpcServiceMethod::AsyncType async_type_;","I think you can just say AsyncType, right, since this is already at class scope?",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/15771,199276663,2018-06-29T20:48:45Z,include/grpcpp/impl/codegen/rpc_service_method.h,"@@ -58,18 +59,57 @@ class RpcServiceMethod : public RpcMethod {   /// Takes ownership of the handler   RpcServiceMethod(const char* name, RpcMethod::RpcType type,                    MethodHandler* handler)-      : RpcMethod(name, type), server_tag_(nullptr), handler_(handler) {}+      : RpcMethod(name, type),+        server_tag_(nullptr),+        async_type_(AsyncType::UNSET),+        handler_(handler) {}++  enum class AsyncType {","Out of curiosity, why enum class and not just enum? We aren't really using those elsewhere afaik and you're just using them as int's and not arbitrary constexprs",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/15771,199278823,2018-06-29T20:58:32Z,test/cpp/end2end/raw_end2end_test.cc,"@@ -0,0 +1,463 @@+/*+ *+ * Copyright 2015 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <cinttypes>+#include <memory>+#include <thread>++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/time.h>+#include <grpcpp/channel.h>+#include <grpcpp/client_context.h>+#include <grpcpp/create_channel.h>+#include <grpcpp/server.h>+#include <grpcpp/server_builder.h>+#include <grpcpp/server_context.h>++#include ""src/core/lib/gpr/env.h""+#include ""src/core/lib/iomgr/port.h""+#include ""src/proto/grpc/testing/duplicate/echo_duplicate.grpc.pb.h""+#include ""src/proto/grpc/testing/echo.grpc.pb.h""+#include ""test/core/util/port.h""+#include ""test/core/util/test_config.h""+#include ""test/cpp/util/byte_buffer_proto_helper.h""+#include ""test/cpp/util/string_ref_helper.h""++#include <gtest/gtest.h>++using grpc::testing::EchoRequest;+using grpc::testing::EchoResponse;++namespace grpc {+namespace testing {++namespace {++void* tag(int i) { return (void*)static_cast<intptr_t>(i); }+int detag(void* p) { return static_cast<int>(reinterpret_cast<intptr_t>(p)); }++class Verifier {+ public:+  Verifier() : lambda_run_(false) {}+  // Expect sets the expected ok value for a specific tag+  Verifier& Expect(int i, bool expect_ok) {+    return ExpectUnless(i, expect_ok, false);+  }","This verifier duplicates a lot of code from async_end2end_test unnecessarily. This version isn't using ExpectMaybe, ExpectUnless, the lambda flavor of verify, DoOnceThenAsyncNext, etc at all. Can I suggest removing them to keep the unit tests simpler?",OK
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/15771,199289558,2018-06-29T21:57:25Z,include/grpcpp/impl/codegen/rpc_service_method.h,"@@ -58,18 +59,57 @@ class RpcServiceMethod : public RpcMethod {   /// Takes ownership of the handler   RpcServiceMethod(const char* name, RpcMethod::RpcType type,                    MethodHandler* handler)-      : RpcMethod(name, type), server_tag_(nullptr), handler_(handler) {}+      : RpcMethod(name, type),+        server_tag_(nullptr),+        async_type_(AsyncType::UNSET),+        handler_(handler) {}++  enum class AsyncType {",I was asked to use enum class in a different review. Usage [here](https://github.com/grpc/grpc/blob/master/src/core/lib/channel/channel_trace.h#L78). That is the only reason.I will flip the question; are there reasons to prefer normal enum over enum class?,
13115060,rongjiecomputer,https://api.github.com/repos/grpc/grpc/pulls/15914,199342169,2018-07-01T08:34:45Z,templates/test/cpp/naming/resolver_component_tests_defs.include,"@@ -43,6 +44,11 @@ args = argp.parse_args() def test_runner_log(msg):   sys.stderr.write('\n%s: %s\n' % (__file__, msg)) +def python_args(arg_list):+  if platform.system() == 'Windows':+    return ['C:\\Python27\\python.exe'] + arg_list",Please use [`sys.executable`](https://docs.python.org/2/library/sys.html#sys.executable) instead of hard-coding `C:\\Python27\\python.exe`.,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15906,199870351,2018-07-03T16:23:38Z,src/core/ext/transport/chttp2/client/insecure/channel_create.cc,"@@ -92,10 +93,11 @@ grpc_channel* grpc_insecure_channel_create(const char* target,       ""grpc_insecure_channel_create(target=%s, args=%p, reserved=%p)"", 3,       (target, args, reserved));   GPR_ASSERT(reserved == nullptr);-  // Add channel arg containing the client channel factory.-  grpc_arg arg =-      grpc_client_channel_factory_create_channel_arg(&client_channel_factory);-  grpc_channel_args* new_args = grpc_channel_args_copy_and_add(args, &arg, 1);+  grpc_arg args_to_add[] = {+      grpc_client_channel_factory_create_channel_arg(&client_channel_factory),+      grpc_core::channelz::ClientChannelNode::CreateArg()};","Instead of doing this via the chttp2 code, where it has to be done separately for secure and insecure channels, I suggest doing it here:https://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/client_channel_plugin.cc#L37That function can modify the channel args via the builder.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15906,199871388,2018-07-03T16:26:32Z,src/core/lib/channel/channelz.h,"@@ -79,6 +87,14 @@ class ChannelNode : public RefCounted<ChannelNode> {   ManualConstructor<ChannelTrace> trace_; }; +// Creation functions++typedef RefCountedPtr<ChannelNode> (*ChannelNodeCreationFunc)(grpc_channel*,+                                                              size_t);++RefCountedPtr<ChannelNode> MakeChannelNode(grpc_channel* channel,","Suggest making this a factory function in the `ChannelNode` class, in which case the ctor can be private.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/15771,199875791,2018-07-03T16:39:56Z,include/grpcpp/impl/codegen/rpc_service_method.h,"@@ -58,18 +59,57 @@ class RpcServiceMethod : public RpcMethod {   /// Takes ownership of the handler   RpcServiceMethod(const char* name, RpcMethod::RpcType type,                    MethodHandler* handler)-      : RpcMethod(name, type), server_tag_(nullptr), handler_(handler) {}+      : RpcMethod(name, type),+        server_tag_(nullptr),+        async_type_(AsyncType::UNSET),+        handler_(handler) {}++  enum class AsyncType {",No objections in retrospect. We should increasingly move to enum class whenever possible.,
13988745,wheezil,https://api.github.com/repos/grpc/grpc/pulls/15938,200988253,2018-07-09T12:45:59Z,README.md,"@@ -37,6 +37,16 @@ For instructions on how to use the language-specific gRPC runtime in your projec  You can find per-language quickstart guides and tutorials in [Documentation section on grpc.io website](https://grpc.io/docs/). The code examples are available in the [examples](examples) directory. ++## Windows Visual C++ Quickstart Install","For protobuf itself, the vcpkg instructions are here:https://github.com/google/protobuf/blob/master/src/README.mdThat's what I was basing my change on (although I didn't put it in the right place).I have no information about the diligence of the vcpkg maintainers.  I used this approach on a simple POC and it worked.  The only issue I had was that the EXE for the grpc java plugin isn't in the package. However, the maven plugin seems like a better approach anyway.",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/15912,201097737,2018-07-09T18:11:37Z,tools/internal_ci/helper_scripts/prepare_build_windows.bat,"@@ -34,6 +34,12 @@ netsh interface ip add dnsservers ""Local Area Connection 8"" 8.8.4.4 index=3 @rem Needed for big_query_utils python -m pip install google-api-python-client +@rem Install Python 3.7+chocolatey install -y python3","On second thought, it would be immaterial if we are hoping Kokoro to preinstall it for us sooner than 3.8 comes along.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/15962,201180880,2018-07-09T23:43:35Z,src/core/lib/iomgr/executor.cc,"@@ -85,217 +75,260 @@ static size_t run_closures(grpc_closure_list list) {   return n; } -bool grpc_executor_is_threaded() {-  return gpr_atm_no_barrier_load(&g_cur_threads) > 0;+bool GrpcExecutor::IsThreaded() {+  return gpr_atm_no_barrier_load(&num_threads) > 0; } -void grpc_executor_set_threading(bool threading) {-  gpr_atm cur_threads = gpr_atm_no_barrier_load(&g_cur_threads);+void GrpcExecutor::SetThreading(bool threading) {+  gpr_atm curr_num_threads = gpr_atm_no_barrier_load(&num_threads);+   if (threading) {-    if (cur_threads > 0) return;-    g_max_threads = GPR_MAX(1, 2 * gpr_cpu_num_cores());-    gpr_atm_no_barrier_store(&g_cur_threads, 1);+    if (curr_num_threads > 0) return;++    // TODO (sreek): max_threads initialization can be moved into the+    // constructor+    max_threads = GPR_MAX(1, 2 * gpr_cpu_num_cores());+    gpr_atm_no_barrier_store(&num_threads, 1);     gpr_tls_init(&g_this_thread_state);-    g_thread_state = static_cast<thread_state*>(-        gpr_zalloc(sizeof(thread_state) * g_max_threads));-    for (size_t i = 0; i < g_max_threads; i++) {-      gpr_mu_init(&g_thread_state[i].mu);-      gpr_cv_init(&g_thread_state[i].cv);-      g_thread_state[i].thd = grpc_core::Thread();-      g_thread_state[i].elems = GRPC_CLOSURE_LIST_INIT;+    thd_state = static_cast<thread_state*>(+        gpr_zalloc(sizeof(thread_state) * max_threads));++    for (size_t i = 0; i < max_threads; i++) {+      gpr_mu_init(&thd_state[i].mu);+      gpr_cv_init(&thd_state[i].cv);+      thd_state[i].id = i;+      thd_state[i].thd = grpc_core::Thread();+      thd_state[i].elems = GRPC_CLOSURE_LIST_INIT;     } -    g_thread_state[0].thd =-        grpc_core::Thread(""grpc_executor"", executor_thread, &g_thread_state[0]);-    g_thread_state[0].thd.Start();+    thd_state[0].thd =+        grpc_core::Thread(name, &GrpcExecutor::ThreadMain, &thd_state[0]);+    thd_state[0].thd.Start();   } else {-    if (cur_threads == 0) return;-    for (size_t i = 0; i < g_max_threads; i++) {-      gpr_mu_lock(&g_thread_state[i].mu);-      g_thread_state[i].shutdown = true;-      gpr_cv_signal(&g_thread_state[i].cv);-      gpr_mu_unlock(&g_thread_state[i].mu);+    if (curr_num_threads == 0) return;++    for (size_t i = 0; i < max_threads; i++) {+      gpr_mu_lock(&thd_state[i].mu);+      thd_state[i].shutdown = true;+      gpr_cv_signal(&thd_state[i].cv);+      gpr_mu_unlock(&thd_state[i].mu);     }-    /* ensure no thread is adding a new thread... once this is past, then-       no thread will try to add a new one either (since shutdown is true) */-    gpr_spinlock_lock(&g_adding_thread_lock);-    gpr_spinlock_unlock(&g_adding_thread_lock);-    for (gpr_atm i = 0; i < g_cur_threads; i++) {-      g_thread_state[i].thd.Join();++    /* Ensure no thread is adding a new thread. Once this is past, then no+     * thread will try to add a new one either (since shutdown is true) */+    gpr_spinlock_lock(&adding_thread_lock);+    gpr_spinlock_unlock(&adding_thread_lock);++    for (gpr_atm i = 0; i < num_threads; i++) {+      thd_state[i].thd.Join();     }-    gpr_atm_no_barrier_store(&g_cur_threads, 0);-    for (size_t i = 0; i < g_max_threads; i++) {-      gpr_mu_destroy(&g_thread_state[i].mu);-      gpr_cv_destroy(&g_thread_state[i].cv);-      run_closures(g_thread_state[i].elems);++    gpr_atm_no_barrier_store(&num_threads, 0);+    for (size_t i = 0; i < max_threads; i++) {+      gpr_mu_destroy(&thd_state[i].mu);+      gpr_cv_destroy(&thd_state[i].cv);+      RunClosures(thd_state[i].elems);     }-    gpr_free(g_thread_state);++    gpr_free(thd_state);     gpr_tls_destroy(&g_this_thread_state);   } } -void grpc_executor_init() {-  gpr_atm_no_barrier_store(&g_cur_threads, 0);-  grpc_executor_set_threading(true);-}--void grpc_executor_shutdown() { grpc_executor_set_threading(false); }+void GrpcExecutor::Shutdown() { SetThreading(false); } -static void executor_thread(void* arg) {+void GrpcExecutor::ThreadMain(void* arg) {   thread_state* ts = static_cast<thread_state*>(arg);   gpr_tls_set(&g_this_thread_state, (intptr_t)ts);    grpc_core::ExecCtx exec_ctx(GRPC_EXEC_CTX_FLAG_IS_INTERNAL_THREAD);    size_t subtract_depth = 0;   for (;;) {-    if (executor_trace.enabled()) {-      gpr_log(GPR_INFO, ""EXECUTOR[%d]: step (sub_depth=%"" PRIdPTR "")"",-              static_cast<int>(ts - g_thread_state), subtract_depth);-    }+    EXECUTOR_TRACE(""EXECUTOR[%ld]: step (sub_depth=%"" PRIdPTR "")"", ts->id,+                   subtract_depth);+     gpr_mu_lock(&ts->mu);     ts->depth -= subtract_depth;+    // Wait for closures to be enqueued or for the executor to be shutdown     while (grpc_closure_list_empty(ts->elems) && !ts->shutdown) {       ts->queued_long_job = false;       gpr_cv_wait(&ts->cv, &ts->mu, gpr_inf_future(GPR_CLOCK_MONOTONIC));     }+     if (ts->shutdown) {-      if (executor_trace.enabled()) {-        gpr_log(GPR_INFO, ""EXECUTOR[%d]: shutdown"",-                static_cast<int>(ts - g_thread_state));-      }+      EXECUTOR_TRACE(""EXECUTOR[%ld]: shutdown"", ts->id);       gpr_mu_unlock(&ts->mu);       break;     }+     GRPC_STATS_INC_EXECUTOR_QUEUE_DRAINED();-    grpc_closure_list exec = ts->elems;+    grpc_closure_list closures = ts->elems;     ts->elems = GRPC_CLOSURE_LIST_INIT;     gpr_mu_unlock(&ts->mu);-    if (executor_trace.enabled()) {-      gpr_log(GPR_INFO, ""EXECUTOR[%d]: execute"",-              static_cast<int>(ts - g_thread_state));-    }++    EXECUTOR_TRACE(""EXECUTOR[%ld]: execute"", ts->id);      grpc_core::ExecCtx::Get()->InvalidateNow();-    subtract_depth = run_closures(exec);+    subtract_depth = RunClosures(closures);   } } -static void executor_push(grpc_closure* closure, grpc_error* error,-                          bool is_short) {+void GrpcExecutor::Enqueue(grpc_closure* closure, grpc_error* error,+                           bool is_short) {   bool retry_push;   if (is_short) {     GRPC_STATS_INC_EXECUTOR_SCHEDULED_SHORT_ITEMS();   } else {     GRPC_STATS_INC_EXECUTOR_SCHEDULED_LONG_ITEMS();   }+   do {     retry_push = false;     size_t cur_thread_count =-        static_cast<size_t>(gpr_atm_no_barrier_load(&g_cur_threads));+        static_cast<size_t>(gpr_atm_no_barrier_load(&num_threads));++    // If the number of threads is zero(i.e either the executor is not threaded+    // or already shutdown), then queue the closure on the exec context itself     if (cur_thread_count == 0) {-      if (executor_trace.enabled()) { #ifndef NDEBUG-        gpr_log(GPR_DEBUG, ""EXECUTOR: schedule %p (created %s:%d) inline"",-                closure, closure->file_created, closure->line_created);+      EXECUTOR_TRACE(""EXECUTOR: schedule %p (created %s:%d) inline"", closure,+                     closure->file_created, closure->line_created); #else-        gpr_log(GPR_INFO, ""EXECUTOR: schedule %p inline"", closure);+      EXECUTOR_TRACE(""EXECUTOR: schedule %p inline"", closure); #endif-      }       grpc_closure_list_append(grpc_core::ExecCtx::Get()->closure_list(),                                closure, error);       return;     }+     thread_state* ts = (thread_state*)gpr_tls_get(&g_this_thread_state);     if (ts == nullptr) {-      ts = &g_thread_state[GPR_HASH_POINTER(grpc_core::ExecCtx::Get(),-                                            cur_thread_count)];+      ts = &thd_state[GPR_HASH_POINTER(grpc_core::ExecCtx::Get(),+                                       cur_thread_count)];     } else {       GRPC_STATS_INC_EXECUTOR_SCHEDULED_TO_SELF();     }+     thread_state* orig_ts = ts;      bool try_new_thread;     for (;;) {-      if (executor_trace.enabled()) { #ifndef NDEBUG-        gpr_log(-            GPR_DEBUG,-            ""EXECUTOR: try to schedule %p (%s) (created %s:%d) to thread %d"",-            closure, is_short ? ""short"" : ""long"", closure->file_created,-            closure->line_created, static_cast<int>(ts - g_thread_state));+      EXECUTOR_TRACE(+          ""EXECUTOR: try to schedule %p (%s) (created %s:%d) to thread %ld"",+          closure, is_short ? ""short"" : ""long"", closure->file_created,+          closure->line_created, ts->id); #else-        gpr_log(GPR_INFO, ""EXECUTOR: try to schedule %p (%s) to thread %d"",-                closure, is_short ? ""short"" : ""long"",-                (int)(ts - g_thread_state));+      EXECUTOR_TRACE(""EXECUTOR: try to schedule %p (%s) to thread %ld"", closure,+                     is_short ? ""short"" : ""long"", ts->id); #endif-      }+       gpr_mu_lock(&ts->mu);       if (ts->queued_long_job) {         // if there's a long job queued, we never queue anything else to this         // queue (since long jobs can take 'infinite' time and we need to-        // guarantee no starvation)-        // ... spin through queues and try again+        // guarantee no starvation). Spin through queues and try again         gpr_mu_unlock(&ts->mu);-        size_t idx = static_cast<size_t>(ts - g_thread_state);-        ts = &g_thread_state[(idx + 1) % cur_thread_count];+        size_t idx = ts->id;+        ts = &thd_state[(idx + 1) % cur_thread_count];         if (ts == orig_ts) {+          // We cycled through all the threads. Retry enqueue again (by creating+          // a new thread)           retry_push = true;+          // TODO (sreek): What if the executor is shutdown OR if+          // cur_thread_count is already equal to max_threads ? (currently - as+          // of July 2018, we do not run in to this issue because there is only+          // one instance of long job in gRPC. This has to be fixed soon)           try_new_thread = true;           break;         }+         continue;       }++      // == Found the thread state (i.e thread) to enqueue this closure! ==++      // Also, if this thread has been waiting for closures, wake it up.+      // - If grpc_closure_list_empty() is true and the Executor is not+      //   shutdown, it means that the thread must be waiting in ThreadMain()+      // - Note that gpr_cv_signal() won't immediately wakeup the thread. That+      //   happens after we release the mutex &ts->mu a few lines below       if (grpc_closure_list_empty(ts->elems) && !ts->shutdown) {         GRPC_STATS_INC_EXECUTOR_WAKEUP_INITIATED();         gpr_cv_signal(&ts->cv);       }+       grpc_closure_list_append(&ts->elems, closure, error);++      // If we already queued more than MAX_DEPTH number of closures on this+      // thread, use this as a hint to create more threads       ts->depth++;       try_new_thread = ts->depth > MAX_DEPTH &&-                       cur_thread_count < g_max_threads && !ts->shutdown;-      if (!is_short) ts->queued_long_job = true;+                       cur_thread_count < max_threads && !ts->shutdown;++      ts->queued_long_job = !is_short;+       gpr_mu_unlock(&ts->mu);       break;     }-    if (try_new_thread && gpr_spinlock_trylock(&g_adding_thread_lock)) {++    if (try_new_thread && gpr_spinlock_trylock(&adding_thread_lock)) {       cur_thread_count =-          static_cast<size_t>(gpr_atm_no_barrier_load(&g_cur_threads));-      if (cur_thread_count < g_max_threads) {-        gpr_atm_no_barrier_store(&g_cur_threads, cur_thread_count + 1);--        g_thread_state[cur_thread_count].thd =-            grpc_core::Thread(""grpc_executor"", executor_thread,-                              &g_thread_state[cur_thread_count]);-        g_thread_state[cur_thread_count].thd.Start();+          static_cast<size_t>(gpr_atm_no_barrier_load(&num_threads));+      if (cur_thread_count < max_threads) {+        // Increment num_threads (Safe to do a no_barrier_store instead of a+        // cas because we always increment num_threads under the+        // 'adding_thread_lock')+        gpr_atm_no_barrier_store(&num_threads, cur_thread_count + 1);++        thd_state[cur_thread_count].thd = grpc_core::Thread(+            name, &GrpcExecutor::ThreadMain, &thd_state[cur_thread_count]);+        thd_state[cur_thread_count].thd.Start();       }-      gpr_spinlock_unlock(&g_adding_thread_lock);+      gpr_spinlock_unlock(&adding_thread_lock);     }+     if (retry_push) {       GRPC_STATS_INC_EXECUTOR_PUSH_RETRIES();     }   } while (retry_push); } -static void executor_push_short(grpc_closure* closure, grpc_error* error) {-  executor_push(closure, error, true);+static GrpcExecutor g_global_executor(""grpc-executor"");++void enqueue_long(grpc_closure* closure, grpc_error* error) {+  g_global_executor.Enqueue(closure, error, false);","I'd suggest writing `g_global_executor.Enqueue(closure, error, false /* is_short */)`In fact, boolean arguments are [a code smell](https://www.martinfowler.com/bliki/FlagArgument.html). Ideally, we'd have `EnqueueShort` and `EnqueueLong` or some such.",OK
22083734,matt-kwong,https://api.github.com/repos/grpc/grpc/pulls/15961,201182244,2018-07-09T23:52:15Z,third_party/toolchains/BUILD,"@@ -0,0 +1,46 @@+# Copyright 2017 gRPC authors.",Why does this file belong in the `third_party` directory?,
14932100,adelez,https://api.github.com/repos/grpc/grpc/pulls/15961,201191091,2018-07-10T00:58:28Z,third_party/toolchains/BUILD,"@@ -0,0 +1,46 @@+# Copyright 2017 gRPC authors.",This is about the bazel toolchains.,
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/15979,201437787,2018-07-10T17:55:19Z,src/core/tsi/alts/zero_copy_frame_protector/alts_grpc_integrity_only_record_protocol.cc,"@@ -42,34 +42,33 @@ typedef struct alts_grpc_integrity_only_record_protocol { static tsi_result alts_grpc_integrity_only_extra_copy_protect(     alts_grpc_record_protocol* rp, grpc_slice_buffer* unprotected_slices,     grpc_slice_buffer* protected_slices) {-  /* Allocates memory for protected frame.  */+  /* Allocates memory for protected frame and copies data.  */   size_t protected_frame_size =       unprotected_slices->length + rp->header_length + rp->tag_length;   grpc_slice protected_slice = GRPC_SLICE_MALLOC(protected_frame_size);+  uint8_t* data = GRPC_SLICE_START_PTR(protected_slice) + rp->header_length;+  for (size_t i = 0; i < unprotected_slices->count; i++) {+    memcpy(data, GRPC_SLICE_START_PTR(unprotected_slices->slices[i]),+           GRPC_SLICE_LENGTH(unprotected_slices->slices[i]));+    data += GRPC_SLICE_LENGTH(unprotected_slices->slices[i]);+  }   /* Calls alts_iovec_record_protocol protect.  */   char* error_details = nullptr;   iovec_t header_iovec = {GRPC_SLICE_START_PTR(protected_slice),                           rp->header_length};   iovec_t tag_iovec = {GRPC_SLICE_START_PTR(protected_slice) +                            rp->header_length + unprotected_slices->length,","Should not we also use that of `data`? After copy, `unprotected_slices` can also be modified. ",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/15979,201442961,2018-07-10T18:12:43Z,src/core/tsi/alts/zero_copy_frame_protector/alts_grpc_integrity_only_record_protocol.cc,"@@ -42,34 +42,33 @@ typedef struct alts_grpc_integrity_only_record_protocol { static tsi_result alts_grpc_integrity_only_extra_copy_protect(     alts_grpc_record_protocol* rp, grpc_slice_buffer* unprotected_slices,     grpc_slice_buffer* protected_slices) {-  /* Allocates memory for protected frame.  */+  /* Allocates memory for protected frame and copies data.  */   size_t protected_frame_size =       unprotected_slices->length + rp->header_length + rp->tag_length;   grpc_slice protected_slice = GRPC_SLICE_MALLOC(protected_frame_size);+  uint8_t* data = GRPC_SLICE_START_PTR(protected_slice) + rp->header_length;+  for (size_t i = 0; i < unprotected_slices->count; i++) {+    memcpy(data, GRPC_SLICE_START_PTR(unprotected_slices->slices[i]),+           GRPC_SLICE_LENGTH(unprotected_slices->slices[i]));+    data += GRPC_SLICE_LENGTH(unprotected_slices->slices[i]);+  }   /* Calls alts_iovec_record_protocol protect.  */   char* error_details = nullptr;   iovec_t header_iovec = {GRPC_SLICE_START_PTR(protected_slice),                           rp->header_length};   iovec_t tag_iovec = {GRPC_SLICE_START_PTR(protected_slice) +                            rp->header_length + unprotected_slices->length,","unprotected_slices is not modified (the content of unprotected slices may be modified by another thread). We first copy (not move) unprotected_slices into protected_slice. The `data` is a pointer mainly used for copy, as grpc does not provide a function for copying slice buffer.After copy (line 54), we only use `unprotected_slices->length`.",OK
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/15979,201443320,2018-07-10T18:13:51Z,src/core/tsi/alts/zero_copy_frame_protector/alts_grpc_integrity_only_record_protocol.cc,"@@ -42,34 +42,33 @@ typedef struct alts_grpc_integrity_only_record_protocol { static tsi_result alts_grpc_integrity_only_extra_copy_protect(     alts_grpc_record_protocol* rp, grpc_slice_buffer* unprotected_slices,     grpc_slice_buffer* protected_slices) {-  /* Allocates memory for protected frame.  */+  /* Allocates memory for protected frame and copies data.  */   size_t protected_frame_size =       unprotected_slices->length + rp->header_length + rp->tag_length;   grpc_slice protected_slice = GRPC_SLICE_MALLOC(protected_frame_size);+  uint8_t* data = GRPC_SLICE_START_PTR(protected_slice) + rp->header_length;+  for (size_t i = 0; i < unprotected_slices->count; i++) {+    memcpy(data, GRPC_SLICE_START_PTR(unprotected_slices->slices[i]),+           GRPC_SLICE_LENGTH(unprotected_slices->slices[i]));+    data += GRPC_SLICE_LENGTH(unprotected_slices->slices[i]);+  }   /* Calls alts_iovec_record_protocol protect.  */   char* error_details = nullptr;   iovec_t header_iovec = {GRPC_SLICE_START_PTR(protected_slice),                           rp->header_length};   iovec_t tag_iovec = {GRPC_SLICE_START_PTR(protected_slice) +                            rp->header_length + unprotected_slices->length,                        rp->tag_length};-  alts_grpc_record_protocol_convert_slice_buffer_to_iovec(rp,-                                                          unprotected_slices);+  rp->iovec_buf[0].iov_base =+      GRPC_SLICE_START_PTR(protected_slice) + rp->header_length;+  rp->iovec_buf[0].iov_len = unprotected_slices->length;","As above, we only use `unprotected_slices->length` for keeping track of frame data length. ",
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/15962,201447703,2018-07-10T18:27:27Z,src/core/lib/iomgr/executor.cc,"@@ -85,217 +75,260 @@ static size_t run_closures(grpc_closure_list list) {   return n; } -bool grpc_executor_is_threaded() {-  return gpr_atm_no_barrier_load(&g_cur_threads) > 0;+bool GrpcExecutor::IsThreaded() {+  return gpr_atm_no_barrier_load(&num_threads) > 0; } -void grpc_executor_set_threading(bool threading) {-  gpr_atm cur_threads = gpr_atm_no_barrier_load(&g_cur_threads);+void GrpcExecutor::SetThreading(bool threading) {+  gpr_atm curr_num_threads = gpr_atm_no_barrier_load(&num_threads);+   if (threading) {-    if (cur_threads > 0) return;-    g_max_threads = GPR_MAX(1, 2 * gpr_cpu_num_cores());-    gpr_atm_no_barrier_store(&g_cur_threads, 1);+    if (curr_num_threads > 0) return;++    // TODO (sreek): max_threads initialization can be moved into the+    // constructor+    max_threads = GPR_MAX(1, 2 * gpr_cpu_num_cores());+    gpr_atm_no_barrier_store(&num_threads, 1);     gpr_tls_init(&g_this_thread_state);-    g_thread_state = static_cast<thread_state*>(-        gpr_zalloc(sizeof(thread_state) * g_max_threads));-    for (size_t i = 0; i < g_max_threads; i++) {-      gpr_mu_init(&g_thread_state[i].mu);-      gpr_cv_init(&g_thread_state[i].cv);-      g_thread_state[i].thd = grpc_core::Thread();-      g_thread_state[i].elems = GRPC_CLOSURE_LIST_INIT;+    thd_state = static_cast<thread_state*>(+        gpr_zalloc(sizeof(thread_state) * max_threads));++    for (size_t i = 0; i < max_threads; i++) {+      gpr_mu_init(&thd_state[i].mu);+      gpr_cv_init(&thd_state[i].cv);+      thd_state[i].id = i;+      thd_state[i].thd = grpc_core::Thread();+      thd_state[i].elems = GRPC_CLOSURE_LIST_INIT;     } -    g_thread_state[0].thd =-        grpc_core::Thread(""grpc_executor"", executor_thread, &g_thread_state[0]);-    g_thread_state[0].thd.Start();+    thd_state[0].thd =+        grpc_core::Thread(name, &GrpcExecutor::ThreadMain, &thd_state[0]);+    thd_state[0].thd.Start();   } else {-    if (cur_threads == 0) return;-    for (size_t i = 0; i < g_max_threads; i++) {-      gpr_mu_lock(&g_thread_state[i].mu);-      g_thread_state[i].shutdown = true;-      gpr_cv_signal(&g_thread_state[i].cv);-      gpr_mu_unlock(&g_thread_state[i].mu);+    if (curr_num_threads == 0) return;++    for (size_t i = 0; i < max_threads; i++) {+      gpr_mu_lock(&thd_state[i].mu);+      thd_state[i].shutdown = true;+      gpr_cv_signal(&thd_state[i].cv);+      gpr_mu_unlock(&thd_state[i].mu);     }-    /* ensure no thread is adding a new thread... once this is past, then-       no thread will try to add a new one either (since shutdown is true) */-    gpr_spinlock_lock(&g_adding_thread_lock);-    gpr_spinlock_unlock(&g_adding_thread_lock);-    for (gpr_atm i = 0; i < g_cur_threads; i++) {-      g_thread_state[i].thd.Join();++    /* Ensure no thread is adding a new thread. Once this is past, then no+     * thread will try to add a new one either (since shutdown is true) */+    gpr_spinlock_lock(&adding_thread_lock);+    gpr_spinlock_unlock(&adding_thread_lock);++    for (gpr_atm i = 0; i < num_threads; i++) {+      thd_state[i].thd.Join();     }-    gpr_atm_no_barrier_store(&g_cur_threads, 0);-    for (size_t i = 0; i < g_max_threads; i++) {-      gpr_mu_destroy(&g_thread_state[i].mu);-      gpr_cv_destroy(&g_thread_state[i].cv);-      run_closures(g_thread_state[i].elems);++    gpr_atm_no_barrier_store(&num_threads, 0);+    for (size_t i = 0; i < max_threads; i++) {+      gpr_mu_destroy(&thd_state[i].mu);+      gpr_cv_destroy(&thd_state[i].cv);+      RunClosures(thd_state[i].elems);     }-    gpr_free(g_thread_state);++    gpr_free(thd_state);     gpr_tls_destroy(&g_this_thread_state);   } } -void grpc_executor_init() {-  gpr_atm_no_barrier_store(&g_cur_threads, 0);-  grpc_executor_set_threading(true);-}--void grpc_executor_shutdown() { grpc_executor_set_threading(false); }+void GrpcExecutor::Shutdown() { SetThreading(false); } -static void executor_thread(void* arg) {+void GrpcExecutor::ThreadMain(void* arg) {   thread_state* ts = static_cast<thread_state*>(arg);   gpr_tls_set(&g_this_thread_state, (intptr_t)ts);    grpc_core::ExecCtx exec_ctx(GRPC_EXEC_CTX_FLAG_IS_INTERNAL_THREAD);    size_t subtract_depth = 0;   for (;;) {-    if (executor_trace.enabled()) {-      gpr_log(GPR_INFO, ""EXECUTOR[%d]: step (sub_depth=%"" PRIdPTR "")"",-              static_cast<int>(ts - g_thread_state), subtract_depth);-    }+    EXECUTOR_TRACE(""EXECUTOR[%ld]: step (sub_depth=%"" PRIdPTR "")"", ts->id,+                   subtract_depth);+     gpr_mu_lock(&ts->mu);     ts->depth -= subtract_depth;+    // Wait for closures to be enqueued or for the executor to be shutdown     while (grpc_closure_list_empty(ts->elems) && !ts->shutdown) {       ts->queued_long_job = false;       gpr_cv_wait(&ts->cv, &ts->mu, gpr_inf_future(GPR_CLOCK_MONOTONIC));     }+     if (ts->shutdown) {-      if (executor_trace.enabled()) {-        gpr_log(GPR_INFO, ""EXECUTOR[%d]: shutdown"",-                static_cast<int>(ts - g_thread_state));-      }+      EXECUTOR_TRACE(""EXECUTOR[%ld]: shutdown"", ts->id);       gpr_mu_unlock(&ts->mu);       break;     }+     GRPC_STATS_INC_EXECUTOR_QUEUE_DRAINED();-    grpc_closure_list exec = ts->elems;+    grpc_closure_list closures = ts->elems;     ts->elems = GRPC_CLOSURE_LIST_INIT;     gpr_mu_unlock(&ts->mu);-    if (executor_trace.enabled()) {-      gpr_log(GPR_INFO, ""EXECUTOR[%d]: execute"",-              static_cast<int>(ts - g_thread_state));-    }++    EXECUTOR_TRACE(""EXECUTOR[%ld]: execute"", ts->id);      grpc_core::ExecCtx::Get()->InvalidateNow();-    subtract_depth = run_closures(exec);+    subtract_depth = RunClosures(closures);   } } -static void executor_push(grpc_closure* closure, grpc_error* error,-                          bool is_short) {+void GrpcExecutor::Enqueue(grpc_closure* closure, grpc_error* error,+                           bool is_short) {   bool retry_push;   if (is_short) {     GRPC_STATS_INC_EXECUTOR_SCHEDULED_SHORT_ITEMS();   } else {     GRPC_STATS_INC_EXECUTOR_SCHEDULED_LONG_ITEMS();   }+   do {     retry_push = false;     size_t cur_thread_count =-        static_cast<size_t>(gpr_atm_no_barrier_load(&g_cur_threads));+        static_cast<size_t>(gpr_atm_no_barrier_load(&num_threads));++    // If the number of threads is zero(i.e either the executor is not threaded+    // or already shutdown), then queue the closure on the exec context itself     if (cur_thread_count == 0) {-      if (executor_trace.enabled()) { #ifndef NDEBUG-        gpr_log(GPR_DEBUG, ""EXECUTOR: schedule %p (created %s:%d) inline"",-                closure, closure->file_created, closure->line_created);+      EXECUTOR_TRACE(""EXECUTOR: schedule %p (created %s:%d) inline"", closure,+                     closure->file_created, closure->line_created); #else-        gpr_log(GPR_INFO, ""EXECUTOR: schedule %p inline"", closure);+      EXECUTOR_TRACE(""EXECUTOR: schedule %p inline"", closure); #endif-      }       grpc_closure_list_append(grpc_core::ExecCtx::Get()->closure_list(),                                closure, error);       return;     }+     thread_state* ts = (thread_state*)gpr_tls_get(&g_this_thread_state);     if (ts == nullptr) {-      ts = &g_thread_state[GPR_HASH_POINTER(grpc_core::ExecCtx::Get(),-                                            cur_thread_count)];+      ts = &thd_state[GPR_HASH_POINTER(grpc_core::ExecCtx::Get(),+                                       cur_thread_count)];     } else {       GRPC_STATS_INC_EXECUTOR_SCHEDULED_TO_SELF();     }+     thread_state* orig_ts = ts;      bool try_new_thread;     for (;;) {-      if (executor_trace.enabled()) { #ifndef NDEBUG-        gpr_log(-            GPR_DEBUG,-            ""EXECUTOR: try to schedule %p (%s) (created %s:%d) to thread %d"",-            closure, is_short ? ""short"" : ""long"", closure->file_created,-            closure->line_created, static_cast<int>(ts - g_thread_state));+      EXECUTOR_TRACE(+          ""EXECUTOR: try to schedule %p (%s) (created %s:%d) to thread %ld"",+          closure, is_short ? ""short"" : ""long"", closure->file_created,+          closure->line_created, ts->id); #else-        gpr_log(GPR_INFO, ""EXECUTOR: try to schedule %p (%s) to thread %d"",-                closure, is_short ? ""short"" : ""long"",-                (int)(ts - g_thread_state));+      EXECUTOR_TRACE(""EXECUTOR: try to schedule %p (%s) to thread %ld"", closure,+                     is_short ? ""short"" : ""long"", ts->id); #endif-      }+       gpr_mu_lock(&ts->mu);       if (ts->queued_long_job) {         // if there's a long job queued, we never queue anything else to this         // queue (since long jobs can take 'infinite' time and we need to-        // guarantee no starvation)-        // ... spin through queues and try again+        // guarantee no starvation). Spin through queues and try again         gpr_mu_unlock(&ts->mu);-        size_t idx = static_cast<size_t>(ts - g_thread_state);-        ts = &g_thread_state[(idx + 1) % cur_thread_count];+        size_t idx = ts->id;+        ts = &thd_state[(idx + 1) % cur_thread_count];         if (ts == orig_ts) {+          // We cycled through all the threads. Retry enqueue again (by creating+          // a new thread)           retry_push = true;+          // TODO (sreek): What if the executor is shutdown OR if+          // cur_thread_count is already equal to max_threads ? (currently - as+          // of July 2018, we do not run in to this issue because there is only+          // one instance of long job in gRPC. This has to be fixed soon)           try_new_thread = true;           break;         }+         continue;       }++      // == Found the thread state (i.e thread) to enqueue this closure! ==++      // Also, if this thread has been waiting for closures, wake it up.+      // - If grpc_closure_list_empty() is true and the Executor is not+      //   shutdown, it means that the thread must be waiting in ThreadMain()+      // - Note that gpr_cv_signal() won't immediately wakeup the thread. That+      //   happens after we release the mutex &ts->mu a few lines below       if (grpc_closure_list_empty(ts->elems) && !ts->shutdown) {         GRPC_STATS_INC_EXECUTOR_WAKEUP_INITIATED();         gpr_cv_signal(&ts->cv);       }+       grpc_closure_list_append(&ts->elems, closure, error);++      // If we already queued more than MAX_DEPTH number of closures on this+      // thread, use this as a hint to create more threads       ts->depth++;       try_new_thread = ts->depth > MAX_DEPTH &&-                       cur_thread_count < g_max_threads && !ts->shutdown;-      if (!is_short) ts->queued_long_job = true;+                       cur_thread_count < max_threads && !ts->shutdown;++      ts->queued_long_job = !is_short;+       gpr_mu_unlock(&ts->mu);       break;     }-    if (try_new_thread && gpr_spinlock_trylock(&g_adding_thread_lock)) {++    if (try_new_thread && gpr_spinlock_trylock(&adding_thread_lock)) {       cur_thread_count =-          static_cast<size_t>(gpr_atm_no_barrier_load(&g_cur_threads));-      if (cur_thread_count < g_max_threads) {-        gpr_atm_no_barrier_store(&g_cur_threads, cur_thread_count + 1);--        g_thread_state[cur_thread_count].thd =-            grpc_core::Thread(""grpc_executor"", executor_thread,-                              &g_thread_state[cur_thread_count]);-        g_thread_state[cur_thread_count].thd.Start();+          static_cast<size_t>(gpr_atm_no_barrier_load(&num_threads));+      if (cur_thread_count < max_threads) {+        // Increment num_threads (Safe to do a no_barrier_store instead of a+        // cas because we always increment num_threads under the+        // 'adding_thread_lock')+        gpr_atm_no_barrier_store(&num_threads, cur_thread_count + 1);++        thd_state[cur_thread_count].thd = grpc_core::Thread(+            name, &GrpcExecutor::ThreadMain, &thd_state[cur_thread_count]);+        thd_state[cur_thread_count].thd.Start();       }-      gpr_spinlock_unlock(&g_adding_thread_lock);+      gpr_spinlock_unlock(&adding_thread_lock);     }+     if (retry_push) {       GRPC_STATS_INC_EXECUTOR_PUSH_RETRIES();     }   } while (retry_push); } -static void executor_push_short(grpc_closure* closure, grpc_error* error) {-  executor_push(closure, error, true);+static GrpcExecutor g_global_executor(""grpc-executor"");++void enqueue_long(grpc_closure* closure, grpc_error* error) {+  g_global_executor.Enqueue(closure, error, false);",Added /* is_short */ comment.  Adding `EnqueueShort`/`EnqueueLong` would be a bigger refactor,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15982,201745267,2018-07-11T15:49:42Z,src/core/lib/channel/channelz_registry.h,"@@ -23,6 +23,7 @@  #include ""src/core/lib/avl/avl.h""",This include is no longer needed.,OK
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/15853,201871160,2018-07-11T23:35:48Z,src/cpp/server/load_reporter/load_reporter_async_service_impl.h,"@@ -0,0 +1,195 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_SRC_CPP_SERVER_LOAD_REPORTER_ASYNC_SERVICE_IMPL_H+#define GRPC_SRC_CPP_SERVER_LOAD_REPORTER_ASYNC_SERVICE_IMPL_H++#include <grpc/support/port_platform.h>++#include <grpc/support/log.h>+#include <grpcpp/alarm.h>+#include <grpcpp/grpcpp.h>++#include ""src/core/lib/gprpp/thd.h""+#include ""src/cpp/server/load_reporter/load_reporter.h""++namespace grpc {+namespace load_reporter {++// Async load reporting service. It's mainly responsible for controlling the+// procedure of incoming requests. The real business logic is handed off to the+// LoadReporter. There should be at most one instance of this service on a+// server to avoid spreading the load data into multiple places.+class LoadReporterAsyncServiceImpl+    : public grpc::lb::v1::LoadReporter::AsyncService {+ public:+  explicit LoadReporterAsyncServiceImpl(+      std::unique_ptr<ServerCompletionQueue> cq);+  ~LoadReporterAsyncServiceImpl();++  // Starts the working thread.+  void StartThread();++  // Not copyable nor movable.+  LoadReporterAsyncServiceImpl(const LoadReporterAsyncServiceImpl&) = delete;+  LoadReporterAsyncServiceImpl& operator=(const LoadReporterAsyncServiceImpl&) =+      delete;++ private:+  class ReportLoadHandler;++  // A tag that can be called with a bool argument. It's tailored for+  // ReportLoadHandler's use. Before being used, it should be constructed with a+  // method of ReportLoadHandler and a shared pointer to the handler. The+  // shared pointer will be moved to the invoked function and the function can+  // only be invoked once. That makes ref counting of the handler easier,+  // because the shared pointer is not bound to the function and can be gone+  // once the invoked function returns (if not used any more).+  class CallableTag {+   public:+    using HandlerFunction =+        std::function<void(std::shared_ptr<ReportLoadHandler>, bool)>;++    CallableTag() {}++    CallableTag(HandlerFunction func,+                std::shared_ptr<ReportLoadHandler> handler)+        : handler_function_(std::move(func)), handler_(std::move(handler)) {+      GPR_ASSERT(handler_function_ != nullptr);+      GPR_ASSERT(handler_ != nullptr);+    }++    // Runs the tag. This should be called only once. The handler is no longer+    // owned by this tag after this method is invoked.+    void Run(bool ok);++    // Releases and returns the shared pointer to the handler.+    std::shared_ptr<ReportLoadHandler> ReleaseHandler() {+      return std::move(handler_);+    }++   private:+    HandlerFunction handler_function_ = nullptr;+    std::shared_ptr<ReportLoadHandler> handler_;+  };++  // Each handler takes care of one load reporting stream. It contains+  // per-stream data and it will access the members of the parent class (i.e.,+  // LoadReporterAsyncServiceImpl) for service-wide data (e.g., the load data).+  class ReportLoadHandler+      : public std::enable_shared_from_this<ReportLoadHandler> {+   public:+    // Instantiates a ReportLoadHandler and requests the next load reporting+    // call. The handler object will manage its own lifetime, so no action is+    // needed from the caller any more regarding that object.+    static void CreateAndStart(ServerCompletionQueue* cq,+                               LoadReporterAsyncServiceImpl* service,+                               LoadReporter* load_reporter);++    // This ctor is public because we want to use std::make_shared<> in+    // CreateAndStart(). This ctor shouldn't be used elsewhere.+    ReportLoadHandler(ServerCompletionQueue* cq,+                      LoadReporterAsyncServiceImpl* service,+                      LoadReporter* load_reporter);++   private:+    // After the handler has a call request delivered, it starts reading the+    // initial request. Also, a new handler is spawned so that we can keep+    // servicing future calls.+    void OnRequestDelivered(std::shared_ptr<ReportLoadHandler> self, bool ok);++    // The first Read() is expected to succeed, after which the handler starts+    // sending load reports back to the balancer. The second Read() is+    // expected to fail, which happens when the balancer half-closes the+    // stream to signal that it's no longer interested in the load reports. For+    // the latter case, the handler will then close the stream.+    void OnReadDone(std::shared_ptr<ReportLoadHandler> self, bool ok);++    // The report sending operations are sequential as: send report -> send+    // done, schedule the next send -> waiting for the alarm to fire -> alarm+    // fires, send report -> ...+    void SendReport(std::shared_ptr<ReportLoadHandler> self, bool ok);+    void ScheduleNextReport(std::shared_ptr<ReportLoadHandler> self, bool ok);++    // Called when Finish() is done.+    void OnFinishDone(std::shared_ptr<ReportLoadHandler> self, bool ok);++    // Called when AsyncNotifyWhenDone() notifies us.+    void OnDoneNotified(std::shared_ptr<ReportLoadHandler> self, bool ok);++    void Shutdown(std::shared_ptr<ReportLoadHandler> self, const char* reason);++    // The key fields of the stream.+    grpc::string lb_id_;+    grpc::string load_balanced_hostname_;+    grpc::string load_key_;+    uint64_t load_report_interval_ms_;++    // The data for RPC communication with the load reportee.+    ServerContext ctx_;+    ::grpc::lb::v1::LoadReportRequest request_;++    // The members passed down from LoadReporterAsyncServiceImpl.+    ServerCompletionQueue* cq_;+    LoadReporterAsyncServiceImpl* service_;+    LoadReporter* load_reporter_;+    ServerAsyncReaderWriter<::grpc::lb::v1::LoadReportResponse,+                            ::grpc::lb::v1::LoadReportRequest>+        stream_;++    // The status of the RPC progress.+    enum CallStatus {+      WAITING_FOR_DELIVERY,+      DELIVERED,+      INITIAL_REQUEST_RECEIVED,+      INITIAL_RESPONSE_SENT,+      FINISH_CALLED+    } call_status_;+    bool shutdown_{false};+    bool done_notified_{false};+    bool is_cancelled_{false};+    CallableTag on_done_notified_;+    CallableTag on_finish_done_;+    CallableTag next_inbound_;+    CallableTag next_outbound_;+    std::unique_ptr<Alarm> next_report_alarm_;+  };++  // Handles the incoming requests and drives the completion queue in a loop.+  static void Work(void* arg);++  // Schedules the next data fetching from Census and LB feedback sampling.+  void ScheduleNextFetchAndSample();++  // Fetches data from Census and samples LB feedback.+  void FetchAndSample(bool ok);++  std::unique_ptr<ServerCompletionQueue> cq_;+  // To synchronize the operations related to shutdown state of cq_, so that we+  // don't enqueue new tags into cq_ after it is already shut down.+  std::mutex cq_shutdown_mu_;","It's only meant to protect the cq shutdown state (since the shutdown state can be changed by other thread). That's why it's declared in the service class instead of the handler class. The handler needs to use this mutex when it wants to use the cq. But the handler itself doesn't need to be protected. Also, please note that all the operations of the handlers are done in a single thread. ",OK
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/15853,201877131,2018-07-12T00:15:52Z,src/cpp/server/load_reporter/load_reporter_async_service_impl.h,"@@ -0,0 +1,195 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_SRC_CPP_SERVER_LOAD_REPORTER_ASYNC_SERVICE_IMPL_H+#define GRPC_SRC_CPP_SERVER_LOAD_REPORTER_ASYNC_SERVICE_IMPL_H++#include <grpc/support/port_platform.h>++#include <grpc/support/log.h>+#include <grpcpp/alarm.h>+#include <grpcpp/grpcpp.h>++#include ""src/core/lib/gprpp/thd.h""+#include ""src/cpp/server/load_reporter/load_reporter.h""++namespace grpc {+namespace load_reporter {++// Async load reporting service. It's mainly responsible for controlling the+// procedure of incoming requests. The real business logic is handed off to the+// LoadReporter. There should be at most one instance of this service on a+// server to avoid spreading the load data into multiple places.+class LoadReporterAsyncServiceImpl+    : public grpc::lb::v1::LoadReporter::AsyncService {+ public:+  explicit LoadReporterAsyncServiceImpl(+      std::unique_ptr<ServerCompletionQueue> cq);+  ~LoadReporterAsyncServiceImpl();++  // Starts the working thread.+  void StartThread();++  // Not copyable nor movable.+  LoadReporterAsyncServiceImpl(const LoadReporterAsyncServiceImpl&) = delete;+  LoadReporterAsyncServiceImpl& operator=(const LoadReporterAsyncServiceImpl&) =+      delete;++ private:+  class ReportLoadHandler;++  // A tag that can be called with a bool argument. It's tailored for+  // ReportLoadHandler's use. Before being used, it should be constructed with a+  // method of ReportLoadHandler and a shared pointer to the handler. The+  // shared pointer will be moved to the invoked function and the function can+  // only be invoked once. That makes ref counting of the handler easier,+  // because the shared pointer is not bound to the function and can be gone+  // once the invoked function returns (if not used any more).+  class CallableTag {+   public:+    using HandlerFunction =+        std::function<void(std::shared_ptr<ReportLoadHandler>, bool)>;++    CallableTag() {}++    CallableTag(HandlerFunction func,+                std::shared_ptr<ReportLoadHandler> handler)+        : handler_function_(std::move(func)), handler_(std::move(handler)) {+      GPR_ASSERT(handler_function_ != nullptr);+      GPR_ASSERT(handler_ != nullptr);+    }++    // Runs the tag. This should be called only once. The handler is no longer+    // owned by this tag after this method is invoked.+    void Run(bool ok);++    // Releases and returns the shared pointer to the handler.+    std::shared_ptr<ReportLoadHandler> ReleaseHandler() {+      return std::move(handler_);+    }++   private:+    HandlerFunction handler_function_ = nullptr;+    std::shared_ptr<ReportLoadHandler> handler_;+  };++  // Each handler takes care of one load reporting stream. It contains+  // per-stream data and it will access the members of the parent class (i.e.,+  // LoadReporterAsyncServiceImpl) for service-wide data (e.g., the load data).+  class ReportLoadHandler+      : public std::enable_shared_from_this<ReportLoadHandler> {+   public:+    // Instantiates a ReportLoadHandler and requests the next load reporting+    // call. The handler object will manage its own lifetime, so no action is+    // needed from the caller any more regarding that object.+    static void CreateAndStart(ServerCompletionQueue* cq,+                               LoadReporterAsyncServiceImpl* service,+                               LoadReporter* load_reporter);++    // This ctor is public because we want to use std::make_shared<> in+    // CreateAndStart(). This ctor shouldn't be used elsewhere.+    ReportLoadHandler(ServerCompletionQueue* cq,+                      LoadReporterAsyncServiceImpl* service,+                      LoadReporter* load_reporter);++   private:+    // After the handler has a call request delivered, it starts reading the","Good question!Ultimately we want to simplify the refcounting of the handlers, which basically means the handler callback doesn't need to do anything if it doesn't have a next step to do (e.g., the `OnFinishDone()` callback is the end of a series of operations). But the problem is that the `std::function` will always hold an extra ref if we `std::bind()` the shared pointer to the callback function when creating the tag. That means we have to reset the function to release that extra ref if the callback doesn't have any next step, which doesn't meet our goal. So we add `CallableTag` to temporarily hold the ref for the half-bound closure and feed the ref to that closure when it's invoked. As a result, we avoid binding the shared pointer to any `std::function`. That's why all the handler callbacks have an extra `std::shared_ptr<>` parameter now. `shared_from_this()` solves a simpler problem - creating the ref. But now that we have the extra parameter, it can be removed.",OK
22083734,matt-kwong,https://api.github.com/repos/grpc/grpc/pulls/16002,202125821,2018-07-12T17:57:49Z,tools/dockerfile/test/bazel/Dockerfile,"@@ -15,7 +15,7 @@ FROM gcr.io/oss-fuzz-base/base-builder  # Install basic packages and Bazel dependencies.-RUN apt-get update && apt-get install -y software-properties-common python-software-properties+RUN apt-get update && apt-get install -y software-properties-common python-software-properties python-dev",Our Dockerfiles are generated from template files because we have so many of them and a lot of them share common package installations. Can you make this change to https://github.com/grpc/grpc/blob/master/templates/tools/dockerfile/test/bazel/Dockerfile.template and then run `./tools/buildgen/generate_projects.sh`? The script will update this Dockerfile for you.,OK
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/15992,202390842,2018-07-13T15:39:01Z,bazel/grpc_python.bzl,"@@ -0,0 +1,70 @@+""""""Custom rules for gRPC Python""""""++# Modified from @cython//:Tools/rules.bzl","These first three lines invite the question ""why do we have to write our own `pyx_library` anyway?"" and... there should be an answer here. I don't see the term ""gRPC"" appear in the rest of this file - what's gRPC-specific about this code? If nothing, does this file belong in the Cython repository? If so, we can still add it to this repository today but should there also be a TODO to migrate it to the Cython repository?",OK
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/15992,202392987,2018-07-13T15:46:12Z,third_party/py/python_configure.bzl,"@@ -0,0 +1,330 @@+""""""Repository rule for Python autoconfiguration.++`python_configure` depends on the following environment variables:++  * `PYTHON_BIN_PATH`: location of python binary.+  * `PYTHON_LIB_PATH`: Location of python libraries.+""""""++_BAZEL_SH = ""BAZEL_SH""+_PYTHON_BIN_PATH = ""PYTHON_BIN_PATH""+_PYTHON_LIB_PATH = ""PYTHON_LIB_PATH""+_TF_PYTHON_CONFIG_REPO = ""TF_PYTHON_CONFIG_REPO""+++def _tpl(repository_ctx, tpl, substitutions={}, out=None):+  if not out:+    out = tpl+  repository_ctx.template(+      out,+      Label(""//third_party/py:%s.tpl"" % tpl),+      substitutions)+++def _fail(msg):+  """"""Output failure message when auto configuration fails.""""""+  red = ""\033[0;31m""+  no_color = ""\033[0m""+  fail(""%sPython Configuration Error:%s %s\n"" % (red, no_color, msg))+++def _is_windows(repository_ctx):+  """"""Returns true if the host operating system is windows.""""""+  os_name = repository_ctx.os.name.lower()+  if os_name.find(""windows"") != -1:+    return True+  return False+++def _execute(repository_ctx, cmdline, error_msg=None, error_details=None,+             empty_stdout_fine=False):+  """"""Executes an arbitrary shell command.++  Args:+    repository_ctx: the repository_ctx object+    cmdline: list of strings, the command to execute+    error_msg: string, a summary of the error if the command fails+    error_details: string, details about the error or steps to fix it+    empty_stdout_fine: bool, if True, an empty stdout result is fine, otherwise+      it's an error+  Return:+    the result of repository_ctx.execute(cmdline)+  """"""+  result = repository_ctx.execute(cmdline)+  if result.stderr or not (empty_stdout_fine or result.stdout):+    _fail(""\n"".join([+        error_msg.strip() if error_msg else ""Repository command failed"",+        result.stderr.strip(),+        error_details if error_details else """"]))+  return result","Tuck this inside an `else:`. (The `_fail` call raises some sort of exception, right?)",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/15992,202394117,2018-07-13T15:49:35Z,third_party/py/python_configure.bzl,"@@ -0,0 +1,330 @@+""""""Repository rule for Python autoconfiguration.++`python_configure` depends on the following environment variables:++  * `PYTHON_BIN_PATH`: location of python binary.+  * `PYTHON_LIB_PATH`: Location of python libraries.+""""""++_BAZEL_SH = ""BAZEL_SH""+_PYTHON_BIN_PATH = ""PYTHON_BIN_PATH""+_PYTHON_LIB_PATH = ""PYTHON_LIB_PATH""+_TF_PYTHON_CONFIG_REPO = ""TF_PYTHON_CONFIG_REPO""+++def _tpl(repository_ctx, tpl, substitutions={}, out=None):+  if not out:+    out = tpl+  repository_ctx.template(+      out,+      Label(""//third_party/py:%s.tpl"" % tpl),+      substitutions)+++def _fail(msg):+  """"""Output failure message when auto configuration fails.""""""+  red = ""\033[0;31m""+  no_color = ""\033[0m""+  fail(""%sPython Configuration Error:%s %s\n"" % (red, no_color, msg))+++def _is_windows(repository_ctx):+  """"""Returns true if the host operating system is windows.""""""+  os_name = repository_ctx.os.name.lower()+  if os_name.find(""windows"") != -1:+    return True+  return False+++def _execute(repository_ctx, cmdline, error_msg=None, error_details=None,+             empty_stdout_fine=False):+  """"""Executes an arbitrary shell command.++  Args:+    repository_ctx: the repository_ctx object+    cmdline: list of strings, the command to execute+    error_msg: string, a summary of the error if the command fails+    error_details: string, details about the error or steps to fix it+    empty_stdout_fine: bool, if True, an empty stdout result is fine, otherwise+      it's an error+  Return:+    the result of repository_ctx.execute(cmdline)+  """"""+  result = repository_ctx.execute(cmdline)+  if result.stderr or not (empty_stdout_fine or result.stdout):+    _fail(""\n"".join([+        error_msg.strip() if error_msg else ""Repository command failed"",+        result.stderr.strip(),+        error_details if error_details else """"]))+  return result+++def _read_dir(repository_ctx, src_dir):+  """"""Returns a string with all files in a directory.++  Finds all files inside a directory, traversing subfolders and following+  symlinks. The returned string contains the full path of all files+  separated by line breaks.+  """"""+  if _is_windows(repository_ctx):+    src_dir = src_dir.replace(""/"", ""\\"")+    find_result = _execute(+        repository_ctx, [""cmd.exe"", ""/c"", ""dir"", src_dir, ""/b"", ""/s"", ""/a-d""],+        empty_stdout_fine=True)+    # src_files will be used in genrule.outs where the paths must+    # use forward slashes.+    result = find_result.stdout.replace(""\\"", ""/"")+  else:+    find_result = _execute(+        repository_ctx, [""find"", src_dir, ""-follow"", ""-type"", ""f""],+        empty_stdout_fine=True)+    result = find_result.stdout+  return result+++def _genrule(src_dir, genrule_name, command, outs):+  """"""Returns a string with a genrule.++  Genrule executes the given command and produces the given outputs.+  """"""+  return (+      'genrule(\n' ++      '    name = ""' ++      genrule_name + '"",\n' ++      '    outs = [\n' ++      outs ++      '\n    ],\n' ++      '    cmd = """"""\n' ++      command ++      '\n   """""",\n' ++      ')\n'+  )+++def _norm_path(path):+  """"""Returns a path with '/' and remove the trailing slash.""""""+  path = path.replace(""\\"", ""/"")+  if path[-1] == ""/"":+    path = path[:-1]+  return path+++def _symlink_genrule_for_dir(repository_ctx, src_dir, dest_dir, genrule_name,+    src_files = [], dest_files = []):+  """"""Returns a genrule to symlink(or copy if on Windows) a set of files.++  If src_dir is passed, files will be read from the given directory; otherwise+  we assume files are in src_files and dest_files+  """"""+  if src_dir != None:+    src_dir = _norm_path(src_dir)+    dest_dir = _norm_path(dest_dir)+    files = '\n'.join(sorted(_read_dir(repository_ctx, src_dir).splitlines()))+    # Create a list with the src_dir stripped to use for outputs.+    dest_files = files.replace(src_dir, '').splitlines()+    src_files = files.splitlines()+  command = []+  outs = []+  for i in range(len(dest_files)):+    if dest_files[i] != """":+      # If we have only one file to link we do not want to use the dest_dir, as+      # $(@D) will include the full path to the file.+      dest = '$(@D)/' + dest_dir + dest_files[i] if len(dest_files) != 1 else '$(@D)/' + dest_files[i]+      # On Windows, symlink is not supported, so we just copy all the files.+      cmd = 'cp -f' if _is_windows(repository_ctx) else 'ln -s'+      command.append(cmd + ' ""%s"" ""%s""' % (src_files[i] , dest))+      outs.append('        ""' + dest_dir + dest_files[i] + '"",')+  genrule = _genrule(src_dir, genrule_name, "" && "".join(command),+                     ""\n"".join(outs))+  return genrule+++def _get_python_bin(repository_ctx):+  """"""Gets the python bin path.""""""+  python_bin = repository_ctx.os.environ.get(_PYTHON_BIN_PATH)+  if python_bin != None:+    return python_bin+  python_bin_path = repository_ctx.which(""python"")+  if python_bin_path != None:+    return str(python_bin_path)+  _fail(""Cannot find python in PATH, please make sure "" ++        ""python is installed and add its directory in PATH, or --define "" ++        ""%s='/something/else'.\nPATH=%s"" % (+            _PYTHON_BIN_PATH, repository_ctx.os.environ.get(""PATH"", """")))+++def _get_bash_bin(repository_ctx):+  """"""Gets the bash bin path.""""""+  bash_bin = repository_ctx.os.environ.get(_BAZEL_SH)+  if bash_bin != None:+    return bash_bin+  else:+    bash_bin_path = repository_ctx.which(""bash"")+    if bash_bin_path != None:+      return str(bash_bin_path)+    else:+      _fail(""Cannot find bash in PATH, please make sure "" ++            ""bash is installed and add its directory in PATH, or --define "" ++            ""%s='/path/to/bash'.\nPATH=%s"" % (+                _BAZEL_SH, repository_ctx.os.environ.get(""PATH"", """")))+++def _get_python_lib(repository_ctx, python_bin):+  """"""Gets the python lib path.""""""+  python_lib = repository_ctx.os.environ.get(_PYTHON_LIB_PATH)+  if python_lib != None:+    return python_lib+  print_lib = (""<<END\n"" ++      ""from __future__ import print_function\n"" ++      ""import site\n"" ++      ""import os\n"" ++      ""\n"" ++      ""try:\n"" ++      ""  input = raw_input\n"" ++      ""except NameError:\n"" ++      ""  pass\n"" ++      ""\n"" ++      ""python_paths = []\n"" ++      ""if os.getenv('PYTHONPATH') is not None:\n"" ++      ""  python_paths = os.getenv('PYTHONPATH').split(':')\n"" ++      ""try:\n"" ++      ""  library_paths = site.getsitepackages()\n"" ++      ""except AttributeError:\n"" ++      "" from distutils.sysconfig import get_python_lib\n"" ++      "" library_paths = [get_python_lib()]\n"" ++      ""all_paths = set(python_paths + library_paths)\n"" ++      ""paths = []\n"" ++      ""for path in all_paths:\n"" ++      ""  if os.path.isdir(path):\n"" ++      ""    paths.append(path)\n"" ++      ""if len(paths) >=1:\n"" ++      ""  print(paths[0])\n"" ++      ""END"")+  cmd = '%s - %s' % (python_bin, print_lib)+  result = repository_ctx.execute([_get_bash_bin(repository_ctx), ""-c"", cmd])+  return result.stdout.strip('\n')+++def _check_python_lib(repository_ctx, python_lib):+  """"""Checks the python lib path.""""""+  cmd = 'test -d ""%s"" -a -x ""%s""' % (python_lib, python_lib)+  result = repository_ctx.execute([_get_bash_bin(repository_ctx), ""-c"", cmd])+  if result.return_code == 1:+    _fail(""Invalid python library path: %s"" % python_lib)+++def _check_python_bin(repository_ctx, python_bin):+  """"""Checks the python bin path.""""""+  cmd =  '[[ -x ""%s"" ]] && [[ ! -d ""%s"" ]]' % (python_bin, python_bin)+  result = repository_ctx.execute([_get_bash_bin(repository_ctx), ""-c"", cmd])+  if result.return_code == 1:+    _fail(""--define %s='%s' is not executable. Is it the python binary?"" % (+        _PYTHON_BIN_PATH, python_bin))+++def _get_python_include(repository_ctx, python_bin):+  """"""Gets the python include path.""""""+  result = _execute(+      repository_ctx,+      [python_bin, ""-c"",+       'from __future__ import print_function;' ++       'from distutils import sysconfig;' ++       'print(sysconfig.get_python_inc())'],+      error_msg=""Problem getting python include path."",+      error_details=(""Is the Python binary path set up right? "" ++                     ""(See ./configure or "" + _PYTHON_BIN_PATH + "".) "" ++                     ""Is distutils installed?""))+  return result.stdout.splitlines()[0]+++def _get_python_import_lib_name(repository_ctx, python_bin):+  """"""Get Python import library name (pythonXY.lib) on Windows.""""""+  result = _execute(+      repository_ctx,+      [python_bin, ""-c"",+       'import sys;' ++       'print(""python"" + str(sys.version_info[0]) + ' ++       '      str(sys.version_info[1]) + "".lib"")'],+      error_msg=""Problem getting python import library."",+      error_details=(""Is the Python binary path set up right? "" ++                     ""(See ./configure or "" + _PYTHON_BIN_PATH + "".) ""))+  return result.stdout.splitlines()[0]+++def _get_numpy_include(repository_ctx, python_bin):+  """"""Gets the numpy include path.""""""+  return _execute(repository_ctx,+                  [python_bin, ""-c"",+                   'from __future__ import print_function;' ++                   'import numpy;' ++                   ' print(numpy.get_include());'],+                  error_msg=""Problem getting numpy include path."",+                  error_details=""Is numpy installed?"").stdout.splitlines()[0]+++def _create_local_python_repository(repository_ctx):+  """"""Creates the repository containing files set up to build with Python.""""""+  python_bin = _get_python_bin(repository_ctx)+  _check_python_bin(repository_ctx, python_bin)+  python_lib = _get_python_lib(repository_ctx, python_bin)+  _check_python_lib(repository_ctx, python_lib)+  python_include = _get_python_include(repository_ctx, python_bin)+  # numpy_include = _get_numpy_include(repository_ctx, python_bin) + '/numpy'",We generally don't allow commented-out code in the repository. Should this be some special exception? Should it be a TODO if the commented-out code suggests something to be done in the future?,OK
26072277,dfawley,https://api.github.com/repos/grpc/grpc/pulls/15460,202421020,2018-07-13T17:28:53Z,doc/PROTOCOL-SEMANTICS.md,"@@ -0,0 +1,268 @@+# gRPC semantics++gRPC has many features, but the most fundamental core is the ability to perform+RPCs. The goal of this document is defining the semantics of gRPC's RPCs.++## Channels++Most implementations will have Channel and Server concepts. A Channel is a+virtual connection to an endpoint, capable of sending RPCs. Channel is ""virtual""+because the Channel is free to have zero or many actual connections. A Channel+is free to determine which actual endpoint to use and may change it every RPC,+permitting client-side load balancing. A Server is capable of receiving incoming+connections and receiving RPCs.++A ""connection"" is not a gRPC semantic concept and thus users should not assume a+correlation between connections and RPCs. Although, practically, users should be+aware of the common restriction that RPCs are unable to survive longer than the+connection on which they exist.++The exact details of how the communication is performed and higher level+abstractions can change when necessary and are thus not a focus for this+document. Although implementations SHOULD support the [HTTP/2+transport](PROTOCOL-HTTP2.md) to provide a basis for interoperability.++## Methods++An RPC is performed on a Method. The Method has a name, defines the intended+operation, the message types involved with the RPC, and the cardinality of+those messages.  It does not define the endpoint to send the RPC to; this is+normally handled by the Channel.++A Method's intended operation is just normal documentation describing what a+Method does, intended for a developer. gRPC itself is not generally aware of the+intended operation.++A Method has a request message type and a separate response message type. gRPC+is only aware of these types well enough to serialize and deserialize them.+Messages are considered opaque byte sequences of a known length to gRPC itself.","I've been considering this w.r.t. my transport redesign.  Some transports (probably only inproc) are not actually byte-based.  The wire protocol needs to know the encoder/compressor used to transmit the message; these operations seem more like transport-level details to me, not grpc call semantic details.",OK
26072277,dfawley,https://api.github.com/repos/grpc/grpc/pulls/15460,202462707,2018-07-13T20:22:22Z,doc/PROTOCOL-SEMANTICS.md,"@@ -0,0 +1,268 @@+# gRPC semantics++gRPC has many features, but the most fundamental core is the ability to perform+RPCs. The goal of this document is defining the semantics of gRPC's RPCs.++## Channels++Most implementations will have Channel and Server concepts. A Channel is a+virtual connection to an endpoint, capable of sending RPCs. Channel is ""virtual""+because the Channel is free to have zero or many actual connections. A Channel+is free to determine which actual endpoint to use and may change it every RPC,+permitting client-side load balancing. A Server is capable of receiving incoming+connections and receiving RPCs.++A ""connection"" is not a gRPC semantic concept and thus users should not assume a+correlation between connections and RPCs. Although, practically, users should be+aware of the common restriction that RPCs are unable to survive longer than the+connection on which they exist.++The exact details of how the communication is performed and higher level+abstractions can change when necessary and are thus not a focus for this+document. Although implementations SHOULD support the [HTTP/2+transport](PROTOCOL-HTTP2.md) to provide a basis for interoperability.++## Methods++An RPC is performed on a Method. The Method has a name, defines the intended+operation, the message types involved with the RPC, and the cardinality of+those messages.  It does not define the endpoint to send the RPC to; this is+normally handled by the Channel.++A Method's intended operation is just normal documentation describing what a+Method does, intended for a developer. gRPC itself is not generally aware of the+intended operation.++A Method has a request message type and a separate response message type. gRPC+is only aware of these types well enough to serialize and deserialize them.+Messages are considered opaque byte sequences of a known length to gRPC itself.++A Method's request and response each have a cardinality: either one (""unary""),+or zero to many (a ""stream""). This produces four possible configurations which,+for convenience, each have a name:++|                       | **unary response** | **streaming response** |+| --------------------- | ------------------ | ---------------------- |+| **unary request**     | unary              | server-streaming       |+| **streaming request** | client-streaming   | bidirectional (bidi)   |++While we use the term ""method,"" pedantically it is closer to ""function"" as it is+not object oriented and there is no ""receiver"" involved (the `this` variable in+many languages) other than the destination machine. gRPC is based on message+passing, not object orientation.++Related Methods are typically grouped into a Service. To gRPC, a Service is a+group of methods that tend to be implemented together and that all share the+Service's namespace. A Service is a higher-level abstraction and may not be+present explicitly in all implementations. However, the namespace provided by a+Service is a core distinguishing feature of its Methods; if two Methods have the+same name but exist in different Services they must be considered distinct and+not be confused. A Method name including its Service namespace prefix with a ""/""+separator is a ""full method name"".++## Calls++RPCs, or ""Calls,"" are initiated by a client to a server, typically via a+Channel. There may be multiple servers that _could_ have received the Call (as+is common for load balancing), but only a single server may process an+individual Call. Calls are assumed to be non-idempotent and may not be+""replayed"" except for when gRPC is explicitly informed it is safe to do so.++Calls are natively two independent streams (i.e., full duplex bidirectional) of+Messages. The request stream is started with Request Headers and ended by Half+Close. The response stream is started with Response Headers and ended by+Trailers, or consistes only of Trailers. Messages may exist between the headers+and the end of the stream. Request Headers, Response Headers, Messages, Half+Close, and Trailers are the units of communication and, absent the Call's+termination, will be communicated to the remote without the need to send further+units on the stream. However, see the optimizations permitted for unary Calls+below.++Request Headers contain the Full Method Name and Metadata. Response Headers+contain Metadata. Trailers contain the Status and Metadata. Messages contain the+Message Payload. These contents are not exhaustive; gRPC features may extend+these concepts. It is quite common for features to add additional fields to+Request Headers, Response Headers, and Trailers.++The Call initiation is with Request Headers, within which the client+indicates the method to be run by its Full Method Name. The Call is gracefully+completed when the server responds with Trailers, which contains a Status+communicating the success or failure of the RPC. If a server responds with+Trailers before receiving the client's Half Close, then any unprocessed+client-sent Messages and Half Close is lost. Note that on the server there is a+period of time between when the server application responds with a Trailers and+when that Trailers is actually sent; the Call is only truly complete when the+Trailers is sent. Similarly, on the client there is a period between the gRPC+implementation receiving the Trailers and when the application receives the+Trailers; the Call is only truly complete when the Trailers is received by the+application.++Calls may terminate early by being ""cancelled."" Implementations must allow+clients to cancel Calls, but cancellations may occur in other ways like I/O+failures. A cancellation appears as a Trailers with a Status Code of CANCELLED+to clients and is a special state on servers. Cancellation is an abrupt killing+of the Call; inbound and outbound buffered data should be cleared. Cancellation+trumps graceful completion; if the client gRPC implementation received the+Trailers before the cancellation, yet the client application has not received+the Trailers, then cancellation generally should win. No auxiliary information+is included in cancellation signals between the client and server. Server+implementations may fail a Call and respond with Trailers while claiming to the+server application that the Call was cancelled.++The two independent streams are each unidirectional and do not provide any+information in the reverse direction other than Flow Control. Flow Control+is a signal from the receiver to the sender to temporarily pause sending+additional messages to avoid excessive buffering. Flow Control only applies to+messages, but since streams are in-order Half Close or Trailers may be delayed+waiting for message Flow Control in the same stream. No message receipt+acknowledgement information is provided. However applications may use messages+for such signals, as a response naturally acknowledges its request. Note in+particular that there is no provision for the server application to not know+whether the client application received a unary Call's response or a streaming+Call's Status.++Unary Calls may be optimized to be half-duplex and treat each stream as a single+communication unit. That is, on the client a unary Call may be delayed from+being sent until the Half Close is ready to be sent and on the server the+response may be delayed until the Trailers is ready.++Unary Calls that terminate with a Status Code of OK must contain a response+message. Unary Calls that terminate with a Status Code other than OK do not need+a response message, and at the implementation's discretion the response message+may be discarded if present.++## Status++A Status contains a ""code"" and a ""description"". The Status Description is a+human-readable Unicode string for developer debugging. The Status Code is a+value from a pre-defined list of such codes. While Status Code is best+communicated to users by its name, it commonly is treated as an integer+internally, and so each code has a numeric value.++The valid Status Codes are:++| Num | Name                |+| --- | ------------------- |+| 0   | OK                  |+| 1   | CANCELLED           |+| 2   | UNKNOWN             |+| 3   | INVALID_ARGUMENT    |+| 4   | DEADLINE_EXCEEDED   |+| 5   | NOT_FOUND           |+| 6   | ALREADY_EXISTS      |+| 7   | PERMISSION_DENIED   |+| 8   | RESOURCE_EXHAUSTED  |+| 9   | FAILED_PRECONDITION |+| 10  | ABORTED             |+| 11  | OUT_OF_RANGE        |+| 12  | UNIMPLEMENTED       |+| 13  | INTERNAL            |+| 14  | UNAVAILABLE         |+| 15  | DATA_LOSS           |+| 16  | UNAUTHENTICATED     |++Using the OK Status Code for a Call may only be decided by server applications.+Library implementations must not ""fabricate"" an OK Status Code; it may only+communicate an OK Status Code that was provided to it. While there may be+additional restrictions on Status Code usage like those detailed in+[statuscodes.md](statuscodes.md), those restrictions are more to provide a+cohesive experience instead of a core, fundamental requirement.++## Metadata++Metadata has keys with associated values. Each key can have multiple values.+Keys are unordered, but values for a key are ordered. Keys are case insensitive,+and commonly canonicalized by making lower case. APIs are permitted to require a+canonical representation and that representation may be different than the+""lower case"" representation mentioned here. A key can be for ASCII or binary+values. If a key is for binary values, its name must be suffixed with ""-bin"".+Otherwise it is for ASCII values.++ASCII values are discouraged from having leading or trailing whitespace. If such+a value contains leading or trailing whitespace, the whitespace may be stripped.+Multiple ASCII values for the same key may be joined together with "","" (a comma)+as the delimiter and be considered semantically equivalent to the multi-value+form.  However, such a transformation is lossy; an arbitrary ASCII value may not+be split on comma and be assumed to be equivalent to a valid multi-value form+for its key.++The position of the Metadata in either Headers or Trailers is semantically+important. Metadata from a Headers may not be moved to Trailers or vise-versa+without additional knowledge of the individual key semantics.++## Additional Features++Although these are ""additional"" features, that does not make them unimportant.+The are additional because they do not need to be represented as a fundamental+gRPC protocol concept.++### Deadline Propagation++It is a common concept for RPCs to have a Deadline, a point in time by which the+Call needs to complete before the client will give up. If the Client has a+Deadline for the Call it should be included in the Request Headers. Calls are+not required to have a Deadline. If a Call has a Deadline, both the client and+server should track the Deadline and Cancel the Call when the Deadline is+reached. When the client Cancels the Call, it should report a Trailers","""it"" is...the server?If the client cancels, the server doesn't have a chance to send a trailer, at least in grpc-go.  The client cancels by sending RST_STREAM.  The stream is gone.Or did you mean ""when the client's deadline has expired""?",
26072277,dfawley,https://api.github.com/repos/grpc/grpc/pulls/15460,202464594,2018-07-13T20:29:43Z,doc/PROTOCOL-SEMANTICS.md,"@@ -0,0 +1,268 @@+# gRPC semantics++gRPC has many features, but the most fundamental core is the ability to perform+RPCs. The goal of this document is defining the semantics of gRPC's RPCs.++## Channels++Most implementations will have Channel and Server concepts. A Channel is a+virtual connection to an endpoint, capable of sending RPCs. Channel is ""virtual""+because the Channel is free to have zero or many actual connections. A Channel+is free to determine which actual endpoint to use and may change it every RPC,+permitting client-side load balancing. A Server is capable of receiving incoming+connections and receiving RPCs.++A ""connection"" is not a gRPC semantic concept and thus users should not assume a+correlation between connections and RPCs. Although, practically, users should be+aware of the common restriction that RPCs are unable to survive longer than the+connection on which they exist.++The exact details of how the communication is performed and higher level+abstractions can change when necessary and are thus not a focus for this+document. Although implementations SHOULD support the [HTTP/2+transport](PROTOCOL-HTTP2.md) to provide a basis for interoperability.++## Methods++An RPC is performed on a Method. The Method has a name, defines the intended+operation, the message types involved with the RPC, and the cardinality of+those messages.  It does not define the endpoint to send the RPC to; this is+normally handled by the Channel.++A Method's intended operation is just normal documentation describing what a+Method does, intended for a developer. gRPC itself is not generally aware of the+intended operation.++A Method has a request message type and a separate response message type. gRPC+is only aware of these types well enough to serialize and deserialize them.+Messages are considered opaque byte sequences of a known length to gRPC itself.++A Method's request and response each have a cardinality: either one (""unary""),+or zero to many (a ""stream""). This produces four possible configurations which,+for convenience, each have a name:++|                       | **unary response** | **streaming response** |+| --------------------- | ------------------ | ---------------------- |+| **unary request**     | unary              | server-streaming       |+| **streaming request** | client-streaming   | bidirectional (bidi)   |++While we use the term ""method,"" pedantically it is closer to ""function"" as it is+not object oriented and there is no ""receiver"" involved (the `this` variable in+many languages) other than the destination machine. gRPC is based on message+passing, not object orientation.++Related Methods are typically grouped into a Service. To gRPC, a Service is a+group of methods that tend to be implemented together and that all share the+Service's namespace. A Service is a higher-level abstraction and may not be+present explicitly in all implementations. However, the namespace provided by a+Service is a core distinguishing feature of its Methods; if two Methods have the+same name but exist in different Services they must be considered distinct and+not be confused. A Method name including its Service namespace prefix with a ""/""+separator is a ""full method name"".++## Calls++RPCs, or ""Calls,"" are initiated by a client to a server, typically via a+Channel. There may be multiple servers that _could_ have received the Call (as+is common for load balancing), but only a single server may process an+individual Call. Calls are assumed to be non-idempotent and may not be+""replayed"" except for when gRPC is explicitly informed it is safe to do so.++Calls are natively two independent streams (i.e., full duplex bidirectional) of+Messages. The request stream is started with Request Headers and ended by Half+Close. The response stream is started with Response Headers and ended by+Trailers, or consistes only of Trailers. Messages may exist between the headers+and the end of the stream. Request Headers, Response Headers, Messages, Half+Close, and Trailers are the units of communication and, absent the Call's+termination, will be communicated to the remote without the need to send further+units on the stream. However, see the optimizations permitted for unary Calls+below.++Request Headers contain the Full Method Name and Metadata. Response Headers+contain Metadata. Trailers contain the Status and Metadata. Messages contain the+Message Payload. These contents are not exhaustive; gRPC features may extend+these concepts. It is quite common for features to add additional fields to+Request Headers, Response Headers, and Trailers.++The Call initiation is with Request Headers, within which the client+indicates the method to be run by its Full Method Name. The Call is gracefully+completed when the server responds with Trailers, which contains a Status+communicating the success or failure of the RPC. If a server responds with+Trailers before receiving the client's Half Close, then any unprocessed+client-sent Messages and Half Close is lost. Note that on the server there is a+period of time between when the server application responds with a Trailers and+when that Trailers is actually sent; the Call is only truly complete when the+Trailers is sent. Similarly, on the client there is a period between the gRPC+implementation receiving the Trailers and when the application receives the+Trailers; the Call is only truly complete when the Trailers is received by the+application.++Calls may terminate early by being ""cancelled."" Implementations must allow+clients to cancel Calls, but cancellations may occur in other ways like I/O+failures. A cancellation appears as a Trailers with a Status Code of CANCELLED+to clients and is a special state on servers. Cancellation is an abrupt killing+of the Call; inbound and outbound buffered data should be cleared. Cancellation+trumps graceful completion; if the client gRPC implementation received the+Trailers before the cancellation, yet the client application has not received+the Trailers, then cancellation generally should win. No auxiliary information+is included in cancellation signals between the client and server. Server+implementations may fail a Call and respond with Trailers while claiming to the+server application that the Call was cancelled.++The two independent streams are each unidirectional and do not provide any+information in the reverse direction other than Flow Control. Flow Control+is a signal from the receiver to the sender to temporarily pause sending+additional messages to avoid excessive buffering. Flow Control only applies to+messages, but since streams are in-order Half Close or Trailers may be delayed+waiting for message Flow Control in the same stream. No message receipt+acknowledgement information is provided. However applications may use messages+for such signals, as a response naturally acknowledges its request. Note in+particular that there is no provision for the server application to not know+whether the client application received a unary Call's response or a streaming+Call's Status.++Unary Calls may be optimized to be half-duplex and treat each stream as a single+communication unit. That is, on the client a unary Call may be delayed from+being sent until the Half Close is ready to be sent and on the server the+response may be delayed until the Trailers is ready.++Unary Calls that terminate with a Status Code of OK must contain a response+message. Unary Calls that terminate with a Status Code other than OK do not need+a response message, and at the implementation's discretion the response message+may be discarded if present.++## Status++A Status contains a ""code"" and a ""description"". The Status Description is a+human-readable Unicode string for developer debugging. The Status Code is a+value from a pre-defined list of such codes. While Status Code is best+communicated to users by its name, it commonly is treated as an integer+internally, and so each code has a numeric value.++The valid Status Codes are:++| Num | Name                |+| --- | ------------------- |+| 0   | OK                  |+| 1   | CANCELLED           |+| 2   | UNKNOWN             |+| 3   | INVALID_ARGUMENT    |+| 4   | DEADLINE_EXCEEDED   |+| 5   | NOT_FOUND           |+| 6   | ALREADY_EXISTS      |+| 7   | PERMISSION_DENIED   |+| 8   | RESOURCE_EXHAUSTED  |+| 9   | FAILED_PRECONDITION |+| 10  | ABORTED             |+| 11  | OUT_OF_RANGE        |+| 12  | UNIMPLEMENTED       |+| 13  | INTERNAL            |+| 14  | UNAVAILABLE         |+| 15  | DATA_LOSS           |+| 16  | UNAUTHENTICATED     |++Using the OK Status Code for a Call may only be decided by server applications.+Library implementations must not ""fabricate"" an OK Status Code; it may only+communicate an OK Status Code that was provided to it. While there may be+additional restrictions on Status Code usage like those detailed in+[statuscodes.md](statuscodes.md), those restrictions are more to provide a+cohesive experience instead of a core, fundamental requirement.++## Metadata++Metadata has keys with associated values. Each key can have multiple values.+Keys are unordered, but values for a key are ordered. Keys are case insensitive,+and commonly canonicalized by making lower case. APIs are permitted to require a+canonical representation and that representation may be different than the+""lower case"" representation mentioned here. A key can be for ASCII or binary+values. If a key is for binary values, its name must be suffixed with ""-bin"".+Otherwise it is for ASCII values.++ASCII values are discouraged from having leading or trailing whitespace. If such+a value contains leading or trailing whitespace, the whitespace may be stripped.+Multiple ASCII values for the same key may be joined together with "","" (a comma)+as the delimiter and be considered semantically equivalent to the multi-value+form.  However, such a transformation is lossy; an arbitrary ASCII value may not+be split on comma and be assumed to be equivalent to a valid multi-value form+for its key.++The position of the Metadata in either Headers or Trailers is semantically+important. Metadata from a Headers may not be moved to Trailers or vise-versa+without additional knowledge of the individual key semantics.++## Additional Features++Although these are ""additional"" features, that does not make them unimportant.+The are additional because they do not need to be represented as a fundamental+gRPC protocol concept.++### Deadline Propagation++It is a common concept for RPCs to have a Deadline, a point in time by which the+Call needs to complete before the client will give up. If the Client has a+Deadline for the Call it should be included in the Request Headers. Calls are+not required to have a Deadline. If a Call has a Deadline, both the client and+server should track the Deadline and Cancel the Call when the Deadline is+reached. When the client Cancels the Call, it should report a Trailers+containing a Status Code of DEADLINE_EXCEEDED.++While the feature is called ""Deadline"" and involves Deadlines from the user's+perspective, it is generally communicated with a timeout, which is a duration+instead of a point in time. Communicating a duration avoids the need for civil+time clock synchronization between the client and server.++By its very nature, the client and server's Deadline will be slightly different+and their detection of its expiration will race. When clients receive a+Cancellation on a Call with a Deadline, they should double-check whether the+Deadline has passed. If it has passed, they should override the cancellation+with Trailers with one that has a Status Code of DEADLINE_EXCEEDED.++### Authority++Virtual hosting is a common concept where a server supports multiple identities+and supports different services depending on the identity. ""Identity"" is a+server name, in ""host"" or ""host:port"" form as found for the ""authority"" portion+of URIs. Transports able to support virtual hosting should transmit the+authority the client identifies the service as and make that available to the+server application. The authority would appear to be included in the Request+Headers to the server application.++# Appendix++## Appendix A: Call ABNF++A conceptual Call, ignoring cancellation signaling, in+[ABNF syntax](http://tools.ietf.org/html/rfc5234):+```+call              = request-stream response-stream ; in parallel+request-stream    = request-headers *request [half-close]+response-stream   = [response-headers *response] trailers++request-headers   = full-method-name metadata",[deadline] and [authority]?,OK
2811396,ejona86,https://api.github.com/repos/grpc/grpc/pulls/15460,202483271,2018-07-13T22:01:30Z,doc/PROTOCOL-SEMANTICS.md,"@@ -0,0 +1,268 @@+# gRPC semantics++gRPC has many features, but the most fundamental core is the ability to perform+RPCs. The goal of this document is defining the semantics of gRPC's RPCs.++## Channels++Most implementations will have Channel and Server concepts. A Channel is a+virtual connection to an endpoint, capable of sending RPCs. Channel is ""virtual""+because the Channel is free to have zero or many actual connections. A Channel+is free to determine which actual endpoint to use and may change it every RPC,+permitting client-side load balancing. A Server is capable of receiving incoming+connections and receiving RPCs.++A ""connection"" is not a gRPC semantic concept and thus users should not assume a+correlation between connections and RPCs. Although, practically, users should be+aware of the common restriction that RPCs are unable to survive longer than the+connection on which they exist.++The exact details of how the communication is performed and higher level+abstractions can change when necessary and are thus not a focus for this+document. Although implementations SHOULD support the [HTTP/2+transport](PROTOCOL-HTTP2.md) to provide a basis for interoperability.++## Methods++An RPC is performed on a Method. The Method has a name, defines the intended+operation, the message types involved with the RPC, and the cardinality of+those messages.  It does not define the endpoint to send the RPC to; this is+normally handled by the Channel.++A Method's intended operation is just normal documentation describing what a+Method does, intended for a developer. gRPC itself is not generally aware of the+intended operation.++A Method has a request message type and a separate response message type. gRPC+is only aware of these types well enough to serialize and deserialize them.+Messages are considered opaque byte sequences of a known length to gRPC itself.++A Method's request and response each have a cardinality: either one (""unary""),+or zero to many (a ""stream""). This produces four possible configurations which,+for convenience, each have a name:++|                       | **unary response** | **streaming response** |+| --------------------- | ------------------ | ---------------------- |+| **unary request**     | unary              | server-streaming       |+| **streaming request** | client-streaming   | bidirectional (bidi)   |++While we use the term ""method,"" pedantically it is closer to ""function"" as it is+not object oriented and there is no ""receiver"" involved (the `this` variable in+many languages) other than the destination machine. gRPC is based on message+passing, not object orientation.++Related Methods are typically grouped into a Service. To gRPC, a Service is a+group of methods that tend to be implemented together and that all share the+Service's namespace. A Service is a higher-level abstraction and may not be+present explicitly in all implementations. However, the namespace provided by a+Service is a core distinguishing feature of its Methods; if two Methods have the+same name but exist in different Services they must be considered distinct and+not be confused. A Method name including its Service namespace prefix with a ""/""+separator is a ""full method name"".++## Calls++RPCs, or ""Calls,"" are initiated by a client to a server, typically via a+Channel. There may be multiple servers that _could_ have received the Call (as+is common for load balancing), but only a single server may process an+individual Call. Calls are assumed to be non-idempotent and may not be+""replayed"" except for when gRPC is explicitly informed it is safe to do so.++Calls are natively two independent streams (i.e., full duplex bidirectional) of+Messages. The request stream is started with Request Headers and ended by Half+Close. The response stream is started with Response Headers and ended by+Trailers, or consistes only of Trailers. Messages may exist between the headers+and the end of the stream. Request Headers, Response Headers, Messages, Half+Close, and Trailers are the units of communication and, absent the Call's+termination, will be communicated to the remote without the need to send further+units on the stream. However, see the optimizations permitted for unary Calls+below.++Request Headers contain the Full Method Name and Metadata. Response Headers+contain Metadata. Trailers contain the Status and Metadata. Messages contain the+Message Payload. These contents are not exhaustive; gRPC features may extend+these concepts. It is quite common for features to add additional fields to+Request Headers, Response Headers, and Trailers.++The Call initiation is with Request Headers, within which the client+indicates the method to be run by its Full Method Name. The Call is gracefully+completed when the server responds with Trailers, which contains a Status+communicating the success or failure of the RPC. If a server responds with+Trailers before receiving the client's Half Close, then any unprocessed+client-sent Messages and Half Close is lost. Note that on the server there is a+period of time between when the server application responds with a Trailers and+when that Trailers is actually sent; the Call is only truly complete when the+Trailers is sent. Similarly, on the client there is a period between the gRPC+implementation receiving the Trailers and when the application receives the+Trailers; the Call is only truly complete when the Trailers is received by the+application.++Calls may terminate early by being ""cancelled."" Implementations must allow+clients to cancel Calls, but cancellations may occur in other ways like I/O+failures. A cancellation appears as a Trailers with a Status Code of CANCELLED+to clients and is a special state on servers. Cancellation is an abrupt killing+of the Call; inbound and outbound buffered data should be cleared. Cancellation+trumps graceful completion; if the client gRPC implementation received the+Trailers before the cancellation, yet the client application has not received+the Trailers, then cancellation generally should win. No auxiliary information+is included in cancellation signals between the client and server. Server+implementations may fail a Call and respond with Trailers while claiming to the+server application that the Call was cancelled.++The two independent streams are each unidirectional and do not provide any+information in the reverse direction other than Flow Control. Flow Control+is a signal from the receiver to the sender to temporarily pause sending+additional messages to avoid excessive buffering. Flow Control only applies to+messages, but since streams are in-order Half Close or Trailers may be delayed+waiting for message Flow Control in the same stream. No message receipt+acknowledgement information is provided. However applications may use messages+for such signals, as a response naturally acknowledges its request. Note in+particular that there is no provision for the server application to not know+whether the client application received a unary Call's response or a streaming+Call's Status.++Unary Calls may be optimized to be half-duplex and treat each stream as a single+communication unit. That is, on the client a unary Call may be delayed from+being sent until the Half Close is ready to be sent and on the server the+response may be delayed until the Trailers is ready.++Unary Calls that terminate with a Status Code of OK must contain a response+message. Unary Calls that terminate with a Status Code other than OK do not need+a response message, and at the implementation's discretion the response message+may be discarded if present.++## Status++A Status contains a ""code"" and a ""description"". The Status Description is a+human-readable Unicode string for developer debugging. The Status Code is a+value from a pre-defined list of such codes. While Status Code is best+communicated to users by its name, it commonly is treated as an integer+internally, and so each code has a numeric value.++The valid Status Codes are:++| Num | Name                |+| --- | ------------------- |+| 0   | OK                  |+| 1   | CANCELLED           |+| 2   | UNKNOWN             |+| 3   | INVALID_ARGUMENT    |+| 4   | DEADLINE_EXCEEDED   |+| 5   | NOT_FOUND           |+| 6   | ALREADY_EXISTS      |+| 7   | PERMISSION_DENIED   |+| 8   | RESOURCE_EXHAUSTED  |+| 9   | FAILED_PRECONDITION |+| 10  | ABORTED             |+| 11  | OUT_OF_RANGE        |+| 12  | UNIMPLEMENTED       |+| 13  | INTERNAL            |+| 14  | UNAVAILABLE         |+| 15  | DATA_LOSS           |+| 16  | UNAUTHENTICATED     |++Using the OK Status Code for a Call may only be decided by server applications.+Library implementations must not ""fabricate"" an OK Status Code; it may only+communicate an OK Status Code that was provided to it. While there may be+additional restrictions on Status Code usage like those detailed in+[statuscodes.md](statuscodes.md), those restrictions are more to provide a+cohesive experience instead of a core, fundamental requirement.++## Metadata++Metadata has keys with associated values. Each key can have multiple values.+Keys are unordered, but values for a key are ordered. Keys are case insensitive,+and commonly canonicalized by making lower case. APIs are permitted to require a+canonical representation and that representation may be different than the+""lower case"" representation mentioned here. A key can be for ASCII or binary+values. If a key is for binary values, its name must be suffixed with ""-bin"".+Otherwise it is for ASCII values.++ASCII values are discouraged from having leading or trailing whitespace. If such+a value contains leading or trailing whitespace, the whitespace may be stripped.+Multiple ASCII values for the same key may be joined together with "","" (a comma)+as the delimiter and be considered semantically equivalent to the multi-value+form.  However, such a transformation is lossy; an arbitrary ASCII value may not+be split on comma and be assumed to be equivalent to a valid multi-value form+for its key.++The position of the Metadata in either Headers or Trailers is semantically+important. Metadata from a Headers may not be moved to Trailers or vise-versa+without additional knowledge of the individual key semantics.++## Additional Features++Although these are ""additional"" features, that does not make them unimportant.+The are additional because they do not need to be represented as a fundamental+gRPC protocol concept.++### Deadline Propagation++It is a common concept for RPCs to have a Deadline, a point in time by which the+Call needs to complete before the client will give up. If the Client has a+Deadline for the Call it should be included in the Request Headers. Calls are+not required to have a Deadline. If a Call has a Deadline, both the client and+server should track the Deadline and Cancel the Call when the Deadline is+reached. When the client Cancels the Call, it should report a Trailers","The client library, which cancelled the call. The Trailers here is generated client-side. I'll replace the ""it"" to be more clear. Something needs to be here to make it clear that the ""report"" is ""to the client application"".",OK
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/15983,202497435,2018-07-14T00:04:22Z,src/core/ext/transport/chttp2/transport/internal.h,"@@ -584,6 +584,7 @@ struct grpc_chttp2_stream {    grpc_slice_buffer flow_controlled_buffer; +  grpc_closure_list run_after_write;","I copied the pattern of the old per-transport ```run_after_write```, and that one is not initialized either.",OK
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/15983,202497996,2018-07-14T00:12:05Z,src/core/ext/transport/chttp2/transport/writing.cc,"@@ -609,15 +609,11 @@ grpc_chttp2_begin_write_result grpc_chttp2_begin_write(     stream_ctx.FlushData();     stream_ctx.FlushTrailingMetadata(); -    if (stream_ctx.stream_became_writable()) {","Before ``` grpc_chttp2_end_write``` would only have an effect for streams that were unblocked by flow control, so it wasn't an issue, just kind of a misnomer of ```writable```.Now we need to execute the new callback list, so we need to make sure it happens every time.",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16014,202550120,2018-07-15T18:23:45Z,src/compiler/ruby_generator.cc,"@@ -160,12 +160,23 @@ grpc::string GetServices(const FileDescriptor* file) {       return output;     } +    bool need_change_to_module;",`need_change_to_module` is unused?,OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16014,202550179,2018-07-15T18:25:45Z,bazel/grpc_deps.bzl,"@@ -116,8 +116,8 @@ def grpc_deps():     if ""com_google_protobuf"" not in native.existing_rules():         native.http_archive(             name = ""com_google_protobuf"",-            strip_prefix = ""protobuf-b5fbb742af122b565925987e65c08957739976a7"",-            url = ""https://github.com/google/protobuf/archive/b5fbb742af122b565925987e65c08957739976a7.tar.gz"",+            strip_prefix = ""protobuf-ab8edf1dbe2237b4717869eaab11a2998541ad8d"",",I think it would be better if this change was split up:1) upgrade our protobuf submodule dependency in one PR2) make this ruby upgrade after that protobuf upgrade has been done in a second PR,OK
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/15853,202557104,2018-07-15T22:47:20Z,src/cpp/server/load_reporter/load_reporter_async_service_impl.h,"@@ -0,0 +1,195 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_SRC_CPP_SERVER_LOAD_REPORTER_ASYNC_SERVICE_IMPL_H+#define GRPC_SRC_CPP_SERVER_LOAD_REPORTER_ASYNC_SERVICE_IMPL_H++#include <grpc/support/port_platform.h>++#include <grpc/support/log.h>+#include <grpcpp/alarm.h>+#include <grpcpp/grpcpp.h>++#include ""src/core/lib/gprpp/thd.h""+#include ""src/cpp/server/load_reporter/load_reporter.h""++namespace grpc {+namespace load_reporter {++// Async load reporting service. It's mainly responsible for controlling the+// procedure of incoming requests. The real business logic is handed off to the+// LoadReporter. There should be at most one instance of this service on a+// server to avoid spreading the load data into multiple places.+class LoadReporterAsyncServiceImpl+    : public grpc::lb::v1::LoadReporter::AsyncService {+ public:+  explicit LoadReporterAsyncServiceImpl(+      std::unique_ptr<ServerCompletionQueue> cq);+  ~LoadReporterAsyncServiceImpl();++  // Starts the working thread.+  void StartThread();++  // Not copyable nor movable.+  LoadReporterAsyncServiceImpl(const LoadReporterAsyncServiceImpl&) = delete;+  LoadReporterAsyncServiceImpl& operator=(const LoadReporterAsyncServiceImpl&) =+      delete;++ private:+  class ReportLoadHandler;++  // A tag that can be called with a bool argument. It's tailored for+  // ReportLoadHandler's use. Before being used, it should be constructed with a+  // method of ReportLoadHandler and a shared pointer to the handler. The+  // shared pointer will be moved to the invoked function and the function can+  // only be invoked once. That makes ref counting of the handler easier,+  // because the shared pointer is not bound to the function and can be gone+  // once the invoked function returns (if not used any more).+  class CallableTag {+   public:+    using HandlerFunction =+        std::function<void(std::shared_ptr<ReportLoadHandler>, bool)>;++    CallableTag() {}++    CallableTag(HandlerFunction func,+                std::shared_ptr<ReportLoadHandler> handler)+        : handler_function_(std::move(func)), handler_(std::move(handler)) {+      GPR_ASSERT(handler_function_ != nullptr);+      GPR_ASSERT(handler_ != nullptr);+    }++    // Runs the tag. This should be called only once. The handler is no longer+    // owned by this tag after this method is invoked.+    void Run(bool ok);++    // Releases and returns the shared pointer to the handler.+    std::shared_ptr<ReportLoadHandler> ReleaseHandler() {+      return std::move(handler_);+    }++   private:+    HandlerFunction handler_function_ = nullptr;+    std::shared_ptr<ReportLoadHandler> handler_;+  };++  // Each handler takes care of one load reporting stream. It contains+  // per-stream data and it will access the members of the parent class (i.e.,+  // LoadReporterAsyncServiceImpl) for service-wide data (e.g., the load data).+  class ReportLoadHandler+      : public std::enable_shared_from_this<ReportLoadHandler> {+   public:+    // Instantiates a ReportLoadHandler and requests the next load reporting+    // call. The handler object will manage its own lifetime, so no action is+    // needed from the caller any more regarding that object.+    static void CreateAndStart(ServerCompletionQueue* cq,+                               LoadReporterAsyncServiceImpl* service,+                               LoadReporter* load_reporter);++    // This ctor is public because we want to use std::make_shared<> in+    // CreateAndStart(). This ctor shouldn't be used elsewhere.+    ReportLoadHandler(ServerCompletionQueue* cq,+                      LoadReporterAsyncServiceImpl* service,+                      LoadReporter* load_reporter);++   private:+    // After the handler has a call request delivered, it starts reading the","After discussion offline, this is resolved.BTW, I'd like to append some comment after I read ""Item 13: Use objects to manage resources"" in Effective C++. If we do choose to use `std::shared_ptr` here, moving the refcounting complexity from the ""end"" (like, manually releasing the ref in the last callback) to the ""beginning"" (using something like `CallableTag`) is beneficial because it eliminates the effort to make sure the resource is always released, which is hard in case of exceptions being thrown before the resource is released or other situations that cause early returning.",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/16025,202800763,2018-07-16T19:43:40Z,src/python/grpcio/grpc/_channel.py,"@@ -208,7 +221,8 @@ def consume_request_iterator():  # pylint: disable=too-many-branches                         else:                             return                         while True:-                            state.condition.wait()+                            state.condition.wait(condition_wait_timeout)","If fork support is enabled, a generator can't take longer than a second to generate a request?",
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/16025,202804078,2018-07-16T19:55:45Z,src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi,"@@ -430,9 +431,14 @@ cdef class Channel:    def next_call_event(self):     def on_success(tag):-      _process_integrated_call_tag(self._state, tag)+      if tag is not None:+        _process_integrated_call_tag(self._state, tag)+    if is_fork_support_enabled():+      queue_deadline = time.time() + 1.0","Also here.  I'm really worried about adding a deadline, its not clear that this will have the correct behavior.",OK
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/16025,202889445,2018-07-17T04:11:32Z,src/python/grpcio/grpc/_channel.py,"@@ -208,7 +221,8 @@ def consume_request_iterator():  # pylint: disable=too-many-branches                         else:                             return                         while True:-                            state.condition.wait()+                            state.condition.wait(condition_wait_timeout)","This goes from a wait-until to a wait-one-second-and-then-wait-again loop, where the event being waited for is either of the following to occur: (a) the completion queue returns our send_message operation's tag, or (b) the call has meanwhile been completed (state.code is not None)The issue is that `state.condition.wait()` may block ""forever"" waiting for core to complete the send op. This interferes with the book-keeping in the python fork handler, as it will want to wait for this thread to pause or complete. It would actually be fine for the fork to proceed if the parent was still waiting, as the lock is released by the call to `wait()`, but that information would have to be conveyed atomically with the wait call. Something like the following won't work:```with state.condition:   cygrpc.decrement_active_thread_count()   state.condition.wait()   cygrpc.increment_active_thread_count()```Because fork could occur before the parent actually waits, and the child would inherit a locked condition variable on the call. (This could be kinda-sorta-okay, since the inherited call will anyways be failed in the child...but would prevent some of the normal API methods from functioning)But yes, this behavior is non-obvious, nor is it obvious that 1 second is a good timeout value here (I suspect it could be too long, but then there are also performance impacts if its too short). I'll try to think of a cleaner way of doing this.",OK
18316330,kpayson64,https://api.github.com/repos/grpc/grpc/pulls/16025,203126112,2018-07-17T18:11:20Z,src/python/grpcio/grpc/_channel.py,"@@ -208,7 +221,8 @@ def consume_request_iterator():  # pylint: disable=too-many-branches                         else:                             return                         while True:-                            state.condition.wait()+                            state.condition.wait(condition_wait_timeout)","I'm less worried about fork behavior, and more concerned about regular behavior with ```GRPC_ENABLE_FORK_SUPPORT=True```Specifically, what happens if we hit the timeout before the send_message operation completes?  AFAICT, we would issue another write request.  It is illegal for the c-core to have more than one outstanding write requests, and would probably lead to a segfault.Prior to this change, we had the invariant that if we pass the ```wait()``` call, an operation has completed.  We no longer have that invariant (here and below).",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/16022,203143962,2018-07-17T19:06:35Z,src/core/lib/channel/channelz_registry.cc,"@@ -125,3 +125,27 @@ char* ChannelzRegistry::InternalGetTopChannels(intptr_t start_channel_id) {  }  // namespace channelz }  // namespace grpc_core++char* grpc_channelz_get_top_channels(intptr_t start_channel_id) {+  return grpc_core::channelz::ChannelzRegistry::GetTopChannels(+      start_channel_id);+}++char* grpc_channelz_get_channel(intptr_t channel_id) {+  grpc_core::channelz::ChannelNode* channel_node =+      grpc_core::channelz::ChannelzRegistry::GetChannelNode(channel_id);+  if (channel_node == nullptr) {+    return nullptr;+  }+  grpc_json* top_level_json = grpc_json_create(GRPC_JSON_OBJECT);+  grpc_json* json = top_level_json;+  grpc_json* channel_json = channel_node->RenderJson();+  grpc_json_link_child(json, channel_json, nullptr);+  channel_json->parent = json;",I have been meaning to make some better convenience functions for our json library now that I have been using it a lot,
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/16010,203208065,2018-07-17T23:02:44Z,src/core/lib/iomgr/executor.cc,"@@ -298,60 +316,126 @@ void GrpcExecutor::Enqueue(grpc_closure* closure, grpc_error* error,   } while (retry_push); } -static GrpcExecutor* global_executor;+static GrpcExecutor* executors[GRPC_NUM_EXECUTORS]; -void enqueue_long(grpc_closure* closure, grpc_error* error) {-  global_executor->Enqueue(closure, error, false /* is_short */);+void default_enqueue_short(grpc_closure* closure, grpc_error* error) {+  executors[GRPC_DEFAULT_EXECUTOR]->Enqueue(closure, error,+                                            true /* is_short */); } -void enqueue_short(grpc_closure* closure, grpc_error* error) {-  global_executor->Enqueue(closure, error, true /* is_short */);+void default_enqueue_long(grpc_closure* closure, grpc_error* error) {+  executors[GRPC_DEFAULT_EXECUTOR]->Enqueue(closure, error,+                                            false /* is_short */); } -// Short-Job executor scheduler-static const grpc_closure_scheduler_vtable global_executor_vtable_short = {-    enqueue_short, enqueue_short, ""executor-short""};-static grpc_closure_scheduler global_scheduler_short = {-    &global_executor_vtable_short};+void resolver_enqueue_short(grpc_closure* closure, grpc_error* error) {+  executors[GRPC_RESOLVER_EXECUTOR]->Enqueue(closure, error,+                                             true /* is_short */);+} -// Long-job executor scheduler-static const grpc_closure_scheduler_vtable global_executor_vtable_long = {-    enqueue_long, enqueue_long, ""executor-long""};-static grpc_closure_scheduler global_scheduler_long = {-    &global_executor_vtable_long};+void resolver_enqueue_long(grpc_closure* closure, grpc_error* error) {+  executors[GRPC_RESOLVER_EXECUTOR]->Enqueue(closure, error,+                                             false /* is_short */);+}++static const grpc_closure_scheduler_vtable vtables_[] = {+    {&default_enqueue_short, &default_enqueue_short, ""def-ex-short""},+    {&default_enqueue_long, &default_enqueue_long, ""def-ex-long""},+    {&resolver_enqueue_short, &resolver_enqueue_short, ""res-ex-short""},+    {&resolver_enqueue_long, &resolver_enqueue_long, ""res-ex-long""}};++static grpc_closure_scheduler schedulers_[] = {+    {&vtables_[0]},  // Default short+    {&vtables_[1]},  // Default long+    {&vtables_[2]},  // Resolver short+    {&vtables_[3]}   // Resolver long+};++const char* executor_name(GrpcExecutorType executor_type) {+  switch (executor_type) {+    case GRPC_DEFAULT_EXECUTOR:+      return ""default-executor"";+    case GRPC_RESOLVER_EXECUTOR:+      return ""resolver-executor"";+    default:+      GPR_UNREACHABLE_CODE(return ""unknown"");+  }+  GPR_UNREACHABLE_CODE(return ""unknown"");+}  // grpc_executor_init() and grpc_executor_shutdown() functions are called in the // the grpc_init() and grpc_shutdown() code paths which are protected by a // global mutex. So it is okay to assume that these functions are thread-safe void grpc_executor_init() {-  if (global_executor != nullptr) {-    // grpc_executor_init() already called once (and grpc_executor_shutdown()-    // wasn't called)-    return;+  EXECUTOR_TRACE0(""grpc_executor_init() enter"");+  for (int i = 0; i < GRPC_NUM_EXECUTORS; i++) {+    // Return if grpc_executor_init() already called earlier+    if (executors[i] != nullptr) {+      // Ideally we should also assert that all executors i.e executor[0] to+      // executor[GRPC_NUM_EXECUTORS-1] are != nullptr too.+      GPR_ASSERT(i == 0);+      break;+    }++    executors[i] = grpc_core::New<GrpcExecutor>(+        executor_name(static_cast<GrpcExecutorType>(i)));+    executors[i]->Init();   }+  EXECUTOR_TRACE0(""grpc_executor_init() done"");+} -  global_executor = grpc_core::New<GrpcExecutor>(""global-executor"");-  global_executor->Init();+grpc_closure_scheduler* grpc_executor_scheduler(GrpcExecutorType executor_type,+                                                GrpcExecutorJobType job_type) {+  return &schedulers_[(executor_type * GRPC_NUM_EXECUTORS) + job_type];","I get what's going on, but this is complex and fragile. Why not have a 2D array we can index more naturally? Even just a switch/if-elses would suffice, given the few combinations we have.",
120217,dgquintas,https://api.github.com/repos/grpc/grpc/pulls/16010,203208301,2018-07-17T23:04:05Z,src/core/lib/iomgr/executor.cc,"@@ -298,60 +316,126 @@ void GrpcExecutor::Enqueue(grpc_closure* closure, grpc_error* error,   } while (retry_push); } -static GrpcExecutor* global_executor;+static GrpcExecutor* executors[GRPC_NUM_EXECUTORS]; -void enqueue_long(grpc_closure* closure, grpc_error* error) {-  global_executor->Enqueue(closure, error, false /* is_short */);+void default_enqueue_short(grpc_closure* closure, grpc_error* error) {+  executors[GRPC_DEFAULT_EXECUTOR]->Enqueue(closure, error,+                                            true /* is_short */); } -void enqueue_short(grpc_closure* closure, grpc_error* error) {-  global_executor->Enqueue(closure, error, true /* is_short */);+void default_enqueue_long(grpc_closure* closure, grpc_error* error) {+  executors[GRPC_DEFAULT_EXECUTOR]->Enqueue(closure, error,+                                            false /* is_short */); } -// Short-Job executor scheduler-static const grpc_closure_scheduler_vtable global_executor_vtable_short = {-    enqueue_short, enqueue_short, ""executor-short""};-static grpc_closure_scheduler global_scheduler_short = {-    &global_executor_vtable_short};+void resolver_enqueue_short(grpc_closure* closure, grpc_error* error) {+  executors[GRPC_RESOLVER_EXECUTOR]->Enqueue(closure, error,+                                             true /* is_short */);+} -// Long-job executor scheduler-static const grpc_closure_scheduler_vtable global_executor_vtable_long = {-    enqueue_long, enqueue_long, ""executor-long""};-static grpc_closure_scheduler global_scheduler_long = {-    &global_executor_vtable_long};+void resolver_enqueue_long(grpc_closure* closure, grpc_error* error) {+  executors[GRPC_RESOLVER_EXECUTOR]->Enqueue(closure, error,+                                             false /* is_short */);+}++static const grpc_closure_scheduler_vtable vtables_[] = {+    {&default_enqueue_short, &default_enqueue_short, ""def-ex-short""},+    {&default_enqueue_long, &default_enqueue_long, ""def-ex-long""},+    {&resolver_enqueue_short, &resolver_enqueue_short, ""res-ex-short""},+    {&resolver_enqueue_long, &resolver_enqueue_long, ""res-ex-long""}};++static grpc_closure_scheduler schedulers_[] = {+    {&vtables_[0]},  // Default short+    {&vtables_[1]},  // Default long+    {&vtables_[2]},  // Resolver short+    {&vtables_[3]}   // Resolver long+};++const char* executor_name(GrpcExecutorType executor_type) {+  switch (executor_type) {+    case GRPC_DEFAULT_EXECUTOR:+      return ""default-executor"";+    case GRPC_RESOLVER_EXECUTOR:+      return ""resolver-executor"";+    default:+      GPR_UNREACHABLE_CODE(return ""unknown"");+  }+  GPR_UNREACHABLE_CODE(return ""unknown"");+}  // grpc_executor_init() and grpc_executor_shutdown() functions are called in the // the grpc_init() and grpc_shutdown() code paths which are protected by a // global mutex. So it is okay to assume that these functions are thread-safe void grpc_executor_init() {-  if (global_executor != nullptr) {-    // grpc_executor_init() already called once (and grpc_executor_shutdown()-    // wasn't called)-    return;+  EXECUTOR_TRACE0(""grpc_executor_init() enter"");+  for (int i = 0; i < GRPC_NUM_EXECUTORS; i++) {+    // Return if grpc_executor_init() already called earlier+    if (executors[i] != nullptr) {+      // Ideally we should also assert that all executors i.e executor[0] to+      // executor[GRPC_NUM_EXECUTORS-1] are != nullptr too.+      GPR_ASSERT(i == 0);+      break;+    }++    executors[i] = grpc_core::New<GrpcExecutor>(+        executor_name(static_cast<GrpcExecutorType>(i)));+    executors[i]->Init();   }+  EXECUTOR_TRACE0(""grpc_executor_init() done"");+} -  global_executor = grpc_core::New<GrpcExecutor>(""global-executor"");-  global_executor->Init();+grpc_closure_scheduler* grpc_executor_scheduler(GrpcExecutorType executor_type,+                                                GrpcExecutorJobType job_type) {+  return &schedulers_[(executor_type * GRPC_NUM_EXECUTORS) + job_type];+}++grpc_closure_scheduler* grpc_executor_scheduler(GrpcExecutorJobType job_type) {+  return grpc_executor_scheduler(GRPC_DEFAULT_EXECUTOR, job_type); }  void grpc_executor_shutdown() {-  // Shutdown already called-  if (global_executor == nullptr) {-    return;+  EXECUTOR_TRACE0(""grpc_executor_shutdown() enter"");+  for (int i = 0; i < GRPC_NUM_EXECUTORS; i++) {+    // Return if grpc_executor_shutdown() is already called earlier+    if (executors[i] == nullptr) {+      // Ideally we should also assert that all executors i.e executor[0] to+      // executor[GRPC_NUM_EXECUTORS-1] are nullptr too.+      GPR_ASSERT(i == 0);","same as in the init function. What's special about i==0? Without having looked into much more detail, this looks a bit smelly :)",OK
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/16023,203212169,2018-07-17T23:27:32Z,include/grpcpp/ext/channelz_server_plugin.h,"@@ -0,0 +1,54 @@+/*+ *+ * Copyright 2015 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPCPP_EXT_CHANNELZ_SERVER_PLUGIN_H+#define GRPCPP_EXT_CHANNELZ_SERVER_PLUGIN_H++#include <grpcpp/impl/server_builder_plugin.h>+#include <grpcpp/support/config.h>++namespace grpc {+class ServerInitializer;+class ChannelzServer;+}  // namespace grpc++namespace grpc {+namespace channelz {++class ChannelzServerPlugin : public ::grpc::ServerBuilderPlugin {","I agree with @markdroth that we don't need to expose this plugin. Actually, the src file for this header already adds the plugin automatically. The reflection header this PR is following shouldn't have exposed its plugin either. But note that the internal `grpc++_init.cc` is using ` reflection::InitProtoReflectionServerBuilderPlugin()` to ""manually"" register the plugin. So that file should have access to the init function, although I guess an internal API might be enough.  BTW, server load reporting service can't be a reference for this because it has some build dependency consideration.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/16023,203246604,2018-07-18T04:13:22Z,src/cpp/server/channelz/channelz_server.cc,"@@ -0,0 +1,59 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/cpp/server/channelz/channelz_server.h""++#include <google/protobuf/text_format.h>+#include <google/protobuf/util/json_util.h>++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>++namespace grpc {++ChannelzServer::ChannelzServer() {}++Status ChannelzServer::GetTopChannels(+    ServerContext* context, const channelz::v1::GetTopChannelsRequest* request,","True, I renamed to `unused`",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/16023,203246937,2018-07-18T04:16:18Z,src/cpp/server/channelz/channelz_server.cc,"@@ -0,0 +1,59 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/cpp/server/channelz/channelz_server.h""++#include <google/protobuf/text_format.h>+#include <google/protobuf/util/json_util.h>++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>++namespace grpc {++ChannelzServer::ChannelzServer() {}++Status ChannelzServer::GetTopChannels(+    ServerContext* context, const channelz::v1::GetTopChannelsRequest* request,","That is what I thought, but that actually causes this error:```/Users/ncteisen/Desktop/grpc/gens/src/proto/grpc/channelz/channelz.grpc.pb.h:201:28: note: hidden overloaded virtual function 'grpc::channelz::v1::Channelz::Service::GetTopChannels' declared here: type      mismatch at 2nd parameter ('const ::grpc::channelz::v1::GetTopChannelsRequest *' vs 'const ::grpc::channelz::v1::GetTopChannelsRequest &')    virtual ::grpc::Status GetTopChannels(::grpc::ServerContext* context, const ::grpc::channelz::v1::GetTopChannelsRequest* request, ::grpc::channelz::v1::GetTopChannelsResponse* response);```",
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/16025,203252766,2018-07-18T05:12:10Z,src/python/grpcio/grpc/_cython/_cygrpc/fork_posix.pyx.pxi,"@@ -0,0 +1,161 @@+# Copyright 2018 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+++import logging+import os+import threading++_LOGGER = logging.getLogger(__name__)++_AWAIT_THREADS_TIMEOUT_SECONDS = 5++_TRUE_VALUES = ['yes',  'Yes',  'YES', 'true', 'True', 'TRUE', '1']++# This flag enables experimental support within gRPC Python for applications+# that will fork() without exec(). When enabled, gRPC Python will attempt to+# pause all of its internally created threads before the fork syscall proceeds.+#+# For this to be successful, the application must not have multiple threads of+# its own calling into gRPC when fork is invoked. Any callbacks from gRPC+# Python-spawned threads into user code (e.g., callbacks for asynchronous RPCs)+# must  not block and should execute quickly.+#+# This flag is not supported on Windows.+_GRPC_ENABLE_FORK_SUPPORT = (+    os.environ.get('GRPC_ENABLE_FORK_SUPPORT', '0')+        .lower() in _TRUE_VALUES)++_GRPC_POLL_STRATEGY = os.environ.get('GRPC_POLL_STRATEGY')++cdef void __prefork() nogil:+    with gil:+        with _fork_state.fork_in_progress_condition:+            _fork_state.fork_in_progress = True+        if not _fork_state.active_thread_count.await_zero_threads(+                _AWAIT_THREADS_TIMEOUT_SECONDS):+            _LOGGER.error(+                'Failed to shutdown gRPC Python threads prior to fork. '+                'Behavior after fork will be undefined.')+++cdef void __postfork_parent() nogil:+    with gil:+        with _fork_state.fork_in_progress_condition:+            _fork_state.post_fork_child_cleanup_callbacks = []+            _fork_state.fork_in_progress = False+            _fork_state.fork_in_progress_condition.notify_all()+++cdef void __postfork_child() nogil:+    with gil:+        with _fork_state.fork_in_progress_condition:+            for state_to_reset in _fork_state.postfork_states_to_reset:+                state_to_reset.reset_postfork_child()+            _fork_state.fork_epoch += 1+            _fork_state.post_fork_child_cleanup_callbacks = []+            _fork_state.fork_in_progress = False+++def fork_handlers_and_grpc_init():+    grpc_init()+    if _GRPC_ENABLE_FORK_SUPPORT:+        # TODO(ericgribkoff) epoll1 is default for grpcio distribution. Decide whether to expose+        # grpc_get_poll_strategy_name() from ev_posix.cc to get actual polling choice.+        if _GRPC_POLL_STRATEGY is not None and _GRPC_POLL_STRATEGY != ""epoll1"":+            _LOGGER.error(+                'gRPC Python fork support is only compatible with the epoll1 '+                'polling engine')+            return+        with _fork_state.fork_handler_registered_lock:+            if not _fork_state.fork_handler_registered:+                pthread_atfork(&__prefork, &__postfork_parent, &__postfork_child)+                _fork_state.fork_handler_registered = True+++def fork_managed_thread(target, args=()):+    if _GRPC_ENABLE_FORK_SUPPORT:+        def managed_target(*args):+            _fork_state.active_thread_count.increment()+            target(*args)","There's another bug here: the active thread count is only incremented once the thread's target function has actually started to run. This is problematic in (at least) the following concrete scenario: a call to channel.subscribe() starts a new thread and sets channel._connectivity_state.polling=True. Fork is invoked before the new thread's first line of code is actually run, and so the active thread count hasn't been incremented. This means the thread's code could go on to do bad things itself (such as grab a lock) before fork actually executes, and also that the child will inherit the channel with the belief that it already has a connectivity polling thread, when it does not.I addressed this by introducing cygrpc.ForkManagedThread as a new delegating class (not an override of threading.Thread), whose start() method increments the active thread count before calling threading.Thread.start(). This will increment the global thread count before the call to start() returns, meaning that any subsequent calls to fork will correctly wait for this thread to pause/conclude before proceeding.",OK
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/16053,203556250,2018-07-18T22:54:47Z,src/core/lib/iomgr/lockfree_event.cc,"@@ -89,7 +89,11 @@ void LockfreeEvent::DestroyEvent() {  void LockfreeEvent::NotifyOn(grpc_closure* closure) {   while (true) {-    gpr_atm curr = gpr_atm_no_barrier_load(&state_);+    /* This load needs to be an acquire load because this can be a shutdown+     * error that we might need to reference. Adding acquire semantics makes+     * sure that the shutdown error has been inited properly before us",initialized yes. me being lazy. will correct it :),OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/15969,203700795,2018-07-19T12:06:31Z,src/csharp/Grpc.Core/Grpc.Core.csproj,"@@ -69,4 +73,11 @@    <Import Project=""NativeDeps.csproj.include"" /> +  <ItemGroup>+    <Content Include=""build\**\*.*"">","Wouldn't it be better to list all the .targets files explicitly?Like that it would be obvious that you're including .targets files and what platforms they'll be used for.Btw, have you verified that the build/MonoAndroid/Grpc.Core.targets  file is actually needed?  AFAIK for the netstandard1.5 platform, the copying of the native libraries to the destination should work automagically without needing to provide the .targets file (as you can see we only have the .targets file for the net45 desktop platforms).",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/16057,203878331,2018-07-19T21:28:06Z,tools/internal_ci/linux/grpc_publish_packages.sh,"@@ -0,0 +1,110 @@+#!/bin/bash+# Copyright 2018 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++set -ex++shopt -s nullglob++export GOOGLE_APPLICATION_CREDENTIALS=${KOKORO_GFILE_DIR}/GrpcTesting-d0eeee2db331.json++GCS_ROOT=gs://packages.grpc.io+MANIFEST_FILE=index.xml+ARCHIVE_UUID=${KOKORO_BUILD_ID:-$(uuidgen)}+GIT_BRANCH_NAME=master #${KOKORO_GITHUB_COMMIT:-master}","I want to reuse the script to build on release branches as well, so we can rely on this to build releases automatically (with a push of a button at most) and deprecate experimental. I expected `KOKORO_GITHUB_COMMIT` to be preloaded with the branch name from the artifact build, but it seems to always be the commit SHA1. Is there a way to get access to that data or do we need an additional field in the Kokoro job?",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/16057,203878698,2018-07-19T21:29:32Z,tools/internal_ci/linux/grpc_publish_packages.sh,"@@ -0,0 +1,110 @@+#!/bin/bash+# Copyright 2018 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++set -ex++shopt -s nullglob++export GOOGLE_APPLICATION_CREDENTIALS=${KOKORO_GFILE_DIR}/GrpcTesting-d0eeee2db331.json++GCS_ROOT=gs://packages.grpc.io+MANIFEST_FILE=index.xml+ARCHIVE_UUID=${KOKORO_BUILD_ID:-$(uuidgen)}+GIT_BRANCH_NAME=master #${KOKORO_GITHUB_COMMIT:-master}+GIT_COMMIT=${KOKORO_GIT_COMMIT:-unknown}+ARCHIVE_TIMESTAMP=$(date -Iseconds)+TARGET_DIR=$(mktemp -d grpc_publish_packages.sh.XXXX)+YEAR_MONTH_PREFIX=$(date ""+%Y/%m"")+YEAR_PREFIX=${YEAR_MONTH_PREFIX%%/*}","I wanted to invoke `date` only once to avoid race conditions where the two `date` invocations return two different year/month pairs. Granted, it is very unlikely that the race happens in practice, but on principle I wanted to avoid that. That's why I rely on string manipulation on the output of the first `date` command.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16069,203884566,2018-07-19T21:53:15Z,src/core/lib/gpr/arena.cc,"@@ -118,35 +122,49 @@ void* gpr_arena_alloc(gpr_arena* arena, size_t size) {   size = GPR_ROUND_UP_TO_ALIGNMENT_SIZE(size);   size_t start = static_cast<size_t>(       gpr_atm_no_barrier_fetch_add(&arena->size_so_far, size));+  size_t total_size_of_arena_allocations = start + size;   zone* z = &arena->initial_zone;-  while (start > z->size_end) {-    zone* next_z = (zone*)gpr_atm_acq_load(&z->next_atm);-    if (next_z == nullptr) {-      size_t next_z_size =-          static_cast<size_t>(gpr_atm_no_barrier_load(&arena->size_so_far));-      next_z = static_cast<zone*>(zalloc_aligned(-          GPR_ROUND_UP_TO_ALIGNMENT_SIZE(sizeof(zone)) + next_z_size));-      next_z->size_begin = z->size_end;-      next_z->size_end = z->size_end + next_z_size;-      if (!gpr_atm_rel_cas(&z->next_atm, static_cast<gpr_atm>(NULL),-                           (gpr_atm)next_z)) {-        gpr_free_aligned(next_z);-        next_z = (zone*)gpr_atm_acq_load(&z->next_atm);++  // Check to see if the allocation isn't able to start in the initial zone.+  // This statement is true only in the uncommon case because of our arena+  // sizing historesis (that is, most calls should have a large enough initial+  // zone and will not need to grow the arena).+  if (start >= z->size_end) {+    // Find the correct zone to start the allocation in+    gpr_mu_lock(&arena->arena_growth_mutex);+    while (start >= z->size_end) {+      if (z->next == nullptr) {+        size_t next_z_size = total_size_of_arena_allocations;+        z->next = static_cast<zone*>(zalloc_aligned(+            GPR_ROUND_UP_TO_ALIGNMENT_SIZE(sizeof(zone)) + next_z_size));+        z->next->size_begin = z->size_end;+        z->next->size_end = z->size_end + next_z_size;       }+      z = z->next;     }-    z = next_z;+    gpr_mu_unlock(&arena->arena_growth_mutex);   }-  if (start + size > z->size_end) {+  // Now that we have a zone we could start in, can the allocation fit in this+  // zone? If not, call arena_alloc again. Note that this means some space in",Good catch on this!  Could we avoid this waste by refactoring this function such that the part we recurse into does not do the duplicate increment?Is it true that this will happen only if we didn't just grow the arena above?  Can we avoid this recursion altogether by moving this check into the block above where we're holding the mutex?,
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/16069,203899187,2018-07-19T23:10:08Z,src/core/lib/gpr/arena.cc,"@@ -118,35 +122,49 @@ void* gpr_arena_alloc(gpr_arena* arena, size_t size) {   size = GPR_ROUND_UP_TO_ALIGNMENT_SIZE(size);   size_t start = static_cast<size_t>(       gpr_atm_no_barrier_fetch_add(&arena->size_so_far, size));+  size_t total_size_of_arena_allocations = start + size;   zone* z = &arena->initial_zone;-  while (start > z->size_end) {-    zone* next_z = (zone*)gpr_atm_acq_load(&z->next_atm);-    if (next_z == nullptr) {-      size_t next_z_size =-          static_cast<size_t>(gpr_atm_no_barrier_load(&arena->size_so_far));-      next_z = static_cast<zone*>(zalloc_aligned(-          GPR_ROUND_UP_TO_ALIGNMENT_SIZE(sizeof(zone)) + next_z_size));-      next_z->size_begin = z->size_end;-      next_z->size_end = z->size_end + next_z_size;-      if (!gpr_atm_rel_cas(&z->next_atm, static_cast<gpr_atm>(NULL),-                           (gpr_atm)next_z)) {-        gpr_free_aligned(next_z);-        next_z = (zone*)gpr_atm_acq_load(&z->next_atm);++  // Check to see if the allocation isn't able to start in the initial zone.+  // This statement is true only in the uncommon case because of our arena+  // sizing historesis (that is, most calls should have a large enough initial+  // zone and will not need to grow the arena).+  if (start >= z->size_end) {+    // Find the correct zone to start the allocation in+    gpr_mu_lock(&arena->arena_growth_mutex);+    while (start >= z->size_end) {+      if (z->next == nullptr) {+        size_t next_z_size = total_size_of_arena_allocations;+        z->next = static_cast<zone*>(zalloc_aligned(+            GPR_ROUND_UP_TO_ALIGNMENT_SIZE(sizeof(zone)) + next_z_size));+        z->next->size_begin = z->size_end;+        z->next->size_end = z->size_end + next_z_size;       }+      z = z->next;     }-    z = next_z;+    gpr_mu_unlock(&arena->arena_growth_mutex);   }-  if (start + size > z->size_end) {+  // Now that we have a zone we could start in, can the allocation fit in this+  // zone? If not, call arena_alloc again. Note that this means some space in","I had the same thoughts and had tried a rewrite where we did not recurse and instead did this check inside the mutex. It didn't work. The problem is that we rely on size_so_far to tell us the next available memory to start an allocation at, so we unfortunately *need* the duplicate increment. Let's say we are trying to allocate x bytes onto the initial zone, which already has some bytes allocated on it. The remaining bytes available on the initial zone is less than x, so we decide that we should allocate it on the next zone. We go ahead and increment size_so_far only once and return the appropriate ptr to the available memory. Now someone calls gpr_arena_alloc and the ptr they receive, based on `size_so_far`, actually clobbers our x bytes. You can see that the inherent problem / feature here is that we don't use per-zone usage tracking, and instead just rely on this one total usage metric, size_so_far. I think it's actually a performance vs. space tradeoff to do it this way because I tried to write an implementation that uses per-zone tracking (avoids duplicate increment as well as the recursive call) and couldn't figure out how to make it equally performant. Another unfortunate thing about the duplicate increment is that we could theoretically waste a ton of space with a particularly antagonistic set of calls to gpr_arena_alloc.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16069,204078575,2018-07-20T15:16:40Z,src/core/lib/gpr/arena.cc,"@@ -118,35 +122,49 @@ void* gpr_arena_alloc(gpr_arena* arena, size_t size) {   size = GPR_ROUND_UP_TO_ALIGNMENT_SIZE(size);   size_t start = static_cast<size_t>(       gpr_atm_no_barrier_fetch_add(&arena->size_so_far, size));+  size_t total_size_of_arena_allocations = start + size;   zone* z = &arena->initial_zone;-  while (start > z->size_end) {-    zone* next_z = (zone*)gpr_atm_acq_load(&z->next_atm);-    if (next_z == nullptr) {-      size_t next_z_size =-          static_cast<size_t>(gpr_atm_no_barrier_load(&arena->size_so_far));-      next_z = static_cast<zone*>(zalloc_aligned(-          GPR_ROUND_UP_TO_ALIGNMENT_SIZE(sizeof(zone)) + next_z_size));-      next_z->size_begin = z->size_end;-      next_z->size_end = z->size_end + next_z_size;-      if (!gpr_atm_rel_cas(&z->next_atm, static_cast<gpr_atm>(NULL),-                           (gpr_atm)next_z)) {-        gpr_free_aligned(next_z);-        next_z = (zone*)gpr_atm_acq_load(&z->next_atm);++  // Check to see if the allocation isn't able to start in the initial zone.+  // This statement is true only in the uncommon case because of our arena+  // sizing historesis (that is, most calls should have a large enough initial+  // zone and will not need to grow the arena).+  if (start >= z->size_end) {+    // Find the correct zone to start the allocation in+    gpr_mu_lock(&arena->arena_growth_mutex);+    while (start >= z->size_end) {+      if (z->next == nullptr) {+        size_t next_z_size = total_size_of_arena_allocations;+        z->next = static_cast<zone*>(zalloc_aligned(+            GPR_ROUND_UP_TO_ALIGNMENT_SIZE(sizeof(zone)) + next_z_size));+        z->next->size_begin = z->size_end;+        z->next->size_end = z->size_end + next_z_size;       }+      z = z->next;     }-    z = next_z;+    gpr_mu_unlock(&arena->arena_growth_mutex);   }-  if (start + size > z->size_end) {+  // Now that we have a zone we could start in, can the allocation fit in this+  // zone? If not, call arena_alloc again. Note that this means some space in","I see... So the fact that we re-increment `size_so_far` is the thing that prevents multiple simultaneous callers from stepping on each other.  In particular, I think (but please correct me if I'm wrong) that this means that whenever we need to allocate x bytes and there are x - n (where n > 0) remaining in the current zone, we will waste x bytes (x - n in the current zone and n in the new zone).This behavior wasn't at all clear from first read of the code.  It would probably be a good idea to add this explanation into the comment.Am I correct in saying that as soon as the arena needs a second zone, all subsequent callers will need to acquire the mutex, even if they don't wind up needing to add a new zone themselves (i.e., if the arena already has 2 zones, the next caller will need to acquire the mutex even if it fits in the second zone)?Assuming that's correct, it seems like we could still avoid this recursion and thus avoid the need to release and then re-acquire the mutex:- On lines 132 and 135, instead of checking whether the allocation can start in the current zone, check whether the allocation can end in the current zone.- If we get to the last zone and still can't fit (the block on line 136), then just duplicate lines 123-125 to increment `size_so_far` before adding the new zone.Also, given that we're acquiring the mutex anyway, it seems like we could avoid wasting space if we wanted by storing the amount of wasted space and the starting offset of the waste in fields protected by the mutex.  Then, callers that have to acquire the mutex anyway could use that information to grab some of the wasted space, if they fit.  Of course, this does add complexity, and the amount of waste is probably not huge, and this won't be an issue for most RPCs anyway, so it's probably not worth the complexity.",OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/16069,204149668,2018-07-20T19:38:27Z,src/core/lib/gpr/arena.cc,"@@ -118,35 +122,49 @@ void* gpr_arena_alloc(gpr_arena* arena, size_t size) {   size = GPR_ROUND_UP_TO_ALIGNMENT_SIZE(size);   size_t start = static_cast<size_t>(       gpr_atm_no_barrier_fetch_add(&arena->size_so_far, size));+  size_t total_size_of_arena_allocations = start + size;   zone* z = &arena->initial_zone;-  while (start > z->size_end) {-    zone* next_z = (zone*)gpr_atm_acq_load(&z->next_atm);-    if (next_z == nullptr) {-      size_t next_z_size =-          static_cast<size_t>(gpr_atm_no_barrier_load(&arena->size_so_far));-      next_z = static_cast<zone*>(zalloc_aligned(-          GPR_ROUND_UP_TO_ALIGNMENT_SIZE(sizeof(zone)) + next_z_size));-      next_z->size_begin = z->size_end;-      next_z->size_end = z->size_end + next_z_size;-      if (!gpr_atm_rel_cas(&z->next_atm, static_cast<gpr_atm>(NULL),-                           (gpr_atm)next_z)) {-        gpr_free_aligned(next_z);-        next_z = (zone*)gpr_atm_acq_load(&z->next_atm);++  // Check to see if the allocation isn't able to start in the initial zone.+  // This statement is true only in the uncommon case because of our arena+  // sizing historesis (that is, most calls should have a large enough initial+  // zone and will not need to grow the arena).+  if (start >= z->size_end) {+    // Find the correct zone to start the allocation in+    gpr_mu_lock(&arena->arena_growth_mutex);+    while (start >= z->size_end) {+      if (z->next == nullptr) {+        size_t next_z_size = total_size_of_arena_allocations;+        z->next = static_cast<zone*>(zalloc_aligned(+            GPR_ROUND_UP_TO_ALIGNMENT_SIZE(sizeof(zone)) + next_z_size));+        z->next->size_begin = z->size_end;+        z->next->size_end = z->size_end + next_z_size;       }+      z = z->next;     }-    z = next_z;+    gpr_mu_unlock(&arena->arena_growth_mutex);   }-  if (start + size > z->size_end) {+  // Now that we have a zone we could start in, can the allocation fit in this+  // zone? If not, call arena_alloc again. Note that this means some space in","Yes, I believe your statement on the precise number of wasted bytes is correct. I've added your explanation as a comment in the code.Yes, once the arena needs a second zone, subsequent callers will need to acquire the mutex in order to navigate past the initial zone and find a zone they can potentially allocate in. I've changed the code to avoid recursion according to your suggestion.We should be aware of the workaround for avoiding wasting space in case it's needed in the future, but I agree that it's probably not worth the added complexity. ",
1096616,mattleibow,https://api.github.com/repos/grpc/grpc/pulls/16089,204216782,2018-07-21T17:41:41Z,src/csharp/Grpc.Core/Internal/NativeLogRedirector.cs,"@@ -51,6 +51,7 @@ public static void Redirect(NativeMethods native)             }         } +        [MonoPInvokeCallback(typeof(GprLogDelegate))]","If this is not added, then this runtime error occurs:> Attempting to JIT compile method '(wrapper native-to-managed) Grpc.Core.Internal.NativeLogRedirector:HandleWrite (intptr,int,ulong,intptr,intptr)' while running in aot-only mode. See https://developer.xamarin.com/guides/ios/advanced_topics/limitations/ for more information.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16089,204395621,2018-07-23T13:14:56Z,src/csharp/Grpc.Core/Internal/PlatformApis.cs,"@@ -33,12 +33,17 @@ namespace Grpc.Core.Internal     internal static class PlatformApis     {         const string UnityEngineApplicationClassName = ""UnityEngine.Application, UnityEngine"";+        const string XamarinAndroidApplicationClassName = ""Android.App.Application, Mono.Android"";+        const string XamariniOSApplicationClassName = ""UIKit.UIApplication, Xamarin.iOS"";","can you provide some reasoning why UIKit.UIApplication, Xamarin.iOS  is a good detection mechanism? I saw https://github.com/grpc/grpc/pull/15969/files is using a different class name (but using `Mono.CSharp.Enum, Mono.CSharp` actually might be a typo.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16089,204407422,2018-07-23T13:49:24Z,src/csharp/Grpc.Core/Internal/NativeLogRedirector.cs,"@@ -86,4 +87,15 @@ private static void HandleWrite(IntPtr fileStringPtr, int line, ulong threadId,             }         }     }++    [AttributeUsage(AttributeTargets.Method)]+    internal sealed class MonoPInvokeCallbackAttribute : Attribute","This is probably worth a comment that explains why this is defined and that just naming a custom attribute ""MonoPInvokeCallback"" is enough for the AOT compiler to pick it up (= it doesn't have to a specific attribute class defined in Mono's assemblies).",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16084,204430399,2018-07-23T14:49:36Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -67,6 +67,9 @@ using grpc_core::internal::ServerRetryThrottleData;  /* Client channel implementation */ +gpr_timespec start, end;","Instead of using global variables, could record this via the disabled-by-default stats mechanism, which would give us a histogram when we run a test with a large number of RPCs.",OK
2446666,ahouben,https://api.github.com/repos/grpc/grpc/pulls/15969,204434986,2018-07-23T15:00:34Z,src/csharp/Grpc.Core/Internal/PlatformApis.cs,"@@ -33,12 +33,17 @@ namespace Grpc.Core.Internal     internal static class PlatformApis     {         const string UnityEngineApplicationClassName = ""UnityEngine.Application, UnityEngine"";+        const string XamarinAndroidActivityClassName = ""Android.App.Activity, Mono.Android"";","Good you doublecheck ;)Unfortunately, I can't give you a reference to a good source.I couldn't find a better way of querying the underlying runtime from within a .netstandard1.5 library project other than how `isMono` and `isUnity` are already detected (using reflection) and chose types which most probably must exist in all versions of assemblies Mono.Android and monotouch assemblies since the beginning of time.This should probably be changed to ""Java.Lang.Object, Mono.Android"" to be more similar to the ""Foundation.NSObject, Xamarin.iOS"" managed base object of the two platforms.Is there a better way ?",
2446666,ahouben,https://api.github.com/repos/grpc/grpc/pulls/15969,204454081,2018-07-23T15:50:11Z,src/csharp/Grpc.Core/Grpc.Core.csproj,"@@ -69,4 +73,11 @@    <Import Project=""NativeDeps.csproj.include"" /> +  <ItemGroup>+    <Content Include=""build\**\*.*"">","Sure, explicitly listing the .targets files is fine, too.Yes, the build/MonoAndroid/Grpc.Core.targets file is necessary, because in `Android App` projects builds use the `Build Action` called `AndroidNativeLibrary` to include native libraries in the build, see https://docs.microsoft.com/en-us/xamarin/android/platform/native-libraries.There's another TODO here for `Android Class Library` projects which use the `Build Action` called `EmbeddedNativeLibrary`.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16106,204771551,2018-07-24T14:11:38Z,doc/statuscodes.md,"@@ -47,3 +48,5 @@ The following status codes are never generated by the library: - ABORTED - OUT_OF_RANGE - DATA_LOSS++The decision to retry RPCs at the application level depends on the application and the type of error. There is no single guidance that will work for all. ","Suggest alternative wording:Applications that may wish to [retry](https://github.com/grpc/proposal/blob/master/A6-client-retries.md) failed RPCs must decide which status codes on which to retry.  However, because any status code returned by the gRPC library can also be returned by the server application, there is no fixed list of status codes on which it is appropriate to retry in all applications.  As a result, individual applications must make their own determination as to which status codes should cause an RPC to be retried.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16106,204849208,2018-07-24T17:44:12Z,doc/statuscodes.md,"@@ -47,3 +48,5 @@ The following status codes are never generated by the library: - ABORTED - OUT_OF_RANGE - DATA_LOSS++The decision to retry RPCs at the application level depends on the application and the type of error. There is no single guidance that will work for all. ","Okay, so let's include something about how the gRPC library may generate the same code for different reasons, as shown in the table above.The way this is currently phrased doesn't provide much context to the reader.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16106,204857594,2018-07-24T18:07:54Z,doc/statuscodes.md,"@@ -47,3 +48,5 @@ The following status codes are never generated by the library: - ABORTED - OUT_OF_RANGE - DATA_LOSS++Applications that may wish to retry failed RPCs must decide which status codes on which to retry. As shown in the table above, the gRPC library can generate the same status code for different cases. Server applications can also return those same status codes. Therefore, there is no fixed list of status codes on which it is appropriate to retry in all applications. As a result, individual applications must make their own determination as to which status codes should cause an RPC to be retried.","Please make the first occurrence of ""retry"" a link to https://github.com/grpc/proposal/blob/master/A6-client-retries.md.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16018,205082293,2018-07-25T12:04:58Z,doc/server-reflection.md,"@@ -15,6 +15,19 @@ This broadly involves two problems: determining what formats (which protobuf messages) a server’s method uses, and determining how to convert messages between human readable format and the (likely binary) wire format. +## Enabling server reflection","I think adding links to tutorials in different languages is very useful, but at the same time I'm not 100% convinced that this document is the right place for it (or at least the way it's being done).This doc is the ""gRPC server reflection protocol"" and it was meant mostly as a design doc / spec (and not a guide how to use), so suddenly adding a section that links to tutorials feels a bit misplaced).Btw, there's also the C++ server tutorial which ideally could act as general introduction but, at the same time it's C++ specific, despite lot of the concepts described there (and the grpc_cli command examples) are universal.Maybe it could be reworked to contain the general introduction and then link to language-specific guides?This ""protocol description"" doc could then contain only a link to usage guide.What do you think?",OK
3584893,jadekler,https://api.github.com/repos/grpc/grpc/pulls/16018,205165114,2018-07-25T15:52:47Z,doc/server-reflection.md,"@@ -15,6 +15,19 @@ This broadly involves two problems: determining what formats (which protobuf messages) a server’s method uses, and determining how to convert messages between human readable format and the (likely binary) wire format. +## Enabling server reflection","Good points. I choose this doc because it has the most SEO when users search for ""grpc server reflection"", but I'm open to other docs. The doc you suggested - is that https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md?Alternatively, perhaps an option is a spot on grpc.io.",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/16081,205191819,2018-07-25T17:15:40Z,src/core/lib/iomgr/resource_quota.cc,"@@ -785,6 +826,37 @@ void grpc_resource_user_shutdown(grpc_resource_user* resource_user) {   } } +bool grpc_resource_user_alloc_threads(grpc_resource_user* resource_user,+                                      int thd_count) {+  bool is_success = false;+  gpr_mu_lock(&resource_user->resource_quota->thd_mu);+  grpc_resource_quota* rq = resource_user->resource_quota;+  if (rq->num_threads + thd_count <= rq->max_threads) {+    rq->num_threads += thd_count;+    gpr_atm_no_barrier_fetch_add(&resource_user->num_threads, thd_count);+    is_success = true;+  }+  gpr_mu_unlock(&resource_user->resource_quota->thd_mu);+  return is_success;+}++void grpc_resource_user_free_threads(grpc_resource_user* resource_user,+                                     int thd_count) {+  gpr_mu_lock(&resource_user->resource_quota->thd_mu);+  grpc_resource_quota* rq = resource_user->resource_quota;+  rq->num_threads -= thd_count;+  int old_cnt = static_cast<int>(+      gpr_atm_no_barrier_fetch_add(&resource_user->num_threads, -thd_count));+  if (old_cnt < thd_count || rq->num_threads < 0) {+    gpr_log(GPR_ERROR,+            ""Releasing more threads (%d) that currently allocated (rq threads: ""+            ""%d, ru threads: %d)"",+            thd_count, old_cnt, rq->num_threads + thd_count);",It looks like the last two parameters to the debug statement should be swapped. Old_count is the # resource user threads and rq->num_threads + thread_count was the # of rq threads?,OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/16081,205192938,2018-07-25T17:19:00Z,src/core/lib/iomgr/resource_quota.h,"@@ -93,6 +93,22 @@ void grpc_resource_user_ref(grpc_resource_user* resource_user); void grpc_resource_user_unref(grpc_resource_user* resource_user); void grpc_resource_user_shutdown(grpc_resource_user* resource_user); +/* Attempts to get quota (from the resource_user) to create 'thd_count' number+ * of threads. Returns true if successful (i.e the caller is now free to create+ * 'thd_count' number of threads) or false if quota is not available */+bool grpc_resource_user_alloc_threads(grpc_resource_user* resource_user,","Very much nit: alloc can be a noun, so I would suggest renaming this to ""grpc_resource_user_allocate_threads"" so that first time readers don't get tripped up on misinterpreting it as a noun",OK
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/16136,205215497,2018-07-25T18:25:29Z,doc/csharp/server_reflection.md,"@@ -0,0 +1,52 @@+# gRPC C# Server Reflection++This document shows how to use gRPC Server Reflection in gRPC C#.+Please see [C++ Server Reflection Tutorial](../server_reflection_tutorial.md)+for general information and more examples how to use server reflection.++## Enable server reflection in C# servers++C# Server Reflection is an add-on library.+To use it, first install the [Grpc.Reflection](https://www.nuget.org/packages/Grpc.Reflection/)+Nuget package into your project.++Unlike in other languages, with C# you need to manually register the service","I would drop the ""Unlike in other languages"". Python behaves similarly.",OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/16081,205226479,2018-07-25T18:59:31Z,include/grpcpp/resource_quota.h,"@@ -26,10 +26,10 @@ struct grpc_resource_quota;  namespace grpc { -/// ResourceQuota represents a bound on memory usage by the gRPC library.-/// A ResourceQuota can be attached to a server (via \a ServerBuilder),+/// ResourceQuota represents a bound on memory and thread usage by the gRPC+/// library. A ResourceQuota can be attached to a server (via \a ServerBuilder), /// or a client channel (via \a ChannelArguments).-/// gRPC will attempt to keep memory used by all attached entities+/// gRPC will attempt to keep memory and threads used by all attached entities","Since ResourceQuota now refers to both memory and thread usage, I would recommend re-naming the Resize method. It's no longer clear that the method is intended to refer to memory since there are now two ""sizes"" (threads and memory). However, I don't know how possible this change is since Resize() is part of the API.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16142,205424300,2018-07-26T11:40:19Z,tools/run_tests/performance/README.md,"@@ -104,3 +104,29 @@ Example memory profile of grpc-go server, with `go tools pprof`: ``` $ go tool pprof --text --alloc_space http://localhost:<pprof_port>/debug/heap ```++### Configuration environment variables:++* QPS_WORKER_CHANNEL_CONNECT_TIMEOUT++  Consuming process: qps_worker++  Type: integer (number of seconds)++  This can be used to configure the amount of time that benchmark+  clients wait for channels to the benchmark server to become ready.+  This is useful in certain benchmark environments in which the+  server can take a long time to become ready. Note: if setting+  this to a high value, then the scenario config under test should+  probably also have a large ""warmup_seconds"".++* QPS_WORKERS++  Consuming process: qps_json_driver++  Type: comma separated list of host:port++  Set this to a comma separated list of QPS worker processes/machines.+  Note that the driver will start the ""benchmark server"" on the first","I think this is not accurate.  from the list, the first N items will be consumed to represent servers based on the json configuration of how many servers are requested for given scenario. The next K will be taken as clients).https://github.com/grpc/grpc/blob/158fb288fc9807ddf9d6adca6f3d4803e855ae34/tools/run_tests/performance/scenario_config.py#L137special cases:- if you specify num_server + num_clients  less than the number of items in QPS_WORKERS, the rest will get unused.- i think num_clients=0 used to mean something like ""consume all the remaining workers from the list"", but I'm not sure if that's the case or not.It's actually pretty convoluted :-)",OK
1009310,JackOfMostTrades,https://api.github.com/repos/grpc/grpc/pulls/12656,205613659,2018-07-26T21:50:23Z,src/python/grpcio/grpc/__init__.py,"@@ -1378,7 +1378,8 @@ def method_handlers_generic_handler(service, method_handlers):  def ssl_channel_credentials(root_certificates=None,                             private_key=None,-                            certificate_chain=None):+                            certificate_chain=None,+                            verify_options=None):","There was a bit of churn before the PR was opened that led to this being an object. At first there were more options (like assert fingerprint, skip hostname verification, ...) but all that got pulled out. Given that, I think it would be perfectly fine just to have a `verify_callback=None` argument that could be passed in directly. It could be helpful to forward-plan for additional options inside the verify_options, but I can't name any off the top of my head I think should be added that the callback couldn't implement. I also think it's reasonably pythonic if we wanted to support more options in the future to just to add those as additional optional named arguments.So given that context, unless you think otherwise I'll just change this to a `verify_callback` parameter.",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/16161,205619737,2018-07-26T22:18:28Z,src/core/lib/iomgr/ev_poll_posix.cc,"@@ -557,6 +557,23 @@ static void fd_notify_on_error(grpc_fd* fd, grpc_closure* closure) {   abort(); } +static void fd_set_readable(grpc_fd* fd) {+  gpr_mu_lock(&fd->mu);+  set_ready_locked(fd, &fd->read_closure);+  gpr_mu_unlock(&fd->mu);+}++static void fd_set_writable(grpc_fd* fd) {+  gpr_mu_lock(&fd->mu);+  set_ready_locked(fd, &fd->write_closure);+  gpr_mu_unlock(&fd->mu);+}++static void fd_set_error(grpc_fd* fd) {+  gpr_log(GPR_ERROR, ""Polling engine does not support tracking errors."");+  abort();",similar to https://github.com/grpc/grpc/blob/7fc47f27d5956fdc8ca7a3567ea8313e7fe742b5/src/core/lib/iomgr/ev_poll_posix.cc#L494,
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/16161,205631219,2018-07-26T23:28:40Z,src/core/lib/iomgr/ev_poll_posix.cc,"@@ -557,6 +557,23 @@ static void fd_notify_on_error(grpc_fd* fd, grpc_closure* closure) {   abort(); } +static void fd_set_readable(grpc_fd* fd) {+  gpr_mu_lock(&fd->mu);+  set_ready_locked(fd, &fd->read_closure);+  gpr_mu_unlock(&fd->mu);+}++static void fd_set_writable(grpc_fd* fd) {+  gpr_mu_lock(&fd->mu);+  set_ready_locked(fd, &fd->write_closure);+  gpr_mu_unlock(&fd->mu);+}++static void fd_set_error(grpc_fd* fd) {+  gpr_log(GPR_ERROR, ""Polling engine does not support tracking errors."");+  abort();","ok..that sounds reasonable (i.e checking the can_track_err field).. Since this is not a super critical feature and there is a way to gracefully fail, I prefer going that route and not aborting..I feel in general abort() should be reserved for cases where the program do not know how to proceed (and proceeding further would result in very bad consequences)",OK
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/16081,205916129,2018-07-27T22:44:05Z,src/core/lib/iomgr/resource_quota.cc,"@@ -135,12 +138,32 @@ struct grpc_resource_quota {    gpr_atm last_size; +  /* Mutex to protect max_threads and num_threads */+  /* Note: We could have used gpr_atm for max_threads and num_threads and avoid+   * having this mutex; but in that case, each invocation of the function+   * grpc_resource_user_alloc_threads() will have to do atleast two atomic loads+   * (for max_threads and num_threads) followed by a CAS (on num_threads).+   * Moreover, we expect grpc_resource_user_alloc_threads() to be often called+   * concurrently thereby increasing the chances of failing the CAS operation.+   * This additional complexity is not worth the tiny perf gain we may (or may+   * not) have by using atomics */+  gpr_mu thd_mu;++  /* Max number of threads allowed */+  int max_threads;++  /* Number of threads currently allocated via this resource_quota object */+  int num_threads;","Thanks for the suggestion. After I made the change, the code reads much better!(Generally in c-core the variable names are short and I am also generally big fan of small names. In this case, however, I agree with you).",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12656,205929172,2018-07-28T01:48:22Z,src/ruby/ext/grpc/rb_channel_credentials.c,"@@ -124,6 +125,84 @@ static ID id_pem_private_key; /* The attribute used on the mark object to hold the pem_private_key. */ static ID id_pem_cert_chain; +/* The attribute used on the mark object to hold the checkServerIdentity+ * callback. */+static ID id_check_server_identity_cb;++struct verify_callback_params {+  VALUE cb;+  const char* servername;+  const char* cert;+};++static VALUE verify_peer_callback_try_wrapper(VALUE arg) {+  VALUE cb;+  VALUE servername;+  VALUE cert;++  cb = rb_ary_entry(arg, 0);+  servername = rb_ary_entry(arg, 1);+  cert = rb_ary_entry(arg, 2);++  if (rb_class_of(cb) == rb_cProc) {+    rb_funcall(cb, rb_intern(""call""), 2, servername, cert);+  } else if (rb_class_of(cb) == rb_cSymbol) {+    rb_funcall(rb_class_of(cb), rb_to_id(cb), 2, servername, cert);+  } else {+    printf(+        ""Callback argument in verify_peer_callback_try_wrapper is an invalid ""+        ""type!\n"");+    return INT2NUM(1);+  }+  return INT2NUM(0);+}++static VALUE verify_peer_callback_catch_wrapper(VALUE arg,+                                                VALUE exception_object) {+  // Catch just always returns a failure signal.+  return INT2NUM(1);+}++/* Before we jump back from native code (which doesn't have the GVL), it's+   important to re-acquire it otherwise badness can happen. So this method+   should be invoked with the GVL (i.e. by using the rb_thread_call_with_gvl()+   method). */+static void* invoke_rb_verify_callback_with_gvl(void* arg) {+  VALUE result;+  VALUE passthrough;+  struct verify_callback_params* params = (struct verify_callback_params*)arg;++  passthrough = rb_ary_new();+  rb_ary_store(passthrough, 0, params->cb);+  rb_ary_store(+      passthrough, 1,+      params->servername != NULL ? rb_str_new2(params->servername) : Qnil);+  rb_ary_store(passthrough, 2,+               params->cert != NULL ? rb_str_new2(params->cert) : Qnil);++  result = rb_rescue(verify_peer_callback_try_wrapper, passthrough,+                     verify_peer_callback_catch_wrapper, Qnil);+  return NUM2INT(result) == 0 ? NULL : arg;+}++static int verify_peer_callback_wrapper(const char* servername,+                                        const char* cert, void* userdata) {+  struct verify_callback_params params;+  if (userdata == NULL) {+    printf(""Error! Callback function wasn't set!\n"");+    return 1;+  }++  params.cb = (VALUE)userdata;+  params.servername = servername;+  params.cert = cert;++  return rb_thread_call_with_gvl(invoke_rb_verify_callback_with_gvl, &params) ==","I think the way this callback is invoked with respect to concurrency needs to be changed.The C-Core is completely non-blocking and asynchronous. Since some C-Core thread (which may or may not be a ruby thread), is directly acquiring the interpreter lock and calling in to this ruby application handler, this has the potential to indefinitely block a C-Core thread and prevent intended work from being done.One fix for this could be to dedicate a ruby thread to the task of invoking these callbacks. Such a thread could poll for work on a queue of ""ready-to-run"" ""veroify peer callbacks"". The actual verify peer callback handler that the C-Core invokes would just add to that queue, signal conditional variable, etc.. We already have such a thread for the task is invoking ruby-defined ""call credentials"" callbacks (See https://github.com/grpc/grpc/blob/master/src/ruby/ext/grpc/rb_event_thread.c#L126), so I think that adding another would could be reasonable. An optimization could be to combine both of these thread in to one, but I'm not sure that's worth doing.",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/12656,205929628,2018-07-28T02:05:33Z,src/ruby/ext/grpc/rb_channel_credentials.c,"@@ -124,6 +125,84 @@ static ID id_pem_private_key; /* The attribute used on the mark object to hold the pem_private_key. */ static ID id_pem_cert_chain; +/* The attribute used on the mark object to hold the checkServerIdentity+ * callback. */+static ID id_check_server_identity_cb;++struct verify_callback_params {+  VALUE cb;+  const char* servername;+  const char* cert;+};++static VALUE verify_peer_callback_try_wrapper(VALUE arg) {+  VALUE cb;+  VALUE servername;+  VALUE cert;++  cb = rb_ary_entry(arg, 0);+  servername = rb_ary_entry(arg, 1);+  cert = rb_ary_entry(arg, 2);++  if (rb_class_of(cb) == rb_cProc) {+    rb_funcall(cb, rb_intern(""call""), 2, servername, cert);+  } else if (rb_class_of(cb) == rb_cSymbol) {+    rb_funcall(rb_class_of(cb), rb_to_id(cb), 2, servername, cert);+  } else {+    printf(+        ""Callback argument in verify_peer_callback_try_wrapper is an invalid ""+        ""type!\n"");+    return INT2NUM(1);+  }+  return INT2NUM(0);+}++static VALUE verify_peer_callback_catch_wrapper(VALUE arg,+                                                VALUE exception_object) {+  // Catch just always returns a failure signal.+  return INT2NUM(1);+}++/* Before we jump back from native code (which doesn't have the GVL), it's+   important to re-acquire it otherwise badness can happen. So this method+   should be invoked with the GVL (i.e. by using the rb_thread_call_with_gvl()+   method). */+static void* invoke_rb_verify_callback_with_gvl(void* arg) {+  VALUE result;+  VALUE passthrough;+  struct verify_callback_params* params = (struct verify_callback_params*)arg;++  passthrough = rb_ary_new();+  rb_ary_store(passthrough, 0, params->cb);+  rb_ary_store(+      passthrough, 1,+      params->servername != NULL ? rb_str_new2(params->servername) : Qnil);+  rb_ary_store(passthrough, 2,+               params->cert != NULL ? rb_str_new2(params->cert) : Qnil);++  result = rb_rescue(verify_peer_callback_try_wrapper, passthrough,+                     verify_peer_callback_catch_wrapper, Qnil);+  return NUM2INT(result) == 0 ? NULL : arg;+}++static int verify_peer_callback_wrapper(const char* servername,+                                        const char* cert, void* userdata) {+  struct verify_callback_params params;+  if (userdata == NULL) {+    printf(""Error! Callback function wasn't set!\n"");+    return 1;+  }++  params.cb = (VALUE)userdata;+  params.servername = servername;+  params.cert = cert;++  return rb_thread_call_with_gvl(invoke_rb_verify_callback_with_gvl, &params) ==","Also, just to add, granted an indefinitely blocking application callback would also deadlock a dedicated callback thread and prevent more callbacks from being fired, but IMO overall the dedicated thread is simpler; it's difficult to reason about what happens when a c-core thread acquires a ruby lock and runs ruby code.",
1009310,JackOfMostTrades,https://api.github.com/repos/grpc/grpc/pulls/12656,205930096,2018-07-28T02:29:21Z,src/ruby/ext/grpc/rb_channel_credentials.c,"@@ -124,6 +125,84 @@ static ID id_pem_private_key; /* The attribute used on the mark object to hold the pem_private_key. */ static ID id_pem_cert_chain; +/* The attribute used on the mark object to hold the checkServerIdentity+ * callback. */+static ID id_check_server_identity_cb;++struct verify_callback_params {+  VALUE cb;+  const char* servername;+  const char* cert;+};++static VALUE verify_peer_callback_try_wrapper(VALUE arg) {+  VALUE cb;+  VALUE servername;+  VALUE cert;++  cb = rb_ary_entry(arg, 0);+  servername = rb_ary_entry(arg, 1);+  cert = rb_ary_entry(arg, 2);++  if (rb_class_of(cb) == rb_cProc) {+    rb_funcall(cb, rb_intern(""call""), 2, servername, cert);+  } else if (rb_class_of(cb) == rb_cSymbol) {+    rb_funcall(rb_class_of(cb), rb_to_id(cb), 2, servername, cert);+  } else {+    printf(+        ""Callback argument in verify_peer_callback_try_wrapper is an invalid ""+        ""type!\n"");+    return INT2NUM(1);+  }+  return INT2NUM(0);+}++static VALUE verify_peer_callback_catch_wrapper(VALUE arg,+                                                VALUE exception_object) {+  // Catch just always returns a failure signal.+  return INT2NUM(1);+}++/* Before we jump back from native code (which doesn't have the GVL), it's+   important to re-acquire it otherwise badness can happen. So this method+   should be invoked with the GVL (i.e. by using the rb_thread_call_with_gvl()+   method). */+static void* invoke_rb_verify_callback_with_gvl(void* arg) {+  VALUE result;+  VALUE passthrough;+  struct verify_callback_params* params = (struct verify_callback_params*)arg;++  passthrough = rb_ary_new();+  rb_ary_store(passthrough, 0, params->cb);+  rb_ary_store(+      passthrough, 1,+      params->servername != NULL ? rb_str_new2(params->servername) : Qnil);+  rb_ary_store(passthrough, 2,+               params->cert != NULL ? rb_str_new2(params->cert) : Qnil);++  result = rb_rescue(verify_peer_callback_try_wrapper, passthrough,+                     verify_peer_callback_catch_wrapper, Qnil);+  return NUM2INT(result) == 0 ? NULL : arg;+}++static int verify_peer_callback_wrapper(const char* servername,+                                        const char* cert, void* userdata) {+  struct verify_callback_params params;+  if (userdata == NULL) {+    printf(""Error! Callback function wasn't set!\n"");+    return 1;+  }++  params.cb = (VALUE)userdata;+  params.servername = servername;+  params.cert = cert;++  return rb_thread_call_with_gvl(invoke_rb_verify_callback_with_gvl, &params) ==","Hmm, what you're saying makes total sense, but the verify callback exposed by C-Core at present expects the callback to be synchronous so it doesn't pass in the on_peer_checked closure that would allow the callback to be asynchronous.I don't think it would be a big deal to tweak the C-Core API so that callbacks are asynchronous. Which sounds like it might be important given interpreter locks. Is there anyone that should weight in before I go down the route of changing that core API?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/12656,206257905,2018-07-30T17:32:23Z,src/ruby/ext/grpc/rb_channel_credentials.c,"@@ -124,6 +125,84 @@ static ID id_pem_private_key; /* The attribute used on the mark object to hold the pem_private_key. */ static ID id_pem_cert_chain; +/* The attribute used on the mark object to hold the checkServerIdentity+ * callback. */+static ID id_check_server_identity_cb;++struct verify_callback_params {+  VALUE cb;+  const char* servername;+  const char* cert;+};++static VALUE verify_peer_callback_try_wrapper(VALUE arg) {+  VALUE cb;+  VALUE servername;+  VALUE cert;++  cb = rb_ary_entry(arg, 0);+  servername = rb_ary_entry(arg, 1);+  cert = rb_ary_entry(arg, 2);++  if (rb_class_of(cb) == rb_cProc) {+    rb_funcall(cb, rb_intern(""call""), 2, servername, cert);+  } else if (rb_class_of(cb) == rb_cSymbol) {+    rb_funcall(rb_class_of(cb), rb_to_id(cb), 2, servername, cert);+  } else {+    printf(+        ""Callback argument in verify_peer_callback_try_wrapper is an invalid ""+        ""type!\n"");+    return INT2NUM(1);+  }+  return INT2NUM(0);+}++static VALUE verify_peer_callback_catch_wrapper(VALUE arg,+                                                VALUE exception_object) {+  // Catch just always returns a failure signal.+  return INT2NUM(1);+}++/* Before we jump back from native code (which doesn't have the GVL), it's+   important to re-acquire it otherwise badness can happen. So this method+   should be invoked with the GVL (i.e. by using the rb_thread_call_with_gvl()+   method). */+static void* invoke_rb_verify_callback_with_gvl(void* arg) {+  VALUE result;+  VALUE passthrough;+  struct verify_callback_params* params = (struct verify_callback_params*)arg;++  passthrough = rb_ary_new();+  rb_ary_store(passthrough, 0, params->cb);+  rb_ary_store(+      passthrough, 1,+      params->servername != NULL ? rb_str_new2(params->servername) : Qnil);+  rb_ary_store(passthrough, 2,+               params->cert != NULL ? rb_str_new2(params->cert) : Qnil);++  result = rb_rescue(verify_peer_callback_try_wrapper, passthrough,+                     verify_peer_callback_catch_wrapper, Qnil);+  return NUM2INT(result) == 0 ? NULL : arg;+}++static int verify_peer_callback_wrapper(const char* servername,+                                        const char* cert, void* userdata) {+  struct verify_callback_params params;+  if (userdata == NULL) {+    printf(""Error! Callback function wasn't set!\n"");+    return 1;+  }++  params.cb = (VALUE)userdata;+  params.servername = servername;+  params.cert = cert;++  return rb_thread_call_with_gvl(invoke_rb_verify_callback_with_gvl, &params) ==","I agree, it's not okay to block in a callback from a C-core thread.I'm not thrilled about adding yet another case where we need an asynchronous callback from C-core to the application.  We already have a few of these, and they've caused a number of headaches over time; it turns out to be fairly tricky to get the synchronization and state machinery right when leaving and re-entering C-core.That having been said, I don't have a better suggestion, and the C-core API is not a public API, so we do have the flexibility to change this later if we can come up with something better.  So I'd say go ahead and add the callback to the API.I suggest that you model the changes after one of the existing implementations.  The best one to look at is probably the metadata credentials plugin, whose API is defined here:https://github.com/grpc/grpc/blob/master/include/grpc/grpc_security.h#L304The implementation is here:https://github.com/grpc/grpc/blob/master/src/core/lib/security/credentials/plugin/plugin_credentials.cchttps://github.com/grpc/grpc/blob/master/src/core/lib/security/credentials/plugin/plugin_credentials.hNote that this API allows both sync and async returns.  The sync return is much simpler and more efficient in the case where no blocking is needed; the async return requires a callback and a thread hop, so it's more complex and less efficient.One thing that is not handled correctly in the metadata credentials plugin API is cancellation.  Unfortunately, this API didn't originally support cancellation, and all of the wrapped language APIs were added without cancellation support.  When we later realized that we needed to support this, we were able to change the C-core API, but it was too late to fix the wrapped language APIs.  So we did a poor man's approach: we have C-core mark the request as cancelled, and when the wrapped language eventually invokes the callback, nothing actually happens.  But this means that we still wind up doing a lot of processing in the application that isn't actually necessary, because we have no way to inform it that the work is no longer needed.  I highly recommend not making that mistake with this new API: let's make sure that we expose a way of propagating cancelations to the wrapped language, so that this can be handled as a first-class citizen.Please let me know if you have any questions.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/16186,206370268,2018-07-31T01:20:54Z,src/core/lib/debug/trace.h,"@@ -97,18 +88,41 @@ class TraceFlag { #endif }; -#ifndef NDEBUG-typedef TraceFlag DebugOnlyTraceFlag;-#else-class DebugOnlyTraceFlag {+#else   // GRPC_USE_TRACERS+// Otherwise optimize away tracers.+class TraceFlag {  public:-  DebugOnlyTraceFlag(bool default_enabled, const char* name) {}-  bool enabled() { return false; }+  constexpr TraceFlag(bool default_enabled, const char* name) {}+  const char* name() const { return ""DisabledTracer""; }+  bool enabled() const { return false; }+};+#endif  // GRPC_USE_TRACERS - private:-  void set_enabled(bool enabled) {}+#if GRPC_USE_TRACERS+#if defined(NDEBUG)+// If we are using tracers, and opt build, use disabled DebugTracers.+class DebugOnlyTraceFlag : public TraceFlag {","My only worry here is that switching to use inheritance might prevent some compiler optimization.Specifically, in the tracers-enabled, opt-mode case, I want to be sure that a compiler will optimize out```if (some_debug_tracer.enabled()) {  ...}```Before, when we had `bool enabled() { return false; }` I was confidant this would happen. If we switch to inheritance I am not totally sure a compiler would be smart enough.",
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/16183,206623112,2018-07-31T17:49:43Z,test/cpp/interop/client_helper.cc,"@@ -88,11 +88,13 @@ std::shared_ptr<Channel> CreateChannelForTestCase(    std::shared_ptr<CallCredentials> creds;   if (test_case == ""compute_engine_creds"") {-    GPR_ASSERT(FLAGS_use_tls);+    GPR_ASSERT(FLAGS_use_tls ||+               FLAGS_custom_credentials_type == ""google_default_credentials"");     creds = GoogleComputeEngineCredentials();     GPR_ASSERT(creds);   } else if (test_case == ""jwt_token_creds"") {-    GPR_ASSERT(FLAGS_use_tls);+    GPR_ASSERT(FLAGS_use_tls ||",How about we do not set the environment variable if google default creds are used regardless of test cases? Since google default creds will fetch a token from metadata server if 1) env variable is not set and 2) token is not available in a pre-defined path.,OK
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/16167,206747773,2018-08-01T03:43:59Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -571,15 +571,27 @@ static void start_transport_op_locked(void* arg, grpc_error* error_ignored) {    if (op->send_ping.on_initiate != nullptr || op->send_ping.on_ack != nullptr) {     if (chand->lb_policy == nullptr) {-      GRPC_CLOSURE_SCHED(-          op->send_ping.on_initiate,-          GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Ping with no load balancing""));-      GRPC_CLOSURE_SCHED(-          op->send_ping.on_ack,-          GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Ping with no load balancing""));+      grpc_error* error =+          GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Ping with no load balancing"");+      GRPC_CLOSURE_SCHED(op->send_ping.on_initiate, GRPC_ERROR_REF(error));+      GRPC_CLOSURE_SCHED(op->send_ping.on_ack, error);     } else {-      chand->lb_policy->PingOneLocked(op->send_ping.on_initiate,-                                      op->send_ping.on_ack);+      grpc_error* error = GRPC_ERROR_NONE;+      grpc_core::LoadBalancingPolicy::PickState pick_state;+      memset(&pick_state, 0, sizeof(pick_state));","Hhhmmm, this is dangerous behavior, to memset a class that has constructors in it.",
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/15941,206972533,2018-08-01T17:48:26Z,src/core/lib/iomgr/tcp_posix.cc,"@@ -96,17 +99,30 @@ struct grpc_tcp {    grpc_closure read_done_closure;   grpc_closure write_done_closure;+  grpc_closure error_closure;    char* peer_string;    grpc_resource_user* resource_user;   grpc_resource_user_slice_allocator slice_allocator;++  grpc_core::TracedBuffer* head; /* List of traced buffers */+  gpr_mu traced_buffer_lock;     /* Lock for access to list of traced buffers */+  void* outgoing_buffer_arg; /* buffer arg provided on grpc_endpoint_write */+  int bytes_counter;         /* Current TCP relative sequence number. Used for+                                timestamping traced buffers. */+  bool socket_ts_enabled; /* True if timestamping options are set on the socket+                           */+  gpr_atm+      stop_error_notification; /* Set to 1 if we do not want to be notified on","This field is essentially a boolean stored as an atomic. So I suggest renaming this variable too (to something like `is_error_notification_enabled` or something else) . Generally I follow the following rule when naming booleans:Any boolean that stores the current state should be  prefixed with ""is""/""are"" (the only exception to this are boolean args to a function - since they almost always request an action to be performed instead of storing a state)",OK
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/15941,206976230,2018-08-01T17:59:47Z,src/core/lib/iomgr/internal_errqueue.h,"@@ -0,0 +1,82 @@+/*",Redefining macros feels like an anti-pattern .. Are you sure we couldn't avoid this ?What if we define `GRPC_LINUX_ERRQUEUE` only if kernel version is >= 4.0.0 ?Would it then eliminate the need for this file ?,
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/15941,207056327,2018-08-01T22:51:33Z,src/core/lib/iomgr/tcp_posix.cc,"@@ -96,17 +99,30 @@ struct grpc_tcp {    grpc_closure read_done_closure;   grpc_closure write_done_closure;+  grpc_closure error_closure;    char* peer_string;    grpc_resource_user* resource_user;   grpc_resource_user_slice_allocator slice_allocator;++  grpc_core::TracedBuffer* head; /* List of traced buffers */+  gpr_mu traced_buffer_lock;     /* Lock for access to list of traced buffers */",nit: Consider renaming to `traced_buffer_mu` to be consistent with how we name mutex variables in core,OK
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/15941,207056421,2018-08-01T22:52:10Z,src/core/lib/iomgr/tcp_posix.cc,"@@ -96,17 +99,30 @@ struct grpc_tcp {    grpc_closure read_done_closure;   grpc_closure write_done_closure;+  grpc_closure error_closure;    char* peer_string;    grpc_resource_user* resource_user;   grpc_resource_user_slice_allocator slice_allocator;++  grpc_core::TracedBuffer* head; /* List of traced buffers */+  gpr_mu traced_buffer_lock;     /* Lock for access to list of traced buffers */+  void* outgoing_buffer_arg; /* buffer arg provided on grpc_endpoint_write */",This would be a good place add the detailed description about `outgoing_buffer_arg`  (similar to what you wrote in this PR's description),
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16224,207240327,2018-08-02T14:10:28Z,examples/csharp/HelloworldXamarin/README.md,"@@ -6,23 +6,26 @@ EXPERIMENTAL ONLY Support of the Xamarin platform is currently experimental. The example depends on experimental Grpc.Core nuget package that hasn't been officially released and is only available via the [daily builds](https://packages.grpc.io/)-source.+source. +NOTE: To downlaod the package please manually [download](https://packages.grpc.io/archive/2018/07/a3b54ef90841ec45fe5e28f54245b7944d0904f9-d24c85c7-32ed-4924-b9af-80e7a4aeb34d/index.xml) the .nupkg file into a local directory. Then add a nuget source that points to that directory (That can be done in [Visual Studio](https://docs.microsoft.com/en-us/nuget/tools/package-manager-ui#package-sources) or Visual Studio for Mac via ""Configure nuget sources""). After that, nuget will also explore that directory when looking for packages.++  BACKGROUND --------------The example project supports Xamarin.Android and Xamarin.iOS+The example project supports `Xamarin.Android` and `Xamarin.iOS`.  For this sample, we've already generated the server and client stubs from [helloworld.proto][].  PREREQUISITES ------------- -- The latest version Xamarin Studio or Visual Studio 2017 with Xamarin support installed.+- The latest version Visual Studio for Mac or Visual Studio 2017 with Xamarin support installed.","Ah, ok, Xamarin Studio is no longer a thing: https://en.wikipedia.org/wiki/Xamarin says ""On Windows Xamarin Studio is now deprecated and was replaced with Xamarin for Visual Studio. On macOS Xamarin Studio is still in development, but was rebranded 2016 as Visual Studio for Mac.""",OK
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/16170,207348934,2018-08-02T19:39:47Z,test/core/iomgr/timer_list_test.cc,"@@ -151,17 +151,95 @@ void destruction_test(void) {   GPR_ASSERT(1 == cb_called[2][0]); } -int main(int argc, char** argv) {-  grpc_test_init(argc, argv);-  grpc_core::ExecCtx::GlobalInit();+/* Clean up a list with pending timers that simulate long-running-services. */+/* https://github.com/grpc/grpc/issues/15904 */+void long_running_service_cleanup_test(void) {+  grpc_timer timers[4];   grpc_core::ExecCtx exec_ctx;-  grpc_determine_iomgr_platform();-  grpc_iomgr_platform_init();-  gpr_set_log_verbosity(GPR_LOG_SEVERITY_DEBUG);-  add_test();-  destruction_test();-  grpc_iomgr_platform_shutdown();++  gpr_log(GPR_INFO, ""long_running_service_cleanup_test"");++  grpc_millis now = grpc_core::ExecCtx::Get()->Now();+  GPR_ASSERT(now >= 2160000000); /* 25 days in milliseconds */+  grpc_timer_list_init();+  grpc_core::testing::grpc_tracer_enable_flag(&grpc_timer_trace);+  grpc_core::testing::grpc_tracer_enable_flag(&grpc_timer_check_trace);+  memset(cb_called, 0, sizeof(cb_called));++  grpc_timer_init(","It would be good to explain in a couple of lines what your test is trying to do..something like ```1) Simulate grpc server start time to 25 days in the past2) Create 3 timers - one with a deadline 25 days in future, one just 3 milliseconds in future, one way out in the future3) Simulate 4 milliseconds of elapsed time by changing `now` (cached at step 1) to `now+4`...```",
10722952,jzeferino,https://api.github.com/repos/grpc/grpc/pulls/16224,207365147,2018-08-02T20:36:24Z,examples/csharp/HelloworldXamarin/README.md,"@@ -6,23 +6,26 @@ EXPERIMENTAL ONLY Support of the Xamarin platform is currently experimental. The example depends on experimental Grpc.Core nuget package that hasn't been officially released and is only available via the [daily builds](https://packages.grpc.io/)-source.+source. +NOTE: To downlaod the package please manually [download](https://packages.grpc.io/archive/2018/07/a3b54ef90841ec45fe5e28f54245b7944d0904f9-d24c85c7-32ed-4924-b9af-80e7a4aeb34d/index.xml) the .nupkg file into a local directory. Then add a nuget source that points to that directory (That can be done in [Visual Studio](https://docs.microsoft.com/en-us/nuget/tools/package-manager-ui#package-sources) or Visual Studio for Mac via ""Configure nuget sources""). After that, nuget will also explore that directory when looking for packages.",since is temporary I would mind to have it there. When the package will be release I can update this.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16232,207583374,2018-08-03T15:31:25Z,src/core/ext/filters/client_channel/subchannel_index.cc,"@@ -49,6 +49,8 @@ static grpc_subchannel_key* create_key(     grpc_channel_args* (*copy_channel_args)(const grpc_channel_args* args)) {   grpc_subchannel_key* k =       static_cast<grpc_subchannel_key*>(gpr_malloc(sizeof(*k)));+  // Currently, args->filter_count is always 0, which means we only use the","Good catch!  This looks like a bug to me -- it would actually be bad if we considered two subchannels with different filter lists to be the same.We've probably gotten away with this because in general, it's the set of channel args that determines the set of filters.  However, I think there are some cases (especially internally) where a filter registration function will decide whether or not to add a filter based on something other than channel args.  But you can verify this by looking at all existing filter registration functions (i.e., functions passed to `grpc_channel_init_register_stage()` to register filters, or C++ filters using `grpc::RegisterChannelFilter()`).To fix this, I think we should do one of two things:1. Fix the code somehow to actually populate `args->filter_count` and `args->filters` before creating the subchannel key, so that we ensure that we don't treat subchannels with different filters as the same.2. Decide that we want to require that subchannels with different filter lists will always have different channel args.  In this case, we should document this restriction for registration functions.  (Note that even if a registration function uses some external mechanism to actually make the decision, it could then *set* a different channel arg to reflect its decision, so the channel args would always be different if the set of filters are different.)  We should also remove the `filters` and `filter_count` fields from `grpc_subchannel_args`.  (Actually, at that point, the only field left in `grpc_subchannel_args` would be the channel args, so we could just replace `grpc_subchannel_args` with `grpc_channel_args`.)",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/16232,207687336,2018-08-03T23:14:38Z,src/core/ext/filters/client_channel/subchannel_index.cc,"@@ -49,6 +49,8 @@ static grpc_subchannel_key* create_key(     grpc_channel_args* (*copy_channel_args)(const grpc_channel_args* args)) {   grpc_subchannel_key* k =       static_cast<grpc_subchannel_key*>(gpr_malloc(sizeof(*k)));+  // Currently, args->filter_count is always 0, which means we only use the","This is hard to achieve, because the subchannel stack is created after it's connected.When we *create* a subchannel, we use the channel args (basically the same one as the `chand->resolver_result`) to create the subchannel key. And we don't know any thing about the filters yet.When the subchannel is *connected*, we will create the channel stack in https://github.com/grpc/grpc/blob/6a2fbcb4d27243e8c32227b681c38c6221e09a00/src/core/ext/filters/client_channel/subchannel.cc#L586. The channel stack builder will create the filters based on `c->connecting_result.channel_args` and `c->connecting_result.transport`. So, when we create the subchannel key, we don't know what filters a subchannel will have.Also, that why I feel it's hard to pre-compute the size of the subchannel stack and add it into the call size estimate.",
1058384,Capstan,https://api.github.com/repos/grpc/grpc/pulls/16204,207952223,2018-08-06T16:25:30Z,test/cpp/util/cli_credentials.cc,"@@ -29,47 +31,107 @@ DEFINE_string(     ssl_target, """",     ""If not empty, treat the server host name as this for ssl/tls certificate ""     ""validation."");+DEFINE_string(channel_creds_type, """",+              ""The channel creds type: insecure, ssl, or alts."");  namespace grpc { namespace testing { -std::shared_ptr<grpc::ChannelCredentials> CliCredentials::GetCredentials()+grpc::string CliCredentials::GetDefaultChannelCredsType() const {+  // Compatibility logic for --enable_ssl.+  if (FLAGS_enable_ssl) {+    fprintf(stderr,+            ""warning: --enable_ssl is deprecated. Use ""+            ""--channel_creds_type=ssl.\n"");+    return ""ssl"";+  }+  // Implicit channel for GoogleDefaultCredentials is SSL.+  if (FLAGS_access_token.empty() && FLAGS_use_auth) {+    return ""ssl"";+  }+  return ""insecure"";+}++std::shared_ptr<grpc::ChannelCredentials>+CliCredentials::GetChannelCredentials() const {+  if (FLAGS_channel_creds_type.compare(""insecure"") == 0) {+    return grpc::InsecureChannelCredentials();+  } else if (FLAGS_channel_creds_type.compare(""ssl"") == 0) {+    return grpc::SslCredentials(grpc::SslCredentialsOptions());+  } else if (FLAGS_channel_creds_type.compare(""alts"") == 0) {+    return grpc::experimental::AltsCredentials(+        grpc::experimental::AltsCredentialsOptions());+  }+  fprintf(stderr,+          ""--channel_creds_type=%s invalid; must be insecure, ssl or alts.\n"",+          FLAGS_channel_creds_type.c_str());+  return std::shared_ptr<grpc::ChannelCredentials>();+}++std::shared_ptr<grpc::CallCredentials> CliCredentials::GetCallCredentials()     const {   if (!FLAGS_access_token.empty()) {     if (FLAGS_use_auth) {       fprintf(stderr,               ""warning: use_auth is ignored when access_token is provided."");     }--    return grpc::CompositeChannelCredentials(-        grpc::SslCredentials(grpc::SslCredentialsOptions()),-        grpc::AccessTokenCredentials(FLAGS_access_token));+    return grpc::AccessTokenCredentials(FLAGS_access_token);   }+  // TODO(@capstan): Support GoogleDefaultCredentials on other channel types.","Given that GDC are essentially SSL + local auth credentials as pulled from the local environment (ENV variable + local file with JWT, AppEngine Metadata API, GCE Metadata API), there's no reason that said credentials could be used on a different channel type. That said, GDC's creds accessor is only a ChannelCreds, and thus cannot be used with ALTS or LOAS, as you can only pick one ChannelCreds and composite CallCreds on top of it.If the answer is that GDC is supposed to *be* the equivalent of transport credentials for transports that don't have them, then perhaps this TODO is not meant to be achievable. If so, I should update this and downstream PRs to move `google_default_credentials` to be a `channel_creds_type`.",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/16241,208283223,2018-08-07T15:43:26Z,src/core/ext/filters/http/client/http_client_filter.cc,"@@ -364,43 +356,28 @@ static void hc_start_transport_stream_op_batch(       method = GRPC_MDELEM_METHOD_PUT;     } -    remove_if_present(-        batch->payload->send_initial_metadata.send_initial_metadata,-        GRPC_BATCH_METHOD);-    remove_if_present(-        batch->payload->send_initial_metadata.send_initial_metadata,-        GRPC_BATCH_SCHEME);-    remove_if_present(-        batch->payload->send_initial_metadata.send_initial_metadata,-        GRPC_BATCH_TE);-    remove_if_present(-        batch->payload->send_initial_metadata.send_initial_metadata,-        GRPC_BATCH_CONTENT_TYPE);-    remove_if_present(-        batch->payload->send_initial_metadata.send_initial_metadata,-        GRPC_BATCH_USER_AGENT);-     /* Send : prefixed headers, which have to be before any application        layer headers. */     error = grpc_metadata_batch_add_head(         batch->payload->send_initial_metadata.send_initial_metadata,-        &calld->method, method);+        &calld->method_storage, method);     if (error != GRPC_ERROR_NONE) goto done;     error = grpc_metadata_batch_add_head(         batch->payload->send_initial_metadata.send_initial_metadata,-        &calld->scheme, channeld->static_scheme);+        &channeld->scheme_storage, channeld->static_scheme);","I'm a little confused on what you're trying to do here. You're moving the metadata storage to the channel data, but setting it to the metadata elem in hc_start_transport_stream_op_batch, which is called per call.",
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/16204,208385396,2018-08-07T21:06:25Z,test/cpp/util/cli_credentials.cc,"@@ -23,16 +23,20 @@ DEFINE_bool(     enable_ssl, false,     ""Whether to use ssl/tls. Deprecated. Use --channel_creds_type=ssl."");-DEFINE_bool(use_auth, false, ""Whether to create default google credentials."");+DEFINE_bool(use_auth, false,+            ""Whether to create default google credentials. Deprecated. Use ""+            ""--channel_creds_type=google_default_credentials.""); DEFINE_string(     access_token, """",     ""The access token that will be sent to the server to authenticate RPCs.""); DEFINE_string(     ssl_target, """",     ""If not empty, treat the server host name as this for ssl/tls certificate ""     ""validation."");-DEFINE_string(channel_creds_type, """",-              ""The channel creds type: insecure, ssl, or alts."");+DEFINE_string(+    channel_creds_type, """",+    ""The channel creds type: insecure, ssl, google_default_credentials or """,nit: google_default_credentials is a bit long for a flag value :),OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16283,208595270,2018-08-08T14:09:36Z,doc/ssl-performance.md,"@@ -0,0 +1,30 @@+# SSL in gRPC and performance++The SSL requirement of gRPC isn't necessarily making it easy to integrate. The HTTP/2 protocol requires ALPN support, which is a fairly new handshake protocol only supported by recent implementations.++As a result, we've tried hard to provide a smooth experience to our users when compiling and distributing gRPC, but this may come at performance costs due to this. More specifically, we will sometime build the SSL library by disabling assembly code, which can impact performances by an order of magnitude when processing encrypted streams.",... by disabling assembly code (by setting `OPENSSL_NO_ASM`)... referencing the option name could make it easier for curious minds to find where/how we are enabling/disabling assembly optimizations`https://github.com/grpc/grpc/blob/e916e79cb88b007559e079a8cac2250105a76954/cmake/ssl.cmake#L20,OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16283,208597157,2018-08-08T14:14:33Z,doc/ssl-performance.md,"@@ -0,0 +1,30 @@+# SSL in gRPC and performance++The SSL requirement of gRPC isn't necessarily making it easy to integrate. The HTTP/2 protocol requires ALPN support, which is a fairly new handshake protocol only supported by recent implementations.++As a result, we've tried hard to provide a smooth experience to our users when compiling and distributing gRPC, but this may come at performance costs due to this. More specifically, we will sometime build the SSL library by disabling assembly code, which can impact performances by an order of magnitude when processing encrypted streams.++Build system | Condition | Platform | Assembly code+---|---|---|--+Makefile | with OpenSSL 1.0.2 development files | all | :heavy_check_mark:+Makefile | all other cases | all | :x:+Bazel | | Linux | :heavy_check_mark:+Bazel | | MacOS | :heavy_check_mark:+Bazel | | Windows | :x:+CMake | | Windows | :x:+CMake | | all others | :heavy_check_mark:","actually, CMake's story is a bit more complicated.- When building from submodule (the default), we set OPENSSL_NO_ASM for all platforms, not just for Windows:https://github.com/grpc/grpc/blob/e916e79cb88b007559e079a8cac2250105a76954/cmake/ssl.cmake#L20 . This is not necessary on Linux and Mac, but it's necessary on Windows if one wants to be able to build from generated visual studio projects. If one uses ninja on Win instead of VS, building with assembly optimizations is possible.- If we not building from submodule, use the system-installed openssl (which is assumed to have assembly optimizations enabled).",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16314,209315372,2018-08-10T16:27:09Z,tools/internal_ci/helper_scripts/prepare_build_macos_interop_rc,"@@ -17,17 +17,6 @@ # builds. This rc script must be used in the root directory of gRPC # and is expected to be used before prepare_build_macos_rc -export CONFIG=opt--# Move gRPC repo to directory that Docker for Mac has drive access to-mkdir /Users/kbuilder/workspace","this was causing the ""out of disk space"" error:   kokoro workers have one small system volume and one large volume mounted to /tmpfs where the build normally happens. Building under /Users/kbuilder we end up having only 2.8G of free space (and the gRPC C++ build is large)",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16183,209328628,2018-08-10T17:18:08Z,tools/run_tests/run_interop_tests.py,"@@ -1285,23 +1300,40 @@ def aggregate_http2_results(stdout):      jobs = []     if args.cloud_to_prod:-        if args.transport_security != 'tls':-            print('TLS is always enabled for cloud_to_prod scenarios.')+        if args.transport_security not in ['tls', 'google_default_credentials']:+            print(+                'TLS or google default credential is always enabled for cloud_to_prod scenarios.'+            )         for server_host_nickname in args.prod_servers:             for language in languages:                 for test_case in _TEST_CASES:                     if not test_case in language.unimplemented_test_cases():                         if not test_case in _SKIP_ADVANCED + _SKIP_COMPRESSION:-                            test_job = cloud_to_prod_jobspec(+                            tls_test_job = cloud_to_prod_jobspec(                                 language,                                 test_case,                                 server_host_nickname,                                 prod_servers[server_host_nickname],                                 docker_image=docker_images.get(str(language)),                                 manual_cmd_log=client_manual_cmd_log,                                 service_account_key_file=args.-                                service_account_key_file)-                            jobs.append(test_job)+                                service_account_key_file,","I think this works. But it now becomes a little odd that we can no longer run the script with <i>only</i> TLS, or <i>only</i> google default creds, they need to now always be ran together.@yihuazhang @adelez I'm thinking it might end up simpler to modify `grpc_run_interop_tests.sh` to invoke `run_interop_tests.py` twice, with different credentials.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16308,209338665,2018-08-10T17:54:32Z,src/csharp/Grpc.Core/Internal/PlatformApis.cs,"@@ -63,7 +64,25 @@ static PlatformApis()             isNetCore = false; #endif             isMono = Type.GetType(""Mono.Runtime"") != null;-            isUnity = Type.GetType(UnityEngineApplicationClassName) != null;++            // Unity+            var unityApplicationClass = Type.GetType(UnityEngineApplicationClassName);+            if (unityApplicationClass != null)+            {+                isUnity = true;+                // Consult value of Application.platform via reflection+                // https://docs.unity3d.com/ScriptReference/Application-platform.html+                var platformProperty = unityApplicationClass.GetTypeInfo().GetProperty(""platform"");+                var unityRuntimePlatform = platformProperty?.GetValue(null)?.ToString();+                isUnityIOS = (unityRuntimePlatform == ""IPhonePlayer"");+            }+            else+            {+                isUnity = false;+                isUnityIOS = false;+            }++            // Xamarin             isXamarinIOS = Type.GetType(XamarinIOSObjectClassName) != null;","it seems very unlikely someone would use that class name and assembly name. Also, see comment above.",
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/16264,209341452,2018-08-10T18:04:31Z,src/core/lib/iomgr/ev_epoll1_linux.cc,"@@ -141,6 +141,10 @@ struct grpc_fd {   struct grpc_fd* freelist_next;    grpc_iomgr_object iomgr_object;++  /* Only used when GRPC_ENABLE_FORK_SUPPORT=1 */+  struct grpc_fd* fork_fd_list_next;","I reduced this from two pointers to one (`grpc_fork_fd_list*`) in the non-fork case. `grpc_fork_fd_list` wraps the `grpc_fd* next` and `grpc_fd *prev` pointers, and these will only be allocated when fork support is enabled.Generally, the conclusion on the implementation in https://github.com/grpc/grpc/pull/16025 (which added an `int` to all grpc_endpoints) was that the maximum number of fds is capped, so a small constant amount of additional memory per fd is acceptable, and preferable to the complexity of adding any compile-time flags to try to save what is now 1 pointer (8 bytes) * max fds (~60k?).We could instead store a map from fd name (the string used as an index by the iomgr) to the fd itself, and avoid any additional allocations in the non-fork case, but this adds extra complexity that I don't think is warranted, at least not yet.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16308,209341769,2018-08-10T18:05:44Z,src/csharp/Grpc.Core/GrpcEnvironment.cs,"@@ -360,12 +361,26 @@ internal static string GetCoreVersionString()          internal static void GrpcNativeInit()         {+            if (!IsNativeShutdownAllowed && alreadyInvokedNativeInit)+            {+                // Normally grpc_init and grpc_shutdown calls should come in pairs (C core does reference counting),+                // but in case we avoid grpc_shutdown calls altogether, calling grpc_init has no effect+                // besides incrementing an internal C core counter that could theoretically overflow.+                // NOTE: synchronization not necessary here as we are only trying to avoid calling grpc_init","The idea is that it's not guaranteed that if we set alreadyInvokedNativeInit, other thread will immediately see that, but they will see it ""very soon"" and we don't mind invoking grpc_init once or twice in the meantime. In the worst case, each thread will run grpc_init once and that's still far from risking the owerflow.The idea is the same as Joshua Bloch's  ""Racy-Single-Check"" idiom - http://javaagile.blogspot.com/2013/05/the-racy-single-check-idiom.htmlwhich is used e.g. in Java String to initialize the hashCode field.But you're right that this technique is a bit of an overkill for this situation. I'll double check that GrpcNativeInit only happens when a GrpcEnvironment gets initialized and probably use a lock.",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16308,209343602,2018-08-10T18:12:17Z,src/csharp/Grpc.Core/GrpcEnvironment.cs,"@@ -360,12 +361,26 @@ internal static string GetCoreVersionString()          internal static void GrpcNativeInit()         {+            if (!IsNativeShutdownAllowed && alreadyInvokedNativeInit)+            {+                // Normally grpc_init and grpc_shutdown calls should come in pairs (C core does reference counting),+                // but in case we avoid grpc_shutdown calls altogether, calling grpc_init has no effect+                // besides incrementing an internal C core counter that could theoretically overflow.+                // NOTE: synchronization not necessary here as we are only trying to avoid calling grpc_init","I'd tend to err on the side of caution around this. And I really have no idea if this is an issue in C#, but see [benign data races blog post](https://software.intel.com/en-us/blogs/2013/01/06/benign-data-races-what-could-possibly-go-wrong)",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/13207,209633213,2018-08-13T14:36:42Z,src/csharp/Grpc.Tools/Grpc.Tools.csproj,"@@ -0,0 +1,102 @@+<Project Sdk=""Microsoft.NET.Sdk"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"">++  <Import Project=""..\Grpc.Core\Version.csproj.include"" />++  <PropertyGroup>+    <AssemblyName>Protobuf.MSBuild</AssemblyName>+    <Version>$(GrpcCsharpVersion)</Version>+    <!-- If changing targets, change also paths in Google.Protobuf.Tools.targets. -->+    <TargetFrameworks>net45;netstandard1.3</TargetFrameworks>+  </PropertyGroup>++  <!-- This is copied verbatim from Grpc.Core/Common.csproj.include. Other settings+       in that file conflict with the intent of this build, as it cannot be signed,+       and may not compile Grpc.Core/Version.cs, as that file references constants+       in Grpc.Core.dll.+       TODO(kkm): Refactor imports. -->+  <PropertyGroup Condition=""'$(OS)' != 'Windows_NT'"">+    <!-- Workaround for https://github.com/dotnet/sdk/issues/335 -->+    <FrameworkPathOverride Condition=""Exists('/usr/lib/mono/4.5-api')"">/usr/lib/mono/4.5-api</FrameworkPathOverride>+    <FrameworkPathOverride Condition=""Exists('/usr/local/lib/mono/4.5-api')"">/usr/local/lib/mono/4.5-api</FrameworkPathOverride>+    <FrameworkPathOverride Condition=""Exists('/Library/Frameworks/Mono.framework/Versions/Current/lib/mono/4.5-api')"">/Library/Frameworks/Mono.framework/Versions/Current/lib/mono/4.5-api</FrameworkPathOverride>+  </PropertyGroup>++  <PropertyGroup Label=""Asset root folders. TODO(kkm): Change with package separation."">+    <!-- TODO(kkm): Rework whole section when splitting packages.  -->+    <!-- GRPC: ../../third_party/protobuf/src/google/protobuf/  -->+    <!-- GPB:  ../src/google/protobuf/ -->+    <Assets_ProtoInclude>../../../third_party/protobuf/src/google/protobuf/</Assets_ProtoInclude>++    <!-- GPB:  protoc\ -->+    <!-- GRPC: protoc_plugins\protoc_ -->+    <Assets_ProtoCompiler>../protoc_plugins/protoc_</Assets_ProtoCompiler>++    <!-- GRPC: protoc_plugins\ -->+    <Assets_GrpcPlugins>../protoc_plugins/</Assets_GrpcPlugins>+  </PropertyGroup>++  <PropertyGroup>+    <_NetStandard>False</_NetStandard>+    <_NetStandard Condition="" $(TargetFramework.StartsWith('netstandard')) or $(TargetFramework.StartsWith('netcore')) "">True</_NetStandard>++    <!-- So we do not hardcode an exact version into #if's. -->+    <DefineConstants Condition=""$(_NetStandard)"">$(DefineConstants);NETSTANDARD</DefineConstants>+  </PropertyGroup>++  <PropertyGroup Label=""NuGet package definition"" Condition="" '$(Configuration)' == 'Release' "">+    <!-- TODO(kkm): Change to ""build\"" after splitting. -->+    <BuildOutputTargetFolder>build\_protobuf\</BuildOutputTargetFolder>+    <DevelopmentDependency>true</DevelopmentDependency>+    <NoPackageAnalysis>true</NoPackageAnalysis>+    <PackageId>Grpc.Tools</PackageId>+    <Description>gRPC and Protocol Buffer compiler for managed C# and native C++ projects.++Add this package to a project that contains .proto files to be compiled to code.+It contains the compilers, include files and project system integration for gRPC+and Protocol buffer service description files necessary to build them on Windows,+Linux and MacOS. Managed runtime is supplied separately in the Grpc.Core package.</Description>+    <Copyright>Copyright 2018 gRPC authors</Copyright>+    <Authors>gRPC authors</Authors>+    <PackageLicenseUrl>https://github.com/grpc/grpc/blob/master/LICENSE</PackageLicenseUrl>+    <PackageProjectUrl>https://github.com/grpc/grpc</PackageProjectUrl>+    <PackageTags>gRPC RPC protocol HTTP/2</PackageTags>+  </PropertyGroup>++  <ItemGroup Label=""NuGet package assets"">+    <None Pack=""true"" PackagePath=""build\"" Include=""build\**\*.xml; build\**\*.props; build\**\*.targets;"" />++    <!-- Protobuf assets (for Google.Protobuf.Tools) -->+    <_ProtoAssetName Include=""any;api;descriptor;duration;empty;field_mask;+                              source_context;struct;timestamp;type;wrappers"" />+    <_Asset PackagePath=""build/native/include/google/protobuf/"" Include=""@(_ProtoAssetName->'$(Assets_ProtoInclude)%(Identity).proto')"" />++    <!-- TODO(kkm): GPB builds assets into ""macosx"", GRPC into ""macos"". -->+    <_Asset PackagePath=""build/native/bin/windows/protoc.exe"" Include=""$(Assets_ProtoCompiler)windows_x86/protoc.exe"" />+    <_Asset PackagePath=""build/native/bin/linux_x86/protoc"" Include=""$(Assets_ProtoCompiler)linux_x86/protoc"" />+    <_Asset PackagePath=""build/native/bin/linux_x64/protoc"" Include=""$(Assets_ProtoCompiler)linux_x64/protoc"" />+    <_Asset PackagePath=""build/native/bin/macosx_x86/protoc"" Include=""$(Assets_ProtoCompiler)macos_x86/protoc"" /> <!-- GPB: macosx-->+    <_Asset PackagePath=""build/native/bin/macosx_x64/protoc"" Include=""$(Assets_ProtoCompiler)macos_x64/protoc"" /> <!-- GPB: macosx-->++    <!-- gRPC assets (for Grpc.Tools) -->+    <_Asset PackagePath=""build/native/bin/windows/grpc_csharp_plugin.exe"" Include=""$(Assets_GrpcPlugins)protoc_windows_x86/grpc_csharp_plugin.exe"" />","is it necessary to change PackagePath in the nuget?The old Grpc.Tools puts the protoc binaries and paths in a different path, and people have written ""generate"" scripts that assume what those paths are. I know we discussed the current experience is bad, but we still should require changes from users's code unless  it's absolutely necessary. I see two options:1. can we use the old paths that are used in Grpc.Toolshttps://github.com/grpc/grpc/blob/e495476b1e31023637259883aa735fcc716c6adc/src/csharp/Grpc.Tools.nuspec#L202. otherwise, we'd probably need to offer this new msbuild intergration in a new nuget package with a different name (at least until it's proven user are happy with this new functionality and that it works for most people).",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/16340,209672076,2018-08-13T16:19:51Z,summerofcode/2018/naresh.md,"@@ -0,0 +1,78 @@+# Project overview++## Title++Enable building of gRPC Python with Bazel++## Overview++gRPC Python currently has a constellation of scripts written to build the project, but it has a lot of limitations in terms of speed and maintainability. Bazel is the open-sourced variant of Google's internal system, Blaze, which is an ideal replacement for building such projects in a fast and declarative fashion. But Bazel in itself is still in active development, especially in terms of Python (amongst a few others).++The project aimed to fill this gap and build gRPC Python with Bazel.++[Project page](https://summerofcode.withgoogle.com/projects/#6482576244473856)++[Link to proposal](https://storage.googleapis.com/summerofcode-prod.appspot.com/gsoc/core_project/doc/5316764725411840_1522049732_Naresh_Ramesh_-_GSoC_proposal.pdf)++## Thoughts and challenges++### State of Bazel for Python++Although previously speculated, the project didn't require any contributions directly to [bazelbuild/bazel](https://github.com/bazelbuild/bazel). The Bazel rules for Python are currently separated out into it's own repo at [bazelbuild/rules_python](https://github.com/bazelbuild/rules_python/).++Bazel is still very much in active development for Python though. There's still challenges when it comes to building for Python 2 vs 3. Using pip packages is still in experimental. Bazel Python support is currently distributed across two repositories and is yet to begin migration to one place (which will be [bazelbuild/rules_python](https://github.com/bazelbuild/rules_python/)).++Bazel's roadmap for Python is publicly available [here as a Google doc](https://docs.google.com/document/d/1A6J3j3y1SQ0HliS86_mZBnB5UeBe7vExWL2Ryd_EONI/edit).++### Cross collaboration between projects++Cross contribution surprisingly came up because of building protobuf sources for Python, which is still not natively supported by Bazel. An existing repository, [pubref/rules_protobuf](https://github.com/pubref/rules_protobuf), which was maintained by an independent maintainer (i.e. not a part of Bazel) helped solve this problem, but had [one major blocking issue](https://github.com/pubref/rules_protobuf/issues/233) and could not be resolved at the source. But [a solution to the issue](https://github.com/pubref/rules_protobuf/pull/196) was proposed by user dududko, which was not merged because of failing golang tests but worked well for Python. Hence, a fork of this repo was made and is to be used with gRPC until the solution can be merged back at the source.++### Building Cython code++Building Cython code is still not supported by Bazel, but the team at [cython/cython](https://github.com/cython/cython) have added support for Bazel on their side. The way it works is by including Cython as a third-party Bazel dependency and using custom Bazel rules for building our Cython code using the binary within the dependency.++## How to use++All the Bazel tests for gRPC Python can be run using a single command:++```bash+bazel test --spawn_strategy=standalone --genrule_strategy=standalone //src/python/...+```++If any specific test is to be run, like say `LoggingPoolTest` (which is present in `src/python/grpcio_tests/tests/unit/framework/foundation/_logging_pool_test.py`), the command to run would be:","`_logging_pool_test` might be a bad example because it is a test module that only contains one test class.... now that I look, nearly all of our test modules seem to contain just one test class.Can you give an example of running just a single method? Something like `bazel test --spawn_strategy=standalone --genrule_strategy=standalone //src/python/grpcio_tests/tests/unit/_rpc_test --test_arg=RPCTest.testUnrecognizedMethod`? Does that work? (Don't spend too much time investigating now...)",OK
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/16298,209828878,2018-08-14T04:57:30Z,src/core/lib/iomgr/ev_posix.cc,"@@ -101,10 +101,15 @@ const grpc_event_engine_vtable* init_non_polling(bool explicit_request) { } }  // namespace -static const event_engine_factory g_factories[] = {+#define ENGINE_HEAD_CUSTOM ""head_custom""+#define ENGINE_TAIL_CUSTOM ""tail_custom""++static event_engine_factory g_factories[] = {+    {ENGINE_HEAD_CUSTOM, nullptr},          {ENGINE_HEAD_CUSTOM, nullptr},","This is not looking very clean to me.  How about we have a separate factory list `g_custom_factories` of a fixed size containing `(polling engine name, factory, priority)` triplet (where `priority` is an enum that is `HEAD` or `TAIL`)(or have two custom factory lists `g_custom_factories[2]` one for head and one for tail)",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16298,209836985,2018-08-14T06:07:07Z,src/core/lib/iomgr/ev_posix.cc,"@@ -101,10 +101,15 @@ const grpc_event_engine_vtable* init_non_polling(bool explicit_request) { } }  // namespace -static const event_engine_factory g_factories[] = {+#define ENGINE_HEAD_CUSTOM ""head_custom""+#define ENGINE_TAIL_CUSTOM ""tail_custom""++static event_engine_factory g_factories[] = {+    {ENGINE_HEAD_CUSTOM, nullptr},          {ENGINE_HEAD_CUSTOM, nullptr},","I would like to slightly push back against this comment for the reason that this would clean up the list of `g_factories` but would complicate the `register` and `try_engine` functions since those would now need to have 3 separate loops, or a doubly-nested loop with the outer loop pointing to the head of each separate list, neither of which is straightforward. That said, I can understand that it is not clean as it currently stands. Do you think that this could be addressed by adding a more detailed comment here? I can do that gladly.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16302,209849577,2018-08-14T07:16:49Z,src/core/lib/surface/completion_queue.h,"@@ -47,6 +47,16 @@ typedef struct grpc_cq_completion {   uintptr_t next; } grpc_cq_completion; +/// For callback CQs, the following is what is actually intended by+/// the tag.+namespace grpc_core {+class CQCallbackInterface {","I didn't want to call it CallbackInterface since we have internal callbacks as well, and CompletionQueueCallbackInterface is really long, so I thought CQCallbackInterface. I think it should be CQ rather than Cq since CQ is for CompletionQueue .",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16302,209854086,2018-08-14T07:37:05Z,src/core/lib/surface/completion_queue.cc,"@@ -448,14 +487,14 @@ grpc_completion_queue* grpc_completion_queue_create_internal(   gpr_ref_init(&cq->owning_refs, 2);    poller_vtable->init(POLLSET_FROM_CQ(cq), &cq->mu);-  vtable->init(DATA_FROM_CQ(cq));+  vtable->init(DATA_FROM_CQ(cq), shutdown_callback);    GRPC_CLOSURE_INIT(&cq->pollset_shutdown_done, on_pollset_shutdown_done, cq,                     grpc_schedule_on_exec_ctx);   return cq; } -static void cq_init_next(void* ptr) {+static void cq_init_next(void* ptr, grpc_core::CQCallbackInterface*) {","I will change this. It's actually not a good idea since it obscures the intent of the (unused) parameter. I need to make sure that it doesn't cause a compiler warning, though.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16356,210331594,2018-08-15T16:45:06Z,src/cpp/thread_manager/thread_manager.cc,"@@ -166,22 +166,37 @@ void ThreadManager::MainWorkLoop() {       case WORK_FOUND:         // If we got work and there are now insufficient pollers and there is         // quota available to create a new thread, start a new poller thread-        if (!shutdown_ && num_pollers_ < min_pollers_ &&-            grpc_resource_user_allocate_threads(resource_user_, 1)) {-          num_pollers_++;-          num_threads_++;-          if (num_threads_ > max_active_threads_sofar_) {-            max_active_threads_sofar_ = num_threads_;+        bool got_thread;","I thought about that, but leaving it uninitialized at first makes sure that we're covering all our cases properly (since the compiler would complain otherwise about use without initialization). I didn't want to accidentally leave it in a bad state. But I can also see that it's probably more idiomatic to do what you said. That said, I will instead reverse the condition (to be `resource_exhausted` and start it as false).",
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/16356,210365824,2018-08-15T18:34:22Z,src/cpp/thread_manager/thread_manager.h,"@@ -72,7 +72,7 @@ class ThreadManager {   // The implementation of DoWork() should also do any setup needed to ensure   // that the next call to PollForWork() (not necessarily by the current thread)   // actually finds some work-  virtual void DoWork(void* tag, bool ok) = 0;+  virtual void DoWork(void* tag, bool ok, bool resources) = 0;",Can you update the comment above to talk about `resources` parameter too ?,OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16367,210633267,2018-08-16T15:06:40Z,src/csharp/Grpc.Core/Marshaller.cs,"@@ -29,36 +29,122 @@ public class Marshaller<T>         readonly Func<T, byte[]> serializer;         readonly Func<byte[], T> deserializer; +        readonly Action<T, SerializationContext> contextualSerializer;+        readonly Func<DeserializationContext, T> contextualDeserializer;+         /// <summary>-        /// Initializes a new marshaller.+        /// Initializes a new marshaller from simple serialize/deserialize functions.         /// </summary>         /// <param name=""serializer"">Function that will be used to serialize messages.</param>         /// <param name=""deserializer"">Function that will be used to deserialize messages.</param>         public Marshaller(Func<T, byte[]> serializer, Func<byte[], T> deserializer)         {-            this.serializer = GrpcPreconditions.CheckNotNull(serializer, ""serializer"");-            this.deserializer = GrpcPreconditions.CheckNotNull(deserializer, ""deserializer"");+            this.serializer = GrpcPreconditions.CheckNotNull(serializer, nameof(serializer));+            this.deserializer = GrpcPreconditions.CheckNotNull(deserializer, nameof(deserializer));+            this.contextualSerializer = EmulateContextualSerializer;+            this.contextualDeserializer = EmulateContextualDeserializer;         }          /// <summary>-        /// Gets the serializer function.+        /// Initializes a new marshaller from serialize/deserialize fuctions that can access serialization and deserialization+        /// context. Compared to the simple serializer/deserializer functions, using the contextual version provides more+        /// flexibility and can lead to increased efficiency (and better performance).+        /// Note: This constructor is part of an experimental API that can change or be removed without any prior notice.         /// </summary>-        public Func<T, byte[]> Serializer+        /// <param name=""serializer"">Function that will be used to serialize messages.</param>+        /// <param name=""deserializer"">Function that will be used to deserialize messages.</param>+        public Marshaller(Action<T, SerializationContext> serializer, Func<DeserializationContext, T> deserializer)",another option here would be not to pass the  serializer/deserializer delegates but instead pass a newly introduced interface / abstract class with the serialize() / deserialize() methods.,OK
35056280,srini100,https://api.github.com/repos/grpc/grpc/pulls/16358,210687550,2018-08-16T17:58:00Z,BUILD,"@@ -2154,4 +2157,11 @@ grpc_cc_library(     ], ) +grpc_cc_library(+    name = ""shadow_boringssl"",+    hdrs = [+        ""src/core/tsi/boringssl_shadow.h"",",Use consistent naming. Rename boringssl_shadow.h to shadow_boringssl.h. boringssl_grpc.h sounds more intuitive.,OK
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/16378,210936061,2018-08-17T14:54:18Z,src/python/grpcio/grpc/_channel.py,"@@ -24,6 +24,7 @@ from grpc._cython import cygrpc from grpc.framework.foundation import callable_util +logging.basicConfig()","It's a little weird to see these calls inside the library modules - I sort of get the sense from the function's documentation that it's of global effect and is only useful once per Python interpreter lifetime. If that's the case, what would you think of putting these calls in the test modules? Something like```pythonif __name__ == '__main__':    logging.basicConfig()    unittest.main(verbosity=2)```?Incidentally, where do other Python codebases put their calls to this function?",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16358,211206309,2018-08-20T10:02:01Z,tools/distrib/generate_grpc_shadow_boringssl.sh,"@@ -0,0 +1,88 @@+#!/bin/bash+# Copyright 2018 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++set -e++cd $(dirname $0)++filename_original=""../../src/core/tsi/grpc_shadow_boringssl.h""+boringssl_podspec_original=""../../src/objective-c/BoringSSL-GRPC.podspec""+if [ ""$TEST"" == """" ]; then+  filename=$filename_original+  boringssl_podspec=$boringssl_podspec_original+else+  filename=""${filename_original}.tmp""+  boringssl_podspec=""${boringssl_podspec_original}.tmp""+fi+symbol_list=""../../src/objective-c/grpc_shadow_boringssl_symbol_list""++symbols=($(cat $symbol_list | tail -n +2))++> $filename+echo '/*' >> $filename",nit: do we really need to generate the license agreement? it adds complexity to the file and obscures the real purpose.,OK
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/16318,211416335,2018-08-20T21:40:40Z,src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi,"@@ -142,10 +144,10 @@ cdef _cancel(       _check_and_raise_call_error_no_metadata(c_call_error)  -cdef BatchOperationEvent _next_call_event(+cdef _next_call_event(","`_latent_event` returns the result of `_interpret_event`. With the optional deadline, the returned event type can be a `ConnectivityEvent` in the event of a timeout.",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/16170,211445838,2018-08-21T00:15:36Z,test/core/iomgr/timer_list_test.cc,"@@ -151,17 +151,95 @@ void destruction_test(void) {   GPR_ASSERT(1 == cb_called[2][0]); } -int main(int argc, char** argv) {-  grpc_test_init(argc, argv);-  grpc_core::ExecCtx::GlobalInit();+/* Clean up a list with pending timers that simulate long-running-services. */+/* https://github.com/grpc/grpc/issues/15904 */+void long_running_service_cleanup_test(void) {+  grpc_timer timers[4];   grpc_core::ExecCtx exec_ctx;-  grpc_determine_iomgr_platform();-  grpc_iomgr_platform_init();-  gpr_set_log_verbosity(GPR_LOG_SEVERITY_DEBUG);-  add_test();-  destruction_test();-  grpc_iomgr_platform_shutdown();++  gpr_log(GPR_INFO, ""long_running_service_cleanup_test"");++  grpc_millis now = grpc_core::ExecCtx::Get()->Now();+  GPR_ASSERT(now >= 2160000000); /* 25 days in milliseconds */+  grpc_timer_list_init();+  grpc_core::testing::grpc_tracer_enable_flag(&grpc_timer_trace);+  grpc_core::testing::grpc_tracer_enable_flag(&grpc_timer_check_trace);+  memset(cb_called, 0, sizeof(cb_called));++  grpc_timer_init(+      &timers[0], now + 2160000000,+      GRPC_CLOSURE_CREATE(cb, (void*)(intptr_t)0, grpc_schedule_on_exec_ctx));+  grpc_timer_init(+      &timers[1], now + 3,+      GRPC_CLOSURE_CREATE(cb, (void*)(intptr_t)1, grpc_schedule_on_exec_ctx));+  grpc_timer_init(+      &timers[2], GRPC_MILLIS_INF_FUTURE - 1,+      GRPC_CLOSURE_CREATE(cb, (void*)(intptr_t)2, grpc_schedule_on_exec_ctx));++  gpr_timespec deadline_spec = grpc_millis_to_timespec(+      now + 2160000000, gpr_clock_type::GPR_CLOCK_MONOTONIC);++  /* grpc_timespec_to_millis_round_up is how users usually compute a millisecond+    input value into grpc_timer_init, so we mimic that behavior here */+  grpc_timer_init(+      &timers[3], grpc_timespec_to_millis_round_up(deadline_spec),+      GRPC_CLOSURE_CREATE(cb, (void*)(intptr_t)3, grpc_schedule_on_exec_ctx));++  grpc_core::ExecCtx::Get()->TestOnlySetNow(now + 4);+  GPR_ASSERT(grpc_timer_check(nullptr) == GRPC_TIMERS_FIRED);+  grpc_core::ExecCtx::Get()->Flush();+  GPR_ASSERT(0 == cb_called[0][0]);  // Timer 0 not called+  GPR_ASSERT(0 == cb_called[0][1]);+  GPR_ASSERT(0 == cb_called[1][0]);+  GPR_ASSERT(1 == cb_called[1][1]);  // Timer 1 fired+  GPR_ASSERT(0 == cb_called[2][0]);  // Timer 2 not called+  GPR_ASSERT(0 == cb_called[2][1]);+  GPR_ASSERT(0 == cb_called[3][0]);  // Timer 3 not called+  GPR_ASSERT(0 == cb_called[3][1]);++  grpc_timer_list_shutdown();+  grpc_core::ExecCtx::Get()->Flush();+  /* Timers 0, 2, and 3 were fired with an error during cleanup */+  GPR_ASSERT(1 == cb_called[0][0]);+  GPR_ASSERT(0 == cb_called[1][0]);+  GPR_ASSERT(1 == cb_called[2][0]);+  GPR_ASSERT(1 == cb_called[3][0]);+}++int main(int argc, char** argv) {+  /* Tests with default g_start_time */+  {+    grpc_test_init(argc, argv);",Done. It's in the long running service tests area below.,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16409,211544820,2018-08-21T09:48:27Z,BUILDING.md,"@@ -107,7 +107,8 @@ Therefore, gRPC supports several major build systems, which should satisfy most  From the grpc repository root ```sh- $ make+ $ make + $ make install","this doesn't logically belong here. These are instructions how to build gRPC itself.The instructions how to  use gRPC in your projects are here: https://github.com/grpc/grpc/tree/master/src/cpp#to-start-using-grpc-c (which involves the `make install` piece for make and also a warning what's bad about using it).We can add a link to the ""how to use"" instructions from BUILDING.md, but we shouldn't add the `make install` command.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16407,211654382,2018-08-21T15:37:04Z,include/grpcpp/impl/codegen/client_context.h,"@@ -200,8 +200,9 @@ class ClientContext {   ///   /// \return A multimap of initial metadata key-value pairs from the server.   const std::multimap<grpc::string_ref, grpc::string_ref>&-  GetServerInitialMetadata() const {+  GetServerInitialMetadata() {","Changing this to be non-const is a public API change.  I'm not sure that's okay.The only alternative I can see would be to declare the `recv_initial_metadata_` member as `mutable`, although that's pretty ugly.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16318,211683587,2018-08-21T17:02:20Z,include/grpc/grpc.h,"@@ -79,6 +79,9 @@ GRPCAPI void grpc_init(void);     destroyed. */ GRPCAPI void grpc_shutdown(void); +/** Returns 1 if the grpc library has been initialized */+GRPCAPI int grpc_is_initialized(void);","We'll need a gRFC for this change, as per:https://github.com/grpc/proposal/blob/master/P3-grfcs-for-core-api-changes.md",
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/16318,211713639,2018-08-21T18:34:00Z,include/grpc/grpc.h,"@@ -79,6 +79,9 @@ GRPCAPI void grpc_init(void);     destroyed. */ GRPCAPI void grpc_shutdown(void); +/** Returns 1 if the grpc library has been initialized */+GRPCAPI int grpc_is_initialized(void);","Yes, this should have been marked experimental. I added the experimental ""tag"" to the comment along with a link to the fork support tracking issue regarding stabilizing it in the future.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/16418,211791821,2018-08-21T23:36:00Z,src/core/ext/filters/message_size/message_size_filter.cc,"@@ -99,10 +99,15 @@ struct call_data {   // recv_message_ready up-call on transport_stream_op, and remember to   // call our next_recv_message_ready member after handling it.   grpc_closure recv_message_ready;+  grpc_closure recv_trailing_metadata_ready;+  // The error caused by a message that is too large, or GRPC_ERROR_NONE+  grpc_error* error;   // Used by recv_message_ready.   grpc_core::OrphanablePtr<grpc_core::ByteStream>* recv_message;   // Original recv_message_ready callback, invoked after our own.   grpc_closure* next_recv_message_ready;+  // Original recv_trailing_metadata callback, invoked after our own.+  grpc_closure* next_recv_trailing_metadata_ready;",nit; why `next_recv_trailing_metadata_ready` and not `original_recv_trailing_metadata_ready`. We usually just do original,OK
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/16418,211795802,2018-08-22T00:02:02Z,test/core/iomgr/error_test.cc,"@@ -187,16 +187,6 @@ static void test_os_error() {   GRPC_ERROR_UNREF(error); } -static void test_special() {","well, originally, when the parent was GRPC_ERROR_NONE, grpc_error_add_child would create an actual error out of it  which basically said - no error. Note that, this new error is no longer equal to GRPC_ERROR_NONE. For this new error, the original grpc_error_add_child would add a reference to the child, making it work. Note on l196, we actually depend on the behavior of a new error being created with a status of GRPC_STATUS_OK.With the new semantics, we won't be creating this new error. Instead, we would just return a reference to child",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/16418,211797694,2018-08-22T00:13:39Z,test/core/iomgr/error_test.cc,"@@ -187,16 +187,6 @@ static void test_os_error() {   GRPC_ERROR_UNREF(error); } -static void test_special() {",Won't a GRPC_ERROR_NONE get GRPC_STATUS_OK when `grpc_error_get_int` is called? https://github.com/grpc/grpc/blob/master/src/core/lib/iomgr/error.cc#L458,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16358,211971772,2018-08-22T14:18:34Z,tools/distrib/generate_grpc_shadow_boringssl.sh,"@@ -0,0 +1,95 @@+#!/bin/bash+# Copyright 2018 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++# This script generates a list of preprocessor macros to overwrite BoringSSL+# symbol names by adding GRPC_SHADOW prefix. This is necessary to make gRPC+# work with apps that also has OpenSSL dependency on iOS.+# The list of symbols to be overwritten is in+# src/objective-c/grpc_shadow_boringssl_symbol_list. This script generates the+# macros in src/core/tsi/grpc_shadow_boringssl for gRPC core and+# src/objective-c/BoringSSL.podspec for BoringSSL.+set -e++cd $(dirname $0)++filename_original=""../../src/core/tsi/grpc_shadow_boringssl.h""+boringssl_podspec_original=""../../src/objective-c/BoringSSL-GRPC.podspec""+if [ ""$TEST"" == """" ]; then+  filename=$filename_original+  boringssl_podspec=$boringssl_podspec_original+else+  filename=""${filename_original}.tmp""+  boringssl_podspec=""${boringssl_podspec_original}.tmp""+fi+symbol_list=""../../src/objective-c/grpc_shadow_boringssl_symbol_list""++symbols=($(cat $symbol_list | tail -n +3))++> $filename+echo '/*' >> $filename",I thinks you can whitelist the file in license checker so that license header is not required:https://github.com/grpc/grpc/blob/82bc60c0e13bfb00213b3a94ba72893d044e4c9a/tools/distrib/check_copyright.py#L68I think it's worth doing that as it would simplify the script.,
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/16418,211973677,2018-08-22T14:23:30Z,src/core/lib/surface/call.cc,"@@ -733,90 +680,42 @@ static grpc_error* error_from_status(grpc_status_code status,       GRPC_ERROR_INT_GRPC_STATUS, status); } -static void cancel_with_status(grpc_call* c, status_source source,-                               grpc_status_code status,+static void cancel_with_status(grpc_call* c, grpc_status_code status,                                const char* description) {-  cancel_with_error(c, source, error_from_status(status, description));+  cancel_with_error(c, error_from_status(status, description)); } -/*******************************************************************************- * FINAL STATUS CODE MANIPULATION- */--static bool get_final_status_from(-    grpc_call* call, grpc_error* error, bool allow_ok_status,-    void (*set_value)(grpc_status_code code, void* user_data),-    void* set_value_user_data, grpc_slice* details, const char** error_string) {-  grpc_status_code code;-  grpc_slice slice = grpc_empty_slice();-  grpc_error_get_status(error, call->send_deadline, &code, &slice, nullptr,-                        error_string);-  if (code == GRPC_STATUS_OK && !allow_ok_status) {-    return false;-  }--  set_value(code, set_value_user_data);-  if (details != nullptr) {-    *details = grpc_slice_ref_internal(slice);-  }-  return true;-}--static void get_final_status(-    grpc_call* call, void (*set_value)(grpc_status_code code, void* user_data),-    void* set_value_user_data, grpc_slice* details, const char** error_string) {-  int i;-  received_status status[STATUS_SOURCE_COUNT];-  for (i = 0; i < STATUS_SOURCE_COUNT; i++) {-    status[i] = unpack_received_status(gpr_atm_acq_load(&call->status[i]));-  }+static void set_final_status(grpc_call* call, grpc_error* error) {   if (grpc_call_error_trace.enabled()) {-    gpr_log(GPR_INFO, ""get_final_status %s"", call->is_client ? ""CLI"" : ""SVR"");-    for (i = 0; i < STATUS_SOURCE_COUNT; i++) {-      if (status[i].is_set) {-        gpr_log(GPR_INFO, ""  %d: %s"", i, grpc_error_string(status[i].error));-      }-    }+    gpr_log(GPR_DEBUG, ""set_final_status %s"", call->is_client ? ""CLI"" : ""SVR"");+    gpr_log(GPR_DEBUG, ""%s"", grpc_error_string(error));   }-  /* first search through ignoring ""OK"" statuses: if something went wrong,-   * ensure we report it */-  for (int allow_ok_status = 0; allow_ok_status < 2; allow_ok_status++) {-    /* search for the best status we can present: ideally the error we use has a-       clearly defined grpc-status, and we'll prefer that. */-    for (i = 0; i < STATUS_SOURCE_COUNT; i++) {-      if (status[i].is_set &&-          grpc_error_has_clear_grpc_status(status[i].error)) {-        if (get_final_status_from(call, status[i].error, allow_ok_status != 0,-                                  set_value, set_value_user_data, details,-                                  error_string)) {-          return;-        }+  grpc_core::channelz::ChannelNode* channelz_channel =+      grpc_channel_get_channelz_node(call->channel);+  if (call->is_client) {+    grpc_slice slice = grpc_empty_slice();+    grpc_error_get_status(error, call->send_deadline,+                          call->final_op.client.status, &slice, nullptr,+                          call->final_op.client.error_string);+    *call->final_op.client.status_details = grpc_slice_ref_internal(slice);+    call->status_error = error;+    if (channelz_channel != nullptr) {+      if (*call->final_op.client.status != GRPC_STATUS_OK) {+        channelz_channel->RecordCallFailed();+      } else {+        channelz_channel->RecordCallSucceeded();       }     }-    /* If no clearly defined status exists, search for 'anything' */-    for (i = 0; i < STATUS_SOURCE_COUNT; i++) {-      if (status[i].is_set) {-        if (get_final_status_from(call, status[i].error, allow_ok_status != 0,-                                  set_value, set_value_user_data, details,-                                  error_string)) {-          return;-        }+  } else {","Server is going to be handled by a different channelz class acctually.  could you remove this else block and leave me a TODO, update server channel bookkeeping?",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16318,212026649,2018-08-22T16:43:44Z,include/grpc/grpc.h,"@@ -79,6 +79,9 @@ GRPCAPI void grpc_init(void);     destroyed. */ GRPCAPI void grpc_shutdown(void); +/** Returns 1 if the grpc library has been initialized */+GRPCAPI int grpc_is_initialized(void);",I'm ok with this being experimental as long as its removal/promotion is tracked.,OK
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/16318,212030542,2018-08-22T16:56:40Z,include/grpc/grpc.h,"@@ -79,6 +79,9 @@ GRPCAPI void grpc_init(void);     destroyed. */ GRPCAPI void grpc_shutdown(void); +/** Returns 1 if the grpc library has been initialized */+GRPCAPI int grpc_is_initialized(void);","Thanks for the review! I kind of messed up my ""only review the second commit"" plan by then adding a 3rd/4th commit to update this method as experimental. The full comment on this function now includes the tracking issue as well:```/** EXPERIMENTAL. Returns 1 if the grpc library has been initialized.    TODO(ericgribkoff) Decide if this should be promoted to non-experimental as    part of stabilizing the fork support API, as tracked in    https://github.com/grpc/grpc/issues/15334 */```",
28123841,guantaol,https://api.github.com/repos/grpc/grpc/pulls/16414,212143754,2018-08-22T23:40:16Z,test/core/end2end/inproc_callback_test.cc,"@@ -0,0 +1,462 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""test/core/end2end/end2end_tests.h""++#include <string.h>++#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include ""src/core/ext/transport/inproc/inproc_transport.h""+#include ""src/core/lib/surface/channel.h""+#include ""src/core/lib/surface/completion_queue.h""+#include ""src/core/lib/surface/server.h""+#include ""test/core/util/port.h""+#include ""test/core/util/test_config.h""++typedef struct inproc_fixture_data {+  bool dummy;  // reserved for future expansion. Struct can't be empty+} inproc_fixture_data;++namespace {+template <typename F>+class CQDeletingCallback : public grpc_core::CQCallbackInterface {+ public:+  explicit CQDeletingCallback(F f) : func_(f) {}+  ~CQDeletingCallback() override {}+  void Run(bool ok) override {+    func_(ok);+    grpc_core::Delete(this);+  }++ private:+  F func_;+};++template <typename F>+grpc_core::CQCallbackInterface* NewDeletingCallback(F f) {+  return grpc_core::New<CQDeletingCallback<F>>(f);+}++class ShutdownCallback : public grpc_core::CQCallbackInterface {+ public:+  ShutdownCallback() : done_(false) {+    gpr_mu_init(&mu_);+    gpr_cv_init(&cv_);+  }+  ~ShutdownCallback() override {}+  void Run(bool ok) override {+    gpr_log(GPR_DEBUG, ""CQ shutdown notification invoked"");+    gpr_mu_lock(&mu_);+    done_ = true;+    gpr_cv_broadcast(&cv_);+    gpr_mu_unlock(&mu_);+  }+  void Wait(gpr_timespec deadline) {+    gpr_mu_lock(&mu_);+    while (!done_ && !gpr_cv_wait(&cv_, &mu_, deadline)) {+    }+    gpr_mu_unlock(&mu_);+  }++ private:+  bool done_;+  gpr_mu mu_;+  gpr_cv cv_;+};++ShutdownCallback* g_shutdown_callback;+}  // namespace++static gpr_mu tags_mu;+static gpr_cv tags_cv;+const size_t kAvailableTags = 4;+bool tags[kAvailableTags];+bool tags_valid[kAvailableTags];+bool tags_expected[kAvailableTags];+bool tags_needed[kAvailableTags];++static void expect_tag(intptr_t tag, bool ok) {+  size_t idx = static_cast<size_t>(tag);+  GPR_ASSERT(idx < kAvailableTags);+  tags_needed[idx] = true;+  tags_expected[idx] = ok;+}++static void verify_tags(gpr_timespec deadline) {+  bool done = false;++  gpr_mu_lock(&tags_mu);+  while (!done) {+    done = gpr_time_cmp(gpr_now(GPR_CLOCK_MONOTONIC), deadline) > 0;+    for (size_t i = 0; i < kAvailableTags; i++) {+      if (tags_needed[i]) {+        if (tags_valid[i]) {+          gpr_log(GPR_DEBUG, ""Verifying tag %d"", static_cast<int>(i));+          if (tags[i] != tags_expected[i]) {+            gpr_log(GPR_ERROR, ""Got wrong result (%d instead of %d) for tag %d"",+                    tags[i], tags_expected[i], static_cast<int>(i));+          }+          tags_valid[i] = false;+          tags_needed[i] = false;+        } else if (done) {+          gpr_log(GPR_ERROR, ""Didn't get tag %d"", static_cast<int>(i));+        }+      }+    }+    bool empty = true;+    for (size_t i = 0; i < kAvailableTags; i++) {+      if (tags_needed[i]) {+        empty = false;+      }+    }+    done = done || empty;+    if (done) {+      for (size_t i = 0; i < kAvailableTags; i++) {+        if (tags_valid[i]) {+          gpr_log(GPR_ERROR, ""Got unexpected tag %d and result %d"",+                  static_cast<int>(i), tags[i]);+        }+        tags_valid[i] = false;+      }+    } else {+      gpr_cv_wait(&tags_cv, &tags_mu, deadline);+    }+  }+  gpr_mu_unlock(&tags_mu);+}++static grpc_end2end_test_fixture inproc_create_fixture(+    grpc_channel_args* client_args, grpc_channel_args* server_args) {+  grpc_end2end_test_fixture f;+  inproc_fixture_data* ffd = static_cast<inproc_fixture_data*>(+      gpr_malloc(sizeof(inproc_fixture_data)));+  memset(&f, 0, sizeof(f));++  f.fixture_data = ffd;+  g_shutdown_callback = grpc_core::New<ShutdownCallback>();+  f.cq =+      grpc_completion_queue_create_for_callback(g_shutdown_callback, nullptr);+  f.shutdown_cq = grpc_completion_queue_create_for_pluck(nullptr);++  return f;+}++void inproc_init_client(grpc_end2end_test_fixture* f,+                        grpc_channel_args* client_args) {+  f->client = grpc_inproc_channel_create(f->server, client_args, nullptr);+  GPR_ASSERT(f->client);+}++void inproc_init_server(grpc_end2end_test_fixture* f,+                        grpc_channel_args* server_args) {+  if (f->server) {+    grpc_server_destroy(f->server);+  }+  f->server = grpc_server_create(server_args, nullptr);+  grpc_server_register_completion_queue(f->server, f->cq, nullptr);+  grpc_server_start(f->server);+}++void inproc_tear_down(grpc_end2end_test_fixture* f) {+  inproc_fixture_data* ffd = static_cast<inproc_fixture_data*>(f->fixture_data);+  gpr_free(ffd);+}++static grpc_core::CQCallbackInterface* tag(intptr_t t) {+  auto func = [t](bool ok) {+    gpr_mu_lock(&tags_mu);+    gpr_log(GPR_DEBUG, ""Completing operation %"" PRIdPTR, t);+    bool was_empty = true;+    for (size_t i = 0; i < kAvailableTags; i++) {+      if (tags_valid[i]) {+        was_empty = false;+      }+    }+    size_t idx = static_cast<size_t>(t);+    tags[idx] = ok;+    tags_valid[idx] = true;+    if (was_empty) {+      gpr_cv_signal(&tags_cv);+    }+    gpr_mu_unlock(&tags_mu);+  };+  auto cb = NewDeletingCallback(func);+  return cb;+}++static grpc_end2end_test_fixture begin_test(grpc_end2end_test_config config,+                                            const char* test_name,+                                            grpc_channel_args* client_args,+                                            grpc_channel_args* server_args) {+  grpc_end2end_test_fixture f;+  gpr_log(GPR_INFO, ""Running test: %s/%s"", test_name, config.name);+  f = config.create_fixture(client_args, server_args);+  config.init_server(&f, server_args);+  config.init_client(&f, client_args);+  return f;+}++static gpr_timespec n_seconds_from_now(int n) {+  return grpc_timeout_seconds_to_deadline(n);+}++static gpr_timespec five_seconds_from_now() { return n_seconds_from_now(5); }++static void drain_cq(grpc_completion_queue* cq) {+  g_shutdown_callback->Wait(five_seconds_from_now());",Do we need g_shutdown_callback has been invoked after returning from Wait()? It seems that we may return from Wait if the deadline expires.,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16358,212334107,2018-08-23T14:36:21Z,tools/distrib/check_boringssl_commit.sh,"@@ -0,0 +1,32 @@+#!/bin/bash","nit:  check_boringssl_commit.sh is not a great name.  You are checking if the ""shadow boringssl symbol list is up to date"", the fact that you are looking whether the commit sha in a file is the same is implementation detail. IMHO, seeing ""commit"" in the script name doesn't tell me anything usefulI suggest renaming to `check_boringssl_symbol_list.sh`, `check_boringssl_shadow_symbol_list.sh` or sth in that sense.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16358,212334500,2018-08-23T14:37:27Z,tools/distrib/check_boringssl_commit.sh,"@@ -0,0 +1,32 @@+#!/bin/bash","`check_shadow_boringssl_symbol_list.sh` is perhaps the best name, but leaving up to you.",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/16443,212407223,2018-08-23T18:12:57Z,include/grpc/grpc_security_constants.h,"@@ -74,26 +75,27 @@ typedef enum {      presents a certificate.       If the client presents a certificate, the client authentication is done by-     grpc framework (The client needs to either present a signed cert or skip no-     certificate for a successful connection).+     the gRPC framework (the client needs to either present a signed cert or not+     present a certificate at all for a successful connection).       The key cert pair should still be valid for the SSL connection to be      established. */   GRPC_SSL_REQUEST_CLIENT_CERTIFICATE_AND_VERIFY,-  /** Server requests client certificate but enforces that the client presents a+  /** Server requests client certificate and enforces that the client presents a      certificate.       If the client presents a certificate, the client authentication is left to-     the application based on the metadata like certificate etc.+     the application (the necessary metadata will be available to the+     application via authentication context properties, see grpc_auth_context).       The key cert pair should still be valid for the SSL connection to be      established. */   GRPC_SSL_REQUEST_AND_REQUIRE_CLIENT_CERTIFICATE_BUT_DONT_VERIFY,-  /** Server requests client certificate but enforces that the client presents a+  /** Server requests client certificate and enforces that the client presents a      certificate. -     The cerificate presented by the client is verified by grpc framework (The-     client needs to present signed certs for a successful connection).+     The cerificate presented by the client is verified by the gRPC framework+     (the client needs to present signed certs for a successful connection).       The key cert pair should still be valid for the SSL connection to be","In GRPC_SSL_DONT_REQUEST_CLIENT_CERTIFICATE, server does not verify client certificate at all.How about ""The client's key and certificate themselves need to be valid for the SSL connection to be established"". The main difference between VERIFY and BUT_DONT_VERIFY is whether the client certificate is chained back to the root certificates configured by the server. Except in GRPC_SSL_DONT_REQUEST_CLIENT_CERTIFICATE, the client key needs to match the client's certificate.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/16418,212500857,2018-08-24T01:30:51Z,src/core/lib/surface/call.cc,"@@ -733,90 +680,42 @@ static grpc_error* error_from_status(grpc_status_code status,       GRPC_ERROR_INT_GRPC_STATUS, status); } -static void cancel_with_status(grpc_call* c, status_source source,-                               grpc_status_code status,+static void cancel_with_status(grpc_call* c, grpc_status_code status,                                const char* description) {-  cancel_with_error(c, source, error_from_status(status, description));+  cancel_with_error(c, error_from_status(status, description)); } -/*******************************************************************************- * FINAL STATUS CODE MANIPULATION- */--static bool get_final_status_from(-    grpc_call* call, grpc_error* error, bool allow_ok_status,-    void (*set_value)(grpc_status_code code, void* user_data),-    void* set_value_user_data, grpc_slice* details, const char** error_string) {-  grpc_status_code code;-  grpc_slice slice = grpc_empty_slice();-  grpc_error_get_status(error, call->send_deadline, &code, &slice, nullptr,-                        error_string);-  if (code == GRPC_STATUS_OK && !allow_ok_status) {-    return false;-  }--  set_value(code, set_value_user_data);-  if (details != nullptr) {-    *details = grpc_slice_ref_internal(slice);-  }-  return true;-}--static void get_final_status(-    grpc_call* call, void (*set_value)(grpc_status_code code, void* user_data),-    void* set_value_user_data, grpc_slice* details, const char** error_string) {-  int i;-  received_status status[STATUS_SOURCE_COUNT];-  for (i = 0; i < STATUS_SOURCE_COUNT; i++) {-    status[i] = unpack_received_status(gpr_atm_acq_load(&call->status[i]));-  }+static void set_final_status(grpc_call* call, grpc_error* error) {   if (grpc_call_error_trace.enabled()) {-    gpr_log(GPR_INFO, ""get_final_status %s"", call->is_client ? ""CLI"" : ""SVR"");-    for (i = 0; i < STATUS_SOURCE_COUNT; i++) {-      if (status[i].is_set) {-        gpr_log(GPR_INFO, ""  %d: %s"", i, grpc_error_string(status[i].error));-      }-    }+    gpr_log(GPR_DEBUG, ""set_final_status %s"", call->is_client ? ""CLI"" : ""SVR"");+    gpr_log(GPR_DEBUG, ""%s"", grpc_error_string(error));   }-  /* first search through ignoring ""OK"" statuses: if something went wrong,-   * ensure we report it */-  for (int allow_ok_status = 0; allow_ok_status < 2; allow_ok_status++) {-    /* search for the best status we can present: ideally the error we use has a-       clearly defined grpc-status, and we'll prefer that. */-    for (i = 0; i < STATUS_SOURCE_COUNT; i++) {-      if (status[i].is_set &&-          grpc_error_has_clear_grpc_status(status[i].error)) {-        if (get_final_status_from(call, status[i].error, allow_ok_status != 0,-                                  set_value, set_value_user_data, details,-                                  error_string)) {-          return;-        }+  grpc_core::channelz::ChannelNode* channelz_channel =+      grpc_channel_get_channelz_node(call->channel);+  if (call->is_client) {+    grpc_slice slice = grpc_empty_slice();+    grpc_error_get_status(error, call->send_deadline,+                          call->final_op.client.status, &slice, nullptr,+                          call->final_op.client.error_string);+    *call->final_op.client.status_details = grpc_slice_ref_internal(slice);","That could still be done without creating the extra slice on the stack. ```grpc_error_get_status(error, call->send_deadline,                                      call->final_op.client.status, call->final_op.client.status_details,                                       nullptr, call->final_op.client.error_string);// explicitly take a refgrpc_slice_ref_internal(call->final_op.client.status_details);```",OK
42048362,mhaidrygoog,https://api.github.com/repos/grpc/grpc/pulls/16414,212681019,2018-08-24T16:18:32Z,test/core/end2end/inproc_callback_test.cc,"@@ -0,0 +1,498 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""test/core/end2end/end2end_tests.h""++#include <string.h>++#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include ""src/core/ext/transport/inproc/inproc_transport.h""+#include ""src/core/lib/surface/channel.h""+#include ""src/core/lib/surface/completion_queue.h""+#include ""src/core/lib/surface/server.h""+#include ""test/core/util/port.h""+#include ""test/core/util/test_config.h""++typedef struct inproc_fixture_data {+  bool dummy;  // reserved for future expansion. Struct can't be empty+} inproc_fixture_data;++namespace {+template <typename F>+class CQDeletingCallback : public grpc_core::CQCallbackInterface {+ public:+  explicit CQDeletingCallback(F f) : func_(f) {}+  ~CQDeletingCallback() override {}+  void Run(bool ok) override {+    func_(ok);+    grpc_core::Delete(this);+  }++ private:+  F func_;+};++template <typename F>+grpc_core::CQCallbackInterface* NewDeletingCallback(F f) {+  return grpc_core::New<CQDeletingCallback<F>>(f);+}++class ShutdownCallback : public grpc_core::CQCallbackInterface {+ public:+  ShutdownCallback() : done_(false) {+    gpr_mu_init(&mu_);+    gpr_cv_init(&cv_);+  }+  ~ShutdownCallback() override {}+  void Run(bool ok) override {+    gpr_log(GPR_DEBUG, ""CQ shutdown notification invoked"");+    gpr_mu_lock(&mu_);+    done_ = true;+    gpr_cv_broadcast(&cv_);+    gpr_mu_unlock(&mu_);+  }+  // The Wait function waits for a specified amount of+  // time for the completion of the shutdown and returns+  // whether it was successfully shut down+  bool Wait(gpr_timespec deadline) {+    gpr_mu_lock(&mu_);+    while (!done_ && !gpr_cv_wait(&cv_, &mu_, deadline)) {+    }+    bool ret = done_;+    gpr_mu_unlock(&mu_);+    return ret;+  }++ private:+  bool done_;+  gpr_mu mu_;+  gpr_cv cv_;+};++ShutdownCallback* g_shutdown_callback;+}  // namespace++// The following global structure is the tag collection. It holds+// all information related to tags expected and tags received+// during the execution, with each callback setting a tag.+// The tag sets are implemented and checked using arrays and+// linear lookups (rather than maps) so that this test doesn't+// need the C++ standard library.+static gpr_mu tags_mu;+static gpr_cv tags_cv;+const size_t kAvailableTags = 4;+bool tags[kAvailableTags];+bool tags_valid[kAvailableTags];+bool tags_expected[kAvailableTags];+bool tags_needed[kAvailableTags];++// Mark that a tag is expected; this function must be executed in the+// main thread only while there are no other threads altering the+// expectation set (e.g., by calling expect_tag or verify_tags)+static void expect_tag(intptr_t tag, bool ok) {+  size_t idx = static_cast<size_t>(tag);+  GPR_ASSERT(idx < kAvailableTags);+  tags_needed[idx] = true;+  tags_expected[idx] = ok;+}++// Check that the expected tags have reached, within a certain+// deadline. This must also be executed only on the main thread while+// there are no other threads altering the expectation set (e.g., by+// calling expect_tag or verify_tags). The tag verifier doesn't have+// to drive the CQ at all (unlike the next-based end2end tests)+// because the tags will get set when the callbacks are executed,+// which happens when a particular batch related to a callback is+// complete.+static void verify_tags(gpr_timespec deadline) {+  bool done = false;++  gpr_mu_lock(&tags_mu);+  while (!done) {+    done = gpr_time_cmp(gpr_now(GPR_CLOCK_MONOTONIC), deadline) > 0;+    for (size_t i = 0; i < kAvailableTags; i++) {+      if (tags_needed[i]) {+        if (tags_valid[i]) {+          gpr_log(GPR_DEBUG, ""Verifying tag %d"", static_cast<int>(i));+          if (tags[i] != tags_expected[i]) {+            gpr_log(GPR_ERROR, ""Got wrong result (%d instead of %d) for tag %d"",+                    tags[i], tags_expected[i], static_cast<int>(i));+            GPR_ASSERT(false);+          }+          tags_valid[i] = false;+          tags_needed[i] = false;+        } else if (done) {+          gpr_log(GPR_ERROR, ""Didn't get tag %d"", static_cast<int>(i));+          GPR_ASSERT(false);+        }+      }+    }+    bool empty = true;+    for (size_t i = 0; i < kAvailableTags; i++) {+      if (tags_needed[i]) {+        empty = false;+      }+    }+    done = done || empty;+    if (done) {+      for (size_t i = 0; i < kAvailableTags; i++) {+        if (tags_valid[i]) {+          gpr_log(GPR_ERROR, ""Got unexpected tag %d and result %d"",+                  static_cast<int>(i), tags[i]);+          GPR_ASSERT(false);+        }+        tags_valid[i] = false;+      }+    } else {+      gpr_cv_wait(&tags_cv, &tags_mu, deadline);+    }+  }+  gpr_mu_unlock(&tags_mu);+}++// This function creates a callback functor that emits the+// desired tag into the global tag set+static grpc_core::CQCallbackInterface* tag(intptr_t t) {+  auto func = [t](bool ok) {+    gpr_mu_lock(&tags_mu);+    gpr_log(GPR_DEBUG, ""Completing operation %"" PRIdPTR, t);+    bool was_empty = true;+    for (size_t i = 0; i < kAvailableTags; i++) {+      if (tags_valid[i]) {+        was_empty = false;+      }+    }+    size_t idx = static_cast<size_t>(t);+    tags[idx] = ok;+    tags_valid[idx] = true;+    if (was_empty) {+      gpr_cv_signal(&tags_cv);+    }+    gpr_mu_unlock(&tags_mu);+  };+  auto cb = NewDeletingCallback(func);+  return cb;+}++static grpc_end2end_test_fixture inproc_create_fixture(+    grpc_channel_args* client_args, grpc_channel_args* server_args) {+  grpc_end2end_test_fixture f;+  inproc_fixture_data* ffd = static_cast<inproc_fixture_data*>(+      gpr_malloc(sizeof(inproc_fixture_data)));+  memset(&f, 0, sizeof(f));++  f.fixture_data = ffd;+  g_shutdown_callback = grpc_core::New<ShutdownCallback>();+  f.cq =+      grpc_completion_queue_create_for_callback(g_shutdown_callback, nullptr);+  f.shutdown_cq = grpc_completion_queue_create_for_pluck(nullptr);++  return f;+}++void inproc_init_client(grpc_end2end_test_fixture* f,+                        grpc_channel_args* client_args) {+  f->client = grpc_inproc_channel_create(f->server, client_args, nullptr);+  GPR_ASSERT(f->client);+}++void inproc_init_server(grpc_end2end_test_fixture* f,+                        grpc_channel_args* server_args) {+  if (f->server) {+    grpc_server_destroy(f->server);+  }+  f->server = grpc_server_create(server_args, nullptr);+  grpc_server_register_completion_queue(f->server, f->cq, nullptr);+  grpc_server_start(f->server);+}++void inproc_tear_down(grpc_end2end_test_fixture* f) {+  inproc_fixture_data* ffd = static_cast<inproc_fixture_data*>(f->fixture_data);+  gpr_free(ffd);+}++static grpc_end2end_test_fixture begin_test(grpc_end2end_test_config config,+                                            const char* test_name,+                                            grpc_channel_args* client_args,+                                            grpc_channel_args* server_args) {+  grpc_end2end_test_fixture f;+  gpr_log(GPR_INFO, ""Running test: %s/%s"", test_name, config.name);+  f = config.create_fixture(client_args, server_args);+  config.init_server(&f, server_args);+  config.init_client(&f, client_args);+  return f;+}++static gpr_timespec n_seconds_from_now(int n) {+  return grpc_timeout_seconds_to_deadline(n);+}++static gpr_timespec five_seconds_from_now() { return n_seconds_from_now(5); }++static void drain_cq(grpc_completion_queue* cq) {+  // Wait for the shutdown callback to arrive, or fail the test+  GPR_ASSERT(g_shutdown_callback->Wait(five_seconds_from_now()));+  gpr_log(GPR_DEBUG, ""CQ shutdown wait complete"");+  grpc_core::Delete(g_shutdown_callback);+}++static void shutdown_server(grpc_end2end_test_fixture* f) {+  if (!f->server) return;+  grpc_server_shutdown_and_notify(+      f->server, f->shutdown_cq,+      reinterpret_cast<void*>(static_cast<intptr_t>(1000)));+  GPR_ASSERT(+      grpc_completion_queue_pluck(f->shutdown_cq, (void*)((intptr_t)1000),+                                  grpc_timeout_seconds_to_deadline(5), nullptr)+          .type == GRPC_OP_COMPLETE);+  grpc_server_destroy(f->server);+  f->server = nullptr;+}++static void shutdown_client(grpc_end2end_test_fixture* f) {+  if (!f->client) return;+  grpc_channel_destroy(f->client);+  f->client = nullptr;+}++static void end_test(grpc_end2end_test_fixture* f) {+  shutdown_server(f);+  shutdown_client(f);++  grpc_completion_queue_shutdown(f->cq);+  drain_cq(f->cq);+  grpc_completion_queue_destroy(f->cq);+  grpc_completion_queue_destroy(f->shutdown_cq);+}++static void simple_request_body(grpc_end2end_test_config config,+                                grpc_end2end_test_fixture f) {+  grpc_call* c;+  grpc_call* s;+  grpc_op ops[6];+  grpc_op* op;+  grpc_metadata_array initial_metadata_recv;+  grpc_metadata_array trailing_metadata_recv;+  grpc_metadata_array request_metadata_recv;+  grpc_call_details call_details;+  grpc_status_code status;+  const char* error_string;+  grpc_call_error error;+  grpc_slice details;+  int was_cancelled = 2;+  char* peer;+  gpr_timespec deadline = five_seconds_from_now();++  c = grpc_channel_create_call(f.client, nullptr, GRPC_PROPAGATE_DEFAULTS, f.cq,+                               grpc_slice_from_static_string(""/foo""), nullptr,+                               deadline, nullptr);+  GPR_ASSERT(c);++  peer = grpc_call_get_peer(c);+  GPR_ASSERT(peer != nullptr);+  gpr_log(GPR_DEBUG, ""client_peer_before_call=%s"", peer);+  gpr_free(peer);++  grpc_metadata_array_init(&initial_metadata_recv);+  grpc_metadata_array_init(&trailing_metadata_recv);+  grpc_metadata_array_init(&request_metadata_recv);+  grpc_call_details_init(&call_details);++  // Create a basic client unary request batch (no payload)+  memset(ops, 0, sizeof(ops));",I'm not sure if this is very trivial but it may be helpful to have a small helper function to provide this op array. Also if these ops are common among multiple tests it may be useful to have one common function in a library to return an array of ops that may be consumed by those tests.,OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16414,212688141,2018-08-24T16:46:45Z,test/core/end2end/inproc_callback_test.cc,"@@ -0,0 +1,498 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""test/core/end2end/end2end_tests.h""++#include <string.h>++#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include ""src/core/ext/transport/inproc/inproc_transport.h""+#include ""src/core/lib/surface/channel.h""+#include ""src/core/lib/surface/completion_queue.h""+#include ""src/core/lib/surface/server.h""+#include ""test/core/util/port.h""+#include ""test/core/util/test_config.h""++typedef struct inproc_fixture_data {+  bool dummy;  // reserved for future expansion. Struct can't be empty+} inproc_fixture_data;++namespace {+template <typename F>+class CQDeletingCallback : public grpc_core::CQCallbackInterface {+ public:+  explicit CQDeletingCallback(F f) : func_(f) {}+  ~CQDeletingCallback() override {}+  void Run(bool ok) override {+    func_(ok);+    grpc_core::Delete(this);+  }++ private:+  F func_;+};++template <typename F>+grpc_core::CQCallbackInterface* NewDeletingCallback(F f) {+  return grpc_core::New<CQDeletingCallback<F>>(f);+}++class ShutdownCallback : public grpc_core::CQCallbackInterface {+ public:+  ShutdownCallback() : done_(false) {+    gpr_mu_init(&mu_);+    gpr_cv_init(&cv_);+  }+  ~ShutdownCallback() override {}+  void Run(bool ok) override {+    gpr_log(GPR_DEBUG, ""CQ shutdown notification invoked"");+    gpr_mu_lock(&mu_);+    done_ = true;+    gpr_cv_broadcast(&cv_);+    gpr_mu_unlock(&mu_);+  }+  // The Wait function waits for a specified amount of+  // time for the completion of the shutdown and returns+  // whether it was successfully shut down+  bool Wait(gpr_timespec deadline) {+    gpr_mu_lock(&mu_);+    while (!done_ && !gpr_cv_wait(&cv_, &mu_, deadline)) {+    }+    bool ret = done_;+    gpr_mu_unlock(&mu_);+    return ret;+  }++ private:+  bool done_;+  gpr_mu mu_;+  gpr_cv cv_;+};++ShutdownCallback* g_shutdown_callback;+}  // namespace++// The following global structure is the tag collection. It holds+// all information related to tags expected and tags received+// during the execution, with each callback setting a tag.+// The tag sets are implemented and checked using arrays and+// linear lookups (rather than maps) so that this test doesn't+// need the C++ standard library.+static gpr_mu tags_mu;+static gpr_cv tags_cv;+const size_t kAvailableTags = 4;+bool tags[kAvailableTags];+bool tags_valid[kAvailableTags];+bool tags_expected[kAvailableTags];+bool tags_needed[kAvailableTags];++// Mark that a tag is expected; this function must be executed in the+// main thread only while there are no other threads altering the+// expectation set (e.g., by calling expect_tag or verify_tags)+static void expect_tag(intptr_t tag, bool ok) {+  size_t idx = static_cast<size_t>(tag);+  GPR_ASSERT(idx < kAvailableTags);+  tags_needed[idx] = true;+  tags_expected[idx] = ok;+}++// Check that the expected tags have reached, within a certain+// deadline. This must also be executed only on the main thread while+// there are no other threads altering the expectation set (e.g., by+// calling expect_tag or verify_tags). The tag verifier doesn't have+// to drive the CQ at all (unlike the next-based end2end tests)+// because the tags will get set when the callbacks are executed,+// which happens when a particular batch related to a callback is+// complete.+static void verify_tags(gpr_timespec deadline) {+  bool done = false;++  gpr_mu_lock(&tags_mu);+  while (!done) {+    done = gpr_time_cmp(gpr_now(GPR_CLOCK_MONOTONIC), deadline) > 0;+    for (size_t i = 0; i < kAvailableTags; i++) {+      if (tags_needed[i]) {+        if (tags_valid[i]) {+          gpr_log(GPR_DEBUG, ""Verifying tag %d"", static_cast<int>(i));+          if (tags[i] != tags_expected[i]) {+            gpr_log(GPR_ERROR, ""Got wrong result (%d instead of %d) for tag %d"",+                    tags[i], tags_expected[i], static_cast<int>(i));+            GPR_ASSERT(false);+          }+          tags_valid[i] = false;+          tags_needed[i] = false;+        } else if (done) {+          gpr_log(GPR_ERROR, ""Didn't get tag %d"", static_cast<int>(i));+          GPR_ASSERT(false);+        }+      }+    }+    bool empty = true;+    for (size_t i = 0; i < kAvailableTags; i++) {+      if (tags_needed[i]) {+        empty = false;+      }+    }+    done = done || empty;+    if (done) {+      for (size_t i = 0; i < kAvailableTags; i++) {+        if (tags_valid[i]) {+          gpr_log(GPR_ERROR, ""Got unexpected tag %d and result %d"",+                  static_cast<int>(i), tags[i]);+          GPR_ASSERT(false);+        }+        tags_valid[i] = false;+      }+    } else {+      gpr_cv_wait(&tags_cv, &tags_mu, deadline);+    }+  }+  gpr_mu_unlock(&tags_mu);+}++// This function creates a callback functor that emits the+// desired tag into the global tag set+static grpc_core::CQCallbackInterface* tag(intptr_t t) {+  auto func = [t](bool ok) {+    gpr_mu_lock(&tags_mu);+    gpr_log(GPR_DEBUG, ""Completing operation %"" PRIdPTR, t);+    bool was_empty = true;+    for (size_t i = 0; i < kAvailableTags; i++) {+      if (tags_valid[i]) {+        was_empty = false;+      }+    }+    size_t idx = static_cast<size_t>(t);+    tags[idx] = ok;+    tags_valid[idx] = true;+    if (was_empty) {+      gpr_cv_signal(&tags_cv);+    }+    gpr_mu_unlock(&tags_mu);+  };+  auto cb = NewDeletingCallback(func);+  return cb;+}++static grpc_end2end_test_fixture inproc_create_fixture(+    grpc_channel_args* client_args, grpc_channel_args* server_args) {+  grpc_end2end_test_fixture f;+  inproc_fixture_data* ffd = static_cast<inproc_fixture_data*>(+      gpr_malloc(sizeof(inproc_fixture_data)));+  memset(&f, 0, sizeof(f));++  f.fixture_data = ffd;+  g_shutdown_callback = grpc_core::New<ShutdownCallback>();+  f.cq =+      grpc_completion_queue_create_for_callback(g_shutdown_callback, nullptr);+  f.shutdown_cq = grpc_completion_queue_create_for_pluck(nullptr);++  return f;+}++void inproc_init_client(grpc_end2end_test_fixture* f,+                        grpc_channel_args* client_args) {+  f->client = grpc_inproc_channel_create(f->server, client_args, nullptr);+  GPR_ASSERT(f->client);+}++void inproc_init_server(grpc_end2end_test_fixture* f,+                        grpc_channel_args* server_args) {+  if (f->server) {+    grpc_server_destroy(f->server);+  }+  f->server = grpc_server_create(server_args, nullptr);+  grpc_server_register_completion_queue(f->server, f->cq, nullptr);+  grpc_server_start(f->server);+}++void inproc_tear_down(grpc_end2end_test_fixture* f) {+  inproc_fixture_data* ffd = static_cast<inproc_fixture_data*>(f->fixture_data);+  gpr_free(ffd);+}++static grpc_end2end_test_fixture begin_test(grpc_end2end_test_config config,+                                            const char* test_name,+                                            grpc_channel_args* client_args,+                                            grpc_channel_args* server_args) {+  grpc_end2end_test_fixture f;+  gpr_log(GPR_INFO, ""Running test: %s/%s"", test_name, config.name);+  f = config.create_fixture(client_args, server_args);+  config.init_server(&f, server_args);+  config.init_client(&f, client_args);+  return f;+}++static gpr_timespec n_seconds_from_now(int n) {+  return grpc_timeout_seconds_to_deadline(n);+}++static gpr_timespec five_seconds_from_now() { return n_seconds_from_now(5); }++static void drain_cq(grpc_completion_queue* cq) {+  // Wait for the shutdown callback to arrive, or fail the test+  GPR_ASSERT(g_shutdown_callback->Wait(five_seconds_from_now()));+  gpr_log(GPR_DEBUG, ""CQ shutdown wait complete"");+  grpc_core::Delete(g_shutdown_callback);+}++static void shutdown_server(grpc_end2end_test_fixture* f) {+  if (!f->server) return;+  grpc_server_shutdown_and_notify(+      f->server, f->shutdown_cq,+      reinterpret_cast<void*>(static_cast<intptr_t>(1000)));+  GPR_ASSERT(+      grpc_completion_queue_pluck(f->shutdown_cq, (void*)((intptr_t)1000),+                                  grpc_timeout_seconds_to_deadline(5), nullptr)+          .type == GRPC_OP_COMPLETE);+  grpc_server_destroy(f->server);+  f->server = nullptr;+}++static void shutdown_client(grpc_end2end_test_fixture* f) {+  if (!f->client) return;+  grpc_channel_destroy(f->client);+  f->client = nullptr;+}++static void end_test(grpc_end2end_test_fixture* f) {+  shutdown_server(f);+  shutdown_client(f);++  grpc_completion_queue_shutdown(f->cq);+  drain_cq(f->cq);+  grpc_completion_queue_destroy(f->cq);+  grpc_completion_queue_destroy(f->shutdown_cq);+}++static void simple_request_body(grpc_end2end_test_config config,+                                grpc_end2end_test_fixture f) {+  grpc_call* c;+  grpc_call* s;+  grpc_op ops[6];+  grpc_op* op;+  grpc_metadata_array initial_metadata_recv;+  grpc_metadata_array trailing_metadata_recv;+  grpc_metadata_array request_metadata_recv;+  grpc_call_details call_details;+  grpc_status_code status;+  const char* error_string;+  grpc_call_error error;+  grpc_slice details;+  int was_cancelled = 2;+  char* peer;+  gpr_timespec deadline = five_seconds_from_now();++  c = grpc_channel_create_call(f.client, nullptr, GRPC_PROPAGATE_DEFAULTS, f.cq,+                               grpc_slice_from_static_string(""/foo""), nullptr,+                               deadline, nullptr);+  GPR_ASSERT(c);++  peer = grpc_call_get_peer(c);+  GPR_ASSERT(peer != nullptr);+  gpr_log(GPR_DEBUG, ""client_peer_before_call=%s"", peer);+  gpr_free(peer);++  grpc_metadata_array_init(&initial_metadata_recv);+  grpc_metadata_array_init(&trailing_metadata_recv);+  grpc_metadata_array_init(&request_metadata_recv);+  grpc_call_details_init(&call_details);++  // Create a basic client unary request batch (no payload)+  memset(ops, 0, sizeof(ops));","Great observation... but we try not to reuse code or have helper functions in tests for two reasons.1. Readability - let it be obvious what each test is trying to do using only a linear reading of the test body1. Testability - every helper function itself is a surface that needs to get testedSo there are cases where we use helpers when the overall code is incredibly complex, but in those cases we try to have tests for the helpers too.",OK
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/16351,212868965,2018-08-27T05:28:33Z,src/cpp/server/health/default_health_check_service.cc,"@@ -30,29 +30,162 @@ #include ""src/cpp/server/health/health.pb.h""  namespace grpc {++//+// DefaultHealthCheckService+//++DefaultHealthCheckService::DefaultHealthCheckService() {+  services_map_[""""].SetServingStatus(SERVING);+}++void DefaultHealthCheckService::SetServingStatus(+    const grpc::string& service_name, bool serving) {+  std::unique_lock<std::mutex> lock(mu_);+  services_map_[service_name].SetServingStatus(serving ? SERVING : NOT_SERVING);+}++void DefaultHealthCheckService::SetServingStatus(bool serving) {+  const ServingStatus status = serving ? SERVING : NOT_SERVING;+  std::unique_lock<std::mutex> lock(mu_);+  for (auto& p : services_map_) {+    ServiceData& service_data = p.second;+    service_data.SetServingStatus(status);+  }+}++DefaultHealthCheckService::ServingStatus+DefaultHealthCheckService::GetServingStatus(+    const grpc::string& service_name) const {+  std::lock_guard<std::mutex> lock(mu_);+  auto it = services_map_.find(service_name);+  if (it == services_map_.end()) {+    return NOT_FOUND;+  }+  const ServiceData& service_data = it->second;+  return service_data.GetServingStatus();+}++void DefaultHealthCheckService::RegisterCallHandler(+    const grpc::string& service_name,+    std::shared_ptr<HealthCheckServiceImpl::CallHandler> handler) {+  std::unique_lock<std::mutex> lock(mu_);+  ServiceData& service_data = services_map_[service_name];+  service_data.AddCallHandler(handler /* copies ref */);+  handler->SendHealth(std::move(handler), service_data.GetServingStatus());+}++void DefaultHealthCheckService::UnregisterCallHandler(+    const grpc::string& service_name,+    std::shared_ptr<HealthCheckServiceImpl::CallHandler> handler) {+  std::unique_lock<std::mutex> lock(mu_);+  auto it = services_map_.find(service_name);+  if (it == services_map_.end()) return;+  ServiceData& service_data = it->second;+  service_data.RemoveCallHandler(std::move(handler));+  if (service_data.Unused()) {+    services_map_.erase(it);+  }+}++DefaultHealthCheckService::HealthCheckServiceImpl*+DefaultHealthCheckService::GetHealthCheckService(+    std::unique_ptr<ServerCompletionQueue> cq) {+  GPR_ASSERT(impl_ == nullptr);+  impl_.reset(new HealthCheckServiceImpl(this, std::move(cq)));+  return impl_.get();+}++//+// DefaultHealthCheckService::ServiceData+//++void DefaultHealthCheckService::ServiceData::SetServingStatus(+    ServingStatus status) {+  status_ = status;+  for (auto& call_handler : call_handlers_) {+    call_handler->SendHealth(call_handler /* copies ref */, status);+  }+}++void DefaultHealthCheckService::ServiceData::AddCallHandler(+    std::shared_ptr<HealthCheckServiceImpl::CallHandler> handler) {+  call_handlers_.insert(std::move(handler));+}++void DefaultHealthCheckService::ServiceData::RemoveCallHandler(+    std::shared_ptr<HealthCheckServiceImpl::CallHandler> handler) {+  call_handlers_.erase(std::move(handler));+}++//+// DefaultHealthCheckService::HealthCheckServiceImpl+//+ namespace { const char kHealthCheckMethodName[] = ""/grpc.health.v1.Health/Check"";+const char kHealthWatchMethodName[] = ""/grpc.health.v1.Health/Watch""; }  // namespace  DefaultHealthCheckService::HealthCheckServiceImpl::HealthCheckServiceImpl(-    DefaultHealthCheckService* service)-    : service_(service), method_(nullptr) {-  internal::MethodHandler* handler =-      new internal::RpcMethodHandler<HealthCheckServiceImpl, ByteBuffer,-                                     ByteBuffer>(-          std::mem_fn(&HealthCheckServiceImpl::Check), this);-  method_ = new internal::RpcServiceMethod(-      kHealthCheckMethodName, internal::RpcMethod::NORMAL_RPC, handler);-  AddMethod(method_);-}--Status DefaultHealthCheckService::HealthCheckServiceImpl::Check(-    ServerContext* context, const ByteBuffer* request, ByteBuffer* response) {-  // Decode request.-  std::vector<Slice> slices;-  if (!request->Dump(&slices).ok()) {-    return Status(StatusCode::INVALID_ARGUMENT, """");+    DefaultHealthCheckService* database,+    std::unique_ptr<ServerCompletionQueue> cq)+    : database_(database), cq_(std::move(cq)) {+  // Add Check() method.+  check_method_ = new internal::RpcServiceMethod(+      kHealthCheckMethodName, internal::RpcMethod::NORMAL_RPC, nullptr);+  AddMethod(check_method_);+  // Add Watch() method.+  watch_method_ = new internal::RpcServiceMethod(+      kHealthWatchMethodName, internal::RpcMethod::SERVER_STREAMING, nullptr);+  AddMethod(watch_method_);+  // Create serving thread.+  thread_ = std::unique_ptr<::grpc_core::Thread>(+      new ::grpc_core::Thread(""health_check_service"", Serve, this));+}++DefaultHealthCheckService::HealthCheckServiceImpl::~HealthCheckServiceImpl() {+  // We will reach here after the server starts shutting down.+  shutdown_ = true;+  {+    std::unique_lock<std::mutex> lock(cq_shutdown_mu_);+    cq_->Shutdown();+  }+  thread_->Join();+}++void DefaultHealthCheckService::HealthCheckServiceImpl::StartServingThread() {+  thread_->Start();+}++void DefaultHealthCheckService::HealthCheckServiceImpl::Serve(void* arg) {+  HealthCheckServiceImpl* service =+      reinterpret_cast<HealthCheckServiceImpl*>(arg);+  // TODO(juanlishen): This is a workaround to wait for the cq to be ready.+  // Need to figure out why cq is not ready after service starts.+  gpr_sleep_until(gpr_time_add(gpr_now(GPR_CLOCK_MONOTONIC),+                               gpr_time_from_seconds(1, GPR_TIMESPAN)));+  CheckCallHandler::CreateAndStart(service->cq_.get(), service->database_,+                                   service);+  WatchCallHandler::CreateAndStart(service->cq_.get(), service->database_,+                                   service);+  void* tag;+  bool ok;+  while (true) {+    if (!service->cq_->Next(&tag, &ok)) {","I am not a big fan of a single cq on a single thread. But I think it will work.A bit more context on the sync-only implementation of the previous implementation: When I first did the PR, it contains sync and async versions (use automatically depending on whether the server has sync or async). The async version was done similar to the Unimplemented version, but was later removed because ""our sync server will be as cheap as async"" :). But of course when we have a stream version of API, it should use async somehow.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16351,213045612,2018-08-27T17:08:23Z,src/cpp/server/health/default_health_check_service.cc,"@@ -30,29 +30,162 @@ #include ""src/cpp/server/health/health.pb.h""  namespace grpc {++//+// DefaultHealthCheckService+//++DefaultHealthCheckService::DefaultHealthCheckService() {+  services_map_[""""].SetServingStatus(SERVING);+}++void DefaultHealthCheckService::SetServingStatus(+    const grpc::string& service_name, bool serving) {+  std::unique_lock<std::mutex> lock(mu_);+  services_map_[service_name].SetServingStatus(serving ? SERVING : NOT_SERVING);+}++void DefaultHealthCheckService::SetServingStatus(bool serving) {+  const ServingStatus status = serving ? SERVING : NOT_SERVING;+  std::unique_lock<std::mutex> lock(mu_);+  for (auto& p : services_map_) {+    ServiceData& service_data = p.second;+    service_data.SetServingStatus(status);+  }+}++DefaultHealthCheckService::ServingStatus+DefaultHealthCheckService::GetServingStatus(+    const grpc::string& service_name) const {+  std::lock_guard<std::mutex> lock(mu_);+  auto it = services_map_.find(service_name);+  if (it == services_map_.end()) {+    return NOT_FOUND;+  }+  const ServiceData& service_data = it->second;+  return service_data.GetServingStatus();+}++void DefaultHealthCheckService::RegisterCallHandler(+    const grpc::string& service_name,+    std::shared_ptr<HealthCheckServiceImpl::CallHandler> handler) {+  std::unique_lock<std::mutex> lock(mu_);+  ServiceData& service_data = services_map_[service_name];+  service_data.AddCallHandler(handler /* copies ref */);+  handler->SendHealth(std::move(handler), service_data.GetServingStatus());+}++void DefaultHealthCheckService::UnregisterCallHandler(+    const grpc::string& service_name,+    std::shared_ptr<HealthCheckServiceImpl::CallHandler> handler) {+  std::unique_lock<std::mutex> lock(mu_);+  auto it = services_map_.find(service_name);+  if (it == services_map_.end()) return;+  ServiceData& service_data = it->second;+  service_data.RemoveCallHandler(std::move(handler));+  if (service_data.Unused()) {+    services_map_.erase(it);+  }+}++DefaultHealthCheckService::HealthCheckServiceImpl*+DefaultHealthCheckService::GetHealthCheckService(+    std::unique_ptr<ServerCompletionQueue> cq) {+  GPR_ASSERT(impl_ == nullptr);+  impl_.reset(new HealthCheckServiceImpl(this, std::move(cq)));+  return impl_.get();+}++//+// DefaultHealthCheckService::ServiceData+//++void DefaultHealthCheckService::ServiceData::SetServingStatus(+    ServingStatus status) {+  status_ = status;+  for (auto& call_handler : call_handlers_) {+    call_handler->SendHealth(call_handler /* copies ref */, status);+  }+}++void DefaultHealthCheckService::ServiceData::AddCallHandler(+    std::shared_ptr<HealthCheckServiceImpl::CallHandler> handler) {+  call_handlers_.insert(std::move(handler));+}++void DefaultHealthCheckService::ServiceData::RemoveCallHandler(+    std::shared_ptr<HealthCheckServiceImpl::CallHandler> handler) {+  call_handlers_.erase(std::move(handler));+}++//+// DefaultHealthCheckService::HealthCheckServiceImpl+//+ namespace { const char kHealthCheckMethodName[] = ""/grpc.health.v1.Health/Check"";+const char kHealthWatchMethodName[] = ""/grpc.health.v1.Health/Watch""; }  // namespace  DefaultHealthCheckService::HealthCheckServiceImpl::HealthCheckServiceImpl(-    DefaultHealthCheckService* service)-    : service_(service), method_(nullptr) {-  internal::MethodHandler* handler =-      new internal::RpcMethodHandler<HealthCheckServiceImpl, ByteBuffer,-                                     ByteBuffer>(-          std::mem_fn(&HealthCheckServiceImpl::Check), this);-  method_ = new internal::RpcServiceMethod(-      kHealthCheckMethodName, internal::RpcMethod::NORMAL_RPC, handler);-  AddMethod(method_);-}--Status DefaultHealthCheckService::HealthCheckServiceImpl::Check(-    ServerContext* context, const ByteBuffer* request, ByteBuffer* response) {-  // Decode request.-  std::vector<Slice> slices;-  if (!request->Dump(&slices).ok()) {-    return Status(StatusCode::INVALID_ARGUMENT, """");+    DefaultHealthCheckService* database,+    std::unique_ptr<ServerCompletionQueue> cq)+    : database_(database), cq_(std::move(cq)) {+  // Add Check() method.+  check_method_ = new internal::RpcServiceMethod(+      kHealthCheckMethodName, internal::RpcMethod::NORMAL_RPC, nullptr);+  AddMethod(check_method_);+  // Add Watch() method.+  watch_method_ = new internal::RpcServiceMethod(+      kHealthWatchMethodName, internal::RpcMethod::SERVER_STREAMING, nullptr);+  AddMethod(watch_method_);+  // Create serving thread.+  thread_ = std::unique_ptr<::grpc_core::Thread>(+      new ::grpc_core::Thread(""health_check_service"", Serve, this));+}++DefaultHealthCheckService::HealthCheckServiceImpl::~HealthCheckServiceImpl() {+  // We will reach here after the server starts shutting down.+  shutdown_ = true;+  {+    std::unique_lock<std::mutex> lock(cq_shutdown_mu_);+    cq_->Shutdown();+  }+  thread_->Join();+}++void DefaultHealthCheckService::HealthCheckServiceImpl::StartServingThread() {+  thread_->Start();+}++void DefaultHealthCheckService::HealthCheckServiceImpl::Serve(void* arg) {+  HealthCheckServiceImpl* service =+      reinterpret_cast<HealthCheckServiceImpl*>(arg);+  // TODO(juanlishen): This is a workaround to wait for the cq to be ready.+  // Need to figure out why cq is not ready after service starts.+  gpr_sleep_until(gpr_time_add(gpr_now(GPR_CLOCK_MONOTONIC),+                               gpr_time_from_seconds(1, GPR_TIMESPAN)));+  CheckCallHandler::CreateAndStart(service->cq_.get(), service->database_,+                                   service);+  WatchCallHandler::CreateAndStart(service->cq_.get(), service->database_,+                                   service);+  void* tag;+  bool ok;+  while (true) {+    if (!service->cq_->Next(&tag, &ok)) {","Yeah.  Given that we need the async implementation for the streaming method, it seemed like a good idea to use async for the unary method too.I agree that a single polling thread might prove a bottleneck in some cases.  I was thinking that if/when that happens, we could add some optional parameters to set the number of threads here.  But I would welcome alternative suggestions if you have any.I suspect that the number of threads here is the real issue, not the number of cqs.  Is there some reason we might want to spread over multiple cqs too?",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16402,213048336,2018-08-27T17:17:49Z,bazel/grpc_build_system.bzl,"@@ -24,178 +24,203 @@ #  # The set of pollers to test against if a test exercises polling-POLLERS = ['epollex', 'epollsig', 'epoll1', 'poll', 'poll-cv']+POLLERS = [""epollex"", ""epollsig"", ""epoll1"", ""poll"", ""poll-cv""]","Any reason for all the single-quote to double-quote changes in this PR? Skylark accepts either, correct? If Skylark prefers double-quote, please move the stylistic side of this PR into a separate PR so that this PR can just focus on the functional changes.",
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/16351,213121536,2018-08-27T21:27:51Z,src/cpp/server/health/default_health_check_service.cc,"@@ -30,29 +30,162 @@ #include ""src/cpp/server/health/health.pb.h""  namespace grpc {++//+// DefaultHealthCheckService+//++DefaultHealthCheckService::DefaultHealthCheckService() {+  services_map_[""""].SetServingStatus(SERVING);+}++void DefaultHealthCheckService::SetServingStatus(+    const grpc::string& service_name, bool serving) {+  std::unique_lock<std::mutex> lock(mu_);+  services_map_[service_name].SetServingStatus(serving ? SERVING : NOT_SERVING);+}++void DefaultHealthCheckService::SetServingStatus(bool serving) {+  const ServingStatus status = serving ? SERVING : NOT_SERVING;+  std::unique_lock<std::mutex> lock(mu_);+  for (auto& p : services_map_) {+    ServiceData& service_data = p.second;+    service_data.SetServingStatus(status);+  }+}++DefaultHealthCheckService::ServingStatus+DefaultHealthCheckService::GetServingStatus(+    const grpc::string& service_name) const {+  std::lock_guard<std::mutex> lock(mu_);+  auto it = services_map_.find(service_name);+  if (it == services_map_.end()) {+    return NOT_FOUND;+  }+  const ServiceData& service_data = it->second;+  return service_data.GetServingStatus();+}++void DefaultHealthCheckService::RegisterCallHandler(+    const grpc::string& service_name,+    std::shared_ptr<HealthCheckServiceImpl::CallHandler> handler) {+  std::unique_lock<std::mutex> lock(mu_);+  ServiceData& service_data = services_map_[service_name];+  service_data.AddCallHandler(handler /* copies ref */);+  handler->SendHealth(std::move(handler), service_data.GetServingStatus());+}++void DefaultHealthCheckService::UnregisterCallHandler(+    const grpc::string& service_name,+    std::shared_ptr<HealthCheckServiceImpl::CallHandler> handler) {+  std::unique_lock<std::mutex> lock(mu_);+  auto it = services_map_.find(service_name);+  if (it == services_map_.end()) return;+  ServiceData& service_data = it->second;+  service_data.RemoveCallHandler(std::move(handler));+  if (service_data.Unused()) {+    services_map_.erase(it);+  }+}++DefaultHealthCheckService::HealthCheckServiceImpl*+DefaultHealthCheckService::GetHealthCheckService(+    std::unique_ptr<ServerCompletionQueue> cq) {+  GPR_ASSERT(impl_ == nullptr);+  impl_.reset(new HealthCheckServiceImpl(this, std::move(cq)));+  return impl_.get();+}++//+// DefaultHealthCheckService::ServiceData+//++void DefaultHealthCheckService::ServiceData::SetServingStatus(+    ServingStatus status) {+  status_ = status;+  for (auto& call_handler : call_handlers_) {+    call_handler->SendHealth(call_handler /* copies ref */, status);+  }+}++void DefaultHealthCheckService::ServiceData::AddCallHandler(+    std::shared_ptr<HealthCheckServiceImpl::CallHandler> handler) {+  call_handlers_.insert(std::move(handler));+}++void DefaultHealthCheckService::ServiceData::RemoveCallHandler(+    std::shared_ptr<HealthCheckServiceImpl::CallHandler> handler) {+  call_handlers_.erase(std::move(handler));+}++//+// DefaultHealthCheckService::HealthCheckServiceImpl+//+ namespace { const char kHealthCheckMethodName[] = ""/grpc.health.v1.Health/Check"";+const char kHealthWatchMethodName[] = ""/grpc.health.v1.Health/Watch""; }  // namespace  DefaultHealthCheckService::HealthCheckServiceImpl::HealthCheckServiceImpl(-    DefaultHealthCheckService* service)-    : service_(service), method_(nullptr) {-  internal::MethodHandler* handler =-      new internal::RpcMethodHandler<HealthCheckServiceImpl, ByteBuffer,-                                     ByteBuffer>(-          std::mem_fn(&HealthCheckServiceImpl::Check), this);-  method_ = new internal::RpcServiceMethod(-      kHealthCheckMethodName, internal::RpcMethod::NORMAL_RPC, handler);-  AddMethod(method_);-}--Status DefaultHealthCheckService::HealthCheckServiceImpl::Check(-    ServerContext* context, const ByteBuffer* request, ByteBuffer* response) {-  // Decode request.-  std::vector<Slice> slices;-  if (!request->Dump(&slices).ok()) {-    return Status(StatusCode::INVALID_ARGUMENT, """");+    DefaultHealthCheckService* database,+    std::unique_ptr<ServerCompletionQueue> cq)+    : database_(database), cq_(std::move(cq)) {+  // Add Check() method.+  check_method_ = new internal::RpcServiceMethod(+      kHealthCheckMethodName, internal::RpcMethod::NORMAL_RPC, nullptr);+  AddMethod(check_method_);+  // Add Watch() method.+  watch_method_ = new internal::RpcServiceMethod(+      kHealthWatchMethodName, internal::RpcMethod::SERVER_STREAMING, nullptr);+  AddMethod(watch_method_);+  // Create serving thread.+  thread_ = std::unique_ptr<::grpc_core::Thread>(+      new ::grpc_core::Thread(""health_check_service"", Serve, this));+}++DefaultHealthCheckService::HealthCheckServiceImpl::~HealthCheckServiceImpl() {+  // We will reach here after the server starts shutting down.+  shutdown_ = true;+  {+    std::unique_lock<std::mutex> lock(cq_shutdown_mu_);+    cq_->Shutdown();+  }+  thread_->Join();+}++void DefaultHealthCheckService::HealthCheckServiceImpl::StartServingThread() {+  thread_->Start();+}++void DefaultHealthCheckService::HealthCheckServiceImpl::Serve(void* arg) {+  HealthCheckServiceImpl* service =+      reinterpret_cast<HealthCheckServiceImpl*>(arg);+  // TODO(juanlishen): This is a workaround to wait for the cq to be ready.+  // Need to figure out why cq is not ready after service starts.+  gpr_sleep_until(gpr_time_add(gpr_now(GPR_CLOCK_MONOTONIC),+                               gpr_time_from_seconds(1, GPR_TIMESPAN)));+  CheckCallHandler::CreateAndStart(service->cq_.get(), service->database_,+                                   service);+  WatchCallHandler::CreateAndStart(service->cq_.get(), service->database_,+                                   service);+  void* tag;+  bool ok;+  while (true) {+    if (!service->cq_->Next(&tag, &ok)) {","In an original implementation, we did the async service handling by requesting something on easy async cq in a similar way as the Unimplemented. The benefit of that is 1. we do not need to create a cq behind the back and 2 the handling scales out to all cq/threads automatically. But it would be more complicated and not as self-contained as this implementation (especially for a streaming call). So I think this is good.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16407,213693367,2018-08-29T14:12:07Z,include/grpcpp/impl/codegen/metadata_map.h,"@@ -32,7 +36,31 @@ class MetadataMap {     g_core_codegen_interface->grpc_metadata_array_destroy(&arr_);   } +  grpc::string GetBinaryErrorDetails() {+    // if filled, extract from the multimap for O(log(n))+    if (filled) {+      auto iter = map_.find(kBinaryErrorDetailsKey);+      if (iter != map_.end()) {+        return grpc::string(iter->second.begin(), iter->second.length());+      }+    }+    // if not yet filled, take the O(n) lookup to avoid allocating the","IMHO, a better approach for this would be to plumb the binary error details through core as a first-class citizen (i.e., the same way we pass the status code and message), so that it's not returned as part of metadata to begin with.  But we can do that as a separate PR.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16407,213715023,2018-08-29T15:02:33Z,include/grpcpp/impl/codegen/metadata_map.h,"@@ -32,7 +36,31 @@ class MetadataMap {     g_core_codegen_interface->grpc_metadata_array_destroy(&arr_);   } +  grpc::string GetBinaryErrorDetails() {+    // if filled, extract from the multimap for O(log(n))+    if (filled) {+      auto iter = map_.find(kBinaryErrorDetailsKey);+      if (iter != map_.end()) {+        return grpc::string(iter->second.begin(), iter->second.length());+      }+    }+    // if not yet filled, take the O(n) lookup to avoid allocating the+    // multimap until it is requested.+    else {+      for (size_t i = 0; i < arr_.count; i++) {+        if (grpc_slice_str_cmp(arr_.metadata[i].key, kBinaryErrorDetailsKey)) {+          return grpc::string(reinterpret_cast<const char*>(+                                  GRPC_SLICE_START_PTR(arr_.metadata[i].value)),+                              GRPC_SLICE_LENGTH(arr_.metadata[i].value));+        }+      }+    }+    return grpc::string();+  }+   void FillMap() {","Hmm...  @vjpai, is this class considered part of our public API?  I want to make sure it's okay to remove the `FillMap()` method.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16492,213829729,2018-08-29T20:50:27Z,test/cpp/end2end/client_callback_end2end_test.cc,"@@ -0,0 +1,126 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <functional>+#include <mutex>++#include <grpcpp/channel.h>+#include <grpcpp/client_context.h>+#include <grpcpp/create_channel.h>+#include <grpcpp/generic/generic_stub.h>+#include <grpcpp/impl/codegen/proto_utils.h>+#include <grpcpp/server.h>+#include <grpcpp/server_builder.h>+#include <grpcpp/server_context.h>+#include <grpcpp/support/client_callback.h>++#include ""src/proto/grpc/testing/echo.grpc.pb.h""+#include ""test/core/util/test_config.h""+#include ""test/cpp/end2end/test_service_impl.h""+#include ""test/cpp/util/byte_buffer_proto_helper.h""++#include <gtest/gtest.h>++namespace grpc {+namespace testing {+namespace {++class ClientCallbackEnd2endTest : public ::testing::Test {+ protected:+  ClientCallbackEnd2endTest() {}++  void SetUp() override {+    ServerBuilder builder;+    builder.RegisterService(&service_);++    server_ = builder.BuildAndStart();+    is_server_started_ = true;+  }++  void ResetStub() {+    ChannelArguments args;+    channel_ = server_->InProcessChannel(args);+    stub_.reset(new GenericStub(channel_));+  }++  void TearDown() override {+    if (is_server_started_) {+      server_->Shutdown();+    }+  }++  void SendRpcs(int num_rpcs) {+    const grpc::string kMethodName(""/grpc.testing.EchoTestService/Echo"");+    grpc::string test_string("""");+    for (int i = 0; i < num_rpcs; i++) {+      EchoRequest request;+      std::unique_ptr<ByteBuffer> send_buf;+      ByteBuffer recv_buf;+      ClientContext cli_ctx;++      test_string += ""Hello world. "";+      request.set_message(test_string);+      send_buf = SerializeToByteBuffer(&request);++      std::mutex mu;+      std::condition_variable cv;+      bool done;+      stub_->experimental().UnaryCall(","I think we need to move away from adding prefixes and suffixes on the method names. The reason for this (which I also discussed in the internal design document) is that we don't know what method names are being used in the user's `.proto` file and they could very well have a method name with the prefix or suffix that we're planning to use.Technically those reasons don't apply to this particular use since this is a generic stub, but I think it's never too soon to break the antipattern.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16492,213871989,2018-08-30T00:13:59Z,test/cpp/end2end/client_callback_end2end_test.cc,"@@ -0,0 +1,126 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <functional>+#include <mutex>++#include <grpcpp/channel.h>+#include <grpcpp/client_context.h>+#include <grpcpp/create_channel.h>+#include <grpcpp/generic/generic_stub.h>+#include <grpcpp/impl/codegen/proto_utils.h>+#include <grpcpp/server.h>+#include <grpcpp/server_builder.h>+#include <grpcpp/server_context.h>+#include <grpcpp/support/client_callback.h>++#include ""src/proto/grpc/testing/echo.grpc.pb.h""+#include ""test/core/util/test_config.h""+#include ""test/cpp/end2end/test_service_impl.h""+#include ""test/cpp/util/byte_buffer_proto_helper.h""++#include <gtest/gtest.h>++namespace grpc {+namespace testing {+namespace {++class ClientCallbackEnd2endTest : public ::testing::Test {+ protected:+  ClientCallbackEnd2endTest() {}++  void SetUp() override {+    ServerBuilder builder;+    builder.RegisterService(&service_);++    server_ = builder.BuildAndStart();+    is_server_started_ = true;+  }++  void ResetStub() {+    ChannelArguments args;+    channel_ = server_->InProcessChannel(args);+    stub_.reset(new GenericStub(channel_));+  }++  void TearDown() override {+    if (is_server_started_) {+      server_->Shutdown();+    }+  }++  void SendRpcs(int num_rpcs) {+    const grpc::string kMethodName(""/grpc.testing.EchoTestService/Echo"");+    grpc::string test_string("""");+    for (int i = 0; i < num_rpcs; i++) {+      EchoRequest request;+      std::unique_ptr<ByteBuffer> send_buf;+      ByteBuffer recv_buf;+      ClientContext cli_ctx;++      test_string += ""Hello world. "";+      request.set_message(test_string);+      send_buf = SerializeToByteBuffer(&request);++      std::mutex mu;+      std::condition_variable cv;+      bool done = false;+      stub_->experimental().UnaryCall(","Yes, this is temporary; I mentioned this in the include file. We can't make it a ""real"" part of the API until we go through the gRFC process, and I don't want to do that until we are really sure that this will work.",
42048362,mhaidrygoog,https://api.github.com/repos/grpc/grpc/pulls/16492,214104653,2018-08-30T16:52:50Z,include/grpcpp/impl/codegen/callback_common.h,"@@ -0,0 +1,79 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPCPP_IMPL_CODEGEN_CALLBACK_COMMON_H+#define GRPCPP_IMPL_CODEGEN_CALLBACK_COMMON_H++#include <functional>++#include <grpcpp/impl/codegen/call.h>+#include <grpcpp/impl/codegen/channel_interface.h>+#include <grpcpp/impl/codegen/config.h>+#include <grpcpp/impl/codegen/core_codegen_interface.h>+#include <grpcpp/impl/codegen/status.h>++// Forward declarations+namespace grpc_core {+class CQCallbackInterface;+};++namespace grpc {+namespace internal {++class CallbackWithStatusTag {",These two classes seem to have some common code. Would it make sense to have a common CallBackWithTag class and may be add these 2 as sub classes?,OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16492,214114441,2018-08-30T17:24:43Z,include/grpcpp/impl/codegen/callback_common.h,"@@ -0,0 +1,79 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPCPP_IMPL_CODEGEN_CALLBACK_COMMON_H+#define GRPCPP_IMPL_CODEGEN_CALLBACK_COMMON_H++#include <functional>++#include <grpcpp/impl/codegen/call.h>+#include <grpcpp/impl/codegen/channel_interface.h>+#include <grpcpp/impl/codegen/config.h>+#include <grpcpp/impl/codegen/core_codegen_interface.h>+#include <grpcpp/impl/codegen/status.h>++// Forward declarations+namespace grpc_core {+class CQCallbackInterface;+};++namespace grpc {+namespace internal {++class CallbackWithStatusTag {","I wouldn't add an extra level of inheritance but it might be ok to do that through composition. But the reality is that these classes are small and formulaic, so I would prefer not to do that: it might take more work to stub out the classes than these classes are actually worth.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16460,214437073,2018-08-31T18:18:20Z,src/core/ext/transport/chttp2/transport/chttp2_transport.cc,"@@ -2887,17 +2903,20 @@ bool Chttp2IncomingByteStream::Next(size_t max_size_hint,   } } +void Chttp2IncomingByteStream::EnsureStreamDecompressionCtxExists() {",Suggest renaming to `MaybeCreateStreamDecompressionCtx` since that's more consistent with our general naming patterns,OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16543,214521648,2018-09-01T19:40:51Z,src/csharp/Grpc.Core/Internal/NativeMetadataCredentialsPlugin.cs,"@@ -68,7 +68,8 @@ private void NativeMetadataInterceptorHandler(IntPtr statePtr, IntPtr serviceUrl             }             catch (Exception e)             {-                Native.grpcsharp_metadata_credentials_notify_from_plugin(callbackPtr, userDataPtr, MetadataArraySafeHandle.Create(Metadata.Empty), StatusCode.Unknown, GetMetadataExceptionStatusMsg);+                var detail = GetMetadataExceptionStatusMsg + "" "" + e.ToString();","nit: it seems not ideal that the same exception handler code appears twice.I could see a couple of possible cleanups:a) put this call creds exception handler code into a (small) utility and call that twiceb) looking more closely, I actually think that this exception handler here is almost dead code leftover from [an earlier change that I made :)](https://github.com/grpc/grpc/commit/27670c81a9beec3365ab5b373c707a847c0df503). That is, the only way to get an Exception to fire here that I can think of if is the `QueueUserWorkItem` call threw an exception (which would not happen AFAIK under reasonable circumstances). So it might make sense to    * get rid of this exception handler   * have it attach a different status message to emphasize where it came from",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16552,214967676,2018-09-04T15:44:43Z,src/csharp/Grpc.Core/ServerCredentials.cs,"@@ -57,42 +57,106 @@ internal override ServerCredentialsSafeHandle ToNativeCredentials()         }     } +    /// <summary>+    /// Modes of requesting client's SSL certificate by the server.+    /// Corresponds to <c>grpc_ssl_client_certificate_request_type</c>.+    /// </summary>+    public enum SslClientCertificateRequestType {","Up for discussion: I don't like that the `SslClientCertificateRequestType.RequestAndRequireClientCertificateButDontVerify` literals feel extremely long, so perhaps a shorter name should be used for the type at least (ie. for `SslClientCertificateRequestType`).",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16489,215022196,2018-09-04T18:34:05Z,test/core/util/port_isolated_runtime_environment.cc,"@@ -28,22 +31,24 @@ #include ""test/core/util/port.h""  #define MIN_PORT 49152-#define MAX_PORT 65536+#define MAX_PORT 65535 -int get_random_starting_port() {+static int get_random_port_offset() {   srand(gpr_now(GPR_CLOCK_REALTIME).tv_nsec);-  return rand() % (MAX_PORT - MIN_PORT + 1) + MIN_PORT;+  double rnd = static_cast<double>(rand()) /+               (static_cast<double>(RAND_MAX) + 1.0);  // values from [0,1)+  return static_cast<int>(rnd * (MAX_PORT - MIN_PORT + 1)); } -static int s_allocated_port = get_random_starting_port();+static int s_initial_offset = get_random_port_offset();+static gpr_atm s_pick_counter = 0;  int grpc_pick_unused_port_or_die(void) {-  int allocated_port = s_allocated_port++;-  if (s_allocated_port == MAX_PORT) {-    s_allocated_port = MIN_PORT;-  }--  return allocated_port;+  int orig_counter_val =+      static_cast<int>(gpr_atm_full_fetch_add(&s_pick_counter, 1));+  GPR_ASSERT(orig_counter_val < (MAX_PORT - MIN_PORT + 1));","why is it problematic?   You want to prevent tests from reusing a port that has been already allocated by another test to prevent hard-to-debug issues caused by crosstalk of tests.  With normal port server, picking the port will also fail if there are no ports available.  The ""isolated runtime"" implementation doesn't support returning used ports back to port server - so asserting once we exhausted all the available ports is the right thing to do.Realistically, as each test binary runs in a separate container, exhausting the available port won't happen in practice (you would need a single test binary that goes through several thousand ports), but if someone writes an exotic test that uses too many ports in the future, we do want to know we ran out of ports rather then acting like everything is fine and then end up rootcausing flakes to find out we've been reusing ports silently.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16543,215050567,2018-09-04T20:10:35Z,src/csharp/Grpc.Core/Internal/NativeMetadataCredentialsPlugin.cs,"@@ -68,7 +68,8 @@ private void NativeMetadataInterceptorHandler(IntPtr statePtr, IntPtr serviceUrl             }             catch (Exception e)             {-                Native.grpcsharp_metadata_credentials_notify_from_plugin(callbackPtr, userDataPtr, MetadataArraySafeHandle.Create(Metadata.Empty), StatusCode.Unknown, GetMetadataExceptionStatusMsg);+                var detail = GetMetadataExceptionStatusMsg + "" "" + e.ToString();","Good catch. We need to catch an exception here because throwing when inside a callback from native code can crash the application.Also, seems like attempting to call `grpcsharp_metadata_credentials_notify_from_plugin` from here is against the C core contract anyway as it should be done from another thread.Updated the code  to just log an error (which should never happen anyway unless something is horribly wrong). PTAL.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16556,215310609,2018-09-05T15:09:42Z,src/csharp/Grpc.Core.Tests/ChannelConnectivityTest.cs,"@@ -73,6 +73,24 @@ public async Task Channel_WaitForStateChangedAsync()             Assert.AreEqual(ChannelState.Ready, channel.State);         } +        [Test]+        public async Task Channel_TryWaitForStateChangedAsync()+        {+            helper.UnaryHandler = new UnaryServerMethod<string, string>((request, context) =>+            {+                return Task.FromResult(request);+            });++            Assert.IsFalse(await channel.TryWaitForStateChangedAsync(channel.State, DateTime.UtcNow.AddMilliseconds(10)));++            var stateChangedTask = channel.TryWaitForStateChangedAsync(channel.State);++            await Calls.AsyncUnaryCall(helper.CreateUnaryCall(), ""abc"");","Good point about the test being more complex than needed. I used ConnectAsync to simplify.About introducing TryConnectAsync: we could add it but no one is actually asking for it and I'd like to prevent increasing the API surface when not necessary. Also one of the use cases for `TryWaitForStateChangedAsync` is continuous monitoring of channel's connectivity state which means that the method will be run in a loop, possibly with short timeout (so not incurring extra overhead when throwing an exception seem important)  I don't see the same problem for ConnectAsync.",OK
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/16544,215360649,2018-09-05T17:31:00Z,include/grpcpp/impl/codegen/async_stream.h,"@@ -496,6 +496,13 @@ class ClientAsyncReaderWriter final     assert(size == sizeof(ClientAsyncReaderWriter));   } +  // This operator should never be called as the memory should be freed as part+  // of the arena destruction. It only exists to provide a matching operator+  // delete to the operator new so that some compilers will not complain (see+  // https://github.com/grpc/grpc/issues/11301) Note at the time of adding this+  // there are no tests catching the compiler warning.+  static void operator delete(void*, void*) { assert(0); }",I do not know why vs is complaining while other compilers are not. I assume it will complain about the AsyncReader when it is used. So I would add it to prevent similar issues coming back.,OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16014,215416231,2018-09-05T20:33:29Z,src/ruby/spec/pb/codegen/package_option_spec.rb,"@@ -0,0 +1,53 @@+# Copyright 2018 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++require 'spec_helper'+require 'open3'+require 'tmpdir'++describe 'Code Generation Options' do+  it 'should generate and respect package options' do+    unless system('which grpc_ruby_plugin') && system('which protoc')+      skip 'protoc || grpc_ruby_plugin missing, cannot verify package code-gen'+    end++    root_dir = File.join(File.dirname(__FILE__), '..', '..', '..', '..')+    pb_dir = File.join(root_dir, 'proto')++    # Regenerate it+    plugin, = Open3.capture2('which', 'grpc_ruby_plugin')+    plugin = plugin.strip+    Dir.mktmpdir(nil, File.dirname(__FILE__)) do |tmp_dir|+      pid = spawn(+        'protoc',+        '-I.',+        'grpc/testing/package_options.proto',+        ""--grpc_out=#{tmp_dir}"", # generate the service+        ""--ruby_out=#{tmp_dir}"", # generate the definitions+        ""--plugin=protoc-gen-grpc=#{plugin}"",+        chdir: pb_dir)+      Process.wait(pid)++      begin+        $LOAD_PATH.push(tmp_dir)++        # this will fail if the package structure of the generated service does+        # not match the generated protobuf defintions+        expect(require('grpc/testing/package_options_services_pb')).to be_truthy","nit: this check relies on some implicit things going on, e.g. that the protoc compiler generates the ruby message definitions with respect for the `ruby_package` option (correct?).Can we increase the strictness of this check to make clear that the services and protobuf messages were both generated in the correct module? E.g., perhaps assert that the expected class exists only after loading the `_pb` file?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16552,215462789,2018-09-06T00:14:41Z,src/csharp/Grpc.IntegrationTesting/SslCredentialsTest.cs,"@@ -72,19 +76,133 @@ public void Init()         [OneTimeTearDown]         public void Cleanup()         {-            channel.ShutdownAsync().Wait();-            server.ShutdownAsync().Wait();+            if (channel != null)+            {+                channel.ShutdownAsync().Wait();+            }+            if (server != null)+            {+                server.ShutdownAsync().Wait();+            }         }          [Test]-        public void AuthenticatedClientAndServer()+        public async Task NoClientCert_DontRequestClientCertificate_Accepted()         {-            var response = client.UnaryCall(new SimpleRequest { ResponseSize = 10 });-            Assert.AreEqual(10, response.Payload.Body.Length);+            InitClientAndServer(+                clientAddKeyCertPair: false,+                clientCertRequestType: SslClientCertificateRequestType.DontRequestClientCertificate);++            await CheckAccepted(expectPeerAuthenticated: false);         }          [Test]-        public async Task AuthContextIsPopulated()+        public async Task ClientWithCert_DontRequestClientCertificate_AcceptedButPeerNotAuthenticated()+        {+            InitClientAndServer(+                clientAddKeyCertPair: true,+                clientCertRequestType: SslClientCertificateRequestType.DontRequestClientCertificate);++            await CheckAccepted(expectPeerAuthenticated: false);+        }++        [Test]+        public async Task NoClientCert_RequestClientCertificateButDontVerify_Accepted()+        {+            InitClientAndServer(+                clientAddKeyCertPair: false,+                clientCertRequestType: SslClientCertificateRequestType.RequestClientCertificateButDontVerify);++            await CheckAccepted(expectPeerAuthenticated: false);+        }++        [Test]+        public async Task NoClientCert_RequestClientCertificateAndVerify_Accepted()+        {+            InitClientAndServer(+                clientAddKeyCertPair: false,+                clientCertRequestType: SslClientCertificateRequestType.RequestClientCertificateAndVerify);++            await CheckAccepted(expectPeerAuthenticated: false);+        }++        [Test]+        public async Task ClientWithCert_RequestAndRequireClientCertificateButDontVerify_Accepted()+        {+            InitClientAndServer(+                clientAddKeyCertPair: true,+                clientCertRequestType: SslClientCertificateRequestType.RequestAndRequireClientCertificateButDontVerify);++            await CheckAccepted(expectPeerAuthenticated: true);+            await CheckAuthContextIsPopulated();+        }++        [Test]+        public async Task ClientWithCert_RequestAndRequireClientCertificateAndVerify_Accepted()+        {+            InitClientAndServer(+                clientAddKeyCertPair: true,+                clientCertRequestType: SslClientCertificateRequestType.RequestAndRequireClientCertificateAndVerify);++            await CheckAccepted(expectPeerAuthenticated: true);+            await CheckAuthContextIsPopulated();+        }++        [Test]+        public void NoClientCert_RequestAndRequireClientCertificateButDontVerify_Rejected()+        {+            InitClientAndServer(+                clientAddKeyCertPair: false,+                clientCertRequestType: SslClientCertificateRequestType.RequestAndRequireClientCertificateButDontVerify);++            CheckRejected();+        }++        [Test]+        public void NoClientCert_RequestAndRequireClientCertificateAndVerify_Rejected()+        {+            InitClientAndServer(+                clientAddKeyCertPair: false,+                clientCertRequestType: SslClientCertificateRequestType.RequestAndRequireClientCertificateAndVerify);++            CheckRejected();+        }++        [Test]+        public void Constructor_LegacyForceClientAuth()+        {+            var creds = new SslServerCredentials(new[] { keyCertPair }, rootCert, true);+            Assert.AreEqual(SslClientCertificateRequestType.RequestAndRequireClientCertificateAndVerify, creds.ClientCertificateRequest);++            var creds2 = new SslServerCredentials(new[] { keyCertPair }, rootCert, false);+            Assert.AreEqual(SslClientCertificateRequestType.DontRequestClientCertificate, creds2.ClientCertificateRequest);+        }++        [Test]+        public void Constructor_NullRootCerts()+        {+            var keyCertPairs = new[] { keyCertPair };+            new SslServerCredentials(keyCertPairs, null, SslClientCertificateRequestType.DontRequestClientCertificate);","nit: use e.g. `Assert.DoesNotThrow` here?Otherwise, the plain object instantiations can look somewhat like unused/dead code.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16568,215690625,2018-09-06T16:22:04Z,tools/internal_ci/linux/grpc_tsan_on_foundry.sh,"@@ -15,4 +15,5 @@  export UPLOAD_TEST_RESULTS=true EXTRA_FLAGS=""--copt=-gmlt --strip=never --copt=-fsanitize=thread --linkopt=-fsanitize=thread --test_timeout=3600 --action_env=TSAN_OPTIONS=suppressions=test/core/util/tsan_suppressions.txt:halt_on_error=1:second_deadlock_stack=1 --cache_test_results=no""-github/grpc/tools/internal_ci/linux/grpc_bazel_on_foundry_base.sh ""${EXTRA_FLAGS}""+EXCLUDE_TESTS=""-//test/cpp/qps/...""","looks like under //test/cpp/qps there's many more tests than what we're trying to disablebased on `'exclude_configs': ['tsan', 'asan']`  from https://github.com/grpc/grpc/blob/ceecf80283e6ca184df587f76ed053f1f5295b7f/test/cpp/qps/gen_build_yaml.py#L93See the test cases being run here:https://source.cloud.google.com/results/invocations/c21d1218-1ee5-4c3a-95ce-97191d102ba8/targetsWe probably need to be more specific about the set of tests we exclude.",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/16488,216196910,2018-09-10T04:45:34Z,src/core/lib/transport/metadata_batch.cc,"@@ -25,11 +25,103 @@  #include <grpc/support/alloc.h> #include <grpc/support/log.h>+#include <grpc/support/string_util.h>  #include ""src/core/lib/profiling/timers.h"" #include ""src/core/lib/slice/slice_internal.h"" #include ""src/core/lib/slice/slice_string_helpers.h"" +static_hpack_table_metadata_info static_hpack_table_metadata[] = {+    {0, 0, GRPC_BATCH_CALLOUTS_COUNT},  // NOT USED+    {GRPC_MDELEM_AUTHORITY_EMPTY_INDEX, 10 + 32, GRPC_BATCH_AUTHORITY},+    {GRPC_MDELEM_METHOD_GET_INDEX, 10 + 32, GRPC_BATCH_METHOD},+    {GRPC_MDELEM_METHOD_POST_INDEX, 11 + 32, GRPC_BATCH_METHOD},+    {GRPC_MDELEM_PATH_SLASH_INDEX, 6 + 32, GRPC_BATCH_PATH},+    {GRPC_MDELEM_PATH_SLASH_INDEX_DOT_HTML_INDEX, 16 + 32, GRPC_BATCH_PATH},+    {GRPC_MDELEM_SCHEME_HTTP_INDEX, 11 + 32, GRPC_BATCH_SCHEME},+    {GRPC_MDELEM_SCHEME_HTTPS_INDEX, 12 + 32, GRPC_BATCH_SCHEME},+    {GRPC_MDELEM_STATUS_200_INDEX, 10 + 32, GRPC_BATCH_STATUS},+    {GRPC_MDELEM_STATUS_204_INDEX, 10 + 32, GRPC_BATCH_STATUS},+    {GRPC_MDELEM_STATUS_206_INDEX, 10 + 32, GRPC_BATCH_STATUS},+    {GRPC_MDELEM_STATUS_304_INDEX, 10 + 32, GRPC_BATCH_STATUS},+    {GRPC_MDELEM_STATUS_400_INDEX, 10 + 32, GRPC_BATCH_STATUS},+    {GRPC_MDELEM_STATUS_404_INDEX, 10 + 32, GRPC_BATCH_STATUS},+    {GRPC_MDELEM_STATUS_500_INDEX, 10 + 32, GRPC_BATCH_STATUS},+    {GRPC_MDELEM_ACCEPT_CHARSET_EMPTY_INDEX, 14 + 32,+     GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_ACCEPT_ENCODING_GZIP_DEFLATE_INDEX, 28 + 32,+     GRPC_BATCH_ACCEPT_ENCODING},+    {GRPC_MDELEM_MDELEM_ACCEPT_LANGUAGE_EMPTY_INDEX, 15 + 32,+     GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_MDELEM_ACCEPT_RANGES_EMPTY_INDEX, 13 + 32,+     GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_ACCEPT_EMPTY_INDEX, 6 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_ACCESS_CONTROL_ALLOW_ORIGIN_EMPTY_INDEX, 27 + 32,+     GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_AGE_EMPTY_INDEX, 3 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_ALLOW_EMPTY_INDEX, 5 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_AUTHORIZATION_EMPTY_INDEX, 13 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_CACHE_CONTROL_EMPTY_INDEX, 13 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_CONTENT_DISPOSITION_EMPTY_INDEX, 19 + 32,+     GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_CONTENT_ENCODING_EMPTY_INDEX, 16 + 32,+     GRPC_BATCH_CONTENT_ENCODING},+    {GRPC_MDELEM_CONTENT_LANGUAGE_EMPTY_INDEX, 16 + 32,+     GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_CONTENT_LENGTH_EMPTY_INDEX, 14 + 32,+     GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_CONTENT_LOCATION_EMPTY_INDEX, 16 + 32,+     GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_CONTENT_RANGE_EMPTY_INDEX, 13 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_CONTENT_TYPE_EMPTY_INDEX, 12 + 32, GRPC_BATCH_CONTENT_TYPE},+    {GRPC_MDELEM_COOKIE_EMPTY_INDEX, 6 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_DATE_EMPTY_INDEX, 4 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_ETAG_EMPTY_INDEX, 4 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_EXPECT_EMPTY_INDEX, 6 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_EXPIRES_EMPTY_INDEX, 7 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_FROM_EMPTY_INDEX, 4 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_HOST_EMPTY_INDEX, 4 + 32, GRPC_BATCH_HOST},+    {GRPC_MDELEM_IF_MATCH_EMPTY_INDEX, 8 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_IF_MODIFIED_SINCE_EMPTY_INDEX, 17 + 32,+     GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_IF_NONE_MATCH_EMPTY_INDEX, 13 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_IF_RANGE_EMPTY_INDEX, 8 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_IF_UNMODIFIED_SINCE_EMPTY_INDEX, 19 + 32,+     GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_LAST_MODIFIED_EMPTY_INDEX, 13 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_LINK_EMPTY_INDEX, 4 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_LOCATION_EMPTY_INDEX, 8 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_MAX_FORWARDS_EMPTY_INDEX, 12 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_PROXY_AUTHENTICATE_EMPTY_INDEX, 18 + 32,+     GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_PROXY_AUTHORIZATION_EMPTY_INDEX, 19 + 32,+     GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_RANGE_EMPTY_INDEX, 5 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_REFERER_EMPTY_INDEX, 7 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_REFRESH_EMPTY_INDEX, 7 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_RETRY_AFTER_EMPTY_INDEX, 11 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_SERVER_EMPTY_INDEX, 6 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_COOKIE_EMPTY_INDEX, 10 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_STRICT_TRANSPORT_SECURITY_EMPTY_INDEX, 25 + 32,+     GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_TRANSFER_ENCODING_EMPTY_INDEX, 17 + 32,+     GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_USER_AGENT_EMPTY_INDEX, 10 + 32, GRPC_BATCH_USER_AGENT},+    {GRPC_MDELEM_VARY_EMPTY_INDEX, 4 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_VIA_EMPTY_INDEX, 3 + 32, GRPC_BATCH_CALLOUTS_COUNT},+    {GRPC_MDELEM_WWW_AUTHENTICATE_EMPTY_INDEX, 16 + 32,+     GRPC_BATCH_CALLOUTS_COUNT},+};++/* This is a faster check for seeing if a mdelem index is used or not. To verify+   that the index value is valid, use 'is_valid_mdelem_index' */+static bool is_mdelem_index_used(uint8_t index);","I'm aware that this function, as well as `set_mdelem_index_unused`, should probably take a linked_mdelem instead of an uint8_t or a uint8_t*. I'm also aware that in the places where I'm setting the linked_mdelem's index to 0, I should really be calling `set_mdelem_index_unused`. I'll make these changes in a later PR because the tests have been flaky/difficult (including unrelated infrastructure errors) and I'd like to get this in. ",OK
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/16492,216405008,2018-09-10T17:21:06Z,include/grpcpp/impl/codegen/call.h,"@@ -654,7 +657,12 @@ class CallOpSet : public CallOpSetInterface,    void set_output_tag(void* return_tag) { return_tag_ = return_tag; } +  void* cq_tag() override { return cq_tag_; }++  void set_cq_tag(void* cq_tag) { cq_tag_ = cq_tag; }","If I understand correctly, setting a cq_tag other than this means we are by-passing the FinalizeResult of this class, and thus it needs to be called explicitly in the new tag. We should document this.",OK
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/16492,216410631,2018-09-10T17:37:32Z,src/cpp/common/callback_common.cc,"@@ -0,0 +1,117 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <functional>++#include <grpcpp/impl/codegen/callback_common.h>+#include <grpcpp/impl/codegen/status.h>++#include ""src/core/lib/gprpp/memory.h""+#include ""src/core/lib/surface/completion_queue.h""++namespace grpc {+namespace internal {++namespace {+class CallbackWithSuccessImpl : public grpc_core::CQCallbackInterface {+ public:+  static void operator delete(void* ptr, std::size_t size) {+    assert(size == sizeof(CallbackWithSuccessImpl));+  }","There used to be the issue with VS2015 asking for a delete(void*, void*). I am not sure whether we should proactively adding it to those classes or wait for people to complain...",
309153,iainmcgin,https://api.github.com/repos/grpc/grpc/pulls/16014,216711137,2018-09-11T15:23:22Z,AUTHORS,"@@ -1 +1,2 @@ Google Inc.+WeWork Companies Inc.","From your CONTRIBUTING.md: ""please consider adding an entry to the AUTHORS file listing the copyright holder for the contribution (yourself, if you are signing the individual CLA, or your company, for corporate CLAs)""",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16611,216934317,2018-09-12T08:09:51Z,doc/interop-test-descriptions.md,"@@ -944,6 +944,11 @@ the experimental flag, `soak_iterations`. This tests puts stress on several gRPC components; the resolver, the load  balancer, and the RPC hotpath. +#### long_connection","One thought BTW: though we chatted earlier and decided on using unary RPC's, on second thought I'm thinking it will also be useful to run a ""long connection"" bidi streaming test case <i>in addition</i>.... just to test some things that this test won't be as well suited for.So while this test would be good to have, I think it would <i>also</i> be good to have a single long ""bidi streaming"" version of it.... which could go into a separate PR, but I'd be open to add it here",
42048362,mhaidrygoog,https://api.github.com/repos/grpc/grpc/pulls/16541,217118918,2018-09-12T17:21:15Z,include/grpcpp/impl/codegen/client_callback.h,"@@ -90,6 +90,149 @@ class CallbackUnaryCallImpl { };  }  // namespace internal++/// TODO(vjpai): Move these contents out of experimental+/// TODO(vjpai): Merge with contents of sync_stream.h or async_stream.h if+/// possible, including getting their interfaces into the interface classes+namespace experimental {++// Forward declaration+template <class W, class R>+class ClientCallbackReaderWriter;++/// TODO(vjpai): Put this factory into ::grpc::internal when possible+template <class W, class R>+class ClientCallbackReaderWriterFactory {+ public:+  static ::grpc::experimental::ClientCallbackReaderWriter<W, R>* Create(+      ::grpc::ChannelInterface* channel,+      const ::grpc::internal::RpcMethod& method, ClientContext* context) {+    ::grpc::internal::Call call =+        channel->CreateCall(method, context, channel->CallbackCQ());+    return new (g_core_codegen_interface->grpc_call_arena_alloc(+        call.call(),+        sizeof(::grpc::experimental::ClientCallbackReaderWriter<W, R>)))::grpc::+        experimental::ClientCallbackReaderWriter<W, R>(call, context);+  }+};++/// Callback-based client-side API for bi-directional streaming RPCs,+/// where the outgoing message stream coming from the client has messages of+/// type \a W, and the incoming messages stream coming from the server has+/// messages of type \a R.+/// TODO(vjpai): make this a derived class of an interface class+template <class W, class R>+class ClientCallbackReaderWriter final {+ public:+  // always allocated against a call arena, no memory free required+  static void operator delete(void* ptr, std::size_t size) {+    assert(size == sizeof(ClientCallbackReaderWriter));+  }++  // This operator should never be called as the memory should be freed as part+  // of the arena destruction. It only exists to provide a matching operator+  // delete to the operator new so that some compilers will not complain (see+  // https://github.com/grpc/grpc/issues/11301) Note at the time of adding this+  // there are no tests catching the compiler warning.+  static void operator delete(void*, void*) { assert(0); }++  void StartCall(std::function<void(Status)> on_completion) {+    StartCall(std::move(on_completion), nullptr);+  }++  void StartCall(std::function<void(Status)> on_completion,+                 std::function<void(bool)> on_metadata_available) {+    // This call may initiate two batches+    // 1. Send initial metadata/recv initial metadata, optional callback+    // 2. Recv trailing metadata, on_completion callback+","Why do we have a set of Start ops and Finish ops. What would happen if we batch the Send Initial Metadata, Recv Initial Metadata and Receive Status on client all in one op set?",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16541,217124241,2018-09-12T17:36:48Z,include/grpcpp/impl/codegen/client_callback.h,"@@ -90,6 +90,149 @@ class CallbackUnaryCallImpl { };  }  // namespace internal++/// TODO(vjpai): Move these contents out of experimental+/// TODO(vjpai): Merge with contents of sync_stream.h or async_stream.h if+/// possible, including getting their interfaces into the interface classes+namespace experimental {++// Forward declaration+template <class W, class R>+class ClientCallbackReaderWriter;++/// TODO(vjpai): Put this factory into ::grpc::internal when possible+template <class W, class R>+class ClientCallbackReaderWriterFactory {+ public:+  static ::grpc::experimental::ClientCallbackReaderWriter<W, R>* Create(+      ::grpc::ChannelInterface* channel,+      const ::grpc::internal::RpcMethod& method, ClientContext* context) {+    ::grpc::internal::Call call =+        channel->CreateCall(method, context, channel->CallbackCQ());+    return new (g_core_codegen_interface->grpc_call_arena_alloc(+        call.call(),+        sizeof(::grpc::experimental::ClientCallbackReaderWriter<W, R>)))::grpc::+        experimental::ClientCallbackReaderWriter<W, R>(call, context);+  }+};++/// Callback-based client-side API for bi-directional streaming RPCs,+/// where the outgoing message stream coming from the client has messages of+/// type \a W, and the incoming messages stream coming from the server has+/// messages of type \a R.+/// TODO(vjpai): make this a derived class of an interface class+template <class W, class R>+class ClientCallbackReaderWriter final {+ public:+  // always allocated against a call arena, no memory free required+  static void operator delete(void* ptr, std::size_t size) {+    assert(size == sizeof(ClientCallbackReaderWriter));+  }++  // This operator should never be called as the memory should be freed as part+  // of the arena destruction. It only exists to provide a matching operator+  // delete to the operator new so that some compilers will not complain (see+  // https://github.com/grpc/grpc/issues/11301) Note at the time of adding this+  // there are no tests catching the compiler warning.+  static void operator delete(void*, void*) { assert(0); }++  void StartCall(std::function<void(Status)> on_completion) {+    StartCall(std::move(on_completion), nullptr);+  }++  void StartCall(std::function<void(Status)> on_completion,+                 std::function<void(bool)> on_metadata_available) {+    // This call may initiate two batches+    // 1. Send initial metadata/recv initial metadata, optional callback+    // 2. Recv trailing metadata, on_completion callback+","I think you might be right in at least some cases. If the user wants the recv initial metadata callback, then they shouldn't be lumped together (since that would delay the callback until the entire batch is done). If the user doesn't want a separate callback, though, it should be fine to go ahead and lump them all together since the important concern is to make sure that we're at least initiating the recv initial metadata before the recv status or any recv messages. I'l try out that change.",OK
42048362,mhaidrygoog,https://api.github.com/repos/grpc/grpc/pulls/16541,217129791,2018-09-12T17:53:22Z,include/grpcpp/impl/codegen/client_callback.h,"@@ -90,6 +90,149 @@ class CallbackUnaryCallImpl { };  }  // namespace internal++/// TODO(vjpai): Move these contents out of experimental+/// TODO(vjpai): Merge with contents of sync_stream.h or async_stream.h if+/// possible, including getting their interfaces into the interface classes+namespace experimental {++// Forward declaration+template <class W, class R>+class ClientCallbackReaderWriter;++/// TODO(vjpai): Put this factory into ::grpc::internal when possible+template <class W, class R>+class ClientCallbackReaderWriterFactory {+ public:+  static ::grpc::experimental::ClientCallbackReaderWriter<W, R>* Create(+      ::grpc::ChannelInterface* channel,+      const ::grpc::internal::RpcMethod& method, ClientContext* context) {+    ::grpc::internal::Call call =+        channel->CreateCall(method, context, channel->CallbackCQ());+    return new (g_core_codegen_interface->grpc_call_arena_alloc(+        call.call(),+        sizeof(::grpc::experimental::ClientCallbackReaderWriter<W, R>)))::grpc::+        experimental::ClientCallbackReaderWriter<W, R>(call, context);+  }+};++/// Callback-based client-side API for bi-directional streaming RPCs,+/// where the outgoing message stream coming from the client has messages of+/// type \a W, and the incoming messages stream coming from the server has+/// messages of type \a R.+/// TODO(vjpai): make this a derived class of an interface class+template <class W, class R>+class ClientCallbackReaderWriter final {+ public:+  // always allocated against a call arena, no memory free required+  static void operator delete(void* ptr, std::size_t size) {+    assert(size == sizeof(ClientCallbackReaderWriter));+  }++  // This operator should never be called as the memory should be freed as part+  // of the arena destruction. It only exists to provide a matching operator+  // delete to the operator new so that some compilers will not complain (see+  // https://github.com/grpc/grpc/issues/11301) Note at the time of adding this+  // there are no tests catching the compiler warning.+  static void operator delete(void*, void*) { assert(0); }++  void StartCall(std::function<void(Status)> on_completion) {+    StartCall(std::move(on_completion), nullptr);+  }++  void StartCall(std::function<void(Status)> on_completion,+                 std::function<void(bool)> on_metadata_available) {+    // This call may initiate two batches+    // 1. Send initial metadata/recv initial metadata, optional callback+    // 2. Recv trailing metadata, on_completion callback+",I have a dumber follow up question. Why do we need a recv status when we already have a recv initial metadata? Wouldn't receiving the intial metadata already signify that the server is alive.,
14932100,adelez,https://api.github.com/repos/grpc/grpc/pulls/16611,217140546,2018-09-12T18:25:48Z,test/cpp/interop/interop_client.cc,"@@ -1052,6 +1052,32 @@ bool InteropClient::DoChannelSoakTest(int32_t soak_iterations) {   return true; } +bool InteropClient::DoLongConnectionTest(int32_t soak_iterations, +                                         int32_t iteration_interval) {+  gpr_log(GPR_DEBUG, ""Sending %d RPCs..."", soak_iterations);+  GPR_ASSERT(soak_iterations > 0);+  GPR_ASSERT(iteration_interval > 0);+  SimpleRequest request;+  SimpleResponse response;+  int num_failures = 0;+  for (int i = 0; i < soak_iterations; ++i) {","I personally don't want to add another flag which essentially does the same thing. I'd prefer renaming soak_iterations to just num_of_iterations, but this can go in a separate refactoring PR.",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16611,217185145,2018-09-12T20:53:52Z,test/cpp/interop/client.cc,"@@ -57,6 +57,7 @@ DEFINE_string(     ""half_duplex : half-duplex streaming;\n""     ""jwt_token_creds: large_unary with JWT token auth;\n""     ""large_unary : single request and (large) response;\n""+    ""long_connection: sends large_unary rpcs over a single long connection;\n""","I might actually rename this from `long_connection` to `long_lived_channel`, because `long_connection` might be confusing: not all of the RPC's made on the channel are guaranteed to be on the same connection",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16541,217400042,2018-09-13T14:14:52Z,include/grpcpp/impl/codegen/client_callback.h,"@@ -90,6 +90,149 @@ class CallbackUnaryCallImpl { };  }  // namespace internal++/// TODO(vjpai): Move these contents out of experimental+/// TODO(vjpai): Merge with contents of sync_stream.h or async_stream.h if+/// possible, including getting their interfaces into the interface classes+namespace experimental {++// Forward declaration+template <class W, class R>+class ClientCallbackReaderWriter;++/// TODO(vjpai): Put this factory into ::grpc::internal when possible+template <class W, class R>+class ClientCallbackReaderWriterFactory {+ public:+  static ::grpc::experimental::ClientCallbackReaderWriter<W, R>* Create(+      ::grpc::ChannelInterface* channel,+      const ::grpc::internal::RpcMethod& method, ClientContext* context) {+    ::grpc::internal::Call call =+        channel->CreateCall(method, context, channel->CallbackCQ());+    return new (g_core_codegen_interface->grpc_call_arena_alloc(+        call.call(),+        sizeof(::grpc::experimental::ClientCallbackReaderWriter<W, R>)))::grpc::+        experimental::ClientCallbackReaderWriter<W, R>(call, context);+  }+};++/// Callback-based client-side API for bi-directional streaming RPCs,+/// where the outgoing message stream coming from the client has messages of+/// type \a W, and the incoming messages stream coming from the server has+/// messages of type \a R.+/// TODO(vjpai): make this a derived class of an interface class+template <class W, class R>+class ClientCallbackReaderWriter final {+ public:+  // always allocated against a call arena, no memory free required+  static void operator delete(void* ptr, std::size_t size) {+    assert(size == sizeof(ClientCallbackReaderWriter));+  }++  // This operator should never be called as the memory should be freed as part+  // of the arena destruction. It only exists to provide a matching operator+  // delete to the operator new so that some compilers will not complain (see+  // https://github.com/grpc/grpc/issues/11301) Note at the time of adding this+  // there are no tests catching the compiler warning.+  static void operator delete(void*, void*) { assert(0); }++  void StartCall(std::function<void(Status)> on_completion) {+    StartCall(std::move(on_completion), nullptr);+  }++  void StartCall(std::function<void(Status)> on_completion,+                 std::function<void(bool)> on_metadata_available) {+    // This call may initiate two batches+    // 1. Send initial metadata/recv initial metadata, optional callback+    // 2. Recv trailing metadata, on_completion callback+","Following our conversation: different purposes, status comes at the end and signifies the successful/unsuccessful _completion_ of the RPC, not just the condition of the server.",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16014,217633726,2018-09-14T08:16:30Z,src/ruby/spec/pb/codegen/package_option_spec.rb,"@@ -0,0 +1,53 @@+# Copyright 2018 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++require 'spec_helper'+require 'open3'+require 'tmpdir'++describe 'Code Generation Options' do+  it 'should generate and respect package options' do+    unless system('which grpc_ruby_plugin', out: File::NULL) && system('which protoc', out: File::NULL)","whoops, actually, can we please change the way this test find the `grpc_ruby_plugin` and `protoc` so that is always runs and won't ever get skipped during c-builds?See this test for an example of doing that: https://github.com/grpc/grpc/blob/master/src/ruby/end2end/package_with_underscore_checker.rb#L19 (the way that the test finds `protoc` and `grpc_ruby_plugin` executables can be copied over this test as well.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16582,217763373,2018-09-14T16:04:18Z,src/core/ext/filters/http/client/http_client_filter.cc,"@@ -67,6 +67,8 @@ struct call_data {   grpc_closure on_send_message_next_done;   grpc_closure* original_send_message_on_complete;   grpc_closure send_message_on_complete;+  grpc_error* recv_trailing_metadata_err;","Please move these two up to line 61, so all of the fields related to recv_trailing_metadata are in one place.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16582,217765782,2018-09-14T16:12:59Z,src/core/ext/filters/http/client/http_client_filter.cc,"@@ -157,12 +159,28 @@ static void recv_initial_metadata_ready(void* user_data, grpc_error* error) {   } else {     GRPC_ERROR_REF(error);   }-  GRPC_CLOSURE_RUN(calld->original_recv_initial_metadata_ready, error);+  grpc_closure* closure = calld->original_recv_initial_metadata_ready;+  calld->original_recv_initial_metadata_ready = nullptr;+  if (calld->seen_recv_trailing_metadata_ready) {+    GRPC_CALL_COMBINER_START(+        calld->call_combiner, &calld->recv_trailing_metadata_ready,+        calld->recv_trailing_metadata_err, ""continue recv trailing metadata"");+  }+  GRPC_CLOSURE_RUN(closure, error); }  static void recv_trailing_metadata_ready(void* user_data, grpc_error* error) {   grpc_call_element* elem = static_cast<grpc_call_element*>(user_data);   call_data* calld = static_cast<call_data*>(elem->call_data);+  if (calld->original_recv_initial_metadata_ready != nullptr) {+    calld->recv_trailing_metadata_err = GRPC_ERROR_REF(error);+    calld->seen_recv_trailing_metadata_ready = true;+    GRPC_CLOSURE_INIT(&calld->recv_trailing_metadata_ready,+                      recv_trailing_metadata_ready, elem,+                      grpc_schedule_on_exec_ctx);+    GRPC_CALL_COMBINER_STOP(calld->call_combiner, ""wait for initial metadata"");","Suggest changing the string here to be a bit more descriptive: ""deferring recv_trailing_metadata_ready until after recv_initial_metadata_ready"".",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16582,217765838,2018-09-14T16:13:16Z,src/core/ext/filters/http/client/http_client_filter.cc,"@@ -157,12 +159,28 @@ static void recv_initial_metadata_ready(void* user_data, grpc_error* error) {   } else {     GRPC_ERROR_REF(error);   }-  GRPC_CLOSURE_RUN(calld->original_recv_initial_metadata_ready, error);+  grpc_closure* closure = calld->original_recv_initial_metadata_ready;+  calld->original_recv_initial_metadata_ready = nullptr;+  if (calld->seen_recv_trailing_metadata_ready) {+    GRPC_CALL_COMBINER_START(+        calld->call_combiner, &calld->recv_trailing_metadata_ready,+        calld->recv_trailing_metadata_err, ""continue recv trailing metadata"");",s/recv trailing metadata/recv_trailing_metadata_ready/,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16582,217766165,2018-09-14T16:14:23Z,src/core/ext/filters/http/server/http_server_filter.cc,"@@ -65,6 +65,9 @@ struct call_data {    grpc_closure recv_trailing_metadata_ready;   grpc_closure* original_recv_trailing_metadata_ready;+",Please remove blank line -- let's put all recv_trailing_metadata fields in one section.,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16582,217766338,2018-09-14T16:14:57Z,src/core/ext/filters/http/server/http_server_filter.cc,"@@ -65,6 +65,9 @@ struct call_data {    grpc_closure recv_trailing_metadata_ready;",Please add a comment here:// State for intercepting recv_trailing_metadata.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16582,217768171,2018-09-14T16:21:36Z,src/core/ext/filters/http/server/http_server_filter.cc,"@@ -331,6 +342,15 @@ static void hs_recv_message_ready(void* user_data, grpc_error* err) { static void hs_recv_trailing_metadata_ready(void* user_data, grpc_error* err) {   grpc_call_element* elem = static_cast<grpc_call_element*>(user_data);   call_data* calld = static_cast<call_data*>(elem->call_data);+  if (calld->original_recv_initial_metadata_ready) {",This should just check `seen_recv_initial_metadata_ready`.,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16582,217769606,2018-09-14T16:26:42Z,src/core/ext/filters/http/server/http_server_filter.cc,"@@ -301,7 +304,15 @@ static void hs_recv_initial_metadata_ready(void* user_data, grpc_error* err) {   } else {     GRPC_ERROR_REF(err);   }-  GRPC_CLOSURE_RUN(calld->original_recv_initial_metadata_ready, err);+  grpc_closure* closure = calld->original_recv_initial_metadata_ready;+  calld->original_recv_initial_metadata_ready = nullptr;+  if (calld->seen_recv_trailing_metadata_ready) {+    GRPC_CALL_COMBINER_START(calld->call_combiner,+                             &calld->recv_trailing_metadata_ready,+                             calld->recv_trailing_metadata_ready_error,+                             ""continue recv trailing metadata"");","""resuming recv_trailing_metadata_ready from recv_initial_metadata_ready""",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16582,217769645,2018-09-14T16:26:49Z,src/core/ext/filters/http/server/http_server_filter.cc,"@@ -331,6 +342,15 @@ static void hs_recv_message_ready(void* user_data, grpc_error* err) { static void hs_recv_trailing_metadata_ready(void* user_data, grpc_error* err) {   grpc_call_element* elem = static_cast<grpc_call_element*>(user_data);   call_data* calld = static_cast<call_data*>(elem->call_data);+  if (calld->original_recv_initial_metadata_ready) {+    calld->recv_trailing_metadata_ready_error = GRPC_ERROR_REF(err);+    calld->seen_recv_trailing_metadata_ready = true;+    GRPC_CLOSURE_INIT(&calld->recv_trailing_metadata_ready,+                      hs_recv_trailing_metadata_ready, elem,+                      grpc_schedule_on_exec_ctx);+    GRPC_CALL_COMBINER_STOP(calld->call_combiner, ""wait for initial metadata"");","""deferring recv_trailing_metadata_ready until after recv_initial_metadata_ready and recv_message_ready""",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16582,217769720,2018-09-14T16:27:03Z,src/core/ext/filters/message_size/message_size_filter.cc,"@@ -147,14 +149,30 @@ static void recv_message_ready(void* user_data, grpc_error* error) {     GRPC_ERROR_REF(error);   }   // Invoke the next callback.-  GRPC_CLOSURE_RUN(calld->next_recv_message_ready, error);+  grpc_closure* closure = calld->next_recv_message_ready;+  calld->next_recv_message_ready = nullptr;+  if (calld->seen_recv_trailing_metadata) {+    GRPC_CALL_COMBINER_START(+        calld->call_combiner, &calld->recv_trailing_metadata_ready,+        calld->recv_trailing_metadata_error, ""continue recv trailing metadata"");",s/recv trailing metadata/recv_trailing_metadata_ready/,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16582,217769763,2018-09-14T16:27:12Z,src/core/ext/filters/message_size/message_size_filter.cc,"@@ -147,14 +149,30 @@ static void recv_message_ready(void* user_data, grpc_error* error) {     GRPC_ERROR_REF(error);   }   // Invoke the next callback.-  GRPC_CLOSURE_RUN(calld->next_recv_message_ready, error);+  grpc_closure* closure = calld->next_recv_message_ready;+  calld->next_recv_message_ready = nullptr;+  if (calld->seen_recv_trailing_metadata) {+    GRPC_CALL_COMBINER_START(+        calld->call_combiner, &calld->recv_trailing_metadata_ready,+        calld->recv_trailing_metadata_error, ""continue recv trailing metadata"");+  }+  GRPC_CLOSURE_RUN(closure, error); }  // Callback invoked on completion of recv_trailing_metadata // Notifies the recv_trailing_metadata batch of any message size failures static void recv_trailing_metadata_ready(void* user_data, grpc_error* error) {   grpc_call_element* elem = static_cast<grpc_call_element*>(user_data);   call_data* calld = static_cast<call_data*>(elem->call_data);+  if (calld->next_recv_message_ready) {+    calld->seen_recv_trailing_metadata = true;+    calld->recv_trailing_metadata_error = GRPC_ERROR_REF(error);+    GRPC_CLOSURE_INIT(&calld->recv_trailing_metadata_ready,+                      recv_trailing_metadata_ready, elem,+                      grpc_schedule_on_exec_ctx);+    GRPC_CALL_COMBINER_STOP(calld->call_combiner, ""wait for recv message"");","""deferring recv_trailing_metadata_ready until after recv_message_ready""",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16582,217770687,2018-09-14T16:30:35Z,src/core/ext/filters/http/server/http_server_filter.cc,"@@ -301,7 +304,15 @@ static void hs_recv_initial_metadata_ready(void* user_data, grpc_error* err) {   } else {     GRPC_ERROR_REF(err);   }-  GRPC_CLOSURE_RUN(calld->original_recv_initial_metadata_ready, err);+  grpc_closure* closure = calld->original_recv_initial_metadata_ready;+  calld->original_recv_initial_metadata_ready = nullptr;+  if (calld->seen_recv_trailing_metadata_ready) {+    GRPC_CALL_COMBINER_START(calld->call_combiner,+                             &calld->recv_trailing_metadata_ready,+                             calld->recv_trailing_metadata_ready_error,+                             ""continue recv trailing metadata"");+  }+  GRPC_CLOSURE_RUN(closure, err); }  static void hs_recv_message_ready(void* user_data, grpc_error* err) {",This also needs to be modified similarly to `hs_recv_initial_metadata_ready()`.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16582,217771448,2018-09-14T16:33:14Z,src/core/ext/filters/http/server/http_server_filter.cc,"@@ -301,7 +304,15 @@ static void hs_recv_initial_metadata_ready(void* user_data, grpc_error* err) {   } else {     GRPC_ERROR_REF(err);   }-  GRPC_CLOSURE_RUN(calld->original_recv_initial_metadata_ready, err);+  grpc_closure* closure = calld->original_recv_initial_metadata_ready;","No need to do the two-phase thing for unsetting `original_recv_initial_metadata_ready` here, since we can use `seen_recv_initial_metadata_ready` below.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16582,217772577,2018-09-14T16:37:20Z,src/core/lib/security/transport/server_auth_filter.cc,"@@ -49,6 +49,8 @@ struct call_data {   size_t num_consumed_md;   grpc_closure cancel_closure;   gpr_atm state;  // async_state+  grpc_error* recv_trailing_metadata_error;","Please move these up to line 47, so that all fields related to recv_trailing_metadata are in one place.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16582,217772801,2018-09-14T16:38:14Z,src/core/lib/security/transport/server_auth_filter.cc,"@@ -115,7 +117,14 @@ static void on_md_processing_done_inner(grpc_call_element* elem,         remove_consumed_md, elem, ""Response metadata filtering error"");   }   calld->error = GRPC_ERROR_REF(error);",Please rename `calld->error` to `calld->recv_initial_metadata_error`.,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16582,217772900,2018-09-14T16:38:39Z,src/core/lib/security/transport/server_auth_filter.cc,"@@ -115,7 +117,14 @@ static void on_md_processing_done_inner(grpc_call_element* elem,         remove_consumed_md, elem, ""Response metadata filtering error"");   }   calld->error = GRPC_ERROR_REF(error);-  GRPC_CLOSURE_SCHED(calld->original_recv_initial_metadata_ready, error);+  grpc_closure* closure = calld->original_recv_initial_metadata_ready;+  calld->original_recv_initial_metadata_ready = nullptr;+  if (calld->seen_recv_trailing_ready) {+    GRPC_CALL_COMBINER_START(+        calld->call_combiner, &calld->recv_trailing_metadata_ready,+        calld->recv_trailing_metadata_error, ""continue recv trailing metadata"");",s/recv trailing metadata/recv_trailing_metadata_ready/,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16582,217773204,2018-09-14T16:39:46Z,src/core/lib/security/transport/server_auth_filter.cc,"@@ -184,13 +193,27 @@ static void recv_initial_metadata_ready(void* arg, grpc_error* error) {       return;     }   }-  GRPC_CLOSURE_RUN(calld->original_recv_initial_metadata_ready,-                   GRPC_ERROR_REF(error));+  grpc_closure* closure = calld->original_recv_initial_metadata_ready;+  calld->original_recv_initial_metadata_ready = nullptr;+  if (calld->seen_recv_trailing_ready) {+    GRPC_CALL_COMBINER_START(+        calld->call_combiner, &calld->recv_trailing_metadata_ready,+        calld->recv_trailing_metadata_error, ""continue recv trailing metadata"");",s/recv trailing metadata/recv_trailing_metadata_ready/,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16582,217773514,2018-09-14T16:40:48Z,src/core/lib/security/transport/server_auth_filter.cc,"@@ -184,13 +193,27 @@ static void recv_initial_metadata_ready(void* arg, grpc_error* error) {       return;     }   }-  GRPC_CLOSURE_RUN(calld->original_recv_initial_metadata_ready,-                   GRPC_ERROR_REF(error));+  grpc_closure* closure = calld->original_recv_initial_metadata_ready;+  calld->original_recv_initial_metadata_ready = nullptr;+  if (calld->seen_recv_trailing_ready) {+    GRPC_CALL_COMBINER_START(+        calld->call_combiner, &calld->recv_trailing_metadata_ready,+        calld->recv_trailing_metadata_error, ""continue recv trailing metadata"");+  }+  GRPC_CLOSURE_RUN(closure, GRPC_ERROR_REF(error)); }  static void recv_trailing_metadata_ready(void* user_data, grpc_error* err) {   grpc_call_element* elem = static_cast<grpc_call_element*>(user_data);   call_data* calld = static_cast<call_data*>(elem->call_data);+  if (calld->original_recv_initial_metadata_ready) {+    calld->recv_trailing_metadata_error = GRPC_ERROR_REF(err);+    calld->seen_recv_trailing_ready = true;+    GRPC_CLOSURE_INIT(&calld->recv_trailing_metadata_ready,+                      recv_trailing_metadata_ready, elem,+                      grpc_schedule_on_exec_ctx);+    GRPC_CALL_COMBINER_STOP(calld->call_combiner, ""wait for initial metadata"");","""deferring recv_trailing_metadata_ready until after recv_initial_metadata_ready""",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16617,217802867,2018-09-14T18:26:47Z,include/grpc/grpc.h,"@@ -201,6 +201,110 @@ GRPCAPI void grpc_channel_watch_connectivity_state( /** Check whether a grpc channel supports connectivity watcher */ GRPCAPI int grpc_channel_support_connectivity_watcher(grpc_channel* channel); +/** Returns a grpc_addresses struct with enough space for+    \a capacity addresses. */+GRPCAPI grpc_addresses* grpc_addresses_create_with_capacity(size_t capacity,+                                                            void* reserved);++/** Destroy addresses list. */+GRPCAPI void grpc_addresses_destroy(grpc_addresses* addresses);++/** Add backend address with \a target to \a addresses.+ * Channel will connect to \a target directly.+ * \a target is an uri with the ipv4, ipv6, or unix scheme. */+GRPCAPI bool grpc_addresses_add_backend_address(grpc_addresses* addresses,+                                                const char* target,+                                                void* reserved);++/** Add remote balancer address with \a target to \a addresses.+ * Channel will connect to remote balancer using \a address.+ * \a target is an uri with the ipv4, ipv6, or unix scheme.+ * \a balancer_name is used for overriding server name in secure connections and+ * can be empty. If set grpc creates its copy. */+GRPCAPI bool grpc_addresses_add_balancer_address(grpc_addresses* addresses,+                                                 const char* target,+                                                 const char* balancer_name,+                                                 void* reserved);++/**+ * Get the scheme of \a uri.+ */+GRPCAPI const char* grpc_uri_get_scheme(const grpc_uri* uri);++/**+ * Get the authority of \a uri.+ */+GRPCAPI const char* grpc_uri_get_authority(const grpc_uri* uri);++/**+ * Get the path of \a uri.+ */+GRPCAPI const char* grpc_uri_get_path(const grpc_uri* uri);++/**+ * Get the value of \a uri argument with value \a key, or NULL \a key is not+ * present.+ */+GRPCAPI const char* grpc_uri_get_query_arg(const grpc_uri* uri,+                                           const char* key);++typedef struct grpc_uri_query_iterator {+  const grpc_uri* uri;+  size_t index;+  const char* key;+  const char* value;+} grpc_uri_query_iterator;++/**+ * Get the iterator over query of \a uri.+ * Returned iterator points before the first element.+ */+GRPCAPI grpc_uri_query_iterator+grpc_uri_get_query_iterator(const grpc_uri* uri);++/**+ * Returns NULL when \a iterator is at the end.+ */+GRPCAPI grpc_uri_query_iterator* grpc_uri_query_iterator_next(+    grpc_uri_query_iterator* iterator);++/**+ * Get the fragment of \a uri.+ */+GRPCAPI const char* grpc_uri_get_fragment(const grpc_uri* uri);++/**+ * Get the target to resolve from \a args.+ */+GRPCAPI grpc_uri* grpc_resolver_args_get_target(grpc_resolver_args* args);++/**+ * Create and register a new resolver factory with \a scheme and callbacks.+ * \a scheme must be unique.+ * Thread Safety: All factories have to be registered before creating Channels.+ */+GRPCAPI void grpc_resolver_factory_register(+    const char* scheme, void* factory_user_data,+    void* (*resolver_factory_resolve)(void* factory_user_data,+                                      grpc_resolver_args* args,+                                      grpc_resolver_observer* observer),+    void (*resolver_factory_destroy)(void* factory_user_data),+    void (*resolver_request_reresolution)(void* resolver_user_data),+    void (*resolver_destroy)(void* resolver_user_data), void* reserved);++/**+ * Destroy \a observer.+ * This function should be called on resolver destruction.+ * No \a observer methods must be used after object is destroyed.+ */+GRPCAPI void grpc_resolver_observer_destroy(grpc_resolver_observer* observer);++/**+ * Set new list of \a addresses to \a observer.+ */+GRPCAPI void grpc_resolver_observer_set_addresses(","This is effectively a callback from the resolver back to gRPC.  What are the lifetime semantics here?  How do we know when it's safe to destroy the observer?  Presumably, we need to know that the resolver is not going to send any more callbacks before we can do that.  We probably need to figure out the ref-counting story here.Also, note that there's some complexity that we'll need to handle whenever we do a callback from core to the application (in this context, the external resolver plugin); for details, see my comment in the following review thread:https://github.com/grpc/grpc/pull/12656#pullrequestreview-141303768Note that in the specific case of the resolver, there's no need to support cancellation of individual requests, but there is a need to support shutting down a resolver while there is a request outstanding.  So we'll need to make sure we have the semantics for this figured out and documented.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16617,217806761,2018-09-14T18:40:25Z,include/grpc/grpc.h,"@@ -201,6 +201,110 @@ GRPCAPI void grpc_channel_watch_connectivity_state( /** Check whether a grpc channel supports connectivity watcher */ GRPCAPI int grpc_channel_support_connectivity_watcher(grpc_channel* channel); +/** Returns a grpc_addresses struct with enough space for+    \a capacity addresses. */+GRPCAPI grpc_addresses* grpc_addresses_create_with_capacity(size_t capacity,+                                                            void* reserved);++/** Destroy addresses list. */+GRPCAPI void grpc_addresses_destroy(grpc_addresses* addresses);++/** Add backend address with \a target to \a addresses.+ * Channel will connect to \a target directly.+ * \a target is an uri with the ipv4, ipv6, or unix scheme. */+GRPCAPI bool grpc_addresses_add_backend_address(grpc_addresses* addresses,+                                                const char* target,+                                                void* reserved);++/** Add remote balancer address with \a target to \a addresses.+ * Channel will connect to remote balancer using \a address.+ * \a target is an uri with the ipv4, ipv6, or unix scheme.+ * \a balancer_name is used for overriding server name in secure connections and+ * can be empty. If set grpc creates its copy. */+GRPCAPI bool grpc_addresses_add_balancer_address(grpc_addresses* addresses,+                                                 const char* target,+                                                 const char* balancer_name,+                                                 void* reserved);++/**+ * Get the scheme of \a uri.+ */+GRPCAPI const char* grpc_uri_get_scheme(const grpc_uri* uri);++/**+ * Get the authority of \a uri.+ */+GRPCAPI const char* grpc_uri_get_authority(const grpc_uri* uri);++/**+ * Get the path of \a uri.+ */+GRPCAPI const char* grpc_uri_get_path(const grpc_uri* uri);++/**+ * Get the value of \a uri argument with value \a key, or NULL \a key is not+ * present.+ */+GRPCAPI const char* grpc_uri_get_query_arg(const grpc_uri* uri,+                                           const char* key);++typedef struct grpc_uri_query_iterator {+  const grpc_uri* uri;+  size_t index;+  const char* key;+  const char* value;+} grpc_uri_query_iterator;++/**+ * Get the iterator over query of \a uri.+ * Returned iterator points before the first element.+ */+GRPCAPI grpc_uri_query_iterator+grpc_uri_get_query_iterator(const grpc_uri* uri);++/**+ * Returns NULL when \a iterator is at the end.+ */+GRPCAPI grpc_uri_query_iterator* grpc_uri_query_iterator_next(+    grpc_uri_query_iterator* iterator);++/**+ * Get the fragment of \a uri.+ */+GRPCAPI const char* grpc_uri_get_fragment(const grpc_uri* uri);++/**+ * Get the target to resolve from \a args.+ */+GRPCAPI grpc_uri* grpc_resolver_args_get_target(grpc_resolver_args* args);++/**+ * Create and register a new resolver factory with \a scheme and callbacks.+ * \a scheme must be unique.+ * Thread Safety: All factories have to be registered before creating Channels.+ */+GRPCAPI void grpc_resolver_factory_register(+    const char* scheme, void* factory_user_data,+    void* (*resolver_factory_resolve)(void* factory_user_data,+                                      grpc_resolver_args* args,+                                      grpc_resolver_observer* observer),+    void (*resolver_factory_destroy)(void* factory_user_data),+    void (*resolver_request_reresolution)(void* resolver_user_data),",What are the thread safety semantics of these methods?,
2811396,ejona86,https://api.github.com/repos/grpc/grpc/pulls/16618,217816736,2018-09-14T19:18:23Z,include/grpc/impl/codegen/grpc_types.h,"@@ -216,7 +216,7 @@ typedef struct { #define GRPC_ARG_HTTP2_WRITE_BUFFER_SIZE ""grpc.http2.write_buffer_size"" /** Should we allow receipt of true-binary data on http2 connections?     Defaults to on (1) */-#define GRPC_ARG_HTTP2_ENABLE_TRUE_BINARY ""grpc.http2.true_binary""",We're dropping binary metadata support?,
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/16618,217821355,2018-09-14T19:39:04Z,include/grpc/impl/codegen/grpc_types.h,"@@ -216,7 +216,7 @@ typedef struct { #define GRPC_ARG_HTTP2_WRITE_BUFFER_SIZE ""grpc.http2.write_buffer_size"" /** Should we allow receipt of true-binary data on http2 connections?     Defaults to on (1) */-#define GRPC_ARG_HTTP2_ENABLE_TRUE_BINARY ""grpc.http2.true_binary""","Rather, we are muxing the two into the same bit. HFAST will represent all H2 spec breaking optimizations rather than toggle each one with its own option (until a valid use case comes along which needs one and not the other)",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16617,217830130,2018-09-14T20:14:41Z,src/core/ext/filters/client_channel/resolver/custom/custom_resolver.cc,"@@ -0,0 +1,363 @@+//+// Copyright 2016 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.+//++// Shim resolver for exposing public API for custom application resolvers.++#include <grpc/support/port_platform.h>++#include <limits.h>+#include <stdbool.h>+#include <stdio.h>+#include <stdlib.h>+#include <string.h>++#include <grpc/support/alloc.h>+#include <grpc/support/string_util.h>++#include ""src/core/ext/filters/client_channel/lb_policy_factory.h""+#include ""src/core/ext/filters/client_channel/parse_address.h""+#include ""src/core/ext/filters/client_channel/resolver_registry.h""+#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/gpr/host_port.h""+#include ""src/core/lib/gpr/string.h""+#include ""src/core/lib/gprpp/mutex_lock.h""+#include ""src/core/lib/iomgr/closure.h""+#include ""src/core/lib/iomgr/combiner.h""+#include ""src/core/lib/iomgr/resolve_address.h""+#include ""src/core/lib/iomgr/unix_sockets_posix.h""+#include ""src/core/lib/slice/slice_internal.h""+#include ""src/core/lib/slice/slice_string_helpers.h""++struct grpc_addresses {};+struct grpc_resolver {};+struct grpc_resolver_observer {};+struct grpc_resolver_factory {};+struct grpc_resolver_args {+  const grpc_core::ResolverArgs* args;+};++namespace grpc_core {++namespace {++struct ResolverFactoryVTable {+  void* (*resolve)(void* factory_user_data, grpc_resolver_args* args,+                   grpc_resolver_observer* observer);+  void (*destroy)(void* factory_user_data);+};++struct ResolverVTable {+  void (*request_reresolution)(void* resolver_user_data);+  void (*destroy)(void* resolver_user_data);+};++class CustomResolverObserver;++class ResolverAddresses : public grpc_addresses {+ public:+  ResolverAddresses(size_t capacity) : capacity_(capacity) {+    addresses_ = grpc_lb_addresses_create(capacity, nullptr);+    addresses_->num_addresses = 0;+  }++  ~ResolverAddresses() { grpc_lb_addresses_destroy(addresses_); }++  bool AddAddress(const char* target, bool is_balancer,+                  const char* balancer_name) {+    if (addresses_->num_addresses >= capacity_) {+      return false;+    };+    grpc_uri* uri = grpc_uri_parse(target, false);+    if (!uri) return false;+    size_t index = addresses_->num_addresses++;+    bool result = grpc_lb_addresses_set_address_from_uri(+        addresses_, index, uri, is_balancer, balancer_name, nullptr);+    grpc_uri_destroy(uri);+    if (!result) {+      addresses_->num_addresses--;+    }+    return result;+  }++  grpc_lb_addresses* GetAddresses() { return addresses_; }++ private:+  grpc_lb_addresses* addresses_;+  size_t capacity_;+};++class CustomResolverFactory;++class CustomResolver : public Resolver {+ public:+  explicit CustomResolver(const ResolverArgs& args,+                          const ResolverVTable& vtable);++  void Init(void* user_data) { user_data_ = user_data; }+  void SetNextResult(grpc_channel_args* resolved_channel_args);++  void NextLocked(grpc_channel_args** result,+                  grpc_closure* on_complete) override;++  void RequestReresolutionLocked() override;++  void InitObserver(CustomResolverObserver* observer);++ private:+  friend class CustomResolverFactory;++  virtual ~CustomResolver();++  void MaybeFinishNextLocked();++  void ShutdownLocked() override;++  void* user_data_ = nullptr;+  ResolverVTable vtable_;++  // Next resolved addresses.+  gpr_mu resolved_lock_;+  grpc_closure resolved_closure_;+  grpc_channel_args* resolved_channel_args_ = nullptr;+  // Pending next completion, or NULL.+  grpc_closure* next_completion_ = nullptr;+  grpc_channel_args** target_result_ = nullptr;+};++CustomResolver::CustomResolver(const ResolverArgs& args,+                               const ResolverVTable& vtable)+    : Resolver(args.combiner), vtable_(vtable) {+  gpr_mu_init(&resolved_lock_);+}++CustomResolver::~CustomResolver() {+  grpc_channel_args_destroy(resolved_channel_args_);+  gpr_mu_destroy(&resolved_lock_);+}++struct SetNextArgs {+  CustomResolver* resolver;+  RefCountedPtr<Resolver> resolver_guard;+};++void CustomResolver::SetNextResult(grpc_channel_args* resolved_channel_args) {+  bool has_scheduled_closure = false;+  {+    MutexLock lock(&resolved_lock_);+    if (resolved_channel_args_ != nullptr) {+      has_scheduled_closure = true;+      grpc_channel_args_destroy(resolved_channel_args_);+    }+    resolved_channel_args_ = resolved_channel_args;+  }+  if (!has_scheduled_closure) {+    auto args = New<SetNextArgs>(SetNextArgs{this, Ref()});+    GRPC_CLOSURE_INIT(&resolved_closure_,+                      [](void* raw_args, grpc_error* error) {+                        auto args = static_cast<SetNextArgs*>(raw_args);+                        args->resolver->MaybeFinishNextLocked();+                        Delete(args);+                      },+                      args, grpc_combiner_scheduler(combiner()));+    GRPC_CLOSURE_SCHED(&resolved_closure_, GRPC_ERROR_NONE);+  }+}++void CustomResolver::NextLocked(grpc_channel_args** target_result,+                                grpc_closure* on_complete) {+  GPR_ASSERT(next_completion_ == nullptr);+  next_completion_ = on_complete;+  target_result_ = target_result;+  MaybeFinishNextLocked();+}++void CustomResolver::RequestReresolutionLocked() {+  vtable_.request_reresolution(user_data_);+}++void CustomResolver::MaybeFinishNextLocked() {+  if (next_completion_ != nullptr) {+    grpc_channel_args* channel_args;+    {+      MutexLock lock(&resolved_lock_);+      channel_args = resolved_channel_args_;+      resolved_channel_args_ = nullptr;+    }+    if (channel_args != nullptr) {+      *target_result_ = channel_args;+      auto next_completion = next_completion_;+      next_completion_ = nullptr;+      GRPC_CLOSURE_SCHED(next_completion, GRPC_ERROR_NONE);+    }+  }+}++void CustomResolver::ShutdownLocked() {+  vtable_.destroy(user_data_);+  if (next_completion_ != nullptr) {+    *target_result_ = nullptr;+    auto next_completion = next_completion_;+    next_completion_ = nullptr;+    GRPC_CLOSURE_SCHED(next_completion, GRPC_ERROR_CREATE_FROM_STATIC_STRING(+                                            ""Resolver Shutdown""));+  }+}++//+// Observer+//++class CustomResolverObserver : public grpc_resolver_observer {+ public:+  CustomResolverObserver(const ResolverArgs& args,+                         RefCountedPtr<Resolver> resolver) {+    resolver_ = std::move(resolver);",These two can be initialized via an initializer list.,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16617,217834960,2018-09-14T20:34:42Z,src/core/ext/filters/client_channel/resolver/custom/custom_resolver.cc,"@@ -0,0 +1,363 @@+//+// Copyright 2016 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.+//++// Shim resolver for exposing public API for custom application resolvers.++#include <grpc/support/port_platform.h>++#include <limits.h>+#include <stdbool.h>+#include <stdio.h>+#include <stdlib.h>+#include <string.h>++#include <grpc/support/alloc.h>+#include <grpc/support/string_util.h>++#include ""src/core/ext/filters/client_channel/lb_policy_factory.h""+#include ""src/core/ext/filters/client_channel/parse_address.h""+#include ""src/core/ext/filters/client_channel/resolver_registry.h""+#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/gpr/host_port.h""+#include ""src/core/lib/gpr/string.h""+#include ""src/core/lib/gprpp/mutex_lock.h""+#include ""src/core/lib/iomgr/closure.h""+#include ""src/core/lib/iomgr/combiner.h""+#include ""src/core/lib/iomgr/resolve_address.h""+#include ""src/core/lib/iomgr/unix_sockets_posix.h""+#include ""src/core/lib/slice/slice_internal.h""+#include ""src/core/lib/slice/slice_string_helpers.h""++struct grpc_addresses {};+struct grpc_resolver {};+struct grpc_resolver_observer {};+struct grpc_resolver_factory {};+struct grpc_resolver_args {+  const grpc_core::ResolverArgs* args;+};++namespace grpc_core {++namespace {++struct ResolverFactoryVTable {+  void* (*resolve)(void* factory_user_data, grpc_resolver_args* args,+                   grpc_resolver_observer* observer);+  void (*destroy)(void* factory_user_data);+};++struct ResolverVTable {+  void (*request_reresolution)(void* resolver_user_data);+  void (*destroy)(void* resolver_user_data);+};++class CustomResolverObserver;++class ResolverAddresses : public grpc_addresses {+ public:+  ResolverAddresses(size_t capacity) : capacity_(capacity) {+    addresses_ = grpc_lb_addresses_create(capacity, nullptr);+    addresses_->num_addresses = 0;+  }++  ~ResolverAddresses() { grpc_lb_addresses_destroy(addresses_); }++  bool AddAddress(const char* target, bool is_balancer,+                  const char* balancer_name) {+    if (addresses_->num_addresses >= capacity_) {+      return false;+    };+    grpc_uri* uri = grpc_uri_parse(target, false);+    if (!uri) return false;+    size_t index = addresses_->num_addresses++;+    bool result = grpc_lb_addresses_set_address_from_uri(+        addresses_, index, uri, is_balancer, balancer_name, nullptr);+    grpc_uri_destroy(uri);+    if (!result) {+      addresses_->num_addresses--;+    }+    return result;+  }++  grpc_lb_addresses* GetAddresses() { return addresses_; }++ private:+  grpc_lb_addresses* addresses_;+  size_t capacity_;+};++class CustomResolverFactory;++class CustomResolver : public Resolver {+ public:+  explicit CustomResolver(const ResolverArgs& args,+                          const ResolverVTable& vtable);++  void Init(void* user_data) { user_data_ = user_data; }+  void SetNextResult(grpc_channel_args* resolved_channel_args);++  void NextLocked(grpc_channel_args** result,+                  grpc_closure* on_complete) override;++  void RequestReresolutionLocked() override;++  void InitObserver(CustomResolverObserver* observer);++ private:+  friend class CustomResolverFactory;++  virtual ~CustomResolver();++  void MaybeFinishNextLocked();++  void ShutdownLocked() override;++  void* user_data_ = nullptr;+  ResolverVTable vtable_;++  // Next resolved addresses.+  gpr_mu resolved_lock_;+  grpc_closure resolved_closure_;+  grpc_channel_args* resolved_channel_args_ = nullptr;+  // Pending next completion, or NULL.+  grpc_closure* next_completion_ = nullptr;+  grpc_channel_args** target_result_ = nullptr;+};++CustomResolver::CustomResolver(const ResolverArgs& args,+                               const ResolverVTable& vtable)+    : Resolver(args.combiner), vtable_(vtable) {+  gpr_mu_init(&resolved_lock_);+}++CustomResolver::~CustomResolver() {+  grpc_channel_args_destroy(resolved_channel_args_);+  gpr_mu_destroy(&resolved_lock_);+}++struct SetNextArgs {+  CustomResolver* resolver;+  RefCountedPtr<Resolver> resolver_guard;","Why record the same pointer twice, once as a raw pointer and once as a `RefCountedPtr<>`?If the reason for this was because one is the base class and the other is the subclass, I think you can actually make the `RefCountedPtr<>` to be of the subclass type; it should automatically convert when you assign it.  But if that doesn't work for some reason, it seems better to cast to the subclass rather than recording the same pointer twice.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16617,217838619,2018-09-14T20:49:57Z,src/core/ext/filters/client_channel/resolver/custom/custom_resolver.cc,"@@ -0,0 +1,363 @@+//+// Copyright 2016 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.+//++// Shim resolver for exposing public API for custom application resolvers.++#include <grpc/support/port_platform.h>++#include <limits.h>+#include <stdbool.h>+#include <stdio.h>+#include <stdlib.h>+#include <string.h>++#include <grpc/support/alloc.h>+#include <grpc/support/string_util.h>++#include ""src/core/ext/filters/client_channel/lb_policy_factory.h""+#include ""src/core/ext/filters/client_channel/parse_address.h""+#include ""src/core/ext/filters/client_channel/resolver_registry.h""+#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/gpr/host_port.h""+#include ""src/core/lib/gpr/string.h""+#include ""src/core/lib/gprpp/mutex_lock.h""+#include ""src/core/lib/iomgr/closure.h""+#include ""src/core/lib/iomgr/combiner.h""+#include ""src/core/lib/iomgr/resolve_address.h""+#include ""src/core/lib/iomgr/unix_sockets_posix.h""+#include ""src/core/lib/slice/slice_internal.h""+#include ""src/core/lib/slice/slice_string_helpers.h""++struct grpc_addresses {};+struct grpc_resolver {};+struct grpc_resolver_observer {};+struct grpc_resolver_factory {};+struct grpc_resolver_args {+  const grpc_core::ResolverArgs* args;+};++namespace grpc_core {++namespace {++struct ResolverFactoryVTable {+  void* (*resolve)(void* factory_user_data, grpc_resolver_args* args,+                   grpc_resolver_observer* observer);+  void (*destroy)(void* factory_user_data);+};++struct ResolverVTable {+  void (*request_reresolution)(void* resolver_user_data);+  void (*destroy)(void* resolver_user_data);+};++class CustomResolverObserver;++class ResolverAddresses : public grpc_addresses {+ public:+  ResolverAddresses(size_t capacity) : capacity_(capacity) {+    addresses_ = grpc_lb_addresses_create(capacity, nullptr);+    addresses_->num_addresses = 0;+  }++  ~ResolverAddresses() { grpc_lb_addresses_destroy(addresses_); }++  bool AddAddress(const char* target, bool is_balancer,+                  const char* balancer_name) {+    if (addresses_->num_addresses >= capacity_) {+      return false;+    };+    grpc_uri* uri = grpc_uri_parse(target, false);+    if (!uri) return false;+    size_t index = addresses_->num_addresses++;+    bool result = grpc_lb_addresses_set_address_from_uri(+        addresses_, index, uri, is_balancer, balancer_name, nullptr);+    grpc_uri_destroy(uri);+    if (!result) {+      addresses_->num_addresses--;+    }+    return result;+  }++  grpc_lb_addresses* GetAddresses() { return addresses_; }++ private:+  grpc_lb_addresses* addresses_;+  size_t capacity_;+};++class CustomResolverFactory;++class CustomResolver : public Resolver {",Suggest renaming this to `PluginResolver`.,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16617,218106354,2018-09-17T15:04:53Z,test/core/client_channel/resolvers/custom_resolver_test.cc,"@@ -0,0 +1,359 @@+/*+ *+ * Copyright 2017 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <string.h>++#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>++#include ""src/core/ext/filters/client_channel/lb_policy_factory.h""+#include ""src/core/ext/filters/client_channel/parse_address.h""+#include ""src/core/ext/filters/client_channel/resolver/fake/fake_resolver.h""+#include ""src/core/ext/filters/client_channel/resolver_registry.h""+#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/gprpp/ref_counted_ptr.h""+#include ""src/core/lib/iomgr/combiner.h""+#include ""src/core/lib/security/credentials/fake/fake_credentials.h""++#include ""test/core/util/test_config.h""++#include <gtest/gtest.h>++grpc_lb_addresses* grpc_addresses_copy_lb_addresses_for_test(+    grpc_addresses* addresses);++namespace grpc {+namespace testing {+namespace {++class AddressesDelete {+ public:+  void operator()(grpc_addresses* addresses) {+    grpc_addresses_destroy(addresses);+  }+};++typedef std::unique_ptr<grpc_addresses, AddressesDelete> Addresses;++typedef struct on_resolution_arg {+  grpc_channel_args* resolver_result;+  grpc_lb_addresses* expected_resolver_result;+  gpr_event ev;+} on_resolution_arg;++// Callback to check the resolution result is as expected.+void on_resolution_cb(void* arg, grpc_error* error) {+  if (error != GRPC_ERROR_NONE) return;+  on_resolution_arg* res = static_cast<on_resolution_arg*>(arg);+  // We only check the addresses channel arg because that's the only one+  // explicitly set by the test via+  // FakeResolverResponseGenerator::SetResponse().+  const grpc_lb_addresses* actual_lb_addresses =+      grpc_lb_addresses_find_channel_arg(res->resolver_result);+  const grpc_lb_addresses* expected_lb_addresses =+      res->expected_resolver_result;+  GPR_ASSERT(+      grpc_lb_addresses_cmp(actual_lb_addresses, expected_lb_addresses) == 0);+  grpc_channel_args_destroy(res->resolver_result);+  grpc_lb_addresses_destroy(res->expected_resolver_result);+  gpr_event_set(&res->ev, (void*)1);+}++// Create a new resolution containing 2 addresses.+static Addresses create_new_resolver_result(size_t index) {+  const size_t num_addresses = 2;+  char* uri_string;+  char* balancer_name;+  // Create grpc_addresses.+  Addresses addresses(grpc_addresses_create(num_addresses, nullptr));+  for (size_t i = 0; i < num_addresses; ++i) {+    gpr_asprintf(&uri_string, ""ipv4:127.0.0.1:100%"" PRIuPTR,+                 index * num_addresses + i);+    gpr_asprintf(&balancer_name, ""balancer%"" PRIuPTR,+                 index * num_addresses + i);+    if (num_addresses % 2 == 0) {+      grpc_addresses_add_balancer_address(addresses.get(), uri_string,+                                          balancer_name);+    } else {+      grpc_addresses_add_direct_address(addresses.get(), uri_string);+    }+    gpr_free(balancer_name);+    gpr_free(uri_string);+  }+  return addresses;+}++static on_resolution_arg create_on_resolution_arg(const Addresses& results) {+  on_resolution_arg on_res_arg;+  memset(&on_res_arg, 0, sizeof(on_res_arg));+  on_res_arg.expected_resolver_result =+      grpc_addresses_copy_lb_addresses_for_test(results.get());+  gpr_event_init(&on_res_arg.ev);+  return on_res_arg;+}++class Resolver {+ public:+  explicit Resolver(grpc_resolver_observer* observer) : observer_(observer) {}+  virtual ~Resolver() { grpc_resolver_observer_destroy(observer_); }++  virtual void RequestReresolution() = 0;++  static void RequestReresolutionWrapper(void* user_data) {+    static_cast<Resolver*>(user_data)->RequestReresolution();+  }+  static void DestroyWrapper(void* user_data) {+    delete static_cast<Resolver*>(user_data);+  }++ protected:+  void SetAddresses(const Addresses& addresses) {+    grpc_resolver_observer_set_addresses(observer_, addresses.get());+  }++ private:+  grpc_resolver_observer* observer_;+  grpc_addresses* reresolution_response_ = nullptr;+};++class ResolverFactory {+ public:+  ResolverFactory() {}+  virtual ~ResolverFactory() {}++  virtual Resolver* Resolve(grpc_resolver_args* args,+                            grpc_resolver_observer* observer) = 0;++  static void* ResolveWrapper(void* user_data, grpc_resolver_args* args,+                              grpc_resolver_observer* observer) {+    return static_cast<ResolverFactory*>(user_data)->Resolve(args, observer);+  }+  static void DestroyWrapper(void* user_data) {+    delete static_cast<ResolverFactory*>(user_data);+  }+};++class FakeResolver : public Resolver {+ public:+  FakeResolver(grpc_resolver_args* args, grpc_resolver_observer* observer)+      : Resolver(observer) {}++  void RequestReresolution() {+    if (reresolution_response_ != nullptr) {+      SetAddresses(reresolution_response_);+    }+  }++  void SetResponse(const Addresses& addresses) { SetAddresses(addresses); }++  void SetReresolutionResponse(Addresses addresses) {+    reresolution_response_ = std::move(addresses);+  }++ private:+  Addresses reresolution_response_ = nullptr;+};++class FakeResolverFactory : public ResolverFactory {+ public:+  FakeResolverFactory(FakeResolver** resolver) : resolver_(resolver) {}++  Resolver* Resolve(grpc_resolver_args* args,+                    grpc_resolver_observer* observer) {+    GPR_ASSERT(resolver_ != nullptr);+    auto resolver = new FakeResolver(args, observer);+    *resolver_ = resolver;+    resolver_ = nullptr;+    return resolver;+  }++ private:+  FakeResolver** resolver_;+};++static grpc_core::OrphanablePtr<grpc_core::Resolver> build_custom_resolver(+    const char* scheme, grpc_combiner* combiner) {+  grpc_core::ResolverFactory* factory =+      grpc_core::ResolverRegistry::LookupResolverFactory(scheme);+  grpc_channel_args channel_args = {0, nullptr};+  grpc_core::ResolverArgs args;+  args.args = &channel_args;+  args.combiner = combiner;+  return factory->CreateResolver(args);+}++static void register_resolver_factory(const char* scheme,+                                      ResolverFactory* factory) {+  grpc_resolver_factory_register(+      scheme, factory, ResolverFactory::ResolveWrapper,+      ResolverFactory::DestroyWrapper, Resolver::RequestReresolutionWrapper,+      Resolver::DestroyWrapper, nullptr);+}++TEST(CustomResolverTest, End2End) {+  FakeResolver* fake_resolver = nullptr;+  register_resolver_factory(""custom"", new FakeResolverFactory(&fake_resolver));++  grpc_core::ExecCtx exec_ctx;+  grpc_combiner* combiner = grpc_combiner_create();+  // Create resolver.+  grpc_core::OrphanablePtr<grpc_core::Resolver> resolver =+      build_custom_resolver(""custom"", combiner);+  GPR_ASSERT(resolver.get() != nullptr);+  GPR_ASSERT(fake_resolver != nullptr);+  // Test 1: normal resolution.+  // next_results != NULL, reresolution_results == NULL.+  // Expected response is next_results.+  Addresses results = create_new_resolver_result(1);+  on_resolution_arg on_res_arg = create_on_resolution_arg(results);+  grpc_closure* on_resolution = GRPC_CLOSURE_CREATE(+      on_resolution_cb, &on_res_arg, grpc_combiner_scheduler(combiner));+  // Resolution won't be triggered until next_results is set.+  resolver->NextLocked(&on_res_arg.resolver_result, on_resolution);+  fake_resolver->SetResponse(results);+  grpc_core::ExecCtx::Get()->Flush();+  GPR_ASSERT(gpr_event_wait(&on_res_arg.ev,+                            grpc_timeout_seconds_to_deadline(5)) != nullptr);+  // Test 2: update resolution.+  // next_results != NULL, reresolution_results == NULL.+  // Expected response is next_results.+  results = create_new_resolver_result(2);+  on_res_arg = create_on_resolution_arg(results);+  on_resolution = GRPC_CLOSURE_CREATE(on_resolution_cb, &on_res_arg,+                                      grpc_combiner_scheduler(combiner));+  // Resolution won't be triggered until next_results is set.+  resolver->NextLocked(&on_res_arg.resolver_result, on_resolution);+  fake_resolver->SetResponse(results);+  grpc_core::ExecCtx::Get()->Flush();+  GPR_ASSERT(gpr_event_wait(&on_res_arg.ev,+                            grpc_timeout_seconds_to_deadline(5)) != nullptr);+  // Test 3: normal re-resolution.+  // next_results == NULL, reresolution_results != NULL.+  // Expected response is reresolution_results.+  Addresses reresolution_results = create_new_resolver_result(3);+  on_res_arg = create_on_resolution_arg(reresolution_results);+  on_resolution_arg on_reresolution_res_arg =+      create_on_resolution_arg(reresolution_results);+  on_resolution = GRPC_CLOSURE_CREATE(on_resolution_cb, &on_res_arg,+                                      grpc_combiner_scheduler(combiner));+  resolver->NextLocked(&on_res_arg.resolver_result, on_resolution);+  // Set reresolution_results.+  fake_resolver->SetReresolutionResponse(std::move(reresolution_results));+  // Flush here to guarantee that the response has been set.+  grpc_core::ExecCtx::Get()->Flush();+  // Trigger a re-resolution.+  resolver->RequestReresolutionLocked();+  grpc_core::ExecCtx::Get()->Flush();+  GPR_ASSERT(gpr_event_wait(&on_res_arg.ev,+                            grpc_timeout_seconds_to_deadline(5)) != nullptr);+  // Test 4: repeat re-resolution.+  // next_results == NULL, reresolution_results != NULL.+  // Expected response is reresolution_results.+  on_resolution =+      GRPC_CLOSURE_CREATE(on_resolution_cb, &on_reresolution_res_arg,+                          grpc_combiner_scheduler(combiner));+  resolver->NextLocked(&on_reresolution_res_arg.resolver_result, on_resolution);+  // Trigger a re-resolution.+  resolver->RequestReresolutionLocked();+  grpc_core::ExecCtx::Get()->Flush();+  GPR_ASSERT(gpr_event_wait(&on_res_arg.ev,+                            grpc_timeout_seconds_to_deadline(5)) != nullptr);+  // Test 5: normal resolution.+  // next_results != NULL, reresolution_results != NULL.+  // Expected response is next_results.+  results = create_new_resolver_result(4);+  on_res_arg = create_on_resolution_arg(results);+  on_resolution = GRPC_CLOSURE_CREATE(on_resolution_cb, &on_res_arg,+                                      grpc_combiner_scheduler(combiner));+  // Resolution won't be triggered until next_results is set.+  resolver->NextLocked(&on_res_arg.resolver_result, on_resolution);+  fake_resolver->SetResponse(results);+  grpc_core::ExecCtx::Get()->Flush();+  GPR_ASSERT(gpr_event_wait(&on_res_arg.ev,+                            grpc_timeout_seconds_to_deadline(5)) != nullptr);+  // Test 6: multiple updates.+  // If SetAddresses is called multiple times the last one wins.+  results = create_new_resolver_result(5);+  fake_resolver->SetResponse(results);+  results = create_new_resolver_result(6);+  fake_resolver->SetResponse(results);+  results = create_new_resolver_result(7);+  fake_resolver->SetResponse(results);+  memset(&on_res_arg, 0, sizeof(on_res_arg));+  on_res_arg = create_on_resolution_arg(results);+  on_resolution = GRPC_CLOSURE_CREATE(on_resolution_cb, &on_res_arg,+                                      grpc_combiner_scheduler(combiner));+  resolver->NextLocked(&on_res_arg.resolver_result, on_resolution);+  grpc_core::ExecCtx::Get()->Flush();+  GPR_ASSERT(gpr_event_wait(&on_res_arg.ev,+                            grpc_timeout_seconds_to_deadline(5)) != nullptr);+  // Test 7: no-op.+  // Requesting a new resolution without setting the response shouldn't+  // trigger the resolution callback.+  memset(&on_res_arg, 0, sizeof(on_res_arg));+  on_resolution = GRPC_CLOSURE_CREATE(on_resolution_cb, &on_res_arg,+                                      grpc_combiner_scheduler(combiner));+  resolver->NextLocked(&on_res_arg.resolver_result, on_resolution);+  grpc_core::ExecCtx::Get()->Flush();+  GPR_ASSERT(gpr_event_wait(&on_res_arg.ev,+                            grpc_timeout_milliseconds_to_deadline(100)) ==+             nullptr);+  // Clean up.+  // Note: Need to explicitly unref the resolver and flush the exec_ctx+  // to make sure that the final resolver callback (with error set to+  // ""Resolver Shutdown"") is invoked before on_res_arg goes out of scope.+  resolver.reset();+  grpc_core::ExecCtx::Get()->Flush();+  GRPC_COMBINER_UNREF(combiner, ""CustomResolverTest"");+}++class ZeroResolverFactory : public ResolverFactory {+ public:+  virtual Resolver* Resolve(grpc_resolver_args* args,+                            grpc_resolver_observer* observer) {+    return nullptr;+  }+};++TEST(CustomResolverTest, Failure) {",Suggest calling this something like `FailToInstantiateResolver`.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16617,218114263,2018-09-17T15:24:10Z,src/core/ext/filters/client_channel/resolver/custom/custom_resolver.cc,"@@ -0,0 +1,363 @@+//+// Copyright 2016 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.+//++// Shim resolver for exposing public API for custom application resolvers.++#include <grpc/support/port_platform.h>++#include <limits.h>+#include <stdbool.h>+#include <stdio.h>+#include <stdlib.h>+#include <string.h>++#include <grpc/support/alloc.h>+#include <grpc/support/string_util.h>++#include ""src/core/ext/filters/client_channel/lb_policy_factory.h""+#include ""src/core/ext/filters/client_channel/parse_address.h""+#include ""src/core/ext/filters/client_channel/resolver_registry.h""+#include ""src/core/lib/channel/channel_args.h""+#include ""src/core/lib/gpr/host_port.h""+#include ""src/core/lib/gpr/string.h""+#include ""src/core/lib/gprpp/mutex_lock.h""+#include ""src/core/lib/iomgr/closure.h""+#include ""src/core/lib/iomgr/combiner.h""+#include ""src/core/lib/iomgr/resolve_address.h""+#include ""src/core/lib/iomgr/unix_sockets_posix.h""+#include ""src/core/lib/slice/slice_internal.h""+#include ""src/core/lib/slice/slice_string_helpers.h""++struct grpc_addresses {};+struct grpc_resolver {};+struct grpc_resolver_observer {};+struct grpc_resolver_factory {};+struct grpc_resolver_args {+  const grpc_core::ResolverArgs* args;+};++namespace grpc_core {++namespace {++struct ResolverFactoryVTable {+  void* (*resolve)(void* factory_user_data, grpc_resolver_args* args,+                   grpc_resolver_observer* observer);+  void (*destroy)(void* factory_user_data);+};++struct ResolverVTable {+  void (*request_reresolution)(void* resolver_user_data);+  void (*destroy)(void* resolver_user_data);+};++class CustomResolverObserver;++class ResolverAddresses : public grpc_addresses {+ public:+  ResolverAddresses(size_t capacity) : capacity_(capacity) {+    addresses_ = grpc_lb_addresses_create(capacity, nullptr);+    addresses_->num_addresses = 0;+  }++  ~ResolverAddresses() { grpc_lb_addresses_destroy(addresses_); }++  bool AddAddress(const char* target, bool is_balancer,+                  const char* balancer_name) {+    if (addresses_->num_addresses >= capacity_) {+      return false;+    };+    grpc_uri* uri = grpc_uri_parse(target, false);+    if (!uri) return false;+    size_t index = addresses_->num_addresses++;+    bool result = grpc_lb_addresses_set_address_from_uri(+        addresses_, index, uri, is_balancer, balancer_name, nullptr);+    grpc_uri_destroy(uri);+    if (!result) {+      addresses_->num_addresses--;+    }+    return result;+  }++  grpc_lb_addresses* GetAddresses() { return addresses_; }++ private:+  grpc_lb_addresses* addresses_;+  size_t capacity_;+};++class CustomResolverFactory;++class CustomResolver : public Resolver {","Currently, each individual polling-based resolver needs to contain code to handle (a) automatically retrying with exponential backoff upon failure and (b) using a minimum reresolution interval to avoid hammering the name service.  However, because this functionality is actually common to all polling-based resolvers, we plan to eventually move it out of the individual resolver implementations and into the client channel code.  When we do that, we will remove this code from the individual resolver implementations, but we won't be able to do that for the plugins, since we won't control them.  So for now, I think we need to add that functionality here in the `CustomResolver` class, so that plugins can be written assuming that this functionality will be handled for them.  Later, when we move this functionality into the client channel code, we can remove it from here.You can probably copy most of the implementation of this from src/core/ext/filters/client_channel/resolver/dns/native/dns_resolver.cc.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16582,218190913,2018-09-17T19:05:59Z,src/core/lib/security/transport/server_auth_filter.cc,"@@ -41,16 +41,16 @@ struct call_data {   grpc_transport_stream_op_batch* recv_initial_metadata_batch;   grpc_closure* original_recv_initial_metadata_ready;   grpc_closure recv_initial_metadata_ready;-  grpc_error* error;+  grpc_error* recv_initial_metadata_error;   grpc_closure recv_trailing_metadata_ready;   grpc_closure* original_recv_trailing_metadata_ready;+  grpc_error* recv_trailing_metadata_error;+  bool seen_recv_trailing_ready;",Please call this `seen_recv_trailing_metadata_ready`.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16582,218193326,2018-09-17T19:14:23Z,src/core/lib/surface/server.cc,"@@ -730,18 +733,39 @@ static void server_on_recv_initial_metadata(void* ptr, grpc_error* error) {     grpc_error* src_error = error;","No need for this local variable anymore; instead, assign directly to `calld->recv_initial_metadata_error`.",OK
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/16640,218218245,2018-09-17T20:36:49Z,src/python/grpcio/grpc/_cython/_cygrpc/credentials.pyx.pxi,"@@ -144,8 +144,14 @@ cdef class SSLChannelCredentials(ChannelCredentials):       return grpc_ssl_credentials_create(           c_pem_root_certificates, NULL, NULL, NULL)     else:-      c_pem_key_certificate_pair.private_key = self._private_key-      c_pem_key_certificate_pair.certificate_chain = self._certificate_chain+      if self._private_key:","The real problem is we are hiding Cython exceptions, not just here. We should revamp Cython code to surface exceptions.I will file an issue for that.",OK
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/16582,218243858,2018-09-17T22:09:14Z,src/core/lib/surface/server.cc,"@@ -730,18 +733,39 @@ static void server_on_recv_initial_metadata(void* ptr, grpc_error* error) {     grpc_error* src_error = error;",reverted. it would actually be needed since we want recv_initial_metadata_error to ref the new error and not the old error.,OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16490,218325702,2018-09-18T07:35:17Z,src/ruby/lib/grpc/generic/active_call.rb,"@@ -582,6 +584,23 @@ def attach_peer_cert(peer_cert)      private +    # response_status_as_trailers_only sends a status as Trailers-only+    # https://github.com/grpc/grpc/blob/ceecf80283e6ca184df587f76ed053f1f5295b7f/doc/PROTOCOL-HTTP2.md+    def response_status_as_trailers_only(code, details, metadata: {})+      @send_initial_md_mutex.synchronize do+        # Can't send Trailers-Only since Response-Headers have already been sent+        return false if @metadata_sent+        @metadata_sent = true+      end++      @call.run_batch(+        SEND_INITIAL_METADATA => @metadata_to_send,","Sorry, don't fully understand here - this `response_status_as_trailers_only` is sending both metadata and trailers, is this intended?",
5616899,ganmacs,https://api.github.com/repos/grpc/grpc/pulls/16490,218366363,2018-09-18T09:45:41Z,src/ruby/lib/grpc/generic/active_call.rb,"@@ -582,6 +584,23 @@ def attach_peer_cert(peer_cert)      private +    # response_status_as_trailers_only sends a status as Trailers-only+    # https://github.com/grpc/grpc/blob/ceecf80283e6ca184df587f76ed053f1f5295b7f/doc/PROTOCOL-HTTP2.md+    def response_status_as_trailers_only(code, details, metadata: {})+      @send_initial_md_mutex.synchronize do+        # Can't send Trailers-Only since Response-Headers have already been sent+        return false if @metadata_sent+        @metadata_sent = true+      end++      @call.run_batch(+        SEND_INITIAL_METADATA => @metadata_to_send,",Yes. I'd like to send response data as Trailers-Only (https://github.com/grpc/grpc/blob/ceecf80283e6ca184df587f76ed053f1f5295b7f/doc/PROTOCOL-HTTP2.md#responses) if possible.,
24657604,wcevans,https://api.github.com/repos/grpc/grpc/pulls/16646,218547027,2018-09-18T18:35:00Z,src/compiler/cpp_generator.cc,"@@ -547,6 +548,115 @@ void PrintHeaderClientMethod(grpc_generator::Printer* printer,   } } +void PrintHeaderClientMethodCallbackInterfacesStart(+    grpc_generator::Printer* printer,+    std::map<grpc::string, grpc::string>* vars) {+  // This declares the interface for the callback-based API. The components+  // are pure; even though this is new (post-1.0) API, it can be pure because+  // it is an entirely new interface that happens to be scoped within+  // StubInterface, not new additions to StubInterface itself+  printer->Print(""class experimental_async_interface {\n"");+  // All methods in this new interface are public. There is no need for private+  // ""Raw"" methods since the callback-based API returns unowned raw pointers+  printer->Print("" public:\n"");+  printer->Indent();+}++void PrintHeaderClientMethodCallbackInterfaces(+    grpc_generator::Printer* printer, const grpc_generator::Method* method,+    std::map<grpc::string, grpc::string>* vars, bool is_public) {+  // Reserve is_public for future expansion+  assert(is_public);++  (*vars)[""Method""] = method->name();+  (*vars)[""Request""] = method->input_type_name();+  (*vars)[""Response""] = method->output_type_name();++  if (method->NoStreaming()) {+    printer->Print(*vars,+                   ""virtual void $Method$(::grpc::ClientContext* context, ""+                   ""const $Request$* request, $Response$* response, ""+                   ""std::function<void(::grpc::Status)>) = 0;\n"");+  } else if (ClientOnlyStreaming(method)) {+    // TODO(vjpai): Add support for client-side streaming+  } else if (ServerOnlyStreaming(method)) {+    // TODO(vjpai): Add support for server-side streaming+  } else if (method->BidiStreaming()) {+    // TODO(vjpai): Add support for bidi streaming+  }+}++void PrintHeaderClientMethodCallbackInterfacesEnd(+    grpc_generator::Printer* printer,+    std::map<grpc::string, grpc::string>* vars) {+  printer->Outdent();+  printer->Print(""};\n"");++  // Declare a function to give the async stub contents. It can't be pure+  // since this is new API in StubInterface, but it is meaningless by default+  // (since any stub that wants to use it must have its own implementation of+  // the callback functions therein), so make the default return value nullptr.+  // Intentionally include the word ""class"" to avoid possible shadowing.+  printer->Print(+      ""virtual class experimental_async_interface* experimental_async() { ""+      ""return nullptr; }\n"");+}++void PrintHeaderClientMethodCallbackStart(+    grpc_generator::Printer* printer,+    std::map<grpc::string, grpc::string>* vars) {+  // This declares the stub entry for the callback-based API.+  printer->Print(""class experimental_async final :\n"");+  printer->Print(""  public StubInterface::experimental_async_interface {\n"");",Why is this preferred over an entirely separate class (e.g. CallbackStubInterface)?,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16646,218552390,2018-09-18T18:51:03Z,src/compiler/cpp_generator.cc,"@@ -547,6 +548,115 @@ void PrintHeaderClientMethod(grpc_generator::Printer* printer,   } } +void PrintHeaderClientMethodCallbackInterfacesStart(+    grpc_generator::Printer* printer,+    std::map<grpc::string, grpc::string>* vars) {+  // This declares the interface for the callback-based API. The components+  // are pure; even though this is new (post-1.0) API, it can be pure because+  // it is an entirely new interface that happens to be scoped within+  // StubInterface, not new additions to StubInterface itself+  printer->Print(""class experimental_async_interface {\n"");+  // All methods in this new interface are public. There is no need for private+  // ""Raw"" methods since the callback-based API returns unowned raw pointers+  printer->Print("" public:\n"");+  printer->Indent();+}++void PrintHeaderClientMethodCallbackInterfaces(+    grpc_generator::Printer* printer, const grpc_generator::Method* method,+    std::map<grpc::string, grpc::string>* vars, bool is_public) {+  // Reserve is_public for future expansion+  assert(is_public);++  (*vars)[""Method""] = method->name();+  (*vars)[""Request""] = method->input_type_name();+  (*vars)[""Response""] = method->output_type_name();++  if (method->NoStreaming()) {+    printer->Print(*vars,","So the overload method works for unary, but not for streaming (esp bidi streaming). Agreed that this could be interesting. @ncteisen mentioned this as part of a broader proposal, but nobody ever gave a use case for this part. Would be interesting to see a use-case. That said, that's also independent of callback vs non-calback.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16646,218552731,2018-09-18T18:52:03Z,src/compiler/cpp_generator.cc,"@@ -547,6 +548,115 @@ void PrintHeaderClientMethod(grpc_generator::Printer* printer,   } } +void PrintHeaderClientMethodCallbackInterfacesStart(+    grpc_generator::Printer* printer,+    std::map<grpc::string, grpc::string>* vars) {+  // This declares the interface for the callback-based API. The components+  // are pure; even though this is new (post-1.0) API, it can be pure because+  // it is an entirely new interface that happens to be scoped within+  // StubInterface, not new additions to StubInterface itself+  printer->Print(""class experimental_async_interface {\n"");","I think I might be ok with that. We've been using ""experimental"" in lower-case though, so let me see if we're ok with going with uppercase. I don't accidentally want to make this api just yet.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16646,218575737,2018-09-18T20:06:09Z,src/compiler/cpp_generator.cc,"@@ -547,6 +548,115 @@ void PrintHeaderClientMethod(grpc_generator::Printer* printer,   } } +void PrintHeaderClientMethodCallbackInterfacesStart(+    grpc_generator::Printer* printer,+    std::map<grpc::string, grpc::string>* vars) {+  // This declares the interface for the callback-based API. The components+  // are pure; even though this is new (post-1.0) API, it can be pure because+  // it is an entirely new interface that happens to be scoped within+  // StubInterface, not new additions to StubInterface itself+  printer->Print(""class experimental_async_interface {\n"");+  // All methods in this new interface are public. There is no need for private+  // ""Raw"" methods since the callback-based API returns unowned raw pointers+  printer->Print("" public:\n"");+  printer->Indent();+}++void PrintHeaderClientMethodCallbackInterfaces(+    grpc_generator::Printer* printer, const grpc_generator::Method* method,+    std::map<grpc::string, grpc::string>* vars, bool is_public) {+  // Reserve is_public for future expansion+  assert(is_public);++  (*vars)[""Method""] = method->name();+  (*vars)[""Request""] = method->input_type_name();+  (*vars)[""Response""] = method->output_type_name();++  if (method->NoStreaming()) {+    printer->Print(*vars,","Actually, the streaming case isn't necessarily bad either since we can just have overloads of Read and Write, I think.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16646,218620067,2018-09-18T22:52:08Z,test/cpp/codegen/compiler_test_golden,"@@ -105,6 +106,22 @@ class ServiceA final {       return std::unique_ptr< ::grpc::ClientAsyncReaderWriterInterface< ::grpc::testing::Request, ::grpc::testing::Response>>(PrepareAsyncMethodA4Raw(context, cq));     }     // Method A4 trailing comment 1+    class experimental_async_interface {","Great question. I'd actually suggest going the other way, and naming that experimental_async as well for now. Longer term, the design plan is to just use ""async()"" as the marker. I had earlier thought that GenericStub could just go without any marker like that, since the overloads are sufficient for distinction, but I think that actually a marker for consistency would be reasonable. If you think that that's a good idea, I'll loop it into this PR as well.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/16651,218878715,2018-09-19T16:42:12Z,test/cpp/end2end/client_lb_end2end_test.cc,"@@ -570,20 +588,21 @@ TEST_F(ClientLbEnd2endTest, PickFirstManyUpdates) {   for (size_t i = 0; i < servers_.size(); ++i) {     ports.emplace_back(servers_[i]->port_);   }-  for (const bool force_creation : {true, false}) {-    grpc_subchannel_index_test_only_set_force_creation(force_creation);-    gpr_log(GPR_INFO, ""Force subchannel creation: %d"", force_creation);-    for (size_t i = 0; i < 1000; ++i) {-      std::shuffle(ports.begin(), ports.end(),-                   std::mt19937(std::random_device()()));-      SetNextResolution(ports);-      if (i % 10 == 0) CheckRpcSendOk(stub, DEBUG_LOCATION);-    }+  for (size_t i = 0; i < 1000; ++i) {+    std::shuffle(ports.begin(), ports.end(),+                 std::mt19937(std::random_device()()));+    SetNextResolution(ports);+    if (i % 10 == 0) CheckRpcSendOk(stub, DEBUG_LOCATION);   }   // Check LB policy name for the channel.   EXPECT_EQ(""pick_first"", channel->GetLoadBalancingPolicyName());+  // Wait for a while so that the resolution setting closure is flushed.+  sleep(2);","Calling `CheckRpcSendOk()` again works!This is a use-after-free bug after the test has been destroyed (`ClientLbEnd2endWithParamTest`'s dtor called). So as long as we have a separate test for `force_creation == true`, we are faced with this bug. BTW, `::testing::Bool()` yields `{false, true}` (which doesn't matter a lot since we can flip the bool's meaning). Also, it looks like the tests with different param value are run in a non-deterministic fashion. Sometimes, `*/1` runs first.```➜  grpc git:(improve_force_creation) ✗ tools/run_tests/run_tests.py -l c++ -r ""PickFirstManyUpdates""  PASSED: make [time=149.4sec, retries=0:0]2018-09-18 18:25:16,276 detected port server running version 202018-09-18 18:25:16,309 my port server is version 20PASSED: bins/opt/client_lb_end2end_test --gtest_filter=ReuseSubchannel/ClientLbEnd2endWithParamTest.PickFirstManyUpdates/1  GRPC_POLL_STRATEGY=epollsig [time=PASSED: bins/opt/client_lb_end2end_test --gtest_filter=ReuseSubchannel/ClientLbEnd2endWithParamTest.PickFirstManyUpdates/1  GRPC_POLL_STRATEGY=poll [time=2.1sPASSED: bins/opt/client_lb_end2end_test --gtest_filter=ReuseSubchannel/ClientLbEnd2endWithParamTest.PickFirstManyUpdates/1  GRPC_POLL_STRATEGY=epollex [time=2PASSED: bins/opt/client_lb_end2end_test --gtest_filter=ReuseSubchannel/ClientLbEnd2endWithParamTest.PickFirstManyUpdates/1  GRPC_POLL_STRATEGY=epoll1 [time=2.PASSED: bins/opt/client_lb_end2end_test --gtest_filter=ReuseSubchannel/ClientLbEnd2endWithParamTest.PickFirstManyUpdates/0  GRPC_POLL_STRATEGY=epoll1 [time=2.PASSED: bins/opt/client_lb_end2end_test --gtest_filter=ReuseSubchannel/ClientLbEnd2endWithParamTest.PickFirstManyUpdates/0  GRPC_POLL_STRATEGY=epollex [time=2PASSED: bins/opt/client_lb_end2end_test --gtest_filter=ReuseSubchannel/ClientLbEnd2endWithParamTest.PickFirstManyUpdates/0  GRPC_POLL_STRATEGY=epollsig [time=PASSED: bins/opt/client_lb_end2end_test --gtest_filter=ReuseSubchannel/ClientLbEnd2endWithParamTest.PickFirstManyUpdates/0  GRPC_POLL_STRATEGY=poll [time=2.6sPASSED: bins/opt/client_lb_end2end_test --gtest_filter=ReuseSubchannel/ClientLbEnd2endWithParamTest.PickFirstManyUpdates/1  GRPC_POLL_STRATEGY=poll-cv [time=4PASSED: bins/opt/client_lb_end2end_test --gtest_filter=ReuseSubchannel/ClientLbEnd2endWithParamTest.PickFirstManyUpdates/0  GRPC_POLL_STRATEGY=poll-cv [time=4SUCCESS: All tests passed```But sometimes the opposite.```➜  grpc git:(improve_force_creation) ✗ tools/run_tests/run_tests.py -l c++ -r ""PickFirstManyUpdates"" PASSED: make [time=147.8sec, retries=0:0]2018-09-19 09:35:49,129 detected port server running version 202018-09-19 09:35:49,160 my port server is version 20PASSED: bins/opt/client_lb_end2end_test --gtest_filter=SubchannelForceCreation/ClientLbEnd2endWithParamTest.PickFirstManyUpdates/0  GRPC_POLL_STRATEGY=epollexPASSED: bins/opt/client_lb_end2end_test --gtest_filter=SubchannelForceCreation/ClientLbEnd2endWithParamTest.PickFirstManyUpdates/0  GRPC_POLL_STRATEGY=epollsiPASSED: bins/opt/client_lb_end2end_test --gtest_filter=SubchannelForceCreation/ClientLbEnd2endWithParamTest.PickFirstManyUpdates/0  GRPC_POLL_STRATEGY=poll [tPASSED: bins/opt/client_lb_end2end_test --gtest_filter=SubchannelForceCreation/ClientLbEnd2endWithParamTest.PickFirstManyUpdates/0  GRPC_POLL_STRATEGY=epoll1 PASSED: bins/opt/client_lb_end2end_test --gtest_filter=SubchannelForceCreation/ClientLbEnd2endWithParamTest.PickFirstManyUpdates/1  GRPC_POLL_STRATEGY=epoll1 PASSED: bins/opt/client_lb_end2end_test --gtest_filter=SubchannelForceCreation/ClientLbEnd2endWithParamTest.PickFirstManyUpdates/1  GRPC_POLL_STRATEGY=epollsiPASSED: bins/opt/client_lb_end2end_test --gtest_filter=SubchannelForceCreation/ClientLbEnd2endWithParamTest.PickFirstManyUpdates/1  GRPC_POLL_STRATEGY=epollexPASSED: bins/opt/client_lb_end2end_test --gtest_filter=SubchannelForceCreation/ClientLbEnd2endWithParamTest.PickFirstManyUpdates/1  GRPC_POLL_STRATEGY=poll [tPASSED: bins/opt/client_lb_end2end_test --gtest_filter=SubchannelForceCreation/ClientLbEnd2endWithParamTest.PickFirstManyUpdates/0  GRPC_POLL_STRATEGY=poll-cvPASSED: bins/opt/client_lb_end2end_test --gtest_filter=SubchannelForceCreation/ClientLbEnd2endWithParamTest.PickFirstManyUpdates/1  GRPC_POLL_STRATEGY=poll-cvSUCCESS: All tests passed```",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/16654,218889240,2018-09-19T17:13:05Z,src/core/tsi/alts_transport_security.cc,"@@ -63,3 +64,15 @@ void grpc_tsi_alts_shutdown() {   gpr_cv_destroy(&g_alts_resource.cv);   gpr_mu_destroy(&g_alts_resource.mu); }++void grpc_tsi_alts_shared_resource_ref() { gpr_ref(&g_alts_resource.refcount); }++void grpc_tsi_alts_shared_resource_unref() {+  if (gpr_unref(&g_alts_resource.refcount)) {+    grpc_completion_queue_shutdown(g_alts_resource.cq);",Lines 72-76 and Lines 58-62 can be refactored into a single function to avoid code duplication,OK
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/16654,218891458,2018-09-19T17:19:55Z,src/core/tsi/alts_transport_security.cc,"@@ -63,3 +64,15 @@ void grpc_tsi_alts_shutdown() {   gpr_cv_destroy(&g_alts_resource.cv);   gpr_mu_destroy(&g_alts_resource.mu); }++void grpc_tsi_alts_shared_resource_ref() { gpr_ref(&g_alts_resource.refcount); }",Initialization is lazily at https://github.com/grpc/grpc/blob/master/src/core/tsi/alts/handshaker/alts_tsi_handshaker.cc#L333,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16654,218899418,2018-09-19T17:43:35Z,src/core/tsi/alts_transport_security.cc,"@@ -63,3 +64,15 @@ void grpc_tsi_alts_shutdown() {   gpr_cv_destroy(&g_alts_resource.cv);   gpr_mu_destroy(&g_alts_resource.mu); }++void grpc_tsi_alts_shared_resource_ref() { gpr_ref(&g_alts_resource.refcount); }","Let me say this a different way: In terms of the API here, it seems odd to me that `grpc_tsi_alts_shared_resource_ref()` and `alts_get_shared_resource()` are different methods.  Shouldn't the API be that there is a single method that is responsible for returning a pointer along with a new ref, which the caller holds until they explicitly unref it?  Otherwise, the API allows weird things like taking a new ref when the previous refcount was 0 and no object actually exists.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16654,218911194,2018-09-19T18:18:03Z,src/core/tsi/alts_transport_security.cc,"@@ -50,6 +50,7 @@ void grpc_tsi_alts_init() {   g_alts_resource.is_cq_drained = false;   gpr_mu_init(&g_alts_resource.mu);   gpr_cv_init(&g_alts_resource.cv);+  gpr_ref_init(&g_alts_resource.refcount, 0); }  void grpc_tsi_alts_shutdown() {","I don't think it makes sense to have an API that can be used in both a ref-counted and non-ref-counted fashion.  We should pick one of the two approaches and stick with it.  If this is going to be ref-counted and Envoy is going to use it, then Envoy should be responsible for taking a ref and releasing it when it is no longer needed.",OK
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/16654,218943059,2018-09-19T19:57:27Z,src/core/tsi/alts_transport_security.cc,"@@ -63,3 +64,15 @@ void grpc_tsi_alts_shutdown() {   gpr_cv_destroy(&g_alts_resource.cv);   gpr_mu_destroy(&g_alts_resource.mu); }++void grpc_tsi_alts_shared_resource_ref() { gpr_ref(&g_alts_resource.refcount); }","I agree it will be better to have an API that returns a pointer along with the ref. Since in the current ALTS impl, the shared resource is needed at the TSI layer, we need to call `grpc_tsi_alts_shared_resource_ref()` at the credential layer and plumb it all the way down to TSI. I will update the code.",OK
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/16661,219234795,2018-09-20T16:35:50Z,src/core/ext/transport/chttp2/transport/parsing.cc,"@@ -409,67 +409,75 @@ static void on_initial_header(void* tp, grpc_mdelem md) {     gpr_free(value);   } -  if (grpc_slice_eq(GRPC_MDKEY(md), GRPC_MDSTR_GRPC_STATUS) &&-      !grpc_mdelem_eq(md, GRPC_MDELEM_GRPC_STATUS_0)) {-    /* TODO(ctiller): check for a status like "" 0"" */-    s->seen_error = true;-  }+  if (GRPC_MDELEM_STORAGE(md) == GRPC_MDELEM_STORAGE_STATIC) {+    if (md.payload == GRPC_MDELEM_GRPC_STATUS_1.payload ||+        md.payload == GRPC_MDELEM_GRPC_STATUS_2.payload) {+      s->seen_error = true;+    }+  } else {+    if (grpc_slice_eq(GRPC_MDKEY(md), GRPC_MDSTR_GRPC_STATUS) &&+        !grpc_mdelem_eq(md, GRPC_MDELEM_GRPC_STATUS_0)) {+      /* TODO(ctiller): check for a status like "" 0"" */+      s->seen_error = true;+    } -  if (grpc_slice_eq(GRPC_MDKEY(md), GRPC_MDSTR_GRPC_TIMEOUT)) {-    grpc_millis* cached_timeout =-        static_cast<grpc_millis*>(grpc_mdelem_get_user_data(md, free_timeout));-    grpc_millis timeout;-    if (cached_timeout != nullptr) {-      timeout = *cached_timeout;-    } else {-      if (GPR_UNLIKELY(-              !grpc_http2_decode_timeout(GRPC_MDVALUE(md), &timeout))) {-        char* val = grpc_slice_to_c_string(GRPC_MDVALUE(md));-        gpr_log(GPR_ERROR, ""Ignoring bad timeout value '%s'"", val);-        gpr_free(val);-        timeout = GRPC_MILLIS_INF_FUTURE;+    if (grpc_slice_eq(GRPC_MDKEY(md), GRPC_MDSTR_GRPC_TIMEOUT)) {","Do you mean this to be inside of the else block above? Isn't that changing the behavior? Before this would be executed un conditionally, now it is skipped if `GRPC_MDELEM_STORAGE(md) == GRPC_MDELEM_STORAGE_STATIC` is true",OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/16661,219242265,2018-09-20T16:58:57Z,src/core/ext/transport/chttp2/transport/parsing.cc,"@@ -409,67 +409,75 @@ static void on_initial_header(void* tp, grpc_mdelem md) {     gpr_free(value);   } -  if (grpc_slice_eq(GRPC_MDKEY(md), GRPC_MDSTR_GRPC_STATUS) &&-      !grpc_mdelem_eq(md, GRPC_MDELEM_GRPC_STATUS_0)) {-    /* TODO(ctiller): check for a status like "" 0"" */-    s->seen_error = true;-  }+  if (GRPC_MDELEM_STORAGE(md) == GRPC_MDELEM_STORAGE_STATIC) {+    if (md.payload == GRPC_MDELEM_GRPC_STATUS_1.payload ||+        md.payload == GRPC_MDELEM_GRPC_STATUS_2.payload) {+      s->seen_error = true;+    }+  } else {+    if (grpc_slice_eq(GRPC_MDKEY(md), GRPC_MDSTR_GRPC_STATUS) &&+        !grpc_mdelem_eq(md, GRPC_MDELEM_GRPC_STATUS_0)) {+      /* TODO(ctiller): check for a status like "" 0"" */+      s->seen_error = true;+    } -  if (grpc_slice_eq(GRPC_MDKEY(md), GRPC_MDSTR_GRPC_TIMEOUT)) {-    grpc_millis* cached_timeout =-        static_cast<grpc_millis*>(grpc_mdelem_get_user_data(md, free_timeout));-    grpc_millis timeout;-    if (cached_timeout != nullptr) {-      timeout = *cached_timeout;-    } else {-      if (GPR_UNLIKELY(-              !grpc_http2_decode_timeout(GRPC_MDVALUE(md), &timeout))) {-        char* val = grpc_slice_to_c_string(GRPC_MDVALUE(md));-        gpr_log(GPR_ERROR, ""Ignoring bad timeout value '%s'"", val);-        gpr_free(val);-        timeout = GRPC_MILLIS_INF_FUTURE;+    if (grpc_slice_eq(GRPC_MDKEY(md), GRPC_MDSTR_GRPC_TIMEOUT)) {","I intend it to be skipped because I noticed that none of the grpc static elements have a key of TIMEOUT. So if `GRPC_MDELEM_STORAGE(md) == GRPC_MDELEM_STORAGE_STATIC` is true, we no longer need to go down this code path.",OK
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/16661,219250317,2018-09-20T17:24:42Z,src/core/ext/transport/chttp2/transport/parsing.cc,"@@ -409,67 +409,75 @@ static void on_initial_header(void* tp, grpc_mdelem md) {     gpr_free(value);   } -  if (grpc_slice_eq(GRPC_MDKEY(md), GRPC_MDSTR_GRPC_STATUS) &&-      !grpc_mdelem_eq(md, GRPC_MDELEM_GRPC_STATUS_0)) {-    /* TODO(ctiller): check for a status like "" 0"" */-    s->seen_error = true;-  }+  if (GRPC_MDELEM_STORAGE(md) == GRPC_MDELEM_STORAGE_STATIC) {+    if (md.payload == GRPC_MDELEM_GRPC_STATUS_1.payload ||+        md.payload == GRPC_MDELEM_GRPC_STATUS_2.payload) {+      s->seen_error = true;+    }+  } else {+    if (grpc_slice_eq(GRPC_MDKEY(md), GRPC_MDSTR_GRPC_STATUS) &&+        !grpc_mdelem_eq(md, GRPC_MDELEM_GRPC_STATUS_0)) {+      /* TODO(ctiller): check for a status like "" 0"" */+      s->seen_error = true;+    } -  if (grpc_slice_eq(GRPC_MDKEY(md), GRPC_MDSTR_GRPC_TIMEOUT)) {-    grpc_millis* cached_timeout =-        static_cast<grpc_millis*>(grpc_mdelem_get_user_data(md, free_timeout));-    grpc_millis timeout;-    if (cached_timeout != nullptr) {-      timeout = *cached_timeout;-    } else {-      if (GPR_UNLIKELY(-              !grpc_http2_decode_timeout(GRPC_MDVALUE(md), &timeout))) {-        char* val = grpc_slice_to_c_string(GRPC_MDVALUE(md));-        gpr_log(GPR_ERROR, ""Ignoring bad timeout value '%s'"", val);-        gpr_free(val);-        timeout = GRPC_MILLIS_INF_FUTURE;+    if (grpc_slice_eq(GRPC_MDKEY(md), GRPC_MDSTR_GRPC_TIMEOUT)) {",What about this: https://github.com/grpc/grpc/blob/master/src/core/lib/transport/static_metadata.h#L86,
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/16661,219256089,2018-09-20T17:42:11Z,src/core/ext/transport/chttp2/transport/parsing.cc,"@@ -409,67 +409,75 @@ static void on_initial_header(void* tp, grpc_mdelem md) {     gpr_free(value);   } -  if (grpc_slice_eq(GRPC_MDKEY(md), GRPC_MDSTR_GRPC_STATUS) &&-      !grpc_mdelem_eq(md, GRPC_MDELEM_GRPC_STATUS_0)) {-    /* TODO(ctiller): check for a status like "" 0"" */-    s->seen_error = true;-  }+  if (GRPC_MDELEM_STORAGE(md) == GRPC_MDELEM_STORAGE_STATIC) {+    if (md.payload == GRPC_MDELEM_GRPC_STATUS_1.payload ||+        md.payload == GRPC_MDELEM_GRPC_STATUS_2.payload) {+      s->seen_error = true;+    }+  } else {+    if (grpc_slice_eq(GRPC_MDKEY(md), GRPC_MDSTR_GRPC_STATUS) &&+        !grpc_mdelem_eq(md, GRPC_MDELEM_GRPC_STATUS_0)) {+      /* TODO(ctiller): check for a status like "" 0"" */+      s->seen_error = true;+    } -  if (grpc_slice_eq(GRPC_MDKEY(md), GRPC_MDSTR_GRPC_TIMEOUT)) {-    grpc_millis* cached_timeout =-        static_cast<grpc_millis*>(grpc_mdelem_get_user_data(md, free_timeout));-    grpc_millis timeout;-    if (cached_timeout != nullptr) {-      timeout = *cached_timeout;-    } else {-      if (GPR_UNLIKELY(-              !grpc_http2_decode_timeout(GRPC_MDVALUE(md), &timeout))) {-        char* val = grpc_slice_to_c_string(GRPC_MDVALUE(md));-        gpr_log(GPR_ERROR, ""Ignoring bad timeout value '%s'"", val);-        gpr_free(val);-        timeout = GRPC_MILLIS_INF_FUTURE;+    if (grpc_slice_eq(GRPC_MDKEY(md), GRPC_MDSTR_GRPC_TIMEOUT)) {",Isn't that just a static string? There are no metadata elements with a key of timeout here: https://github.com/grpc/grpc/blob/master/src/core/lib/transport/static_metadata.h#L263Could a mdelem have `GRPC_MDELEM_STORAGE(md) == GRPC_MDELEM_STORAGE_STATIC` and not be present in the static metadata table?,OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/16661,219290704,2018-09-20T19:32:16Z,src/core/ext/transport/chttp2/transport/parsing.cc,"@@ -409,67 +409,75 @@ static void on_initial_header(void* tp, grpc_mdelem md) {     gpr_free(value);   } -  if (grpc_slice_eq(GRPC_MDKEY(md), GRPC_MDSTR_GRPC_STATUS) &&-      !grpc_mdelem_eq(md, GRPC_MDELEM_GRPC_STATUS_0)) {-    /* TODO(ctiller): check for a status like "" 0"" */-    s->seen_error = true;-  }+  if (GRPC_MDELEM_STORAGE(md) == GRPC_MDELEM_STORAGE_STATIC) {+    if (md.payload == GRPC_MDELEM_GRPC_STATUS_1.payload ||","The reason I don't use grpc_mdelem_eq is because if the payload is not equal, I already know that the metadata elements are not equal because I confirmed that md is static. If I used grpc_mdelem_eq here, then if the payloads are not equal, grpc_mdelem_eq executes more instructions to determine if they're equal or not. I'm avoiding the execution of these additional instructions.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16582,219515605,2018-09-21T14:24:15Z,src/core/ext/filters/message_size/message_size_filter.cc,"@@ -147,14 +149,31 @@ static void recv_message_ready(void* user_data, grpc_error* error) {     GRPC_ERROR_REF(error);   }   // Invoke the next callback.-  GRPC_CLOSURE_RUN(calld->next_recv_message_ready, error);+  grpc_closure* closure = calld->next_recv_message_ready;+  calld->next_recv_message_ready = nullptr;+  if (calld->seen_recv_trailing_metadata) {+    calld->seen_recv_trailing_metadata = false;+    GRPC_CALL_COMBINER_START(calld->call_combiner,+                             &calld->recv_trailing_metadata_ready,+                             calld->recv_trailing_metadata_error,+                             ""continue recv_trailing_metadata_ready"");+  }+  GRPC_CLOSURE_RUN(closure, error); }  // Callback invoked on completion of recv_trailing_metadata // Notifies the recv_trailing_metadata batch of any message size failures static void recv_trailing_metadata_ready(void* user_data, grpc_error* error) {   grpc_call_element* elem = static_cast<grpc_call_element*>(user_data);   call_data* calld = static_cast<call_data*>(elem->call_data);+  if (calld->next_recv_message_ready != nullptr) {","I just noticed that we probably need to also check `calld->next_recv_message_ready != nullptr` here.  Otherwise, for a streaming call with no messages received, we will never invoke the recv_trailing_metadata_ready callback.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16627,219545347,2018-09-21T15:53:49Z,src/core/lib/security/security_connector/security_connector.cc,"@@ -287,303 +279,7 @@ grpc_security_connector* grpc_security_connector_find_in_args(   return nullptr; } -static tsi_client_certificate_request_type-get_tsi_client_certificate_request_type(-    grpc_ssl_client_certificate_request_type grpc_request_type) {-  switch (grpc_request_type) {-    case GRPC_SSL_DONT_REQUEST_CLIENT_CERTIFICATE:-      return TSI_DONT_REQUEST_CLIENT_CERTIFICATE;--    case GRPC_SSL_REQUEST_CLIENT_CERTIFICATE_BUT_DONT_VERIFY:-      return TSI_REQUEST_CLIENT_CERTIFICATE_BUT_DONT_VERIFY;--    case GRPC_SSL_REQUEST_CLIENT_CERTIFICATE_AND_VERIFY:-      return TSI_REQUEST_CLIENT_CERTIFICATE_AND_VERIFY;--    case GRPC_SSL_REQUEST_AND_REQUIRE_CLIENT_CERTIFICATE_BUT_DONT_VERIFY:-      return TSI_REQUEST_AND_REQUIRE_CLIENT_CERTIFICATE_BUT_DONT_VERIFY;--    case GRPC_SSL_REQUEST_AND_REQUIRE_CLIENT_CERTIFICATE_AND_VERIFY:-      return TSI_REQUEST_AND_REQUIRE_CLIENT_CERTIFICATE_AND_VERIFY;--    default:-      return TSI_DONT_REQUEST_CLIENT_CERTIFICATE;-  }-}--/* -- Fake implementation. -- */--typedef struct {-  grpc_channel_security_connector base;-  char* target;-  char* expected_targets;-  bool is_lb_channel;-  char* target_name_override;-} grpc_fake_channel_security_connector;--static void fake_channel_destroy(grpc_security_connector* sc) {-  grpc_fake_channel_security_connector* c =-      reinterpret_cast<grpc_fake_channel_security_connector*>(sc);-  grpc_call_credentials_unref(c->base.request_metadata_creds);-  gpr_free(c->target);-  gpr_free(c->expected_targets);-  gpr_free(c->target_name_override);-  gpr_free(c);-}--static void fake_server_destroy(grpc_security_connector* sc) { gpr_free(sc); }--static bool fake_check_target(const char* target_type, const char* target,-                              const char* set_str) {-  GPR_ASSERT(target_type != nullptr);-  GPR_ASSERT(target != nullptr);-  char** set = nullptr;-  size_t set_size = 0;-  gpr_string_split(set_str, "","", &set, &set_size);-  bool found = false;-  for (size_t i = 0; i < set_size; ++i) {-    if (set[i] != nullptr && strcmp(target, set[i]) == 0) found = true;-  }-  for (size_t i = 0; i < set_size; ++i) {-    gpr_free(set[i]);-  }-  gpr_free(set);-  return found;-}--static void fake_secure_name_check(const char* target,-                                   const char* expected_targets,-                                   bool is_lb_channel) {-  if (expected_targets == nullptr) return;-  char** lbs_and_backends = nullptr;-  size_t lbs_and_backends_size = 0;-  bool success = false;-  gpr_string_split(expected_targets, "";"", &lbs_and_backends,-                   &lbs_and_backends_size);-  if (lbs_and_backends_size > 2 || lbs_and_backends_size == 0) {-    gpr_log(GPR_ERROR, ""Invalid expected targets arg value: '%s'"",-            expected_targets);-    goto done;-  }-  if (is_lb_channel) {-    if (lbs_and_backends_size != 2) {-      gpr_log(GPR_ERROR,-              ""Invalid expected targets arg value: '%s'. Expectations for LB ""-              ""channels must be of the form 'be1,be2,be3,...;lb1,lb2,..."",-              expected_targets);-      goto done;-    }-    if (!fake_check_target(""LB"", target, lbs_and_backends[1])) {-      gpr_log(GPR_ERROR, ""LB target '%s' not found in expected set '%s'"",-              target, lbs_and_backends[1]);-      goto done;-    }-    success = true;-  } else {-    if (!fake_check_target(""Backend"", target, lbs_and_backends[0])) {-      gpr_log(GPR_ERROR, ""Backend target '%s' not found in expected set '%s'"",-              target, lbs_and_backends[0]);-      goto done;-    }-    success = true;-  }-done:-  for (size_t i = 0; i < lbs_and_backends_size; ++i) {-    gpr_free(lbs_and_backends[i]);-  }-  gpr_free(lbs_and_backends);-  if (!success) abort();-}--static void fake_check_peer(grpc_security_connector* sc, tsi_peer peer,-                            grpc_auth_context** auth_context,-                            grpc_closure* on_peer_checked) {-  const char* prop_name;-  grpc_error* error = GRPC_ERROR_NONE;-  *auth_context = nullptr;-  if (peer.property_count != 1) {-    error = GRPC_ERROR_CREATE_FROM_STATIC_STRING(-        ""Fake peers should only have 1 property."");-    goto end;-  }-  prop_name = peer.properties[0].name;-  if (prop_name == nullptr ||-      strcmp(prop_name, TSI_CERTIFICATE_TYPE_PEER_PROPERTY)) {-    char* msg;-    gpr_asprintf(&msg, ""Unexpected property in fake peer: %s."",-                 prop_name == nullptr ? ""<EMPTY>"" : prop_name);-    error = GRPC_ERROR_CREATE_FROM_COPIED_STRING(msg);-    gpr_free(msg);-    goto end;-  }-  if (strncmp(peer.properties[0].value.data, TSI_FAKE_CERTIFICATE_TYPE,-              peer.properties[0].value.length)) {-    error = GRPC_ERROR_CREATE_FROM_STATIC_STRING(-        ""Invalid value for cert type property."");-    goto end;-  }-  *auth_context = grpc_auth_context_create(nullptr);-  grpc_auth_context_add_cstring_property(-      *auth_context, GRPC_TRANSPORT_SECURITY_TYPE_PROPERTY_NAME,-      GRPC_FAKE_TRANSPORT_SECURITY_TYPE);-end:-  GRPC_CLOSURE_SCHED(on_peer_checked, error);-  tsi_peer_destruct(&peer);-}--static void fake_channel_check_peer(grpc_security_connector* sc, tsi_peer peer,-                                    grpc_auth_context** auth_context,-                                    grpc_closure* on_peer_checked) {-  fake_check_peer(sc, peer, auth_context, on_peer_checked);-  grpc_fake_channel_security_connector* c =-      reinterpret_cast<grpc_fake_channel_security_connector*>(sc);-  fake_secure_name_check(c->target, c->expected_targets, c->is_lb_channel);-}--static void fake_server_check_peer(grpc_security_connector* sc, tsi_peer peer,-                                   grpc_auth_context** auth_context,-                                   grpc_closure* on_peer_checked) {-  fake_check_peer(sc, peer, auth_context, on_peer_checked);-}--static int fake_channel_cmp(grpc_security_connector* sc1,-                            grpc_security_connector* sc2) {-  grpc_fake_channel_security_connector* c1 =-      reinterpret_cast<grpc_fake_channel_security_connector*>(sc1);-  grpc_fake_channel_security_connector* c2 =-      reinterpret_cast<grpc_fake_channel_security_connector*>(sc2);-  int c = grpc_channel_security_connector_cmp(&c1->base, &c2->base);-  if (c != 0) return c;-  c = strcmp(c1->target, c2->target);-  if (c != 0) return c;-  if (c1->expected_targets == nullptr || c2->expected_targets == nullptr) {-    c = GPR_ICMP(c1->expected_targets, c2->expected_targets);-  } else {-    c = strcmp(c1->expected_targets, c2->expected_targets);-  }-  if (c != 0) return c;-  return GPR_ICMP(c1->is_lb_channel, c2->is_lb_channel);-}--static int fake_server_cmp(grpc_security_connector* sc1,-                           grpc_security_connector* sc2) {-  return grpc_server_security_connector_cmp(-      reinterpret_cast<grpc_server_security_connector*>(sc1),-      reinterpret_cast<grpc_server_security_connector*>(sc2));-}--static bool fake_channel_check_call_host(grpc_channel_security_connector* sc,-                                         const char* host,-                                         grpc_auth_context* auth_context,-                                         grpc_closure* on_call_host_checked,-                                         grpc_error** error) {-  grpc_fake_channel_security_connector* c =-      reinterpret_cast<grpc_fake_channel_security_connector*>(sc);-  char* authority_hostname = nullptr;-  char* authority_ignored_port = nullptr;-  char* target_hostname = nullptr;-  char* target_ignored_port = nullptr;-  gpr_split_host_port(host, &authority_hostname, &authority_ignored_port);-  gpr_split_host_port(c->target, &target_hostname, &target_ignored_port);-  if (c->target_name_override != nullptr) {-    char* fake_security_target_name_override_hostname = nullptr;-    char* fake_security_target_name_override_ignored_port = nullptr;-    gpr_split_host_port(c->target_name_override,-                        &fake_security_target_name_override_hostname,-                        &fake_security_target_name_override_ignored_port);-    if (strcmp(authority_hostname,-               fake_security_target_name_override_hostname) != 0) {-      gpr_log(GPR_ERROR,-              ""Authority (host) '%s' != Fake Security Target override '%s'"",-              host, fake_security_target_name_override_hostname);-      abort();-    }-    gpr_free(fake_security_target_name_override_hostname);-    gpr_free(fake_security_target_name_override_ignored_port);-  } else if (strcmp(authority_hostname, target_hostname) != 0) {-    gpr_log(GPR_ERROR, ""Authority (host) '%s' != Target '%s'"",-            authority_hostname, target_hostname);-    abort();-  }-  gpr_free(authority_hostname);-  gpr_free(authority_ignored_port);-  gpr_free(target_hostname);-  gpr_free(target_ignored_port);-  return true;-}--static void fake_channel_cancel_check_call_host(-    grpc_channel_security_connector* sc, grpc_closure* on_call_host_checked,-    grpc_error* error) {-  GRPC_ERROR_UNREF(error);-}--static void fake_channel_add_handshakers(-    grpc_channel_security_connector* sc,-    grpc_handshake_manager* handshake_mgr) {-  grpc_handshake_manager_add(-      handshake_mgr,-      grpc_security_handshaker_create(-          tsi_create_fake_handshaker(true /* is_client */), &sc->base));-}--static void fake_server_add_handshakers(grpc_server_security_connector* sc,-                                        grpc_handshake_manager* handshake_mgr) {-  grpc_handshake_manager_add(-      handshake_mgr,-      grpc_security_handshaker_create(-          tsi_create_fake_handshaker(false /* is_client */), &sc->base));-}--static grpc_security_connector_vtable fake_channel_vtable = {-    fake_channel_destroy, fake_channel_check_peer, fake_channel_cmp};--static grpc_security_connector_vtable fake_server_vtable = {-    fake_server_destroy, fake_server_check_peer, fake_server_cmp};--grpc_channel_security_connector* grpc_fake_channel_security_connector_create(-    grpc_channel_credentials* channel_creds,-    grpc_call_credentials* request_metadata_creds, const char* target,-    const grpc_channel_args* args) {-  grpc_fake_channel_security_connector* c =-      static_cast<grpc_fake_channel_security_connector*>(-          gpr_zalloc(sizeof(*c)));-  gpr_ref_init(&c->base.base.refcount, 1);-  c->base.base.url_scheme = GRPC_FAKE_SECURITY_URL_SCHEME;-  c->base.base.vtable = &fake_channel_vtable;-  c->base.channel_creds = channel_creds;-  c->base.request_metadata_creds =-      grpc_call_credentials_ref(request_metadata_creds);-  c->base.check_call_host = fake_channel_check_call_host;-  c->base.cancel_check_call_host = fake_channel_cancel_check_call_host;-  c->base.add_handshakers = fake_channel_add_handshakers;-  c->target = gpr_strdup(target);-  const char* expected_targets = grpc_fake_transport_get_expected_targets(args);-  c->expected_targets = gpr_strdup(expected_targets);-  c->is_lb_channel = grpc_core::FindTargetAuthorityTableInArgs(args) != nullptr;-  const grpc_arg* target_name_override_arg =-      grpc_channel_args_find(args, GRPC_SSL_TARGET_NAME_OVERRIDE_ARG);-  if (target_name_override_arg != nullptr) {-    c->target_name_override =-        gpr_strdup(grpc_channel_arg_get_string(target_name_override_arg));-  }-  return &c->base;-}--grpc_server_security_connector* grpc_fake_server_security_connector_create(-    grpc_server_credentials* server_creds) {-  grpc_server_security_connector* c =-      static_cast<grpc_server_security_connector*>(-          gpr_zalloc(sizeof(grpc_server_security_connector)));-  gpr_ref_init(&c->base.refcount, 1);-  c->base.vtable = &fake_server_vtable;-  c->base.url_scheme = GRPC_FAKE_SECURITY_URL_SCHEME;-  c->server_creds = server_creds;-  c->add_handshakers = fake_server_add_handshakers;-  return c;-}--/* --- Ssl implementation. --- */+/* --- Ssl session cache implementation. --- */","Why is SSL-specific code not in ssl_security_connector.cc?If the reason for this is that you ultimately want it to be used by multiple security connectors, then I suggest moving it to its own file.  That way, it can be dependended on by any security connector implementation that needs it but not be part of this library, which should contain only the core security_connector API.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16627,219546192,2018-09-21T15:56:37Z,src/core/lib/security/security_connector/security_connector.cc,"@@ -625,71 +321,32 @@ grpc_arg grpc_ssl_session_cache_create_channel_arg(       const_cast<char*>(GRPC_SSL_SESSION_CACHE_ARG), cache, &vtable); } -typedef struct {-  grpc_channel_security_connector base;-  tsi_ssl_client_handshaker_factory* client_handshaker_factory;-  char* target_name;-  char* overridden_target_name;-  const verify_peer_options* verify_options;-} grpc_ssl_channel_security_connector;--typedef struct {-  grpc_server_security_connector base;-  tsi_ssl_server_handshaker_factory* server_handshaker_factory;-} grpc_ssl_server_security_connector;--static bool server_connector_has_cert_config_fetcher(-    grpc_ssl_server_security_connector* c) {-  GPR_ASSERT(c != nullptr);-  grpc_ssl_server_credentials* server_creds =-      reinterpret_cast<grpc_ssl_server_credentials*>(c->base.server_creds);-  GPR_ASSERT(server_creds != nullptr);-  return server_creds->certificate_config_fetcher.cb != nullptr;-}+/* --- Util --- */ -static void ssl_channel_destroy(grpc_security_connector* sc) {-  grpc_ssl_channel_security_connector* c =-      reinterpret_cast<grpc_ssl_channel_security_connector*>(sc);-  grpc_channel_credentials_unref(c->base.channel_creds);-  grpc_call_credentials_unref(c->base.request_metadata_creds);-  tsi_ssl_client_handshaker_factory_unref(c->client_handshaker_factory);-  c->client_handshaker_factory = nullptr;-  if (c->target_name != nullptr) gpr_free(c->target_name);-  if (c->overridden_target_name != nullptr) gpr_free(c->overridden_target_name);-  gpr_free(sc);-}+tsi_client_certificate_request_type get_tsi_client_certificate_request_type(","Same comments as above:- Non-static functions must have a `grpc_` prefix.- If this is not directly part of the security_connector API, it does not belong in this file.  Please move it to its own library.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16627,219546663,2018-09-21T15:57:52Z,src/core/lib/security/security_connector/security_connector.cc,"@@ -700,103 +357,6 @@ static const char** fill_alpn_protocol_strings(size_t* num_alpn_protocols) {   return alpn_protocol_strings; } -/* Attempts to replace the server_handshaker_factory with a new factory using- * the provided grpc_ssl_server_certificate_config. Should new factory creation- * fail, the existing factory will not be replaced. Returns true on success (new- * factory created). */-static bool try_replace_server_handshaker_factory(-    grpc_ssl_server_security_connector* sc,-    const grpc_ssl_server_certificate_config* config) {-  if (config == nullptr) {-    gpr_log(GPR_ERROR,-            ""Server certificate config callback returned invalid (NULL) ""-            ""config."");-    return false;-  }-  gpr_log(GPR_DEBUG, ""Using new server certificate config (%p)."", config);--  size_t num_alpn_protocols = 0;-  const char** alpn_protocol_strings =-      fill_alpn_protocol_strings(&num_alpn_protocols);-  tsi_ssl_pem_key_cert_pair* cert_pairs = grpc_convert_grpc_to_tsi_cert_pairs(-      config->pem_key_cert_pairs, config->num_key_cert_pairs);-  tsi_ssl_server_handshaker_factory* new_handshaker_factory = nullptr;-  grpc_ssl_server_credentials* server_creds =-      reinterpret_cast<grpc_ssl_server_credentials*>(sc->base.server_creds);-  tsi_result result = tsi_create_ssl_server_handshaker_factory_ex(-      cert_pairs, config->num_key_cert_pairs, config->pem_root_certs,-      get_tsi_client_certificate_request_type(-          server_creds->config.client_certificate_request),-      ssl_cipher_suites(), alpn_protocol_strings,-      static_cast<uint16_t>(num_alpn_protocols), &new_handshaker_factory);-  gpr_free(cert_pairs);-  gpr_free((void*)alpn_protocol_strings);--  if (result != TSI_OK) {-    gpr_log(GPR_ERROR, ""Handshaker factory creation failed with %s."",-            tsi_result_to_string(result));-    return false;-  }-  tsi_ssl_server_handshaker_factory_unref(sc->server_handshaker_factory);-  sc->server_handshaker_factory = new_handshaker_factory;-  return true;-}--/* Attempts to fetch the server certificate config if a callback is available.- * Current certificate config will continue to be used if the callback returns- * an error. Returns true if new credentials were sucessfully loaded. */-static bool try_fetch_ssl_server_credentials(-    grpc_ssl_server_security_connector* sc) {-  grpc_ssl_server_certificate_config* certificate_config = nullptr;-  bool status;--  GPR_ASSERT(sc != nullptr);-  if (!server_connector_has_cert_config_fetcher(sc)) return false;--  grpc_ssl_server_credentials* server_creds =-      reinterpret_cast<grpc_ssl_server_credentials*>(sc->base.server_creds);-  grpc_ssl_certificate_config_reload_status cb_result =-      server_creds->certificate_config_fetcher.cb(-          server_creds->certificate_config_fetcher.user_data,-          &certificate_config);-  if (cb_result == GRPC_SSL_CERTIFICATE_CONFIG_RELOAD_UNCHANGED) {-    gpr_log(GPR_DEBUG, ""No change in SSL server credentials."");-    status = false;-  } else if (cb_result == GRPC_SSL_CERTIFICATE_CONFIG_RELOAD_NEW) {-    status = try_replace_server_handshaker_factory(sc, certificate_config);-  } else {-    // Log error, continue using previously-loaded credentials.-    gpr_log(GPR_ERROR,-            ""Failed fetching new server credentials, continuing to ""-            ""use previously-loaded credentials."");-    status = false;-  }--  if (certificate_config != nullptr) {-    grpc_ssl_server_certificate_config_destroy(certificate_config);-  }-  return status;-}--static void ssl_server_add_handshakers(grpc_server_security_connector* sc,-                                       grpc_handshake_manager* handshake_mgr) {-  grpc_ssl_server_security_connector* c =-      reinterpret_cast<grpc_ssl_server_security_connector*>(sc);-  // Instantiate TSI handshaker.-  try_fetch_ssl_server_credentials(c);-  tsi_handshaker* tsi_hs = nullptr;-  tsi_result result = tsi_ssl_server_handshaker_factory_create_handshaker(-      c->server_handshaker_factory, &tsi_hs);-  if (result != TSI_OK) {-    gpr_log(GPR_ERROR, ""Handshaker creation failed with error %s."",-            tsi_result_to_string(result));-    return;-  }-  // Create handshakers.-  grpc_handshake_manager_add(-      handshake_mgr, grpc_security_handshaker_create(tsi_hs, &sc->base));-}- int grpc_ssl_host_matches_name(const tsi_peer* peer, const char* peer_name) {","This belongs in ssl_security_connector or in its own library.I'll stop noting this to, but please move all SSL-related code out of this file.",OK
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/16582,219595133,2018-09-21T18:50:48Z,src/core/ext/filters/message_size/message_size_filter.cc,"@@ -147,14 +149,31 @@ static void recv_message_ready(void* user_data, grpc_error* error) {     GRPC_ERROR_REF(error);   }   // Invoke the next callback.-  GRPC_CLOSURE_RUN(calld->next_recv_message_ready, error);+  grpc_closure* closure = calld->next_recv_message_ready;+  calld->next_recv_message_ready = nullptr;+  if (calld->seen_recv_trailing_metadata) {+    calld->seen_recv_trailing_metadata = false;","Debugged it. What's actually happening is this sequence of events -1) We receive trailing metadata but delay it because we have a recv message OP.2) We receive the message and schedule the trailing metadata closure on the call combiner.3) We run the recv trailing metadata closure.4) In the mean time, we have received another recv message op which again sees that recv trailing metadata has been seen and schedules the trailing metadata closure again.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16582,219596627,2018-09-21T18:56:40Z,src/core/ext/filters/message_size/message_size_filter.cc,"@@ -147,14 +149,31 @@ static void recv_message_ready(void* user_data, grpc_error* error) {     GRPC_ERROR_REF(error);   }   // Invoke the next callback.-  GRPC_CLOSURE_RUN(calld->next_recv_message_ready, error);+  grpc_closure* closure = calld->next_recv_message_ready;+  calld->next_recv_message_ready = nullptr;+  if (calld->seen_recv_trailing_metadata) {+    calld->seen_recv_trailing_metadata = false;","Okay, that makes sense.It's probably worth a comment here explaining why this is safe.  In particular, one might think that it's not actually safe to resume the recv_trailing_metadata_ready callback until after we know that *all* recv_message ops have completed.  But in practice, we can't do that, because we don't actually know whether or not there are going to be additional recv_message ops on the call.  However, what saves us here is that once the transport has invoked the recv_trailing_metadata_ready callback, any further recv_message ops will return with a null payload.  And since we know that we won't generate an error in recv_message_ready if the payload is null (because it can't possibly be over the configured size limit), we don't need to defer the recv_trailing_metadata_ready callback until we see that subsequent recv_message_ready callback.",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16596,219712886,2018-09-23T21:50:33Z,src/ruby/spec/generic/client_stub_spec.rb,"@@ -50,7 +50,7 @@ def check_op_view_of_finished_client_call(op_view,    expect { op_view.start_call }.to raise_error(RuntimeError) -  sanity_check_values_of_accessors(op_view,+  consistency_check_values_of_accessors(op_view,",There are just two style check errors here: the style checker wants these multi-line parameters to be aligned with the top one.,OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16637,219713262,2018-09-23T22:06:14Z,tools/run_tests/python_utils/jobset.py,"@@ -261,7 +267,15 @@ def GetSpec(self):         return self._spec      def start(self):-        self._tempfile = tempfile.TemporaryFile()+        if self._spec.logfilename:+            # make sure the log directory exists+            logfile_dir = os.path.dirname(+                os.path.abspath(self._spec.logfilename))+            if not os.path.exists(logfile_dir):+                os.makedirs(logfile_dir)+            self._tempfile = open(self._spec.logfilename, 'w+')","nit: might be worth renaming `self._tempfile` to something like `self._output_file`, since it's no longer always writing to a tempfile.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16627,219891857,2018-09-24T15:57:46Z,src/core/lib/security/security_connector/security_connector.cc,"@@ -40,61 +40,8 @@ grpc_core::DebugOnlyTraceFlag grpc_trace_security_connector_refcount(     false, ""security_connector_refcount""); -/* -- Constants. -- */--#ifndef INSTALL_PREFIX-static const char* installed_roots_path = ""/usr/share/grpc/roots.pem"";-#else-static const char* installed_roots_path =-    INSTALL_PREFIX ""/share/grpc/roots.pem"";-#endif--/** Environment variable used as a flag to enable/disable loading system root-    certificates from the OS trust store. */-#ifndef GRPC_NOT_USE_SYSTEM_SSL_ROOTS_ENV_VAR-#define GRPC_NOT_USE_SYSTEM_SSL_ROOTS_ENV_VAR ""GRPC_NOT_USE_SYSTEM_SSL_ROOTS""-#endif--#ifndef TSI_OPENSSL_ALPN_SUPPORT-#define TSI_OPENSSL_ALPN_SUPPORT 1-#endif--/* -- Overridden default roots. -- */--static grpc_ssl_roots_override_callback ssl_roots_override_cb = nullptr;--void grpc_set_ssl_roots_override_callback(grpc_ssl_roots_override_callback cb) {-  ssl_roots_override_cb = cb;-}--/* -- Cipher suites. -- */--/* Defines the cipher suites that we accept by default. All these cipher suites-   are compliant with HTTP2. */-#define GRPC_SSL_CIPHER_SUITES     \-  ""ECDHE-ECDSA-AES128-GCM-SHA256:"" \-  ""ECDHE-ECDSA-AES256-GCM-SHA384:"" \-  ""ECDHE-RSA-AES128-GCM-SHA256:""   \-  ""ECDHE-RSA-AES256-GCM-SHA384""--static gpr_once cipher_suites_once = GPR_ONCE_INIT;-static const char* cipher_suites = nullptr;--static void init_cipher_suites(void) {-  char* overridden = gpr_getenv(""GRPC_SSL_CIPHER_SUITES"");-  cipher_suites = overridden != nullptr ? overridden : GRPC_SSL_CIPHER_SUITES;-}--const char* ssl_cipher_suites(void) {-  gpr_once_init(&cipher_suites_once, init_cipher_suites);-  return cipher_suites;-}--/* -- Common methods. -- */--/* Returns the first property with that name. */-const tsi_peer_property* tsi_peer_get_property_by_name(const tsi_peer* peer,-                                                       const char* name) {+const tsi_peer_property* tsi_peer_get_property_by_name(",Doesn't this belong in the src/core/tsi instead of here?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16627,219893597,2018-09-24T16:02:37Z,src/core/lib/security/security_connector/security_connector_util.h,"@@ -0,0 +1,52 @@+/*+ *+ * Copyright 2015 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_SECURITY_SECURITY_CONNECTOR_SECURITY_CONNECTOR_UTIL_H+#define GRPC_CORE_LIB_SECURITY_SECURITY_CONNECTOR_SECURITY_CONNECTOR_UTIL_H++#include <grpc/support/port_platform.h>++#include <stdbool.h>++#include <grpc/grpc_security.h>++#include ""src/core/tsi/transport_security_interface.h""++/* --- Util. --- */++/* Return HTTP2-compliant cipher suites that gRPC accepts by default. */+const char* grpc_get_ssl_cipher_suites(void);",All of the functions in this library look SSL-related.  I suggest renaming this library to something like ssl_utils.Also consider moving the code from the default_ssl_root_store and ssl_session_cache libraries into this one.,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16654,219899452,2018-09-24T16:20:34Z,src/core/tsi/alts_transport_security.cc,"@@ -28,38 +28,66 @@ alts_shared_resource* alts_get_shared_resource(void) {   return &g_alts_resource; } -static void grpc_tsi_alts_wait_for_cq_drain() {-  gpr_mu_lock(&g_alts_resource.mu);-  while (!g_alts_resource.is_cq_drained) {-    gpr_cv_wait(&g_alts_resource.cv, &g_alts_resource.mu,+static void wait_for_cq_drain() {+  while (!g_alts_resource.is_cq_drained)",Why is it safe to access `is_cq_drained` without a lock?  And why is it needed in the first place if we're using a condition variable for this?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16654,219899592,2018-09-24T16:21:00Z,src/core/tsi/alts_transport_security.cc,"@@ -28,38 +28,66 @@ alts_shared_resource* alts_get_shared_resource(void) {   return &g_alts_resource; } -static void grpc_tsi_alts_wait_for_cq_drain() {-  gpr_mu_lock(&g_alts_resource.mu);-  while (!g_alts_resource.is_cq_drained) {-    gpr_cv_wait(&g_alts_resource.cv, &g_alts_resource.mu,+static void wait_for_cq_drain() {+  while (!g_alts_resource.is_cq_drained)+    gpr_cv_wait(&g_alts_resource.cq_cv, &g_alts_resource.mu,                 gpr_inf_future(GPR_CLOCK_REALTIME));-  }-  gpr_mu_unlock(&g_alts_resource.mu);+}++static void wait_for_resource_destroy() {+  while (!g_alts_resource.can_destroy_resource)",Why is it safe to access `can_destroy_resource` without a lock? And why is it needed in the first place if we're using a condition variable for this?,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16367,220086077,2018-09-25T07:38:09Z,src/csharp/Grpc.Core/Marshaller.cs,"@@ -29,36 +29,122 @@ public class Marshaller<T>         readonly Func<T, byte[]> serializer;         readonly Func<byte[], T> deserializer; +        readonly Action<T, SerializationContext> contextualSerializer;+        readonly Func<DeserializationContext, T> contextualDeserializer;+         /// <summary>-        /// Initializes a new marshaller.+        /// Initializes a new marshaller from simple serialize/deserialize functions.         /// </summary>         /// <param name=""serializer"">Function that will be used to serialize messages.</param>         /// <param name=""deserializer"">Function that will be used to deserialize messages.</param>         public Marshaller(Func<T, byte[]> serializer, Func<byte[], T> deserializer)         {-            this.serializer = GrpcPreconditions.CheckNotNull(serializer, ""serializer"");-            this.deserializer = GrpcPreconditions.CheckNotNull(deserializer, ""deserializer"");+            this.serializer = GrpcPreconditions.CheckNotNull(serializer, nameof(serializer));+            this.deserializer = GrpcPreconditions.CheckNotNull(deserializer, nameof(deserializer));+            this.contextualSerializer = EmulateContextualSerializer;+            this.contextualDeserializer = EmulateContextualDeserializer;         }          /// <summary>-        /// Gets the serializer function.+        /// Initializes a new marshaller from serialize/deserialize fuctions that can access serialization and deserialization+        /// context. Compared to the simple serializer/deserializer functions, using the contextual version provides more+        /// flexibility and can lead to increased efficiency (and better performance).+        /// Note: This constructor is part of an experimental API that can change or be removed without any prior notice.         /// </summary>-        public Func<T, byte[]> Serializer+        /// <param name=""serializer"">Function that will be used to serialize messages.</param>+        /// <param name=""deserializer"">Function that will be used to deserialize messages.</param>+        public Marshaller(Action<T, SerializationContext> serializer, Func<DeserializationContext, T> deserializer)         {-            get-            {-                return this.serializer;-            }+            this.contextualSerializer = GrpcPreconditions.CheckNotNull(serializer, nameof(serializer));+            this.contextualDeserializer = GrpcPreconditions.CheckNotNull(deserializer, nameof(deserializer));+            this.serializer = EmulateSimpleSerializer;+            this.deserializer = EmulateSimpleDeserializer;         } +        /// <summary>+        /// Gets the serializer function.+        /// </summary>+        public Func<T, byte[]> Serializer => this.serializer;+         /// <summary>         /// Gets the deserializer function.         /// </summary>-        public Func<byte[], T> Deserializer+        public Func<byte[], T> Deserializer => this.deserializer;++        /// <summary>+        /// Gets the serializer function.+        /// Note: experimental API that can change or be removed without any prior notice.+        /// </summary>+        public Action<T, SerializationContext> ContextualSerializer => this.contextualSerializer;++        /// <summary>+        /// Gets the serializer function.+        /// Note: experimental API that can change or be removed without any prior notice.+        /// </summary>+        public Func<DeserializationContext, T> ContextualDeserializer => this.contextualDeserializer;++        // for backward compatibility, emulate the simple serializer using the contextual one+        private byte[] EmulateSimpleSerializer(T msg)         {-            get+            // TODO(jtattermusch): avoid the allocation by passing a thread-local instance+            var context = new EmulatedSerializationContext();+            this.contextualSerializer(msg, context);+            return context.GetPayload();+        }++        // for backward compatibility, emulate the simple deserializer using the contextual one+        private T EmulateSimpleDeserializer(byte[] payload)+        {+            // TODO(jtattermusch): avoid the allocation by passing a thread-local instance+            var context = new EmulatedDeserializationContext(payload);+            return this.contextualDeserializer(context);+        }++        // for backward compatibility, emulate the contextual serializer using the simple one+        private void EmulateContextualSerializer(T message, SerializationContext context)+        {+            var payload = this.serializer(message);+            context.Complete(payload);+        }++        // for backward compatibility, emulate the contextual deserializer using the simple one+        private T EmulateContextualDeserializer(DeserializationContext context)+        {+            return this.deserializer(context.PayloadAsNewBuffer());+        }++        internal class EmulatedSerializationContext : SerializationContext+        {+            bool isComplete;+            byte[] payload;++            public override void Complete(byte[] payload)+            {+                GrpcPreconditions.CheckState(!isComplete);+                this.isComplete = true;+                this.payload = payload;+            }++            internal byte[] GetPayload()+            {",nit: `GrpcPreconditions.CheckState(isComplete);` ?,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16367,220095948,2018-09-25T08:11:57Z,src/csharp/Grpc.Core/Marshaller.cs,"@@ -29,36 +29,122 @@ public class Marshaller<T>         readonly Func<T, byte[]> serializer;         readonly Func<byte[], T> deserializer; +        readonly Action<T, SerializationContext> contextualSerializer;+        readonly Func<DeserializationContext, T> contextualDeserializer;+         /// <summary>-        /// Initializes a new marshaller.+        /// Initializes a new marshaller from simple serialize/deserialize functions.         /// </summary>         /// <param name=""serializer"">Function that will be used to serialize messages.</param>         /// <param name=""deserializer"">Function that will be used to deserialize messages.</param>         public Marshaller(Func<T, byte[]> serializer, Func<byte[], T> deserializer)         {-            this.serializer = GrpcPreconditions.CheckNotNull(serializer, ""serializer"");-            this.deserializer = GrpcPreconditions.CheckNotNull(deserializer, ""deserializer"");+            this.serializer = GrpcPreconditions.CheckNotNull(serializer, nameof(serializer));+            this.deserializer = GrpcPreconditions.CheckNotNull(deserializer, nameof(deserializer));+            this.contextualSerializer = EmulateContextualSerializer;","When this ""old-style"" constructor is used, when will `this.contextualSerializer` and `this.contextualDeserializer` ever be used by the gRPC-C# library? Is the plan to switch over gRPC-C# to start calling the `contextualSerializer` and `contextualDelegates`?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16367,220096553,2018-09-25T08:13:47Z,src/csharp/Grpc.Core/Marshaller.cs,"@@ -29,36 +29,122 @@ public class Marshaller<T>         readonly Func<T, byte[]> serializer;         readonly Func<byte[], T> deserializer; +        readonly Action<T, SerializationContext> contextualSerializer;+        readonly Func<DeserializationContext, T> contextualDeserializer;+         /// <summary>-        /// Initializes a new marshaller.+        /// Initializes a new marshaller from simple serialize/deserialize functions.         /// </summary>         /// <param name=""serializer"">Function that will be used to serialize messages.</param>         /// <param name=""deserializer"">Function that will be used to deserialize messages.</param>         public Marshaller(Func<T, byte[]> serializer, Func<byte[], T> deserializer)         {-            this.serializer = GrpcPreconditions.CheckNotNull(serializer, ""serializer"");-            this.deserializer = GrpcPreconditions.CheckNotNull(deserializer, ""deserializer"");+            this.serializer = GrpcPreconditions.CheckNotNull(serializer, nameof(serializer));+            this.deserializer = GrpcPreconditions.CheckNotNull(deserializer, nameof(deserializer));+            this.contextualSerializer = EmulateContextualSerializer;+            this.contextualDeserializer = EmulateContextualDeserializer;         }          /// <summary>-        /// Gets the serializer function.+        /// Initializes a new marshaller from serialize/deserialize fuctions that can access serialization and deserialization+        /// context. Compared to the simple serializer/deserializer functions, using the contextual version provides more+        /// flexibility and can lead to increased efficiency (and better performance).+        /// Note: This constructor is part of an experimental API that can change or be removed without any prior notice.         /// </summary>-        public Func<T, byte[]> Serializer+        /// <param name=""serializer"">Function that will be used to serialize messages.</param>+        /// <param name=""deserializer"">Function that will be used to deserialize messages.</param>+        public Marshaller(Action<T, SerializationContext> serializer, Func<DeserializationContext, T> deserializer)         {-            get-            {-                return this.serializer;-            }+            this.contextualSerializer = GrpcPreconditions.CheckNotNull(serializer, nameof(serializer));+            this.contextualDeserializer = GrpcPreconditions.CheckNotNull(deserializer, nameof(deserializer));+            this.serializer = EmulateSimpleSerializer;","similarly to the above question, if `contextualSerializer/Deserializer` delegates are soon to be used, it seems like these `serializer` and `deserializer` delegates won't be needed at that time?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16367,220100445,2018-09-25T08:26:17Z,src/csharp/Grpc.Core/Marshaller.cs,"@@ -29,36 +29,122 @@ public class Marshaller<T>         readonly Func<T, byte[]> serializer;         readonly Func<byte[], T> deserializer; +        readonly Action<T, SerializationContext> contextualSerializer;+        readonly Func<DeserializationContext, T> contextualDeserializer;+         /// <summary>-        /// Initializes a new marshaller.+        /// Initializes a new marshaller from simple serialize/deserialize functions.         /// </summary>         /// <param name=""serializer"">Function that will be used to serialize messages.</param>         /// <param name=""deserializer"">Function that will be used to deserialize messages.</param>         public Marshaller(Func<T, byte[]> serializer, Func<byte[], T> deserializer)         {-            this.serializer = GrpcPreconditions.CheckNotNull(serializer, ""serializer"");-            this.deserializer = GrpcPreconditions.CheckNotNull(deserializer, ""deserializer"");+            this.serializer = GrpcPreconditions.CheckNotNull(serializer, nameof(serializer));+            this.deserializer = GrpcPreconditions.CheckNotNull(deserializer, nameof(deserializer));+            this.contextualSerializer = EmulateContextualSerializer;+            this.contextualDeserializer = EmulateContextualDeserializer;         }          /// <summary>-        /// Gets the serializer function.+        /// Initializes a new marshaller from serialize/deserialize fuctions that can access serialization and deserialization+        /// context. Compared to the simple serializer/deserializer functions, using the contextual version provides more+        /// flexibility and can lead to increased efficiency (and better performance).+        /// Note: This constructor is part of an experimental API that can change or be removed without any prior notice.         /// </summary>-        public Func<T, byte[]> Serializer+        /// <param name=""serializer"">Function that will be used to serialize messages.</param>+        /// <param name=""deserializer"">Function that will be used to deserialize messages.</param>+        public Marshaller(Action<T, SerializationContext> serializer, Func<DeserializationContext, T> deserializer)         {-            get-            {-                return this.serializer;-            }+            this.contextualSerializer = GrpcPreconditions.CheckNotNull(serializer, nameof(serializer));+            this.contextualDeserializer = GrpcPreconditions.CheckNotNull(deserializer, nameof(deserializer));+            this.serializer = EmulateSimpleSerializer;+            this.deserializer = EmulateSimpleDeserializer;         } +        /// <summary>+        /// Gets the serializer function.+        /// </summary>+        public Func<T, byte[]> Serializer => this.serializer;+         /// <summary>         /// Gets the deserializer function.         /// </summary>-        public Func<byte[], T> Deserializer+        public Func<byte[], T> Deserializer => this.deserializer;++        /// <summary>+        /// Gets the serializer function.+        /// Note: experimental API that can change or be removed without any prior notice.+        /// </summary>+        public Action<T, SerializationContext> ContextualSerializer => this.contextualSerializer;++        /// <summary>+        /// Gets the serializer function.+        /// Note: experimental API that can change or be removed without any prior notice.+        /// </summary>+        public Func<DeserializationContext, T> ContextualDeserializer => this.contextualDeserializer;++        // for backward compatibility, emulate the simple serializer using the contextual one+        private byte[] EmulateSimpleSerializer(T msg)         {-            get+            // TODO(jtattermusch): avoid the allocation by passing a thread-local instance+            var context = new EmulatedSerializationContext();+            this.contextualSerializer(msg, context);+            return context.GetPayload();+        }++        // for backward compatibility, emulate the simple deserializer using the contextual one+        private T EmulateSimpleDeserializer(byte[] payload)+        {+            // TODO(jtattermusch): avoid the allocation by passing a thread-local instance+            var context = new EmulatedDeserializationContext(payload);+            return this.contextualDeserializer(context);+        }++        // for backward compatibility, emulate the contextual serializer using the simple one+        private void EmulateContextualSerializer(T message, SerializationContext context)","Just another question, `SerializationContext` and `DeserializationContext` are going to be provided by gRPC C# library to the contextual serializer/deserializer delegates, right?",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16367,220290723,2018-09-25T17:47:15Z,src/csharp/Grpc.Core/Marshaller.cs,"@@ -29,36 +29,122 @@ public class Marshaller<T>         readonly Func<T, byte[]> serializer;         readonly Func<byte[], T> deserializer; +        readonly Action<T, SerializationContext> contextualSerializer;+        readonly Func<DeserializationContext, T> contextualDeserializer;+         /// <summary>-        /// Initializes a new marshaller.+        /// Initializes a new marshaller from simple serialize/deserialize functions.         /// </summary>         /// <param name=""serializer"">Function that will be used to serialize messages.</param>         /// <param name=""deserializer"">Function that will be used to deserialize messages.</param>         public Marshaller(Func<T, byte[]> serializer, Func<byte[], T> deserializer)         {-            this.serializer = GrpcPreconditions.CheckNotNull(serializer, ""serializer"");-            this.deserializer = GrpcPreconditions.CheckNotNull(deserializer, ""deserializer"");+            this.serializer = GrpcPreconditions.CheckNotNull(serializer, nameof(serializer));+            this.deserializer = GrpcPreconditions.CheckNotNull(deserializer, nameof(deserializer));+            this.contextualSerializer = EmulateContextualSerializer;","Yes, the plan is to switch gRPC C# library to use contextualSerializer and contextualDeserializer because they are more general and their implementation can trivially invoke the old-style serializer and deserializer with no extra overhead (I plan to do the switch in #16371). ",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16367,220295944,2018-09-25T18:01:57Z,src/csharp/Grpc.Core/Marshaller.cs,"@@ -29,36 +29,122 @@ public class Marshaller<T>         readonly Func<T, byte[]> serializer;         readonly Func<byte[], T> deserializer; +        readonly Action<T, SerializationContext> contextualSerializer;+        readonly Func<DeserializationContext, T> contextualDeserializer;+         /// <summary>-        /// Initializes a new marshaller.+        /// Initializes a new marshaller from simple serialize/deserialize functions.         /// </summary>         /// <param name=""serializer"">Function that will be used to serialize messages.</param>         /// <param name=""deserializer"">Function that will be used to deserialize messages.</param>         public Marshaller(Func<T, byte[]> serializer, Func<byte[], T> deserializer)         {-            this.serializer = GrpcPreconditions.CheckNotNull(serializer, ""serializer"");-            this.deserializer = GrpcPreconditions.CheckNotNull(deserializer, ""deserializer"");+            this.serializer = GrpcPreconditions.CheckNotNull(serializer, nameof(serializer));+            this.deserializer = GrpcPreconditions.CheckNotNull(deserializer, nameof(deserializer));+            this.contextualSerializer = EmulateContextualSerializer;+            this.contextualDeserializer = EmulateContextualDeserializer;         }          /// <summary>-        /// Gets the serializer function.+        /// Initializes a new marshaller from serialize/deserialize fuctions that can access serialization and deserialization+        /// context. Compared to the simple serializer/deserializer functions, using the contextual version provides more+        /// flexibility and can lead to increased efficiency (and better performance).+        /// Note: This constructor is part of an experimental API that can change or be removed without any prior notice.         /// </summary>-        public Func<T, byte[]> Serializer+        /// <param name=""serializer"">Function that will be used to serialize messages.</param>+        /// <param name=""deserializer"">Function that will be used to deserialize messages.</param>+        public Marshaller(Action<T, SerializationContext> serializer, Func<DeserializationContext, T> deserializer)         {-            get-            {-                return this.serializer;-            }+            this.contextualSerializer = GrpcPreconditions.CheckNotNull(serializer, nameof(serializer));+            this.contextualDeserializer = GrpcPreconditions.CheckNotNull(deserializer, nameof(deserializer));+            this.serializer = EmulateSimpleSerializer;",That's right. For now we can have the emulation work both ways and we can remove it once we switch to using contextual serializer/deserializer in gRPC C# library.,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16367,220297900,2018-09-25T18:07:30Z,src/csharp/Grpc.Core/Marshaller.cs,"@@ -29,36 +29,122 @@ public class Marshaller<T>         readonly Func<T, byte[]> serializer;         readonly Func<byte[], T> deserializer; +        readonly Action<T, SerializationContext> contextualSerializer;+        readonly Func<DeserializationContext, T> contextualDeserializer;+         /// <summary>-        /// Initializes a new marshaller.+        /// Initializes a new marshaller from simple serialize/deserialize functions.         /// </summary>         /// <param name=""serializer"">Function that will be used to serialize messages.</param>         /// <param name=""deserializer"">Function that will be used to deserialize messages.</param>         public Marshaller(Func<T, byte[]> serializer, Func<byte[], T> deserializer)         {-            this.serializer = GrpcPreconditions.CheckNotNull(serializer, ""serializer"");-            this.deserializer = GrpcPreconditions.CheckNotNull(deserializer, ""deserializer"");+            this.serializer = GrpcPreconditions.CheckNotNull(serializer, nameof(serializer));+            this.deserializer = GrpcPreconditions.CheckNotNull(deserializer, nameof(deserializer));+            this.contextualSerializer = EmulateContextualSerializer;+            this.contextualDeserializer = EmulateContextualDeserializer;         }          /// <summary>-        /// Gets the serializer function.+        /// Initializes a new marshaller from serialize/deserialize fuctions that can access serialization and deserialization+        /// context. Compared to the simple serializer/deserializer functions, using the contextual version provides more+        /// flexibility and can lead to increased efficiency (and better performance).+        /// Note: This constructor is part of an experimental API that can change or be removed without any prior notice.         /// </summary>-        public Func<T, byte[]> Serializer+        /// <param name=""serializer"">Function that will be used to serialize messages.</param>+        /// <param name=""deserializer"">Function that will be used to deserialize messages.</param>+        public Marshaller(Action<T, SerializationContext> serializer, Func<DeserializationContext, T> deserializer)         {-            get-            {-                return this.serializer;-            }+            this.contextualSerializer = GrpcPreconditions.CheckNotNull(serializer, nameof(serializer));+            this.contextualDeserializer = GrpcPreconditions.CheckNotNull(deserializer, nameof(deserializer));+            this.serializer = EmulateSimpleSerializer;+            this.deserializer = EmulateSimpleDeserializer;         } +        /// <summary>+        /// Gets the serializer function.+        /// </summary>+        public Func<T, byte[]> Serializer => this.serializer;+         /// <summary>         /// Gets the deserializer function.         /// </summary>-        public Func<byte[], T> Deserializer+        public Func<byte[], T> Deserializer => this.deserializer;++        /// <summary>+        /// Gets the serializer function.+        /// Note: experimental API that can change or be removed without any prior notice.+        /// </summary>+        public Action<T, SerializationContext> ContextualSerializer => this.contextualSerializer;++        /// <summary>+        /// Gets the serializer function.+        /// Note: experimental API that can change or be removed without any prior notice.+        /// </summary>+        public Func<DeserializationContext, T> ContextualDeserializer => this.contextualDeserializer;++        // for backward compatibility, emulate the simple serializer using the contextual one+        private byte[] EmulateSimpleSerializer(T msg)         {-            get+            // TODO(jtattermusch): avoid the allocation by passing a thread-local instance+            var context = new EmulatedSerializationContext();+            this.contextualSerializer(msg, context);+            return context.GetPayload();+        }++        // for backward compatibility, emulate the simple deserializer using the contextual one+        private T EmulateSimpleDeserializer(byte[] payload)+        {+            // TODO(jtattermusch): avoid the allocation by passing a thread-local instance+            var context = new EmulatedDeserializationContext(payload);+            return this.contextualDeserializer(context);+        }++        // for backward compatibility, emulate the contextual serializer using the simple one+        private void EmulateContextualSerializer(T message, SerializationContext context)+        {+            var payload = this.serializer(message);+            context.Complete(payload);+        }++        // for backward compatibility, emulate the contextual deserializer using the simple one+        private T EmulateContextualDeserializer(DeserializationContext context)+        {+            return this.deserializer(context.PayloadAsNewBuffer());+        }++        internal class EmulatedSerializationContext : SerializationContext+        {+            bool isComplete;+            byte[] payload;++            public override void Complete(byte[] payload)+            {+                GrpcPreconditions.CheckState(!isComplete);+                this.isComplete = true;+                this.payload = payload;+            }++            internal byte[] GetPayload()+            {",That check is not necessary. GetPayload() will be called from internal code only and it's better to check for payload != null there rather then catching an exception.,OK
534844,bwkimmel,https://api.github.com/repos/grpc/grpc/pulls/16703,220389175,2018-09-25T23:42:21Z,test/core/gpr/BUILD,"@@ -81,12 +81,12 @@ grpc_cc_test( grpc_cc_test(     name = ""mpscq_test"",     srcs = [""mpscq_test.cc""],+    data = [""//third_party/toolchains/machine-size:large""],","This should be `exec_compatible_with = [""<constraint>""],`.I'm not sure how `grpc_cc_test` relates to `cc_test` -- you may need to add an `exec_compatible_with` to its definition to pass it along to an underlying `cc_test`.Same for other build targets below.",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16702,220391158,2018-09-25T23:54:56Z,tools/run_tests/run_interop_tests.py,"@@ -777,7 +777,7 @@ def cloud_to_prod_jobspec(language,     ]     if transport_security == 'tls':         transport_security_options = ['--use_tls=true']-    elif transport_security == 'google_default_credentials' and language == 'c++':+    elif transport_security == 'google_default_credentials' and (language == 'c++' or language == 'go'):         transport_security_options = [             '--custom_credentials_type=google_default_credentials'         ]","I am taking a closer look at how the `JobSpec` suite name is being formed on line 820, and it looks to me like both the google default credentials and TLS prod to cloud test cases will have the same ""shortname"" (this would be a pre-existing problem). I think this might be breaking something in how reporting is set up (https://github.com/grpc/grpc/blob/master/tools/run_tests/python_utils/jobset.py#L461)",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16704,220426524,2018-09-26T04:55:49Z,doc/grpc-polling-engines.md,"@@ -0,0 +1,154 @@+# Polling Engines++_Author: Sree Kuchibhotla (@sreecha) - Sep 2018_+++## Why do we need a 'polling engine' ?++Polling engine component was created for the following reasons:++- gRPC code deals with a bunch of file descriptors on which events like descriptor being readable/writable/error have to be monitored+- gRPC code knows the actions to perform when such events happen+  -  For example:+    - `grpc_endpoint` code calls recvmsg call when the fd is readable and sendmsg call when the fd is writable+    - ` tcp_client` connect code issues async connect and finishes creating the client once the fd is writable (i.e when the connect actually finished)+- gRPC needed some component that can ""efficiently"" to the above operations __using the threads provided by the applications (i.e not create any new threads)__.  Also by ""efficiently"" we mean optimized for latency and throughput+++## Polling Engine Implementations in gRPC+There are multiple polling engine implementations depending on the OS and the OS version.  Fortunately all of them expose the same interface++- Linux:++  - **epollex** (default but requires kernel version >= 4.5),+  - epoll1 (If epollex is not available and glibc version >= 2.9)+  - epollsig (if epollex, epoll1 are unavailable AND Kernel has epoll support)+  - poll (if kernel NOT have epoll support)+- Mac: **poll** (default), poll-cv",Why is `poll-cv` listed only for Mac and not Linux?,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16367,220547698,2018-09-26T12:53:02Z,src/csharp/Grpc.Core.Tests/ContextualMarshallerTest.cs,"@@ -0,0 +1,119 @@+#region Copyright notice and license++// Copyright 2018 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Generic;+using System.Diagnostics;+using System.IO;+using System.Linq;+using System.Threading;+using System.Threading.Tasks;++using Grpc.Core;+using Grpc.Core.Internal;+using Grpc.Core.Utils;+using NUnit.Framework;++namespace Grpc.Core.Tests+{+    public class ContextualMarshallerTest+    {+        const string Host = ""127.0.0.1"";++        MockServiceHelper helper;+        Server server;+        Channel channel;++        [SetUp]+        public void Init()+        {+            var contextualMarshaller = new Marshaller<string>(+                (str, serializationContext) =>+                {+                    if (str == ""UNSERIALIZABLE_VALUE"")+                    {+                        // Google.Protobuf throws exception inherited from IOException+                        throw new IOException(""Error serializing the message."");+                    }+                    if (str == ""SERIALIZE_TO_NULL"")+                    {+                        return;+                    }+                    var bytes = System.Text.Encoding.UTF8.GetBytes(str);+                    serializationContext.Complete(bytes);","with the return-based API, one basically has to allocate a new object (buffer) each time a message is serialized, but for performance reasons we don't want that. The plan is to add more methods that will allow to serialize messages directly to native memory (a grpc slice) so that we don't have to copy any data unnecessarily and to allow gRPC c# library to use different memory management strategies than allocating one-time buffers.The new apis will probably have more methods e.g. `GetMemory(int sizeHint)` to request a memory to serialize into  and then a parameterless `Complete()` method to announce that we are done with serialization. (this is similar idea as PipeWriter with GetMemory(), Advance() and Flush() methods https://github.com/dotnet/corefx/blob/master/src/System.IO.Pipelines/src/System/IO/Pipelines/PipeWriter.cs)",OK
2001509,kalman5,https://api.github.com/repos/grpc/grpc/pulls/15995,220631265,2018-09-26T16:18:20Z,doc/keepalive.md,"@@ -0,0 +1,36 @@+# Keepalive Ping User Guide for gRPC Core (and dependants)++The keepalive ping is a way to check if a channel is currently working by sending HTTP2 pings over the transport. It is sent periodically, and if the ping is not acknowledged by the peer within a certain timeout period, the transport is disconnected.++This guide documents the knobs within gRPC core to control the current behavior of the keepalive ping.++The keepalive ping is controlled by two important channel arguments -+* **GRPC_ARG_KEEPALIVE_TIME_MS**+  * This channel argument controls the period (in milliseconds) after which a keepalive ping is sent on the transport.+* **GRPC_ARG_KEEPALIVE_TIMEOUT_MS**+  * This channel argument controls the amount of time (in milliseconds), the sender of the keepalive ping waits for an acknowledgement. If it does not receive an acknowledgement within this time, it will close the connection.++The above two channel arguments should be sufficient for most users, but the following arguments can also be useful in certain use cases.","In case of stream that keeps a database connection open, with the default keep alive that database connection will remain in a idle transaction status for around 2 hours.",OK
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/16704,220644775,2018-09-26T16:57:46Z,doc/grpc-polling-engines.md,"@@ -0,0 +1,154 @@+# Polling Engines","Polling engine is part of the iomgr. iomgr includes other components too like endpoints, timers and executors.",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/15995,220677113,2018-09-26T18:36:35Z,doc/keepalive.md,"@@ -0,0 +1,36 @@+# Keepalive Ping User Guide for gRPC Core (and dependants)++The keepalive ping is a way to check if a channel is currently working by sending HTTP2 pings over the transport. It is sent periodically, and if the ping is not acknowledged by the peer within a certain timeout period, the transport is disconnected.++This guide documents the knobs within gRPC core to control the current behavior of the keepalive ping.++The keepalive ping is controlled by two important channel arguments -+* **GRPC_ARG_KEEPALIVE_TIME_MS**+  * This channel argument controls the period (in milliseconds) after which a keepalive ping is sent on the transport.+* **GRPC_ARG_KEEPALIVE_TIMEOUT_MS**+  * This channel argument controls the amount of time (in milliseconds), the sender of the keepalive ping waits for an acknowledgement. If it does not receive an acknowledgement within this time, it will close the connection.++The above two channel arguments should be sufficient for most users, but the following arguments can also be useful in certain use cases.",sure! depending on the usecase it might be a good idea to set these to something more desirable. Please refer https://github.com/grpc/proposal/blob/master/A8-client-side-keepalive.md for the original proposal,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16702,220679575,2018-09-26T18:43:56Z,tools/run_tests/run_interop_tests.py,"@@ -1318,7 +1329,7 @@ def aggregate_http2_results(stdout):                                 service_account_key_file,                                 transport_security='tls')                             jobs.append(tls_test_job)-                            if language == 'c++':+                            if str(language) in ['c++', 'go']:","sorry, one more thing:we need to pass: `auth=True` to this `cloud_to_prod_jobspec` invocation, similarly as is done above for c++Without passing `auth=True`, this script won't pass the args like --default_service_account, needed for these OAuth tests",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16490,220795333,2018-09-27T05:13:44Z,src/ruby/lib/grpc/generic/active_call.rb,"@@ -205,6 +205,8 @@ def remote_send(req, marshalled = false)     # list, mulitple metadata for its key are sent     def send_status(code = OK, details = '', assert_finished = false,                     metadata: {})+      return if response_status_as_trailers_only(code, details, metadata: metadata)+","I don't think we need the new `response_status_as_trailers_only` utility. If below, instead of calling `send_initial_metadata`, we first checked whether or not we've already sent initial metadata and then added the send initial metadata op to the same batch as the `send_status_from_server` op, then I think that would do what's needed here in a slightly simpler way.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16699,220795591,2018-09-27T05:15:47Z,src/cpp/client/channel_cc.cc,"@@ -116,10 +117,11 @@ internal::Call Channel::CreateCall(const internal::RpcMethod& method,     } else if (!host_.empty()) {       host_str = host_.c_str();     }-    grpc_slice method_slice = SliceFromCopiedString(method.name());+    grpc_slice method_slice =","It's an interesting topic. It would be a static string for anything coming from codegen, but there's nothing preventing a generic call from putting in an arbitrary crap string. So, suggestion: can we have a separate version of this function for Codegen vs generic? This is not API and it's fully internal. We'd be adding a method to an interface, but that's fine as long as the new method isn't pure (and the simplest thing to do for the new codegen-specific method in the interface would be to just have it call the general one). If you think that would be valuable, I could write that up pretty quickly, I think.",
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/16699,220938444,2018-09-27T14:09:18Z,src/cpp/client/channel_cc.cc,"@@ -116,10 +117,11 @@ internal::Call Channel::CreateCall(const internal::RpcMethod& method,     } else if (!host_.empty()) {       host_str = host_.c_str();     }-    grpc_slice method_slice = SliceFromCopiedString(method.name());+    grpc_slice method_slice =","Thank you @vjpai for the insight! I have two rather stupid questions for my own education:1) for almost all of codegen, shouldn't will take the kRegistered branch above?2) when we add the separate API, we still need this new SliceFromArray that I added to avoid temporary string, right?",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16699,220968803,2018-09-27T15:23:51Z,src/cpp/client/channel_cc.cc,"@@ -116,10 +117,11 @@ internal::Call Channel::CreateCall(const internal::RpcMethod& method,     } else if (!host_.empty()) {       host_str = host_.c_str();     }-    grpc_slice method_slice = SliceFromCopiedString(method.name());+    grpc_slice method_slice =","Ok now after all of that, I finally understand Yang's question better. Although the generic case can take in any arbitrary string as its name argument, we've never required that that string must remain alive during the duration of the use of the call. We should have a test that does something about this. This is why I would advise against the use of static_buffer. I've commented before that static_buffer is misnamed, and that's certainly true in this case (it doesn't have to be truly static, just alive for the duration of the slice), but I don't think that we can actually maintain that in this case since the creation of the call is separated from the actual initiation of the call (2-phase init) and using this slice in metadata.",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16490,221005274,2018-09-27T17:11:14Z,src/ruby/lib/grpc/generic/active_call.rb,"@@ -582,6 +584,23 @@ def attach_peer_cert(peer_cert)      private +    # response_status_as_trailers_only sends a status as Trailers-only+    # https://github.com/grpc/grpc/blob/ceecf80283e6ca184df587f76ed053f1f5295b7f/doc/PROTOCOL-HTTP2.md+    def response_status_as_trailers_only(code, details, metadata: {})+      @send_initial_md_mutex.synchronize do+        # Can't send Trailers-Only since Response-Headers have already been sent+        return false if @metadata_sent+        @metadata_sent = true+      end+","After my comment above, @ganmacs can you please also add a comment here that we are attempting to send initial metadata in the same op batch as trailing metadata in order to experimentally support retries?",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/16710,221074990,2018-09-27T20:58:25Z,doc/core/grpc-endpoint.md,"@@ -0,0 +1,67 @@+# gRPC Endpoints (`grpc_endpoint`) - TCP endpoint+_Author: Sree Kuchibhotla (@sreecha) - Sep 2018_++This document talks about `grpc_endpoint` abstraction and talks about the TCP endpoint's posix implementation in detail.++### What is an endpoint ?+`grpc_endpoint` is an abstraction used by gRPC to read/write bytes. There are different endpoint implementations depending on the underlying transport.+++### Endpoint interface++The interface is documented well here: [`endpoint.h`](https://github.com/grpc/grpc/blob/v1.15.1/src/core/lib/iomgr/endpoint.h)++### TCP endpoint++TCP endpoint is implemented here: [tcp_posix.cc](https://github.com/grpc/grpc/blob/v1.15.1/src/core/lib/iomgr/tcp_posix.cc)++#### Read++``` C+++// Implementation of grpc_endpoint_read() API+void tcp_read(grpc_endpoint* ep, grpc_slice_buffer* slices, grpc_closure* cb) {+ // 1. fd = Get grpc_fd from endpoint+ // 2. Store read completion callback “cb” on the endpoint+ // 3. Call polling engine API grpc_fd_notify_on_read(fd, tcp_handle_read)","Presenting incomplete details is also pretty confusing imo, but we can always improve the documentation later I guess",OK
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/16710,221075281,2018-09-27T20:59:29Z,doc/core/grpc-endpoint.md,"@@ -0,0 +1,67 @@+# gRPC Endpoints (`grpc_endpoint`) - TCP endpoint+_Author: Sree Kuchibhotla (@sreecha) - Sep 2018_++This document talks about `grpc_endpoint` abstraction and talks about the TCP endpoint's posix implementation in detail.++### What is an endpoint ?+`grpc_endpoint` is an abstraction used by gRPC to read/write bytes. There are different endpoint implementations depending on the underlying transport.+++### Endpoint interface++The interface is documented well here: [`endpoint.h`](https://github.com/grpc/grpc/blob/v1.15.1/src/core/lib/iomgr/endpoint.h)++### TCP endpoint++TCP endpoint is implemented here: [tcp_posix.cc](https://github.com/grpc/grpc/blob/v1.15.1/src/core/lib/iomgr/tcp_posix.cc)++#### Read++``` C+++// Implementation of grpc_endpoint_read() API+void tcp_read(grpc_endpoint* ep, grpc_slice_buffer* slices, grpc_closure* cb) {+ // 1. fd = Get grpc_fd from endpoint+ // 2. Store read completion callback “cb” on the endpoint+ // 3. Call polling engine API grpc_fd_notify_on_read(fd, tcp_handle_read)+}+```++``` C+++void tcp_handle_read() {+  // 1. Do the actual reading by calling recvmsg()+  // 2. Call read-completion callback if bytes are read+  // 3. Call grpc_fd_notify_on_read(fd, tcp_handle_read) again if+  //    there are more bytes to read (i.e recvmsg returns EAGAIN)++}+```++#### Write++``` C+++// Implementation of grpc_endpoint_write() API+void tcp_write(grpc_endpoint* ep, grpc_slice_buffer* slices, grpc_closure* cb, void* arg) {+  // 1. fd = Get grpc_fd from endpoint+  // 2. Store write completion callback “cb” on the endpoint+  // 3. Do the actual write (via a helper function tcp_flush) by calling TCP sendmsg()+  // 4. If sendmsg() returned EAGAIN, call notify_on_write() (see below)+}++void notify_on_write() {+  // 1. “Cover” the endpoint by starting adding this endpoint to a backup poller+  //    Note: This is NOT the same backup poller as the one used to maintain+  //    long-lived/infrequently used channels).++  // 2. Call grpc_fd_notify_on_write(fd, tcp_drop_uncovered_and_handle_write) to+  //    register a callback to do the actual write+}++```++##### What does ""Covering a write"" mean? - and ""endpoint backup poller""",The question mark seems misplaced,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16735,221641447,2018-10-01T14:57:36Z,tools/codegen/core/gen_static_metadata.py,"@@ -68,6 +68,67 @@     'gzip',     'stream/gzip',     # metadata elements+    (':authority', ''),","Please add a ""begin hpack static elements"" comment here, and an ""end hpack static elements"" comment after the last hpack static element in the list, so that people editing the list know which elements must be in that order without having to consult the RFC.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16490,221788790,2018-10-01T23:35:30Z,src/ruby/lib/grpc/generic/active_call.rb,"@@ -205,14 +205,24 @@ def remote_send(req, marshalled = false)     # list, mulitple metadata for its key are sent     def send_status(code = OK, details = '', assert_finished = false,                     metadata: {})-      send_initial_metadata+      metadata_already_sent = @send_initial_md_mutex.synchronize do+        # Can't send Trailers-Only since Response-Headers have already been sent+        v = @metadata_sent+        @metadata_sent ||= true+        v+      end+       ops = {         SEND_STATUS_FROM_SERVER => Struct::Status.new(code, details, metadata)       }       ops[RECV_CLOSE_ON_SERVER] = nil if assert_finished++      # To send initial metadata as trailing metadata(Trailers-Only) in order to support retries.+      # https://github.com/grpc/grpc/blob/92b45c8eefcdde5e0c0ec36373fdecb7cd7007d7/doc/PROTOCOL-HTTP2.md#responses","This code change looks good. I'm thinking about this more though and I think there should be a ruby-level test for this, which would a) prevent us from ignoring this comment and breaking retries of ruby servers in the future, and b) provide an illustrative example of RPC retries from ruby actually happeningIt would be great if we could add a ruby-equivalent of this [existing retry test](https://github.com/grpc/grpc/blob/master/test/core/end2end/tests/retry.cc#L100) that's written in C. Basically, the test would:1) provide a ""service config"" channel arg to the client to configure retries for e.g. ""aborted"" status2) send an RPC to the server3) Accept the first RPC, and have the server return status ""aborted"", and check that the special ""grpc-previous-rpc-attempts"" header was zero at the server4) Accept a second RPC at the server, and have the server return status ""OK"", and check that the special ""grpc-previous-rpc-attempts"" header from the client was 1.I'd expect this test will be decently large. And in particular accepting RPC's in a certain order could be tricky; to deal with this, I suggest running the server with a ""pool_size"" parameter of 1. Let me know if you'd like help and I can try and send a patch to your branch",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/15807,221848093,2018-10-02T07:32:11Z,include/grpc/impl/codegen/port_platform.h,"@@ -518,4 +518,18 @@ typedef unsigned __int64 uint64_t; #define __STDC_FORMAT_MACROS #endif +#if defined(__clang__) && defined(__has_cpp_attribute) \+    && !defined(GOOGLE_PROTOBUF_OS_APPLE)+# if defined(GOOGLE_PROTOBUF_OS_NACL) || defined(EMSCRIPTEN) || \+     __has_cpp_attribute(clang::fallthrough)+#  define GOOGLE_FALLTHROUGH_INTENDED [[clang::fallthrough]]",naming: this probably should be called `GOOGLE_..`.   `GRPC_FALLTHROUGH_INTENDED` or `GPR_FALLTHROUGH_INTENDED`?,OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/16712,222370627,2018-10-03T16:05:10Z,test/cpp/qps/client_async.cc,"@@ -949,10 +949,182 @@ std::unique_ptr<Client> CreateAsyncClient(const ClientConfig& config) {       return nullptr;   } }+ std::unique_ptr<Client> CreateGenericAsyncStreamingClient(     const ClientConfig& args) {   return std::unique_ptr<Client>(new GenericAsyncStreamingClient(args)); } +struct CallbackClientRpcData {+  CallbackClientRpcData()","I would suggest renaming this to `CallbackClientRpcContext` for a couple of reasons: 1) You use it as a context anyway by storing these in a vector called `ctxs` 2) For consistency: the existing code refers to this type of structure as a Context, such as `ClientRpcContext`",OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/16712,222395580,2018-10-03T17:21:47Z,test/cpp/qps/client_async.cc,"@@ -949,10 +949,182 @@ std::unique_ptr<Client> CreateAsyncClient(const ClientConfig& config) {       return nullptr;   } }+ std::unique_ptr<Client> CreateGenericAsyncStreamingClient(     const ClientConfig& args) {   return std::unique_ptr<Client>(new GenericAsyncStreamingClient(args)); } +struct CallbackClientRpcData {+  CallbackClientRpcData()+      : thread_mu_(), thread_cv_(), rpc_done_(false), alarm_(nullptr) {}++  ~CallbackClientRpcData() { delete alarm_; }++  std::mutex thread_mu_;","I suggest you rename this variable to just mu_. Since it lives inside `CallbackClientRpcData` and its purpose it to protect accesses to that structure, naming it mu_ is probably more correct than naming it `thread_mu_`. ",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16712,222398492,2018-10-03T17:30:37Z,test/cpp/qps/client_async.cc,"@@ -949,10 +949,182 @@ std::unique_ptr<Client> CreateAsyncClient(const ClientConfig& config) {       return nullptr;   } }+ std::unique_ptr<Client> CreateGenericAsyncStreamingClient(     const ClientConfig& args) {   return std::unique_ptr<Client>(new GenericAsyncStreamingClient(args)); } +struct CallbackClientRpcData {+  CallbackClientRpcData()+      : thread_mu_(), thread_cv_(), rpc_done_(false), alarm_(nullptr) {}++  ~CallbackClientRpcData() { delete alarm_; }++  std::mutex thread_mu_;+  std::condition_variable thread_cv_;+  bool rpc_done_;+  Alarm* alarm_;+};++class CallbackClient+    : public ClientImpl<BenchmarkService::Stub, SimpleRequest> {+ public:+  CallbackClient(const ClientConfig& config)+      : ClientImpl<BenchmarkService::Stub, SimpleRequest>(+            config, BenchmarkStubCreator) {+    num_threads_ = NumThreads(config);+    ctxs_.resize(num_threads_);+    threads_done_ = 0;+    SetupLoadTest(config, num_threads_);+  }++  virtual ~CallbackClient() {}++  virtual bool InitThreadFuncImpl(size_t thread_idx) { return true; }++  virtual bool ThreadFuncImpl(Thread* t, size_t thread_idx) = 0;++ protected:+  size_t num_threads_;+  std::mutex mu_;+  std::condition_variable cv_;+  std::vector<CallbackClientRpcData*> ctxs_;+  size_t threads_done_;++  void NotifyThread(size_t thread_idx) {+    std::mutex* thread_mu = &ctxs_[thread_idx]->thread_mu_;+    std::condition_variable* thread_cv = &ctxs_[thread_idx]->thread_cv_;+    std::lock_guard<std::mutex> thread_lock(*thread_mu);+    ctxs_[thread_idx]->rpc_done_ = true;+    thread_cv->notify_one();+  }++  void IssueCallbackRpc(size_t thread_idx, Thread* t) {+    if (!InitThreadFuncImpl(thread_idx)) {+      return;+    }++    if (!closed_loop_) {+      gpr_timespec next_issue_time = NextIssueTime(thread_idx);+      // Start an alarm call back to run the internal callback after+      // next_issue_time+      delete ctxs_[thread_idx]->alarm_;+      ctxs_[thread_idx]->alarm_ = new Alarm;+      Alarm* alarm = ctxs_[thread_idx]->alarm_;+      alarm->experimental().Set(+          next_issue_time,+          [this, t, thread_idx](bool ok) { ThreadFuncImpl(t, thread_idx); });+    } else {+      ThreadFuncImpl(t, thread_idx);+    }+  }++ private:+  int NumThreads(const ClientConfig& config) {+    int num_threads = config.async_client_threads();+    if (num_threads <= 0) {  // Use dynamic sizing+      num_threads = cores_;+      gpr_log(GPR_INFO, ""Sizing async client to %d threads"", num_threads);+    }+    return num_threads;+  }++  void ThreadFunc(size_t thread_idx, Thread* t) override {+    ctxs_[thread_idx] = new CallbackClientRpcData;+    IssueCallbackRpc(thread_idx, t);+    WaitForCompletionOfAllRpcs(thread_idx);++    NotifyMainThread(thread_idx);+    delete ctxs_[thread_idx];+    return;+  }++  void NotifyMainThread(size_t thread_idx) {+    std::lock_guard<std::mutex> l(mu_);+    threads_done_++;+    if (threads_done_ == num_threads_) {+      cv_.notify_one();+    }+  }++  void WaitForCompletionOfAllRpcs(size_t thread_idx) {+    std::mutex* thread_mu = &ctxs_[thread_idx]->thread_mu_;+    std::condition_variable* thread_cv = &ctxs_[thread_idx]->thread_cv_;+    std::unique_lock<std::mutex> thread_lock(*thread_mu);++    while (!ctxs_[thread_idx]->rpc_done_) {+      thread_cv->wait(thread_lock);+    }+    ctxs_[thread_idx]->rpc_done_ = false;+    thread_lock.unlock();+  }++  void DestroyMultithreading() final {+    std::unique_lock<std::mutex> l(mu_);+    while (threads_done_ != num_threads_) {+      cv_.wait(l);+    }+    EndThreads();+  }+};++class CallbackUnaryClient final : public CallbackClient {+ public:+  CallbackUnaryClient(const ClientConfig& config) : CallbackClient(config) {+    StartThreads(num_threads_);+  }+  ~CallbackUnaryClient() {}++  bool ThreadFuncImpl(Thread* t, size_t thread_idx) override {+    auto* stub = channels_[thread_idx % channels_.size()].get_stub();+    ClientContext* context = new grpc::ClientContext();+    SimpleResponse* response = new SimpleResponse();",Can these be entries in the bigger `ctx` data structure so that you don't need to do separate `new` and `delete` on them?,
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/16712,222415729,2018-10-03T18:20:01Z,test/cpp/qps/client_async.cc,"@@ -949,10 +949,182 @@ std::unique_ptr<Client> CreateAsyncClient(const ClientConfig& config) {       return nullptr;   } }+ std::unique_ptr<Client> CreateGenericAsyncStreamingClient(     const ClientConfig& args) {   return std::unique_ptr<Client>(new GenericAsyncStreamingClient(args)); } +struct CallbackClientRpcData {+  CallbackClientRpcData()+      : thread_mu_(), thread_cv_(), rpc_done_(false), alarm_(nullptr) {}++  ~CallbackClientRpcData() { delete alarm_; }++  std::mutex thread_mu_;+  std::condition_variable thread_cv_;",Similar comment here. I'd suggest renaming to `shutdown_cv_` since that's what the cv is used for.,OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/16712,222423509,2018-10-03T18:43:18Z,test/cpp/qps/client_async.cc,"@@ -949,10 +949,182 @@ std::unique_ptr<Client> CreateAsyncClient(const ClientConfig& config) {       return nullptr;   } }+ std::unique_ptr<Client> CreateGenericAsyncStreamingClient(     const ClientConfig& args) {   return std::unique_ptr<Client>(new GenericAsyncStreamingClient(args)); } +struct CallbackClientRpcData {+  CallbackClientRpcData()+      : thread_mu_(), thread_cv_(), rpc_done_(false), alarm_(nullptr) {}++  ~CallbackClientRpcData() { delete alarm_; }++  std::mutex thread_mu_;+  std::condition_variable thread_cv_;+  bool rpc_done_;+  Alarm* alarm_;+};++class CallbackClient+    : public ClientImpl<BenchmarkService::Stub, SimpleRequest> {+ public:+  CallbackClient(const ClientConfig& config)+      : ClientImpl<BenchmarkService::Stub, SimpleRequest>(+            config, BenchmarkStubCreator) {+    num_threads_ = NumThreads(config);+    ctxs_.resize(num_threads_);+    threads_done_ = 0;+    SetupLoadTest(config, num_threads_);+  }++  virtual ~CallbackClient() {}++  virtual bool InitThreadFuncImpl(size_t thread_idx) { return true; }++  virtual bool ThreadFuncImpl(Thread* t, size_t thread_idx) = 0;++ protected:+  size_t num_threads_;+  std::mutex mu_;+  std::condition_variable cv_;+  std::vector<CallbackClientRpcData*> ctxs_;+  size_t threads_done_;++  void NotifyThread(size_t thread_idx) {+    std::mutex* thread_mu = &ctxs_[thread_idx]->thread_mu_;+    std::condition_variable* thread_cv = &ctxs_[thread_idx]->thread_cv_;",Same thing with the condition variable,OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/16712,222426963,2018-10-03T18:53:29Z,test/cpp/qps/client_async.cc,"@@ -949,10 +949,182 @@ std::unique_ptr<Client> CreateAsyncClient(const ClientConfig& config) {       return nullptr;   } }+ std::unique_ptr<Client> CreateGenericAsyncStreamingClient(     const ClientConfig& args) {   return std::unique_ptr<Client>(new GenericAsyncStreamingClient(args)); } +struct CallbackClientRpcData {+  CallbackClientRpcData()+      : thread_mu_(), thread_cv_(), rpc_done_(false), alarm_(nullptr) {}++  ~CallbackClientRpcData() { delete alarm_; }++  std::mutex thread_mu_;+  std::condition_variable thread_cv_;+  bool rpc_done_;+  Alarm* alarm_;+};++class CallbackClient+    : public ClientImpl<BenchmarkService::Stub, SimpleRequest> {+ public:+  CallbackClient(const ClientConfig& config)+      : ClientImpl<BenchmarkService::Stub, SimpleRequest>(+            config, BenchmarkStubCreator) {+    num_threads_ = NumThreads(config);+    ctxs_.resize(num_threads_);+    threads_done_ = 0;+    SetupLoadTest(config, num_threads_);+  }++  virtual ~CallbackClient() {}++  virtual bool InitThreadFuncImpl(size_t thread_idx) { return true; }++  virtual bool ThreadFuncImpl(Thread* t, size_t thread_idx) = 0;++ protected:+  size_t num_threads_;+  std::mutex mu_;+  std::condition_variable cv_;+  std::vector<CallbackClientRpcData*> ctxs_;+  size_t threads_done_;++  void NotifyThread(size_t thread_idx) {+    std::mutex* thread_mu = &ctxs_[thread_idx]->thread_mu_;+    std::condition_variable* thread_cv = &ctxs_[thread_idx]->thread_cv_;+    std::lock_guard<std::mutex> thread_lock(*thread_mu);+    ctxs_[thread_idx]->rpc_done_ = true;+    thread_cv->notify_one();+  }++  void IssueCallbackRpc(size_t thread_idx, Thread* t) {+    if (!InitThreadFuncImpl(thread_idx)) {","What about cleanup or signaling that needs to be done in this if statement branch? Like setting `rpc_done_` to true and signaling the condition variable. Without this, if `InitThreadFuncImpl` returned false, wouldn't the thread wait forever in ` WaitForCompletionOfAllRpcs`?",OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/16712,222431831,2018-10-03T19:08:22Z,test/cpp/qps/client_async.cc,"@@ -949,10 +949,182 @@ std::unique_ptr<Client> CreateAsyncClient(const ClientConfig& config) {       return nullptr;   } }+ std::unique_ptr<Client> CreateGenericAsyncStreamingClient(     const ClientConfig& args) {   return std::unique_ptr<Client>(new GenericAsyncStreamingClient(args)); } +struct CallbackClientRpcData {+  CallbackClientRpcData()+      : thread_mu_(), thread_cv_(), rpc_done_(false), alarm_(nullptr) {}++  ~CallbackClientRpcData() { delete alarm_; }++  std::mutex thread_mu_;+  std::condition_variable thread_cv_;+  bool rpc_done_;+  Alarm* alarm_;+};++class CallbackClient+    : public ClientImpl<BenchmarkService::Stub, SimpleRequest> {+ public:+  CallbackClient(const ClientConfig& config)+      : ClientImpl<BenchmarkService::Stub, SimpleRequest>(+            config, BenchmarkStubCreator) {+    num_threads_ = NumThreads(config);+    ctxs_.resize(num_threads_);+    threads_done_ = 0;+    SetupLoadTest(config, num_threads_);+  }++  virtual ~CallbackClient() {}++  virtual bool InitThreadFuncImpl(size_t thread_idx) { return true; }++  virtual bool ThreadFuncImpl(Thread* t, size_t thread_idx) = 0;++ protected:+  size_t num_threads_;+  std::mutex mu_;+  std::condition_variable cv_;+  std::vector<CallbackClientRpcData*> ctxs_;+  size_t threads_done_;++  void NotifyThread(size_t thread_idx) {+    std::mutex* thread_mu = &ctxs_[thread_idx]->thread_mu_;+    std::condition_variable* thread_cv = &ctxs_[thread_idx]->thread_cv_;+    std::lock_guard<std::mutex> thread_lock(*thread_mu);+    ctxs_[thread_idx]->rpc_done_ = true;+    thread_cv->notify_one();+  }++  void IssueCallbackRpc(size_t thread_idx, Thread* t) {+    if (!InitThreadFuncImpl(thread_idx)) {+      return;+    }++    if (!closed_loop_) {+      gpr_timespec next_issue_time = NextIssueTime(thread_idx);+      // Start an alarm call back to run the internal callback after+      // next_issue_time+      delete ctxs_[thread_idx]->alarm_;+      ctxs_[thread_idx]->alarm_ = new Alarm;+      Alarm* alarm = ctxs_[thread_idx]->alarm_;+      alarm->experimental().Set(+          next_issue_time,+          [this, t, thread_idx](bool ok) { ThreadFuncImpl(t, thread_idx); });+    } else {+      ThreadFuncImpl(t, thread_idx);+    }+  }++ private:+  int NumThreads(const ClientConfig& config) {+    int num_threads = config.async_client_threads();+    if (num_threads <= 0) {  // Use dynamic sizing+      num_threads = cores_;+      gpr_log(GPR_INFO, ""Sizing async client to %d threads"", num_threads);+    }+    return num_threads;+  }++  void ThreadFunc(size_t thread_idx, Thread* t) override {+    ctxs_[thread_idx] = new CallbackClientRpcData;+    IssueCallbackRpc(thread_idx, t);+    WaitForCompletionOfAllRpcs(thread_idx);++    NotifyMainThread(thread_idx);",Nit: How about renaming this to `NotifyMainThreadOfThreadCompletion` or something that indicates what we're notifying the main thread about?,OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/16712,222435658,2018-10-03T19:20:24Z,test/cpp/qps/client_async.cc,"@@ -949,10 +949,182 @@ std::unique_ptr<Client> CreateAsyncClient(const ClientConfig& config) {       return nullptr;   } }+ std::unique_ptr<Client> CreateGenericAsyncStreamingClient(     const ClientConfig& args) {   return std::unique_ptr<Client>(new GenericAsyncStreamingClient(args)); } +struct CallbackClientRpcData {+  CallbackClientRpcData()+      : thread_mu_(), thread_cv_(), rpc_done_(false), alarm_(nullptr) {}++  ~CallbackClientRpcData() { delete alarm_; }++  std::mutex thread_mu_;+  std::condition_variable thread_cv_;+  bool rpc_done_;+  Alarm* alarm_;+};++class CallbackClient+    : public ClientImpl<BenchmarkService::Stub, SimpleRequest> {+ public:+  CallbackClient(const ClientConfig& config)+      : ClientImpl<BenchmarkService::Stub, SimpleRequest>(+            config, BenchmarkStubCreator) {+    num_threads_ = NumThreads(config);+    ctxs_.resize(num_threads_);+    threads_done_ = 0;+    SetupLoadTest(config, num_threads_);+  }++  virtual ~CallbackClient() {}++  virtual bool InitThreadFuncImpl(size_t thread_idx) { return true; }++  virtual bool ThreadFuncImpl(Thread* t, size_t thread_idx) = 0;++ protected:+  size_t num_threads_;+  std::mutex mu_;+  std::condition_variable cv_;+  std::vector<CallbackClientRpcData*> ctxs_;+  size_t threads_done_;++  void NotifyThread(size_t thread_idx) {+    std::mutex* thread_mu = &ctxs_[thread_idx]->thread_mu_;+    std::condition_variable* thread_cv = &ctxs_[thread_idx]->thread_cv_;+    std::lock_guard<std::mutex> thread_lock(*thread_mu);+    ctxs_[thread_idx]->rpc_done_ = true;+    thread_cv->notify_one();+  }++  void IssueCallbackRpc(size_t thread_idx, Thread* t) {+    if (!InitThreadFuncImpl(thread_idx)) {+      return;+    }++    if (!closed_loop_) {+      gpr_timespec next_issue_time = NextIssueTime(thread_idx);+      // Start an alarm call back to run the internal callback after+      // next_issue_time+      delete ctxs_[thread_idx]->alarm_;+      ctxs_[thread_idx]->alarm_ = new Alarm;+      Alarm* alarm = ctxs_[thread_idx]->alarm_;+      alarm->experimental().Set(+          next_issue_time,+          [this, t, thread_idx](bool ok) { ThreadFuncImpl(t, thread_idx); });+    } else {+      ThreadFuncImpl(t, thread_idx);+    }+  }++ private:+  int NumThreads(const ClientConfig& config) {+    int num_threads = config.async_client_threads();+    if (num_threads <= 0) {  // Use dynamic sizing+      num_threads = cores_;+      gpr_log(GPR_INFO, ""Sizing async client to %d threads"", num_threads);+    }+    return num_threads;+  }++  void ThreadFunc(size_t thread_idx, Thread* t) override {+    ctxs_[thread_idx] = new CallbackClientRpcData;+    IssueCallbackRpc(thread_idx, t);+    WaitForCompletionOfAllRpcs(thread_idx);++    NotifyMainThread(thread_idx);+    delete ctxs_[thread_idx];+    return;+  }++  void NotifyMainThread(size_t thread_idx) {+    std::lock_guard<std::mutex> l(mu_);+    threads_done_++;+    if (threads_done_ == num_threads_) {+      cv_.notify_one();+    }+  }++  void WaitForCompletionOfAllRpcs(size_t thread_idx) {+    std::mutex* thread_mu = &ctxs_[thread_idx]->thread_mu_;",See comment in `NotifyThread` about accessing the mutex and condition variable. It applies here as well.,OK
42048362,mhaidrygoog,https://api.github.com/repos/grpc/grpc/pulls/16712,222446188,2018-10-03T19:55:36Z,test/cpp/qps/client_async.cc,"@@ -949,10 +949,182 @@ std::unique_ptr<Client> CreateAsyncClient(const ClientConfig& config) {       return nullptr;   } }+ std::unique_ptr<Client> CreateGenericAsyncStreamingClient(     const ClientConfig& args) {   return std::unique_ptr<Client>(new GenericAsyncStreamingClient(args)); } +struct CallbackClientRpcData {+  CallbackClientRpcData()","I was avoiding renaming it to context as we have a seperate ClientContext structure and this particular structure doesn't embed it like the Async test, hence this name to avoid any such assumption. I don't feel strongly about it though and will rename it if this justification does not seem valid.",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/16712,222510616,2018-10-04T00:49:11Z,test/cpp/qps/client_async.cc,"@@ -949,10 +949,182 @@ std::unique_ptr<Client> CreateAsyncClient(const ClientConfig& config) {       return nullptr;   } }+ std::unique_ptr<Client> CreateGenericAsyncStreamingClient(     const ClientConfig& args) {   return std::unique_ptr<Client>(new GenericAsyncStreamingClient(args)); } +struct CallbackClientRpcData {+  CallbackClientRpcData()","In that case, it seems like naming the variable `ctxs_` would introduce that same confusion / assumption. Could you choose a name other than `ctxs_` for the vector of `CallbackClientRpcData`, maybe `rpc_data_list_`? I think something needs to be renamed here because there's an inconsistency between the structure name and the variable name. It's confusing that we think of this `CallbackClientRpcData` as a context, but it's not actually named that.",OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/16712,222512911,2018-10-04T01:07:37Z,test/cpp/qps/client_async.cc,"@@ -949,10 +949,182 @@ std::unique_ptr<Client> CreateAsyncClient(const ClientConfig& config) {       return nullptr;   } }+ std::unique_ptr<Client> CreateGenericAsyncStreamingClient(     const ClientConfig& args) {   return std::unique_ptr<Client>(new GenericAsyncStreamingClient(args)); } +struct CallbackClientRpcData {+  CallbackClientRpcData()+      : thread_mu_(), thread_cv_(), rpc_done_(false), alarm_(nullptr) {}++  ~CallbackClientRpcData() { delete alarm_; }++  std::mutex thread_mu_;+  std::condition_variable thread_cv_;+  bool rpc_done_;+  Alarm* alarm_;+};++class CallbackClient+    : public ClientImpl<BenchmarkService::Stub, SimpleRequest> {+ public:+  CallbackClient(const ClientConfig& config)+      : ClientImpl<BenchmarkService::Stub, SimpleRequest>(+            config, BenchmarkStubCreator) {+    num_threads_ = NumThreads(config);+    ctxs_.resize(num_threads_);+    threads_done_ = 0;+    SetupLoadTest(config, num_threads_);+  }++  virtual ~CallbackClient() {}++  virtual bool InitThreadFuncImpl(size_t thread_idx) { return true; }++  virtual bool ThreadFuncImpl(Thread* t, size_t thread_idx) = 0;++ protected:+  size_t num_threads_;+  std::mutex mu_;+  std::condition_variable cv_;+  std::vector<CallbackClientRpcData*> ctxs_;+  size_t threads_done_;++  void NotifyThread(size_t thread_idx) {+    std::mutex* thread_mu = &ctxs_[thread_idx]->thread_mu_;+    std::condition_variable* thread_cv = &ctxs_[thread_idx]->thread_cv_;+    std::lock_guard<std::mutex> thread_lock(*thread_mu);+    ctxs_[thread_idx]->rpc_done_ = true;+    thread_cv->notify_one();+  }++  void IssueCallbackRpc(size_t thread_idx, Thread* t) {+    if (!InitThreadFuncImpl(thread_idx)) {","It seems to me like it is involved in synchronization by nature of being called in this method. `IssueCallbackRpc` is called by `ThreadFunc`. Let's say at some point we decide to implement InitThreadFuncImpl to return false sometimes, and it happens to return false when `ThreadFunc` calls it. Then `ThreadFunc` will call `WaitForCompletionOfAllRpcs`, which will wait on the condition: `!ctxs_[thread_idx]->rpc_done_`. But that condition is never true, because ""the only place the rpc_done_ is set true is under the final callback when ThreadCompleted is true"": ThreadFuncImpl is never called, so the final callback, or indeed any callback, never happens. Does that make sense?",OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/16712,222513508,2018-10-04T01:12:34Z,test/cpp/qps/client_async.cc,"@@ -949,10 +949,182 @@ std::unique_ptr<Client> CreateAsyncClient(const ClientConfig& config) {       return nullptr;   } }+ std::unique_ptr<Client> CreateGenericAsyncStreamingClient(     const ClientConfig& args) {   return std::unique_ptr<Client>(new GenericAsyncStreamingClient(args)); } +struct CallbackClientRpcData {+  CallbackClientRpcData()+      : thread_mu_(), thread_cv_(), rpc_done_(false), alarm_(nullptr) {}++  ~CallbackClientRpcData() { delete alarm_; }++  std::mutex thread_mu_;+  std::condition_variable thread_cv_;+  bool rpc_done_;+  Alarm* alarm_;+};++class CallbackClient+    : public ClientImpl<BenchmarkService::Stub, SimpleRequest> {+ public:+  CallbackClient(const ClientConfig& config)+      : ClientImpl<BenchmarkService::Stub, SimpleRequest>(+            config, BenchmarkStubCreator) {+    num_threads_ = NumThreads(config);+    ctxs_.resize(num_threads_);+    threads_done_ = 0;+    SetupLoadTest(config, num_threads_);+  }++  virtual ~CallbackClient() {}++  virtual bool InitThreadFuncImpl(size_t thread_idx) { return true; }++  virtual bool ThreadFuncImpl(Thread* t, size_t thread_idx) = 0;++ protected:+  size_t num_threads_;+  std::mutex mu_;+  std::condition_variable cv_;+  std::vector<CallbackClientRpcData*> ctxs_;+  size_t threads_done_;++  void NotifyThread(size_t thread_idx) {+    std::mutex* thread_mu = &ctxs_[thread_idx]->thread_mu_;+    std::condition_variable* thread_cv = &ctxs_[thread_idx]->thread_cv_;+    std::lock_guard<std::mutex> thread_lock(*thread_mu);+    ctxs_[thread_idx]->rpc_done_ = true;+    thread_cv->notify_one();+  }++  void IssueCallbackRpc(size_t thread_idx, Thread* t) {+    if (!InitThreadFuncImpl(thread_idx)) {+      return;+    }++    if (!closed_loop_) {+      gpr_timespec next_issue_time = NextIssueTime(thread_idx);+      // Start an alarm call back to run the internal callback after+      // next_issue_time+      delete ctxs_[thread_idx]->alarm_;+      ctxs_[thread_idx]->alarm_ = new Alarm;+      Alarm* alarm = ctxs_[thread_idx]->alarm_;+      alarm->experimental().Set(+          next_issue_time,+          [this, t, thread_idx](bool ok) { ThreadFuncImpl(t, thread_idx); });+    } else {+      ThreadFuncImpl(t, thread_idx);+    }+  }++ private:+  int NumThreads(const ClientConfig& config) {+    int num_threads = config.async_client_threads();+    if (num_threads <= 0) {  // Use dynamic sizing+      num_threads = cores_;+      gpr_log(GPR_INFO, ""Sizing async client to %d threads"", num_threads);+    }+    return num_threads;+  }++  void ThreadFunc(size_t thread_idx, Thread* t) override {+    ctxs_[thread_idx] = new CallbackClientRpcData;+    IssueCallbackRpc(thread_idx, t);+    WaitForCompletionOfAllRpcs(thread_idx);++    NotifyMainThread(thread_idx);+    delete ctxs_[thread_idx];+    return;+  }++  void NotifyMainThread(size_t thread_idx) {+    std::lock_guard<std::mutex> l(mu_);+    threads_done_++;+    if (threads_done_ == num_threads_) {+      cv_.notify_one();+    }+  }++  void WaitForCompletionOfAllRpcs(size_t thread_idx) {+    std::mutex* thread_mu = &ctxs_[thread_idx]->thread_mu_;+    std::condition_variable* thread_cv = &ctxs_[thread_idx]->thread_cv_;+    std::unique_lock<std::mutex> thread_lock(*thread_mu);++    while (!ctxs_[thread_idx]->rpc_done_) {+      thread_cv->wait(thread_lock);+    }+    ctxs_[thread_idx]->rpc_done_ = false;+    thread_lock.unlock();","Interesting. If you needed to explicitly unlock it here, I would expect you would have needed to unlock the unique_lock in this function as well: https://github.com/grpc/grpc/blob/475dc6dc5eaf09e1f9af59e3346d937d3b7bbc2e/test/cpp/qps/client_async.cc#L1063",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16767,222716949,2018-10-04T15:27:15Z,src/core/lib/channel/channel_trace.cc,"@@ -48,31 +48,37 @@ ChannelTrace::TraceEvent::TraceEvent(Severity severity, grpc_slice data,       timestamp_(grpc_millis_to_timespec(grpc_core::ExecCtx::Get()->Now(),                                          GPR_CLOCK_REALTIME)),       next_(nullptr),-      referenced_entity_(std::move(referenced_entity)) {}+      referenced_entity_(std::move(referenced_entity)) {+  memory_usage_ = sizeof(TraceEvent) + grpc_slice_memory_usage(data);",This can be set in the initializer list.,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16767,222718737,2018-10-04T15:31:51Z,src/core/lib/channel/channel_trace.cc,"@@ -93,25 +99,27 @@ void ChannelTrace::AddTraceEventHelper(TraceEvent* new_trace_event) {     tail_trace_->set_next(new_trace_event);     tail_trace_ = tail_trace_->next();   }-  ++list_size_;-  // maybe garbage collect the end-  if (list_size_ > max_list_size_) {+  event_list_memory_usage_ += new_trace_event->memory_usage();+  // maybe garbage collect the tail until we are under the memory limit.+  while (event_list_memory_usage_ > max_event_memory_) {","One interesting side-effect of this is that if you add a single event that is by itself larger than the limit, it will have the effect of clearing the list.  That's probably okay, but it might be surprising in practice, so we should definitely document this somewhere.  Maybe in the description of the `AddTraceEvent()` method?",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16774,222741592,2018-10-04T16:32:20Z,include/grpc/impl/codegen/grpc_types.h,"@@ -286,13 +286,21 @@ typedef struct { /** The grpc_socket_factory instance to create and bind sockets. A pointer. */ #define GRPC_ARG_SOCKET_FACTORY ""grpc.socket_factory"" /** The maximum number of trace events to keep in the tracer for each channel or- * subchannel. The default is 10. If set to 0, channel tracing is disabled. */+ * subchannel. The default is 0. If set to 0, channel tracing is disabled. */ #define GRPC_ARG_MAX_CHANNEL_TRACE_EVENTS_PER_NODE \   ""grpc.max_channel_trace_events_per_node""+/** Note this is not a ""channel arg"" key. This is the default value for number",This doesn't belong in a public header.  Please move it to channelz.h.,OK
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/16782,222774657,2018-10-04T18:11:46Z,src/core/lib/security/security_connector/security_connector.cc,"@@ -120,17 +120,21 @@ const tsi_peer_property* tsi_peer_get_property_by_name(const tsi_peer* peer,  void grpc_channel_security_connector_add_handshakers(     grpc_channel_security_connector* connector,+    grpc_pollset_set* interested_parties,     grpc_handshake_manager* handshake_mgr) {   if (connector != nullptr) {     connector->add_handshakers(connector, handshake_mgr);+    connector->base.interested_parties = interested_parties;","Another reason for storing the pointer to `interested_parties` in the security connector is that, as discussed in (https://github.com/grpc/grpc/pull/16695#issuecomment-426395710), I plan to migrate psp to use the `interested_parties` passed in during handshaker construction time (instead of handshake time), which requires to retrieve it from somewhere and I believe security connector is a good place to store it. Since each security connector will always have its own corresponding `interested_parties`, I think it is not a bad idea to store it in security connector itself for the sake of future uses. How do you think?  ",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/16785,222793092,2018-10-04T19:08:36Z,.github/ISSUE_TEMPLATE.md,"@@ -26,6 +26,8 @@ If possible, provide a recipe for reproducing the error. Try being specific and ### What did you see instead?   Make sure you include information that can help us debug (full error message, exception listing, stack trace, logs).++See https://github.com/grpc/grpc/blob/master/TROUBLESHOOTING.md for how to diagnose problems better.",I'd say change the link to```See [TROUBLESHOOTING.md](https://github.com/grpc/grpc/blob/master/TROUBLESHOOTING.md) for how to diagnose problems better.```,
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/16712,222813485,2018-10-04T20:19:32Z,test/cpp/qps/client_callback.cc,"@@ -0,0 +1,208 @@+/*+ *+ * Copyright 2015 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <list>+#include <memory>+#include <mutex>+#include <sstream>+#include <string>+#include <thread>+#include <utility>+#include <vector>++#include <grpc/grpc.h>+#include <grpc/support/cpu.h>+#include <grpc/support/log.h>+#include <grpcpp/alarm.h>+#include <grpcpp/channel.h>+#include <grpcpp/client_context.h>++#include ""src/proto/grpc/testing/benchmark_service.grpc.pb.h""+#include ""test/cpp/qps/client.h""+#include ""test/cpp/qps/usage_timer.h""++namespace grpc {+namespace testing {++/**+ * Maintains context info per RPC+ */+struct CallbackClientRpcContext {+  CallbackClientRpcContext() : response_(), context_(), alarm_() {}++  ~CallbackClientRpcContext() {}++  SimpleResponse response_;+  ClientContext context_;+  Alarm alarm_;+};++static std::unique_ptr<BenchmarkService::Stub> BenchmarkStubCreator(+    const std::shared_ptr<Channel>& ch) {+  return BenchmarkService::NewStub(ch);+}++class CallbackClient+    : public ClientImpl<BenchmarkService::Stub, SimpleRequest> {+ public:+  CallbackClient(const ClientConfig& config)+      : ClientImpl<BenchmarkService::Stub, SimpleRequest>(+            config, BenchmarkStubCreator) {+    num_threads_ = NumThreads(config);+    ctxs_.resize(num_threads_);+    threads_done_ = 0;+    SetupLoadTest(config, num_threads_);+  }++  virtual ~CallbackClient() {}++  /**+   * Setup context data before running RPC+   */+  virtual bool InitThreadFuncImpl(size_t thread_idx) {+    ctxs_[thread_idx].reset(new CallbackClientRpcContext);+    return true;+  }++  virtual bool ThreadFuncImpl(Thread* t, size_t thread_idx) = 0;++ protected:+  size_t num_threads_;+  // The below mutex and condition variable is used by main benchmark thread to+  // wait on completion of all RPCs before shutdown+  std::mutex shutdown_mu_;+  std::condition_variable shutdown_cv_;+  // Context data pointers are maintained per thread and reallocated before+  // running a RPC+  std::vector<std::unique_ptr<CallbackClientRpcContext>> ctxs_;+  // Number of threads that have finished issuing RPCs+  size_t threads_done_;++  void IssueCallbackRpc(size_t thread_idx, Thread* t) {+    if (!InitThreadFuncImpl(thread_idx)) {+      return;+    }++    if (!closed_loop_) {+      gpr_timespec next_issue_time = NextIssueTime(thread_idx);+      // Start an alarm callback to run the internal callback after+      // next_issue_time+      ctxs_[thread_idx]->alarm_.experimental().Set(+          next_issue_time,+          [this, t, thread_idx](bool ok) { ThreadFuncImpl(t, thread_idx); });+    } else {+      ThreadFuncImpl(t, thread_idx);+    }+  }++  /**+   * The main thread of the benchmark will be waiting on DestroyMultithreading.","I still have a question regarding the synchronization:Since the main thread is waiting on DestroyMultithreading, and thus on the condition `threads_done_ != num_threads_`, if any thread immediately returns from the IssueCallbackRpc function because `InitThreadFuncImpl(thread_idx)` returns false, won't the main thread be blocked forever? `threads_done_` will not have incremented. ",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/16767,222854937,2018-10-04T23:15:10Z,src/core/lib/slice/slice_internal.h,"@@ -46,4 +46,9 @@ grpc_slice grpc_slice_maybe_static_intern(grpc_slice slice, uint32_t grpc_static_slice_hash(grpc_slice s); int grpc_static_slice_eq(grpc_slice a, grpc_slice b); +// Returns the memory used by this slice, not counting the slice structure","The slice struct is held within the TraceEvent class, so that memory is counted when we do sizeof(TraceEvent)",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/16767,222856205,2018-10-04T23:23:53Z,test/core/channel/channel_trace_test.cc,"@@ -247,14 +254,93 @@ TEST_P(ChannelTracerTest, TestNesting) {       ChannelTrace::Severity::Warning,       grpc_slice_from_static_string(""subchannel one inactive""), sc1);   AddSimpleTrace(&tracer);-  ValidateChannelTrace(&tracer, 8, GetParam());+  ValidateChannelTrace(&tracer, 8);   sc1.reset();   sc2.reset();   conn1.reset(); } -INSTANTIATE_TEST_CASE_P(ChannelTracerTestSweep, ChannelTracerTest,-                        ::testing::Values(0, 1, 2, 6, 10, 15));+TEST(ChannelTracerTest, TestSmallMemoryLimit) {+  grpc_core::ExecCtx exec_ctx;+  // doesn't make sense, but serves a testing purpose for the channel tracing+  // bookkeeping. All tracing events added should will get immediately garbage+  // collected.+  const int kSmallMemoryLimit = 1;+  ChannelTrace tracer(kSmallMemoryLimit);+  AddSimpleTrace(&tracer);+  AddSimpleTrace(&tracer);+  tracer.AddTraceEvent(ChannelTrace::Severity::Info,+                       grpc_slice_from_static_string(""trace three""));+  tracer.AddTraceEvent(ChannelTrace::Severity::Error,+                       grpc_slice_from_static_string(""trace four error""));+  ValidateChannelTraceCustom(&tracer, 4, 0);+  AddSimpleTrace(&tracer);+  AddSimpleTrace(&tracer);+  ValidateChannelTraceCustom(&tracer, 6, 0);+  AddSimpleTrace(&tracer);+  AddSimpleTrace(&tracer);+  AddSimpleTrace(&tracer);+  AddSimpleTrace(&tracer);+  ValidateChannelTraceCustom(&tracer, 10, 0);+}++TEST(ChannelTracerTest, TestEviction) {+  grpc_core::ExecCtx exec_ctx;+  // This depends on sizeof(ChannelTrace). If that struct has been updated,","Sorry, it actually depends on TraceEvent, which is a private class. I added a helper and friend declaration to access the size rather than hardcode it",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16777,222909312,2018-10-05T07:04:08Z,tools/run_tests/artifacts/build_artifact_csharp.sh,"@@ -17,7 +17,12 @@ set -ex  cd ""$(dirname ""$0"")/../../.."" +mkdir -p cmake/build+cd cmake/build++cmake -DCMAKE_BUILD_TYPE=RelWithDebInfo -DgRPC_BACKWARDS_COMPATIBILITY_MODE=ON -DgRPC_BUILD_TESTS=OFF ""${CMAKE_ARCH_OPTION}"" ../..","style nit: since this is a little long IMO it is more readable with each macro definition on its own linee.g.```cmake -DCMAKE_BUILD_TYPE=RelWithDebInfo \  -DgRPC_BACKWARDS_COMPATIBILITY_MODE=ON \  -DgRPC_BUILD_TESTS=OFF \  ""${CMAKE_ARCH_OPTION}"" ../.```",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16777,223050565,2018-10-05T15:35:16Z,tools/run_tests/artifacts/build_artifact_csharp.sh,"@@ -17,7 +17,12 @@ set -ex  cd ""$(dirname ""$0"")/../../.."" +mkdir -p cmake/build+cd cmake/build++cmake -DCMAKE_BUILD_TYPE=RelWithDebInfo -DgRPC_BACKWARDS_COMPATIBILITY_MODE=ON -DgRPC_BUILD_TESTS=OFF ""${CMAKE_ARCH_OPTION}"" ../.. make grpc_csharp_ext+cd ../..","When building artifacts, we're already building 6 artifact jobs in parallel, so I'll use -j 2 here to get some speedup, but not to overload the machine. https://github.com/grpc/grpc/blob/cf534be6d35979d25e688dbf8b85ed5c999e382d/tools/internal_ci/linux/grpc_build_artifacts.sh#L29",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/16788,223116356,2018-10-05T19:26:24Z,src/core/lib/gprpp/inlined_vector.h,"@@ -123,6 +123,14 @@ class InlinedVector {    void push_back(T&& value) { emplace_back(std::move(value)); } +  void pop_back() {",Yup: https://github.com/abseil/abseil-cpp/blob/cc4bed2d74f7c8717e31f9579214ab52a9c9c610/absl/container/inlined_vector.h#L382,
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/16801,223254260,2018-10-08T06:07:02Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -2211,7 +2211,7 @@ static void add_retriable_send_initial_metadata_op(                                    .grpc_previous_rpc_attempts);   }   if (GPR_UNLIKELY(calld->num_attempts_completed > 0)) {-    grpc_mdelem retry_md = grpc_mdelem_from_slices(+    grpc_mdelem retry_md = grpc_mdelem_from_slices_no_unref(","I am not very familiar with the metadata code, but it looks like we didn't ref prior to this PR. Why should we change to `grpc_mdelem_from_slices_no_unref()` here?Similar with most of the rest changes.",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/16812,223773330,2018-10-09T16:28:09Z,WORKSPACE,"@@ -34,10 +34,11 @@ pip_import( load(""@grpc_python_dependencies//:requirements.bzl"", ""pip_install"") pip_install() +# TODO(ghostwriternr): Switch to upstream repo",Put a link to the issue you've filed against the upstream repository in place of your username - [we don't allow usernames in TODOs](https://github.com/grpc/grpc/blob/912b8ab4d49cd6cde76675d37c896e5edcf67487/.pylintrc#L16-L19) (though I'm sure you'll find lots of disallowed ones if you go looking for them).,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16792,223773477,2018-10-09T16:28:36Z,test/core/security/ssl_server_fuzzer.cc,"@@ -91,7 +91,7 @@ extern ""C"" int LLVMFuzzerTestOneInput(const uint8_t* data, size_t size) {     struct handshake_state state;     state.done_callback_called = false;     grpc_handshake_manager* handshake_mgr = grpc_handshake_manager_create();-    grpc_server_security_connector_add_handshakers(sc, handshake_mgr);+    grpc_server_security_connector_add_handshakers(sc, nullptr, handshake_mgr);     grpc_handshake_manager_do_handshake(","We should also remove the `interested_parties` argument from the `grpc_handshake_manager_do_handshake()` method, since it's no longer needed there.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16727,223774233,2018-10-09T16:31:01Z,tools/dockerfile/interoptest/grpc_interop_cxx/build_interop.sh,"@@ -31,7 +31,7 @@ cd /var/local/git/grpc make install-certs  # build C++ interop client & server-make interop_client interop_server+make interop_client interop_server -j8",not sure about this:Currently 8 interop images are going to be built in parallel and 8*8 = 64 (the workers have 16 cores).https://github.com/grpc/grpc/blob/912b8ab4d49cd6cde76675d37c896e5edcf67487/tools/internal_ci/linux/grpc_interop_tocloud.cfg#L29Change to `-j2` which gives some boost and is conservative enough?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16801,223779379,2018-10-09T16:46:13Z,src/core/lib/transport/metadata.h,"@@ -109,7 +109,11 @@ struct grpc_mdelem {                               (uintptr_t)GRPC_MDELEM_STORAGE_INTERNED_BIT))  /* Unrefs the slices. */-grpc_mdelem grpc_mdelem_from_slices(grpc_slice key, grpc_slice value);+grpc_mdelem grpc_mdelem_from_slices(const grpc_slice& key,","Is it actually helpful to pass the slices in as const references?  My understanding is that the `grpc_slice` API was designed such that you can pass slices around by value, since they're essentially no bigger than a pointer.  But I haven't actually looked at the implementation to verify that.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16801,223779959,2018-10-09T16:47:55Z,src/core/lib/transport/metadata.h,"@@ -109,7 +109,11 @@ struct grpc_mdelem {                               (uintptr_t)GRPC_MDELEM_STORAGE_INTERNED_BIT))  /* Unrefs the slices. */-grpc_mdelem grpc_mdelem_from_slices(grpc_slice key, grpc_slice value);+grpc_mdelem grpc_mdelem_from_slices(const grpc_slice& key,+                                    const grpc_slice& value);+/* Does not unref the slices. */+grpc_mdelem grpc_mdelem_from_slices_no_unref(const grpc_slice& key,","Instead of having two versions of this method, could we perhaps convert the `grpc_slice` API to C++ and change these methods to take the slices as `RefCountedPtr<>`s?  That way, the semantic will be clear from the API.",
38445398,aharperg,https://api.github.com/repos/grpc/grpc/pulls/16190,223864985,2018-10-09T21:10:26Z,src/objective-c/GRPCClient/GRPCCall+ChannelArg.h,"@@ -19,52 +19,20 @@  #include <AvailabilityMacros.h> -typedef NS_ENUM(NSInteger, GRPCCompressAlgorithm) {-  GRPCCompressNone,-  GRPCCompressDeflate,-  GRPCCompressGzip,-};--/**- * Methods to configure GRPC channel options.- */+// Deprecated interface. Please use GRPCCallOptions instead.",Should you add __attribute__((deprecated)) to the methods as well? Or are you concerned about warnings noise?,
38445398,aharperg,https://api.github.com/repos/grpc/grpc/pulls/16190,223866139,2018-10-09T21:14:24Z,src/objective-c/GRPCClient/GRPCCall.h,"@@ -139,43 +143,124 @@ typedef NS_ENUM(NSUInteger, GRPCErrorCode) {   GRPCErrorCodeDataLoss = 15, }; -/**- * Safety remark of a gRPC method as defined in RFC 2616 Section 9.1- */-typedef NS_ENUM(NSUInteger, GRPCCallSafety) {-  /** Signal that there is no guarantees on how the call affects the server state. */-  GRPCCallSafetyDefault = 0,-  /** Signal that the call is idempotent. gRPC is free to use PUT verb. */-  GRPCCallSafetyIdempotentRequest = 1,-  /** Signal that the call is cacheable and will not affect server state. gRPC is free to use GET-     verb. */-  GRPCCallSafetyCacheableRequest = 2,-};- /**  * Keys used in |NSError|'s |userInfo| dictionary to store the response headers and trailers sent by  * the server.  */ extern id const kGRPCHeadersKey; extern id const kGRPCTrailersKey; +/** An object can implement this protocol to receive responses from server from a call. */+@protocol GRPCResponseHandler+@optional+/** Issued when initial metadata is received from the server. */+- (void)receivedInitialMetadata:(NSDictionary *)initialMetadata;+/**+ * Issued when a message is received from the server. The message may be raw data from the server+ * (when using \a GRPCCall2 directly) or deserialized proto object (when using \a ProtoRPC).+ */+- (void)receivedMessage:(id)message;",Perhaps these should be different handler methods? receivedMessageData vs receivedMessageProto or similar?,
38445398,aharperg,https://api.github.com/repos/grpc/grpc/pulls/16190,223868387,2018-10-09T21:21:57Z,src/objective-c/GRPCClient/GRPCCall.h,"@@ -139,43 +143,124 @@ typedef NS_ENUM(NSUInteger, GRPCErrorCode) {   GRPCErrorCodeDataLoss = 15, }; -/**- * Safety remark of a gRPC method as defined in RFC 2616 Section 9.1- */-typedef NS_ENUM(NSUInteger, GRPCCallSafety) {-  /** Signal that there is no guarantees on how the call affects the server state. */-  GRPCCallSafetyDefault = 0,-  /** Signal that the call is idempotent. gRPC is free to use PUT verb. */-  GRPCCallSafetyIdempotentRequest = 1,-  /** Signal that the call is cacheable and will not affect server state. gRPC is free to use GET-     verb. */-  GRPCCallSafetyCacheableRequest = 2,-};- /**  * Keys used in |NSError|'s |userInfo| dictionary to store the response headers and trailers sent by  * the server.  */ extern id const kGRPCHeadersKey; extern id const kGRPCTrailersKey; +/** An object can implement this protocol to receive responses from server from a call. */+@protocol GRPCResponseHandler+@optional+/** Issued when initial metadata is received from the server. */+- (void)receivedInitialMetadata:(NSDictionary *)initialMetadata;+/**+ * Issued when a message is received from the server. The message may be raw data from the server+ * (when using \a GRPCCall2 directly) or deserialized proto object (when using \a ProtoRPC).+ */+- (void)receivedMessage:(id)message;+/**+ * Issued when a call finished. If the call finished successfully, \a error is nil and \a+ * trainingMetadata consists any trailing metadata received from the server. Otherwise, \a error+ * is non-nil and contains the corresponding error information, including gRPC error codes and+ * error descriptions.+ */+- (void)closedWithTrailingMetadata:(NSDictionary *)trailingMetadata error:(NSError *)error;++/**+ * All the responses must be issued to a user-provided dispatch queue. This property specifies the+ * dispatch queue to be used for issuing the notifications.+ */+@property(atomic, readonly) dispatch_queue_t dispatchQueue;++@end++/**+ * Call related parameters. These parameters are automatically specified by Protobuf. If directly+ * using the \a GRPCCall2 class, users should specify these parameters manually.+ */+@interface GRPCRequestOptions : NSObject<NSCopying>++- (instancetype)init NS_UNAVAILABLE;++/** Initialize with all properties. */+- (instancetype)initWithHost:(NSString *)host path:(NSString *)path safety:(GRPCCallSafety)safety;++/** The host serving the RPC service. */+@property(copy, readonly) NSString *host;+/** The path to the RPC call. */+@property(copy, readonly) NSString *path;+/**+ * Specify whether the call is idempotent or cachable. gRPC may select different HTTP verbs for the+ * call based on this information.+ */+@property(readonly) GRPCCallSafety safety;++@end+ #pragma mark GRPCCall -/** Represents a single gRPC remote call. */-@interface GRPCCall : GRXWriter+/**+ * A \a GRPCCall2 object represents an RPC call.+ */+@interface GRPCCall2 : NSObject++- (instancetype)init NS_UNAVAILABLE;  /**- * The authority for the RPC. If nil, the default authority will be used. This property must be nil- * when Cronet transport is enabled.+ * Designated initializer for a call.+ * \param requestOptions Protobuf generated parameters for the call.+ * \param handler The object to which responses should be issed.+ * \param callOptions Options for the call.  */-@property(atomic, copy, readwrite) NSString *serverName;+- (instancetype)initWithRequestOptions:(GRPCRequestOptions *)requestOptions+                               handler:(id<GRPCResponseHandler>)handler+                           callOptions:(GRPCCallOptions *)callOptions NS_DESIGNATED_INITIALIZER;+/**+ * Convevience initializer for a call that uses default call options.+ */+- (instancetype)initWithRequestOptions:(GRPCRequestOptions *)requestOptions+                               handler:(id<GRPCResponseHandler>)handler;  /**- * The timeout for the RPC call in seconds. If set to 0, the call will not timeout. If set to- * positive, the gRPC call returns with status GRPCErrorCodeDeadlineExceeded if it is not completed- * within \a timeout seconds. A negative value is not allowed.+ * Starts the call. Can only be called once.  */-@property NSTimeInterval timeout;+- (void)start;++/**+ * Cancel the request of this call at best effort; notifies the server that the RPC should be+ * cancelled, and issue callback to the user with an error code CANCELED if the call is not+ * finished.+ */+- (void)cancel;++/**+ * Send a message to the server. Data are sent as raw bytes in gRPC message frames.+ */+- (void)writeWithData:(NSData *)data;","""writeData"" for similarity with NSFileHandle, etc.",
38445398,aharperg,https://api.github.com/repos/grpc/grpc/pulls/16190,223869035,2018-10-09T21:24:05Z,src/objective-c/GRPCClient/GRPCCall.h,"@@ -139,43 +143,124 @@ typedef NS_ENUM(NSUInteger, GRPCErrorCode) {   GRPCErrorCodeDataLoss = 15, }; -/**- * Safety remark of a gRPC method as defined in RFC 2616 Section 9.1- */-typedef NS_ENUM(NSUInteger, GRPCCallSafety) {-  /** Signal that there is no guarantees on how the call affects the server state. */-  GRPCCallSafetyDefault = 0,-  /** Signal that the call is idempotent. gRPC is free to use PUT verb. */-  GRPCCallSafetyIdempotentRequest = 1,-  /** Signal that the call is cacheable and will not affect server state. gRPC is free to use GET-     verb. */-  GRPCCallSafetyCacheableRequest = 2,-};- /**  * Keys used in |NSError|'s |userInfo| dictionary to store the response headers and trailers sent by  * the server.  */ extern id const kGRPCHeadersKey; extern id const kGRPCTrailersKey; +/** An object can implement this protocol to receive responses from server from a call. */+@protocol GRPCResponseHandler+@optional+/** Issued when initial metadata is received from the server. */+- (void)receivedInitialMetadata:(NSDictionary *)initialMetadata;+/**+ * Issued when a message is received from the server. The message may be raw data from the server+ * (when using \a GRPCCall2 directly) or deserialized proto object (when using \a ProtoRPC).+ */+- (void)receivedMessage:(id)message;+/**+ * Issued when a call finished. If the call finished successfully, \a error is nil and \a+ * trainingMetadata consists any trailing metadata received from the server. Otherwise, \a error+ * is non-nil and contains the corresponding error information, including gRPC error codes and+ * error descriptions.+ */+- (void)closedWithTrailingMetadata:(NSDictionary *)trailingMetadata error:(NSError *)error;++/**+ * All the responses must be issued to a user-provided dispatch queue. This property specifies the+ * dispatch queue to be used for issuing the notifications.+ */+@property(atomic, readonly) dispatch_queue_t dispatchQueue;++@end++/**+ * Call related parameters. These parameters are automatically specified by Protobuf. If directly+ * using the \a GRPCCall2 class, users should specify these parameters manually.+ */+@interface GRPCRequestOptions : NSObject<NSCopying>++- (instancetype)init NS_UNAVAILABLE;++/** Initialize with all properties. */+- (instancetype)initWithHost:(NSString *)host path:(NSString *)path safety:(GRPCCallSafety)safety;++/** The host serving the RPC service. */+@property(copy, readonly) NSString *host;+/** The path to the RPC call. */+@property(copy, readonly) NSString *path;+/**+ * Specify whether the call is idempotent or cachable. gRPC may select different HTTP verbs for the+ * call based on this information.+ */+@property(readonly) GRPCCallSafety safety;++@end+ #pragma mark GRPCCall -/** Represents a single gRPC remote call. */-@interface GRPCCall : GRXWriter+/**+ * A \a GRPCCall2 object represents an RPC call.+ */+@interface GRPCCall2 : NSObject++- (instancetype)init NS_UNAVAILABLE;  /**- * The authority for the RPC. If nil, the default authority will be used. This property must be nil- * when Cronet transport is enabled.+ * Designated initializer for a call.+ * \param requestOptions Protobuf generated parameters for the call.+ * \param handler The object to which responses should be issed.+ * \param callOptions Options for the call.  */-@property(atomic, copy, readwrite) NSString *serverName;+- (instancetype)initWithRequestOptions:(GRPCRequestOptions *)requestOptions+                               handler:(id<GRPCResponseHandler>)handler+                           callOptions:(GRPCCallOptions *)callOptions NS_DESIGNATED_INITIALIZER;+/**+ * Convevience initializer for a call that uses default call options.+ */+- (instancetype)initWithRequestOptions:(GRPCRequestOptions *)requestOptions+                               handler:(id<GRPCResponseHandler>)handler;  /**- * The timeout for the RPC call in seconds. If set to 0, the call will not timeout. If set to- * positive, the gRPC call returns with status GRPCErrorCodeDeadlineExceeded if it is not completed- * within \a timeout seconds. A negative value is not allowed.+ * Starts the call. Can only be called once.  */-@property NSTimeInterval timeout;+- (void)start;++/**+ * Cancel the request of this call at best effort; notifies the server that the RPC should be+ * cancelled, and issue callback to the user with an error code CANCELED if the call is not+ * finished.+ */","Maybe not the right place to document this, but I've personally found this confusing in the past. If the connection is dead and the server cannot be reached I believe this still returns CANCELED, yes? If that's the case consider phrasing this as:""Cancel the request of this call at best effort; it attempts to notify the server that the RPC should be cancelled, and always issues a callback...""",OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/16801,223875866,2018-10-09T21:49:37Z,src/core/lib/transport/metadata.h,"@@ -109,7 +109,11 @@ struct grpc_mdelem {                               (uintptr_t)GRPC_MDELEM_STORAGE_INTERNED_BIT))  /* Unrefs the slices. */-grpc_mdelem grpc_mdelem_from_slices(grpc_slice key, grpc_slice value);+grpc_mdelem grpc_mdelem_from_slices(const grpc_slice& key,+                                    const grpc_slice& value);+/* Does not unref the slices. */+grpc_mdelem grpc_mdelem_from_slices_no_unref(const grpc_slice& key,","Thank you @markdroth but `grpc_slice` is ref-counted intrusively (internally). I'm not completely sure if that's something we can do with `RefCountedPtr<>`. Moving it to C++ API is a great long term plan, but is perhaps would take a long time.If you have strong preference for having one version of this function, an easier option is to remove the unref from `grpc_mdelem_from_slice`, and calling `unref` explicitly in the call site. Would that be something you prefer over this patch?FWIW, we already ahve `grpc_slice_sub_no_ref` and `grpc_slice_sub`. ",
38445398,aharperg,https://api.github.com/repos/grpc/grpc/pulls/16190,223881557,2018-10-09T22:13:27Z,src/objective-c/GRPCClient/GRPCCall.m,"@@ -317,11 +498,36 @@ - (void)startNextRead {  #pragma mark Send headers -- (void)sendHeaders:(NSDictionary *)headers {+- (void)sendHeaders {+  // TODO (mxyan): Remove after deprecated methods are removed+  uint32_t callSafetyFlags;+  switch (_callSafety) {+    case GRPCCallSafetyDefault:+      callSafetyFlags = 0;+      break;+    case GRPCCallSafetyIdempotentRequest:+      callSafetyFlags = GRPC_INITIAL_METADATA_IDEMPOTENT_REQUEST;+      break;+    case GRPCCallSafetyCacheableRequest:+      callSafetyFlags = GRPC_INITIAL_METADATA_CACHEABLE_REQUEST;+      break;+    default:","By adding a default to the switch you're preventing clang from warning you about incomplete case coverage at compile time. You still need the runtime check, but consider putting the exception as a separate check.",OK
38445398,aharperg,https://api.github.com/repos/grpc/grpc/pulls/16190,223882906,2018-10-09T22:19:33Z,src/objective-c/GRPCClient/GRPCCall.m,"@@ -486,15 +689,43 @@ - (void)startWithWriteable:(id<GRXWriteable>)writeable {   // that the life of the instance is determined by this retain cycle.   _retainSelf = self; -  if (self.tokenProvider != nil) {+  if (_callOptions == nil) {+    GRPCMutableCallOptions *callOptions;+    if ([GRPCHost isHostConfigured:_host]) {+      GRPCHost *hostConfig = [GRPCHost hostWithAddress:_host];+      callOptions = hostConfig.callOptions;+    } else {+      callOptions = [[GRPCMutableCallOptions alloc] init];+    }+    if (_serverName != nil) {+      callOptions.serverAuthority = _serverName;+    }+    if (_timeout != 0) {+      callOptions.timeout = _timeout;+    }+    uint32_t callFlags = [GRPCCall callFlagsForHost:_host path:_path];+    if (callFlags != 0) {+      if (callFlags == GRPC_INITIAL_METADATA_IDEMPOTENT_REQUEST) {+        _callSafety = GRPCCallSafetyIdempotentRequest;+      } else if (callFlags == GRPC_INITIAL_METADATA_CACHEABLE_REQUEST) {+        _callSafety = GRPCCallSafetyCacheableRequest;+      }+    }++    id<GRPCAuthorizationProtocol> tokenProvider = self.tokenProvider;+    if (tokenProvider != nil) {+      callOptions.authTokenProvider = tokenProvider;+    }+    _callOptions = callOptions;+  }+  if (_callOptions.authTokenProvider != nil) {     self.isWaitingForToken = YES;     __weak typeof(self) weakSelf = self;","This is prexisting, but do we have a sense of why there's a strong/weak dance here? In general this API seems to be self-retaining around the duration of the call, which makes sense. Is there something particuar about auth tokens that might require breaking that pattern?",
38445398,aharperg,https://api.github.com/repos/grpc/grpc/pulls/16190,223888167,2018-10-09T22:44:38Z,src/objective-c/GRPCClient/GRPCCallOptions.m,"@@ -0,0 +1,431 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#import ""GRPCCallOptions.h""++static NSString *const kDefaultServerAuthority = nil;+static const NSTimeInterval kDefaultTimeout = 0;+static NSDictionary *const kDefaultInitialMetadata = nil;+static NSString *const kDefaultUserAgentPrefix = nil;+static const NSUInteger kDefaultResponseSizeLimit = 0;+static const GRPCCompressAlgorithm kDefaultCompressAlgorithm = GRPCCompressNone;+static const BOOL kDefaultEnableRetry = YES;+static const NSTimeInterval kDefaultKeepaliveInterval = 0;+static const NSTimeInterval kDefaultKeepaliveTimeout = 0;+static const NSTimeInterval kDefaultConnectMinTimeout = 0;+static const NSTimeInterval kDefaultConnectInitialBackoff = 0;+static const NSTimeInterval kDefaultConnectMaxBackoff = 0;+static NSDictionary *const kDefaultAdditionalChannelArgs = nil;+static NSString *const kDefaultPemRootCert = nil;+static NSString *const kDefaultPemPrivateKey = nil;+static NSString *const kDefaultPemCertChain = nil;+static NSString *const kDefaultOauth2AccessToken = nil;+static const id<GRPCAuthorizationProtocol> kDefaultAuthTokenProvider = nil;+static const GRPCTransportType kDefaultTransportType = GRPCTransportTypeDefault;+static NSString *const kDefaultHostNameOverride = nil;+static const id kDefaultLogContext = nil;+static NSString *kDefaultChannelPoolDomain = nil;+static NSUInteger kDefaultChannelId = 0;++@implementation GRPCCallOptions {+ @protected+  NSString *_serverAuthority;+  NSTimeInterval _timeout;+  NSString *_oauth2AccessToken;+  id<GRPCAuthorizationProtocol> _authTokenProvider;+  NSDictionary *_initialMetadata;+  NSString *_userAgentPrefix;+  NSUInteger _responseSizeLimit;+  GRPCCompressAlgorithm _compressAlgorithm;+  BOOL _enableRetry;+  NSTimeInterval _keepaliveInterval;+  NSTimeInterval _keepaliveTimeout;+  NSTimeInterval _connectMinTimeout;+  NSTimeInterval _connectInitialBackoff;+  NSTimeInterval _connectMaxBackoff;+  NSDictionary *_additionalChannelArgs;+  NSString *_pemRootCert;+  NSString *_pemPrivateKey;+  NSString *_pemCertChain;+  GRPCTransportType _transportType;+  NSString *_hostNameOverride;+  id _logContext;+  NSString *_channelPoolDomain;+  NSUInteger _channelId;+}++@synthesize serverAuthority = _serverAuthority;+@synthesize timeout = _timeout;+@synthesize oauth2AccessToken = _oauth2AccessToken;+@synthesize authTokenProvider = _authTokenProvider;+@synthesize initialMetadata = _initialMetadata;+@synthesize userAgentPrefix = _userAgentPrefix;+@synthesize responseSizeLimit = _responseSizeLimit;+@synthesize compressAlgorithm = _compressAlgorithm;+@synthesize enableRetry = _enableRetry;+@synthesize keepaliveInterval = _keepaliveInterval;+@synthesize keepaliveTimeout = _keepaliveTimeout;+@synthesize connectMinTimeout = _connectMinTimeout;+@synthesize connectInitialBackoff = _connectInitialBackoff;+@synthesize connectMaxBackoff = _connectMaxBackoff;+@synthesize additionalChannelArgs = _additionalChannelArgs;+@synthesize pemRootCert = _pemRootCert;+@synthesize pemPrivateKey = _pemPrivateKey;+@synthesize pemCertChain = _pemCertChain;+@synthesize transportType = _transportType;+@synthesize hostNameOverride = _hostNameOverride;+@synthesize logContext = _logContext;+@synthesize channelPoolDomain = _channelPoolDomain;+@synthesize channelId = _channelId;++- (instancetype)init {+  return [self initWithServerAuthority:kDefaultServerAuthority+                               timeout:kDefaultTimeout+                     oauth2AccessToken:kDefaultOauth2AccessToken+                     authTokenProvider:kDefaultAuthTokenProvider+                       initialMetadata:kDefaultInitialMetadata+                       userAgentPrefix:kDefaultUserAgentPrefix+                     responseSizeLimit:kDefaultResponseSizeLimit+                     compressAlgorithm:kDefaultCompressAlgorithm+                           enableRetry:kDefaultEnableRetry+                     keepaliveInterval:kDefaultKeepaliveInterval+                      keepaliveTimeout:kDefaultKeepaliveTimeout+                     connectMinTimeout:kDefaultConnectMinTimeout+                 connectInitialBackoff:kDefaultConnectInitialBackoff+                     connectMaxBackoff:kDefaultConnectMaxBackoff+                 additionalChannelArgs:kDefaultAdditionalChannelArgs+                           pemRootCert:kDefaultPemRootCert+                         pemPrivateKey:kDefaultPemPrivateKey+                          pemCertChain:kDefaultPemCertChain+                         transportType:kDefaultTransportType+                      hostNameOverride:kDefaultHostNameOverride+                            logContext:kDefaultLogContext+                     channelPoolDomain:kDefaultChannelPoolDomain+                             channelId:kDefaultChannelId];+}++- (instancetype)initWithServerAuthority:(NSString *)serverAuthority+                                timeout:(NSTimeInterval)timeout+                      oauth2AccessToken:(NSString *)oauth2AccessToken+                      authTokenProvider:(id<GRPCAuthorizationProtocol>)authTokenProvider+                        initialMetadata:(NSDictionary *)initialMetadata+                        userAgentPrefix:(NSString *)userAgentPrefix+                      responseSizeLimit:(NSUInteger)responseSizeLimit+                      compressAlgorithm:(GRPCCompressAlgorithm)compressAlgorithm+                            enableRetry:(BOOL)enableRetry+                      keepaliveInterval:(NSTimeInterval)keepaliveInterval+                       keepaliveTimeout:(NSTimeInterval)keepaliveTimeout+                      connectMinTimeout:(NSTimeInterval)connectMinTimeout+                  connectInitialBackoff:(NSTimeInterval)connectInitialBackoff+                      connectMaxBackoff:(NSTimeInterval)connectMaxBackoff+                  additionalChannelArgs:(NSDictionary *)additionalChannelArgs+                            pemRootCert:(NSString *)pemRootCert+                          pemPrivateKey:(NSString *)pemPrivateKey+                           pemCertChain:(NSString *)pemCertChain+                          transportType:(GRPCTransportType)transportType+                       hostNameOverride:(NSString *)hostNameOverride+                             logContext:(id)logContext+                      channelPoolDomain:(NSString *)channelPoolDomain+                              channelId:(NSUInteger)channelId {+  if ((self = [super init])) {+    _serverAuthority = serverAuthority;+    _timeout = timeout;+    _oauth2AccessToken = oauth2AccessToken;+    _authTokenProvider = authTokenProvider;+    _initialMetadata = initialMetadata;+    _userAgentPrefix = userAgentPrefix;+    _responseSizeLimit = responseSizeLimit;+    _compressAlgorithm = compressAlgorithm;+    _enableRetry = enableRetry;+    _keepaliveInterval = keepaliveInterval;+    _keepaliveTimeout = keepaliveTimeout;+    _connectMinTimeout = connectMinTimeout;+    _connectInitialBackoff = connectInitialBackoff;+    _connectMaxBackoff = connectMaxBackoff;+    _additionalChannelArgs = additionalChannelArgs;+    _pemRootCert = pemRootCert;+    _pemPrivateKey = pemPrivateKey;+    _pemCertChain = pemCertChain;+    _transportType = transportType;+    _hostNameOverride = hostNameOverride;+    _logContext = logContext;+    _channelPoolDomain = channelPoolDomain;+    _channelId = channelId;+  }+  return self;+}++- (nonnull id)copyWithZone:(NSZone *)zone {+  GRPCCallOptions *newOptions =+      [[GRPCCallOptions allocWithZone:zone] initWithServerAuthority:_serverAuthority+                                                            timeout:_timeout+                                                  oauth2AccessToken:_oauth2AccessToken+                                                  authTokenProvider:_authTokenProvider+                                                    initialMetadata:_initialMetadata+                                                    userAgentPrefix:_userAgentPrefix+                                                  responseSizeLimit:_responseSizeLimit+                                                  compressAlgorithm:_compressAlgorithm+                                                        enableRetry:_enableRetry+                                                  keepaliveInterval:_keepaliveInterval+                                                   keepaliveTimeout:_keepaliveTimeout+                                                  connectMinTimeout:_connectMinTimeout+                                              connectInitialBackoff:_connectInitialBackoff+                                                  connectMaxBackoff:_connectMaxBackoff+                                              additionalChannelArgs:[_additionalChannelArgs copy]+                                                        pemRootCert:_pemRootCert+                                                      pemPrivateKey:_pemPrivateKey+                                                       pemCertChain:_pemCertChain+                                                      transportType:_transportType+                                                   hostNameOverride:_hostNameOverride+                                                         logContext:_logContext+                                                  channelPoolDomain:_channelPoolDomain+                                                          channelId:_channelId];+  return newOptions;+}++- (nonnull id)mutableCopyWithZone:(NSZone *)zone {+  GRPCMutableCallOptions *newOptions = [[GRPCMutableCallOptions allocWithZone:zone]+      initWithServerAuthority:_serverAuthority+                      timeout:_timeout+            oauth2AccessToken:_oauth2AccessToken+            authTokenProvider:_authTokenProvider+              initialMetadata:_initialMetadata+              userAgentPrefix:_userAgentPrefix+            responseSizeLimit:_responseSizeLimit+            compressAlgorithm:_compressAlgorithm+                  enableRetry:_enableRetry+            keepaliveInterval:_keepaliveInterval+             keepaliveTimeout:_keepaliveTimeout+            connectMinTimeout:_connectMinTimeout+        connectInitialBackoff:_connectInitialBackoff+            connectMaxBackoff:_connectMaxBackoff+        additionalChannelArgs:[_additionalChannelArgs copy]+                  pemRootCert:_pemRootCert+                pemPrivateKey:_pemPrivateKey+                 pemCertChain:_pemCertChain+                transportType:_transportType+             hostNameOverride:_hostNameOverride+                   logContext:_logContext+            channelPoolDomain:_channelPoolDomain+                    channelId:_channelId];+  return newOptions;+}++@end++@implementation GRPCMutableCallOptions++@dynamic serverAuthority;+@dynamic timeout;+@dynamic oauth2AccessToken;+@dynamic authTokenProvider;+@dynamic initialMetadata;+@dynamic userAgentPrefix;+@dynamic responseSizeLimit;+@dynamic compressAlgorithm;+@dynamic enableRetry;+@dynamic keepaliveInterval;+@dynamic keepaliveTimeout;+@dynamic connectMinTimeout;+@dynamic connectInitialBackoff;+@dynamic connectMaxBackoff;+@dynamic additionalChannelArgs;+@dynamic pemRootCert;+@dynamic pemPrivateKey;+@dynamic pemCertChain;+@dynamic transportType;+@dynamic hostNameOverride;+@dynamic logContext;+@dynamic channelPoolDomain;+@dynamic channelId;++- (instancetype)init {+  return [self initWithServerAuthority:kDefaultServerAuthority+                               timeout:kDefaultTimeout+                     oauth2AccessToken:kDefaultOauth2AccessToken+                     authTokenProvider:kDefaultAuthTokenProvider+                       initialMetadata:kDefaultInitialMetadata+                       userAgentPrefix:kDefaultUserAgentPrefix+                     responseSizeLimit:kDefaultResponseSizeLimit+                     compressAlgorithm:kDefaultCompressAlgorithm+                           enableRetry:kDefaultEnableRetry+                     keepaliveInterval:kDefaultKeepaliveInterval+                      keepaliveTimeout:kDefaultKeepaliveTimeout+                     connectMinTimeout:kDefaultConnectMinTimeout+                 connectInitialBackoff:kDefaultConnectInitialBackoff+                     connectMaxBackoff:kDefaultConnectMaxBackoff+                 additionalChannelArgs:kDefaultAdditionalChannelArgs+                           pemRootCert:kDefaultPemRootCert+                         pemPrivateKey:kDefaultPemPrivateKey+                          pemCertChain:kDefaultPemCertChain+                         transportType:kDefaultTransportType+                      hostNameOverride:kDefaultHostNameOverride+                            logContext:kDefaultLogContext+                     channelPoolDomain:kDefaultChannelPoolDomain+                             channelId:kDefaultChannelId];+}++- (nonnull id)copyWithZone:(NSZone *)zone {+  GRPCCallOptions *newOptions =+      [[GRPCCallOptions allocWithZone:zone] initWithServerAuthority:_serverAuthority+                                                            timeout:_timeout+                                                  oauth2AccessToken:_oauth2AccessToken+                                                  authTokenProvider:_authTokenProvider+                                                    initialMetadata:_initialMetadata+                                                    userAgentPrefix:_userAgentPrefix+                                                  responseSizeLimit:_responseSizeLimit+                                                  compressAlgorithm:_compressAlgorithm+                                                        enableRetry:_enableRetry+                                                  keepaliveInterval:_keepaliveInterval+                                                   keepaliveTimeout:_keepaliveTimeout+                                                  connectMinTimeout:_connectMinTimeout+                                              connectInitialBackoff:_connectInitialBackoff+                                                  connectMaxBackoff:_connectMaxBackoff+                                              additionalChannelArgs:[_additionalChannelArgs copy]+                                                        pemRootCert:_pemRootCert+                                                      pemPrivateKey:_pemPrivateKey+                                                       pemCertChain:_pemCertChain+                                                      transportType:_transportType+                                                   hostNameOverride:_hostNameOverride+                                                         logContext:_logContext+                                                  channelPoolDomain:_channelPoolDomain+                                                          channelId:_channelId];+  return newOptions;+}++- (nonnull id)mutableCopyWithZone:(NSZone *)zone {+  GRPCMutableCallOptions *newOptions = [[GRPCMutableCallOptions allocWithZone:zone]+      initWithServerAuthority:_serverAuthority+                      timeout:_timeout+            oauth2AccessToken:_oauth2AccessToken+            authTokenProvider:_authTokenProvider+              initialMetadata:_initialMetadata+              userAgentPrefix:_userAgentPrefix+            responseSizeLimit:_responseSizeLimit+            compressAlgorithm:_compressAlgorithm+                  enableRetry:_enableRetry+            keepaliveInterval:_keepaliveInterval+             keepaliveTimeout:_keepaliveTimeout+            connectMinTimeout:_connectMinTimeout+        connectInitialBackoff:_connectInitialBackoff+            connectMaxBackoff:_connectMaxBackoff+        additionalChannelArgs:[_additionalChannelArgs copy]+                  pemRootCert:_pemRootCert+                pemPrivateKey:_pemPrivateKey+                 pemCertChain:_pemCertChain+                transportType:_transportType+             hostNameOverride:_hostNameOverride+                   logContext:_logContext+            channelPoolDomain:_channelPoolDomain+                    channelId:_channelId];+  return newOptions;+}++- (void)setServerAuthority:(NSString *)serverAuthority {+  _serverAuthority = serverAuthority;+}++- (void)setTimeout:(NSTimeInterval)timeout {+  _timeout = timeout;+}++- (void)setOauth2AccessToken:(NSString *)oauth2AccessToken {+  _oauth2AccessToken = oauth2AccessToken;+}++- (void)setAuthTokenProvider:(id<GRPCAuthorizationProtocol>)authTokenProvider {+  _authTokenProvider = authTokenProvider;+}++- (void)setInitialMetadata:(NSDictionary *)initialMetadata {+  _initialMetadata = initialMetadata;",consider [[NSDictionary alloc] initWithDictionary:initialMetadata copyItems:YES];,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16801,224117754,2018-10-10T15:06:34Z,src/core/lib/transport/metadata.h,"@@ -109,7 +109,11 @@ struct grpc_mdelem {                               (uintptr_t)GRPC_MDELEM_STORAGE_INTERNED_BIT))  /* Unrefs the slices. */-grpc_mdelem grpc_mdelem_from_slices(grpc_slice key, grpc_slice value);+grpc_mdelem grpc_mdelem_from_slices(const grpc_slice& key,+                                    const grpc_slice& value);+/* Does not unref the slices. */+grpc_mdelem grpc_mdelem_from_slices_no_unref(const grpc_slice& key,","> Thank you @markdroth but `grpc_slice` is ref-counted intrusively (internally). I'm not completely sure if that's something we can do with `RefCountedPtr<>`. Moving it to C++ API is a great long term plan, but is perhaps would take a long time.We have an `InternallyRefCounted` base class for internally ref-counted objects.  I haven't looked at the details of the `grpc_slice` implementation, but I'd be surprised if we couldn't find a way to make this work with our existing C++ abstractions.But, I do understand that this would be a more invasive change.  If you don't want to do it now, that's fine.> If you have strong preference for having one version of this function, an easier option is to remove the unref from `grpc_mdelem_from_slice`, and calling `unref` explicitly in the call site. Would that be something you prefer over this patch?> > FWIW, we already ahve `grpc_slice_sub_no_ref` and `grpc_slice_sub`.My real concern here is that I want the semantics of this API to be clear and easy to understand.  I haven't looked at the code in detail, but the fact that we sometimes want the mdelem to take a ref to the slices and sometimes don't seems like a code smell.  I suspect that there's a deeper design problem here, and adding a second entry point may just be papering over the problem instead of fixing it.I suggest looking at all of the other callers of `grpc_mdelem_from_slices()` to see what they're doing.  If we can come up with a unified approach that works for all callers, that seems superior to this two-entry-point approach.",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/16190,224265210,2018-10-10T22:42:47Z,src/objective-c/GRPCClient/GRPCCall+ChannelArg.h,"@@ -19,52 +19,20 @@  #include <AvailabilityMacros.h> -typedef NS_ENUM(NSInteger, GRPCCompressAlgorithm) {-  GRPCCompressNone,-  GRPCCompressDeflate,-  GRPCCompressGzip,-};--/**- * Methods to configure GRPC channel options.- */+// Deprecated interface. Please use GRPCCallOptions instead.",Was think of `attribute((deprecated))` but warning noise is the main concern.,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16807,224267557,2018-10-10T22:54:56Z,test/cpp/qps/client_callback.cc,"@@ -148,36 +147,36 @@ class CallbackUnaryClient final : public CallbackClient {   protected:   bool ThreadFuncImpl(Thread* t, size_t thread_idx) override {-    for (size_t i = 0; i < ctxs_[thread_idx].size(); i++) {-      ScheduleRpc(t, thread_idx, i);+    for (int vector_idx = thread_idx; vector_idx < total_outstanding_rpcs_;+         vector_idx += num_threads_) {+      ScheduleRpc(t, thread_idx, vector_idx);     }     return true;   }    void InitThreadFuncImpl(size_t thread_idx) override { return; }   private:-  void ScheduleRpc(Thread* t, size_t thread_idx, size_t queue_idx) override {+  void ScheduleRpc(Thread* t, size_t thread_idx, size_t vector_idx) override {     if (!closed_loop_) {       gpr_timespec next_issue_time = NextIssueTime(thread_idx);","Actually, I know the right thing to do in this case. The `NextIssueTime` thing should be handled like in the sync case. The vector of NextIssueTime should be as big as the ctx_ vector and then always indexed based on the ctx_vector_idx . The initialization of the NextIssueTime vector (wherever it is, I've forgotten) should be like in the sync client, based on the total number of outstanding RPCs (which is also the thread count in the sync client, but not here).",
42048362,mhaidrygoog,https://api.github.com/repos/grpc/grpc/pulls/16807,224270744,2018-10-10T23:13:07Z,test/cpp/qps/client_callback.cc,"@@ -148,36 +147,36 @@ class CallbackUnaryClient final : public CallbackClient {   protected:   bool ThreadFuncImpl(Thread* t, size_t thread_idx) override {-    for (size_t i = 0; i < ctxs_[thread_idx].size(); i++) {-      ScheduleRpc(t, thread_idx, i);+    for (int vector_idx = thread_idx; vector_idx < total_outstanding_rpcs_;+         vector_idx += num_threads_) {+      ScheduleRpc(t, thread_idx, vector_idx);     }     return true;   }    void InitThreadFuncImpl(size_t thread_idx) override { return; }   private:-  void ScheduleRpc(Thread* t, size_t thread_idx, size_t queue_idx) override {+  void ScheduleRpc(Thread* t, size_t thread_idx, size_t vector_idx) override {     if (!closed_loop_) {       gpr_timespec next_issue_time = NextIssueTime(thread_idx);","Yeah I need to clarify my understanding of next issue time. I believe in the case of Async where a list of next issue time is maintained, the next issue time is still generated per thread_idx. I believe this is because the Async thread issues a new RPC after the previous RPC wakes it up from waiting on the cq. This is not the case for Callback where a new RPC may be issued in a seperate Event manager thread.I agree with Vijay though. I'll figure this out as I add more scenarios to the benchmark suite in another PR.",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/16190,224272052,2018-10-10T23:20:17Z,src/objective-c/GRPCClient/GRPCCall.h,"@@ -139,43 +143,124 @@ typedef NS_ENUM(NSUInteger, GRPCErrorCode) {   GRPCErrorCodeDataLoss = 15, }; -/**- * Safety remark of a gRPC method as defined in RFC 2616 Section 9.1- */-typedef NS_ENUM(NSUInteger, GRPCCallSafety) {-  /** Signal that there is no guarantees on how the call affects the server state. */-  GRPCCallSafetyDefault = 0,-  /** Signal that the call is idempotent. gRPC is free to use PUT verb. */-  GRPCCallSafetyIdempotentRequest = 1,-  /** Signal that the call is cacheable and will not affect server state. gRPC is free to use GET-     verb. */-  GRPCCallSafetyCacheableRequest = 2,-};- /**  * Keys used in |NSError|'s |userInfo| dictionary to store the response headers and trailers sent by  * the server.  */ extern id const kGRPCHeadersKey; extern id const kGRPCTrailersKey; +/** An object can implement this protocol to receive responses from server from a call. */+@protocol GRPCResponseHandler+@optional+/** Issued when initial metadata is received from the server. */+- (void)receivedInitialMetadata:(NSDictionary *)initialMetadata;+/**+ * Issued when a message is received from the server. The message may be raw data from the server+ * (when using \a GRPCCall2 directly) or deserialized proto object (when using \a ProtoRPC).+ */+- (void)receivedMessage:(id)message;+/**+ * Issued when a call finished. If the call finished successfully, \a error is nil and \a+ * trainingMetadata consists any trailing metadata received from the server. Otherwise, \a error+ * is non-nil and contains the corresponding error information, including gRPC error codes and+ * error descriptions.+ */+- (void)closedWithTrailingMetadata:(NSDictionary *)trailingMetadata error:(NSError *)error;++/**+ * All the responses must be issued to a user-provided dispatch queue. This property specifies the+ * dispatch queue to be used for issuing the notifications.+ */+@property(atomic, readonly) dispatch_queue_t dispatchQueue;++@end++/**+ * Call related parameters. These parameters are automatically specified by Protobuf. If directly+ * using the \a GRPCCall2 class, users should specify these parameters manually.+ */+@interface GRPCRequestOptions : NSObject<NSCopying>++- (instancetype)init NS_UNAVAILABLE;++/** Initialize with all properties. */+- (instancetype)initWithHost:(NSString *)host path:(NSString *)path safety:(GRPCCallSafety)safety;","I tend to leave it 'host'. `GRPCHost` is not exposed to user and we [have been using](https://github.com/grpc/grpc/blob/73c99f890a42479bc82e2c0ab132a97cbcf8434a/src/objective-c/GRPCClient/GRPCCall.h#L237) ""host"" to represent the server host.",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/16190,224278772,2018-10-11T00:04:11Z,src/objective-c/GRPCClient/GRPCCall.h,"@@ -139,43 +143,124 @@ typedef NS_ENUM(NSUInteger, GRPCErrorCode) {   GRPCErrorCodeDataLoss = 15, }; -/**- * Safety remark of a gRPC method as defined in RFC 2616 Section 9.1- */-typedef NS_ENUM(NSUInteger, GRPCCallSafety) {-  /** Signal that there is no guarantees on how the call affects the server state. */-  GRPCCallSafetyDefault = 0,-  /** Signal that the call is idempotent. gRPC is free to use PUT verb. */-  GRPCCallSafetyIdempotentRequest = 1,-  /** Signal that the call is cacheable and will not affect server state. gRPC is free to use GET-     verb. */-  GRPCCallSafetyCacheableRequest = 2,-};- /**  * Keys used in |NSError|'s |userInfo| dictionary to store the response headers and trailers sent by  * the server.  */ extern id const kGRPCHeadersKey; extern id const kGRPCTrailersKey; +/** An object can implement this protocol to receive responses from server from a call. */+@protocol GRPCResponseHandler+@optional+/** Issued when initial metadata is received from the server. */+- (void)receivedInitialMetadata:(NSDictionary *)initialMetadata;+/**+ * Issued when a message is received from the server. The message may be raw data from the server+ * (when using \a GRPCCall2 directly) or deserialized proto object (when using \a ProtoRPC).+ */+- (void)receivedMessage:(id)message;+/**+ * Issued when a call finished. If the call finished successfully, \a error is nil and \a+ * trainingMetadata consists any trailing metadata received from the server. Otherwise, \a error+ * is non-nil and contains the corresponding error information, including gRPC error codes and+ * error descriptions.+ */+- (void)closedWithTrailingMetadata:(NSDictionary *)trailingMetadata error:(NSError *)error;++/**+ * All the responses must be issued to a user-provided dispatch queue. This property specifies the+ * dispatch queue to be used for issuing the notifications.+ */+@property(atomic, readonly) dispatch_queue_t dispatchQueue;++@end++/**+ * Call related parameters. These parameters are automatically specified by Protobuf. If directly+ * using the \a GRPCCall2 class, users should specify these parameters manually.+ */+@interface GRPCRequestOptions : NSObject<NSCopying>++- (instancetype)init NS_UNAVAILABLE;++/** Initialize with all properties. */+- (instancetype)initWithHost:(NSString *)host path:(NSString *)path safety:(GRPCCallSafety)safety;++/** The host serving the RPC service. */+@property(copy, readonly) NSString *host;+/** The path to the RPC call. */+@property(copy, readonly) NSString *path;+/**+ * Specify whether the call is idempotent or cachable. gRPC may select different HTTP verbs for the+ * call based on this information.+ */+@property(readonly) GRPCCallSafety safety;++@end+ #pragma mark GRPCCall -/** Represents a single gRPC remote call. */-@interface GRPCCall : GRXWriter+/**+ * A \a GRPCCall2 object represents an RPC call.+ */+@interface GRPCCall2 : NSObject++- (instancetype)init NS_UNAVAILABLE;  /**- * The authority for the RPC. If nil, the default authority will be used. This property must be nil- * when Cronet transport is enabled.+ * Designated initializer for a call.+ * \param requestOptions Protobuf generated parameters for the call.+ * \param handler The object to which responses should be issed.+ * \param callOptions Options for the call.  */-@property(atomic, copy, readwrite) NSString *serverName;+- (instancetype)initWithRequestOptions:(GRPCRequestOptions *)requestOptions+                               handler:(id<GRPCResponseHandler>)handler+                           callOptions:(GRPCCallOptions *)callOptions NS_DESIGNATED_INITIALIZER;+/**+ * Convevience initializer for a call that uses default call options.+ */+- (instancetype)initWithRequestOptions:(GRPCRequestOptions *)requestOptions+                               handler:(id<GRPCResponseHandler>)handler;  /**- * The timeout for the RPC call in seconds. If set to 0, the call will not timeout. If set to- * positive, the gRPC call returns with status GRPCErrorCodeDeadlineExceeded if it is not completed- * within \a timeout seconds. A negative value is not allowed.+ * Starts the call. Can only be called once.  */-@property NSTimeInterval timeout;+- (void)start;++/**+ * Cancel the request of this call at best effort; notifies the server that the RPC should be+ * cancelled, and issue callback to the user with an error code CANCELED if the call is not+ * finished.+ */","I think we can probably phrase like this:Cancel the request of this call at best effort. It attempts to notify the server that the RPC should be cancelled, and issue closedWithTrailingMetadata:error: callback with error code CANCELED if no other error code has already been issued.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16827,224491419,2018-10-11T15:19:35Z,src/core/ext/filters/client_channel/subchannel.cc,"@@ -745,12 +752,74 @@ void grpc_subchannel_call_unref(   GRPC_CALL_STACK_UNREF(SUBCHANNEL_CALL_TO_CALL_STACK(c), REF_REASON); } +// Sets *status and *server_pushback_md based on md_batch and error.",This comment is out of date -- there's no `server_pushback_md` parameter here.,OK
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/16827,224537008,2018-10-11T17:32:00Z,src/core/ext/filters/client_channel/subchannel.h,"@@ -85,9 +85,11 @@ class ConnectedSubchannel : public RefCountedWithTracing<ConnectedSubchannel> {     size_t parent_data_size;   }; -  explicit ConnectedSubchannel(grpc_channel_stack* channel_stack,-                               channelz::SubchannelNode* channelz_subchannel,-                               intptr_t socket_uuid);+  explicit ConnectedSubchannel(+      grpc_channel_stack* channel_stack,+      grpc_core::RefCountedPtr<grpc_core::channelz::SubchannelNode>","Actually, reverting this causes ASAN failures to show up again:```===================================================================635==ERROR: AddressSanitizer: heap-use-after-free on address 0x60e0000075b0 at pc 0x00000063cad2 bp 0x7ffddc050ac0 sp 0x7ffddc050ab8READ of size 8 at 0x60e0000075b0 thread T0    #0 0x63cad1 in grpc_core::channelz::CallCountingHelper::RecordCallFailed() /usr/local/google/home/ncteisen/Desktop/grpc/src/core/lib/channel/channelz.cc:81:3    #1 0x62098c in grpc_core::channelz::SubchannelNode::RecordCallFailed() /usr/local/google/home/ncteisen/Desktop/grpc/./src/core/ext/filters/client_channel/client_channel_channelz.h:83:43    #2 0x61f0fa in recv_trailing_metadata_ready(void*, grpc_error*) /usr/local/google/home/ncteisen/Desktop/grpc/src/core/ext/filters/client_channel/subchannel.cc:782:26    #3 0x5347aa in exec_ctx_run(grpc_closure*, grpc_error*) /usr/local/google/home/ncteisen/Desktop/grpc/src/core/lib/iomgr/exec_ctx.cc:40:3    #4 0x542cc1 in grpc_closure_run(char const*, int, grpc_closure*, grpc_error*) /usr/local/google/home/ncteisen/Desktop/grpc/./src/core/lib/iomgr/closure.h:258:5    #5 0x84dbea in recv_trailing_metadata_ready(void*, grpc_error*) /usr/local/google/home/ncteisen/Desktop/grpc/src/core/ext/filters/message_size/message_size_filter.cc:185:3    #6 0x5347aa in exec_ctx_run(grpc_closure*, grpc_error*) /usr/local/google/home/ncteisen/Desktop/grpc/src/core/lib/iomgr/exec_ctx.cc:40:3    #7 0x542cc1 in grpc_closure_run(char const*, int, grpc_closure*, grpc_error*) /usr/local/google/home/ncteisen/Desktop/grpc/./src/core/lib/iomgr/closure.h:258:5    #8 0x8a30e4 in recv_trailing_metadata_ready(void*, grpc_error*) /usr/local/google/home/ncteisen/Desktop/grpc/src/core/ext/filters/http/client/http_client_filter.cc:191:3    #9 0x5347aa in exec_ctx_run(grpc_closure*, grpc_error*) /usr/local/google/home/ncteisen/Desktop/grpc/src/core/lib/iomgr/exec_ctx.cc:40:3    #10 0x534314 in grpc_core::ExecCtx::Flush() /usr/local/google/home/ncteisen/Desktop/grpc/src/core/lib/iomgr/exec_ctx.cc:134:9    #11 0x51e89a in grpc_core::ExecCtx::~ExecCtx() /usr/local/google/home/ncteisen/Desktop/grpc/./src/core/lib/iomgr/exec_ctx.h:108:5    #12 0x586b55 in grpc_call_cancel /usr/local/google/home/ncteisen/Desktop/grpc/src/core/lib/surface/call.cc:588:1    #13 0x51576f in main /usr/local/google/home/ncteisen/Desktop/grpc/test/core/end2end/goaway_server_test.cc:332:3    #14 0x7feb39ea32b0 in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x202b0)    #15 0x41ff99 in _start (/usr/local/google/home/ncteisen/Desktop/grpc/bins/asan/goaway_server_test+0x41ff99)0x60e0000075b0 is located 48 bytes inside of 160-byte region [0x60e000007580,0x60e000007620)freed by thread T3 (grpc_global_tim) here:    #0 0x4d5428 in __interceptor_free.localalias.0 (/usr/local/google/home/ncteisen/Desktop/grpc/bins/asan/goaway_server_test+0x4d5428)    #1 0x6baf9e in gpr_free /usr/local/google/home/ncteisen/Desktop/grpc/src/core/lib/gpr/alloc.cc:77:3    #2 0x59f766 in void grpc_core::Delete<grpc_core::channelz::BaseNode>(grpc_core::channelz::BaseNode*) /usr/local/google/home/ncteisen/Desktop/grpc/./src/core/lib/gprpp/memory.h:63:5    #3 0x59f66d in grpc_core::RefCounted<grpc_core::channelz::BaseNode>::Unref() /usr/local/google/home/ncteisen/Desktop/grpc/./src/core/lib/gprpp/ref_counted.h:57:7    #4 0x6204a1 in grpc_core::RefCountedPtr<grpc_core::channelz::SubchannelNode>::reset() /usr/local/google/home/ncteisen/Desktop/grpc/./src/core/lib/gprpp/ref_counted_ptr.h:112:36    #5 0x61707e in subchannel_destroy(void*, grpc_error*) /usr/local/google/home/ncteisen/Desktop/grpc/src/core/ext/filters/client_channel/subchannel.cc:198:28    #6 0x51eece in closure_impl::closure_wrapper(void*, grpc_error*) /usr/local/google/home/ncteisen/Desktop/grpc/./src/core/lib/iomgr/closure.h:150:3    #7 0x5347aa in exec_ctx_run(grpc_closure*, grpc_error*) /usr/local/google/home/ncteisen/Desktop/grpc/src/core/lib/iomgr/exec_ctx.cc:40:3    #8 0x534314 in grpc_core::ExecCtx::Flush() /usr/local/google/home/ncteisen/Desktop/grpc/src/core/lib/iomgr/exec_ctx.cc:134:9    #9 0x56a280 in run_some_timers() /usr/local/google/home/ncteisen/Desktop/grpc/src/core/lib/iomgr/timer_manager.cc:131:30    #10 0x569d84 in timer_main_loop() /usr/local/google/home/ncteisen/Desktop/grpc/src/core/lib/iomgr/timer_manager.cc:232:9    #11 0x569b37 in timer_thread(void*) /usr/local/google/home/ncteisen/Desktop/grpc/src/core/lib/iomgr/timer_manager.cc:279:3    #12 0x6d1331 in grpc_core::(anonymous namespace)::ThreadInternalsPosix::ThreadInternalsPosix(char const*, void (*)(void*), void*, bool*)::{lambda(void*)#1}::operator()(void*) const /usr/local/google/home/ncteisen/Desktop/grpc/src/core/lib/gprpp/thd_posix.cc:100:27    #13 0x6d0d65 in grpc_core::(anonymous namespace)::ThreadInternalsPosix::ThreadInternalsPosix(char const*, void (*)(void*), void*, bool*)::{lambda(void*)#1}::__invoke(void*) /usr/local/google/home/ncteisen/Desktop/grpc/src/core/lib/gprpp/thd_posix.cc:74:25    #14 0x4e3092 in __asan::AsanThread::ThreadStart(unsigned long, __sanitizer::atomic_uintptr_t*) (/usr/local/google/home/ncteisen/Desktop/grpc/bins/asan/goaway_server_test+0x4e3092)```",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/16190,224561145,2018-10-11T18:43:21Z,src/objective-c/GRPCClient/GRPCCall.m,"@@ -52,6 +55,165 @@ @interface GRPCCall ()<GRXWriteable> @property(atomic, strong) NSDictionary *responseHeaders; @property(atomic, strong) NSDictionary *responseTrailers; @property(atomic) BOOL isWaitingForToken;++- (instancetype)initWithHost:(NSString *)host+                        path:(NSString *)path+                  callSafety:(GRPCCallSafety)safety+              requestsWriter:(GRXWriter *)requestsWriter+                 callOptions:(GRPCCallOptions *)callOptions;++@end++@implementation GRPCRequestOptions++- (instancetype)initWithHost:(NSString *)host path:(NSString *)path safety:(GRPCCallSafety)safety {+  if ((self = [super init])) {+    _host = host;+    _path = path;+    _safety = safety;+  }+  return self;+}++- (id)copyWithZone:(NSZone *)zone {+  GRPCRequestOptions *request =+      [[GRPCRequestOptions alloc] initWithHost:[_host copy] path:[_path copy] safety:_safety];++  return request;+}++@end++@implementation GRPCCall2 {+  GRPCCallOptions *_callOptions;+  id<GRPCResponseHandler> _handler;++  GRPCCall *_call;+  BOOL _initialMetadataPublished;+  GRXBufferedPipe *_pipe;+  dispatch_queue_t _dispatchQueue;+}++- (instancetype)initWithRequestOptions:(GRPCRequestOptions *)requestOptions+                               handler:(id<GRPCResponseHandler>)handler+                           callOptions:(GRPCCallOptions *)callOptions {+  if (!requestOptions || !requestOptions.host || !requestOptions.path) {+    [NSException raise:NSInvalidArgumentException format:@""Neither host nor path can be nil.""];+  }++  if ((self = [super init])) {+    _requestOptions = [requestOptions copy];+    _callOptions = [callOptions copy];+    _handler = handler;+    _initialMetadataPublished = NO;+    _pipe = [GRXBufferedPipe pipe];+    _dispatchQueue = dispatch_queue_create(NULL, DISPATCH_QUEUE_SERIAL);+  }++  return self;+}++- (instancetype)initWithRequestOptions:(GRPCRequestOptions *)requestOptions+                               handler:(id<GRPCResponseHandler>)handler {+  return [self initWithRequestOptions:requestOptions handler:handler callOptions:nil];+}++- (void)start {+  dispatch_async(_dispatchQueue, ^{+    if (!self->_callOptions) {+      self->_callOptions = [[GRPCCallOptions alloc] init];+    }++    self->_call = [[GRPCCall alloc] initWithHost:self->_requestOptions.host+                                            path:self->_requestOptions.path+                                      callSafety:self->_requestOptions.safety+                                  requestsWriter:self->_pipe+                                     callOptions:self->_callOptions];+    if (self->_callOptions.initialMetadata) {+      [self->_call.requestHeaders addEntriesFromDictionary:self->_callOptions.initialMetadata];+    }+    id<GRXWriteable> responseWriteable = [[GRXWriteable alloc] initWithValueHandler:^(id value) {+      dispatch_async(self->_dispatchQueue, ^{+        if (self->_handler) {+          id<GRPCResponseHandler> handler = self->_handler;+          NSDictionary *headers = nil;+          if (!self->_initialMetadataPublished) {+            headers = self->_call.responseHeaders;+            self->_initialMetadataPublished = YES;+          }+          if (headers) {+            dispatch_async(handler.dispatchQueue, ^{+              [handler receivedInitialMetadata:headers];+            });+          }+          if (value) {+            dispatch_async(handler.dispatchQueue, ^{+              [handler receivedMessage:value];+            });+          }+        }+      });+    }+        completionHandler:^(NSError *errorOrNil) {+          dispatch_async(self->_dispatchQueue, ^{+            if (self->_handler) {+              id<GRPCResponseHandler> handler = self->_handler;+              NSDictionary *headers = nil;+              if (!self->_initialMetadataPublished) {+                headers = self->_call.responseHeaders;+                self->_initialMetadataPublished = YES;+              }+              if (headers) {+                dispatch_async(handler.dispatchQueue, ^{+                  [handler receivedInitialMetadata:headers];+                });+              }+              dispatch_async(handler.dispatchQueue, ^{+                [handler closedWithTrailingMetadata:self->_call.responseTrailers error:errorOrNil];+              });+            }+          });+        }];+    [self->_call startWithWriteable:responseWriteable];+  });+}++- (void)cancel {+  dispatch_async(_dispatchQueue, ^{+    if (self->_call) {+      [self->_call cancel];+      self->_call = nil;+    }+    if (self->_handler) {+      id<GRPCResponseHandler> handler = self->_handler;+      dispatch_async(handler.dispatchQueue, ^{+        [handler closedWithTrailingMetadata:nil+                                      error:[NSError errorWithDomain:kGRPCErrorDomain+                                                                code:GRPCErrorCodeCancelled+                                                            userInfo:@{+                                                              NSLocalizedDescriptionKey :+                                                                  @""Canceled by app""+                                                            }]];+      });+      self->_handler = nil;",The purpose of clearing handler here is to prevent more responses being issued to the handler (since no response should be issued after `closedWithTrailingMetadata`). I'll comment on the code.,OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/16190,224567374,2018-10-11T19:02:33Z,src/objective-c/GRPCClient/GRPCCall.m,"@@ -317,11 +498,36 @@ - (void)startNextRead {  #pragma mark Send headers -- (void)sendHeaders:(NSDictionary *)headers {+- (void)sendHeaders {+  // TODO (mxyan): Remove after deprecated methods are removed+  uint32_t callSafetyFlags;+  switch (_callSafety) {+    case GRPCCallSafetyDefault:+      callSafetyFlags = 0;+      break;+    case GRPCCallSafetyIdempotentRequest:+      callSafetyFlags = GRPC_INITIAL_METADATA_IDEMPOTENT_REQUEST;+      break;+    case GRPCCallSafetyCacheableRequest:+      callSafetyFlags = GRPC_INITIAL_METADATA_CACHEABLE_REQUEST;+      break;+    default:",Didn't really understand this comment. I think the `default` case should not be happening so an exception seems to be reasonable here?,OK
38445398,aharperg,https://api.github.com/repos/grpc/grpc/pulls/16190,224605369,2018-10-11T21:10:06Z,src/objective-c/GRPCClient/GRPCCall.m,"@@ -52,6 +55,165 @@ @interface GRPCCall ()<GRXWriteable> @property(atomic, strong) NSDictionary *responseHeaders; @property(atomic, strong) NSDictionary *responseTrailers; @property(atomic) BOOL isWaitingForToken;++- (instancetype)initWithHost:(NSString *)host+                        path:(NSString *)path+                  callSafety:(GRPCCallSafety)safety+              requestsWriter:(GRXWriter *)requestsWriter+                 callOptions:(GRPCCallOptions *)callOptions;++@end++@implementation GRPCRequestOptions++- (instancetype)initWithHost:(NSString *)host path:(NSString *)path safety:(GRPCCallSafety)safety {+  if ((self = [super init])) {+    _host = host;+    _path = path;+    _safety = safety;+  }+  return self;+}++- (id)copyWithZone:(NSZone *)zone {+  GRPCRequestOptions *request =+      [[GRPCRequestOptions alloc] initWithHost:[_host copy] path:[_path copy] safety:_safety];++  return request;+}++@end++@implementation GRPCCall2 {+  GRPCCallOptions *_callOptions;+  id<GRPCResponseHandler> _handler;++  GRPCCall *_call;+  BOOL _initialMetadataPublished;+  GRXBufferedPipe *_pipe;+  dispatch_queue_t _dispatchQueue;+}++- (instancetype)initWithRequestOptions:(GRPCRequestOptions *)requestOptions+                               handler:(id<GRPCResponseHandler>)handler+                           callOptions:(GRPCCallOptions *)callOptions {+  if (!requestOptions || !requestOptions.host || !requestOptions.path) {+    [NSException raise:NSInvalidArgumentException format:@""Neither host nor path can be nil.""];+  }++  if ((self = [super init])) {+    _requestOptions = [requestOptions copy];+    _callOptions = [callOptions copy];+    _handler = handler;+    _initialMetadataPublished = NO;+    _pipe = [GRXBufferedPipe pipe];+    _dispatchQueue = dispatch_queue_create(NULL, DISPATCH_QUEUE_SERIAL);","dispatch_queue_attr_make_with_qos_class() has appropriate availability guards, so you should be able to wrap it with preprocessor guards and work fine on 7.Alternately you could use dispatch_set_target_queue() and use responseHandler.dispatchQueue as the target queue. This allows your serial to directly inherit QoS from the target, but moves the work in this file to the caller's response queue as well, so that may not be the best solution. Not clear to me if anything else on this queue (notably manipulation of _pipe) is too heavy to share the caller's queue.",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/16190,224616035,2018-10-11T21:53:18Z,src/objective-c/GRPCClient/GRPCCallOptions.h,"@@ -0,0 +1,317 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#import <Foundation/Foundation.h>++/**+ * Safety remark of a gRPC method as defined in RFC 2616 Section 9.1+ */+typedef NS_ENUM(NSUInteger, GRPCCallSafety) {+  /** Signal that there is no guarantees on how the call affects the server state. */+  GRPCCallSafetyDefault = 0,+  /** Signal that the call is idempotent. gRPC is free to use PUT verb. */+  GRPCCallSafetyIdempotentRequest = 1,+  /** Signal that the call is cacheable and will not affect server state. gRPC is free to use GET+   verb. */+  GRPCCallSafetyCacheableRequest = 2,+};++// Compression algorithm to be used by a gRPC call+typedef NS_ENUM(NSInteger, GRPCCompressAlgorithm) {+  GRPCCompressNone = 0,+  GRPCCompressDeflate,+  GRPCCompressGzip,+  GRPCStreamCompressGzip,+};++// The transport to be used by a gRPC call+typedef NS_ENUM(NSInteger, GRPCTransportType) {+  // gRPC internal HTTP/2 stack with BoringSSL+  GRPCTransportTypeDefault = 0,+  // Cronet stack+  GRPCTransportTypeCronet,+  // Insecure channel. FOR TEST ONLY!+  GRPCTransportTypeInsecure,+};++@protocol GRPCAuthorizationProtocol+- (void)getTokenWithHandler:(void (^)(NSString *token))hander;+@end++@interface GRPCCallOptions : NSObject<NSCopying, NSMutableCopying>++// Call parameters+/**+ * The authority for the RPC. If nil, the default authority will be used.+ *+ * Note: This property must be nil when Cronet transport is enabled.+ * Note: This property cannot be used to validate a self-signed server certificate. It control the+ *       :authority header field of the call and performs an extra check that server's certificate+ *       matches the :authority header.+ */+@property(readonly) NSString *serverAuthority;++/**+ * The timeout for the RPC call in seconds. If set to 0, the call will not timeout. If set to+ * positive, the gRPC call returns with status GRPCErrorCodeDeadlineExceeded if it is not completed+ * within \a timeout seconds. A negative value is not allowed.+ */+@property(readonly) NSTimeInterval timeout;++// OAuth2 parameters. Users of gRPC may specify one of the following two parameters.++/**+ * The OAuth2 access token string. The string is prefixed with ""Bearer "" then used as value of the+ * request's ""authorization"" header field. This parameter should not be used simultaneously with+ * \a authTokenProvider.+ */+@property(copy, readonly) NSString *oauth2AccessToken;++/**+ * The interface to get the OAuth2 access token string. gRPC will attempt to acquire token when+ * initiating the call. This parameter should not be used simultaneously with \a oauth2AccessToken.+ */+@property(readonly) id<GRPCAuthorizationProtocol> authTokenProvider;++/**+ * Initial metadata key-value pairs that should be included in the request.+ */+@property(copy, readwrite) NSDictionary *initialMetadata;++// Channel parameters; take into account of channel signature.++/**+ * Custom string that is prefixed to a request's user-agent header field before gRPC's internal+ * user-agent string.+ */+@property(copy, readonly) NSString *userAgentPrefix;++/**+ * The size limit for the response received from server. If it is exceeded, an error with status+ * code GRPCErrorCodeResourceExhausted is returned.+ */+@property(readonly) NSUInteger responseSizeLimit;++/**+ * The compression algorithm to be used by the gRPC call. For more details refer to+ * https://github.com/grpc/grpc/blob/master/doc/compression.md+ */+@property(readonly) GRPCCompressAlgorithm compressAlgorithm;++/**+ * Enable/Disable gRPC call's retry feature. The default is enabled. For details of this feature+ * refer to+ * https://github.com/grpc/proposal/blob/master/A6-client-retries.md+ */+@property(readonly) BOOL enableRetry;++/**+ * HTTP/2 keep-alive feature. The parameter \a keepaliveInterval specifies the interval between two+ * PING frames. The parameter \a keepaliveTimeout specifies the length of the period for which the+ * call should wait for PING ACK. If PING ACK is not received after this period, the call fails.+ */+@property(readonly) NSTimeInterval keepaliveInterval;+@property(readonly) NSTimeInterval keepaliveTimeout;++// Parameters for connection backoff. For details of gRPC's backoff behavior, refer to+// https://github.com/grpc/grpc/blob/master/doc/connection-backoff.md+@property(readonly) NSTimeInterval connectMinTimeout;+@property(readonly) NSTimeInterval connectInitialBackoff;+@property(readonly) NSTimeInterval connectMaxBackoff;++/**+ * Specify channel args to be used for this call. For a list of channel args available, see+ * grpc/grpc_types.h+ */+@property(copy, readonly) NSDictionary *additionalChannelArgs;++// Parameters for SSL authentication.++/**+ * PEM format root certifications that is trusted. If set to nil, gRPC uses a list of default+ * root certificates.+ */+@property(copy, readonly) NSString *pemRootCert;++/**+ * PEM format private key for client authentication, if required by the server.+ */+@property(copy, readonly) NSString *pemPrivateKey;++/**+ * PEM format certificate chain for client authentication, if required by the server.+ */+@property(copy, readonly) NSString *pemCertChain;++/**+ * Select the transport type to be used for this call.+ */+@property(readonly) GRPCTransportType transportType;++/**+ * Override the hostname during the TLS hostname validation process.+ */+@property(copy, readonly) NSString *hostNameOverride;++/**+ * Parameter used for internal logging.+ */+@property(readonly) id logContext;++/**+ * A string that specify the domain where channel is being cached. Channels with different domains+ * will not get cached to the same connection.+ */+@property(copy, readonly) NSString *channelPoolDomain;++/**+ * Channel id allows a call to force creating a new channel (connection) rather than using a cached+ * channel. Calls using distinct channelId will not get cached to the same connection.","I'm not quite sure what's a better way to wording here. The idea is that if channelID are different, different channels are used. The reverse is not true since all other parameters in the signature will also affect whether two calls use the same channel.",OK
38445398,aharperg,https://api.github.com/repos/grpc/grpc/pulls/16190,224616091,2018-10-11T21:53:32Z,src/objective-c/GRPCClient/GRPCCall.m,"@@ -317,11 +498,36 @@ - (void)startNextRead {  #pragma mark Send headers -- (void)sendHeaders:(NSDictionary *)headers {+- (void)sendHeaders {+  // TODO (mxyan): Remove after deprecated methods are removed+  uint32_t callSafetyFlags;+  switch (_callSafety) {+    case GRPCCallSafetyDefault:+      callSafetyFlags = 0;+      break;+    case GRPCCallSafetyIdempotentRequest:+      callSafetyFlags = GRPC_INITIAL_METADATA_IDEMPOTENT_REQUEST;+      break;+    case GRPCCallSafetyCacheableRequest:+      callSafetyFlags = GRPC_INITIAL_METADATA_CACHEABLE_REQUEST;+      break;+    default:","If you leave out default -Wswtich-enum will warn you about values that are not handled. This can be useful to recognize incomplete coverage if the enum is extended later. So I'm suggesting making the check for valid values separate from the switch statement. Sometimes this is easier than others, in this case because callSafetyFlags can legitimately be zero you can't use that to detect a value that doesn't trigger the switch, but, of or example after, the switch you could do:if (callSafetyFlags == 0 && _callSafety != GRPCCallSafetyDefault) { raise... }Personally I'd check the range on _callSafety in the init and throw from there instead just like you validate the host and path.",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/16190,224629546,2018-10-11T22:59:53Z,src/objective-c/GRPCClient/private/ChannelArgsUtil.m,"@@ -0,0 +1,95 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#import ""ChannelArgsUtil.h""++#include <grpc/support/alloc.h>+#include <grpc/support/string_util.h>++static void *copy_pointer_arg(void *p) {+  // Add ref count to the object when making copy+  id obj = (__bridge id)p;+  return (__bridge_retained void *)obj;+}++static void destroy_pointer_arg(void *p) {+  // Decrease ref count to the object when destroying+  CFRelease((CFTreeRef)p);+}++static int cmp_pointer_arg(void *p, void *q) { return p == q; }++static const grpc_arg_pointer_vtable objc_arg_vtable = {copy_pointer_arg, destroy_pointer_arg,+                                                        cmp_pointer_arg};++void FreeChannelArgs(grpc_channel_args *channel_args) {+  for (size_t i = 0; i < channel_args->num_args; ++i) {+    grpc_arg *arg = &channel_args->args[i];+    gpr_free(arg->key);+    if (arg->type == GRPC_ARG_STRING) {+      gpr_free(arg->value.string);+    }+  }+  gpr_free(channel_args->args);+  gpr_free(channel_args);+}++/**+ * Allocates a @c grpc_channel_args and populates it with the options specified in the+ * @c dictionary. Keys must be @c NSString. If the value responds to @c @selector(UTF8String) then+ * it will be mapped to @c GRPC_ARG_STRING. If not, it will be mapped to @c GRPC_ARG_INTEGER if the+ * value responds to @c @selector(intValue). Otherwise, an exception will be raised. The caller of+ * this function is responsible for calling @c freeChannelArgs on a non-NULL returned value.+ */+grpc_channel_args *BuildChannelArgs(NSDictionary *dictionary) {+  if (!dictionary) {+    return NULL;+  }++  NSArray *keys = [dictionary allKeys];+  NSUInteger argCount = [keys count];++  grpc_channel_args *channelArgs = gpr_malloc(sizeof(grpc_channel_args));+  channelArgs->num_args = argCount;+  channelArgs->args = gpr_malloc(argCount * sizeof(grpc_arg));++  // TODO(kriswuollett) Check that keys adhere to GRPC core library requirements","I am not quite sure and it seems to be there for a long time. I guess it is saying that if there's a key in the dictionary but is not a recognized channel arg key for core, we should discard it.",OK
38445398,aharperg,https://api.github.com/repos/grpc/grpc/pulls/16190,224642398,2018-10-12T00:30:20Z,src/objective-c/GRPCClient/private/GRPCChannelPool.h,"@@ -0,0 +1,69 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++/**+ * Signature for the channel. If two channel's signatures are the same, they share the same+ * underlying \a GRPCChannel object.+ */++#import <GRPCClient/GRPCCallOptions.h>++#import ""GRPCChannelFactory.h""++NS_ASSUME_NONNULL_BEGIN++@class GRPCChannel;++@interface GRPCChannelConfiguration : NSObject<NSCopying>++@property(atomic, strong, readwrite) NSString *host;+@property(atomic, strong, readwrite) GRPCCallOptions *callOptions;++@property(readonly) id<GRPCChannelFactory> channelFactory;+@property(readonly) NSMutableDictionary *channelArgs;++- (nullable instancetype)initWithHost:(NSString *)host callOptions:(GRPCCallOptions *)callOptions;++@end++/**+ * Manage the pool of connected channels. When a channel is no longer referenced by any call,+ * destroy the channel after a certain period of time elapsed.+ */+@interface GRPCChannelPool : NSObject++- (instancetype)init;++- (instancetype)initWithChannelDestroyDelay:(NSTimeInterval)channelDestroyDelay;++/**+ * Return a channel with a particular configuration. If the channel does not exist, execute \a+ * createChannel then add it in the pool. If the channel exists, increase its reference count.+ */+- (GRPCChannel *)channelWithConfiguration:(GRPCChannelConfiguration *)configuration+                            createChannel:(GRPCChannel * (^)(void))createChannel;","I'd suggest the second arg be ""createdChannelCallback"" or similar. I'm a little skeptical of this pattern in general however, because it seems like GRPCChannelConfiguration has everything it needs to create the channel directly? ",OK
38445398,aharperg,https://api.github.com/repos/grpc/grpc/pulls/16190,224643655,2018-10-12T00:39:08Z,src/objective-c/GRPCClient/private/GRPCChannelPool.m,"@@ -0,0 +1,387 @@+/*+ *+ * Copyright 2015 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#import <Foundation/Foundation.h>++#import ""GRPCChannelFactory.h""+#import ""GRPCChannelPool.h""+#import ""GRPCConnectivityMonitor.h""+#import ""GRPCCronetChannelFactory.h""+#import ""GRPCInsecureChannelFactory.h""+#import ""GRPCSecureChannelFactory.h""+#import ""version.h""++#import <GRPCClient/GRPCCall+Cronet.h>+#include <grpc/support/log.h>++extern const char *kCFStreamVarName;++// When all calls of a channel are destroyed, destroy the channel after this much seconds.+const NSTimeInterval kChannelDestroyDelay = 30;++@implementation GRPCChannelConfiguration++- (nullable instancetype)initWithHost:(NSString *)host callOptions:(GRPCCallOptions *)callOptions {+  if ((self = [super init])) {+    _host = host;+    _callOptions = callOptions;+  }+  return self;+}++- (id<GRPCChannelFactory>)channelFactory {+  NSError *error;+  id<GRPCChannelFactory> factory;+  GRPCTransportType type = _callOptions.transportType;+  switch (type) {+    case GRPCTransportTypeChttp2BoringSSL:+      // TODO (mxyan): Remove when the API is deprecated+#ifdef GRPC_COMPILE_WITH_CRONET+      if (![GRPCCall isUsingCronet]) {+#endif+        factory = [GRPCSecureChannelFactory factoryWithPEMRootCerts:_callOptions.PEMRootCertificates+                                                         privateKey:_callOptions.PEMPrivateKey+                                                          certChain:_callOptions.PEMCertChain+                                                              error:&error];+        if (error) {+          NSLog(@""Error creating secure channel factory: %@"", error);+          return nil;+        }+        return factory;+#ifdef GRPC_COMPILE_WITH_CRONET+      }+#endif+      // fallthrough+    case GRPCTransportTypeCronet:+      return [GRPCCronetChannelFactory sharedInstance];+    case GRPCTransportTypeInsecure:+      return [GRPCInsecureChannelFactory sharedInstance];+    default:+      GPR_UNREACHABLE_CODE(return nil);+  }+}++- (NSMutableDictionary *)channelArgs {+  NSMutableDictionary *args = [NSMutableDictionary new];++  NSString *userAgent = @""grpc-objc/"" GRPC_OBJC_VERSION_STRING;+  NSString *userAgentPrefix = _callOptions.userAgentPrefix;+  if (userAgentPrefix) {+    args[@GRPC_ARG_PRIMARY_USER_AGENT_STRING] =+        [_callOptions.userAgentPrefix stringByAppendingFormat:@"" %@"", userAgent];+  } else {+    args[@GRPC_ARG_PRIMARY_USER_AGENT_STRING] = userAgent;+  }++  NSString *hostNameOverride = _callOptions.hostNameOverride;+  if (hostNameOverride) {+    args[@GRPC_SSL_TARGET_NAME_OVERRIDE_ARG] = hostNameOverride;+  }++  if (_callOptions.responseSizeLimit) {+    args[@GRPC_ARG_MAX_RECEIVE_MESSAGE_LENGTH] =+        [NSNumber numberWithUnsignedInteger:_callOptions.responseSizeLimit];+  }++  if (_callOptions.compressAlgorithm != GRPC_COMPRESS_NONE) {+    args[@GRPC_COMPRESSION_CHANNEL_DEFAULT_ALGORITHM] =+        [NSNumber numberWithInt:_callOptions.compressAlgorithm];+  }++  if (_callOptions.keepaliveInterval != 0) {+    args[@GRPC_ARG_KEEPALIVE_TIME_MS] =+        [NSNumber numberWithUnsignedInteger:(unsigned int)(_callOptions.keepaliveInterval * 1000)];+    args[@GRPC_ARG_KEEPALIVE_TIMEOUT_MS] =+        [NSNumber numberWithUnsignedInteger:(unsigned int)(_callOptions.keepaliveTimeout * 1000)];+  }++  if (_callOptions.enableRetry == NO) {+    args[@GRPC_ARG_ENABLE_RETRIES] = [NSNumber numberWithInt:_callOptions.enableRetry];+  }++  if (_callOptions.connectMinTimeout > 0) {+    args[@GRPC_ARG_MIN_RECONNECT_BACKOFF_MS] =+        [NSNumber numberWithUnsignedInteger:(unsigned int)(_callOptions.connectMinTimeout * 1000)];+  }+  if (_callOptions.connectInitialBackoff > 0) {+    args[@GRPC_ARG_INITIAL_RECONNECT_BACKOFF_MS] = [NSNumber+        numberWithUnsignedInteger:(unsigned int)(_callOptions.connectInitialBackoff * 1000)];+  }+  if (_callOptions.connectMaxBackoff > 0) {+    args[@GRPC_ARG_MAX_RECONNECT_BACKOFF_MS] =+        [NSNumber numberWithUnsignedInteger:(unsigned int)(_callOptions.connectMaxBackoff * 1000)];+  }++  if (_callOptions.logContext != nil) {+    args[@GRPC_ARG_MOBILE_LOG_CONTEXT] = _callOptions.logContext;+  }++  if (_callOptions.channelPoolDomain.length != 0) {+    args[@GRPC_ARG_CHANNEL_POOL_DOMAIN] = _callOptions.channelPoolDomain;+  }++  [args addEntriesFromDictionary:_callOptions.additionalChannelArgs];++  return args;+}++- (nonnull id)copyWithZone:(nullable NSZone *)zone {+  GRPCChannelConfiguration *newConfig = [[GRPCChannelConfiguration alloc] init];+  newConfig.host = _host;+  newConfig.callOptions = _callOptions;++  return newConfig;+}++- (BOOL)isEqual:(id)object {+  NSAssert([object isKindOfClass:[GRPCChannelConfiguration class]], @""Illegal :isEqual"");+  GRPCChannelConfiguration *obj = (GRPCChannelConfiguration *)object;+  if (!(obj.host == _host || [obj.host isEqualToString:_host])) return NO;+  if (!(obj.callOptions.userAgentPrefix == _callOptions.userAgentPrefix ||+        [obj.callOptions.userAgentPrefix isEqualToString:_callOptions.userAgentPrefix]))+    return NO;+  if (!(obj.callOptions.responseSizeLimit == _callOptions.responseSizeLimit)) return NO;+  if (!(obj.callOptions.compressAlgorithm == _callOptions.compressAlgorithm)) return NO;+  if (!(obj.callOptions.enableRetry == _callOptions.enableRetry)) return NO;+  if (!(obj.callOptions.keepaliveInterval == _callOptions.keepaliveInterval)) return NO;+  if (!(obj.callOptions.keepaliveTimeout == _callOptions.keepaliveTimeout)) return NO;+  if (!(obj.callOptions.connectMinTimeout == _callOptions.connectMinTimeout)) return NO;+  if (!(obj.callOptions.connectInitialBackoff == _callOptions.connectInitialBackoff)) return NO;+  if (!(obj.callOptions.connectMaxBackoff == _callOptions.connectMaxBackoff)) return NO;+  if (!(obj.callOptions.additionalChannelArgs == _callOptions.additionalChannelArgs ||+        [obj.callOptions.additionalChannelArgs+            isEqualToDictionary:_callOptions.additionalChannelArgs]))+    return NO;+  if (!(obj.callOptions.PEMRootCertificates == _callOptions.PEMRootCertificates ||+        [obj.callOptions.PEMRootCertificates isEqualToString:_callOptions.PEMRootCertificates]))+    return NO;+  if (!(obj.callOptions.PEMPrivateKey == _callOptions.PEMPrivateKey ||+        [obj.callOptions.PEMPrivateKey isEqualToString:_callOptions.PEMPrivateKey]))+    return NO;+  if (!(obj.callOptions.PEMCertChain == _callOptions.PEMCertChain ||+        [obj.callOptions.PEMCertChain isEqualToString:_callOptions.PEMCertChain]))+    return NO;+  if (!(obj.callOptions.hostNameOverride == _callOptions.hostNameOverride ||+        [obj.callOptions.hostNameOverride isEqualToString:_callOptions.hostNameOverride]))+    return NO;+  if (!(obj.callOptions.transportType == _callOptions.transportType)) return NO;+  if (!(obj.callOptions.logContext == _callOptions.logContext ||+        [obj.callOptions.logContext isEqual:_callOptions.logContext]))+    return NO;+  if (!(obj.callOptions.channelPoolDomain == _callOptions.channelPoolDomain ||+        [obj.callOptions.channelPoolDomain isEqualToString:_callOptions.channelPoolDomain]))+    return NO;+  if (!(obj.callOptions.channelID == _callOptions.channelID)) return NO;++  return YES;+}++- (NSUInteger)hash {",Ditto for most of hashing belonging in the call options object,OK
38445398,aharperg,https://api.github.com/repos/grpc/grpc/pulls/16190,224643959,2018-10-12T00:41:45Z,src/objective-c/GRPCClient/private/GRPCChannelPool.m,"@@ -0,0 +1,387 @@+/*+ *+ * Copyright 2015 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#import <Foundation/Foundation.h>++#import ""GRPCChannelFactory.h""+#import ""GRPCChannelPool.h""+#import ""GRPCConnectivityMonitor.h""+#import ""GRPCCronetChannelFactory.h""+#import ""GRPCInsecureChannelFactory.h""+#import ""GRPCSecureChannelFactory.h""+#import ""version.h""++#import <GRPCClient/GRPCCall+Cronet.h>+#include <grpc/support/log.h>++extern const char *kCFStreamVarName;++// When all calls of a channel are destroyed, destroy the channel after this much seconds.+const NSTimeInterval kChannelDestroyDelay = 30;++@implementation GRPCChannelConfiguration++- (nullable instancetype)initWithHost:(NSString *)host callOptions:(GRPCCallOptions *)callOptions {+  if ((self = [super init])) {+    _host = host;+    _callOptions = callOptions;+  }+  return self;+}++- (id<GRPCChannelFactory>)channelFactory {+  NSError *error;+  id<GRPCChannelFactory> factory;+  GRPCTransportType type = _callOptions.transportType;+  switch (type) {+    case GRPCTransportTypeChttp2BoringSSL:+      // TODO (mxyan): Remove when the API is deprecated+#ifdef GRPC_COMPILE_WITH_CRONET+      if (![GRPCCall isUsingCronet]) {+#endif+        factory = [GRPCSecureChannelFactory factoryWithPEMRootCerts:_callOptions.PEMRootCertificates+                                                         privateKey:_callOptions.PEMPrivateKey+                                                          certChain:_callOptions.PEMCertChain+                                                              error:&error];+        if (error) {+          NSLog(@""Error creating secure channel factory: %@"", error);+          return nil;+        }+        return factory;+#ifdef GRPC_COMPILE_WITH_CRONET+      }+#endif+      // fallthrough+    case GRPCTransportTypeCronet:+      return [GRPCCronetChannelFactory sharedInstance];+    case GRPCTransportTypeInsecure:+      return [GRPCInsecureChannelFactory sharedInstance];+    default:+      GPR_UNREACHABLE_CODE(return nil);+  }+}++- (NSMutableDictionary *)channelArgs {+  NSMutableDictionary *args = [NSMutableDictionary new];++  NSString *userAgent = @""grpc-objc/"" GRPC_OBJC_VERSION_STRING;+  NSString *userAgentPrefix = _callOptions.userAgentPrefix;+  if (userAgentPrefix) {+    args[@GRPC_ARG_PRIMARY_USER_AGENT_STRING] =+        [_callOptions.userAgentPrefix stringByAppendingFormat:@"" %@"", userAgent];+  } else {+    args[@GRPC_ARG_PRIMARY_USER_AGENT_STRING] = userAgent;+  }++  NSString *hostNameOverride = _callOptions.hostNameOverride;+  if (hostNameOverride) {+    args[@GRPC_SSL_TARGET_NAME_OVERRIDE_ARG] = hostNameOverride;+  }++  if (_callOptions.responseSizeLimit) {+    args[@GRPC_ARG_MAX_RECEIVE_MESSAGE_LENGTH] =+        [NSNumber numberWithUnsignedInteger:_callOptions.responseSizeLimit];+  }++  if (_callOptions.compressAlgorithm != GRPC_COMPRESS_NONE) {+    args[@GRPC_COMPRESSION_CHANNEL_DEFAULT_ALGORITHM] =+        [NSNumber numberWithInt:_callOptions.compressAlgorithm];+  }++  if (_callOptions.keepaliveInterval != 0) {+    args[@GRPC_ARG_KEEPALIVE_TIME_MS] =+        [NSNumber numberWithUnsignedInteger:(unsigned int)(_callOptions.keepaliveInterval * 1000)];+    args[@GRPC_ARG_KEEPALIVE_TIMEOUT_MS] =+        [NSNumber numberWithUnsignedInteger:(unsigned int)(_callOptions.keepaliveTimeout * 1000)];+  }++  if (_callOptions.enableRetry == NO) {+    args[@GRPC_ARG_ENABLE_RETRIES] = [NSNumber numberWithInt:_callOptions.enableRetry];+  }++  if (_callOptions.connectMinTimeout > 0) {+    args[@GRPC_ARG_MIN_RECONNECT_BACKOFF_MS] =+        [NSNumber numberWithUnsignedInteger:(unsigned int)(_callOptions.connectMinTimeout * 1000)];+  }+  if (_callOptions.connectInitialBackoff > 0) {+    args[@GRPC_ARG_INITIAL_RECONNECT_BACKOFF_MS] = [NSNumber+        numberWithUnsignedInteger:(unsigned int)(_callOptions.connectInitialBackoff * 1000)];+  }+  if (_callOptions.connectMaxBackoff > 0) {+    args[@GRPC_ARG_MAX_RECONNECT_BACKOFF_MS] =+        [NSNumber numberWithUnsignedInteger:(unsigned int)(_callOptions.connectMaxBackoff * 1000)];+  }++  if (_callOptions.logContext != nil) {+    args[@GRPC_ARG_MOBILE_LOG_CONTEXT] = _callOptions.logContext;+  }++  if (_callOptions.channelPoolDomain.length != 0) {+    args[@GRPC_ARG_CHANNEL_POOL_DOMAIN] = _callOptions.channelPoolDomain;+  }++  [args addEntriesFromDictionary:_callOptions.additionalChannelArgs];++  return args;+}++- (nonnull id)copyWithZone:(nullable NSZone *)zone {+  GRPCChannelConfiguration *newConfig = [[GRPCChannelConfiguration alloc] init];+  newConfig.host = _host;+  newConfig.callOptions = _callOptions;++  return newConfig;+}++- (BOOL)isEqual:(id)object {+  NSAssert([object isKindOfClass:[GRPCChannelConfiguration class]], @""Illegal :isEqual"");+  GRPCChannelConfiguration *obj = (GRPCChannelConfiguration *)object;+  if (!(obj.host == _host || [obj.host isEqualToString:_host])) return NO;+  if (!(obj.callOptions.userAgentPrefix == _callOptions.userAgentPrefix ||+        [obj.callOptions.userAgentPrefix isEqualToString:_callOptions.userAgentPrefix]))+    return NO;+  if (!(obj.callOptions.responseSizeLimit == _callOptions.responseSizeLimit)) return NO;+  if (!(obj.callOptions.compressAlgorithm == _callOptions.compressAlgorithm)) return NO;+  if (!(obj.callOptions.enableRetry == _callOptions.enableRetry)) return NO;+  if (!(obj.callOptions.keepaliveInterval == _callOptions.keepaliveInterval)) return NO;+  if (!(obj.callOptions.keepaliveTimeout == _callOptions.keepaliveTimeout)) return NO;+  if (!(obj.callOptions.connectMinTimeout == _callOptions.connectMinTimeout)) return NO;+  if (!(obj.callOptions.connectInitialBackoff == _callOptions.connectInitialBackoff)) return NO;+  if (!(obj.callOptions.connectMaxBackoff == _callOptions.connectMaxBackoff)) return NO;+  if (!(obj.callOptions.additionalChannelArgs == _callOptions.additionalChannelArgs ||+        [obj.callOptions.additionalChannelArgs+            isEqualToDictionary:_callOptions.additionalChannelArgs]))+    return NO;+  if (!(obj.callOptions.PEMRootCertificates == _callOptions.PEMRootCertificates ||+        [obj.callOptions.PEMRootCertificates isEqualToString:_callOptions.PEMRootCertificates]))+    return NO;+  if (!(obj.callOptions.PEMPrivateKey == _callOptions.PEMPrivateKey ||+        [obj.callOptions.PEMPrivateKey isEqualToString:_callOptions.PEMPrivateKey]))+    return NO;+  if (!(obj.callOptions.PEMCertChain == _callOptions.PEMCertChain ||+        [obj.callOptions.PEMCertChain isEqualToString:_callOptions.PEMCertChain]))+    return NO;+  if (!(obj.callOptions.hostNameOverride == _callOptions.hostNameOverride ||+        [obj.callOptions.hostNameOverride isEqualToString:_callOptions.hostNameOverride]))+    return NO;+  if (!(obj.callOptions.transportType == _callOptions.transportType)) return NO;+  if (!(obj.callOptions.logContext == _callOptions.logContext ||+        [obj.callOptions.logContext isEqual:_callOptions.logContext]))+    return NO;+  if (!(obj.callOptions.channelPoolDomain == _callOptions.channelPoolDomain ||+        [obj.callOptions.channelPoolDomain isEqualToString:_callOptions.channelPoolDomain]))+    return NO;+  if (!(obj.callOptions.channelID == _callOptions.channelID)) return NO;++  return YES;+}++- (NSUInteger)hash {+  NSUInteger result = 0;+  result ^= _host.hash;+  result ^= _callOptions.userAgentPrefix.hash;+  result ^= _callOptions.responseSizeLimit;+  result ^= _callOptions.compressAlgorithm;+  result ^= _callOptions.enableRetry;+  result ^= (unsigned int)(_callOptions.keepaliveInterval * 1000);+  result ^= (unsigned int)(_callOptions.keepaliveTimeout * 1000);+  result ^= (unsigned int)(_callOptions.connectMinTimeout * 1000);+  result ^= (unsigned int)(_callOptions.connectInitialBackoff * 1000);+  result ^= (unsigned int)(_callOptions.connectMaxBackoff * 1000);+  result ^= _callOptions.additionalChannelArgs.hash;+  result ^= _callOptions.PEMRootCertificates.hash;+  result ^= _callOptions.PEMPrivateKey.hash;+  result ^= _callOptions.PEMCertChain.hash;+  result ^= _callOptions.hostNameOverride.hash;+  result ^= _callOptions.transportType;+  result ^= [_callOptions.logContext hash];+  result ^= _callOptions.channelPoolDomain.hash;+  result ^= _callOptions.channelID;++  return result;+}++@end++/**+ * Time the channel destroy when the channel's calls are unreffed. If there's new call, reset the+ * timer.+ */+@interface GRPCChannelCallRef : NSObject++- (instancetype)initWithChannelConfiguration:(GRPCChannelConfiguration *)configuration+                                destroyDelay:(NSTimeInterval)destroyDelay+                               dispatchQueue:(dispatch_queue_t)dispatchQueue+                              destroyChannel:(void (^)())destroyChannel;++/** Add call ref count to the channel and maybe reset the timer. */+- (void)refChannel;++/** Reduce call ref count to the channel and maybe set the timer. */+- (void)unrefChannel;++@end++@implementation GRPCChannelCallRef {+  GRPCChannelConfiguration *_configuration;+  NSTimeInterval _destroyDelay;+  // We use dispatch queue for this purpose since timer invalidation must happen on the same+  // thread which issued the timer.+  dispatch_queue_t _dispatchQueue;+  void (^_destroyChannel)();++  NSUInteger _refCount;+  NSTimer *_timer;+}++- (instancetype)initWithChannelConfiguration:(GRPCChannelConfiguration *)configuration+                                destroyDelay:(NSTimeInterval)destroyDelay+                               dispatchQueue:(dispatch_queue_t)dispatchQueue+                              destroyChannel:(void (^)())destroyChannel {+  if ((self = [super init])) {+    _configuration = configuration;+    _destroyDelay = destroyDelay;+    _dispatchQueue = dispatchQueue;+    _destroyChannel = destroyChannel;++    _refCount = 0;+    _timer = nil;+  }+  return self;+}++// This function is protected by channel pool dispatch queue.+- (void)refChannel {+  _refCount++;","Based on the described usage, I imagine this class needs locking",
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/16801,224872568,2018-10-12T18:10:19Z,src/core/lib/transport/metadata.h,"@@ -109,7 +109,11 @@ struct grpc_mdelem {                               (uintptr_t)GRPC_MDELEM_STORAGE_INTERNED_BIT))  /* Unrefs the slices. */-grpc_mdelem grpc_mdelem_from_slices(grpc_slice key, grpc_slice value);+grpc_mdelem grpc_mdelem_from_slices(const grpc_slice& key,+                                    const grpc_slice& value);+/* Does not unref the slices. */+grpc_mdelem grpc_mdelem_from_slices_no_unref(const grpc_slice& key,","Thank you @markdroth! I agree with all your statements and tried to make it a RAII class, so that we can have automatic `unref()`'s when it's needed, but I hit a wall. The problem is `grpc_slice` is unfortunately part of the C API in `include/grpc/grpc.h`. So, that effort failed.I think the cleanest way would be really removing `unref()` calls from `grpc_mdelem_from_slices()`, and moving `unref()` calls to call sites when it's necessary. In other words, `grpc_mdelem_from_slices()` doesn't really have any business `unref()`ing the input slice. It should simply created a mdelem from the given slices and that's all. WDYT?",OK
38445398,aharperg,https://api.github.com/repos/grpc/grpc/pulls/16190,224919028,2018-10-12T21:24:35Z,src/objective-c/GRPCClient/private/GRPCHost.m,"@@ -18,46 +18,35 @@  #import ""GRPCHost.h"" +#import <GRPCClient/GRPCCall+Cronet.h> #import <GRPCClient/GRPCCall.h>+ #include <grpc/grpc.h> #include <grpc/grpc_security.h>-#ifdef GRPC_COMPILE_WITH_CRONET-#import <GRPCClient/GRPCCall+ChannelArg.h>-#import <GRPCClient/GRPCCall+Cronet.h>-#endif -#import ""GRPCChannel.h""+#import <GRPCClient/GRPCCallOptions.h>+#import ""GRPCChannelFactory.h"" #import ""GRPCCompletionQueue.h"" #import ""GRPCConnectivityMonitor.h""+#import ""GRPCCronetChannelFactory.h""+#import ""GRPCSecureChannelFactory.h"" #import ""NSDictionary+GRPC.h"" #import ""version.h""  NS_ASSUME_NONNULL_BEGIN -extern const char *kCFStreamVarName;- static NSMutableDictionary *kHostCache;","k is reserved for constants, this needs to be gHostCache or similar.",OK
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/16864,224926091,2018-10-12T22:00:57Z,src/python/grpcio/grpc/_cython/_cygrpc/arguments.pyx.pxi,"@@ -52,7 +52,9 @@ cdef grpc_arg _unwrap_grpc_arg(tuple wrapped_arg):  cdef class _ArgumentProcessor: -  cdef void c(self, argument, grpc_arg_pointer_vtable *vtable, references):+  cdef void c(self, argument, grpc_arg_pointer_vtable *vtable, references) except *:+    if not isinstance(argument, tuple) or len(argument) != 2:","Do we need this when `except *` is present? Wouldn't we get an exception anyway?If so, then I prefer not doing a manual typecheck, as it is unpythonic to unnecessarily restrict types that would just work fine here. ",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/16864,224927180,2018-10-12T22:07:34Z,src/python/grpcio/grpc/_cython/_cygrpc/arguments.pyx.pxi,"@@ -52,7 +52,9 @@ cdef grpc_arg _unwrap_grpc_arg(tuple wrapped_arg):  cdef class _ArgumentProcessor: -  cdef void c(self, argument, grpc_arg_pointer_vtable *vtable, references):+  cdef void c(self, argument, grpc_arg_pointer_vtable *vtable, references) except *:+    if not isinstance(argument, tuple) or len(argument) != 2:","The Cython exception handling is weird. I tried alternative ways without adding ""except *"", the TypeError exception will always crash the process with ""Segment Fault"".",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/16864,224928679,2018-10-12T22:17:05Z,src/python/grpcio/grpc/_channel.py,"@@ -981,4 +981,7 @@ def __del__(self):         # then deletion of this grpc._channel.Channel instance can be made to         # effect closure of the underlying cygrpc.Channel instance.         cygrpc.fork_unregister_channel(self)-        _moot(self._connectivity_state)+        # This prevent the failed-at-initializing object removal from failing.+        # Though the __init__ failed, the removal will still trigger __del__.+        if hasattr(self, ""_connectivity_state""):","The `self._connectivity_state` depends on `self._channel`. Since other classes in gRPC-Python is not doing the preinitializing with `None`, I would think a check in `__del__` is a little bit more consistent.```Python_channel.py@910self._channel = cygrpc.Channel(_common.encode(target), _options(options), credentials)self._call_state = _ChannelCallState(self._channel)self._connectivity_state = _ChannelConnectivityState(self._channel)```",OK
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/16864,224933758,2018-10-12T22:54:38Z,src/python/grpcio/grpc/_cython/_cygrpc/arguments.pyx.pxi,"@@ -52,7 +52,9 @@ cdef grpc_arg _unwrap_grpc_arg(tuple wrapped_arg):  cdef class _ArgumentProcessor: -  cdef void c(self, argument, grpc_arg_pointer_vtable *vtable, references):+  cdef void c(self, argument, grpc_arg_pointer_vtable *vtable, references) except *:+    if not isinstance(argument, tuple) or len(argument) != 2:","Reading your comment again, I think I should clarify: I was suggesting adding `except *` but not throwing `TypeError` manually. Instead, relying on the actual function that iterates through the tuple to raise `ValueError` (since it obviously does recognize that as `ValueError` and prints the eaten exception to console). I think you may have to mark all the functions in the call stack as `except *` if the deeper function is the one raising `ValueError`.",
38445398,aharperg,https://api.github.com/repos/grpc/grpc/pulls/16190,224934794,2018-10-12T23:03:20Z,src/objective-c/GRPCClient/private/GRPCSecureChannelFactory.m,"@@ -0,0 +1,129 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#import ""GRPCSecureChannelFactory.h""++#include <grpc/grpc_security.h>++#import ""ChannelArgsUtil.h""+#import ""GRPCChannel.h""++NS_ASSUME_NONNULL_BEGIN++@implementation GRPCSecureChannelFactory {+  grpc_channel_credentials *_channelCreds;+}+++ (nullable instancetype)factoryWithPEMRootCerts:(nullable NSString *)rootCerts+                                      privateKey:(nullable NSString *)privateKey+                                       certChain:(nullable NSString *)certChain+                                           error:(NSError **)errorPtr {+  return [[self alloc] initWithPEMRootCerts:rootCerts+                                 privateKey:privateKey+                                  certChain:certChain+                                      error:errorPtr];+}++- (NSData *)nullTerminatedDataWithString:(NSString *)string {+  // dataUsingEncoding: does not return a null-terminated string.+  NSData *data = [string dataUsingEncoding:NSASCIIStringEncoding allowLossyConversion:YES];+  NSMutableData *nullTerminated = [NSMutableData dataWithData:data];+  [nullTerminated appendBytes:""\0"" length:1];+  return nullTerminated;+}++- (nullable instancetype)initWithPEMRootCerts:(nullable NSString *)rootCerts+                                   privateKey:(nullable NSString *)privateKey+                                    certChain:(nullable NSString *)certChain+                                        error:(NSError **)errorPtr {+  static NSData *kDefaultRootsASCII;+  static NSError *kDefaultRootsError;+  static dispatch_once_t loading;+  dispatch_once(&loading, ^{+    NSString *defaultPath = @""gRPCCertificates.bundle/roots"";  // .pem+    // Do not use NSBundle.mainBundle, as it's nil for tests of library projects.+    NSBundle *bundle = [NSBundle bundleForClass:self.class];","class is an NSObject method, use method syntax instead of property syntax.",
38445398,aharperg,https://api.github.com/repos/grpc/grpc/pulls/16190,224935982,2018-10-12T23:13:32Z,src/objective-c/GRPCClient/private/GRPCSecureChannelFactory.m,"@@ -0,0 +1,129 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#import ""GRPCSecureChannelFactory.h""++#include <grpc/grpc_security.h>++#import ""ChannelArgsUtil.h""+#import ""GRPCChannel.h""++NS_ASSUME_NONNULL_BEGIN++@implementation GRPCSecureChannelFactory {+  grpc_channel_credentials *_channelCreds;+}+++ (nullable instancetype)factoryWithPEMRootCerts:(nullable NSString *)rootCerts+                                      privateKey:(nullable NSString *)privateKey+                                       certChain:(nullable NSString *)certChain+                                           error:(NSError **)errorPtr {+  return [[self alloc] initWithPEMRootCerts:rootCerts+                                 privateKey:privateKey+                                  certChain:certChain+                                      error:errorPtr];+}++- (NSData *)nullTerminatedDataWithString:(NSString *)string {+  // dataUsingEncoding: does not return a null-terminated string.+  NSData *data = [string dataUsingEncoding:NSASCIIStringEncoding allowLossyConversion:YES];+  NSMutableData *nullTerminated = [NSMutableData dataWithData:data];","handle case where |data| is nil, or just use nil-messaging and [data mutableCopy] to make this safe",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16801,224939481,2018-10-12T23:45:13Z,src/core/lib/transport/metadata.h,"@@ -109,7 +109,11 @@ struct grpc_mdelem {                               (uintptr_t)GRPC_MDELEM_STORAGE_INTERNED_BIT))  /* Unrefs the slices. */-grpc_mdelem grpc_mdelem_from_slices(grpc_slice key, grpc_slice value);+grpc_mdelem grpc_mdelem_from_slices(const grpc_slice& key,+                                    const grpc_slice& value);+/* Does not unref the slices. */+grpc_mdelem grpc_mdelem_from_slices_no_unref(const grpc_slice& key,","> Thank you @markdroth! I agree with all your statements and tried to make it a RAII class, so that we can have automatic `unref()`'s when it's needed, but I hit a wall. The problem is `grpc_slice` is unfortunately part of the C API in `include/grpc/grpc.h`. So, that effort failed.Right, we can't change the public C slice API.  But we could make a C++ class to use internally, and make it accessible externally via the existing public C API.  In other words, the public C API would basically be a thin wrapper around the C++ implementation.Again, though, as I said above, if you don't want to do this now, I am fine with deferring this for work for now.> I think the cleanest way would be really removing `unref()` calls from `grpc_mdelem_from_slices()`, and moving `unref()` calls to call sites when it's necessary. In other words, `grpc_mdelem_from_slices()` doesn't really have any business `unref()`ing the input slice. It should simply created a mdelem from the given slices and that's all. WDYT?If it turns out that that approach seems to better match the expectations of most callers, that's fine.  I don't have time to look at the callers to see if that's true, but it seems reasonable to me if it is.I'd say give it a try and see how it looks.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16860,225645041,2018-10-16T17:52:39Z,src/core/lib/channel/channelz_registry.cc,"@@ -133,10 +136,18 @@ char* ChannelzRegistry::InternalGetTopChannels(intptr_t start_channel_id) {   // start_channel_id=0, which signifies ""give me everything."" Hence this   // funky looking line below.   size_t start_idx = start_channel_id == 0 ? 0 : start_channel_id - 1;+  bool more_to_come = false;",Suggest renaming this to something like `reached_pagination_limit`.,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16898,225655670,2018-10-16T18:24:49Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -1990,6 +1990,16 @@ static void recv_trailing_metadata_ready(void* arg, grpc_error* error) {   }   // Not retrying, so commit the call.   retry_commit(elem, retry_state);+  // Now that the try is committed, give the trailer to the lb policy as needed+  if (calld->pick.recv_trailing_metadata_ready != nullptr) {","This code block handles the case where retries are enabled, but we also need to handle the case where retries are not enabled.  In that case, we need to write a separate callback to intercept recv_trailing_metadata_ready that duplicates this code block.This should probably be done similarly to how we were handling channelz prior to #16827.",OK
44210700,legerman,https://api.github.com/repos/grpc/grpc/pulls/16190,225673612,2018-10-16T19:14:23Z,src/objective-c/GRPCClient/GRPCCallOptions.h,"@@ -0,0 +1,317 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#import <Foundation/Foundation.h>++/**+ * Safety remark of a gRPC method as defined in RFC 2616 Section 9.1+ */+typedef NS_ENUM(NSUInteger, GRPCCallSafety) {+  /** Signal that there is no guarantees on how the call affects the server state. */+  GRPCCallSafetyDefault = 0,+  /** Signal that the call is idempotent. gRPC is free to use PUT verb. */+  GRPCCallSafetyIdempotentRequest = 1,+  /** Signal that the call is cacheable and will not affect server state. gRPC is free to use GET+   verb. */+  GRPCCallSafetyCacheableRequest = 2,+};++// Compression algorithm to be used by a gRPC call+typedef NS_ENUM(NSInteger, GRPCCompressAlgorithm) {","Just throwing out the idea to slowly migrate users towards a new one, you could create a typedef:typedef NS_ENUM(NSInteger, GRPCCompressionAlgorithm) {....}// Use GRPCCompressionAlgorithm as GRPCCompressAlgorithm will be deprecated.typedef GRPCCompressionAlgorithm GRPCCompressAlgorithm;",OK
44210700,legerman,https://api.github.com/repos/grpc/grpc/pulls/16190,225678189,2018-10-16T19:29:00Z,src/objective-c/GRPCClient/GRPCCall+ChannelArg.h,"@@ -19,52 +19,20 @@  #include <AvailabilityMacros.h> -typedef NS_ENUM(NSInteger, GRPCCompressAlgorithm) {-  GRPCCompressNone,-  GRPCCompressDeflate,-  GRPCCompressGzip,-};--/**- * Methods to configure GRPC channel options.- */+// Deprecated interface. Please use GRPCCallOptions instead.",Is there are a strategy/timeline on when these methods are going to be explicitly marked as deprecated?,
44210700,legerman,https://api.github.com/repos/grpc/grpc/pulls/16190,225692302,2018-10-16T20:15:18Z,src/objective-c/GRPCClient/GRPCCallOptions.h,"@@ -0,0 +1,327 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#import <Foundation/Foundation.h>++/**+ * Safety remark of a gRPC method as defined in RFC 2616 Section 9.1+ */+typedef NS_ENUM(NSUInteger, GRPCCallSafety) {+  /** Signal that there is no guarantees on how the call affects the server state. */+  GRPCCallSafetyDefault = 0,+  /** Signal that the call is idempotent. gRPC is free to use PUT verb. */+  GRPCCallSafetyIdempotentRequest = 1,+  /** Signal that the call is cacheable and will not affect server state. gRPC is free to use GET+   verb. */+  GRPCCallSafetyCacheableRequest = 2,+};++// Compression algorithm to be used by a gRPC call+typedef NS_ENUM(NSInteger, GRPCCompressAlgorithm) {+  GRPCCompressNone = 0,+  GRPCCompressDeflate,+  GRPCCompressGzip,+  GRPCStreamCompressGzip,+};++// The transport to be used by a gRPC call+typedef NS_ENUM(NSInteger, GRPCTransportType) {+  // gRPC internal HTTP/2 stack with BoringSSL+  GRPCTransportTypeChttp2BoringSSL = 0,+  // Cronet stack+  GRPCTransportTypeCronet,+  // Insecure channel. FOR TEST ONLY!+  GRPCTransportTypeInsecure,+};++@protocol GRPCAuthorizationProtocol+- (void)getTokenWithHandler:(void (^)(NSString *token))hander;",What about renaming this method to just:`- (void)tokenWithHandler:(void (^)(NSString *token))hander;`,OK
44210700,legerman,https://api.github.com/repos/grpc/grpc/pulls/16190,225697132,2018-10-16T20:31:16Z,src/objective-c/GRPCClient/GRPCCallOptions.m,"@@ -0,0 +1,456 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#import ""GRPCCallOptions.h""++// The default values for the call options.+static NSString *const kDefaultServerAuthority = nil;+static const NSTimeInterval kDefaultTimeout = 0;+static NSDictionary *const kDefaultInitialMetadata = nil;+static NSString *const kDefaultUserAgentPrefix = nil;+static const NSUInteger kDefaultResponseSizeLimit = 0;+static const GRPCCompressAlgorithm kDefaultCompressAlgorithm = GRPCCompressNone;+static const BOOL kDefaultEnableRetry = YES;+static const NSTimeInterval kDefaultKeepaliveInterval = 0;+static const NSTimeInterval kDefaultKeepaliveTimeout = 0;+static const NSTimeInterval kDefaultConnectMinTimeout = 0;+static const NSTimeInterval kDefaultConnectInitialBackoff = 0;+static const NSTimeInterval kDefaultConnectMaxBackoff = 0;+static NSDictionary *const kDefaultAdditionalChannelArgs = nil;+static NSString *const kDefaultPEMRootCertificates = nil;+static NSString *const kDefaultPEMPrivateKey = nil;+static NSString *const kDefaultPEMCertChain = nil;+static NSString *const kDefaultOauth2AccessToken = nil;+static const id<GRPCAuthorizationProtocol> kDefaultAuthTokenProvider = nil;+static const GRPCTransportType kDefaultTransportType = GRPCTransportTypeChttp2BoringSSL;+static NSString *const kDefaultHostNameOverride = nil;+static const id kDefaultLogContext = nil;+static NSString *kDefaultChannelPoolDomain = nil;+static NSUInteger kDefaultChannelID = 0;++@implementation GRPCCallOptions {+ @protected+  NSString *_serverAuthority;+  NSTimeInterval _timeout;+  NSString *_oauth2AccessToken;+  id<GRPCAuthorizationProtocol> _authTokenProvider;+  NSDictionary *_initialMetadata;+  NSString *_userAgentPrefix;+  NSUInteger _responseSizeLimit;+  GRPCCompressAlgorithm _compressAlgorithm;+  BOOL _enableRetry;+  NSTimeInterval _keepaliveInterval;+  NSTimeInterval _keepaliveTimeout;+  NSTimeInterval _connectMinTimeout;+  NSTimeInterval _connectInitialBackoff;+  NSTimeInterval _connectMaxBackoff;+  NSDictionary *_additionalChannelArgs;+  NSString *_PEMRootCertificates;+  NSString *_PEMPrivateKey;+  NSString *_PEMCertChain;+  GRPCTransportType _transportType;+  NSString *_hostNameOverride;+  id _logContext;+  NSString *_channelPoolDomain;+  NSUInteger _channelID;+}++@synthesize serverAuthority = _serverAuthority;+@synthesize timeout = _timeout;+@synthesize oauth2AccessToken = _oauth2AccessToken;+@synthesize authTokenProvider = _authTokenProvider;+@synthesize initialMetadata = _initialMetadata;+@synthesize userAgentPrefix = _userAgentPrefix;+@synthesize responseSizeLimit = _responseSizeLimit;+@synthesize compressAlgorithm = _compressAlgorithm;+@synthesize enableRetry = _enableRetry;+@synthesize keepaliveInterval = _keepaliveInterval;+@synthesize keepaliveTimeout = _keepaliveTimeout;+@synthesize connectMinTimeout = _connectMinTimeout;+@synthesize connectInitialBackoff = _connectInitialBackoff;+@synthesize connectMaxBackoff = _connectMaxBackoff;+@synthesize additionalChannelArgs = _additionalChannelArgs;+@synthesize PEMRootCertificates = _PEMRootCertificates;+@synthesize PEMPrivateKey = _PEMPrivateKey;+@synthesize PEMCertChain = _PEMCertChain;+@synthesize transportType = _transportType;+@synthesize hostNameOverride = _hostNameOverride;+@synthesize logContext = _logContext;+@synthesize channelPoolDomain = _channelPoolDomain;+@synthesize channelID = _channelID;++- (instancetype)init {+  return [self initWithServerAuthority:kDefaultServerAuthority+                               timeout:kDefaultTimeout+                     oauth2AccessToken:kDefaultOauth2AccessToken+                     authTokenProvider:kDefaultAuthTokenProvider+                       initialMetadata:kDefaultInitialMetadata+                       userAgentPrefix:kDefaultUserAgentPrefix+                     responseSizeLimit:kDefaultResponseSizeLimit+                     compressAlgorithm:kDefaultCompressAlgorithm+                           enableRetry:kDefaultEnableRetry+                     keepaliveInterval:kDefaultKeepaliveInterval+                      keepaliveTimeout:kDefaultKeepaliveTimeout+                     connectMinTimeout:kDefaultConnectMinTimeout+                 connectInitialBackoff:kDefaultConnectInitialBackoff+                     connectMaxBackoff:kDefaultConnectMaxBackoff+                 additionalChannelArgs:kDefaultAdditionalChannelArgs+                    PEMRootCertificates:kDefaultPEMRootCertificates+                         PEMPrivateKey:kDefaultPEMPrivateKey+                          PEMCertChain:kDefaultPEMCertChain+                         transportType:kDefaultTransportType+                      hostNameOverride:kDefaultHostNameOverride+                            logContext:kDefaultLogContext+                     channelPoolDomain:kDefaultChannelPoolDomain+                             channelID:kDefaultChannelID];+}++- (instancetype)initWithServerAuthority:(NSString *)serverAuthority+                                timeout:(NSTimeInterval)timeout+                      oauth2AccessToken:(NSString *)oauth2AccessToken+                      authTokenProvider:(id<GRPCAuthorizationProtocol>)authTokenProvider+                        initialMetadata:(NSDictionary *)initialMetadata+                        userAgentPrefix:(NSString *)userAgentPrefix+                      responseSizeLimit:(NSUInteger)responseSizeLimit+                      compressAlgorithm:(GRPCCompressAlgorithm)compressAlgorithm+                            enableRetry:(BOOL)enableRetry+                      keepaliveInterval:(NSTimeInterval)keepaliveInterval+                       keepaliveTimeout:(NSTimeInterval)keepaliveTimeout+                      connectMinTimeout:(NSTimeInterval)connectMinTimeout+                  connectInitialBackoff:(NSTimeInterval)connectInitialBackoff+                      connectMaxBackoff:(NSTimeInterval)connectMaxBackoff+                  additionalChannelArgs:(NSDictionary *)additionalChannelArgs+                     PEMRootCertificates:(NSString *)PEMRootCertificates+                          PEMPrivateKey:(NSString *)PEMPrivateKey+                           PEMCertChain:(NSString *)PEMCertChain+                          transportType:(GRPCTransportType)transportType+                       hostNameOverride:(NSString *)hostNameOverride+                             logContext:(id)logContext+                      channelPoolDomain:(NSString *)channelPoolDomain+                              channelID:(NSUInteger)channelID {+  if ((self = [super init])) {+    _serverAuthority = [serverAuthority copy];+    _timeout = timeout;+    _oauth2AccessToken = [oauth2AccessToken copy];+    _authTokenProvider = authTokenProvider;+    _initialMetadata = [[NSDictionary alloc] initWithDictionary:initialMetadata copyItems:YES];+    _userAgentPrefix = [userAgentPrefix copy];+    _responseSizeLimit = responseSizeLimit;+    _compressAlgorithm = compressAlgorithm;+    _enableRetry = enableRetry;+    _keepaliveInterval = keepaliveInterval;+    _keepaliveTimeout = keepaliveTimeout;+    _connectMinTimeout = connectMinTimeout;+    _connectInitialBackoff = connectInitialBackoff;+    _connectMaxBackoff = connectMaxBackoff;+    _additionalChannelArgs = [[NSDictionary alloc] initWithDictionary:additionalChannelArgs copyItems:YES];+    _PEMRootCertificates = [PEMRootCertificates copy];+    _PEMPrivateKey = [PEMPrivateKey copy];+    _PEMCertChain = [PEMCertChain copy];+    _transportType = transportType;+    _hostNameOverride = [hostNameOverride copy];+    _logContext = logContext;+    _channelPoolDomain = [channelPoolDomain copy];+    _channelID = channelID;+  }+  return self;+}++- (nonnull id)copyWithZone:(NSZone *)zone {+  GRPCCallOptions *newOptions =+      [[GRPCCallOptions allocWithZone:zone] initWithServerAuthority:_serverAuthority+                                                            timeout:_timeout+                                                  oauth2AccessToken:_oauth2AccessToken+                                                  authTokenProvider:_authTokenProvider+                                                    initialMetadata:_initialMetadata+                                                    userAgentPrefix:_userAgentPrefix+                                                  responseSizeLimit:_responseSizeLimit+                                                  compressAlgorithm:_compressAlgorithm+                                                        enableRetry:_enableRetry+                                                  keepaliveInterval:_keepaliveInterval+                                                   keepaliveTimeout:_keepaliveTimeout+                                                  connectMinTimeout:_connectMinTimeout+                                              connectInitialBackoff:_connectInitialBackoff+                                                  connectMaxBackoff:_connectMaxBackoff+                                              additionalChannelArgs:_additionalChannelArgs+                                                 PEMRootCertificates:_PEMRootCertificates+                                                      PEMPrivateKey:_PEMPrivateKey+                                                       PEMCertChain:_PEMCertChain+                                                      transportType:_transportType+                                                   hostNameOverride:_hostNameOverride+                                                         logContext:_logContext+                                                  channelPoolDomain:_channelPoolDomain+                                                          channelID:_channelID];+  return newOptions;+}++- (nonnull id)mutableCopyWithZone:(NSZone *)zone {+  GRPCMutableCallOptions *newOptions = [[GRPCMutableCallOptions allocWithZone:zone]+      initWithServerAuthority:_serverAuthority+                      timeout:_timeout+            oauth2AccessToken:_oauth2AccessToken+            authTokenProvider:_authTokenProvider+              initialMetadata:_initialMetadata+              userAgentPrefix:_userAgentPrefix+            responseSizeLimit:_responseSizeLimit+            compressAlgorithm:_compressAlgorithm+                  enableRetry:_enableRetry+            keepaliveInterval:_keepaliveInterval+             keepaliveTimeout:_keepaliveTimeout+            connectMinTimeout:_connectMinTimeout+        connectInitialBackoff:_connectInitialBackoff+            connectMaxBackoff:_connectMaxBackoff+        additionalChannelArgs:[_additionalChannelArgs copy]+           PEMRootCertificates:_PEMRootCertificates+                PEMPrivateKey:_PEMPrivateKey+                 PEMCertChain:_PEMCertChain+                transportType:_transportType+             hostNameOverride:_hostNameOverride+                   logContext:_logContext+            channelPoolDomain:_channelPoolDomain+                    channelID:_channelID];+  return newOptions;+}++@end++@implementation GRPCMutableCallOptions++@dynamic serverAuthority;+@dynamic timeout;+@dynamic oauth2AccessToken;+@dynamic authTokenProvider;+@dynamic initialMetadata;+@dynamic userAgentPrefix;+@dynamic responseSizeLimit;+@dynamic compressAlgorithm;+@dynamic enableRetry;+@dynamic keepaliveInterval;+@dynamic keepaliveTimeout;+@dynamic connectMinTimeout;+@dynamic connectInitialBackoff;+@dynamic connectMaxBackoff;+@dynamic additionalChannelArgs;+@dynamic PEMRootCertificates;+@dynamic PEMPrivateKey;+@dynamic PEMCertChain;+@dynamic transportType;+@dynamic hostNameOverride;+@dynamic logContext;+@dynamic channelPoolDomain;+@dynamic channelID;++- (instancetype)init {+  return [self initWithServerAuthority:kDefaultServerAuthority+                               timeout:kDefaultTimeout+                     oauth2AccessToken:kDefaultOauth2AccessToken+                     authTokenProvider:kDefaultAuthTokenProvider+                       initialMetadata:kDefaultInitialMetadata+                       userAgentPrefix:kDefaultUserAgentPrefix+                     responseSizeLimit:kDefaultResponseSizeLimit+                     compressAlgorithm:kDefaultCompressAlgorithm+                           enableRetry:kDefaultEnableRetry+                     keepaliveInterval:kDefaultKeepaliveInterval+                      keepaliveTimeout:kDefaultKeepaliveTimeout+                     connectMinTimeout:kDefaultConnectMinTimeout+                 connectInitialBackoff:kDefaultConnectInitialBackoff+                     connectMaxBackoff:kDefaultConnectMaxBackoff+                 additionalChannelArgs:kDefaultAdditionalChannelArgs+                    PEMRootCertificates:kDefaultPEMRootCertificates+                         PEMPrivateKey:kDefaultPEMPrivateKey+                          PEMCertChain:kDefaultPEMCertChain+                         transportType:kDefaultTransportType+                      hostNameOverride:kDefaultHostNameOverride+                            logContext:kDefaultLogContext+                     channelPoolDomain:kDefaultChannelPoolDomain+                             channelID:kDefaultChannelID];+}++- (nonnull id)copyWithZone:(NSZone *)zone {+  GRPCCallOptions *newOptions =+      [[GRPCCallOptions allocWithZone:zone] initWithServerAuthority:_serverAuthority+                                                            timeout:_timeout+                                                  oauth2AccessToken:_oauth2AccessToken+                                                  authTokenProvider:_authTokenProvider+                                                    initialMetadata:_initialMetadata+                                                    userAgentPrefix:_userAgentPrefix+                                                  responseSizeLimit:_responseSizeLimit+                                                  compressAlgorithm:_compressAlgorithm+                                                        enableRetry:_enableRetry+                                                  keepaliveInterval:_keepaliveInterval+                                                   keepaliveTimeout:_keepaliveTimeout+                                                  connectMinTimeout:_connectMinTimeout+                                              connectInitialBackoff:_connectInitialBackoff+                                                  connectMaxBackoff:_connectMaxBackoff+                                              additionalChannelArgs:[_additionalChannelArgs copy]+                                                 PEMRootCertificates:_PEMRootCertificates+                                                      PEMPrivateKey:_PEMPrivateKey+                                                       PEMCertChain:_PEMCertChain+                                                      transportType:_transportType+                                                   hostNameOverride:_hostNameOverride+                                                         logContext:_logContext+                                                  channelPoolDomain:_channelPoolDomain+                                                          channelID:_channelID];+  return newOptions;+}++- (nonnull id)mutableCopyWithZone:(NSZone *)zone {+  GRPCMutableCallOptions *newOptions = [[GRPCMutableCallOptions allocWithZone:zone]+      initWithServerAuthority:_serverAuthority+                      timeout:_timeout+            oauth2AccessToken:_oauth2AccessToken+            authTokenProvider:_authTokenProvider+              initialMetadata:_initialMetadata+              userAgentPrefix:_userAgentPrefix+            responseSizeLimit:_responseSizeLimit+            compressAlgorithm:_compressAlgorithm+                  enableRetry:_enableRetry+            keepaliveInterval:_keepaliveInterval+             keepaliveTimeout:_keepaliveTimeout+            connectMinTimeout:_connectMinTimeout+        connectInitialBackoff:_connectInitialBackoff+            connectMaxBackoff:_connectMaxBackoff+        additionalChannelArgs:[_additionalChannelArgs copy]+           PEMRootCertificates:_PEMRootCertificates+                PEMPrivateKey:_PEMPrivateKey+                 PEMCertChain:_PEMCertChain+                transportType:_transportType+             hostNameOverride:_hostNameOverride+                   logContext:_logContext+            channelPoolDomain:_channelPoolDomain+                    channelID:_channelID];+  return newOptions;+}++- (void)setServerAuthority:(NSString *)serverAuthority {+  _serverAuthority = [serverAuthority copy];+}++- (void)setTimeout:(NSTimeInterval)timeout {+  if (timeout < 0) {+    _timeout = 0;+  } else {+    _timeout = timeout;+  }+}++- (void)setOauth2AccessToken:(NSString *)oauth2AccessToken {+  _oauth2AccessToken = [oauth2AccessToken copy];+}++- (void)setAuthTokenProvider:(id<GRPCAuthorizationProtocol>)authTokenProvider {+  _authTokenProvider = authTokenProvider;",Maybe you want to validate that if this is set then `_oauth2AccessToken` is nil and vice versa (to prevent clients to accidentally populate the two properties) as according the header they are mutually exclusive.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16904,225975648,2018-10-17T15:14:50Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -545,23 +553,56 @@ static void on_resolver_result_changed_locked(void* arg, grpc_error* error) {         gpr_log(GPR_INFO, ""chand=%p: updating existing LB policy \""%s\"" (%p)"",                 chand, lb_policy_name.get(), chand->lb_policy.get());       }-      chand->lb_policy->UpdateLocked(*chand->resolver_result);+      // case (b) or (c)+      trace_this_address_resolution =+          chand->lb_policy->UpdateLocked(*chand->resolver_result);       // No need to set the channel's connectivity state; the existing       // watch on the LB policy will take care of that.       set_connectivity_state = false;     } else {+      trace_this_address_resolution = true;  // case (d)       // Instantiate new LB policy.       create_new_lb_policy_locked(chand, lb_policy_name.get(),                                   &connectivity_state, &connectivity_error);+      // we also log the name of the new LB policy in addition to logging this+      // resolution event.+      if (chand->channelz_channel != nullptr) {+        char* str;+        gpr_asprintf(&str, ""Switched LB policy to %s"", lb_policy_name.get());+        chand->channelz_channel->AddTraceEvent(+            grpc_core::channelz::ChannelTrace::Severity::Info,+            grpc_slice_from_copied_string(str));+        gpr_free(str);+      }     }     // Find service config.     grpc_core::UniquePtr<char> service_config_json =         get_service_config_from_resolver_result_locked(chand);+    if ((service_config_json == nullptr &&","Need to duplicate the comment from line 543 here, because `chand->info_service_config_json` is protected by the same mutex.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16904,225979705,2018-10-17T15:24:43Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -545,23 +553,56 @@ static void on_resolver_result_changed_locked(void* arg, grpc_error* error) {         gpr_log(GPR_INFO, ""chand=%p: updating existing LB policy \""%s\"" (%p)"",                 chand, lb_policy_name.get(), chand->lb_policy.get());       }-      chand->lb_policy->UpdateLocked(*chand->resolver_result);+      // case (b) or (c)+      trace_this_address_resolution =+          chand->lb_policy->UpdateLocked(*chand->resolver_result);       // No need to set the channel's connectivity state; the existing       // watch on the LB policy will take care of that.       set_connectivity_state = false;     } else {+      trace_this_address_resolution = true;  // case (d)       // Instantiate new LB policy.       create_new_lb_policy_locked(chand, lb_policy_name.get(),                                   &connectivity_state, &connectivity_error);+      // we also log the name of the new LB policy in addition to logging this+      // resolution event.+      if (chand->channelz_channel != nullptr) {+        char* str;+        gpr_asprintf(&str, ""Switched LB policy to %s"", lb_policy_name.get());+        chand->channelz_channel->AddTraceEvent(+            grpc_core::channelz::ChannelTrace::Severity::Info,+            grpc_slice_from_copied_string(str));+        gpr_free(str);+      }     }     // Find service config.     grpc_core::UniquePtr<char> service_config_json =         get_service_config_from_resolver_result_locked(chand);+    if ((service_config_json == nullptr &&+         chand->info_service_config_json != nullptr) ||+        (service_config_json != nullptr &&+         chand->info_service_config_json == nullptr) ||+        (service_config_json != nullptr &&+         chand->info_service_config_json != nullptr &&+         gpr_stricmp(service_config_json.get(),+                     chand->info_service_config_json.get()) != 0)) {+      trace_this_address_resolution = true;  // case (a)+      if (chand->channelz_channel != nullptr) {+        chand->channelz_channel->AddTraceEvent(+            grpc_core::channelz::ChannelTrace::Severity::Info,+            grpc_slice_from_static_string(""Service config reloaded""));+      }+    }     // Swap out the data used by cc_get_channel_info().     gpr_mu_lock(&chand->info_mu);     chand->info_lb_policy_name = std::move(lb_policy_name);     chand->info_service_config_json = std::move(service_config_json);     gpr_mu_unlock(&chand->info_mu);+    if (trace_this_address_resolution && chand->channelz_channel != nullptr) {+      chand->channelz_channel->AddTraceEvent(","Instead of having 3 different trace events for the different cases here, can we combine them into a single case?  For example, we could have an `InlinedVector<>` of strings and then add a string to it for each of the cases that is true (e.g., ""switched LB policy to pick_first"" or ""address list became {non-,}empty"").  Then at the end, if the `InlinedVector<>` is not empty, we can log a single event that concatenates the strings it contains.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16904,225980503,2018-10-17T15:26:40Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -545,23 +553,56 @@ static void on_resolver_result_changed_locked(void* arg, grpc_error* error) {         gpr_log(GPR_INFO, ""chand=%p: updating existing LB policy \""%s\"" (%p)"",                 chand, lb_policy_name.get(), chand->lb_policy.get());       }-      chand->lb_policy->UpdateLocked(*chand->resolver_result);+      // case (b) or (c)+      trace_this_address_resolution =+          chand->lb_policy->UpdateLocked(*chand->resolver_result);       // No need to set the channel's connectivity state; the existing       // watch on the LB policy will take care of that.       set_connectivity_state = false;     } else {+      trace_this_address_resolution = true;  // case (d)       // Instantiate new LB policy.       create_new_lb_policy_locked(chand, lb_policy_name.get(),                                   &connectivity_state, &connectivity_error);+      // we also log the name of the new LB policy in addition to logging this+      // resolution event.+      if (chand->channelz_channel != nullptr) {+        char* str;+        gpr_asprintf(&str, ""Switched LB policy to %s"", lb_policy_name.get());+        chand->channelz_channel->AddTraceEvent(+            grpc_core::channelz::ChannelTrace::Severity::Info,+            grpc_slice_from_copied_string(str));+        gpr_free(str);+      }     }     // Find service config.     grpc_core::UniquePtr<char> service_config_json =         get_service_config_from_resolver_result_locked(chand);+    if ((service_config_json == nullptr &&+         chand->info_service_config_json != nullptr) ||+        (service_config_json != nullptr &&+         chand->info_service_config_json == nullptr) ||+        (service_config_json != nullptr &&+         chand->info_service_config_json != nullptr &&+         gpr_stricmp(service_config_json.get(),+                     chand->info_service_config_json.get()) != 0)) {+      trace_this_address_resolution = true;  // case (a)+      if (chand->channelz_channel != nullptr) {+        chand->channelz_channel->AddTraceEvent(+            grpc_core::channelz::ChannelTrace::Severity::Info,+            grpc_slice_from_static_string(""Service config reloaded""));","Ideally, it would be nice to include the service config string in this message.  But if the config is very long, that could eat up all of our trace memory, which seems sub-optimal.  Maybe we can truncate it to some fixed-size prefix?  Not sure if this is worth doing.",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/16190,226026383,2018-10-17T17:31:55Z,src/objective-c/GRPCClient/private/GRPCChannelPool.h,"@@ -0,0 +1,69 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++/**+ * Signature for the channel. If two channel's signatures are the same, they share the same+ * underlying \a GRPCChannel object.+ */++#import <GRPCClient/GRPCCallOptions.h>++#import ""GRPCChannelFactory.h""++NS_ASSUME_NONNULL_BEGIN++@class GRPCChannel;++@interface GRPCChannelConfiguration : NSObject<NSCopying>++@property(atomic, strong, readwrite) NSString *host;+@property(atomic, strong, readwrite) GRPCCallOptions *callOptions;++@property(readonly) id<GRPCChannelFactory> channelFactory;+@property(readonly) NSMutableDictionary *channelArgs;++- (nullable instancetype)initWithHost:(NSString *)host callOptions:(GRPCCallOptions *)callOptions;++@end++/**+ * Manage the pool of connected channels. When a channel is no longer referenced by any call,+ * destroy the channel after a certain period of time elapsed.+ */+@interface GRPCChannelPool : NSObject++- (instancetype)init;++- (instancetype)initWithChannelDestroyDelay:(NSTimeInterval)channelDestroyDelay;++/**+ * Return a channel with a particular configuration. If the channel does not exist, execute \a+ * createChannel then add it in the pool. If the channel exists, increase its reference count.+ */+- (GRPCChannel *)channelWithConfiguration:(GRPCChannelConfiguration *)configuration+                            createChannel:(GRPCChannel * (^)(void))createChannel;",Not sure if this is a best idea but I was trying to prevent dependency of classes in GRPCChannelPool.h to `GRPCChannel`.,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16904,226062772,2018-10-17T19:20:24Z,src/core/ext/filters/client_channel/lb_policy.h,"@@ -95,7 +95,9 @@ class LoadBalancingPolicy   /// Updates the policy with a new set of \a args from the resolver.   /// Note that the LB policy gets the set of addresses from the   /// GRPC_ARG_LB_ADDRESSES channel arg.-  virtual void UpdateLocked(const grpc_channel_args& args) GRPC_ABSTRACT;+  /// Returns true if the update caused the number of backends to go from",I suggest having the client_channel filter stash a bool in its channel data indicating whether the previous resolution result had a non-zero number of addresses.,
44210700,legerman,https://api.github.com/repos/grpc/grpc/pulls/16190,226075748,2018-10-17T20:04:45Z,src/objective-c/GRPCClient/private/GRPCChannel.m,"@@ -18,206 +18,112 @@  #import ""GRPCChannel.h"" -#include <grpc/grpc_security.h>-#ifdef GRPC_COMPILE_WITH_CRONET-#include <grpc/grpc_cronet.h>-#endif-#include <grpc/support/alloc.h> #include <grpc/support/log.h>-#include <grpc/support/string_util.h> -#ifdef GRPC_COMPILE_WITH_CRONET-#import <Cronet/Cronet.h>-#import <GRPCClient/GRPCCall+Cronet.h>-#endif+#import ""ChannelArgsUtil.h""+#import ""GRPCChannelFactory.h""+#import ""GRPCChannelPool.h"" #import ""GRPCCompletionQueue.h""+#import ""GRPCConnectivityMonitor.h""+#import ""GRPCCronetChannelFactory.h""+#import ""GRPCInsecureChannelFactory.h""+#import ""GRPCSecureChannelFactory.h""+#import ""version.h"" -static void *copy_pointer_arg(void *p) {-  // Add ref count to the object when making copy-  id obj = (__bridge id)p;-  return (__bridge_retained void *)obj;-}--static void destroy_pointer_arg(void *p) {-  // Decrease ref count to the object when destroying-  CFRelease((CFTreeRef)p);-}--static int cmp_pointer_arg(void *p, void *q) { return p == q; }--static const grpc_arg_pointer_vtable objc_arg_vtable = {copy_pointer_arg, destroy_pointer_arg,-                                                        cmp_pointer_arg};--static void FreeChannelArgs(grpc_channel_args *channel_args) {-  for (size_t i = 0; i < channel_args->num_args; ++i) {-    grpc_arg *arg = &channel_args->args[i];-    gpr_free(arg->key);-    if (arg->type == GRPC_ARG_STRING) {-      gpr_free(arg->value.string);-    }-  }-  gpr_free(channel_args->args);-  gpr_free(channel_args);-}--/**- * Allocates a @c grpc_channel_args and populates it with the options specified in the- * @c dictionary. Keys must be @c NSString. If the value responds to @c @selector(UTF8String) then- * it will be mapped to @c GRPC_ARG_STRING. If not, it will be mapped to @c GRPC_ARG_INTEGER if the- * value responds to @c @selector(intValue). Otherwise, an exception will be raised. The caller of- * this function is responsible for calling @c freeChannelArgs on a non-NULL returned value.- */-static grpc_channel_args *BuildChannelArgs(NSDictionary *dictionary) {-  if (!dictionary) {-    return NULL;-  }--  NSArray *keys = [dictionary allKeys];-  NSUInteger argCount = [keys count];--  grpc_channel_args *channelArgs = gpr_malloc(sizeof(grpc_channel_args));-  channelArgs->num_args = argCount;-  channelArgs->args = gpr_malloc(argCount * sizeof(grpc_arg));--  // TODO(kriswuollett) Check that keys adhere to GRPC core library requirements--  for (NSUInteger i = 0; i < argCount; ++i) {-    grpc_arg *arg = &channelArgs->args[i];-    arg->key = gpr_strdup([keys[i] UTF8String]);--    id value = dictionary[keys[i]];-    if ([value respondsToSelector:@selector(UTF8String)]) {-      arg->type = GRPC_ARG_STRING;-      arg->value.string = gpr_strdup([value UTF8String]);-    } else if ([value respondsToSelector:@selector(intValue)]) {-      arg->type = GRPC_ARG_INTEGER;-      arg->value.integer = [value intValue];-    } else if (value != nil) {-      arg->type = GRPC_ARG_POINTER;-      arg->value.pointer.p = (__bridge_retained void *)value;-      arg->value.pointer.vtable = &objc_arg_vtable;-    } else {-      [NSException raise:NSInvalidArgumentException-                  format:@""Invalid value type: %@"", [value class]];-    }-  }--  return channelArgs;-}+#import <GRPCClient/GRPCCall+Cronet.h>+#import <GRPCClient/GRPCCallOptions.h>  @implementation GRPCChannel {-  // Retain arguments to channel_create because they may not be used on the thread that invoked-  // the channel_create function.-  NSString *_host;-  grpc_channel_args *_channelArgs;+  GRPCChannelConfiguration *_configuration;+  grpc_channel *_unmanagedChannel; } -#ifdef GRPC_COMPILE_WITH_CRONET-- (instancetype)initWithHost:(NSString *)host-                cronetEngine:(stream_engine *)cronetEngine-                 channelArgs:(NSDictionary *)channelArgs {-  if (!host) {-    [NSException raise:NSInvalidArgumentException format:@""host argument missing""];+- (grpc_call *)unmanagedCallWithPath:(NSString *)path+                     completionQueue:(nonnull GRPCCompletionQueue *)queue+                         callOptions:(GRPCCallOptions *)callOptions {","Given that all of these parameters are marked as nonnull, would it make sense to assert on them if they are nil?```GPR_ASSERT(path.length);GPR_ASSERT(queue);GPR_ASSERT(callOptions);```",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/15754,226236219,2018-10-18T09:36:28Z,src/csharp/INTEGRATION.md,"@@ -0,0 +1,357 @@+Protocol Buffers/gRPC Integration Into .NET Build+=================================================++With Grpc.Tools package version 1.17 we made it easier to compile .proto files+in your project using the `dotnet build` command, Visual Studio, or command-line+MSBuild. You need to configure the .csproj project according to the way you want+to integrate Protocol Buffer files into your build. If you are upgrading an+existing project, read through this list of common scenarios and decide if any+one of them matches your approach. The protoc command line migration is+explained near the end of this document; this migration may be the quickest but+not the long-term solution.++There is also a Reference section at the end of the file.++Reporting issues+----------------++First thing first, if you found a bug in this new build system, or have a+scenario that is not easily covered, please open an [issue in the gRPC+repository](https://github.com/grpc/grpc/issues), and **tag the user @kkm000**+somewhere in the text (for example, include `/cc @kkm000` at end of the issue+text) to seize his immediate attention.++Common scenarios+----------------++### I just want to compile .proto files into my library++This is the approach taken by the examples in the `csharp/examples` directory.+Protoc output files (for example, `Hello.cs` and `HelloGrps.cs` compiled from+`hello.proto`) are placed among *object* and other temporary files of your+project, and automatically provided as inputs to the C# compiler. As with other+automatically generated .cs files, they are included in the source and symbols+NuGet package, if you build one.++Simply reference your .proto files in a `<Protobuf>` item group. The following+example will add all .proto files in a project and all its subdirectories+(excluding special directories such as `bin` and `obj`):++```xml+  <ItemGroup>+    <Protobuf Include=""**/*.proto"" />+  </ItemGroup>+```++You must add a reference to the Nuget packages Grpc.Tools and Grpc (the latter+is a meta-package, in turn referencing Grpc.Core and Google.Protobuf packages).+It is **very important** to mark Grpc.Tools as a development-only dependency, so+that the *users* of your library do not fetch the tools package:++* ""Classic"" .csproj with `packages.config` (Visual Studio, Mono): This is+ handled automatically by NuGet. See the attribute added to the+ [helloworld/packages.config] file by Visual Studio.","btw, the layout of `examples/csharp` has been changed in the meantime.   ""Helloworld"" now has the new-style csproj for dotnet SDK and ""HelloworldLegacyCsproj"" has the legacy projects. I usually call them ""Legacy"" rather than ""Classic"" btw.",OK
8228229,kkm000,https://api.github.com/repos/grpc/grpc/pulls/15754,226351930,2018-10-18T15:24:59Z,src/csharp/INTEGRATION.md,"@@ -0,0 +1,357 @@+Protocol Buffers/gRPC Integration Into .NET Build","Most regular developers have no idea what MSBuild is, and are hardly aware that they are in fact using it when hitting Shift+Ctrl+B for ""Build"" in Visual Studio or typing `dotnet build`; I'd rather avoid mentioning it in a file name. The common theme is ""build"" here; BUILD-INTEGRATION.md maybe then?Or TOOLS-NUGET-PACKAGE.md?CODEGEN etc. sounds also less appealing, looking through the user's eyes. As in ""I want to compile proto files."" The documentation refers to protoc as the Protocol Buffer compiler; codegen may be perceived as just a teensy option to it. I'm afraid CODEGEN would not ring the bell when seen from the user's perspective.But overall, I think that a link from README will go a long way toward rendering the name choice not very important. Absolutely most people read README files on GitHub these days, not looking for one after unpacking a tarball--not .NET users, certainly. Just let me know what name you pefer.From your other comment:>  I usually call them ""Legacy"" rather than ""Classic"" btw.I never heard them called legacy anywhere in MS' own and related development. The operational jargon is ""Classic projects"" vs ""SDK projects"" (or s/project/build/ when speaking of the process, not file format). FWIW, the ""classic"" is not obsolete; they in fact now support ProjectReference, just like SDK projects, with NuGet tasks integrated into MBuild, in lieu of packages.conf (which relied on a plugin shipped with VS to modify the .csproj content). Or maybe I was just spending too much time digging through MSBuld, netcore and NuGet repositories while working on our thing. :)One point statistics is not convincing, but here's a single example I just happened to hit first: a Googler discusses an issue with an MSBuild architect in this jargon: https://github.com/Microsoft/msbuild/issues/3546. I'd go with Classic even in the example name, if I were to choose. When I first seen it renamed to HelloWorldLegacy, it fell on my ear as not exactly right. Yes, I'm biased, but it seems I'm biased in the right direction this time. :)I could not find any named ""official"" names in the documentation (docs.microsoft.com), so we are drawing a blank here. .NET project, Visual Stdio project. Boring. Even my cats have names, although they also do not care...",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16904,226374325,2018-10-18T16:21:02Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -553,10 +565,69 @@ static void on_resolver_result_changed_locked(void* arg, grpc_error* error) {       // Instantiate new LB policy.       create_new_lb_policy_locked(chand, lb_policy_name.get(),                                   &connectivity_state, &connectivity_error);+      if (chand->channelz_channel != nullptr) {+        char* str;+        gpr_asprintf(&str, ""Switched LB policy to %s"", lb_policy_name.get());+        trace_strings.push_back(str);+      }     }     // Find service config.     grpc_core::UniquePtr<char> service_config_json =         get_service_config_from_resolver_result_locked(chand);+    // Note: It's safe to use chand->info_service_config_json here without+    // taking a lock on chand->info_mu, because this function is the+    // only thing that modifies its value, and it can only be invoked+    // once at any given time.+    if (chand->channelz_channel != nullptr) {+      if ((service_config_json == nullptr &&+           chand->info_service_config_json != nullptr) ||+          (service_config_json != nullptr &&+           chand->info_service_config_json == nullptr) ||+          (service_config_json != nullptr &&+           chand->info_service_config_json != nullptr &&","No need for this line.  If `service_config_json != nullptr`, then this must be true, since otherwise the conditions above would have been false.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16904,226375562,2018-10-18T16:24:38Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -131,6 +131,8 @@ typedef struct client_channel_channel_data {   grpc_core::UniquePtr<char> info_service_config_json;   /* backpointer to grpc_channel's channelz node */   grpc_core::channelz::ClientChannelNode* channelz_channel;+  /* caches if the last resolution event led to zero addresses */+  bool previous_resolution_zero_num_addresses;",Suggest reversing the semantics of this: it should be true if the previous resolution had a non-zero number of addresses.  I think that makes it a little more intuitive to understand.,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16904,226380098,2018-10-18T16:36:27Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -553,10 +565,69 @@ static void on_resolver_result_changed_locked(void* arg, grpc_error* error) {       // Instantiate new LB policy.       create_new_lb_policy_locked(chand, lb_policy_name.get(),                                   &connectivity_state, &connectivity_error);+      if (chand->channelz_channel != nullptr) {+        char* str;+        gpr_asprintf(&str, ""Switched LB policy to %s"", lb_policy_name.get());+        trace_strings.push_back(str);+      }     }     // Find service config.     grpc_core::UniquePtr<char> service_config_json =         get_service_config_from_resolver_result_locked(chand);+    // Note: It's safe to use chand->info_service_config_json here without","Suggest moving this new code into a separate helper function, since this one is already fairly large.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16913,226431473,2018-10-18T19:13:16Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc,"@@ -356,15 +356,12 @@ static void on_txt_done_locked(void* arg, int status, int timeouts,   grpc_ares_request_unref_locked(r); } -static grpc_ares_request*-grpc_dns_lookup_ares_continue_after_check_localhost_and_ip_literals_locked(-    const char* dns_server, const char* name, const char* default_port,-    grpc_pollset_set* interested_parties, grpc_closure* on_done,-    grpc_lb_addresses** addrs, bool check_grpclb, char** service_config_json,-    grpc_combiner* combiner) {+void grpc_dns_lookup_ares_continue_after_check_localhost_and_ip_literals_locked(+    grpc_ares_request* r, const char* dns_server, const char* name,+    const char* default_port, grpc_pollset_set* interested_parties,+    grpc_closure* on_done, bool check_grpclb, grpc_combiner* combiner) {","The `on_done` parameter isn't needed anymore, since it's passed in with `r`.",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/16190,226434932,2018-10-18T19:25:06Z,src/objective-c/GRPCClient/private/GRPCWrappedCall.m,"@@ -313,6 +311,8 @@ - (void)cancel {  - (void)dealloc {   grpc_call_unref(_call);+  [_channel unmanagedCallUnref];",Call completion is not recognized in the wrapped call but in `GRPCCall`. Passing this information in means some more holes on the interface of wrapped call. I tend to leave it this way unless there's any big concern with this approach,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16930,226563784,2018-10-19T08:06:35Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/dns_resolver_ares.cc,"@@ -197,25 +200,24 @@ void AresDnsResolver::ResetBackoffLocked() { }  void AresDnsResolver::ShutdownLocked() {+  shutdown_initiated_ = true;   if (have_next_resolution_timer_) {     grpc_timer_cancel(&next_resolution_timer_);   }   if (pending_request_ != nullptr) {     grpc_cancel_ares_request(pending_request_);   }-  if (next_completion_ != nullptr) {-    *target_result_ = nullptr;-    GRPC_CLOSURE_SCHED(next_completion_, GRPC_ERROR_CREATE_FROM_STATIC_STRING(-                                             ""Resolver Shutdown""));-    next_completion_ = nullptr;-  } }  void AresDnsResolver::OnNextResolutionLocked(void* arg, grpc_error* error) {   AresDnsResolver* r = static_cast<AresDnsResolver*>(arg);+  gpr_log(GPR_DEBUG,","I actually [added this in](https://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.h#L31) earlier :) when adding windows, but haven't converted logs to use it.I could convert this PR over to use that if we want, or defer to another PR",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16930,226568573,2018-10-19T08:25:30Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/dns_resolver_ares.cc,"@@ -366,7 +368,9 @@ void AresDnsResolver::OnResolvedLocked(void* arg, grpc_error* error) {   }   r->resolved_result_ = result;   ++r->resolved_version_;-  r->MaybeFinishNextLocked();+  if (!r->shutdown_initiated_) {","Hmm, I've been thinking through this one but am still not sure how best to do this yet. Agree that we can prevent initializing a timer if shutdown has been initiated, but I think the check still needs to take place above in the timer callback's `StartResolvingLocked`, just to prevent the potential race of:1) expired re-resolution timer is scheduled with `GRPC_ERROR_NONE`2) ShutdownLocked is ran3) re-resolution is timer callback is ran with `GRPC_ERROR_NONE` and so starts resolvingAs for this check around `MaybeFinishNextLocked`, I originally put this there to prevent scheduling `next_completion` <i>without</i> an error after `ShutdownLocked` has been ran - to try to avoid ""dropping a shutdown"". But I now see that the [client channel](https://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/client_channel.cc#L515) handles this ""race"" already. However, with this setup I think that with this the problem of `AresDNSResolver` out-living it's channel and potentially accessing a free'd pollset set still exists, because AFAICS there's nothing stopping the channel from dropping it's [resolver ref](https://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/client_channel.cc#L347) <i>after</i> orphaning it's resolver but <i>before</i> the resolver's `ShutdownLocked` is called, in the case that a query completion races with resolver shutdown..... would it make sense to just have `AresDNSResolver` directly take an extra ref on the channel stack, to keep it's pollset set alive? Might try to chat about this tomorrow.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16898,226697395,2018-10-19T15:57:24Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -1268,6 +1273,51 @@ static void resume_pending_batch_in_call_combiner(void* arg,   grpc_subchannel_call_process_op(subchannel_call, batch); } +// The callback to intercept trailing metadata if retries is not enabled+static void recv_trailing_metadata_ready_for_lb(void* arg, grpc_error* error) {","Instead of putting these functions in the section for the pending-batch code, please move them down to into the ""LB pick"" section (starting at line 2637).  If you need a forward declaration for `maybe_intercept_trailing_metadata_for_lb()`, that's fine.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16898,226697971,2018-10-19T15:59:07Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -932,6 +932,11 @@ typedef struct client_channel_call_data {   grpc_core::LoadBalancingPolicy::PickState pick;   grpc_closure pick_closure;   grpc_closure pick_cancel_closure;+  // A closure to fork notifying the lb interceptor and run the original trailer+  // interception callback.+  grpc_closure lb_intercept_recv_trailing_metadata_ready;",This code tends to use the convention that the grpc_closure object has the same name as the function that the closure calls.  So I suggest naming this `recv_trailing_metadata_ready_for_lb`.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16898,226698028,2018-10-19T15:59:18Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -932,6 +932,11 @@ typedef struct client_channel_call_data {   grpc_core::LoadBalancingPolicy::PickState pick;   grpc_closure pick_closure;   grpc_closure pick_cancel_closure;+  // A closure to fork notifying the lb interceptor and run the original trailer+  // interception callback.+  grpc_closure lb_intercept_recv_trailing_metadata_ready;+  // The original trailer interception callback.+  grpc_closure* before_lb_intercept_recv_trailing_metadata_ready;",Suggest calling this `original_recv_trailing_metadata_ready`.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16898,226699258,2018-10-19T16:03:03Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -1268,6 +1273,51 @@ static void resume_pending_batch_in_call_combiner(void* arg,   grpc_subchannel_call_process_op(subchannel_call, batch); } +// The callback to intercept trailing metadata if retries is not enabled+static void recv_trailing_metadata_ready_for_lb(void* arg, grpc_error* error) {+  subchannel_batch_data* batch_data = static_cast<subchannel_batch_data*>(arg);+  grpc_call_element* elem = batch_data->elem;+  call_data* calld = static_cast<call_data*>(elem->call_data);+  GPR_ASSERT(calld->pick.recv_trailing_metadata_ready != nullptr);+  GPR_ASSERT(calld->pick.recv_trailing_metadata != nullptr);++  GRPC_CLOSURE_SCHED(+      calld->pick.recv_trailing_metadata_ready,+      GRPC_ERROR_REF(error));+  calld->pick.recv_trailing_metadata = nullptr;+  calld->pick.recv_trailing_metadata_ready = nullptr;++  GRPC_CLOSURE_RUN(+      calld->before_lb_intercept_recv_trailing_metadata_ready,+      GRPC_ERROR_REF(error));+}++// Installs a interceptor to inform the lb of the trailing metadata, if needed+static void maybe_intercept_trailing_metadata_for_lb(+    void* arg, grpc_transport_stream_op_batch* batch) {+  subchannel_batch_data* batch_data = static_cast<subchannel_batch_data*>(arg);+  grpc_call_element* elem = batch_data->elem;+  call_data* calld = static_cast<call_data*>(elem->call_data);+  if (calld->pick.recv_trailing_metadata_ready != nullptr) {+    GPR_ASSERT(calld->pick.recv_trailing_metadata != nullptr);","I think we should not require this to be non-null, since they might be use-cases where the LB policy wants to know when the call is complete but doesn't actually need to see the trailing metadata.  In that case, it might request a callback but not require us to set the metadata.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16898,226700395,2018-10-19T16:06:40Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -1990,6 +2042,16 @@ static void recv_trailing_metadata_ready(void* arg, grpc_error* error) {   }   // Not retrying, so commit the call.   retry_commit(elem, retry_state);+  // Now that the try is committed, give the trailer to the lb policy as needed+  if (calld->pick.recv_trailing_metadata_ready != nullptr) {+    GPR_ASSERT(calld->pick.recv_trailing_metadata != nullptr);","See above -- we probably want to allow LB policies to set the callback without requesting the metadata, so we should allow this to be null.",OK
2819812,zpencer,https://api.github.com/repos/grpc/grpc/pulls/16898,226704158,2018-10-19T16:19:31Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -932,6 +932,11 @@ typedef struct client_channel_call_data {   grpc_core::LoadBalancingPolicy::PickState pick;   grpc_closure pick_closure;   grpc_closure pick_cancel_closure;+  // A closure to fork notifying the lb interceptor and run the original trailer+  // interception callback.+  grpc_closure lb_intercept_recv_trailing_metadata_ready;+  // The original trailer interception callback.+  grpc_closure* before_lb_intercept_recv_trailing_metadata_ready;",I was trying to capture the fact that this was whatever existed prior to recv_trailing_metadata_ready_for_lb. the What would be the convention if there were multiple optional interceptors?,
2819812,zpencer,https://api.github.com/repos/grpc/grpc/pulls/16898,226705068,2018-10-19T16:22:56Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -1268,6 +1273,51 @@ static void resume_pending_batch_in_call_combiner(void* arg,   grpc_subchannel_call_process_op(subchannel_call, batch); } +// The callback to intercept trailing metadata if retries is not enabled+static void recv_trailing_metadata_ready_for_lb(void* arg, grpc_error* error) {+  subchannel_batch_data* batch_data = static_cast<subchannel_batch_data*>(arg);+  grpc_call_element* elem = batch_data->elem;+  call_data* calld = static_cast<call_data*>(elem->call_data);+  GPR_ASSERT(calld->pick.recv_trailing_metadata_ready != nullptr);",Changed the code to check for `calld->pick.recv_trailing_metadata != nullptr`,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16930,226705554,2018-10-19T16:24:47Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/dns_resolver_ares.cc,"@@ -164,7 +163,11 @@ AresDnsResolver::~AresDnsResolver() {   if (resolved_result_ != nullptr) {     grpc_channel_args_destroy(resolved_result_);   }-  grpc_pollset_set_destroy(interested_parties_);+  if (next_completion_ != nullptr) {+    GRPC_CLOSURE_SCHED(next_completion_, GRPC_ERROR_CREATE_FROM_STATIC_STRING(","I think the behavior we want is as follows:- If there is a pending c-ares request when we are shut down, then we cancel the query.  This causes `OnResolvedLocked()` to be invoked immediately, and it should trigger the callback to the client channel with a shutdown error.- If there is a pending timer when we are shut down, then we cancel the timer.  This causes `OnNextResolutionLocked()` to be invoked immediately, and it should trigger the callback to the client channel with a shutdown error.The basic idea here is that for any given async operation that we kick off, whether that operation is an ares query or a timer, we should terminate the operation early, thus triggering the completion callback for that operation.  The completion callback should be responsible for checking whether we have been shut down and reacting accordingly.  That way, we can avoid race conditions and be sure that we are only invoking the callback to the client channel once.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16898,226715999,2018-10-19T17:00:07Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -2638,6 +2593,39 @@ static void start_retriable_subchannel_batches(void* arg, grpc_error* ignored) { // LB pick // +// The callback to intercept trailing metadata if retries is not enabled+static void recv_trailing_metadata_ready_for_lb(void* arg, grpc_error* error) {+  subchannel_batch_data* batch_data = static_cast<subchannel_batch_data*>(arg);+  grpc_call_element* elem = batch_data->elem;+  call_data* calld = static_cast<call_data*>(elem->call_data);+  if (calld->pick.recv_trailing_metadata != nullptr) {+    *calld->pick.recv_trailing_metadata =+        batch_data->batch.payload->recv_trailing_metadata+            .recv_trailing_metadata;+  }+  GRPC_CLOSURE_SCHED(+      calld->pick.recv_trailing_metadata_ready,+      GRPC_ERROR_REF(error));+  GRPC_CLOSURE_RUN(+      calld->original_recv_trailing_metadata_ready,+      GRPC_ERROR_REF(error));+}++// Installs a interceptor to inform the lb of the trailing metadata, if needed","Terminology nit: We don't refer to these callbacks as ""interceptors""; that term refers to a higher-level interface in the C++ layer (or that of other wrapped languages).  In the context of this code, it's not unreasonable to use ""intercept"" as a generic verb, so I would say something like ""If needed, intercepts the recv_trailing_metadata_ready callback to return trailing metadata to the LB policy"".",OK
2819812,zpencer,https://api.github.com/repos/grpc/grpc/pulls/16898,226719342,2018-10-19T17:12:08Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -2043,15 +2001,12 @@ static void recv_trailing_metadata_ready_for_retries(   // Not retrying, so commit the call.   retry_commit(elem, retry_state);   // Now that the try is committed, give the trailer to the lb policy as needed","This means the lb recv_trailing_metadata_ready callback can be called more than once. Do we need some way to notify the lb when the call is finally committed?At the very least, I think we might need to change it to GRPC_CLOSURE_RUN() to run the callback synchronously at the top, because it seems like the retries code path owns the metadata and may modify it before the lb callback gets a chance to run.What do you think?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16898,226723401,2018-10-19T17:26:21Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -2043,15 +2001,12 @@ static void recv_trailing_metadata_ready_for_retries(   // Not retrying, so commit the call.   retry_commit(elem, retry_state);   // Now that the try is committed, give the trailer to the lb policy as needed","> This means the lb recv_trailing_metadata_ready callback can be called more than once. Do we need some way to notify the lb when the call is finally committed?No.  The LB policy doesn't know anything about retries; from its perspective, each retry attempt is a separate call.  So it doesn't know or care about retries being committed.> At the very least, I think we might need to change it to GRPC_CLOSURE_RUN() to run the callback synchronously at the top, because it seems like the retries code path owns the metadata and may modify it before the lb callback gets a chance to run.Good catch!  I don't think there's an issue of the retry code modifying the metadata, since the retry code uses a different `grpc_metadata_batch` instance for each retry attempt.  But we do need to make sure that we don't free the batch before the LB policy is done with it.  So I think you're right that we should use `GRPC_CLOSURE_RUN()` instead of `GRPC_CLOSURE_SCHED()`.It's probably worth adding a comment here so future readers understand why this is being done with `RUN()` instead of `SCHED()`.",OK
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/16901,226732927,2018-10-19T17:58:35Z,src/core/lib/channel/channelz_registry.cc,"@@ -131,16 +131,12 @@ char* ChannelzRegistry::InternalGetTopChannels(intptr_t start_channel_id) {   grpc_json* json = top_level_json;   grpc_json* json_iterator = nullptr;   InlinedVector<BaseNode*, 10> top_level_channels;-  // uuids index into entities one-off (idx 0 is really uuid 1, since 0 is-  // reserved). However, we want to support requests coming in with-  // start_channel_id=0, which signifies ""give me everything."" Hence this-  // funky looking line below.-  size_t start_idx = start_channel_id == 0 ? 0 : start_channel_id - 1;   bool reached_pagination_limit = false;-  for (size_t i = start_idx; i < entities_.size(); ++i) {+  for (size_t i = 0; i < entities_.size(); ++i) {     if (entities_[i] != nullptr &&         entities_[i]->type() ==-            grpc_core::channelz::BaseNode::EntityType::kTopLevelChannel) {+            grpc_core::channelz::BaseNode::EntityType::kTopLevelChannel &&","You mean O(n) from the queriers POV, right? Since they will have to make m requests for however many requests it takes to get the full dataset?This function's perspective it is O(n), and n will be strictly less than then global_uuid_generator since we do compaction after things unregister themselves",
35056280,srini100,https://api.github.com/repos/grpc/grpc/pulls/16924,226733659,2018-10-19T18:01:02Z,examples/python/helloworld/greeter_client_with_options.py,"@@ -0,0 +1,42 @@+# Copyright 2018 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""The Python implementation of the GRPC helloworld.Greeter client.""""""","Add ""with channel options and call timeout parameters.""",
8943572,carl-mastrangelo,https://api.github.com/repos/grpc/grpc/pulls/16901,226737170,2018-10-19T18:13:04Z,src/core/lib/channel/channelz_registry.cc,"@@ -131,16 +131,12 @@ char* ChannelzRegistry::InternalGetTopChannels(intptr_t start_channel_id) {   grpc_json* json = top_level_json;   grpc_json* json_iterator = nullptr;   InlinedVector<BaseNode*, 10> top_level_channels;-  // uuids index into entities one-off (idx 0 is really uuid 1, since 0 is-  // reserved). However, we want to support requests coming in with-  // start_channel_id=0, which signifies ""give me everything."" Hence this-  // funky looking line below.-  size_t start_idx = start_channel_id == 0 ? 0 : start_channel_id - 1;   bool reached_pagination_limit = false;-  for (size_t i = start_idx; i < entities_.size(); ++i) {+  for (size_t i = 0; i < entities_.size(); ++i) {     if (entities_[i] != nullptr &&         entities_[i]->type() ==-            grpc_core::channelz::BaseNode::EntityType::kTopLevelChannel) {+            grpc_core::channelz::BaseNode::EntityType::kTopLevelChannel &&","Hmm yes, O(n) iterations for a single query, but O(n^2) to scan the whole list.   I'm also worried that this has to be done under a lock (unless this is an immutable copy).  Under a high number of connections, the size of this list will grow, but more importantly, new channels will be prevented from being added or removed, which means blocking.",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16930,226737945,2018-10-19T18:15:46Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/dns_resolver_ares.cc,"@@ -164,7 +163,11 @@ AresDnsResolver::~AresDnsResolver() {   if (resolved_result_ != nullptr) {     grpc_channel_args_destroy(resolved_result_);   }-  grpc_pollset_set_destroy(interested_parties_);+  if (next_completion_ != nullptr) {+    GRPC_CLOSURE_SCHED(next_completion_, GRPC_ERROR_CREATE_FROM_STATIC_STRING(","I still have a concern here about the way that the ref from resolver to client channel is dropped. What's to prevent the following race from happening:1) client channel [orphans its resolver](https://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/client_channel.cc#L635), and so schedules resolver's `ShutdownLocked`2) `ShutdownLocked` closure hasn't <i>ran</i> yet. Meanwhile a pending resolution completes and resolver schedules its `next_completion_` without an error3) client channel's `next_completion_` callback is invoked and client channel's resolver `== nullptr` so it proceeds to [shut down](https://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/client_channel.cc#L515). Client channel now drops it's resolver's channel stack ref4) Resolver's `ShutdownLocked` closure is still scheduled but still hasn't ran. Meanwhile: re-resolution timer goes off and we start resolving - at this point we will access channel's pollset set in an unsafe way.",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/16190,226789167,2018-10-19T21:41:03Z,src/objective-c/GRPCClient/GRPCCall.h,"@@ -139,43 +141,137 @@ typedef NS_ENUM(NSUInteger, GRPCErrorCode) {   GRPCErrorCodeDataLoss = 15, }; -/**- * Safety remark of a gRPC method as defined in RFC 2616 Section 9.1- */-typedef NS_ENUM(NSUInteger, GRPCCallSafety) {-  /** Signal that there is no guarantees on how the call affects the server state. */-  GRPCCallSafetyDefault = 0,-  /** Signal that the call is idempotent. gRPC is free to use PUT verb. */-  GRPCCallSafetyIdempotentRequest = 1,-  /** Signal that the call is cacheable and will not affect server state. gRPC is free to use GET-     verb. */-  GRPCCallSafetyCacheableRequest = 2,-};- /**  * Keys used in |NSError|'s |userInfo| dictionary to store the response headers and trailers sent by  * the server.  */ extern id const kGRPCHeadersKey; extern id const kGRPCTrailersKey; +/** An object can implement this protocol to receive responses from server from a call. */+@protocol GRPCResponseHandler <NSObject>++@optional++/** Issued when initial metadata is received from the server. */+- (void)receivedInitialMetadata:(NSDictionary *)initialMetadata;++/**+ * Issued when a message is received from the server. The message may be raw data from the server+ * (when using \a GRPCCall2 directly) or deserialized proto object (when using \a ProtoRPC).+ */+- (void)receivedMessage:(id)message;++/**+ * Issued when a call finished. If the call finished successfully, \a error is nil and \a+ * trainingMetadata consists any trailing metadata received from the server. Otherwise, \a error+ * is non-nil and contains the corresponding error information, including gRPC error codes and+ * error descriptions.+ */+- (void)closedWithTrailingMetadata:(NSDictionary *)trailingMetadata error:(NSError *)error;++@required++/**+ * All the responses must be issued to a user-provided dispatch queue. This property specifies the+ * dispatch queue to be used for issuing the notifications. A serial queue should be provided if+ * the order of responses (initial metadata, message, message, ..., message, trailing metadata)+ * needs to be maintained.+ */+@property(atomic, readonly) dispatch_queue_t dispatchQueue;++@end++/**+ * Call related parameters. These parameters are automatically specified by Protobuf. If directly+ * using the \a GRPCCall2 class, users should specify these parameters manually.+ */+@interface GRPCRequestOptions : NSObject<NSCopying>",I don't think so. However I'm gonna preserve `GRPCCall` like whatever it is today but give annotation to the new classes.,
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/16190,226838134,2018-10-20T19:55:53Z,src/objective-c/GRPCClient/GRPCCall.m,"@@ -52,6 +55,205 @@ @interface GRPCCall ()<GRXWriteable> @property(atomic, strong) NSDictionary *responseHeaders; @property(atomic, strong) NSDictionary *responseTrailers; @property(atomic) BOOL isWaitingForToken;++- (instancetype)initWithHost:(NSString *)host+                        path:(NSString *)path+                  callSafety:(GRPCCallSafety)safety+              requestsWriter:(GRXWriter *)requestsWriter+                 callOptions:(GRPCCallOptions *)callOptions;++@end++@implementation GRPCRequestOptions++- (instancetype)initWithHost:(NSString *)host path:(NSString *)path safety:(GRPCCallSafety)safety {+  if ((self = [super init])) {+    _host = [host copy];+    _path = [path copy];+    _safety = safety;+  }+  return self;+}++- (id)copyWithZone:(NSZone *)zone {+  GRPCRequestOptions *request =+      [[GRPCRequestOptions alloc] initWithHost:_host path:_path safety:_safety];++  return request;+}++@end++@implementation GRPCCall2 {+  GRPCCallOptions *_callOptions;+  id<GRPCResponseHandler> _handler;++  GRPCCall *_call;+  BOOL _initialMetadataPublished;+  GRXBufferedPipe *_pipe;+  dispatch_queue_t _dispatchQueue;+  bool _started;+}++- (instancetype)initWithRequestOptions:(GRPCRequestOptions *)requestOptions+                       responseHandler:(id<GRPCResponseHandler>)responseHandler+                           callOptions:(GRPCCallOptions *)callOptions {+  if (requestOptions.host.length == 0 || requestOptions.path.length == 0) {+    [NSException raise:NSInvalidArgumentException format:@""Neither host nor path can be nil.""];+  }++  if ((self = [super init])) {+    _requestOptions = [requestOptions copy];+    _callOptions = [callOptions copy];+    _handler = responseHandler;+    _initialMetadataPublished = NO;+    _pipe = [GRXBufferedPipe pipe];+    _dispatchQueue = dispatch_queue_create(NULL, DISPATCH_QUEUE_SERIAL);+    _started = NO;+  }++  return self;+}++- (instancetype)initWithRequestOptions:(GRPCRequestOptions *)requestOptions+                       responseHandler:(id<GRPCResponseHandler>)responseHandler {+  return [self initWithRequestOptions:requestOptions responseHandler:responseHandler callOptions:nil];+}++- (void)start {+  dispatch_async(_dispatchQueue, ^{+    if (self->_started) {+      return;+    }+    self->_started = YES;+    if (!self->_callOptions) {+      self->_callOptions = [[GRPCCallOptions alloc] init];+    }++    self->_call = [[GRPCCall alloc] initWithHost:self->_requestOptions.host+                                            path:self->_requestOptions.path+                                      callSafety:self->_requestOptions.safety+                                  requestsWriter:self->_pipe+                                     callOptions:self->_callOptions];+    if (self->_callOptions.initialMetadata) {+      [self->_call.requestHeaders addEntriesFromDictionary:self->_callOptions.initialMetadata];+    }+    id<GRXWriteable> responseWriteable = [[GRXWriteable alloc] initWithValueHandler:^(id value) {+      dispatch_async(self->_dispatchQueue, ^{+        if (self->_handler) {+          NSDictionary *headers = nil;+          if (!self->_initialMetadataPublished) {+            headers = self->_call.responseHeaders;+            self->_initialMetadataPublished = YES;+          }+          if (headers) {+            [self issueInitialMetadata:headers];+          }+          if (value) {+            [self issueMessage:value];+          }+        }+      });+    }+        completionHandler:^(NSError *errorOrNil) {+          dispatch_async(self->_dispatchQueue, ^{+            if (self->_handler) {+              NSDictionary *headers = nil;+              if (!self->_initialMetadataPublished) {+                headers = self->_call.responseHeaders;+                self->_initialMetadataPublished = YES;+              }+              if (headers) {+                [self issueInitialMetadata:headers];+              }+              [self issueClosedWithTrailingMetadata:self->_call.responseTrailers error:errorOrNil];++              // Clean up _handler so that no more responses are reported to the handler.+              self->_handler = nil;++              if (self->_call) {+                [self->_pipe writesFinishedWithError:nil];+                self->_call = nil;+                self->_pipe = nil;+              }+            }+          });+        }];+    [self->_call startWithWriteable:responseWriteable];+  });+}++- (void)cancel {+  dispatch_async(_dispatchQueue, ^{+    if (self->_call) {+      [self->_call cancel];+      self->_call = nil;+      self->_pipe = nil;+    }+    if (self->_handler) {+      id<GRPCResponseHandler> handler = self->_handler;+      dispatch_async(handler.dispatchQueue, ^{+        if ([handler respondsToSelector:@selector(closedWithTrailingMetadata:error:)]) {+          [handler closedWithTrailingMetadata:nil+                                        error:[NSError errorWithDomain:kGRPCErrorDomain+                                                                  code:GRPCErrorCodeCancelled+                                                              userInfo:@{+                                                                         NSLocalizedDescriptionKey :+                                                                           @""Canceled by app""",A bit tricky since `NSDebugDescriptionErrorKey` has been used for more verbose debug message... I'm thinking of two options: leave it as is (i don't know how bad it would be; people have been using it and are fine so far) or concatenate it in `NSDebugDescriptionErrorKey` (might confuse people as they do not find `NSDebugDescriptionErrorKey` any more) and I tend to leave it.,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16937,226910913,2018-10-22T06:49:14Z,tools/interop_matrix/run_interop_matrix_tests.py,"@@ -92,136 +93,149 @@     nargs='?',     help='The gateway to backend services.') -args = argp.parse_args()--print(str(args)) --def find_all_images_for_lang(lang):+def _get_test_images_for_lang(lang, release_arg, image_path_prefix):     """"""Find docker images for a language across releases and runtimes.    Returns dictionary of list of (<tag>, <image-full-path>) keyed by runtime.   """"""-    # Find all defined releases.-    if args.release == 'all':-        releases = ['master'] + client_matrix.get_release_tags(lang)+    if release_arg == 'all':+        # Use all defined releases for given language+        releases = client_matrix.get_release_tags(lang)     else:         # Look for a particular release.-        if args.release not in ['master'-                               ] + client_matrix.get_release_tags(lang):+        if release_arg not in client_matrix.get_release_tags(lang):             jobset.message(                 'SKIPPED',-                '%s for %s is not defined' % (args.release, lang),+                'release %s for %s is not defined' % (release_arg, lang),                 do_newline=True)             return {}-        releases = [args.release]+        releases = [release_arg] -    # TODO(jtattermusch): why do we need to query the existing images/tags?-    # From LANG_RUNTIME_MATRIX and LANG_RELEASE_MATRIX it should be obvious-    # which tags we want to test - and it should be an error if they are-    # missing.     # Images tuples keyed by runtime.     images = {}     for runtime in client_matrix.LANG_RUNTIME_MATRIX[lang]:-        image_path = '%s/grpc_interop_%s' % (args.gcr_path, runtime)-        output = subprocess.check_output([-            'gcloud', 'beta', 'container', 'images', 'list-tags',-            '--format=json', image_path-        ])-        docker_image_list = json.loads(output)-        # All images should have a single tag or no tag.-        # TODO(adelez): Remove tagless images.-        tags = [i['tags'][0] for i in docker_image_list if i['tags']]-        jobset.message(-            'START',-            'Found images for %s: %s' % (image_path, tags),-            do_newline=True)-        skipped = len(docker_image_list) - len(tags)-        jobset.message(-            'SKIPPED',-            'Skipped images (no-tag/unknown-tag): %d' % skipped,-            do_newline=True)-        # Filter tags based on the releases.-        images[runtime] = [(tag, '%s:%s' % (image_path, tag))-                           for tag in tags-                           if tag in releases]+        image_path = '%s/grpc_interop_%s' % (image_path_prefix, runtime)+        images[runtime] = [+            (tag, '%s:%s' % (image_path, tag)) for tag in releases+        ]     return images  -# caches test cases (list of JobSpec) loaded from file.  Keyed by lang and runtime.-def find_test_cases(lang, runtime, release, suite_name):-    """"""Returns the list of test cases from testcase files per lang/release.""""""+def _read_test_cases_file(lang, runtime, release):+    """"""Read test cases from a bash-like file and return a list of commands""""""     testcase_dir = os.path.join(os.path.dirname(__file__), 'testcases')     filename_prefix = lang     if lang == 'csharp':+        # TODO(jtattermusch): remove this odd specialcase         filename_prefix = runtime     # Check to see if we need to use a particular version of test cases.     lang_version = '%s_%s' % (filename_prefix, release)     if lang_version in client_matrix.TESTCASES_VERSION_MATRIX:-        testcases = os.path.join(+        testcase_file = os.path.join(             testcase_dir, client_matrix.TESTCASES_VERSION_MATRIX[lang_version])     else:-        testcases = os.path.join(testcase_dir, '%s__master' % filename_prefix)+        # TODO(jtattermusch): remove the double-underscore, it is pointless+        testcase_file = os.path.join(testcase_dir,+                                     '%s__master' % filename_prefix)++    lines = []+    with open(testcase_file) as f:+        for line in f.readlines():+            line = re.sub('\\#.*$', '', line)  # remove hash comments+            line = line.strip()+            if line and not line.startswith('echo'):+                # Each non-empty line is a treated as a test case command+                lines.append(line)+    return lines+++def _cleanup_docker_image(image):+    jobset.message('START', 'Cleanup docker image %s' % image, do_newline=True)+    dockerjob.remove_image(image, skip_nonexistent=True)+++args = argp.parse_args()+++# caches test cases (list of JobSpec) loaded from file.  Keyed by lang and runtime.+def _generate_test_case_jobspecs(lang, runtime, release, suite_name):+    """"""Returns the list of test cases from testcase files per lang/release.""""""+    testcase_lines = _read_test_cases_file(lang, runtime, release)      job_spec_list = []-    try:-        with open(testcases) as f:-            # Only line start with 'docker run' are test cases.-            for line in f.readlines():-                if line.startswith('docker run'):-                    m = re.search('--test_case=(.*)""', line)-                    shortname = m.group(1) if m else 'unknown_test'-                    m = re.search(-                        '--server_host_override=(.*).sandbox.googleapis.com',-                        line)-                    server = m.group(1) if m else 'unknown_server'--                    # If server_host arg is not None, replace the original-                    # server_host with the one provided or append to the end of-                    # the command if server_host does not appear originally.-                    if args.server_host:-                        if line.find('--server_host=') > -1:-                            line = re.sub('--server_host=[^ ]*',-                                          '--server_host=%s' % args.server_host,-                                          line)-                        else:-                            line = '%s --server_host=%s""' % (line[:-1],-                                                             args.server_host)-                        print(line)--                    spec = jobset.JobSpec(-                        cmdline=line,-                        shortname='%s:%s:%s:%s' % (suite_name, lang, server,-                                                   shortname),-                        timeout_seconds=_TEST_TIMEOUT,-                        shell=True,-                        flake_retries=5 if args.allow_flakes else 0)-                    job_spec_list.append(spec)-            jobset.message(-                'START',-                'Loaded %s tests from %s' % (len(job_spec_list), testcases),-                do_newline=True)-    except IOError as err:-        jobset.message('FAILED', err, do_newline=True)+    for line in testcase_lines:+        m = re.search('--test_case=(.*)""', line)+        shortname = m.group(1) if m else 'unknown_test'+        m = re.search('--server_host_override=(.*).sandbox.googleapis.com',+                      line)+        server = m.group(1) if m else 'unknown_server'++        # If server_host arg is not None, replace the original+        # server_host with the one provided or append to the end of+        # the command if server_host does not appear originally.+        if args.server_host:+            if line.find('--server_host=') > -1:+                line = re.sub('--server_host=[^ ]*',+                              '--server_host=%s' % args.server_host, line)+            else:","with a brief check, all testcases files <i>appear</i> to include `--server_host=`. So, I suspect this `else` clause here is dead code?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16937,226911293,2018-10-22T06:51:50Z,tools/interop_matrix/run_interop_matrix_tests.py,"@@ -92,136 +93,149 @@     nargs='?',     help='The gateway to backend services.') -args = argp.parse_args()--print(str(args)) --def find_all_images_for_lang(lang):+def _get_test_images_for_lang(lang, release_arg, image_path_prefix):     """"""Find docker images for a language across releases and runtimes.    Returns dictionary of list of (<tag>, <image-full-path>) keyed by runtime.   """"""-    # Find all defined releases.-    if args.release == 'all':-        releases = ['master'] + client_matrix.get_release_tags(lang)+    if release_arg == 'all':+        # Use all defined releases for given language+        releases = client_matrix.get_release_tags(lang)     else:         # Look for a particular release.-        if args.release not in ['master'-                               ] + client_matrix.get_release_tags(lang):+        if release_arg not in client_matrix.get_release_tags(lang):             jobset.message(                 'SKIPPED',-                '%s for %s is not defined' % (args.release, lang),+                'release %s for %s is not defined' % (release_arg, lang),                 do_newline=True)             return {}-        releases = [args.release]+        releases = [release_arg] -    # TODO(jtattermusch): why do we need to query the existing images/tags?-    # From LANG_RUNTIME_MATRIX and LANG_RELEASE_MATRIX it should be obvious-    # which tags we want to test - and it should be an error if they are-    # missing.     # Images tuples keyed by runtime.     images = {}     for runtime in client_matrix.LANG_RUNTIME_MATRIX[lang]:-        image_path = '%s/grpc_interop_%s' % (args.gcr_path, runtime)-        output = subprocess.check_output([-            'gcloud', 'beta', 'container', 'images', 'list-tags',-            '--format=json', image_path-        ])-        docker_image_list = json.loads(output)-        # All images should have a single tag or no tag.-        # TODO(adelez): Remove tagless images.-        tags = [i['tags'][0] for i in docker_image_list if i['tags']]-        jobset.message(-            'START',-            'Found images for %s: %s' % (image_path, tags),-            do_newline=True)-        skipped = len(docker_image_list) - len(tags)-        jobset.message(-            'SKIPPED',-            'Skipped images (no-tag/unknown-tag): %d' % skipped,-            do_newline=True)-        # Filter tags based on the releases.-        images[runtime] = [(tag, '%s:%s' % (image_path, tag))-                           for tag in tags-                           if tag in releases]+        image_path = '%s/grpc_interop_%s' % (image_path_prefix, runtime)+        images[runtime] = [+            (tag, '%s:%s' % (image_path, tag)) for tag in releases+        ]     return images  -# caches test cases (list of JobSpec) loaded from file.  Keyed by lang and runtime.-def find_test_cases(lang, runtime, release, suite_name):-    """"""Returns the list of test cases from testcase files per lang/release.""""""+def _read_test_cases_file(lang, runtime, release):+    """"""Read test cases from a bash-like file and return a list of commands""""""     testcase_dir = os.path.join(os.path.dirname(__file__), 'testcases')     filename_prefix = lang     if lang == 'csharp':+        # TODO(jtattermusch): remove this odd specialcase         filename_prefix = runtime     # Check to see if we need to use a particular version of test cases.     lang_version = '%s_%s' % (filename_prefix, release)     if lang_version in client_matrix.TESTCASES_VERSION_MATRIX:-        testcases = os.path.join(+        testcase_file = os.path.join(             testcase_dir, client_matrix.TESTCASES_VERSION_MATRIX[lang_version])     else:-        testcases = os.path.join(testcase_dir, '%s__master' % filename_prefix)+        # TODO(jtattermusch): remove the double-underscore, it is pointless+        testcase_file = os.path.join(testcase_dir,+                                     '%s__master' % filename_prefix)++    lines = []+    with open(testcase_file) as f:+        for line in f.readlines():+            line = re.sub('\\#.*$', '', line)  # remove hash comments+            line = line.strip()+            if line and not line.startswith('echo'):+                # Each non-empty line is a treated as a test case command+                lines.append(line)+    return lines+++def _cleanup_docker_image(image):+    jobset.message('START', 'Cleanup docker image %s' % image, do_newline=True)+    dockerjob.remove_image(image, skip_nonexistent=True)+++args = argp.parse_args()+++# caches test cases (list of JobSpec) loaded from file.  Keyed by lang and runtime.+def _generate_test_case_jobspecs(lang, runtime, release, suite_name):+    """"""Returns the list of test cases from testcase files per lang/release.""""""+    testcase_lines = _read_test_cases_file(lang, runtime, release)      job_spec_list = []-    try:-        with open(testcases) as f:-            # Only line start with 'docker run' are test cases.-            for line in f.readlines():-                if line.startswith('docker run'):-                    m = re.search('--test_case=(.*)""', line)-                    shortname = m.group(1) if m else 'unknown_test'-                    m = re.search(-                        '--server_host_override=(.*).sandbox.googleapis.com',-                        line)-                    server = m.group(1) if m else 'unknown_server'--                    # If server_host arg is not None, replace the original-                    # server_host with the one provided or append to the end of-                    # the command if server_host does not appear originally.-                    if args.server_host:-                        if line.find('--server_host=') > -1:-                            line = re.sub('--server_host=[^ ]*',-                                          '--server_host=%s' % args.server_host,-                                          line)-                        else:-                            line = '%s --server_host=%s""' % (line[:-1],-                                                             args.server_host)-                        print(line)--                    spec = jobset.JobSpec(-                        cmdline=line,-                        shortname='%s:%s:%s:%s' % (suite_name, lang, server,-                                                   shortname),-                        timeout_seconds=_TEST_TIMEOUT,-                        shell=True,-                        flake_retries=5 if args.allow_flakes else 0)-                    job_spec_list.append(spec)-            jobset.message(-                'START',-                'Loaded %s tests from %s' % (len(job_spec_list), testcases),-                do_newline=True)-    except IOError as err:-        jobset.message('FAILED', err, do_newline=True)+    for line in testcase_lines:+        m = re.search('--test_case=(.*)""', line)+        shortname = m.group(1) if m else 'unknown_test'+        m = re.search('--server_host_override=(.*).sandbox.googleapis.com',+                      line)+        server = m.group(1) if m else 'unknown_server'++        # If server_host arg is not None, replace the original+        # server_host with the one provided or append to the end of+        # the command if server_host does not appear originally.+        if args.server_host:+            if line.find('--server_host=') > -1:+                line = re.sub('--server_host=[^ ]*',+                              '--server_host=%s' % args.server_host, line)+            else:+                line = '%s --server_host=%s""' % (line[:-1], args.server_host)++        spec = jobset.JobSpec(+            cmdline=line,+            shortname='%s:%s:%s:%s' % (suite_name, lang, server, shortname),+            timeout_seconds=_TEST_TIMEOUT_SECONDS,+            shell=True,+            flake_retries=5 if args.allow_flakes else 0)+        job_spec_list.append(spec)     return job_spec_list  -_xml_report_tree = report_utils.new_junit_xml_tree()+def _pull_images_for_lang(lang, images):+    """"""Pull all images for given lang from container registry.""""""+    jobset.message(+        'START', 'Downloading images for language ""%s""' % lang, do_newline=True)+    download_specs = []+    for release, image in images:+        # Pull the image and warm it up.+        # First time we use an image with ""docker run"", it takes time to unpack the image",nit: long comment line here,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16937,226912633,2018-10-22T07:00:27Z,tools/interop_matrix/run_interop_matrix_tests.py,"@@ -92,136 +93,149 @@     nargs='?',     help='The gateway to backend services.') -args = argp.parse_args()--print(str(args)) --def find_all_images_for_lang(lang):+def _get_test_images_for_lang(lang, release_arg, image_path_prefix):     """"""Find docker images for a language across releases and runtimes.    Returns dictionary of list of (<tag>, <image-full-path>) keyed by runtime.   """"""-    # Find all defined releases.-    if args.release == 'all':-        releases = ['master'] + client_matrix.get_release_tags(lang)+    if release_arg == 'all':+        # Use all defined releases for given language+        releases = client_matrix.get_release_tags(lang)     else:         # Look for a particular release.-        if args.release not in ['master'-                               ] + client_matrix.get_release_tags(lang):+        if release_arg not in client_matrix.get_release_tags(lang):             jobset.message(                 'SKIPPED',-                '%s for %s is not defined' % (args.release, lang),+                'release %s for %s is not defined' % (release_arg, lang),                 do_newline=True)             return {}-        releases = [args.release]+        releases = [release_arg] -    # TODO(jtattermusch): why do we need to query the existing images/tags?-    # From LANG_RUNTIME_MATRIX and LANG_RELEASE_MATRIX it should be obvious-    # which tags we want to test - and it should be an error if they are-    # missing.     # Images tuples keyed by runtime.     images = {}     for runtime in client_matrix.LANG_RUNTIME_MATRIX[lang]:-        image_path = '%s/grpc_interop_%s' % (args.gcr_path, runtime)-        output = subprocess.check_output([-            'gcloud', 'beta', 'container', 'images', 'list-tags',-            '--format=json', image_path-        ])-        docker_image_list = json.loads(output)-        # All images should have a single tag or no tag.-        # TODO(adelez): Remove tagless images.-        tags = [i['tags'][0] for i in docker_image_list if i['tags']]-        jobset.message(-            'START',-            'Found images for %s: %s' % (image_path, tags),-            do_newline=True)-        skipped = len(docker_image_list) - len(tags)-        jobset.message(-            'SKIPPED',-            'Skipped images (no-tag/unknown-tag): %d' % skipped,-            do_newline=True)-        # Filter tags based on the releases.-        images[runtime] = [(tag, '%s:%s' % (image_path, tag))-                           for tag in tags-                           if tag in releases]+        image_path = '%s/grpc_interop_%s' % (image_path_prefix, runtime)+        images[runtime] = [+            (tag, '%s:%s' % (image_path, tag)) for tag in releases+        ]     return images  -# caches test cases (list of JobSpec) loaded from file.  Keyed by lang and runtime.-def find_test_cases(lang, runtime, release, suite_name):-    """"""Returns the list of test cases from testcase files per lang/release.""""""+def _read_test_cases_file(lang, runtime, release):+    """"""Read test cases from a bash-like file and return a list of commands""""""     testcase_dir = os.path.join(os.path.dirname(__file__), 'testcases')     filename_prefix = lang     if lang == 'csharp':+        # TODO(jtattermusch): remove this odd specialcase         filename_prefix = runtime     # Check to see if we need to use a particular version of test cases.     lang_version = '%s_%s' % (filename_prefix, release)     if lang_version in client_matrix.TESTCASES_VERSION_MATRIX:-        testcases = os.path.join(+        testcase_file = os.path.join(             testcase_dir, client_matrix.TESTCASES_VERSION_MATRIX[lang_version])     else:-        testcases = os.path.join(testcase_dir, '%s__master' % filename_prefix)+        # TODO(jtattermusch): remove the double-underscore, it is pointless+        testcase_file = os.path.join(testcase_dir,+                                     '%s__master' % filename_prefix)++    lines = []+    with open(testcase_file) as f:+        for line in f.readlines():+            line = re.sub('\\#.*$', '', line)  # remove hash comments+            line = line.strip()+            if line and not line.startswith('echo'):+                # Each non-empty line is a treated as a test case command+                lines.append(line)+    return lines+++def _cleanup_docker_image(image):+    jobset.message('START', 'Cleanup docker image %s' % image, do_newline=True)+    dockerjob.remove_image(image, skip_nonexistent=True)+++args = argp.parse_args()+++# caches test cases (list of JobSpec) loaded from file.  Keyed by lang and runtime.+def _generate_test_case_jobspecs(lang, runtime, release, suite_name):+    """"""Returns the list of test cases from testcase files per lang/release.""""""+    testcase_lines = _read_test_cases_file(lang, runtime, release)      job_spec_list = []-    try:-        with open(testcases) as f:-            # Only line start with 'docker run' are test cases.-            for line in f.readlines():-                if line.startswith('docker run'):-                    m = re.search('--test_case=(.*)""', line)-                    shortname = m.group(1) if m else 'unknown_test'-                    m = re.search(-                        '--server_host_override=(.*).sandbox.googleapis.com',-                        line)-                    server = m.group(1) if m else 'unknown_server'--                    # If server_host arg is not None, replace the original-                    # server_host with the one provided or append to the end of-                    # the command if server_host does not appear originally.-                    if args.server_host:-                        if line.find('--server_host=') > -1:-                            line = re.sub('--server_host=[^ ]*',-                                          '--server_host=%s' % args.server_host,-                                          line)-                        else:-                            line = '%s --server_host=%s""' % (line[:-1],-                                                             args.server_host)-                        print(line)--                    spec = jobset.JobSpec(-                        cmdline=line,-                        shortname='%s:%s:%s:%s' % (suite_name, lang, server,-                                                   shortname),-                        timeout_seconds=_TEST_TIMEOUT,-                        shell=True,-                        flake_retries=5 if args.allow_flakes else 0)-                    job_spec_list.append(spec)-            jobset.message(-                'START',-                'Loaded %s tests from %s' % (len(job_spec_list), testcases),-                do_newline=True)-    except IOError as err:-        jobset.message('FAILED', err, do_newline=True)+    for line in testcase_lines:+        m = re.search('--test_case=(.*)""', line)+        shortname = m.group(1) if m else 'unknown_test'+        m = re.search('--server_host_override=(.*).sandbox.googleapis.com',+                      line)+        server = m.group(1) if m else 'unknown_server'++        # If server_host arg is not None, replace the original+        # server_host with the one provided or append to the end of+        # the command if server_host does not appear originally.+        if args.server_host:+            if line.find('--server_host=') > -1:+                line = re.sub('--server_host=[^ ]*',+                              '--server_host=%s' % args.server_host, line)+            else:+                line = '%s --server_host=%s""' % (line[:-1], args.server_host)++        spec = jobset.JobSpec(+            cmdline=line,+            shortname='%s:%s:%s:%s' % (suite_name, lang, server, shortname),+            timeout_seconds=_TEST_TIMEOUT_SECONDS,+            shell=True,+            flake_retries=5 if args.allow_flakes else 0)+        job_spec_list.append(spec)     return job_spec_list  -_xml_report_tree = report_utils.new_junit_xml_tree()+def _pull_images_for_lang(lang, images):+    """"""Pull all images for given lang from container registry.""""""+    jobset.message(+        'START', 'Downloading images for language ""%s""' % lang, do_newline=True)+    download_specs = []+    for release, image in images:+        # Pull the image and warm it up.+        # First time we use an image with ""docker run"", it takes time to unpack the image+        # and later this delay would fail our test cases.+        cmdline = [+            'gcloud docker -- pull %s && docker run --rm=true %s /bin/true' %","question out of curiosity: the `docker run` after the `docker pull` here is needed to do further one-time unpacking? I could definitely see it would be bad to `docker run` with a yet-un-pulled image, but was unaware that first time `docker run` with an already-pulled image would be problematic",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16898,227050814,2018-10-22T16:48:43Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -2576,6 +2593,39 @@ static void start_retriable_subchannel_batches(void* arg, grpc_error* ignored) { // LB pick // +// The callback to intercept trailing metadata if retries is not enabled+static void recv_trailing_metadata_ready_for_lb(void* arg, grpc_error* error) {+  subchannel_batch_data* batch_data = static_cast<subchannel_batch_data*>(arg);+  grpc_call_element* elem = batch_data->elem;+  call_data* calld = static_cast<call_data*>(elem->call_data);+  if (calld->pick.recv_trailing_metadata != nullptr) {+    *calld->pick.recv_trailing_metadata =+        batch_data->batch.payload->recv_trailing_metadata+            .recv_trailing_metadata;+  }+  GRPC_CLOSURE_SCHED(+      calld->pick.recv_trailing_metadata_ready,+      GRPC_ERROR_REF(error));+  GRPC_CLOSURE_RUN(+      calld->original_recv_trailing_metadata_ready,+      GRPC_ERROR_REF(error));+}++// Installs a interceptor to inform the lb of the trailing metadata, if needed+static void maybe_intercept_trailing_metadata_for_lb(+    void* arg, grpc_transport_stream_op_batch* batch) {+  subchannel_batch_data* batch_data = static_cast<subchannel_batch_data*>(arg);+  grpc_call_element* elem = batch_data->elem;+  call_data* calld = static_cast<call_data*>(elem->call_data);+  calld->original_recv_trailing_metadata_ready =+      batch->payload->recv_trailing_metadata.recv_trailing_metadata_ready;+  GRPC_CLOSURE_INIT(&calld->recv_trailing_metadata_ready_for_lb,+                    recv_trailing_metadata_ready_for_lb, elem,+                    grpc_schedule_on_exec_ctx);","Good question.  The answer requires some background and a bit of history.Every thread in C-core has an [`ExecCtx`](https://github.com/grpc/grpc/blob/master/src/core/lib/iomgr/exec_ctx.h#L88) associated with it.  The `ExecCtx` is a local variable in all functions that enter the C-core API (primarily, everything defined in [`grpc.h`](https://github.com/grpc/grpc/blob/master/include/grpc/grpc.h)), which means that it gets created when a thread enters C-core and destroyed before that thread leaves C-core.  The `ExecCtx` is stored as a thread-local variable and can be accessed by any function within core.The `ExecCtx` does a number of things these days, but its original purpose was to provide a general mechanism to avoid deadlocks.  The idea was that whenever code in core needed to invoke a closure, instead of doing it directly and risking a deadlock due to any locks being held when invoking the closure, the code would instead add the closure to the `ExecCtx`, which would invoke all of the closures in its list before it was destroyed (i.e., before the thread returns out of C-core).  This is where we got the difference between `GRPC_CLOSURE_RUN()` and `GRPC_CLOSURE_SCHED()` -- the former runs immediately, and the latter stores the closure to be invoked as soon as we're sure no locks are being held.Next, we introduced the concept of a [combiner](https://github.com/grpc/grpc/blob/master/src/core/lib/iomgr/combiner.h), which is a synchronization primative that allows us attempt to get a lock and then if the attempt fails, queue the work we would have done under the lock to be done later instead of blocking a thread waiting for the lock (for more info, see the [design sketch](https://github.com/grpc/grpc/blob/master/doc/combiner-explainer.md); note that that doc is being moved in #16959).  Since closures are the main mechanism we have for doing work later, it made sense to provide this new interface via the closure mechanism, which is what led to the introduction of the closure scheduler.Every closure has a [closure scheduler](https://github.com/grpc/grpc/blob/master/src/core/lib/iomgr/closure.h#L53) associated with it.  The scheduler provides the implementations of the `run()` and `sched()` methods that are invoked when we use `GRPC_CLOSURE_RUN()` and `GRPC_CLOSURE_SCHED()`, which allows each scheduler to override the behavior of those two methods.The `grpc_schedule_on_exec_ctx` scheduler is the original behavior of `GRPC_CLOSURE_RUN()` and `GRPC_CLOSURE_SCHED()` -- the former invokes the closure immediately, and the latter saves it on the `ExecCtx` to be invoked before returning out of C-core.The `grpc_combiner_scheduler()` scheduler is a scheduler that uses a combiner.  `GRPC_CLOSURE_SCHED()` will attempt to grab the combiner lock.  If successful, it will invoke the closure in the current thread; otherwise, it will queue the closure on the combiner and invokie it in whatever thread is currently holding the combiner.  `GRPC_CLOSURE_RUN()` will invoke the closure immediately -- but note that this is intended to be used when already holding the combiner and when invoking a closure that you know is also using the same combiner; Bad Things(tm) happen when either of those two conditions is not met.In this case, we are currently using the same combiner for everything in the client channel, including all resolver and LB policy work.  We do plan to change that as part of our work to decouple the control plane and data plane synchronization, but that's the way it is for now.  So for now, we should use `grpc_combiner_scheduler(chand->combiner)` here.Please let me know if you have any questions about any of this.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16937,227052042,2018-10-22T16:52:30Z,tools/interop_matrix/run_interop_matrix_tests.py,"@@ -92,136 +93,149 @@     nargs='?',     help='The gateway to backend services.') -args = argp.parse_args()--print(str(args)) --def find_all_images_for_lang(lang):+def _get_test_images_for_lang(lang, release_arg, image_path_prefix):     """"""Find docker images for a language across releases and runtimes.    Returns dictionary of list of (<tag>, <image-full-path>) keyed by runtime.   """"""-    # Find all defined releases.-    if args.release == 'all':-        releases = ['master'] + client_matrix.get_release_tags(lang)+    if release_arg == 'all':+        # Use all defined releases for given language+        releases = client_matrix.get_release_tags(lang)     else:         # Look for a particular release.-        if args.release not in ['master'-                               ] + client_matrix.get_release_tags(lang):+        if release_arg not in client_matrix.get_release_tags(lang):             jobset.message(                 'SKIPPED',-                '%s for %s is not defined' % (args.release, lang),+                'release %s for %s is not defined' % (release_arg, lang),                 do_newline=True)             return {}-        releases = [args.release]+        releases = [release_arg] -    # TODO(jtattermusch): why do we need to query the existing images/tags?-    # From LANG_RUNTIME_MATRIX and LANG_RELEASE_MATRIX it should be obvious-    # which tags we want to test - and it should be an error if they are-    # missing.     # Images tuples keyed by runtime.     images = {}     for runtime in client_matrix.LANG_RUNTIME_MATRIX[lang]:-        image_path = '%s/grpc_interop_%s' % (args.gcr_path, runtime)-        output = subprocess.check_output([-            'gcloud', 'beta', 'container', 'images', 'list-tags',-            '--format=json', image_path-        ])-        docker_image_list = json.loads(output)-        # All images should have a single tag or no tag.-        # TODO(adelez): Remove tagless images.-        tags = [i['tags'][0] for i in docker_image_list if i['tags']]-        jobset.message(-            'START',-            'Found images for %s: %s' % (image_path, tags),-            do_newline=True)-        skipped = len(docker_image_list) - len(tags)-        jobset.message(-            'SKIPPED',-            'Skipped images (no-tag/unknown-tag): %d' % skipped,-            do_newline=True)-        # Filter tags based on the releases.-        images[runtime] = [(tag, '%s:%s' % (image_path, tag))-                           for tag in tags-                           if tag in releases]+        image_path = '%s/grpc_interop_%s' % (image_path_prefix, runtime)+        images[runtime] = [+            (tag, '%s:%s' % (image_path, tag)) for tag in releases+        ]     return images  -# caches test cases (list of JobSpec) loaded from file.  Keyed by lang and runtime.-def find_test_cases(lang, runtime, release, suite_name):-    """"""Returns the list of test cases from testcase files per lang/release.""""""+def _read_test_cases_file(lang, runtime, release):+    """"""Read test cases from a bash-like file and return a list of commands""""""     testcase_dir = os.path.join(os.path.dirname(__file__), 'testcases')     filename_prefix = lang     if lang == 'csharp':+        # TODO(jtattermusch): remove this odd specialcase         filename_prefix = runtime     # Check to see if we need to use a particular version of test cases.     lang_version = '%s_%s' % (filename_prefix, release)     if lang_version in client_matrix.TESTCASES_VERSION_MATRIX:-        testcases = os.path.join(+        testcase_file = os.path.join(             testcase_dir, client_matrix.TESTCASES_VERSION_MATRIX[lang_version])     else:-        testcases = os.path.join(testcase_dir, '%s__master' % filename_prefix)+        # TODO(jtattermusch): remove the double-underscore, it is pointless+        testcase_file = os.path.join(testcase_dir,+                                     '%s__master' % filename_prefix)++    lines = []+    with open(testcase_file) as f:+        for line in f.readlines():+            line = re.sub('\\#.*$', '', line)  # remove hash comments+            line = line.strip()+            if line and not line.startswith('echo'):+                # Each non-empty line is a treated as a test case command+                lines.append(line)+    return lines+++def _cleanup_docker_image(image):+    jobset.message('START', 'Cleanup docker image %s' % image, do_newline=True)+    dockerjob.remove_image(image, skip_nonexistent=True)+++args = argp.parse_args()+++# caches test cases (list of JobSpec) loaded from file.  Keyed by lang and runtime.+def _generate_test_case_jobspecs(lang, runtime, release, suite_name):+    """"""Returns the list of test cases from testcase files per lang/release.""""""+    testcase_lines = _read_test_cases_file(lang, runtime, release)      job_spec_list = []-    try:-        with open(testcases) as f:-            # Only line start with 'docker run' are test cases.-            for line in f.readlines():-                if line.startswith('docker run'):-                    m = re.search('--test_case=(.*)""', line)-                    shortname = m.group(1) if m else 'unknown_test'-                    m = re.search(-                        '--server_host_override=(.*).sandbox.googleapis.com',-                        line)-                    server = m.group(1) if m else 'unknown_server'--                    # If server_host arg is not None, replace the original-                    # server_host with the one provided or append to the end of-                    # the command if server_host does not appear originally.-                    if args.server_host:-                        if line.find('--server_host=') > -1:-                            line = re.sub('--server_host=[^ ]*',-                                          '--server_host=%s' % args.server_host,-                                          line)-                        else:-                            line = '%s --server_host=%s""' % (line[:-1],-                                                             args.server_host)-                        print(line)--                    spec = jobset.JobSpec(-                        cmdline=line,-                        shortname='%s:%s:%s:%s' % (suite_name, lang, server,-                                                   shortname),-                        timeout_seconds=_TEST_TIMEOUT,-                        shell=True,-                        flake_retries=5 if args.allow_flakes else 0)-                    job_spec_list.append(spec)-            jobset.message(-                'START',-                'Loaded %s tests from %s' % (len(job_spec_list), testcases),-                do_newline=True)-    except IOError as err:-        jobset.message('FAILED', err, do_newline=True)+    for line in testcase_lines:+        m = re.search('--test_case=(.*)""', line)+        shortname = m.group(1) if m else 'unknown_test'+        m = re.search('--server_host_override=(.*).sandbox.googleapis.com',",I was going to revisit the test command updating logic in a followup PR - I this PR I wanted to remove cruft and some illogical stuff and make sure the interop matrix tests don't take that long. Then it will be easier to change the actual test logic (changes like this are better to be done in a separate PR anyway),OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16937,227053627,2018-10-22T16:57:17Z,tools/interop_matrix/run_interop_matrix_tests.py,"@@ -92,136 +93,149 @@     nargs='?',     help='The gateway to backend services.') -args = argp.parse_args()--print(str(args)) --def find_all_images_for_lang(lang):+def _get_test_images_for_lang(lang, release_arg, image_path_prefix):     """"""Find docker images for a language across releases and runtimes.    Returns dictionary of list of (<tag>, <image-full-path>) keyed by runtime.   """"""-    # Find all defined releases.-    if args.release == 'all':-        releases = ['master'] + client_matrix.get_release_tags(lang)+    if release_arg == 'all':+        # Use all defined releases for given language+        releases = client_matrix.get_release_tags(lang)     else:         # Look for a particular release.-        if args.release not in ['master'-                               ] + client_matrix.get_release_tags(lang):+        if release_arg not in client_matrix.get_release_tags(lang):             jobset.message(                 'SKIPPED',-                '%s for %s is not defined' % (args.release, lang),+                'release %s for %s is not defined' % (release_arg, lang),                 do_newline=True)             return {}-        releases = [args.release]+        releases = [release_arg] -    # TODO(jtattermusch): why do we need to query the existing images/tags?-    # From LANG_RUNTIME_MATRIX and LANG_RELEASE_MATRIX it should be obvious-    # which tags we want to test - and it should be an error if they are-    # missing.     # Images tuples keyed by runtime.     images = {}     for runtime in client_matrix.LANG_RUNTIME_MATRIX[lang]:-        image_path = '%s/grpc_interop_%s' % (args.gcr_path, runtime)-        output = subprocess.check_output([-            'gcloud', 'beta', 'container', 'images', 'list-tags',-            '--format=json', image_path-        ])-        docker_image_list = json.loads(output)-        # All images should have a single tag or no tag.-        # TODO(adelez): Remove tagless images.-        tags = [i['tags'][0] for i in docker_image_list if i['tags']]-        jobset.message(-            'START',-            'Found images for %s: %s' % (image_path, tags),-            do_newline=True)-        skipped = len(docker_image_list) - len(tags)-        jobset.message(-            'SKIPPED',-            'Skipped images (no-tag/unknown-tag): %d' % skipped,-            do_newline=True)-        # Filter tags based on the releases.-        images[runtime] = [(tag, '%s:%s' % (image_path, tag))-                           for tag in tags-                           if tag in releases]+        image_path = '%s/grpc_interop_%s' % (image_path_prefix, runtime)+        images[runtime] = [+            (tag, '%s:%s' % (image_path, tag)) for tag in releases+        ]     return images  -# caches test cases (list of JobSpec) loaded from file.  Keyed by lang and runtime.-def find_test_cases(lang, runtime, release, suite_name):-    """"""Returns the list of test cases from testcase files per lang/release.""""""+def _read_test_cases_file(lang, runtime, release):+    """"""Read test cases from a bash-like file and return a list of commands""""""     testcase_dir = os.path.join(os.path.dirname(__file__), 'testcases')     filename_prefix = lang     if lang == 'csharp':+        # TODO(jtattermusch): remove this odd specialcase         filename_prefix = runtime     # Check to see if we need to use a particular version of test cases.     lang_version = '%s_%s' % (filename_prefix, release)     if lang_version in client_matrix.TESTCASES_VERSION_MATRIX:-        testcases = os.path.join(+        testcase_file = os.path.join(             testcase_dir, client_matrix.TESTCASES_VERSION_MATRIX[lang_version])     else:-        testcases = os.path.join(testcase_dir, '%s__master' % filename_prefix)+        # TODO(jtattermusch): remove the double-underscore, it is pointless+        testcase_file = os.path.join(testcase_dir,+                                     '%s__master' % filename_prefix)++    lines = []+    with open(testcase_file) as f:+        for line in f.readlines():+            line = re.sub('\\#.*$', '', line)  # remove hash comments+            line = line.strip()+            if line and not line.startswith('echo'):+                # Each non-empty line is a treated as a test case command+                lines.append(line)+    return lines+++def _cleanup_docker_image(image):+    jobset.message('START', 'Cleanup docker image %s' % image, do_newline=True)+    dockerjob.remove_image(image, skip_nonexistent=True)+++args = argp.parse_args()+++# caches test cases (list of JobSpec) loaded from file.  Keyed by lang and runtime.+def _generate_test_case_jobspecs(lang, runtime, release, suite_name):+    """"""Returns the list of test cases from testcase files per lang/release.""""""+    testcase_lines = _read_test_cases_file(lang, runtime, release)      job_spec_list = []-    try:-        with open(testcases) as f:-            # Only line start with 'docker run' are test cases.-            for line in f.readlines():-                if line.startswith('docker run'):-                    m = re.search('--test_case=(.*)""', line)-                    shortname = m.group(1) if m else 'unknown_test'-                    m = re.search(-                        '--server_host_override=(.*).sandbox.googleapis.com',-                        line)-                    server = m.group(1) if m else 'unknown_server'--                    # If server_host arg is not None, replace the original-                    # server_host with the one provided or append to the end of-                    # the command if server_host does not appear originally.-                    if args.server_host:-                        if line.find('--server_host=') > -1:-                            line = re.sub('--server_host=[^ ]*',-                                          '--server_host=%s' % args.server_host,-                                          line)-                        else:-                            line = '%s --server_host=%s""' % (line[:-1],-                                                             args.server_host)-                        print(line)--                    spec = jobset.JobSpec(-                        cmdline=line,-                        shortname='%s:%s:%s:%s' % (suite_name, lang, server,-                                                   shortname),-                        timeout_seconds=_TEST_TIMEOUT,-                        shell=True,-                        flake_retries=5 if args.allow_flakes else 0)-                    job_spec_list.append(spec)-            jobset.message(-                'START',-                'Loaded %s tests from %s' % (len(job_spec_list), testcases),-                do_newline=True)-    except IOError as err:-        jobset.message('FAILED', err, do_newline=True)+    for line in testcase_lines:+        m = re.search('--test_case=(.*)""', line)+        shortname = m.group(1) if m else 'unknown_test'+        m = re.search('--server_host_override=(.*).sandbox.googleapis.com',+                      line)+        server = m.group(1) if m else 'unknown_server'++        # If server_host arg is not None, replace the original+        # server_host with the one provided or append to the end of+        # the command if server_host does not appear originally.+        if args.server_host:+            if line.find('--server_host=') > -1:+                line = re.sub('--server_host=[^ ]*',+                              '--server_host=%s' % args.server_host, line)+            else:+                line = '%s --server_host=%s""' % (line[:-1], args.server_host)++        spec = jobset.JobSpec(+            cmdline=line,+            shortname='%s:%s:%s:%s' % (suite_name, lang, server, shortname),+            timeout_seconds=_TEST_TIMEOUT_SECONDS,+            shell=True,+            flake_retries=5 if args.allow_flakes else 0)+        job_spec_list.append(spec)     return job_spec_list  -_xml_report_tree = report_utils.new_junit_xml_tree()+def _pull_images_for_lang(lang, images):+    """"""Pull all images for given lang from container registry.""""""+    jobset.message(+        'START', 'Downloading images for language ""%s""' % lang, do_newline=True)+    download_specs = []+    for release, image in images:+        # Pull the image and warm it up.+        # First time we use an image with ""docker run"", it takes time to unpack the image+        # and later this delay would fail our test cases.+        cmdline = [+            'gcloud docker -- pull %s && docker run --rm=true %s /bin/true' %","I didn't know that either, but this seems to be the reason why the parallel downloads had to be rolled back in  #15701 (I realized from the logs that the first time a test is run by `docker run` after pulling the image, it takes much longer to run than the subsequent uses of the same image (this was actually causing the first test case to time out).",
38445398,aharperg,https://api.github.com/repos/grpc/grpc/pulls/16190,227070366,2018-10-22T17:48:12Z,src/objective-c/ProtoRPC/ProtoRPC.m,"@@ -23,9 +23,166 @@ #else #import <GPBProtocolBuffers.h> #endif+#import <GRPCClient/GRPCCall.h> #import <RxLibrary/GRXWriteable.h> #import <RxLibrary/GRXWriter+Transformations.h> +@implementation GRPCUnaryProtoCall {+  GRPCStreamingProtoCall *_call;+}++- (instancetype)initWithRequestOptions:(GRPCRequestOptions *)requestOptions+                               message:(GPBMessage *)message+                       responseHandler:(id<GRPCResponseHandler>)handler+                           callOptions:(GRPCCallOptions *)callOptions+                         responseClass:(Class)responseClass {+  if ((self = [super init])) {+    _call = [[GRPCStreamingProtoCall alloc] initWithRequestOptions:requestOptions+                                                   responseHandler:handler+                                                       callOptions:callOptions+                                                     responseClass:responseClass];+    [_call writeWithMessage:message];+    [_call finish];+  }+  return self;+}++- (void)cancel {+  [_call cancel];+  _call = nil;+}++@end++@interface GRPCStreamingProtoCall ()<GRPCResponseHandler>++@end++@implementation GRPCStreamingProtoCall {+  GRPCRequestOptions *_requestOptions;+  id<GRPCResponseHandler> _handler;+  GRPCCallOptions *_callOptions;+  Class _responseClass;++  GRPCCall2 *_call;+  dispatch_queue_t _dispatchQueue;+}++- (instancetype)initWithRequestOptions:(GRPCRequestOptions *)requestOptions+                       responseHandler:(id<GRPCResponseHandler>)handler+                           callOptions:(GRPCCallOptions *)callOptions+                         responseClass:(Class)responseClass {+  if ((self = [super init])) {+    _requestOptions = [requestOptions copy];+    _handler = handler;+    _callOptions = [callOptions copy];+    _responseClass = responseClass;+    _dispatchQueue = dispatch_queue_create(nil, DISPATCH_QUEUE_SERIAL);++    [self start];+  }+  return self;+}++- (void)start {+  _call = [[GRPCCall2 alloc] initWithRequestOptions:_requestOptions+                                    responseHandler:self+                                        callOptions:_callOptions];+  [_call start];+}++- (void)cancel {+  dispatch_async(_dispatchQueue, ^{+    if (_call) {+      [_call cancel];+      _call = nil;+    }+    if (_handler) {+      id<GRPCResponseHandler> handler = _handler;+      dispatch_async(handler.dispatchQueue, ^{+        [handler closedWithTrailingMetadata:nil+                                      error:[NSError errorWithDomain:kGRPCErrorDomain+                                                                code:GRPCErrorCodeCancelled+                                                            userInfo:@{+                                                              NSLocalizedDescriptionKey :+                                                                  @""Canceled by app""+                                                            }]];+      });+      _handler = nil;+    }+  });+}++- (void)writeWithMessage:(GPBMessage *)message {+  if (![message isKindOfClass:[GPBMessage class]]) {+    [NSException raise:NSInvalidArgumentException format:@""Data must be a valid protobuf type.""];+  }++  dispatch_async(_dispatchQueue, ^{+    if (_call) {+      [_call writeData:[message data]];+    }+  });+}++- (void)finish {+  dispatch_async(_dispatchQueue, ^{+    if (_call) {+      [_call finish];+      _call = nil;+    }+  });+}++- (void)receivedInitialMetadata:(NSDictionary *)initialMetadata {+  if (_handler) {+    id<GRPCResponseHandler> handler = _handler;","You're right that referencing self or _handler (not just self->_handler) will retain self till the block is run. I'm just unclear on why that retain would be a bad thing. In other parts of the API the code is self-retaining for the duration of the call, which makes sense to me.As for the _handler race, that's true, but it appears that's cleared only on cancel. Its not clear from the API that cancel shouldn't stop this handler from running even if the block is already in flight. The behavior is likely undefined as you still have the problem of a race before the block is copied, so its not like its called consistently.At minimum you need a comment here explaining that you're trying to ensure it runs regardless of cancellation.",OK
38445398,aharperg,https://api.github.com/repos/grpc/grpc/pulls/16190,227071641,2018-10-22T17:52:09Z,src/objective-c/ProtoRPC/ProtoRPC.m,"@@ -23,9 +23,166 @@ #else #import <GPBProtocolBuffers.h> #endif+#import <GRPCClient/GRPCCall.h> #import <RxLibrary/GRXWriteable.h> #import <RxLibrary/GRXWriter+Transformations.h> +@implementation GRPCUnaryProtoCall {+  GRPCStreamingProtoCall *_call;+}++- (instancetype)initWithRequestOptions:(GRPCRequestOptions *)requestOptions+                               message:(GPBMessage *)message+                       responseHandler:(id<GRPCResponseHandler>)handler+                           callOptions:(GRPCCallOptions *)callOptions+                         responseClass:(Class)responseClass {+  if ((self = [super init])) {+    _call = [[GRPCStreamingProtoCall alloc] initWithRequestOptions:requestOptions+                                                   responseHandler:handler+                                                       callOptions:callOptions+                                                     responseClass:responseClass];+    [_call writeWithMessage:message];+    [_call finish];+  }+  return self;+}++- (void)cancel {+  [_call cancel];+  _call = nil;+}++@end++@interface GRPCStreamingProtoCall ()<GRPCResponseHandler>++@end++@implementation GRPCStreamingProtoCall {+  GRPCRequestOptions *_requestOptions;+  id<GRPCResponseHandler> _handler;+  GRPCCallOptions *_callOptions;+  Class _responseClass;++  GRPCCall2 *_call;+  dispatch_queue_t _dispatchQueue;+}++- (instancetype)initWithRequestOptions:(GRPCRequestOptions *)requestOptions+                       responseHandler:(id<GRPCResponseHandler>)handler+                           callOptions:(GRPCCallOptions *)callOptions+                         responseClass:(Class)responseClass {+  if ((self = [super init])) {+    _requestOptions = [requestOptions copy];+    _handler = handler;+    _callOptions = [callOptions copy];+    _responseClass = responseClass;+    _dispatchQueue = dispatch_queue_create(nil, DISPATCH_QUEUE_SERIAL);++    [self start];+  }+  return self;+}++- (void)start {+  _call = [[GRPCCall2 alloc] initWithRequestOptions:_requestOptions+                                    responseHandler:self+                                        callOptions:_callOptions];+  [_call start];+}++- (void)cancel {+  dispatch_async(_dispatchQueue, ^{+    if (_call) {+      [_call cancel];+      _call = nil;+    }+    if (_handler) {+      id<GRPCResponseHandler> handler = _handler;+      dispatch_async(handler.dispatchQueue, ^{+        [handler closedWithTrailingMetadata:nil+                                      error:[NSError errorWithDomain:kGRPCErrorDomain+                                                                code:GRPCErrorCodeCancelled+                                                            userInfo:@{+                                                              NSLocalizedDescriptionKey :+                                                                  @""Canceled by app""+                                                            }]];+      });+      _handler = nil;+    }+  });+}++- (void)writeWithMessage:(GPBMessage *)message {+  if (![message isKindOfClass:[GPBMessage class]]) {+    [NSException raise:NSInvalidArgumentException format:@""Data must be a valid protobuf type.""];+  }++  dispatch_async(_dispatchQueue, ^{+    if (_call) {+      [_call writeData:[message data]];+    }+  });+}++- (void)finish {+  dispatch_async(_dispatchQueue, ^{+    if (_call) {+      [_call finish];+      _call = nil;+    }+  });+}++- (void)receivedInitialMetadata:(NSDictionary *)initialMetadata {+  if (_handler) {+    id<GRPCResponseHandler> handler = _handler;+    dispatch_async(handler.dispatchQueue, ^{+      [handler receivedInitialMetadata:initialMetadata];+    });+  }+}++- (void)receivedMessage:(NSData *)message {+  if (_handler) {+    id<GRPCResponseHandler> handler = _handler;+    NSError *error = nil;+    id parsed = [_responseClass parseFromData:message error:&error];+    if (parsed) {+      dispatch_async(handler.dispatchQueue, ^{+        [handler receivedMessage:parsed];+      });+    } else {+      dispatch_async(handler.dispatchQueue, ^{+        [handler closedWithTrailingMetadata:nil error:error];+      });+      handler = nil;+      [_call cancel];","Its fine to release the resources, but there's an important semantic difference between ""caller cancelled"" and data failed to parse that you're losing here. Right now you'll end up propagating a GRPCErrorCodeCancelled, which seems wrong vs GRPCErrorCodeInternal or  GRPCErrorCodeInvalidArgument.",
38445398,aharperg,https://api.github.com/repos/grpc/grpc/pulls/16190,227074643,2018-10-22T18:01:00Z,src/objective-c/ProtoRPC/ProtoRPC.m,"@@ -23,9 +23,166 @@ #else #import <GPBProtocolBuffers.h> #endif+#import <GRPCClient/GRPCCall.h> #import <RxLibrary/GRXWriteable.h> #import <RxLibrary/GRXWriter+Transformations.h> +@implementation GRPCUnaryProtoCall {+  GRPCStreamingProtoCall *_call;+}++- (instancetype)initWithRequestOptions:(GRPCRequestOptions *)requestOptions+                               message:(GPBMessage *)message+                       responseHandler:(id<GRPCResponseHandler>)handler+                           callOptions:(GRPCCallOptions *)callOptions+                         responseClass:(Class)responseClass {+  if ((self = [super init])) {+    _call = [[GRPCStreamingProtoCall alloc] initWithRequestOptions:requestOptions+                                                   responseHandler:handler+                                                       callOptions:callOptions+                                                     responseClass:responseClass];+    [_call writeWithMessage:message];+    [_call finish];+  }+  return self;+}++- (void)cancel {+  [_call cancel];+  _call = nil;+}++@end++@interface GRPCStreamingProtoCall ()<GRPCResponseHandler>++@end++@implementation GRPCStreamingProtoCall {+  GRPCRequestOptions *_requestOptions;+  id<GRPCResponseHandler> _handler;+  GRPCCallOptions *_callOptions;+  Class _responseClass;++  GRPCCall2 *_call;+  dispatch_queue_t _dispatchQueue;+}++- (instancetype)initWithRequestOptions:(GRPCRequestOptions *)requestOptions+                       responseHandler:(id<GRPCResponseHandler>)handler+                           callOptions:(GRPCCallOptions *)callOptions+                         responseClass:(Class)responseClass {+  if ((self = [super init])) {+    _requestOptions = [requestOptions copy];+    _handler = handler;+    _callOptions = [callOptions copy];+    _responseClass = responseClass;+    _dispatchQueue = dispatch_queue_create(nil, DISPATCH_QUEUE_SERIAL);++    [self start];+  }+  return self;+}++- (void)start {+  _call = [[GRPCCall2 alloc] initWithRequestOptions:_requestOptions+                                    responseHandler:self+                                        callOptions:_callOptions];+  [_call start];+}++- (void)cancel {+  dispatch_async(_dispatchQueue, ^{+    if (_call) {+      [_call cancel];+      _call = nil;+    }+    if (_handler) {+      id<GRPCResponseHandler> handler = _handler;+      dispatch_async(handler.dispatchQueue, ^{+        [handler closedWithTrailingMetadata:nil+                                      error:[NSError errorWithDomain:kGRPCErrorDomain+                                                                code:GRPCErrorCodeCancelled+                                                            userInfo:@{+                                                              NSLocalizedDescriptionKey :+                                                                  @""Canceled by app""+                                                            }]];+      });+      _handler = nil;+    }+  });+}++- (void)writeWithMessage:(GPBMessage *)message {+  if (![message isKindOfClass:[GPBMessage class]]) {+    [NSException raise:NSInvalidArgumentException format:@""Data must be a valid protobuf type.""];+  }++  dispatch_async(_dispatchQueue, ^{+    if (_call) {+      [_call writeData:[message data]];+    }+  });+}++- (void)finish {+  dispatch_async(_dispatchQueue, ^{+    if (_call) {+      [_call finish];+      _call = nil;+    }+  });+}++- (void)receivedInitialMetadata:(NSDictionary *)initialMetadata {+  if (_handler) {+    id<GRPCResponseHandler> handler = _handler;+    dispatch_async(handler.dispatchQueue, ^{+      [handler receivedInitialMetadata:initialMetadata];+    });+  }+}++- (void)receivedMessage:(NSData *)message {+  if (_handler) {+    id<GRPCResponseHandler> handler = _handler;+    NSError *error = nil;+    id parsed = [_responseClass parseFromData:message error:&error];+    if (parsed) {+      dispatch_async(handler.dispatchQueue, ^{+        [handler receivedMessage:parsed];+      });+    } else {+      dispatch_async(handler.dispatchQueue, ^{+        [handler closedWithTrailingMetadata:nil error:error];+      });+      handler = nil;+      [_call cancel];+      _call = nil;","That's not an obvious requirement of the public API of this class, and its not clear why this method would be special in that regard vs [... finish], for example. If you're using _dispatchQueue for a lock, the locking should be done inside this class.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16963,227078513,2018-10-22T18:12:31Z,src/core/lib/security/transport/client_auth_filter.cc,"@@ -32,6 +32,7 @@ #include ""src/core/lib/security/context/security_context.h"" #include ""src/core/lib/security/credentials/credentials.h"" #include ""src/core/lib/security/security_connector/security_connector.h""+#include ""src/core/lib/security/security_connector/ssl/ssl_security_connector.h""","I don't think the fake URL string belongs there, since the file is specific to SSL.  Let's keep the fake URL string where it was.Thanks!",OK
38445398,aharperg,https://api.github.com/repos/grpc/grpc/pulls/16190,227137937,2018-10-22T21:04:35Z,src/objective-c/GRPCClient/GRPCCallOptions.h,"@@ -0,0 +1,317 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#import <Foundation/Foundation.h>++/**+ * Safety remark of a gRPC method as defined in RFC 2616 Section 9.1+ */+typedef NS_ENUM(NSUInteger, GRPCCallSafety) {+  /** Signal that there is no guarantees on how the call affects the server state. */+  GRPCCallSafetyDefault = 0,+  /** Signal that the call is idempotent. gRPC is free to use PUT verb. */+  GRPCCallSafetyIdempotentRequest = 1,+  /** Signal that the call is cacheable and will not affect server state. gRPC is free to use GET+   verb. */+  GRPCCallSafetyCacheableRequest = 2,+};++// Compression algorithm to be used by a gRPC call+typedef NS_ENUM(NSInteger, GRPCCompressAlgorithm) {+  GRPCCompressNone = 0,+  GRPCCompressDeflate,+  GRPCCompressGzip,+  GRPCStreamCompressGzip,+};++// The transport to be used by a gRPC call+typedef NS_ENUM(NSInteger, GRPCTransportType) {+  // gRPC internal HTTP/2 stack with BoringSSL+  GRPCTransportTypeDefault = 0,+  // Cronet stack+  GRPCTransportTypeCronet,+  // Insecure channel. FOR TEST ONLY!+  GRPCTransportTypeInsecure,+};++@protocol GRPCAuthorizationProtocol+- (void)getTokenWithHandler:(void (^)(NSString *token))hander;+@end++@interface GRPCCallOptions : NSObject<NSCopying, NSMutableCopying>++// Call parameters+/**+ * The authority for the RPC. If nil, the default authority will be used.+ *+ * Note: This property must be nil when Cronet transport is enabled.+ * Note: This property cannot be used to validate a self-signed server certificate. It control the+ *       :authority header field of the call and performs an extra check that server's certificate+ *       matches the :authority header.+ */+@property(readonly) NSString *serverAuthority;++/**+ * The timeout for the RPC call in seconds. If set to 0, the call will not timeout. If set to+ * positive, the gRPC call returns with status GRPCErrorCodeDeadlineExceeded if it is not completed+ * within \a timeout seconds. A negative value is not allowed.+ */+@property(readonly) NSTimeInterval timeout;++// OAuth2 parameters. Users of gRPC may specify one of the following two parameters.++/**+ * The OAuth2 access token string. The string is prefixed with ""Bearer "" then used as value of the+ * request's ""authorization"" header field. This parameter should not be used simultaneously with+ * \a authTokenProvider.+ */+@property(copy, readonly) NSString *oauth2AccessToken;++/**+ * The interface to get the OAuth2 access token string. gRPC will attempt to acquire token when+ * initiating the call. This parameter should not be used simultaneously with \a oauth2AccessToken.+ */+@property(readonly) id<GRPCAuthorizationProtocol> authTokenProvider;++/**+ * Initial metadata key-value pairs that should be included in the request.+ */+@property(copy, readwrite) NSDictionary *initialMetadata;++// Channel parameters; take into account of channel signature.++/**+ * Custom string that is prefixed to a request's user-agent header field before gRPC's internal+ * user-agent string.+ */+@property(copy, readonly) NSString *userAgentPrefix;++/**+ * The size limit for the response received from server. If it is exceeded, an error with status+ * code GRPCErrorCodeResourceExhausted is returned.+ */+@property(readonly) NSUInteger responseSizeLimit;++/**+ * The compression algorithm to be used by the gRPC call. For more details refer to+ * https://github.com/grpc/grpc/blob/master/doc/compression.md+ */+@property(readonly) GRPCCompressAlgorithm compressAlgorithm;++/**+ * Enable/Disable gRPC call's retry feature. The default is enabled. For details of this feature+ * refer to+ * https://github.com/grpc/proposal/blob/master/A6-client-retries.md+ */+@property(readonly) BOOL enableRetry;++/**+ * HTTP/2 keep-alive feature. The parameter \a keepaliveInterval specifies the interval between two+ * PING frames. The parameter \a keepaliveTimeout specifies the length of the period for which the+ * call should wait for PING ACK. If PING ACK is not received after this period, the call fails.+ */+@property(readonly) NSTimeInterval keepaliveInterval;+@property(readonly) NSTimeInterval keepaliveTimeout;++// Parameters for connection backoff. For details of gRPC's backoff behavior, refer to+// https://github.com/grpc/grpc/blob/master/doc/connection-backoff.md+@property(readonly) NSTimeInterval connectMinTimeout;+@property(readonly) NSTimeInterval connectInitialBackoff;+@property(readonly) NSTimeInterval connectMaxBackoff;++/**+ * Specify channel args to be used for this call. For a list of channel args available, see+ * grpc/grpc_types.h+ */+@property(copy, readonly) NSDictionary *additionalChannelArgs;++// Parameters for SSL authentication.++/**+ * PEM format root certifications that is trusted. If set to nil, gRPC uses a list of default+ * root certificates.+ */+@property(copy, readonly) NSString *pemRootCert;++/**+ * PEM format private key for client authentication, if required by the server.+ */+@property(copy, readonly) NSString *pemPrivateKey;++/**+ * PEM format certificate chain for client authentication, if required by the server.+ */+@property(copy, readonly) NSString *pemCertChain;++/**+ * Select the transport type to be used for this call.+ */+@property(readonly) GRPCTransportType transportType;++/**+ * Override the hostname during the TLS hostname validation process.+ */+@property(copy, readonly) NSString *hostNameOverride;++/**+ * Parameter used for internal logging.+ */+@property(readonly) id logContext;","I think what's being proposed is a class extension, not a category. So you'd declared this in GRPCCallOptions+Private.h@interface GRPCCallOptions ()@property(readonly) SomeRealType *logContext;@endand then import that into the implementation file. You can then use the ivar directly in copy/equal, etc.",OK
2811396,ejona86,https://api.github.com/repos/grpc/grpc/pulls/15460,227448192,2018-10-23T15:32:53Z,doc/PROTOCOL-SEMANTICS.md,"@@ -0,0 +1,268 @@+# gRPC semantics++gRPC has many features, but the most fundamental core is the ability to perform+RPCs. The goal of this document is defining the semantics of gRPC's RPCs.++## Channels++Most implementations will have Channel and Server concepts. A Channel is a+virtual connection to an endpoint, capable of sending RPCs. Channel is ""virtual""+because the Channel is free to have zero or many actual connections. A Channel+is free to determine which actual endpoint to use and may change it every RPC,+permitting client-side load balancing. A Server is capable of receiving incoming+connections and receiving RPCs.++A ""connection"" is not a gRPC semantic concept and thus users should not assume a+correlation between connections and RPCs. Although, practically, users should be+aware of the common restriction that RPCs are unable to survive longer than the+connection on which they exist.++The exact details of how the communication is performed and higher level+abstractions can change when necessary and are thus not a focus for this+document. Although implementations SHOULD support the [HTTP/2+transport](PROTOCOL-HTTP2.md) to provide a basis for interoperability.++## Methods++An RPC is performed on a Method. The Method has a name, defines the intended+operation, the message types involved with the RPC, and the cardinality of+those messages.  It does not define the endpoint to send the RPC to; this is+normally handled by the Channel.++A Method's intended operation is just normal documentation describing what a+Method does, intended for a developer. gRPC itself is not generally aware of the+intended operation.++A Method has a request message type and a separate response message type. gRPC+is only aware of these types well enough to serialize and deserialize them.+Messages are considered opaque byte sequences of a known length to gRPC itself.++A Method's request and response each have a cardinality: either one (""unary""),+or zero to many (a ""stream""). This produces four possible configurations which,+for convenience, each have a name:++|                       | **unary response** | **streaming response** |+| --------------------- | ------------------ | ---------------------- |+| **unary request**     | unary              | server-streaming       |+| **streaming request** | client-streaming   | bidirectional (bidi)   |++While we use the term ""method,"" pedantically it is closer to ""function"" as it is+not object oriented and there is no ""receiver"" involved (the `this` variable in+many languages) other than the destination machine. gRPC is based on message+passing, not object orientation.++Related Methods are typically grouped into a Service. To gRPC, a Service is a+group of methods that tend to be implemented together and that all share the+Service's namespace. A Service is a higher-level abstraction and may not be+present explicitly in all implementations. However, the namespace provided by a+Service is a core distinguishing feature of its Methods; if two Methods have the+same name but exist in different Services they must be considered distinct and+not be confused. A Method name including its Service namespace prefix with a ""/""+separator is a ""full method name"".++## Calls++RPCs, or ""Calls,"" are initiated by a client to a server, typically via a+Channel. There may be multiple servers that _could_ have received the Call (as+is common for load balancing), but only a single server may process an+individual Call. Calls are assumed to be non-idempotent and may not be+""replayed"" except for when gRPC is explicitly informed it is safe to do so.++Calls are natively two independent streams (i.e., full duplex bidirectional) of+Messages. The request stream is started with Request Headers and ended by Half+Close. The response stream is started with Response Headers and ended by+Trailers, or consistes only of Trailers. Messages may exist between the headers+and the end of the stream. Request Headers, Response Headers, Messages, Half+Close, and Trailers are the units of communication and, absent the Call's+termination, will be communicated to the remote without the need to send further+units on the stream. However, see the optimizations permitted for unary Calls+below.++Request Headers contain the Full Method Name and Metadata. Response Headers+contain Metadata. Trailers contain the Status and Metadata. Messages contain the+Message Payload. These contents are not exhaustive; gRPC features may extend+these concepts. It is quite common for features to add additional fields to+Request Headers, Response Headers, and Trailers.++The Call initiation is with Request Headers, within which the client+indicates the method to be run by its Full Method Name. The Call is gracefully+completed when the server responds with Trailers, which contains a Status+communicating the success or failure of the RPC. If a server responds with+Trailers before receiving the client's Half Close, then any unprocessed+client-sent Messages and Half Close is lost. Note that on the server there is a+period of time between when the server application responds with a Trailers and+when that Trailers is actually sent; the Call is only truly complete when the+Trailers is sent. Similarly, on the client there is a period between the gRPC+implementation receiving the Trailers and when the application receives the+Trailers; the Call is only truly complete when the Trailers is received by the+application.++Calls may terminate early by being ""cancelled."" Implementations must allow+clients to cancel Calls, but cancellations may occur in other ways like I/O+failures. A cancellation appears as a Trailers with a Status Code of CANCELLED+to clients and is a special state on servers. Cancellation is an abrupt killing+of the Call; inbound and outbound buffered data should be cleared. Cancellation","Error-trailers aren't cancellation, so they should be in-line and the client should process the server-sent headers. RST is cancellation, but server doesn't really initiate cancellation today (I know it is possible in C, but that's another story). The only time a server cancels today is due to deadline, in which case the client should have already cancelled as well.@carl-mastrangelo, why do you ask? What context is this coming up?I'm noticing that this section should probably remove ""I/O failures"" from ways of cancellation, as we don't do abrupt killing of the call in that case.",
8943572,carl-mastrangelo,https://api.github.com/repos/grpc/grpc/pulls/15460,227479508,2018-10-23T16:56:20Z,doc/PROTOCOL-SEMANTICS.md,"@@ -0,0 +1,268 @@+# gRPC semantics++gRPC has many features, but the most fundamental core is the ability to perform+RPCs. The goal of this document is defining the semantics of gRPC's RPCs.++## Channels++Most implementations will have Channel and Server concepts. A Channel is a+virtual connection to an endpoint, capable of sending RPCs. Channel is ""virtual""+because the Channel is free to have zero or many actual connections. A Channel+is free to determine which actual endpoint to use and may change it every RPC,+permitting client-side load balancing. A Server is capable of receiving incoming+connections and receiving RPCs.++A ""connection"" is not a gRPC semantic concept and thus users should not assume a+correlation between connections and RPCs. Although, practically, users should be+aware of the common restriction that RPCs are unable to survive longer than the+connection on which they exist.++The exact details of how the communication is performed and higher level+abstractions can change when necessary and are thus not a focus for this+document. Although implementations SHOULD support the [HTTP/2+transport](PROTOCOL-HTTP2.md) to provide a basis for interoperability.++## Methods++An RPC is performed on a Method. The Method has a name, defines the intended+operation, the message types involved with the RPC, and the cardinality of+those messages.  It does not define the endpoint to send the RPC to; this is+normally handled by the Channel.++A Method's intended operation is just normal documentation describing what a+Method does, intended for a developer. gRPC itself is not generally aware of the+intended operation.++A Method has a request message type and a separate response message type. gRPC+is only aware of these types well enough to serialize and deserialize them.+Messages are considered opaque byte sequences of a known length to gRPC itself.++A Method's request and response each have a cardinality: either one (""unary""),+or zero to many (a ""stream""). This produces four possible configurations which,+for convenience, each have a name:++|                       | **unary response** | **streaming response** |+| --------------------- | ------------------ | ---------------------- |+| **unary request**     | unary              | server-streaming       |+| **streaming request** | client-streaming   | bidirectional (bidi)   |++While we use the term ""method,"" pedantically it is closer to ""function"" as it is+not object oriented and there is no ""receiver"" involved (the `this` variable in+many languages) other than the destination machine. gRPC is based on message+passing, not object orientation.++Related Methods are typically grouped into a Service. To gRPC, a Service is a+group of methods that tend to be implemented together and that all share the+Service's namespace. A Service is a higher-level abstraction and may not be+present explicitly in all implementations. However, the namespace provided by a+Service is a core distinguishing feature of its Methods; if two Methods have the+same name but exist in different Services they must be considered distinct and+not be confused. A Method name including its Service namespace prefix with a ""/""+separator is a ""full method name"".++## Calls++RPCs, or ""Calls,"" are initiated by a client to a server, typically via a+Channel. There may be multiple servers that _could_ have received the Call (as+is common for load balancing), but only a single server may process an+individual Call. Calls are assumed to be non-idempotent and may not be+""replayed"" except for when gRPC is explicitly informed it is safe to do so.++Calls are natively two independent streams (i.e., full duplex bidirectional) of+Messages. The request stream is started with Request Headers and ended by Half+Close. The response stream is started with Response Headers and ended by+Trailers, or consistes only of Trailers. Messages may exist between the headers+and the end of the stream. Request Headers, Response Headers, Messages, Half+Close, and Trailers are the units of communication and, absent the Call's+termination, will be communicated to the remote without the need to send further+units on the stream. However, see the optimizations permitted for unary Calls+below.++Request Headers contain the Full Method Name and Metadata. Response Headers+contain Metadata. Trailers contain the Status and Metadata. Messages contain the+Message Payload. These contents are not exhaustive; gRPC features may extend+these concepts. It is quite common for features to add additional fields to+Request Headers, Response Headers, and Trailers.++The Call initiation is with Request Headers, within which the client+indicates the method to be run by its Full Method Name. The Call is gracefully+completed when the server responds with Trailers, which contains a Status+communicating the success or failure of the RPC. If a server responds with+Trailers before receiving the client's Half Close, then any unprocessed+client-sent Messages and Half Close is lost. Note that on the server there is a+period of time between when the server application responds with a Trailers and+when that Trailers is actually sent; the Call is only truly complete when the+Trailers is sent. Similarly, on the client there is a period between the gRPC+implementation receiving the Trailers and when the application receives the+Trailers; the Call is only truly complete when the Trailers is received by the+application.++Calls may terminate early by being ""cancelled."" Implementations must allow+clients to cancel Calls, but cancellations may occur in other ways like I/O+failures. A cancellation appears as a Trailers with a Status Code of CANCELLED+to clients and is a special state on servers. Cancellation is an abrupt killing+of the Call; inbound and outbound buffered data should be cleared. Cancellation","@muxi asked if server-headers should be dropped by the client, if the call is cancelled before they can be delivered to the application.   In Java I think we do deliver the complete data frames, but C-core does not, hence the question.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16937,227484219,2018-10-23T17:10:38Z,tools/interop_matrix/run_interop_matrix_tests.py,"@@ -92,136 +93,149 @@     nargs='?',     help='The gateway to backend services.') -args = argp.parse_args()--print(str(args)) --def find_all_images_for_lang(lang):+def _get_test_images_for_lang(lang, release_arg, image_path_prefix):     """"""Find docker images for a language across releases and runtimes.    Returns dictionary of list of (<tag>, <image-full-path>) keyed by runtime.   """"""-    # Find all defined releases.-    if args.release == 'all':-        releases = ['master'] + client_matrix.get_release_tags(lang)+    if release_arg == 'all':+        # Use all defined releases for given language+        releases = client_matrix.get_release_tags(lang)     else:         # Look for a particular release.-        if args.release not in ['master'-                               ] + client_matrix.get_release_tags(lang):+        if release_arg not in client_matrix.get_release_tags(lang):             jobset.message(                 'SKIPPED',-                '%s for %s is not defined' % (args.release, lang),+                'release %s for %s is not defined' % (release_arg, lang),                 do_newline=True)             return {}-        releases = [args.release]+        releases = [release_arg] -    # TODO(jtattermusch): why do we need to query the existing images/tags?-    # From LANG_RUNTIME_MATRIX and LANG_RELEASE_MATRIX it should be obvious-    # which tags we want to test - and it should be an error if they are-    # missing.     # Images tuples keyed by runtime.     images = {}     for runtime in client_matrix.LANG_RUNTIME_MATRIX[lang]:-        image_path = '%s/grpc_interop_%s' % (args.gcr_path, runtime)-        output = subprocess.check_output([-            'gcloud', 'beta', 'container', 'images', 'list-tags',-            '--format=json', image_path-        ])-        docker_image_list = json.loads(output)-        # All images should have a single tag or no tag.-        # TODO(adelez): Remove tagless images.-        tags = [i['tags'][0] for i in docker_image_list if i['tags']]-        jobset.message(-            'START',-            'Found images for %s: %s' % (image_path, tags),-            do_newline=True)-        skipped = len(docker_image_list) - len(tags)-        jobset.message(-            'SKIPPED',-            'Skipped images (no-tag/unknown-tag): %d' % skipped,-            do_newline=True)-        # Filter tags based on the releases.-        images[runtime] = [(tag, '%s:%s' % (image_path, tag))-                           for tag in tags-                           if tag in releases]+        image_path = '%s/grpc_interop_%s' % (image_path_prefix, runtime)+        images[runtime] = [+            (tag, '%s:%s' % (image_path, tag)) for tag in releases+        ]     return images  -# caches test cases (list of JobSpec) loaded from file.  Keyed by lang and runtime.-def find_test_cases(lang, runtime, release, suite_name):-    """"""Returns the list of test cases from testcase files per lang/release.""""""+def _read_test_cases_file(lang, runtime, release):+    """"""Read test cases from a bash-like file and return a list of commands""""""     testcase_dir = os.path.join(os.path.dirname(__file__), 'testcases')     filename_prefix = lang     if lang == 'csharp':+        # TODO(jtattermusch): remove this odd specialcase         filename_prefix = runtime     # Check to see if we need to use a particular version of test cases.     lang_version = '%s_%s' % (filename_prefix, release)     if lang_version in client_matrix.TESTCASES_VERSION_MATRIX:-        testcases = os.path.join(+        testcase_file = os.path.join(             testcase_dir, client_matrix.TESTCASES_VERSION_MATRIX[lang_version])     else:-        testcases = os.path.join(testcase_dir, '%s__master' % filename_prefix)+        # TODO(jtattermusch): remove the double-underscore, it is pointless+        testcase_file = os.path.join(testcase_dir,+                                     '%s__master' % filename_prefix)++    lines = []+    with open(testcase_file) as f:+        for line in f.readlines():+            line = re.sub('\\#.*$', '', line)  # remove hash comments+            line = line.strip()+            if line and not line.startswith('echo'):+                # Each non-empty line is a treated as a test case command+                lines.append(line)+    return lines+++def _cleanup_docker_image(image):+    jobset.message('START', 'Cleanup docker image %s' % image, do_newline=True)+    dockerjob.remove_image(image, skip_nonexistent=True)+++args = argp.parse_args()+++# caches test cases (list of JobSpec) loaded from file.  Keyed by lang and runtime.+def _generate_test_case_jobspecs(lang, runtime, release, suite_name):+    """"""Returns the list of test cases from testcase files per lang/release.""""""+    testcase_lines = _read_test_cases_file(lang, runtime, release)      job_spec_list = []-    try:-        with open(testcases) as f:-            # Only line start with 'docker run' are test cases.-            for line in f.readlines():-                if line.startswith('docker run'):-                    m = re.search('--test_case=(.*)""', line)-                    shortname = m.group(1) if m else 'unknown_test'-                    m = re.search(-                        '--server_host_override=(.*).sandbox.googleapis.com',-                        line)-                    server = m.group(1) if m else 'unknown_server'--                    # If server_host arg is not None, replace the original-                    # server_host with the one provided or append to the end of-                    # the command if server_host does not appear originally.-                    if args.server_host:-                        if line.find('--server_host=') > -1:-                            line = re.sub('--server_host=[^ ]*',-                                          '--server_host=%s' % args.server_host,-                                          line)-                        else:-                            line = '%s --server_host=%s""' % (line[:-1],-                                                             args.server_host)-                        print(line)--                    spec = jobset.JobSpec(-                        cmdline=line,-                        shortname='%s:%s:%s:%s' % (suite_name, lang, server,-                                                   shortname),-                        timeout_seconds=_TEST_TIMEOUT,-                        shell=True,-                        flake_retries=5 if args.allow_flakes else 0)-                    job_spec_list.append(spec)-            jobset.message(-                'START',-                'Loaded %s tests from %s' % (len(job_spec_list), testcases),-                do_newline=True)-    except IOError as err:-        jobset.message('FAILED', err, do_newline=True)+    for line in testcase_lines:+        m = re.search('--test_case=(.*)""', line)+        shortname = m.group(1) if m else 'unknown_test'+        m = re.search('--server_host_override=(.*).sandbox.googleapis.com',+                      line)+        server = m.group(1) if m else 'unknown_server'++        # If server_host arg is not None, replace the original+        # server_host with the one provided or append to the end of+        # the command if server_host does not appear originally.+        if args.server_host:+            if line.find('--server_host=') > -1:+                line = re.sub('--server_host=[^ ]*',+                              '--server_host=%s' % args.server_host, line)+            else:+                line = '%s --server_host=%s""' % (line[:-1], args.server_host)++        spec = jobset.JobSpec(+            cmdline=line,+            shortname='%s:%s:%s:%s' % (suite_name, lang, server, shortname),+            timeout_seconds=_TEST_TIMEOUT_SECONDS,+            shell=True,+            flake_retries=5 if args.allow_flakes else 0)+        job_spec_list.append(spec)     return job_spec_list  -_xml_report_tree = report_utils.new_junit_xml_tree()+def _pull_images_for_lang(lang, images):+    """"""Pull all images for given lang from container registry.""""""+    jobset.message(+        'START', 'Downloading images for language ""%s""' % lang, do_newline=True)+    download_specs = []+    for release, image in images:+        # Pull the image and warm it up.+        # First time we use an image with ""docker run"", it takes time to unpack the image+        # and later this delay would fail our test cases.+        cmdline = [+            'gcloud docker -- pull %s && docker run --rm=true %s /bin/true' %",Can we be certain that this is strictly a `docker run` issue and not another kind of cache-miss-then-hit-on-subsequent-test-runs that's outside of docker and possibly due to grpc clients? There are other places that `docker run` on a freshly pulled image without a warmup `docker run` first - albeit maybe not with a short timeout on the `docker run`. Otherwise this seems like a bad docker gotcha,
83361,euroelessar,https://api.github.com/repos/grpc/grpc/pulls/16946,227495207,2018-10-23T17:41:16Z,src/python/grpcio/grpc/_common.py,"@@ -62,22 +62,30 @@ }  -def encode(s):-    if isinstance(s, bytes):+def encode(s):  #pylint: disable=inconsistent-return-statements+    if isinstance(s, bytes) or (six.PY2 and isinstance(s, str)):         return s     else:-        return s.encode('ascii')+        for encoding in ['utf8', 'latin1']:+            try:+                return s.encode(encoding)+            except UnicodeEncodeError:+                pass+        _LOGGER.exception('Cannot encode %s', s)+        return s  -def decode(b):-    if isinstance(b, str):+def decode(b):  #pylint: disable=inconsistent-return-statements","maybe smth simple like this?```if isinstance(b, bytes):  return b.decode('utf-8', 'replace')return b```similar for `def encode`, just always encoding it as `utf-8` should make a deal",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/16946,227500928,2018-10-23T17:57:07Z,src/python/grpcio/grpc/_common.py,"@@ -62,22 +62,30 @@ }  -def encode(s):-    if isinstance(s, bytes):+def encode(s):  #pylint: disable=inconsistent-return-statements+    if isinstance(s, bytes) or (six.PY2 and isinstance(s, str)):         return s     else:-        return s.encode('ascii')+        for encoding in ['utf8', 'latin1']:+            try:+                return s.encode(encoding)+            except UnicodeEncodeError:+                pass+        _LOGGER.exception('Cannot encode %s', s)+        return s  -def decode(b):-    if isinstance(b, str):+def decode(b):  #pylint: disable=inconsistent-return-statements","If possible, I want to keep the message content. The replace will get rid of character that `utf-8` can't understand. It will fail some cases, if people transmit pure binary data.",OK
83361,euroelessar,https://api.github.com/repos/grpc/grpc/pulls/16946,227535471,2018-10-23T19:37:56Z,src/python/grpcio/grpc/_common.py,"@@ -62,22 +62,30 @@ }  -def encode(s):-    if isinstance(s, bytes):+def encode(s):  #pylint: disable=inconsistent-return-statements+    if isinstance(s, bytes) or (six.PY2 and isinstance(s, str)):         return s     else:-        return s.encode('ascii')+        for encoding in ['utf8', 'latin1']:+            try:+                return s.encode(encoding)+            except UnicodeEncodeError:+                pass+        _LOGGER.exception('Cannot encode %s', s)+        return s  -def decode(b):-    if isinstance(b, str):+def decode(b):  #pylint: disable=inconsistent-return-statements","gRPC HTTP/2 spec explicitly states that message is an utf-8 message, so pure binary data is not an acceptable input (and therefore it should be sanitized, but not honored).Please see https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md#responses for more details.It will be also consistent to grpc-go behavior, which currently sanitizes status messages by replacing invalid bytes sequences with the Unicode replacement character.",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/16945,227567301,2018-10-23T21:15:02Z,tools/run_tests/run_tests.py,"@@ -759,8 +759,12 @@ def dockerfile_dir(self):             self.python_manager_name(), _docker_arch_suffix(self.args.arch))      def python_manager_name(self):-        if self.args.compiler in ['python3.5', 'python3.6']:-            return 'pyenv'+        if self.args.compiler == 'python3.5':+            return 'stretch_35'+        elif self.args.compiler == 'python3.6':+            return 'stretch_36'+        elif self.args.compiler == 'python3.7':+            return 'stretch_37'         elif self.args.compiler == 'python_alpine':             return 'alpine'         else:","The Python3.4 can only be installed by `apt-get` in `jessie`. The `stretch` minimal version of Python3 is Python3.5. So, can we put the `jessie` back for now. And once we moved to Python3.7 successfully, we remove the `jessie` dependency?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16507,227580612,2018-10-23T21:59:50Z,src/core/ext/filters/client_channel/subchannel.cc,"@@ -994,4 +1133,18 @@ grpc_error* ConnectedSubchannel::CreateCall(const CallArgs& args,   return GRPC_ERROR_NONE; } +size_t ConnectedSubchannel::GetInitialCallSizeEstimate(+    size_t parent_data_size) const {+  size_t allocation_size =+      GPR_ROUND_UP_TO_ALIGNMENT_SIZE(sizeof(grpc_subchannel_call));+  if (parent_data_size > 0) {+    allocation_size +=+        GPR_ROUND_UP_TO_ALIGNMENT_SIZE(channel_stack_->call_stack_size) ++        parent_data_size;+  } else {+    allocation_size += channel_stack_->call_stack_size;","The alignment padding is only needed when allocating space for two objects at the same time, where the address of the second object needs to start at the alignment boundary.  In the case where `parent_data_size` is zero, there is no second object, so no padding is needed.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/16945,227606205,2018-10-24T00:07:37Z,tools/run_tests/run_tests.py,"@@ -759,8 +759,10 @@ def dockerfile_dir(self):             self.python_manager_name(), _docker_arch_suffix(self.args.arch))      def python_manager_name(self):-        if self.args.compiler in ['python3.5', 'python3.6']:-            return 'pyenv'+        if self.args.compiler in [+                'python2.7', 'python3.5', 'python3.6', 'python3.7'+        ]:+            return 'stretch_%s' % re.sub(r'\D*', '', self.args.compiler)",I am fine with both solution.Just that we will have a dot in naming...,OK
2819812,zpencer,https://api.github.com/repos/grpc/grpc/pulls/16898,227615455,2018-10-24T01:13:23Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -2576,6 +2593,39 @@ static void start_retriable_subchannel_batches(void* arg, grpc_error* ignored) { // LB pick // +// The callback to intercept trailing metadata if retries is not enabled+static void recv_trailing_metadata_ready_for_lb(void* arg, grpc_error* error) {+  subchannel_batch_data* batch_data = static_cast<subchannel_batch_data*>(arg);+  grpc_call_element* elem = batch_data->elem;+  call_data* calld = static_cast<call_data*>(elem->call_data);+  if (calld->pick.recv_trailing_metadata != nullptr) {+    *calld->pick.recv_trailing_metadata =+        batch_data->batch.payload->recv_trailing_metadata+            .recv_trailing_metadata;+  }+  GRPC_CLOSURE_SCHED(+      calld->pick.recv_trailing_metadata_ready,+      GRPC_ERROR_REF(error));+  GRPC_CLOSURE_RUN(+      calld->original_recv_trailing_metadata_ready,+      GRPC_ERROR_REF(error));+}++// Installs a interceptor to inform the lb of the trailing metadata, if needed+static void maybe_intercept_trailing_metadata_for_lb(+    void* arg, grpc_transport_stream_op_batch* batch) {+  subchannel_batch_data* batch_data = static_cast<subchannel_batch_data*>(arg);+  grpc_call_element* elem = batch_data->elem;+  call_data* calld = static_cast<call_data*>(elem->call_data);+  calld->original_recv_trailing_metadata_ready =+      batch->payload->recv_trailing_metadata.recv_trailing_metadata_ready;+  GRPC_CLOSURE_INIT(&calld->recv_trailing_metadata_ready_for_lb,+                    recv_trailing_metadata_ready_for_lb, elem,+                    grpc_schedule_on_exec_ctx);","> GRPC_CLOSURE_RUN() will invoke the closure immediately -- but note that this is intended to be used when already holding the combiner and when invoking a closure that you know is also using the same combiner; Bad Things(tm) happen when either of those two conditions is not met.I see the assers you are referring to now: https://github.com/grpc/grpc/blob/master/src/core/lib/iomgr/combiner.cc#L357> So for now, we should use grpc_combiner_scheduler(chand->combiner) here.So in effect, in the end state we will split chand->combiner into two (control vs data plane synchronizations)?  And does this mean using grpc_schedule_on_exec_ctx be just wrong then, because it is the thread local closure scheduler and fails to synchronize on the channel object?",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16898,227893797,2018-10-24T17:49:15Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -2576,6 +2593,39 @@ static void start_retriable_subchannel_batches(void* arg, grpc_error* ignored) { // LB pick // +// The callback to intercept trailing metadata if retries is not enabled+static void recv_trailing_metadata_ready_for_lb(void* arg, grpc_error* error) {+  subchannel_batch_data* batch_data = static_cast<subchannel_batch_data*>(arg);+  grpc_call_element* elem = batch_data->elem;+  call_data* calld = static_cast<call_data*>(elem->call_data);+  if (calld->pick.recv_trailing_metadata != nullptr) {+    *calld->pick.recv_trailing_metadata =+        batch_data->batch.payload->recv_trailing_metadata+            .recv_trailing_metadata;+  }+  GRPC_CLOSURE_SCHED(+      calld->pick.recv_trailing_metadata_ready,+      GRPC_ERROR_REF(error));+  GRPC_CLOSURE_RUN(+      calld->original_recv_trailing_metadata_ready,+      GRPC_ERROR_REF(error));+}++// Installs a interceptor to inform the lb of the trailing metadata, if needed+static void maybe_intercept_trailing_metadata_for_lb(+    void* arg, grpc_transport_stream_op_batch* batch) {+  subchannel_batch_data* batch_data = static_cast<subchannel_batch_data*>(arg);+  grpc_call_element* elem = batch_data->elem;+  call_data* calld = static_cast<call_data*>(elem->call_data);+  calld->original_recv_trailing_metadata_ready =+      batch->payload->recv_trailing_metadata.recv_trailing_metadata_ready;+  GRPC_CLOSURE_INIT(&calld->recv_trailing_metadata_ready_for_lb,+                    recv_trailing_metadata_ready_for_lb, elem,+                    grpc_schedule_on_exec_ctx);","> > GRPC_CLOSURE_RUN() will invoke the closure immediately -- but note that this is intended to be used when already holding the combiner and when invoking a closure that you know is also using the same combiner; Bad Things(tm) happen when either of those two conditions is not met.> > > I see the assers you are referring to now: https://github.com/grpc/grpc/blob/master/src/core/lib/iomgr/combiner.cc#L357It looks like that assertion would catch a case where we were accidentally using `GRPC_CLOSURE_RUN()` for a closure running on a *different* combiner than the one we're currently executing in.  However, it would not catch the case where we use `GRPC_CLOSURE_RUN()` on a closure that's running on the `ExecCtx` scheduler (or some other scheduler) while running within a combiner; in that case, there's no way for the scheduler to catch it, beacuse the other schedulers' implementations of `GRPC_CLOSURE_RUN()` don't have any knowledge of the combiner scheduler.  If we accidentally did that anywhere, the result would be that we would wind up increasing lock contention by holding the combiner while running code that doesn't need to be run in the combiner.> > So for now, we should use grpc_combiner_scheduler(chand->combiner) here.> > > So in effect, in the end state we will split chand->combiner into two (control vs data plane synchronizations)?The main goal is to split the data plane and control plane so that they don't interfere with each other.  However, it is likely that we won't want a single combiner for the control plane work; instead, we will probably want each resolver and each LB policy to provide their own synchronization for the control plane work, so that (a) their respective APIs are simplified by removing the need to coordinate use of the combiner and (b) each object can do its own control plane work in parallel.  But we can discuss this further when we start actively working on this.> And does this mean using grpc_schedule_on_exec_ctx be just wrong then, because it is the thread local closure scheduler and fails to synchronize on the channel object?First, note that the `ExecCtx` scheduler is not strictly a thread-local scheduler; there are cases where a closure scheduled on the `ExecCtx` will actually not be executed right away but will instead wait for the next call into core.Second, as mentioned above, the main reason it's wrong to use the `ExecCtx` scheduler here is that it would execute code that doesn't need the combiner while still holding the combiner.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16997,228249228,2018-10-25T16:38:58Z,src/cpp/server/channelz/channelz_service.cc,"@@ -25,6 +25,135 @@  namespace grpc { +Status ChannelzService::GetTopChannels(",It looks like you've accidentally duplicated some code here.,OK
2819812,zpencer,https://api.github.com/repos/grpc/grpc/pulls/16898,228360703,2018-10-25T22:52:04Z,src/core/ext/filters/client_channel/lb_policy.h,"@@ -73,6 +73,16 @@ class LoadBalancingPolicy     /// Closure to run when pick is complete, if not completed synchronously.     /// If null, pick will fail if a result is not available synchronously.     grpc_closure* on_complete;++    // Callback set by lb policy to be notified of trailing metadata.+    // The callback must be scheduled on grpc_schedule_on_exec_ctx.+    grpc_closure* recv_trailing_metadata_ready;","I'm not sure what's the best way to handle ownership of the metadata.  At first I thought this closure should be initialized to run on `grpc_combiner_scheduler(args_.combiner)`, but then I notice that by the time it runs the metadata has already been freed. Should I instead make a copy of the metadata, or bump the refs of the existing metadata, and have the closure be responsible for freeing it?",
2819812,zpencer,https://api.github.com/repos/grpc/grpc/pulls/16898,228361768,2018-10-25T22:57:32Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -2576,6 +2596,45 @@ static void start_retriable_subchannel_batches(void* arg, grpc_error* ignored) { // LB pick // +// The callback to intercept trailing metadata if retries is not enabled+static void recv_trailing_metadata_ready_for_lb(void* arg, grpc_error* error) {+  grpc_call_element* elem = static_cast<grpc_call_element*>(arg);+  call_data* calld = static_cast<call_data*>(elem->call_data);+  if (calld->pick.recv_trailing_metadata != nullptr) {+    *calld->pick.recv_trailing_metadata =+        calld->recv_trailing_metadata_op_batch->payload+            ->recv_trailing_metadata.recv_trailing_metadata;+  }+  GRPC_CLOSURE_SCHED(+      calld->pick.recv_trailing_metadata_ready,+      GRPC_ERROR_REF(error));+  GRPC_CLOSURE_SCHED(+      calld->original_recv_trailing_metadata_ready,+      GRPC_ERROR_REF(error));+  GRPC_ERROR_UNREF(error);+}++// If needed, intercepts the recv_trailing_metadata_ready callback to return+// trailing metadata to the LB policy.+static void maybe_intercept_trailing_metadata_for_lb(+    grpc_call_element* elem, grpc_transport_stream_op_batch* batch) {+  call_data* calld = static_cast<call_data*>(elem->call_data);+  if (!batch->recv_trailing_metadata) {+    return;+  }+  if (calld->pick.recv_trailing_metadata_ready != nullptr) {+    calld->recv_trailing_metadata_op_batch = batch;+    GRPC_CLOSURE_INIT(&calld->recv_trailing_metadata_ready_for_lb,+                      recv_trailing_metadata_ready_for_lb,+                      elem,+                      grpc_schedule_on_exec_ctx);","I know we have discussed using `grpc_combiner_scheduler(chand->combiner)` here, but it turns out there's a place that calls this using GRPC_CLOSURE_RUN under a different combiner [here](https://github.com/grpc/grpc/blob/08ef3bca1a10cb3ee46aa2037fe412c75407a067/src/core/ext/filters/message_size/message_size_filter.cc#L185). `grpc_schedule_on_exec_ctx` seems to work. Maybe I am still missing somewhere wrt the execution model. ",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16898,228590541,2018-10-26T16:31:39Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -2576,6 +2596,45 @@ static void start_retriable_subchannel_batches(void* arg, grpc_error* ignored) { // LB pick // +// The callback to intercept trailing metadata if retries is not enabled+static void recv_trailing_metadata_ready_for_lb(void* arg, grpc_error* error) {+  grpc_call_element* elem = static_cast<grpc_call_element*>(arg);+  call_data* calld = static_cast<call_data*>(elem->call_data);+  if (calld->pick.recv_trailing_metadata != nullptr) {+    *calld->pick.recv_trailing_metadata =+        calld->recv_trailing_metadata_op_batch->payload+            ->recv_trailing_metadata.recv_trailing_metadata;+  }+  GRPC_CLOSURE_SCHED(+      calld->pick.recv_trailing_metadata_ready,+      GRPC_ERROR_REF(error));+  GRPC_CLOSURE_SCHED(+      calld->original_recv_trailing_metadata_ready,+      GRPC_ERROR_REF(error));+  GRPC_ERROR_UNREF(error);+}++// If needed, intercepts the recv_trailing_metadata_ready callback to return+// trailing metadata to the LB policy.+static void maybe_intercept_trailing_metadata_for_lb(+    grpc_call_element* elem, grpc_transport_stream_op_batch* batch) {+  call_data* calld = static_cast<call_data*>(elem->call_data);+  if (!batch->recv_trailing_metadata) {+    return;+  }+  if (calld->pick.recv_trailing_metadata_ready != nullptr) {+    calld->recv_trailing_metadata_op_batch = batch;+    GRPC_CLOSURE_INIT(&calld->recv_trailing_metadata_ready_for_lb,+                      recv_trailing_metadata_ready_for_lb,+                      elem,+                      grpc_schedule_on_exec_ctx);","Looking at this now, I think `grpc_schedule_on_exec_ctx` is correct here.  I think when I told you to use the combiner scheduler, I was thinking that this was for the closure being set by the LB policy itself, not the one here in the client channel.  For this one, there's no need to use the combiner, because we're not accessing anything in the filter's channel_data struct that's protected by the combiner.  And, as you correctly point out, the fact that this callback will be invoked via `GRPC_CLOSURE_RUN()` from whatever filter is below us means that we can't run this filter in the combiner anyway.Sorry for steering you wrong here, and good job figuring out that what I said was wrong!",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16898,228591993,2018-10-26T16:36:18Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -2576,6 +2596,45 @@ static void start_retriable_subchannel_batches(void* arg, grpc_error* ignored) { // LB pick // +// The callback to intercept trailing metadata if retries is not enabled+static void recv_trailing_metadata_ready_for_lb(void* arg, grpc_error* error) {+  grpc_call_element* elem = static_cast<grpc_call_element*>(arg);+  call_data* calld = static_cast<call_data*>(elem->call_data);+  if (calld->pick.recv_trailing_metadata != nullptr) {+    *calld->pick.recv_trailing_metadata =+        calld->recv_trailing_metadata_op_batch->payload+            ->recv_trailing_metadata.recv_trailing_metadata;+  }+  GRPC_CLOSURE_SCHED(","I don't think we can safely use `GRPC_CLOSURE_SCHED()` here, due to the problem you pointed out below about metadata ownership (see discussion below).  Instead, I think we're going to have to find a way to run this closure in the normal chained way -- i.e., we need to invoke this closure, let it run to completion, and then have it invoke the next closure when it's done.  This is unfortunate, because it makes the LB policy API a bit more complicated, but I don't see any reasonable way around it.I can think of two ways of doing this (although this is not necessarily an exhaustive list -- please feel free to offer alternatives).One way is to make the LB policy's interaction with this callback work more like a filter's interaction: we pass the original closure to the LB policy and let it save the original closure and replace it with its own, which would then invoke the original closure when it's done doing its own work.  This seems a little messy and would probably broaden the LB policy API more than I'd really want it to.The other option is to have the LB policy provide a callback that must be run synchronously, and have the client_channel take care of the synchronization.  In other words, the client channel could do the work of popping into the combiner and invoking the LB policy's callback, and then when the LB policy's callback finishes, the client channel can then invoke the original callback to pass control back up the stack.  The LB policy's callback could be returned either as a custom function pointer with a void* arg, or it could be returned as a closure that runs on the `ExecCtx` scheduler, and the client_channel could always invoke it with `GRPC_CLOSURE_RUN()`.One thing to keep in mind here is the fact that we eventually want to split up synchronization between the data plane and the control plane to avoid contention.  The feedback we're giving to the LB policy by allowing it to see the trailing metadata is control plane in nature, but it happens on a per-call basis, which means that it needs data plane performance.  I'm not sure offhand exactly what that means in terms of how we'll want to handle it once we do split up the synchronization, but it may be worth thinking that through before we decide how to handle the current problem, so that we don't make it harder to do the synchronization split later.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16898,228595888,2018-10-26T16:50:16Z,src/core/ext/filters/client_channel/lb_policy.h,"@@ -73,6 +73,16 @@ class LoadBalancingPolicy     /// Closure to run when pick is complete, if not completed synchronously.     /// If null, pick will fail if a result is not available synchronously.     grpc_closure* on_complete;++    // Callback set by lb policy to be notified of trailing metadata.+    // The callback must be scheduled on grpc_schedule_on_exec_ctx.+    grpc_closure* recv_trailing_metadata_ready;","Unfortunately, `grpc_metadata_batch` objects are not ref-counted.  And copying the batch would be bad for performance, because it would require memory allocation.  So I don't think we have any choice but to chain the callbacks, as I described above.Note that the closure created by the LB policy *does* need to run on the combiner scheduler, since the combiner is currently the thing sychronizing everything that happens in the LB policy.  If it doesn't run in the combiner, then the LB policy has to provide some other synchronization mechanism to actually do anything useful with the metadata when the closure gets invoked.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16898,228597994,2018-10-26T16:57:33Z,test/cpp/end2end/client_lb_end2end_test.cc,"@@ -996,6 +1004,199 @@ TEST_F(ClientLbEnd2endTest, RoundRobinSingleReconnect) {   WaitForServer(stub, 0, DEBUG_LOCATION); } +// A minimal forwarding class to avoid implementing a standalone test LB.+class ForwardingLoadBalancingPolicy : public grpc_core::LoadBalancingPolicy {+ public:+  ForwardingLoadBalancingPolicy(+      const Args& args,+      const std::string& delegate_policy_name)+      : grpc_core::LoadBalancingPolicy(args), args_{args} {+    delegate_ = grpc_core::LoadBalancingPolicyRegistry+        ::CreateLoadBalancingPolicy(delegate_policy_name.c_str(), args);+    grpc_pollset_set_add_pollset_set(+        delegate_->interested_parties(),+        interested_parties());+  }++  void UpdateLocked(const grpc_channel_args& args) override {+    delegate_->UpdateLocked(args);+  }++  bool PickLocked(PickState* pick, grpc_error** error) override {+    return delegate_->PickLocked(pick, error);+  }++  void CancelPickLocked(PickState* pick, grpc_error* error) override {+    delegate_->CancelPickLocked(pick, error);+  }++  void CancelMatchingPicksLocked(uint32_t initial_metadata_flags_mask,+                                 uint32_t initial_metadata_flags_eq,+                                 grpc_error* error) override {+    delegate_->CancelMatchingPicksLocked(+        initial_metadata_flags_mask,+        initial_metadata_flags_eq,+        error);+  }++  void NotifyOnStateChangeLocked(grpc_connectivity_state* state,+                                 grpc_closure* closure) override {+    delegate_->NotifyOnStateChangeLocked(state, closure);+  }++  grpc_connectivity_state CheckConnectivityLocked(+      grpc_error** connectivity_error) override {+    return delegate_->CheckConnectivityLocked(connectivity_error);+  }++  void HandOffPendingPicksLocked(LoadBalancingPolicy* new_policy) override {+    delegate_->HandOffPendingPicksLocked(new_policy);+  }++  void ExitIdleLocked() override{+    delegate_->ExitIdleLocked();+  }++  void ResetBackoffLocked() override {+    delegate_->ResetBackoffLocked();+  }++  void FillChildRefsForChannelz(+      grpc_core::channelz::ChildRefsList* child_subchannels,+      grpc_core::channelz::ChildRefsList* ignored) override {+    delegate_->FillChildRefsForChannelz(child_subchannels, ignored);+  }++ protected:+  void ShutdownLocked() override {+    // noop+  }+  Args args_;++ private:+  grpc_core::OrphanablePtr<LoadBalancingPolicy> delegate_;+};++class ClientLbInterceptTrailingMetadataTest : public ClientLbEnd2endTest {+ protected:+  void SetUp() override {+    ClientLbEnd2endTest::SetUp();+    grpc_core::LoadBalancingPolicyRegistry::Builder::+        RegisterLoadBalancingPolicyFactory(+            grpc_core::UniquePtr<grpc_core::LoadBalancingPolicyFactory>(+                grpc_core::New<InterceptTrailingFactory>(this)));+  }++  void TearDown() override {+    ClientLbEnd2endTest::TearDown();+  }++  class InterceptTrailingLb : public ForwardingLoadBalancingPolicy {+   public:+    InterceptTrailingLb(+        const Args& args,+        const std::string& delegate_lb_policy_name,+        ClientLbInterceptTrailingMetadataTest* test)+        : ForwardingLoadBalancingPolicy(args, delegate_lb_policy_name),+        test_{test} {+    }++    bool PickLocked(PickState* pick, grpc_error** error) override {+      bool ret = ForwardingLoadBalancingPolicy::PickLocked(pick, error);+      // If these asserts fail, then we will need to add code to+      // proxy the results to the delegate LB.+      GPR_ASSERT(pick->recv_trailing_metadata == nullptr);+      GPR_ASSERT(pick->recv_trailing_metadata_ready == nullptr);+      // OK to add add callbacks for test+      GRPC_CLOSURE_INIT(+          &recv_trailing_metadata_ready_,+          InterceptTrailingLb::RecordRecvTrailingMetadata,+          this,+          grpc_schedule_on_exec_ctx);","As mentioned above, this needs to run in the combiner.  Otherwise, the LB policy won't be able to safely do anything with the data that results in modifying its internal state.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16898,228598593,2018-10-26T16:59:35Z,test/cpp/end2end/client_lb_end2end_test.cc,"@@ -996,6 +1004,199 @@ TEST_F(ClientLbEnd2endTest, RoundRobinSingleReconnect) {   WaitForServer(stub, 0, DEBUG_LOCATION); } +// A minimal forwarding class to avoid implementing a standalone test LB.+class ForwardingLoadBalancingPolicy : public grpc_core::LoadBalancingPolicy {+ public:+  ForwardingLoadBalancingPolicy(+      const Args& args,+      const std::string& delegate_policy_name)+      : grpc_core::LoadBalancingPolicy(args), args_{args} {+    delegate_ = grpc_core::LoadBalancingPolicyRegistry+        ::CreateLoadBalancingPolicy(delegate_policy_name.c_str(), args);+    grpc_pollset_set_add_pollset_set(+        delegate_->interested_parties(),+        interested_parties());+  }++  void UpdateLocked(const grpc_channel_args& args) override {+    delegate_->UpdateLocked(args);+  }++  bool PickLocked(PickState* pick, grpc_error** error) override {+    return delegate_->PickLocked(pick, error);+  }++  void CancelPickLocked(PickState* pick, grpc_error* error) override {+    delegate_->CancelPickLocked(pick, error);+  }++  void CancelMatchingPicksLocked(uint32_t initial_metadata_flags_mask,+                                 uint32_t initial_metadata_flags_eq,+                                 grpc_error* error) override {+    delegate_->CancelMatchingPicksLocked(+        initial_metadata_flags_mask,+        initial_metadata_flags_eq,+        error);+  }++  void NotifyOnStateChangeLocked(grpc_connectivity_state* state,+                                 grpc_closure* closure) override {+    delegate_->NotifyOnStateChangeLocked(state, closure);+  }++  grpc_connectivity_state CheckConnectivityLocked(+      grpc_error** connectivity_error) override {+    return delegate_->CheckConnectivityLocked(connectivity_error);+  }++  void HandOffPendingPicksLocked(LoadBalancingPolicy* new_policy) override {+    delegate_->HandOffPendingPicksLocked(new_policy);+  }++  void ExitIdleLocked() override{+    delegate_->ExitIdleLocked();+  }++  void ResetBackoffLocked() override {+    delegate_->ResetBackoffLocked();+  }++  void FillChildRefsForChannelz(+      grpc_core::channelz::ChildRefsList* child_subchannels,+      grpc_core::channelz::ChildRefsList* ignored) override {+    delegate_->FillChildRefsForChannelz(child_subchannels, ignored);+  }++ protected:+  void ShutdownLocked() override {+    // noop+  }+  Args args_;++ private:+  grpc_core::OrphanablePtr<LoadBalancingPolicy> delegate_;+};++class ClientLbInterceptTrailingMetadataTest : public ClientLbEnd2endTest {+ protected:+  void SetUp() override {+    ClientLbEnd2endTest::SetUp();+    grpc_core::LoadBalancingPolicyRegistry::Builder::+        RegisterLoadBalancingPolicyFactory(+            grpc_core::UniquePtr<grpc_core::LoadBalancingPolicyFactory>(+                grpc_core::New<InterceptTrailingFactory>(this)));+  }++  void TearDown() override {+    ClientLbEnd2endTest::TearDown();+  }++  class InterceptTrailingLb : public ForwardingLoadBalancingPolicy {+   public:+    InterceptTrailingLb(+        const Args& args,+        const std::string& delegate_lb_policy_name,+        ClientLbInterceptTrailingMetadataTest* test)+        : ForwardingLoadBalancingPolicy(args, delegate_lb_policy_name),+        test_{test} {+    }++    bool PickLocked(PickState* pick, grpc_error** error) override {+      bool ret = ForwardingLoadBalancingPolicy::PickLocked(pick, error);+      // If these asserts fail, then we will need to add code to+      // proxy the results to the delegate LB.+      GPR_ASSERT(pick->recv_trailing_metadata == nullptr);+      GPR_ASSERT(pick->recv_trailing_metadata_ready == nullptr);+      // OK to add add callbacks for test+      GRPC_CLOSURE_INIT(+          &recv_trailing_metadata_ready_,+          InterceptTrailingLb::RecordRecvTrailingMetadata,+          this,+          grpc_schedule_on_exec_ctx);+      pick->recv_trailing_metadata_ready = &recv_trailing_metadata_ready_;","Note that using the same data members for all calls means that this LB policy can only handle a single call at a time.  That's probably fine for this test, but it's probably worth adding a comment about.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16898,228598936,2018-10-26T17:00:35Z,test/cpp/end2end/client_lb_end2end_test.cc,"@@ -996,6 +1004,199 @@ TEST_F(ClientLbEnd2endTest, RoundRobinSingleReconnect) {   WaitForServer(stub, 0, DEBUG_LOCATION); } +// A minimal forwarding class to avoid implementing a standalone test LB.+class ForwardingLoadBalancingPolicy : public grpc_core::LoadBalancingPolicy {+ public:+  ForwardingLoadBalancingPolicy(+      const Args& args,+      const std::string& delegate_policy_name)+      : grpc_core::LoadBalancingPolicy(args), args_{args} {+    delegate_ = grpc_core::LoadBalancingPolicyRegistry+        ::CreateLoadBalancingPolicy(delegate_policy_name.c_str(), args);+    grpc_pollset_set_add_pollset_set(+        delegate_->interested_parties(),+        interested_parties());+  }++  void UpdateLocked(const grpc_channel_args& args) override {+    delegate_->UpdateLocked(args);+  }++  bool PickLocked(PickState* pick, grpc_error** error) override {+    return delegate_->PickLocked(pick, error);+  }++  void CancelPickLocked(PickState* pick, grpc_error* error) override {+    delegate_->CancelPickLocked(pick, error);+  }++  void CancelMatchingPicksLocked(uint32_t initial_metadata_flags_mask,+                                 uint32_t initial_metadata_flags_eq,+                                 grpc_error* error) override {+    delegate_->CancelMatchingPicksLocked(+        initial_metadata_flags_mask,+        initial_metadata_flags_eq,+        error);+  }++  void NotifyOnStateChangeLocked(grpc_connectivity_state* state,+                                 grpc_closure* closure) override {+    delegate_->NotifyOnStateChangeLocked(state, closure);+  }++  grpc_connectivity_state CheckConnectivityLocked(+      grpc_error** connectivity_error) override {+    return delegate_->CheckConnectivityLocked(connectivity_error);+  }++  void HandOffPendingPicksLocked(LoadBalancingPolicy* new_policy) override {+    delegate_->HandOffPendingPicksLocked(new_policy);+  }++  void ExitIdleLocked() override{+    delegate_->ExitIdleLocked();+  }++  void ResetBackoffLocked() override {+    delegate_->ResetBackoffLocked();+  }++  void FillChildRefsForChannelz(+      grpc_core::channelz::ChildRefsList* child_subchannels,+      grpc_core::channelz::ChildRefsList* ignored) override {+    delegate_->FillChildRefsForChannelz(child_subchannels, ignored);+  }++ protected:+  void ShutdownLocked() override {+    // noop+  }+  Args args_;++ private:+  grpc_core::OrphanablePtr<LoadBalancingPolicy> delegate_;+};++class ClientLbInterceptTrailingMetadataTest : public ClientLbEnd2endTest {+ protected:+  void SetUp() override {+    ClientLbEnd2endTest::SetUp();+    grpc_core::LoadBalancingPolicyRegistry::Builder::+        RegisterLoadBalancingPolicyFactory(+            grpc_core::UniquePtr<grpc_core::LoadBalancingPolicyFactory>(+                grpc_core::New<InterceptTrailingFactory>(this)));+  }++  void TearDown() override {+    ClientLbEnd2endTest::TearDown();+  }++  class InterceptTrailingLb : public ForwardingLoadBalancingPolicy {+   public:+    InterceptTrailingLb(+        const Args& args,+        const std::string& delegate_lb_policy_name,+        ClientLbInterceptTrailingMetadataTest* test)+        : ForwardingLoadBalancingPolicy(args, delegate_lb_policy_name),+        test_{test} {+    }++    bool PickLocked(PickState* pick, grpc_error** error) override {+      bool ret = ForwardingLoadBalancingPolicy::PickLocked(pick, error);+      // If these asserts fail, then we will need to add code to+      // proxy the results to the delegate LB.+      GPR_ASSERT(pick->recv_trailing_metadata == nullptr);+      GPR_ASSERT(pick->recv_trailing_metadata_ready == nullptr);+      // OK to add add callbacks for test+      GRPC_CLOSURE_INIT(+          &recv_trailing_metadata_ready_,+          InterceptTrailingLb::RecordRecvTrailingMetadata,+          this,+          grpc_schedule_on_exec_ctx);+      pick->recv_trailing_metadata_ready = &recv_trailing_metadata_ready_;+      pick->recv_trailing_metadata = &recv_trailing_metadata_;+      return ret;+    }++    static void RecordRecvTrailingMetadata(void* arg, grpc_error* err) {+      InterceptTrailingLb* lb = static_cast<InterceptTrailingLb*>(arg);+      GPR_ASSERT(err == GRPC_ERROR_NONE);+      GPR_ASSERT(lb->recv_trailing_metadata_ != nullptr);+      // an simple check to make sure the trailing metadata is valid+      GPR_ASSERT(grpc_get_status_code_from_metadata(+          lb->recv_trailing_metadata_->idx.named.grpc_status->md) ==+              grpc_status_code::GRPC_STATUS_OK);+      GRPC_ERROR_UNREF(err);",No need for this -- closures don't take ownership of the error that they are passed.https://github.com/grpc/grpc/blob/master/doc/core/grpc-error.md#ownership-rules,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16898,228601981,2018-10-26T17:12:17Z,test/cpp/end2end/client_lb_end2end_test.cc,"@@ -996,6 +1004,199 @@ TEST_F(ClientLbEnd2endTest, RoundRobinSingleReconnect) {   WaitForServer(stub, 0, DEBUG_LOCATION); } +// A minimal forwarding class to avoid implementing a standalone test LB.+class ForwardingLoadBalancingPolicy : public grpc_core::LoadBalancingPolicy {","This forwarding class needs to handle one more thing, which is the re-resolution callback.  You can model this off of the way that the grpclb policy delegates it to its nested round_robin policy.  Basically, you need to create your own re-resolution callback and pass it to the delegate policy, and when the child policy invokes your callback, you can in turn invoke the callback that the client_channel has given the forwarding class.For an example, see [`GrpcLb::OnRoundRobinRequestReresolutionLocked()`](https://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc#L1748).",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16898,228603170,2018-10-26T17:16:58Z,test/cpp/end2end/client_lb_end2end_test.cc,"@@ -996,6 +1004,199 @@ TEST_F(ClientLbEnd2endTest, RoundRobinSingleReconnect) {   WaitForServer(stub, 0, DEBUG_LOCATION); } +// A minimal forwarding class to avoid implementing a standalone test LB.+class ForwardingLoadBalancingPolicy : public grpc_core::LoadBalancingPolicy {+ public:+  ForwardingLoadBalancingPolicy(+      const Args& args,+      const std::string& delegate_policy_name)+      : grpc_core::LoadBalancingPolicy(args), args_{args} {+    delegate_ = grpc_core::LoadBalancingPolicyRegistry+        ::CreateLoadBalancingPolicy(delegate_policy_name.c_str(), args);+    grpc_pollset_set_add_pollset_set(+        delegate_->interested_parties(),+        interested_parties());+  }++  void UpdateLocked(const grpc_channel_args& args) override {+    delegate_->UpdateLocked(args);+  }++  bool PickLocked(PickState* pick, grpc_error** error) override {+    return delegate_->PickLocked(pick, error);+  }++  void CancelPickLocked(PickState* pick, grpc_error* error) override {+    delegate_->CancelPickLocked(pick, error);+  }++  void CancelMatchingPicksLocked(uint32_t initial_metadata_flags_mask,+                                 uint32_t initial_metadata_flags_eq,+                                 grpc_error* error) override {+    delegate_->CancelMatchingPicksLocked(+        initial_metadata_flags_mask,+        initial_metadata_flags_eq,+        error);+  }++  void NotifyOnStateChangeLocked(grpc_connectivity_state* state,+                                 grpc_closure* closure) override {+    delegate_->NotifyOnStateChangeLocked(state, closure);+  }++  grpc_connectivity_state CheckConnectivityLocked(+      grpc_error** connectivity_error) override {+    return delegate_->CheckConnectivityLocked(connectivity_error);+  }++  void HandOffPendingPicksLocked(LoadBalancingPolicy* new_policy) override {+    delegate_->HandOffPendingPicksLocked(new_policy);+  }++  void ExitIdleLocked() override{+    delegate_->ExitIdleLocked();+  }++  void ResetBackoffLocked() override {+    delegate_->ResetBackoffLocked();+  }++  void FillChildRefsForChannelz(+      grpc_core::channelz::ChildRefsList* child_subchannels,+      grpc_core::channelz::ChildRefsList* ignored) override {+    delegate_->FillChildRefsForChannelz(child_subchannels, ignored);+  }++ protected:+  void ShutdownLocked() override {+    // noop+  }+  Args args_;++ private:+  grpc_core::OrphanablePtr<LoadBalancingPolicy> delegate_;+};++class ClientLbInterceptTrailingMetadataTest : public ClientLbEnd2endTest {+ protected:+  void SetUp() override {+    ClientLbEnd2endTest::SetUp();+    grpc_core::LoadBalancingPolicyRegistry::Builder::+        RegisterLoadBalancingPolicyFactory(+            grpc_core::UniquePtr<grpc_core::LoadBalancingPolicyFactory>(+                grpc_core::New<InterceptTrailingFactory>(this)));+  }++  void TearDown() override {+    ClientLbEnd2endTest::TearDown();+  }++  class InterceptTrailingLb : public ForwardingLoadBalancingPolicy {+   public:+    InterceptTrailingLb(+        const Args& args,+        const std::string& delegate_lb_policy_name,+        ClientLbInterceptTrailingMetadataTest* test)+        : ForwardingLoadBalancingPolicy(args, delegate_lb_policy_name),+        test_{test} {+    }++    bool PickLocked(PickState* pick, grpc_error** error) override {+      bool ret = ForwardingLoadBalancingPolicy::PickLocked(pick, error);+      // If these asserts fail, then we will need to add code to","Note that these asserts aren't necessarily in the right place to catch this problem.  If the delegate LB policy returns asynchronously but doesn't set these fields until right before it invokes the completion callback, then they won't yet be set at this point, but there could still be a problem.In order to handle that, I think we'll need to override the completion callback before invoking the delegate policy's `PickLocked()` method.  The callback we override will then set these fields before invoking the original completion callback.  And in this method, we only set these fields if the pick returns synchronously.Alternatively, if we only plan to test with policies like pick_first that don't intercept trailing metadata themselves, then this is a non-issue.  But let's at least add a comment about it.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16842,228645880,2018-10-26T19:45:15Z,include/grpcpp/impl/codegen/call.h,"@@ -598,12 +792,353 @@ class CallOpSetInterface : public CompletionQueueTag {  public:   /// Fills in grpc_op, starting from ops[*nops] and moving   /// upwards.-  virtual void FillOps(grpc_call* call, grpc_op* ops, size_t* nops) = 0;+  virtual void FillOps(internal::Call* call) = 0;    /// Get the tag to be used at the core completion queue. Generally, the   /// value of cq_tag will be ""this"". However, it can be overridden if we   /// want core to process the tag differently (e.g., as a core callback)   virtual void* cq_tag() = 0;++  // This will be called while interceptors are run if the RPC is a hijacked+  // RPC. This should set hijacking state for each of the ops.+  virtual void SetHijackingState() = 0;++  // Should be called after interceptors are done running+  virtual void ContinueFillOpsAfterInterception() = 0;++  // Should be called after interceptors are done running on the finalize result+  // path+  virtual void ContinueFinalizeResultAfterInterception() = 0;+};++template <class Op1 = CallNoOp<1>, class Op2 = CallNoOp<2>,+          class Op3 = CallNoOp<3>, class Op4 = CallNoOp<4>,+          class Op5 = CallNoOp<5>, class Op6 = CallNoOp<6>>+class CallOpSet;++class InterceptorBatchMethodsImpl : public InternalInterceptorBatchMethods {+ public:+  InterceptorBatchMethodsImpl() {+    for (auto i = 0;",I think it's more clear if you use an enum for the iterator```for (auto i = static_cast<experimental::InterceptionHookPoints>(0); i < experimental::InterceptionHookPoints::NUM_INTERCEPTION_HOOKS```Because even `int` isn't technically the right index for your array (it's `size_t`),OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16842,228654258,2018-10-26T20:18:45Z,include/grpcpp/impl/codegen/call_wrapper.h,"@@ -0,0 +1,91 @@+/*",Suggest renaming `call.h` to `call_op_set.h` and this to `call.h` ... and perhaps cutting out the interceptor content from `call_op_set.h` and putting that in a different file like `interceptor_common.h`,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16842,228658825,2018-10-26T20:37:04Z,include/grpcpp/impl/codegen/server_interceptor.h,"@@ -0,0 +1,102 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPCPP_IMPL_CODEGEN_SERVER_INTERCEPTOR_H+#define GRPCPP_IMPL_CODEGEN_SERVER_INTERCEPTOR_H++#include <atomic>+#include <vector>++#include <grpc/impl/codegen/log.h>+#include <grpcpp/impl/codegen/interceptor.h>+#include <grpcpp/impl/codegen/string_ref.h>++namespace grpc {++class ServerContext;++namespace internal {+class InterceptorBatchMethodsImpl;+}++namespace experimental {+class ServerRpcInfo;++class ServerInterceptorFactoryInterface {+ public:+  virtual ~ServerInterceptorFactoryInterface() {}+  virtual Interceptor* CreateServerInterceptor(ServerRpcInfo* info) = 0;+};++class ServerRpcInfo {+ public:+  ~ServerRpcInfo(){};++  ServerRpcInfo(const ServerRpcInfo&) = delete;+  ServerRpcInfo(ServerRpcInfo&&) = default;+  ServerRpcInfo& operator=(ServerRpcInfo&&) = default;++  // Getter methods+  const char* method() { return method_; }+  grpc::ServerContext* server_context() { return ctx_; }++ public:+  // Runs interceptor at pos \a pos.+  void RunInterceptor(","In practice, will this ever get invoked by the application or only by our own classes? If the latter, then make it private and use `friend`s .",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/16842,228691864,2018-10-26T23:56:10Z,include/grpcpp/impl/codegen/call.h,"@@ -598,12 +792,353 @@ class CallOpSetInterface : public CompletionQueueTag {  public:   /// Fills in grpc_op, starting from ops[*nops] and moving   /// upwards.-  virtual void FillOps(grpc_call* call, grpc_op* ops, size_t* nops) = 0;+  virtual void FillOps(internal::Call* call) = 0;    /// Get the tag to be used at the core completion queue. Generally, the   /// value of cq_tag will be ""this"". However, it can be overridden if we   /// want core to process the tag differently (e.g., as a core callback)   virtual void* cq_tag() = 0;++  // This will be called while interceptors are run if the RPC is a hijacked+  // RPC. This should set hijacking state for each of the ops.+  virtual void SetHijackingState() = 0;++  // Should be called after interceptors are done running+  virtual void ContinueFillOpsAfterInterception() = 0;++  // Should be called after interceptors are done running on the finalize result+  // path+  virtual void ContinueFinalizeResultAfterInterception() = 0;+};++template <class Op1 = CallNoOp<1>, class Op2 = CallNoOp<2>,+          class Op3 = CallNoOp<3>, class Op4 = CallNoOp<4>,+          class Op5 = CallNoOp<5>, class Op6 = CallNoOp<6>>+class CallOpSet;++class InterceptorBatchMethodsImpl : public InternalInterceptorBatchMethods {+ public:+  InterceptorBatchMethodsImpl() {+    for (auto i = 0;+         i < static_cast<int>(+                 experimental::InterceptionHookPoints::NUM_INTERCEPTION_HOOKS);+         i++) {+      hooks_[i] = false;+    }+  }++  virtual ~InterceptorBatchMethodsImpl() {}++  virtual bool QueryInterceptionHookPoint(+      experimental::InterceptionHookPoints type) override {+    return hooks_[static_cast<int>(type)];+  }++  virtual void Proceed() override { /* fill this */+    if (call_->client_rpc_info() != nullptr) {+      return ProceedClient();+    }+    GPR_CODEGEN_ASSERT(call_->server_rpc_info() != nullptr);+    ProceedServer();+  }++  virtual void Hijack() override {+    // Only the client can hijack when sending down initial metadata+    GPR_CODEGEN_ASSERT(!reverse_ && ops_ != nullptr &&+                       call_->client_rpc_info() != nullptr);+    // It is illegal to call Hijack twice+    GPR_CODEGEN_ASSERT(!ran_hijacking_interceptor_);+    auto* rpc_info = call_->client_rpc_info();+    rpc_info->hijacked_ = true;+    rpc_info->hijacked_interceptor_ = curr_iteration_;+    ClearHookPoints();+    ops_->SetHijackingState();+    ran_hijacking_interceptor_ = true;+    rpc_info->RunInterceptor(this, curr_iteration_);+  }++  virtual void AddInterceptionHookPoint(+      experimental::InterceptionHookPoints type) override {+    hooks_[static_cast<int>(type)] = true;+  }++  virtual ByteBuffer* GetSendMessage() override { return send_message_; }++  virtual std::multimap<grpc::string, grpc::string>* GetSendInitialMetadata()+      override {+    return send_initial_metadata_;+  }++  virtual Status GetSendStatus() override {+    return Status(static_cast<StatusCode>(*code_), *error_message_,+                  *error_details_);+  }++  virtual void ModifySendStatus(const Status& status) override {+    *code_ = static_cast<grpc_status_code>(status.error_code());+    *error_details_ = status.error_details();+    *error_message_ = status.error_message();+  }++  virtual std::multimap<grpc::string, grpc::string>* GetSendTrailingMetadata()+      override {+    return send_trailing_metadata_;+  }++  virtual void* GetRecvMessage() override { return recv_message_; }++  virtual std::multimap<grpc::string_ref, grpc::string_ref>*+  GetRecvInitialMetadata() override {+    return recv_initial_metadata_->map();+  }++  virtual Status* GetRecvStatus() override { return recv_status_; }++  virtual std::multimap<grpc::string_ref, grpc::string_ref>*+  GetRecvTrailingMetadata() override {+    return recv_trailing_metadata_->map();+  }++  virtual void SetSendMessage(ByteBuffer* buf) override { send_message_ = buf; }++  virtual void SetSendInitialMetadata(+      std::multimap<grpc::string, grpc::string>* metadata) override {+    send_initial_metadata_ = metadata;+  }++  virtual void SetSendStatus(grpc_status_code* code,+                             grpc::string* error_details,+                             grpc::string* error_message) override {+    code_ = code;+    error_details_ = error_details;+    error_message_ = error_message;+  }++  virtual void SetSendTrailingMetadata(+      std::multimap<grpc::string, grpc::string>* metadata) override {+    send_trailing_metadata_ = metadata;+  }++  virtual void SetRecvMessage(void* message) override {+    recv_message_ = message;+  }++  virtual void SetRecvInitialMetadata(internal::MetadataMap* map) override {+    recv_initial_metadata_ = map;+  }++  virtual void SetRecvStatus(Status* status) override { recv_status_ = status; }++  virtual void SetRecvTrailingMetadata(internal::MetadataMap* map) override {+    recv_trailing_metadata_ = map;+  }++  virtual std::unique_ptr<ChannelInterface> GetInterceptedChannel() override {+    auto* info = call_->client_rpc_info();+    if (info == nullptr) {+      return std::unique_ptr<ChannelInterface>(nullptr);+    }+    // The intercepted channel starts from the interceptor just after the+    // current interceptor+    return std::unique_ptr<ChannelInterface>(new internal::InterceptedChannel(+        reinterpret_cast<grpc::ChannelInterface*>(info->channel()),+        curr_iteration_ + 1));+  }++  // Clears all state+  void ClearState() {+    reverse_ = false;+    ran_hijacking_interceptor_ = false;+    ClearHookPoints();+  }++  // Prepares for Post_recv operations+  void SetReverse() {+    reverse_ = true;+    ran_hijacking_interceptor_ = false;+    ClearHookPoints();+  }++  // This needs to be set before interceptors are run+  void SetCall(Call* call) { call_ = call; }++  // This needs to be set before interceptors are run using RunInterceptors().+  // Alternatively, RunInterceptors(std::function<void(void)> f) can be used.+  void SetCallOpSetInterface(CallOpSetInterface* ops) { ops_ = ops; }++  // Returns true if no interceptors are run. This should be used only by+  // subclasses of CallOpSetInterface. SetCall and SetCallOpSetInterface should+  // have been called before this. After all the interceptors are done running,+  // either ContinueFillOpsAfterInterception or+  // ContinueFinalizeOpsAfterInterception will be called. Note that neither of+  // them is invoked if there were no interceptors registered.+  bool RunInterceptors() {+    GPR_CODEGEN_ASSERT(ops_);+    auto* client_rpc_info = call_->client_rpc_info();+    if (client_rpc_info != nullptr) {+      if (client_rpc_info->interceptors_.size() == 0) {+        return true;+      } else {+        RunClientInterceptors();+        return false;+      }+    }++    auto* server_rpc_info = call_->server_rpc_info();+    if (server_rpc_info == nullptr ||+        server_rpc_info->interceptors_.size() == 0) {+      return true;+    }+    RunServerInterceptors();+    return false;+  }++  // Returns true if no interceptors are run. Returns false otherwise if there+  // are interceptors registered. After the interceptors are done running \a f+  // will be invoked. This is to be used only by BaseAsyncRequest and+  // SyncRequest.+  bool RunInterceptors(std::function<void(void)> f) {+    // This is used only by the server for initial call request+    GPR_CODEGEN_ASSERT(reverse_ == true);+    GPR_CODEGEN_ASSERT(call_->client_rpc_info() == nullptr);+    auto* server_rpc_info = call_->server_rpc_info();+    if (server_rpc_info == nullptr ||+        server_rpc_info->interceptors_.size() == 0) {+      return true;+    }+    callback_ = std::move(f);+    RunServerInterceptors();+    return false;+  }++ private:+  void RunClientInterceptors() {+    auto* rpc_info = call_->client_rpc_info();+    if (!reverse_) {+      curr_iteration_ = 0;+    } else {+      if (rpc_info->hijacked_) {+        curr_iteration_ = rpc_info->hijacked_interceptor_;+      } else {+        curr_iteration_ = rpc_info->interceptors_.size() - 1;+      }+    }+    rpc_info->RunInterceptor(this, curr_iteration_);+  }++  void RunServerInterceptors() {+    auto* rpc_info = call_->server_rpc_info();+    if (!reverse_) {+      curr_iteration_ = 0;+    } else {+      curr_iteration_ = rpc_info->interceptors_.size() - 1;+    }+    rpc_info->RunInterceptor(this, curr_iteration_);+  }++  void ProceedClient() {+    auto* rpc_info = call_->client_rpc_info();+    if (rpc_info->hijacked_ && !reverse_ &&+        curr_iteration_ == rpc_info->hijacked_interceptor_ &&+        !ran_hijacking_interceptor_) {+      // We now need to provide hijacked recv ops to this interceptor+      ClearHookPoints();+      ops_->SetHijackingState();+      ran_hijacking_interceptor_ = true;+      rpc_info->RunInterceptor(this, curr_iteration_);+      return;+    }+    if (!reverse_) {+      curr_iteration_++;+      // We are going down the stack of interceptors+      if (curr_iteration_ < static_cast<long>(rpc_info->interceptors_.size())) {+        if (rpc_info->hijacked_ &&+            curr_iteration_ > rpc_info->hijacked_interceptor_) {+          // This is a hijacked RPC and we are done with hijacking+          ops_->ContinueFillOpsAfterInterception();+        } else {+          rpc_info->RunInterceptor(this, curr_iteration_);+        }+      } else {+        // we are done running all the interceptors without any hijacking+        ops_->ContinueFillOpsAfterInterception();+      }+    } else {+      curr_iteration_--;+      // We are going up the stack of interceptors+      if (curr_iteration_ >= 0) {+        // Continue running interceptors+        rpc_info->RunInterceptor(this, curr_iteration_);+      } else {+        // we are done running all the interceptors without any hijacking+        ops_->ContinueFinalizeResultAfterInterception();+      }+    }+  }++  void ProceedServer() {+    auto* rpc_info = call_->server_rpc_info();+    if (!reverse_) {+      curr_iteration_++;+      if (curr_iteration_ < static_cast<long>(rpc_info->interceptors_.size())) {",current_interceptor_index I have kept as a long to allow it going negative. I could change that too if you think that's better.,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16842,228717073,2018-10-27T15:41:17Z,test/cpp/end2end/end2end_test.cc,"@@ -291,11 +338,21 @@ class End2endTest : public ::testing::TestWithParam<TestScenario> {     }     args.SetString(GRPC_ARG_SECONDARY_USER_AGENT_STRING, ""end2end_test""); +    auto creators = std::unique_ptr<std::vector<","So are you adding the interceptors into all the end2end tests? I would advise against that since we should have tests that don't use any interceptor. Let me suggest that you add a new parameter for the number of interceptors and let that either be 0 or non-zero, rather than just having a constant. Let me also suggest that changes in end2end_test should be in a future PR.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16842,228717136,2018-10-27T15:42:59Z,include/grpcpp/impl/codegen/client_interceptor.h,"@@ -83,10 +82,10 @@ class ClientRpcInfo {    grpc::ClientContext* ctx_ = nullptr;   const char* method_ = nullptr;-  grpc::Channel* channel_ = nullptr;+  grpc::ChannelInterface* channel_ = nullptr;   std::vector<std::unique_ptr<experimental::Interceptor>> interceptors_;   bool hijacked_ = false;-  int hijacked_interceptor_ = false;+  size_t hijacked_interceptor_ = false;","This is a bad initialization (mistyped).  I think it is unnecessary, right? If the `hijacked_` variable is false then this index is not important anyway, I think.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17045,229067209,2018-10-29T19:29:37Z,src/core/lib/channel/channelz.h,"@@ -268,10 +268,15 @@ class SocketNode : public BaseNode { // Handles channelz bookkeeping for listen sockets class ListenSocketNode : public BaseNode {  public:-  ListenSocketNode();+  // ListenSocketNode takes ownership of host.+  ListenSocketNode(char* host, int port);","Suggest making the `host` parameter a `UniquePtr<char>`, so that the ownership transfer is inherent in the interface and can be enforced by the compiler.",OK
2819812,zpencer,https://api.github.com/repos/grpc/grpc/pulls/16898,229127796,2018-10-29T23:00:14Z,src/core/ext/filters/client_channel/lb_policy.h,"@@ -73,6 +73,16 @@ class LoadBalancingPolicy     /// Closure to run when pick is complete, if not completed synchronously.     /// If null, pick will fail if a result is not available synchronously.     grpc_closure* on_complete;++    // Callback set by lb policy to be notified of trailing metadata.+    // The callback must be scheduled on grpc_schedule_on_exec_ctx.+    grpc_closure* recv_trailing_metadata_ready;","Do we expect that in most cases `recv_trailing_metadata_ready` will inspect the metadata without making any changes to the LB policy? If that is the case, would we want to avoid chaining every RPC on the combiner scheduler?To be specific, I'm thinking is `recv_trailing_metadata_ready` can run on `grpc_schedule_on_exec_ctx` but the LB is not synchronized. If the trailer causes us to read/write the LB, then it is the closure's responsibility for scheduling a separate closure on `grpc_combiner_scheduler(args_.combiner)`. Does this make sense or is it a premature optimization?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17050,229322421,2018-10-30T14:13:19Z,src/core/lib/channel/channelz.cc,"@@ -277,7 +278,20 @@ grpc_json* ServerNode::RenderJson() {   return top_level_json; } -SocketNode::SocketNode() : BaseNode(EntityType::kSocket) {}+SocketNode::SocketNode(const char* remote_peer_string)+    : BaseNode(EntityType::kSocket) {+  const char* ipv6_prefix = ""ipv6:"";","What about IPv4 addresses?More generally, rather than doing this manually, how about using some of our existing functions for doing this parsing?  In particular, I'm thinking of `grpc_parse_uri()` and `grpc_parse_ipv{4,6}_hostport()`, all defined here:https://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/parse_address.hThis would probably require moving that parsing code from ext to lib, though.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16898,229364527,2018-10-30T15:47:26Z,src/core/ext/filters/client_channel/lb_policy.h,"@@ -73,6 +73,16 @@ class LoadBalancingPolicy     /// Closure to run when pick is complete, if not completed synchronously.     /// If null, pick will fail if a result is not available synchronously.     grpc_closure* on_complete;++    // Callback set by lb policy to be notified of trailing metadata.+    // The callback must be scheduled on grpc_schedule_on_exec_ctx.+    grpc_closure* recv_trailing_metadata_ready;","The two use-cases we know of for the LB policy accessing trailing metadata are:1. The xds LB policy wants to see the trailing metadata to know when the call is complete, which it needs to record stats to be sent back to the balancer.2. There may be LB policies that use this information for routing affinity.  For example, we could initially send a request to some random backend, which could forward the request to the right backend and then send back trailing metadata telling the client that all future requests for that resource should be sent to a different backend.  This would require the LB policy to update its routing affinity table for use in subsequent requests.Although there may be other uses in the future, I would guess that pretty much any time the LB policy wants to know about the trailing metadata, it's going to use that information to modify its internal state, which will require synchronization.  So I think we should handle this for it rather than making the LB policy implementor handle it.BTW, I just realized that case 2 is also interesting in that the LB policy will want to remove the metadata from the batch before letting the batch proceed back to the application.  This is another reason why we need to make sure the LB policy's callback has finished before we pass the batch back up to the surface.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/16898,229368186,2018-10-30T15:55:47Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -2576,6 +2596,45 @@ static void start_retriable_subchannel_batches(void* arg, grpc_error* ignored) { // LB pick // +// The callback to intercept trailing metadata if retries is not enabled+static void recv_trailing_metadata_ready_for_lb(void* arg, grpc_error* error) {+  grpc_call_element* elem = static_cast<grpc_call_element*>(arg);+  call_data* calld = static_cast<call_data*>(elem->call_data);+  if (calld->pick.recv_trailing_metadata != nullptr) {+    *calld->pick.recv_trailing_metadata =+        calld->recv_trailing_metadata_op_batch->payload+            ->recv_trailing_metadata.recv_trailing_metadata;+  }+  GRPC_CLOSURE_SCHED(","Just had another thought here: An LB policy implementation may have its own reasons for needing to process the trailing metadata asynchronously, in which case the second approach I mentioned above (requiring the call into the LB policy to be synchronous) wouldn't really work.  So I think we probably do want to just treat it like any filter that intercepts a callback and make it be responsible for chaining to the previous callback when it's done.  This is unfortunate, because it does broaden the LB policy API in a way that seems counter to our goal of making it a public API, but I don't see any reasonable way around it, at least for now. :(",
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/16988,229389275,2018-10-30T16:46:22Z,include/grpcpp/impl/codegen/callback_common.h,"@@ -101,10 +101,11 @@ class CallbackWithStatusTag     GPR_CODEGEN_ASSERT(ignored == ops_);      // Last use of func_ or status_, so ok to move them out-    CatchingCallback(std::move(func_), std::move(status_));-+    auto func = std::move(func_);",What is the purpose of the temps? Are they useful for handling exceptions?,OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16919,229554322,2018-10-31T03:32:25Z,src/python/grpcio_tests/tests/unit/_metadata_flags_test.py,"@@ -0,0 +1,186 @@+# Copyright 2018 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Tests metadata flags feature by testing wait-for-ready semantics""""""++import time+import weakref+import unittest+import threading++import grpc++from tests.unit import test_common+from tests.unit.framework.common import test_constants++_UNARY_UNARY = '/test/UnaryUnary'+_UNARY_STREAM = '/test/UnaryStream'+_STREAM_UNARY = '/test/StreamUnary'+_STREAM_STREAM = '/test/StreamStream'++_REQUEST = b'\x00\x00\x00'+_RESPONSE = b'\x00\x00\x00'++_ALL_CALL_CASES = [+    ('unary_unary', _UNARY_UNARY, False, '__call__', False),+    ('unary_unary', _UNARY_UNARY, False, 'with_call', False),+    ('unary_unary', _UNARY_UNARY, False, 'future', False),+    ('unary_stream', _UNARY_STREAM, False, '__call__', True),+    ('stream_unary', _STREAM_UNARY, True, '__call__', False),+    ('stream_unary', _STREAM_UNARY, True, 'with_call', False),+    ('stream_unary', _STREAM_UNARY, True, 'future', False),+    ('stream_stream', _STREAM_STREAM, True, '__call__', True),+]++# Only with unary type input can fail fast, otherwise+#   C-Core will wait and can't be disabled.+_FAIL_FAST_CASES = _ALL_CALL_CASES[:4]+++def handle_unary_unary(test, request, servicer_context):+    return _RESPONSE+++def handle_unary_stream(test, request, servicer_context):+    for _ in range(test_constants.STREAM_LENGTH):+        yield _RESPONSE+++def handle_stream_unary(test, request_iterator, servicer_context):+    for _ in request_iterator:+        pass+    return _RESPONSE+++def handle_stream_stream(test, request_iterator, servicer_context):+    for _ in request_iterator:+        yield _RESPONSE+++class _MethodHandler(grpc.RpcMethodHandler):++    def __init__(self, test, request_streaming, response_streaming):+        self.request_streaming = request_streaming+        self.response_streaming = response_streaming+        self.request_deserializer = None+        self.response_serializer = None+        self.unary_unary = None+        self.unary_stream = None+        self.stream_unary = None+        self.stream_stream = None+        if self.request_streaming and self.response_streaming:+            self.stream_stream = lambda x, y: handle_stream_stream(test, x, y)+        elif self.request_streaming:+            self.stream_unary = lambda x, y: handle_stream_unary(test, x, y)+        elif self.response_streaming:+            self.unary_stream = lambda x, y: handle_unary_stream(test, x, y)+        else:+            self.unary_unary = lambda x, y: handle_unary_unary(test, x, y)+++class _GenericHandler(grpc.GenericRpcHandler):++    def __init__(self, test):+        self._test = test++    def service(self, handler_call_details):+        if handler_call_details.method == _UNARY_UNARY:+            return _MethodHandler(self._test, False, False)+        elif handler_call_details.method == _UNARY_STREAM:+            return _MethodHandler(self._test, False, True)+        elif handler_call_details.method == _STREAM_UNARY:+            return _MethodHandler(self._test, True, False)+        elif handler_call_details.method == _STREAM_STREAM:+            return _MethodHandler(self._test, True, True)+        else:+            return None+++def execute_call(channel,+                 method_name,+                 server_method,+                 is_stream_input,+                 invoke_method,+                 is_stream_output,+                 wait_for_ready=None):+    multi_callable = getattr(channel, method_name)(server_method)+    if not is_stream_input:+        req = _REQUEST+    else:+        req = iter([_REQUEST] * test_constants.STREAM_LENGTH)+    response = getattr(multi_callable, invoke_method)(+        req,+        timeout=test_constants.SHORT_TIMEOUT,+        wait_for_ready=wait_for_ready)+    if is_stream_output:+        for _ in response:+            pass+    if invoke_method == 'future':+        response = response.result(timeout=test_constants.SHORT_TIMEOUT)+    return response+++class MetadataFlagsTest(unittest.TestCase):++    def test_call_wait_for_ready_disabled(self):+        channel = grpc.insecure_channel('localhost:12345')++        def test_call(*args):+            try:+                execute_call(channel, *args, wait_for_ready=False)+            except Exception as e:  # pylint: disable=broad-except+                self.assertIn('StatusCode.UNAVAILABLE', str(e))++        for case in _FAIL_FAST_CASES:+            test_call(*case)++    def test_call_wait_for_ready_enabled(self):+        # To test the wait mechanism, Python thread is required to make+        #   client set up first without handling them case by case.+        # Also, Python thread don't pass the unhandled exceptions to+        #   main thread. So, it need another method to store the+        #   exceptions and raise them again in main thread.+        self.unhandled_exceptions = []+        self._server = test_common.test_server()+        self._server.add_generic_rpc_handlers((_GenericHandler(+            weakref.proxy(self)),))+        port = self._server.add_insecure_port('[::]:0')","since the test only needs to listen on the loopback interface, bind to `[::1]:0` ?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16919,229556333,2018-10-31T03:49:02Z,src/python/grpcio_tests/tests/unit/_metadata_flags_test.py,"@@ -0,0 +1,186 @@+# Copyright 2018 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Tests metadata flags feature by testing wait-for-ready semantics""""""++import time+import weakref+import unittest+import threading++import grpc++from tests.unit import test_common+from tests.unit.framework.common import test_constants++_UNARY_UNARY = '/test/UnaryUnary'+_UNARY_STREAM = '/test/UnaryStream'+_STREAM_UNARY = '/test/StreamUnary'+_STREAM_STREAM = '/test/StreamStream'++_REQUEST = b'\x00\x00\x00'+_RESPONSE = b'\x00\x00\x00'++_ALL_CALL_CASES = [+    ('unary_unary', _UNARY_UNARY, False, '__call__', False),+    ('unary_unary', _UNARY_UNARY, False, 'with_call', False),+    ('unary_unary', _UNARY_UNARY, False, 'future', False),+    ('unary_stream', _UNARY_STREAM, False, '__call__', True),+    ('stream_unary', _STREAM_UNARY, True, '__call__', False),+    ('stream_unary', _STREAM_UNARY, True, 'with_call', False),+    ('stream_unary', _STREAM_UNARY, True, 'future', False),+    ('stream_stream', _STREAM_STREAM, True, '__call__', True),+]++# Only with unary type input can fail fast, otherwise+#   C-Core will wait and can't be disabled.+_FAIL_FAST_CASES = _ALL_CALL_CASES[:4]+++def handle_unary_unary(test, request, servicer_context):+    return _RESPONSE+++def handle_unary_stream(test, request, servicer_context):+    for _ in range(test_constants.STREAM_LENGTH):+        yield _RESPONSE+++def handle_stream_unary(test, request_iterator, servicer_context):+    for _ in request_iterator:+        pass+    return _RESPONSE+++def handle_stream_stream(test, request_iterator, servicer_context):+    for _ in request_iterator:+        yield _RESPONSE+++class _MethodHandler(grpc.RpcMethodHandler):++    def __init__(self, test, request_streaming, response_streaming):+        self.request_streaming = request_streaming+        self.response_streaming = response_streaming+        self.request_deserializer = None+        self.response_serializer = None+        self.unary_unary = None+        self.unary_stream = None+        self.stream_unary = None+        self.stream_stream = None+        if self.request_streaming and self.response_streaming:+            self.stream_stream = lambda x, y: handle_stream_stream(test, x, y)+        elif self.request_streaming:+            self.stream_unary = lambda x, y: handle_stream_unary(test, x, y)+        elif self.response_streaming:+            self.unary_stream = lambda x, y: handle_unary_stream(test, x, y)+        else:+            self.unary_unary = lambda x, y: handle_unary_unary(test, x, y)+++class _GenericHandler(grpc.GenericRpcHandler):++    def __init__(self, test):+        self._test = test++    def service(self, handler_call_details):+        if handler_call_details.method == _UNARY_UNARY:+            return _MethodHandler(self._test, False, False)+        elif handler_call_details.method == _UNARY_STREAM:+            return _MethodHandler(self._test, False, True)+        elif handler_call_details.method == _STREAM_UNARY:+            return _MethodHandler(self._test, True, False)+        elif handler_call_details.method == _STREAM_STREAM:+            return _MethodHandler(self._test, True, True)+        else:+            return None+++def execute_call(channel,+                 method_name,+                 server_method,+                 is_stream_input,+                 invoke_method,+                 is_stream_output,+                 wait_for_ready=None):+    multi_callable = getattr(channel, method_name)(server_method)+    if not is_stream_input:+        req = _REQUEST+    else:+        req = iter([_REQUEST] * test_constants.STREAM_LENGTH)+    response = getattr(multi_callable, invoke_method)(+        req,+        timeout=test_constants.SHORT_TIMEOUT,+        wait_for_ready=wait_for_ready)+    if is_stream_output:+        for _ in response:+            pass+    if invoke_method == 'future':+        response = response.result(timeout=test_constants.SHORT_TIMEOUT)+    return response+++class MetadataFlagsTest(unittest.TestCase):++    def test_call_wait_for_ready_disabled(self):+        channel = grpc.insecure_channel('localhost:12345')++        def test_call(*args):+            try:+                execute_call(channel, *args, wait_for_ready=False)+            except Exception as e:  # pylint: disable=broad-except+                self.assertIn('StatusCode.UNAVAILABLE', str(e))++        for case in _FAIL_FAST_CASES:+            test_call(*case)++    def test_call_wait_for_ready_enabled(self):+        # To test the wait mechanism, Python thread is required to make+        #   client set up first without handling them case by case.+        # Also, Python thread don't pass the unhandled exceptions to+        #   main thread. So, it need another method to store the+        #   exceptions and raise them again in main thread.+        self.unhandled_exceptions = []+        self._server = test_common.test_server()+        self._server.add_generic_rpc_handlers((_GenericHandler(+            weakref.proxy(self)),))+        port = self._server.add_insecure_port('[::]:0')++        def test_call(*args):+            try:+                channel = grpc.insecure_channel('localhost:%d' % port)+                execute_call(channel, *args, wait_for_ready=True)+            except Exception as e:  # pylint: disable=broad-except+                self.unhandled_exceptions.append(e)","appending to `unhandled_exceptions` here is racey, right? Suggest either protecting this list with a mutex, or passing a local argument to each thread that each thread can store it's exception in",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16919,229558560,2018-10-31T04:07:55Z,src/python/grpcio_tests/tests/unit/_metadata_flags_test.py,"@@ -0,0 +1,186 @@+# Copyright 2018 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Tests metadata flags feature by testing wait-for-ready semantics""""""++import time+import weakref+import unittest+import threading++import grpc++from tests.unit import test_common+from tests.unit.framework.common import test_constants++_UNARY_UNARY = '/test/UnaryUnary'+_UNARY_STREAM = '/test/UnaryStream'+_STREAM_UNARY = '/test/StreamUnary'+_STREAM_STREAM = '/test/StreamStream'++_REQUEST = b'\x00\x00\x00'+_RESPONSE = b'\x00\x00\x00'++_ALL_CALL_CASES = [+    ('unary_unary', _UNARY_UNARY, False, '__call__', False),+    ('unary_unary', _UNARY_UNARY, False, 'with_call', False),+    ('unary_unary', _UNARY_UNARY, False, 'future', False),+    ('unary_stream', _UNARY_STREAM, False, '__call__', True),+    ('stream_unary', _STREAM_UNARY, True, '__call__', False),+    ('stream_unary', _STREAM_UNARY, True, 'with_call', False),+    ('stream_unary', _STREAM_UNARY, True, 'future', False),+    ('stream_stream', _STREAM_STREAM, True, '__call__', True),+]++# Only with unary type input can fail fast, otherwise+#   C-Core will wait and can't be disabled.+_FAIL_FAST_CASES = _ALL_CALL_CASES[:4]+++def handle_unary_unary(test, request, servicer_context):+    return _RESPONSE+++def handle_unary_stream(test, request, servicer_context):+    for _ in range(test_constants.STREAM_LENGTH):+        yield _RESPONSE+++def handle_stream_unary(test, request_iterator, servicer_context):+    for _ in request_iterator:+        pass+    return _RESPONSE+++def handle_stream_stream(test, request_iterator, servicer_context):+    for _ in request_iterator:+        yield _RESPONSE+++class _MethodHandler(grpc.RpcMethodHandler):++    def __init__(self, test, request_streaming, response_streaming):+        self.request_streaming = request_streaming+        self.response_streaming = response_streaming+        self.request_deserializer = None+        self.response_serializer = None+        self.unary_unary = None+        self.unary_stream = None+        self.stream_unary = None+        self.stream_stream = None+        if self.request_streaming and self.response_streaming:+            self.stream_stream = lambda x, y: handle_stream_stream(test, x, y)+        elif self.request_streaming:+            self.stream_unary = lambda x, y: handle_stream_unary(test, x, y)+        elif self.response_streaming:+            self.unary_stream = lambda x, y: handle_unary_stream(test, x, y)+        else:+            self.unary_unary = lambda x, y: handle_unary_unary(test, x, y)+++class _GenericHandler(grpc.GenericRpcHandler):++    def __init__(self, test):+        self._test = test++    def service(self, handler_call_details):+        if handler_call_details.method == _UNARY_UNARY:+            return _MethodHandler(self._test, False, False)+        elif handler_call_details.method == _UNARY_STREAM:+            return _MethodHandler(self._test, False, True)+        elif handler_call_details.method == _STREAM_UNARY:+            return _MethodHandler(self._test, True, False)+        elif handler_call_details.method == _STREAM_STREAM:+            return _MethodHandler(self._test, True, True)+        else:+            return None+++def execute_call(channel,+                 method_name,+                 server_method,+                 is_stream_input,+                 invoke_method,+                 is_stream_output,+                 wait_for_ready=None):+    multi_callable = getattr(channel, method_name)(server_method)+    if not is_stream_input:+        req = _REQUEST+    else:+        req = iter([_REQUEST] * test_constants.STREAM_LENGTH)+    response = getattr(multi_callable, invoke_method)(+        req,+        timeout=test_constants.SHORT_TIMEOUT,+        wait_for_ready=wait_for_ready)+    if is_stream_output:+        for _ in response:+            pass+    if invoke_method == 'future':+        response = response.result(timeout=test_constants.SHORT_TIMEOUT)+    return response+++class MetadataFlagsTest(unittest.TestCase):++    def test_call_wait_for_ready_disabled(self):+        channel = grpc.insecure_channel('localhost:12345')","Since we don't actually have a guarantee that this port won't be in use by other tests running in parallel (right?) - I think this needs to be changed to make sure that nothing is running on this port. Simplest way that I can think of is to create a dummy socket and bind to port `[::1]:0`, and then use the resulting port for the test.",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16919,229558773,2018-10-31T04:09:51Z,src/python/grpcio_tests/tests/unit/_metadata_flags_test.py,"@@ -0,0 +1,186 @@+# Copyright 2018 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Tests metadata flags feature by testing wait-for-ready semantics""""""++import time+import weakref+import unittest+import threading++import grpc++from tests.unit import test_common+from tests.unit.framework.common import test_constants++_UNARY_UNARY = '/test/UnaryUnary'+_UNARY_STREAM = '/test/UnaryStream'+_STREAM_UNARY = '/test/StreamUnary'+_STREAM_STREAM = '/test/StreamStream'++_REQUEST = b'\x00\x00\x00'+_RESPONSE = b'\x00\x00\x00'++_ALL_CALL_CASES = [+    ('unary_unary', _UNARY_UNARY, False, '__call__', False),+    ('unary_unary', _UNARY_UNARY, False, 'with_call', False),+    ('unary_unary', _UNARY_UNARY, False, 'future', False),+    ('unary_stream', _UNARY_STREAM, False, '__call__', True),+    ('stream_unary', _STREAM_UNARY, True, '__call__', False),+    ('stream_unary', _STREAM_UNARY, True, 'with_call', False),+    ('stream_unary', _STREAM_UNARY, True, 'future', False),+    ('stream_stream', _STREAM_STREAM, True, '__call__', True),+]++# Only with unary type input can fail fast, otherwise+#   C-Core will wait and can't be disabled.+_FAIL_FAST_CASES = _ALL_CALL_CASES[:4]+++def handle_unary_unary(test, request, servicer_context):+    return _RESPONSE+++def handle_unary_stream(test, request, servicer_context):+    for _ in range(test_constants.STREAM_LENGTH):+        yield _RESPONSE+++def handle_stream_unary(test, request_iterator, servicer_context):+    for _ in request_iterator:+        pass+    return _RESPONSE+++def handle_stream_stream(test, request_iterator, servicer_context):+    for _ in request_iterator:+        yield _RESPONSE+++class _MethodHandler(grpc.RpcMethodHandler):++    def __init__(self, test, request_streaming, response_streaming):+        self.request_streaming = request_streaming+        self.response_streaming = response_streaming+        self.request_deserializer = None+        self.response_serializer = None+        self.unary_unary = None+        self.unary_stream = None+        self.stream_unary = None+        self.stream_stream = None+        if self.request_streaming and self.response_streaming:+            self.stream_stream = lambda x, y: handle_stream_stream(test, x, y)","nit: rename `x, y` to `req, ctx` - or something along those lines?",
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/17066,229564570,2018-10-31T05:02:03Z,test/core/memory_usage/BUILD,"@@ -31,11 +32,11 @@ grpc_cc_binary(     ], ) -grpc_cc_binary(+cc_library(","No, please use `grpc_cc_library`. If you require copts, you need to make this a bit more global.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/16919,229571896,2018-10-31T06:00:12Z,src/python/grpcio_tests/tests/unit/_metadata_flags_test.py,"@@ -0,0 +1,186 @@+# Copyright 2018 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Tests metadata flags feature by testing wait-for-ready semantics""""""++import time+import weakref+import unittest+import threading++import grpc++from tests.unit import test_common+from tests.unit.framework.common import test_constants++_UNARY_UNARY = '/test/UnaryUnary'+_UNARY_STREAM = '/test/UnaryStream'+_STREAM_UNARY = '/test/StreamUnary'+_STREAM_STREAM = '/test/StreamStream'++_REQUEST = b'\x00\x00\x00'+_RESPONSE = b'\x00\x00\x00'++_ALL_CALL_CASES = [+    ('unary_unary', _UNARY_UNARY, False, '__call__', False),+    ('unary_unary', _UNARY_UNARY, False, 'with_call', False),+    ('unary_unary', _UNARY_UNARY, False, 'future', False),+    ('unary_stream', _UNARY_STREAM, False, '__call__', True),+    ('stream_unary', _STREAM_UNARY, True, '__call__', False),+    ('stream_unary', _STREAM_UNARY, True, 'with_call', False),+    ('stream_unary', _STREAM_UNARY, True, 'future', False),+    ('stream_stream', _STREAM_STREAM, True, '__call__', True),+]++# Only with unary type input can fail fast, otherwise","OMG. You helped me found a huge bug here.1. The retry time of a channel will increase, as for the fifth attempt, the time will be larger than 4 seconds which will fail the SHORT_TIMEOUT.2. The `MAX_MAX_RETRY_ATTEMPTS` in C-Core is 5 [CODE HERE](https://github.com/grpc/grpc/blob/618a3f561d4a93f263cca23abad086ed8f4d5e86/src/core/ext/filters/client_channel/method_params.cc#L34)... That's the reason why the list can never go through.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17050,229778249,2018-10-31T16:47:38Z,src/core/lib/gpr/string.h,"@@ -41,6 +41,9 @@ char* gpr_dump(const char* buf, size_t len, uint32_t flags); int gpr_parse_bytes_to_uint32(const char* data, size_t length,                               uint32_t* result); +/* returns allocated string with the base64 encoding of in */+char* gpr_string_base64_encode(const char* in);","Rather than duplicate this code, I would prefer to either (a) use the existing slice-based base64 API or (b) refactor the slice code so that it can be used for either slices or strings.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17050,229781393,2018-10-31T16:55:33Z,src/core/lib/channel/channelz.h,"@@ -229,10 +229,45 @@ class ServerNode : public BaseNode {   ChannelTrace trace_; }; +// helper class for holding and rendering the information about a particular+// socket's address+class SocketAddress {","This API feels a little clunky.  It's trying to present a view of the individual components of the address, but it's not really able to do that in a properly abstracted way, because not all types of addresses have the same fields, so we wind up stuck with fields like `blob`, which isn't really a thing.I am beginning to wonder whether we should just bite the bullet and move the uri_parser library into lib.  If we do that, then we can greatly simplify the APIs here: we can just pass the peer string from the transport directly into the channelz node, and we can have the channelz node parse it and figure out how to encode it in JSON.  This both minimizes the amount of API glue we need and reduces the amount of special work that each transport needs to implement.What do you think?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17050,229782112,2018-10-31T16:57:12Z,src/core/lib/channel/channelz.cc,"@@ -277,10 +277,65 @@ grpc_json* ServerNode::RenderJson() {   return top_level_json; } -SocketNode::SocketNode(UniquePtr<char> remote_host, int remote_port)+SocketAddress::SocketAddress() : type_(AddressType::kUnset), port_(-1) {}++SocketAddress::SocketAddress(SocketAddress&& other) {+  type_ = other.type_;+  port_ = other.port_;+  blob_.reset((other.blob_.release()));",This should be `blob_ = std::move(other.blob_);`.,OK
35056280,srini100,https://api.github.com/repos/grpc/grpc/pulls/16647,229785985,2018-10-31T17:07:01Z,examples/objective-c/helloworld_macos/README.md,"@@ -0,0 +1,6 @@+# gRPC Objective-C Mac OS Hello World Example++A hello world example app on Mac OS. Note that Mac OS is not first class supported platform of gRPC",*not a first class*,OK
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/17050,229791884,2018-10-31T17:23:01Z,src/core/lib/channel/channelz.h,"@@ -229,10 +229,45 @@ class ServerNode : public BaseNode {   ChannelTrace trace_; }; +// helper class for holding and rendering the information about a particular+// socket's address+class SocketAddress {","My only question is will there ever be any information that is NOT in the peer string, that the channelz object will need to determine the address type? Or will having the peer_string always be enough to determine TCP vs UDS vs future other address typeI do agree though, the code in chttp2 has become too long... I will take a shot at the refactor.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17050,229801675,2018-10-31T17:47:16Z,src/core/lib/gpr/string.h,"@@ -41,6 +41,9 @@ char* gpr_dump(const char* buf, size_t len, uint32_t flags); int gpr_parse_bytes_to_uint32(const char* data, size_t length,                               uint32_t* result); +/* returns allocated string with the base64 encoding of in */+char* gpr_string_base64_encode(const char* in);",The code I'm thinking of is in src/core/lib/slice/b64.h.  Please tell me that we don't already have this code duplicated in chttp2. :),
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/17050,229808125,2018-10-31T18:03:48Z,src/core/lib/gpr/string.h,"@@ -41,6 +41,9 @@ char* gpr_dump(const char* buf, size_t len, uint32_t flags); int gpr_parse_bytes_to_uint32(const char* data, size_t length,                               uint32_t* result); +/* returns allocated string with the base64 encoding of in */+char* gpr_string_base64_encode(const char* in);",Oh boy.... https://github.com/grpc/grpc/blob/master/src/core/ext/transport/chttp2/transport/bin_encoder.h,
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/16944,229831498,2018-10-31T19:11:08Z,src/core/ext/transport/cronet/transport/cronet_transport.cc,"@@ -111,76 +111,90 @@ typedef struct grpc_cronet_transport grpc_cronet_transport; /* TODO (makdharma): reorder structure for memory efficiency per    http://www.catb.org/esr/structure-packing/#_structure_reordering: */ struct read_state {+  read_state(gpr_arena* arena)+      : trailing_metadata(arena), initial_metadata(arena) {+    grpc_slice_buffer_init(&read_slice_buffer);+  }+   /* vars to store data coming from server */-  char* read_buffer;-  bool length_field_received;-  int received_bytes;-  int remaining_bytes;-  int length_field;-  bool compressed;-  char grpc_header_bytes[GRPC_HEADER_SIZE_IN_BYTES];-  char* payload_field;-  bool read_stream_closed;+  char* read_buffer = nullptr;+  bool length_field_received = false;+  int received_bytes = 0;+  int remaining_bytes = 0;+  int length_field = 0;+  bool compressed = 0;+  char grpc_header_bytes[GRPC_HEADER_SIZE_IN_BYTES] = {};+  char* payload_field = nullptr;+  bool read_stream_closed = 0;    /* vars for holding data destined for the application */   grpc_core::ManualConstructor<grpc_core::SliceBufferByteStream> sbs;   grpc_slice_buffer read_slice_buffer;    /* vars for trailing metadata */   grpc_chttp2_incoming_metadata_buffer trailing_metadata;-  bool trailing_metadata_valid;+  bool trailing_metadata_valid = false;    /* vars for initial metadata */   grpc_chttp2_incoming_metadata_buffer initial_metadata; };  struct write_state {-  char* write_buffer;+  char* write_buffer = nullptr; };  /* track state of one stream op */ struct op_state {-  bool state_op_done[OP_NUM_OPS];-  bool state_callback_received[OP_NUM_OPS];+  op_state(gpr_arena* arena) : rs(arena) {}++  bool state_op_done[OP_NUM_OPS] = {};+  bool state_callback_received[OP_NUM_OPS] = {};   /* A non-zero gRPC status code has been seen */-  bool fail_state;+  bool fail_state = false;   /* Transport is discarding all buffered messages */-  bool flush_read;-  bool flush_cronet_when_ready;-  bool pending_write_for_trailer;-  bool pending_send_message;+  bool flush_read = false;+  bool flush_cronet_when_ready = false;+  bool pending_write_for_trailer = false;+  bool pending_send_message = false;   /* User requested RECV_TRAILING_METADATA */-  bool pending_recv_trailing_metadata;+  bool pending_recv_trailing_metadata = false;   /* Cronet has not issued a callback of a bidirectional read */-  bool pending_read_from_cronet;-  grpc_error* cancel_error;+  bool pending_read_from_cronet = false;+  grpc_error* cancel_error = GRPC_ERROR_NONE;   /* data structure for storing data coming from server */   struct read_state rs;   /* data structure for storing data going to the server */   struct write_state ws; };  struct op_and_state {+  op_and_state(gpr_arena* arena) : state(arena) {}+   grpc_transport_stream_op_batch op;   struct op_state state;-  bool done;-  struct stream_obj* s;      /* Pointer back to the stream object */-  struct op_and_state* next; /* next op_and_state in the linked list */+  bool done = false;+  struct stream_obj* s = nullptr; /* Pointer back to the stream object */+  /* next op_and_state in the linked list */+  struct op_and_state* next = nullptr; };  struct op_storage {-  int num_pending_ops;-  struct op_and_state* head;+  int num_pending_ops = 0;+  struct op_and_state* head = nullptr; };  struct stream_obj {+  stream_obj(grpc_transport* gt, grpc_stream* gs,+             grpc_stream_refcount* refcount, gpr_arena* arena);+   gpr_arena* arena;-  struct op_and_state* oas;-  grpc_transport_stream_op_batch* curr_op;+  struct op_and_state* oas = nullptr;+  grpc_transport_stream_op_batch* curr_op = nullptr;   grpc_cronet_transport* curr_ct;   grpc_stream* curr_gs;-  bidirectional_stream* cbs;-  bidirectional_stream_header_array header_array;+  bidirectional_stream* cbs = nullptr;+  bidirectional_stream_header_array header_array =+      bidirectional_stream_header_array();  // Zero-initialize the structure.",But consider adding this to `state` and `storage`. `state` seems need a parameter for sure.,OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/16944,229835095,2018-10-31T19:23:10Z,src/core/ext/transport/cronet/transport/cronet_transport.cc,"@@ -111,76 +111,90 @@ typedef struct grpc_cronet_transport grpc_cronet_transport; /* TODO (makdharma): reorder structure for memory efficiency per    http://www.catb.org/esr/structure-packing/#_structure_reordering: */ struct read_state {+  read_state(gpr_arena* arena)+      : trailing_metadata(arena), initial_metadata(arena) {+    grpc_slice_buffer_init(&read_slice_buffer);+  }+   /* vars to store data coming from server */-  char* read_buffer;-  bool length_field_received;-  int received_bytes;-  int remaining_bytes;-  int length_field;-  bool compressed;-  char grpc_header_bytes[GRPC_HEADER_SIZE_IN_BYTES];-  char* payload_field;-  bool read_stream_closed;+  char* read_buffer = nullptr;+  bool length_field_received = false;+  int received_bytes = 0;+  int remaining_bytes = 0;+  int length_field = 0;+  bool compressed = 0;+  char grpc_header_bytes[GRPC_HEADER_SIZE_IN_BYTES] = {};+  char* payload_field = nullptr;+  bool read_stream_closed = 0;    /* vars for holding data destined for the application */   grpc_core::ManualConstructor<grpc_core::SliceBufferByteStream> sbs;   grpc_slice_buffer read_slice_buffer;    /* vars for trailing metadata */   grpc_chttp2_incoming_metadata_buffer trailing_metadata;-  bool trailing_metadata_valid;+  bool trailing_metadata_valid = false;    /* vars for initial metadata */   grpc_chttp2_incoming_metadata_buffer initial_metadata; };  struct write_state {-  char* write_buffer;+  char* write_buffer = nullptr; };  /* track state of one stream op */ struct op_state {-  bool state_op_done[OP_NUM_OPS];-  bool state_callback_received[OP_NUM_OPS];+  op_state(gpr_arena* arena) : rs(arena) {}++  bool state_op_done[OP_NUM_OPS] = {};+  bool state_callback_received[OP_NUM_OPS] = {};   /* A non-zero gRPC status code has been seen */-  bool fail_state;+  bool fail_state = false;   /* Transport is discarding all buffered messages */-  bool flush_read;-  bool flush_cronet_when_ready;-  bool pending_write_for_trailer;-  bool pending_send_message;+  bool flush_read = false;+  bool flush_cronet_when_ready = false;+  bool pending_write_for_trailer = false;+  bool pending_send_message = false;   /* User requested RECV_TRAILING_METADATA */-  bool pending_recv_trailing_metadata;+  bool pending_recv_trailing_metadata = false;   /* Cronet has not issued a callback of a bidirectional read */-  bool pending_read_from_cronet;-  grpc_error* cancel_error;+  bool pending_read_from_cronet = false;+  grpc_error* cancel_error = GRPC_ERROR_NONE;",`read_state` below needs a parameter?,
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/16944,229842835,2018-10-31T19:48:45Z,src/core/ext/transport/cronet/transport/cronet_transport.cc,"@@ -111,76 +111,90 @@ typedef struct grpc_cronet_transport grpc_cronet_transport; /* TODO (makdharma): reorder structure for memory efficiency per    http://www.catb.org/esr/structure-packing/#_structure_reordering: */ struct read_state {+  read_state(gpr_arena* arena)+      : trailing_metadata(arena), initial_metadata(arena) {+    grpc_slice_buffer_init(&read_slice_buffer);+  }+   /* vars to store data coming from server */-  char* read_buffer;-  bool length_field_received;-  int received_bytes;-  int remaining_bytes;-  int length_field;-  bool compressed;-  char grpc_header_bytes[GRPC_HEADER_SIZE_IN_BYTES];-  char* payload_field;-  bool read_stream_closed;+  char* read_buffer = nullptr;+  bool length_field_received = false;+  int received_bytes = 0;+  int remaining_bytes = 0;+  int length_field = 0;+  bool compressed = 0;+  char grpc_header_bytes[GRPC_HEADER_SIZE_IN_BYTES] = {};+  char* payload_field = nullptr;+  bool read_stream_closed = 0;    /* vars for holding data destined for the application */   grpc_core::ManualConstructor<grpc_core::SliceBufferByteStream> sbs;   grpc_slice_buffer read_slice_buffer;    /* vars for trailing metadata */   grpc_chttp2_incoming_metadata_buffer trailing_metadata;-  bool trailing_metadata_valid;+  bool trailing_metadata_valid = false;    /* vars for initial metadata */   grpc_chttp2_incoming_metadata_buffer initial_metadata; };  struct write_state {-  char* write_buffer;+  char* write_buffer = nullptr; };  /* track state of one stream op */ struct op_state {-  bool state_op_done[OP_NUM_OPS];-  bool state_callback_received[OP_NUM_OPS];+  op_state(gpr_arena* arena) : rs(arena) {}++  bool state_op_done[OP_NUM_OPS] = {};+  bool state_callback_received[OP_NUM_OPS] = {};   /* A non-zero gRPC status code has been seen */-  bool fail_state;+  bool fail_state = false;   /* Transport is discarding all buffered messages */-  bool flush_read;-  bool flush_cronet_when_ready;-  bool pending_write_for_trailer;-  bool pending_send_message;+  bool flush_read = false;+  bool flush_cronet_when_ready = false;+  bool pending_write_for_trailer = false;+  bool pending_send_message = false;   /* User requested RECV_TRAILING_METADATA */-  bool pending_recv_trailing_metadata;+  bool pending_recv_trailing_metadata = false;   /* Cronet has not issued a callback of a bidirectional read */-  bool pending_read_from_cronet;-  grpc_error* cancel_error;+  bool pending_read_from_cronet = false;+  grpc_error* cancel_error = GRPC_ERROR_NONE;   /* data structure for storing data coming from server */   struct read_state rs;   /* data structure for storing data going to the server */   struct write_state ws; };  struct op_and_state {+  op_and_state(gpr_arena* arena) : state(arena) {}+   grpc_transport_stream_op_batch op;   struct op_state state;-  bool done;-  struct stream_obj* s;      /* Pointer back to the stream object */-  struct op_and_state* next; /* next op_and_state in the linked list */+  bool done = false;+  struct stream_obj* s = nullptr; /* Pointer back to the stream object */+  /* next op_and_state in the linked list */+  struct op_and_state* next = nullptr; };  struct op_storage {-  int num_pending_ops;-  struct op_and_state* head;+  int num_pending_ops = 0;+  struct op_and_state* head = nullptr; };  struct stream_obj {+  stream_obj(grpc_transport* gt, grpc_stream* gs,+             grpc_stream_refcount* refcount, gpr_arena* arena);+   gpr_arena* arena;-  struct op_and_state* oas;-  grpc_transport_stream_op_batch* curr_op;+  struct op_and_state* oas = nullptr;+  grpc_transport_stream_op_batch* curr_op = nullptr;   grpc_cronet_transport* curr_ct;   grpc_stream* curr_gs;-  bidirectional_stream* cbs;-  bidirectional_stream_header_array header_array;+  bidirectional_stream* cbs = nullptr;+  bidirectional_stream_header_array header_array =+      bidirectional_stream_header_array();  // Zero-initialize the structure.","That's exactly why I called `bidirectional_stream_header_array()`. For PODs, `{}`, `{0}`, and `X()` is translated to zero-initialization. Here we are essentially instructing the compiler to memset(0) the struct. We cannot use `{}` due to a bug in gcc4.9 and gcc4.8. `{0}` is non-standard. So I updated for the standard syntax of `bidirectional_stream_header_array()`.The storage and state classes are both C++ classes and have a proper default ctor. So we don't need to initialize them.",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/17071,229906160,2018-11-01T00:05:32Z,tools/internal_ci/macos/grpc_basictests_objc_dbg.cfg,"@@ -27,5 +27,5 @@ action {  env_vars {   key: ""RUN_TESTS_FLAGS""-  value: ""-f basictests macos objc dbg --internal_ci -j 1 --inner_jobs 4 --bq_result_table aggregate_results""+  value: ""-f macos objc dbg --internal_ci -j 1 --inner_jobs 4 --bq_result_table aggregate_results""","Also I recommend renaming these tests `ios` rather than `objc` so that other tests (cpp in #17058, for example) on iOS could also use it, eliminating the huge overhead like downloading master  repo of Cocoapods",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16988,229939883,2018-11-01T04:58:42Z,include/grpcpp/impl/codegen/server_callback.h,"@@ -0,0 +1,200 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPCPP_IMPL_CODEGEN_SERVER_CALLBACK_H+#define GRPCPP_IMPL_CODEGEN_SERVER_CALLBACK_H++#include <functional>++#include <grpcpp/impl/codegen/call.h>+#include <grpcpp/impl/codegen/callback_common.h>+#include <grpcpp/impl/codegen/config.h>+#include <grpcpp/impl/codegen/core_codegen_interface.h>+#include <grpcpp/impl/codegen/server_context.h>+#include <grpcpp/impl/codegen/server_interface.h>+#include <grpcpp/impl/codegen/status.h>++namespace grpc {++// forward declarations+namespace internal {+template <class ServiceType, class RequestType, class ResponseType>+class CallbackUnaryHandler;+}  // namespace internal++namespace experimental {++// For unary RPCs, the exposed controller class is only an interface+// and the actual implementation is an internal class.+class ServerCallbackRpcController {"," @yang-g and I discussed this. We should make a decision about the API for that arena soon in case it requires us to put template parameters on the Controller. I think that we should come to the right decision (in a later PR) than try to rush it into this one, imo.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16919,229944305,2018-11-01T05:41:29Z,src/python/grpcio_tests/tests/unit/_metadata_flags_test.py,"@@ -106,6 +107,18 @@ def service(self, handler_call_details):             return None  +def get_free_loopback_tcp_port():+    tcp = socket.socket(socket.AF_INET6)+    tcp.bind(('', 0))+    address_tuple = tcp.getsockname()+    return ""[%s]:%s"" % (address_tuple[0], address_tuple[1])",nit: is `address_tuple[0]` not just `::` ? We could make it a realistic server address <i>I think</i> by changing this to bind to `::1` instead of a wildcard,OK
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/17050,230127406,2018-11-01T17:28:39Z,src/core/lib/channel/channelz.cc,"@@ -277,62 +280,64 @@ grpc_json* ServerNode::RenderJson() {   return top_level_json; } -SocketAddress::SocketAddress() : type_(AddressType::kUnset), port_(-1) {}--SocketAddress::SocketAddress(SocketAddress&& other) {-  type_ = other.type_;-  port_ = other.port_;-  blob_.reset((other.blob_.release()));-}--void SocketAddress::PopulateJson(const char* name, grpc_json* json) {-  if (type_ == AddressType::kUnset) {-    return;-  }+static void PopulateSocketAddressJson(grpc_json* json, const char* name,+                                      const char* addr_str) {+  if (addr_str == nullptr) return;   grpc_json* json_iterator = nullptr;   json_iterator = grpc_json_create_child(json_iterator, json, name, nullptr,                                          GRPC_JSON_OBJECT, false);   json = json_iterator;   json_iterator = nullptr;-  switch (type_) {-    case AddressType::kTcpAddress:-      json_iterator =-          grpc_json_create_child(json_iterator, json, ""tcpip_address"", nullptr,-                                 GRPC_JSON_OBJECT, false);-      json = json_iterator;-      json_iterator = nullptr;-      json_iterator =-          grpc_json_add_number_string_child(json, json_iterator, ""port"", port_);-      json_iterator =-          grpc_json_create_child(json_iterator, json, ""ip_address"", blob_.get(),-                                 GRPC_JSON_STRING, false);-      break;-    case AddressType::kUdsAddress:+  int port_num = -1;+  grpc_uri* uri = grpc_uri_parse(addr_str, true);+  if (uri != nullptr && (strcmp(uri->scheme, ""fd"") != 0)) {+    const char* host_port = uri->path;+    if (*host_port == '/') ++host_port;+    if (strcmp(uri->scheme, ""unix"") == 0) {       json_iterator = grpc_json_create_child(json_iterator, json, ""uds_address"",                                              nullptr, GRPC_JSON_OBJECT, false);       json = json_iterator;       json_iterator = nullptr;       json_iterator =-          grpc_json_create_child(json_iterator, json, ""filename"", blob_.get(),-                                 GRPC_JSON_STRING, false);-      break;-    case AddressType::kDirectChannelAddress:+          grpc_json_create_child(json_iterator, json, ""filename"",+                                 gpr_strdup(host_port), GRPC_JSON_STRING, true);+    } else {+      char* host = nullptr;+      char* port = nullptr;+      if (strcmp(uri->scheme, ""localhost"") == 0) {",This was only coming from the string passed to the listening socket... I suspect that I can do some substitution earlier in the code,OK
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/17050,230133430,2018-11-01T17:45:42Z,src/core/lib/channel/channelz.cc,"@@ -277,62 +280,64 @@ grpc_json* ServerNode::RenderJson() {   return top_level_json; } -SocketAddress::SocketAddress() : type_(AddressType::kUnset), port_(-1) {}--SocketAddress::SocketAddress(SocketAddress&& other) {-  type_ = other.type_;-  port_ = other.port_;-  blob_.reset((other.blob_.release()));-}--void SocketAddress::PopulateJson(const char* name, grpc_json* json) {-  if (type_ == AddressType::kUnset) {-    return;-  }+static void PopulateSocketAddressJson(grpc_json* json, const char* name,+                                      const char* addr_str) {+  if (addr_str == nullptr) return;   grpc_json* json_iterator = nullptr;   json_iterator = grpc_json_create_child(json_iterator, json, name, nullptr,                                          GRPC_JSON_OBJECT, false);   json = json_iterator;   json_iterator = nullptr;-  switch (type_) {-    case AddressType::kTcpAddress:-      json_iterator =-          grpc_json_create_child(json_iterator, json, ""tcpip_address"", nullptr,-                                 GRPC_JSON_OBJECT, false);-      json = json_iterator;-      json_iterator = nullptr;-      json_iterator =-          grpc_json_add_number_string_child(json, json_iterator, ""port"", port_);-      json_iterator =-          grpc_json_create_child(json_iterator, json, ""ip_address"", blob_.get(),-                                 GRPC_JSON_STRING, false);-      break;-    case AddressType::kUdsAddress:+  int port_num = -1;+  grpc_uri* uri = grpc_uri_parse(addr_str, true);+  if (uri != nullptr && (strcmp(uri->scheme, ""fd"") != 0)) {+    const char* host_port = uri->path;+    if (*host_port == '/') ++host_port;+    if (strcmp(uri->scheme, ""unix"") == 0) {       json_iterator = grpc_json_create_child(json_iterator, json, ""uds_address"",                                              nullptr, GRPC_JSON_OBJECT, false);       json = json_iterator;       json_iterator = nullptr;       json_iterator =-          grpc_json_create_child(json_iterator, json, ""filename"", blob_.get(),-                                 GRPC_JSON_STRING, false);-      break;-    case AddressType::kDirectChannelAddress:+          grpc_json_create_child(json_iterator, json, ""filename"",+                                 gpr_strdup(host_port), GRPC_JSON_STRING, true);+    } else {+      char* host = nullptr;+      char* port = nullptr;+      if (strcmp(uri->scheme, ""localhost"") == 0) {","To be a little more clear, this is actually coming from the listening socket's peer string, which is ""localhost:21802""When that gets parsed by the URI parser, we get `uri->scheme=""localhost"", uri->path=""21802""`, which is not correct. Do you think I should fix this up in the uri parser? Or do an explicit check for localhost before even passing to the uri parser",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/16944,230169109,2018-11-01T19:32:10Z,src/core/ext/transport/cronet/transport/cronet_transport.cc,"@@ -314,14 +333,8 @@ static void add_to_storage(struct stream_obj* s,   struct op_storage* storage = &s->storage;   /* add new op at the beginning of the linked list. The memory is freed   in remove_from_storage */-  struct op_and_state* new_op = static_cast<struct op_and_state*>(-      gpr_malloc(sizeof(struct op_and_state)));-  memcpy(&new_op->op, op, sizeof(grpc_transport_stream_op_batch));-  memset(&new_op->state, 0, sizeof(new_op->state));-  new_op->s = s;-  new_op->done = false;+  op_and_state* new_op = grpc_core::New<op_and_state>(s);",This was not plain initialization to 0; some of the data in `op` was copied to `new_op`.,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17050,230183627,2018-11-01T20:19:45Z,src/core/lib/channel/channelz.cc,"@@ -277,62 +280,64 @@ grpc_json* ServerNode::RenderJson() {   return top_level_json; } -SocketAddress::SocketAddress() : type_(AddressType::kUnset), port_(-1) {}--SocketAddress::SocketAddress(SocketAddress&& other) {-  type_ = other.type_;-  port_ = other.port_;-  blob_.reset((other.blob_.release()));-}--void SocketAddress::PopulateJson(const char* name, grpc_json* json) {-  if (type_ == AddressType::kUnset) {-    return;-  }+static void PopulateSocketAddressJson(grpc_json* json, const char* name,+                                      const char* addr_str) {+  if (addr_str == nullptr) return;   grpc_json* json_iterator = nullptr;   json_iterator = grpc_json_create_child(json_iterator, json, name, nullptr,                                          GRPC_JSON_OBJECT, false);   json = json_iterator;   json_iterator = nullptr;-  switch (type_) {-    case AddressType::kTcpAddress:-      json_iterator =-          grpc_json_create_child(json_iterator, json, ""tcpip_address"", nullptr,-                                 GRPC_JSON_OBJECT, false);-      json = json_iterator;-      json_iterator = nullptr;-      json_iterator =-          grpc_json_add_number_string_child(json, json_iterator, ""port"", port_);-      json_iterator =-          grpc_json_create_child(json_iterator, json, ""ip_address"", blob_.get(),-                                 GRPC_JSON_STRING, false);-      break;-    case AddressType::kUdsAddress:+  int port_num = -1;+  grpc_uri* uri = grpc_uri_parse(addr_str, true);+  if (uri != nullptr && (strcmp(uri->scheme, ""fd"") != 0)) {+    const char* host_port = uri->path;+    if (*host_port == '/') ++host_port;+    if (strcmp(uri->scheme, ""unix"") == 0) {       json_iterator = grpc_json_create_child(json_iterator, json, ""uds_address"",                                              nullptr, GRPC_JSON_OBJECT, false);       json = json_iterator;       json_iterator = nullptr;       json_iterator =-          grpc_json_create_child(json_iterator, json, ""filename"", blob_.get(),-                                 GRPC_JSON_STRING, false);-      break;-    case AddressType::kDirectChannelAddress:+          grpc_json_create_child(json_iterator, json, ""filename"",+                                 gpr_strdup(host_port), GRPC_JSON_STRING, true);+    } else {+      char* host = nullptr;+      char* port = nullptr;+      if (strcmp(uri->scheme, ""localhost"") == 0) {","Yeah, I guess the listen socket's address string won't necessarily be a URI.  The string passed to `grpc_server_add_insecure_http2_port()` will get passed directly to `grpc_blocking_resolve_address()` [here](https://github.com/grpc/grpc/blob/master/src/core/ext/transport/chttp2/server/chttp2_server.cc#L311), with no URI parsing happening first.  We do have a [horrible hack](https://github.com/grpc/grpc/blob/master/src/core/lib/iomgr/resolve_address_posix.cc#L57) in place to support `unix:` URIs, but we have a bug somewhere (can't find it at the moment) to fix that.For now, my suggestion would be to first parse it as a URI and then check whether the scheme is one of the 3 specific ones we know how to handle (`ipv4`, `ipv6`, and `unix`).  If it's none of those, then even if it parsed as a URI, we should ignore that and just report the full string as an `OtherAddress`.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17064,230184827,2018-11-01T20:23:27Z,src/python/grpcio_tests/tests/unit/_logging_test.py,"@@ -0,0 +1,68 @@+# Copyright 2018 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Test of gRPC Python's interaction with the python logging module""""""++import unittest+import six+from six.moves import reload_module+import logging+import grpc+import functools+import sys+++def patch_stderr(f):++    @functools.wraps(f)+    def _impl(*args, **kwargs):+        old_stderr = sys.stderr+        sys.stderr = six.StringIO()+        try:+            f(*args, **kwargs)+        finally:+            sys.stderr = old_stderr++    return _impl+++class LoggingTest(unittest.TestCase):++    def test_logger_not_occupied(self):+        self.assertEqual(0, len(logging.getLogger().handlers))++    @patch_stderr+    def test_handler_found(self):+        try:+            reload_module(logging)+            reload_module(grpc)+            self.assertFalse(+                ""No handlers could be found"" in sys.stderr.getvalue())",optional: There is `assertNotIn` function in unit test. https://docs.python.org/2/library/unittest.html#unittest.TestCase.assertNotIn,OK
219470,benjaminp,https://api.github.com/repos/grpc/grpc/pulls/16976,230243477,2018-11-02T00:45:01Z,src/python/grpcio/grpc/_cython/_cygrpc/security.pyx.pxi,"@@ -14,14 +14,14 @@  from libc.string cimport memcpy -import pkg_resources+import pkgutil   cdef grpc_ssl_roots_override_result ssl_roots_override_callback(     char **pem_root_certs) nogil:   with gil:-    temporary_pem_root_certs = pkg_resources.resource_string(-        __name__.rstrip('.cygrpc'), '_credentials/roots.pem')+    temporary_pem_root_certs = pkgutil.get_data(+        __name__[:-len('.cygrpc')], '_credentials/roots.pem')","`rstrip` is the wrong method to use here; the argument is [not a suffix](https://docs.python.org/3/library/stdtypes.html#str.rstrip). My latest update changes the code to do what was probably originally intended, though.",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16919,230269440,2018-11-02T04:50:17Z,src/python/grpcio/grpc/_channel.py,"@@ -906,11 +977,13 @@ def __init__(self, target, options, credentials):           target: The target to which to connect.           options: Configuration options for the channel.           credentials: A cygrpc.ChannelCredentials or None.+          wait_for_ready: A bool to enable wait-for-ready.         """"""         self._channel = cygrpc.Channel(             _common.encode(target), _options(options), credentials)         self._call_state = _ChannelCallState(self._channel)         self._connectivity_state = _ChannelConnectivityState(self._channel)+        self._initial_metadata_flags = _InitialMetadataFlags()","nit here and elsewhere throughout this PR: can we rename `_initial_metadata_flags` to `_send_initial_metadata_flags` ?I think this would make it more clear that these are flags that affect the ""send_initial_metadata"" <i>core operation</i> rather than the to-be-sent metadata itself, and also would be consistent with the naming used in c-core.",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16919,230269520,2018-11-02T04:50:58Z,src/python/grpcio/grpc/_channel.py,"@@ -906,11 +977,13 @@ def __init__(self, target, options, credentials):           target: The target to which to connect.           options: Configuration options for the channel.           credentials: A cygrpc.ChannelCredentials or None.+          wait_for_ready: A bool to enable wait-for-ready.         """"""         self._channel = cygrpc.Channel(             _common.encode(target), _options(options), credentials)         self._call_state = _ChannelCallState(self._channel)         self._connectivity_state = _ChannelConnectivityState(self._channel)+        self._initial_metadata_flags = _InitialMetadataFlags()","nit also: along the same lines, can we rename `_InitialMetadataFlags` to `_SendInitialMetadataFlags` here and elsewhere?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16919,230270074,2018-11-02T04:56:16Z,src/python/grpcio/grpc/_channel.py,"@@ -906,11 +977,13 @@ def __init__(self, target, options, credentials):           target: The target to which to connect.           options: Configuration options for the channel.           credentials: A cygrpc.ChannelCredentials or None.+          wait_for_ready: A bool to enable wait-for-ready.",nit: `wait_for_ready` here is documented but not a parameter,OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16944,230270202,2018-11-02T04:57:32Z,src/core/ext/transport/inproc/inproc_transport.cc,"@@ -46,12 +46,61 @@ static grpc_slice g_fake_path_value; static grpc_slice g_fake_auth_key; static grpc_slice g_fake_auth_value; -typedef struct {+struct inproc_stream;+static bool cancel_stream_locked(inproc_stream* s, grpc_error* error);+static void op_state_machine(void* arg, grpc_error* error);+static void log_metadata(const grpc_metadata_batch* md_batch, bool is_client,+                         bool is_initial);+grpc_error* fill_in_metadata(inproc_stream* s,+                             const grpc_metadata_batch* metadata,+                             uint32_t flags, grpc_metadata_batch* out_md,+                             uint32_t* outflags, bool* markfilled);++struct shared_mu {+  shared_mu() {+    // Share one lock between both sides since both sides get affected+    gpr_mu_init(&mu);+    gpr_ref_init(&refs, 2);+  }+   gpr_mu mu;   gpr_refcount refs;-} shared_mu;+};++struct inproc_transport {","Since this looks like it's become a non-trivial piece of work (and rightly so), does this need to become a class, with appropriate declarations? I know that would complicate matters a lot as you'll need a dozen setters/getters and all the code in the various active functions would need to change to use those. My understanding of the style guide was that [`struct` should just contain data](https://google.github.io/styleguide/cppguide.html#Structs_vs._Classes) with member functions only to setup and reset the data, whereas these seem a little more meaningful. Your call.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/16944,230270399,2018-11-02T04:59:23Z,src/core/ext/transport/inproc/inproc_transport.cc,"@@ -60,125 +109,171 @@ typedef struct inproc_transport {   void (*accept_stream_cb)(void* user_data, grpc_transport* transport,                            const void* server_data);   void* accept_stream_data;-  bool is_closed;+  bool is_closed = false;   struct inproc_transport* other_side;-  struct inproc_stream* stream_list;-} inproc_transport;+  struct inproc_stream* stream_list = nullptr;+};++struct inproc_stream {",Same issue as above re `struct` vs `class`,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16919,230271570,2018-11-02T05:11:51Z,src/python/grpcio/grpc/_interceptor.py,"@@ -193,28 +198,38 @@ def __init__(self, thunk, method, interceptor):         self._method = method         self._interceptor = interceptor -    def __call__(self, request, timeout=None, metadata=None, credentials=None):+    def __call__(self,+                 request,+                 timeout=None,+                 metadata=None,+                 credentials=None,+                 wait_for_ready=None):",this parameter is ignored here?,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16919,230272947,2018-11-02T05:25:35Z,src/python/grpcio/grpc/_channel.py,"@@ -906,11 +977,13 @@ def __init__(self, target, options, credentials):           target: The target to which to connect.           options: Configuration options for the channel.           credentials: A cygrpc.ChannelCredentials or None.+          wait_for_ready: A bool to enable wait-for-ready.         """"""         self._channel = cygrpc.Channel(             _common.encode(target), _options(options), credentials)         self._call_state = _ChannelCallState(self._channel)         self._connectivity_state = _ChannelConnectivityState(self._channel)+        self._initial_metadata_flags = _InitialMetadataFlags()","I'm a little stuck on this....Per [this gRFC comment](https://github.com/grpc/proposal/pull/112#issuecomment-435272949), I thought that we wanted the `wait_for_ready` flag to be per-call, rather than per-channel?In that case, why are the `_initial_metadata` flags a property of the channel?",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/16919,230278015,2018-11-02T06:15:07Z,src/python/grpcio_tests/tests/unit/_metadata_flags_test.py,"@@ -0,0 +1,210 @@+# Copyright 2018 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Tests metadata flags feature by testing wait-for-ready semantics""""""++import time+import weakref+import unittest+import threading+import socket+try:+    import queue as queue+except ImportError:+    import Queue as queue++import grpc++from tests.unit import test_common+from tests.unit.framework.common import test_constants++_UNARY_UNARY = '/test/UnaryUnary'+_UNARY_STREAM = '/test/UnaryStream'+_STREAM_UNARY = '/test/StreamUnary'+_STREAM_STREAM = '/test/StreamStream'++_REQUEST = b'\x00\x00\x00'+_RESPONSE = b'\x00\x00\x00'++_ALL_CALL_CASES = [+    ('unary_unary', _UNARY_UNARY, False, '__call__', False),+    ('unary_unary', _UNARY_UNARY, False, 'with_call', False),+    ('unary_unary', _UNARY_UNARY, False, 'future', False),+    ('unary_stream', _UNARY_STREAM, False, '__call__', True),+    ('stream_unary', _STREAM_UNARY, True, '__call__', False),+    ('stream_unary', _STREAM_UNARY, True, 'with_call', False),+    ('stream_unary', _STREAM_UNARY, True, 'future', False),+    ('stream_stream', _STREAM_STREAM, True, '__call__', True),+]+++def handle_unary_unary(test, request, servicer_context):+    return _RESPONSE+++def handle_unary_stream(test, request, servicer_context):+    for _ in range(test_constants.STREAM_LENGTH):+        yield _RESPONSE+++def handle_stream_unary(test, request_iterator, servicer_context):+    for _ in request_iterator:+        pass+    return _RESPONSE+++def handle_stream_stream(test, request_iterator, servicer_context):+    for _ in request_iterator:+        yield _RESPONSE+++class _MethodHandler(grpc.RpcMethodHandler):++    def __init__(self, test, request_streaming, response_streaming):+        self.request_streaming = request_streaming+        self.response_streaming = response_streaming+        self.request_deserializer = None+        self.response_serializer = None+        self.unary_unary = None+        self.unary_stream = None+        self.stream_unary = None+        self.stream_stream = None+        if self.request_streaming and self.response_streaming:+            self.stream_stream = lambda req, ctx: handle_stream_stream(test, req, ctx)+        elif self.request_streaming:+            self.stream_unary = lambda req, ctx: handle_stream_unary(test, req, ctx)+        elif self.response_streaming:+            self.unary_stream = lambda req, ctx: handle_unary_stream(test, req, ctx)+        else:+            self.unary_unary = lambda req, ctx: handle_unary_unary(test, req, ctx)+++class _GenericHandler(grpc.GenericRpcHandler):++    def __init__(self, test):+        self._test = test++    def service(self, handler_call_details):+        if handler_call_details.method == _UNARY_UNARY:+            return _MethodHandler(self._test, False, False)+        elif handler_call_details.method == _UNARY_STREAM:+            return _MethodHandler(self._test, False, True)+        elif handler_call_details.method == _STREAM_UNARY:+            return _MethodHandler(self._test, True, False)+        elif handler_call_details.method == _STREAM_STREAM:+            return _MethodHandler(self._test, True, True)+        else:+            return None+++def get_free_loopback_tcp_port():+    tcp = socket.socket(socket.AF_INET6)+    tcp.bind(('', 0))+    address_tuple = tcp.getsockname()+    return ""[%s]:%s"" % (address_tuple[0], address_tuple[1])+++def create_dummy_channel():+    """"""Creating dummy channels is a walkaround for retries""""""+    return grpc.insecure_channel(get_free_loopback_tcp_port())+++def execute_call(channel,+                 method_name,+                 server_method,+                 is_stream_input,+                 invoke_method,+                 is_stream_output,+                 wait_for_ready=None):+    multi_callable = getattr(channel, method_name)(server_method)","Personally I'd err on the side of expanding this out, even if there is duplication - it would be nice for readability to be able to compare the described API from the gRFC and the test side by side",OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/16944,230389172,2018-11-02T14:20:11Z,src/core/ext/transport/inproc/inproc_transport.cc,"@@ -46,12 +46,61 @@ static grpc_slice g_fake_path_value; static grpc_slice g_fake_auth_key; static grpc_slice g_fake_auth_value; -typedef struct {+struct inproc_stream;+static bool cancel_stream_locked(inproc_stream* s, grpc_error* error);+static void op_state_machine(void* arg, grpc_error* error);+static void log_metadata(const grpc_metadata_batch* md_batch, bool is_client,+                         bool is_initial);+grpc_error* fill_in_metadata(inproc_stream* s,+                             const grpc_metadata_batch* metadata,+                             uint32_t flags, grpc_metadata_batch* out_md,+                             uint32_t* outflags, bool* markfilled);++struct shared_mu {+  shared_mu() {+    // Share one lock between both sides since both sides get affected+    gpr_mu_init(&mu);+    gpr_ref_init(&refs, 2);+  }+   gpr_mu mu;   gpr_refcount refs;-} shared_mu;+};++struct inproc_transport {","Thank you. Yes, I completely agree that we should make these proper classes. Given that this patch is already too large and, based on our offline discussion that `ctor`/`dtor` are allowed for structs in the style guide, I will keep them as `struct`s in this patch, but will try to move them one by one to proper classes. Almost all functions can be private methods in all of these files.",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/16919,230494474,2018-11-02T20:11:35Z,src/python/grpcio/grpc/_channel.py,"@@ -906,11 +977,13 @@ def __init__(self, target, options, credentials):           target: The target to which to connect.           options: Configuration options for the channel.           credentials: A cygrpc.ChannelCredentials or None.+          wait_for_ready: A bool to enable wait-for-ready.         """"""         self._channel = cygrpc.Channel(             _common.encode(target), _options(options), credentials)         self._call_state = _ChannelCallState(self._channel)         self._connectivity_state = _ChannelConnectivityState(self._channel)+        self._initial_metadata_flags = _InitialMetadataFlags()","If a symbol starts with a verb, people tends to expect it is a function or going to change state of other variables. Class `_InitialMetadataFlags` here is just a derived `int` class to hold flag values. I slightly lean to not change the name.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17058,230750410,2018-11-05T13:35:45Z,tools/run_tests/run_tests.py,"@@ -308,6 +308,13 @@ def configure(self, config, args):      def test_specs(self):         out = []+        if self.platform == 'mac' and self.test_lang == 'c++':","this feels like a hack. we should come up with a better place for these tests rather than gluing on run_tests.py logic for C/C++ which is already complex enough. Also semantically, the tests don't belong here.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17074,230896830,2018-11-05T20:17:52Z,doc/python/sphinx/api.rst,"@@ -0,0 +1,123 @@+API Reference",I list the sections there because I saw the interfaces was separated into those sections in code. And my goal is wanting user to easily navigate through the documentation. The paradigm I am following is the documentation of [Flask](http://flask.pocoo.org/docs/1.0/api/). It uses sections to separate APIs into trunks.How about following aggregation? Spliting `Functions` and `gRPC Enums` into:* Create Client* Create Client Credentials* Create Server* Create Server Credentials* RPC Method Handlers* Channel Ready Future* Channel Connectivity* gRPC Status Code,OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/16919,230953090,2018-11-05T23:30:51Z,src/python/grpcio_tests/tests/unit/_metadata_flags_test.py,"@@ -0,0 +1,244 @@+# Copyright 2018 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Tests metadata flags feature by testing wait-for-ready semantics""""""++import time+import weakref+import unittest+import threading+import socket+try:+    import queue as queue+except ImportError:+    import Queue as queue++import grpc++from tests.unit import test_common+from tests.unit.framework.common import test_constants++_UNARY_UNARY = '/test/UnaryUnary'+_UNARY_STREAM = '/test/UnaryStream'+_STREAM_UNARY = '/test/StreamUnary'+_STREAM_STREAM = '/test/StreamStream'++_REQUEST = b'\x00\x00\x00'+_RESPONSE = b'\x00\x00\x00'+++def handle_unary_unary(test, request, servicer_context):+    return _RESPONSE+++def handle_unary_stream(test, request, servicer_context):+    for _ in range(test_constants.STREAM_LENGTH):+        yield _RESPONSE+++def handle_stream_unary(test, request_iterator, servicer_context):+    for _ in request_iterator:+        pass+    return _RESPONSE+++def handle_stream_stream(test, request_iterator, servicer_context):+    for _ in request_iterator:+        yield _RESPONSE+++class _MethodHandler(grpc.RpcMethodHandler):++    def __init__(self, test, request_streaming, response_streaming):+        self.request_streaming = request_streaming+        self.response_streaming = response_streaming+        self.request_deserializer = None+        self.response_serializer = None+        self.unary_unary = None+        self.unary_stream = None+        self.stream_unary = None+        self.stream_stream = None+        if self.request_streaming and self.response_streaming:+            self.stream_stream = lambda req, ctx: handle_stream_stream(test, req, ctx)+        elif self.request_streaming:+            self.stream_unary = lambda req, ctx: handle_stream_unary(test, req, ctx)+        elif self.response_streaming:+            self.unary_stream = lambda req, ctx: handle_unary_stream(test, req, ctx)+        else:+            self.unary_unary = lambda req, ctx: handle_unary_unary(test, req, ctx)+++class _GenericHandler(grpc.GenericRpcHandler):++    def __init__(self, test):+        self._test = test++    def service(self, handler_call_details):+        if handler_call_details.method == _UNARY_UNARY:+            return _MethodHandler(self._test, False, False)+        elif handler_call_details.method == _UNARY_STREAM:+            return _MethodHandler(self._test, False, True)+        elif handler_call_details.method == _STREAM_UNARY:+            return _MethodHandler(self._test, True, False)+        elif handler_call_details.method == _STREAM_STREAM:+            return _MethodHandler(self._test, True, True)+        else:+            return None+++def get_free_loopback_tcp_port():+    tcp = socket.socket(socket.AF_INET6)+    tcp.bind(('', 0))+    address_tuple = tcp.getsockname()+    return tcp, ""[::1]:%s"" % (address_tuple[1])+++def create_dummy_channel():+    """"""Creating dummy channels is a walkaround for retries""""""+    _, addr = get_free_loopback_tcp_port()+    return grpc.insecure_channel(addr)+++def perform_unary_unary_call(channel, wait_for_ready=None):+    channel.unary_unary(_UNARY_UNARY).__call__(+        _REQUEST,+        # timeout=test_constants.SHORT_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_unary_unary_with_call(channel, wait_for_ready=None):+    channel.unary_unary(_UNARY_UNARY).with_call(+        _REQUEST,+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_unary_unary_future(channel, wait_for_ready=None):+    channel.unary_unary(_UNARY_UNARY).future(+        _REQUEST,+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready).result(+            timeout=test_constants.LONG_TIMEOUT)+++def perform_unary_stream_call(channel, wait_for_ready=None):+    response_iterator = channel.unary_stream(_UNARY_STREAM).__call__(+        _REQUEST,+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+    for _ in response_iterator:+        pass+++def perform_stream_unary_call(channel, wait_for_ready=None):+    channel.stream_unary(_STREAM_UNARY).__call__(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_stream_unary_with_call(channel, wait_for_ready=None):+    channel.stream_unary(_STREAM_UNARY).with_call(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_stream_unary_future(channel, wait_for_ready=None):+    channel.stream_unary(_STREAM_UNARY).future(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready).result(+            timeout=test_constants.LONG_TIMEOUT)+++def perform_stream_stream_call(channel, wait_for_ready=None):+    response_iterator = channel.stream_stream(_STREAM_STREAM).__call__(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+    for _ in response_iterator:+        pass+++_ALL_CALL_CASES = [+    perform_unary_unary_call, perform_unary_unary_with_call,+    perform_unary_unary_future, perform_unary_stream_call,+    perform_stream_unary_call, perform_stream_unary_with_call,+    perform_stream_unary_future, perform_stream_stream_call+]+++class MetadataFlagsTest(unittest.TestCase):++    def check_connection_does_failfast(self, fn, channel, wait_for_ready=None):+        try:+            fn(channel, wait_for_ready)+        except BaseException as e:  # pylint: disable=broad-except+            self.assertIn('StatusCode.UNAVAILABLE', str(e))++    def test_call_wait_for_ready_default(self):+        for perform_call in _ALL_CALL_CASES:+            self.check_connection_does_failfast(perform_call,+                                                create_dummy_channel())++    def test_call_wait_for_ready_disabled(self):+        for perform_call in _ALL_CALL_CASES:+            self.check_connection_does_failfast(+                perform_call, create_dummy_channel(), wait_for_ready=False)++    def test_call_wait_for_ready_enabled(self):+        # To test the wait mechanism, Python thread is required to make+        #   client set up first without handling them case by case.+        # Also, Python thread don't pass the unhandled exceptions to",Will it be a problem for the end user if these exceptions are never surfaced to their application?,
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/16919,230954115,2018-11-05T23:35:58Z,src/python/grpcio_tests/tests/unit/_metadata_flags_test.py,"@@ -0,0 +1,244 @@+# Copyright 2018 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Tests metadata flags feature by testing wait-for-ready semantics""""""++import time+import weakref+import unittest+import threading+import socket+try:+    import queue as queue+except ImportError:+    import Queue as queue++import grpc++from tests.unit import test_common+from tests.unit.framework.common import test_constants++_UNARY_UNARY = '/test/UnaryUnary'+_UNARY_STREAM = '/test/UnaryStream'+_STREAM_UNARY = '/test/StreamUnary'+_STREAM_STREAM = '/test/StreamStream'++_REQUEST = b'\x00\x00\x00'+_RESPONSE = b'\x00\x00\x00'+++def handle_unary_unary(test, request, servicer_context):+    return _RESPONSE+++def handle_unary_stream(test, request, servicer_context):+    for _ in range(test_constants.STREAM_LENGTH):+        yield _RESPONSE+++def handle_stream_unary(test, request_iterator, servicer_context):+    for _ in request_iterator:+        pass+    return _RESPONSE+++def handle_stream_stream(test, request_iterator, servicer_context):+    for _ in request_iterator:+        yield _RESPONSE+++class _MethodHandler(grpc.RpcMethodHandler):++    def __init__(self, test, request_streaming, response_streaming):+        self.request_streaming = request_streaming+        self.response_streaming = response_streaming+        self.request_deserializer = None+        self.response_serializer = None+        self.unary_unary = None+        self.unary_stream = None+        self.stream_unary = None+        self.stream_stream = None+        if self.request_streaming and self.response_streaming:+            self.stream_stream = lambda req, ctx: handle_stream_stream(test, req, ctx)+        elif self.request_streaming:+            self.stream_unary = lambda req, ctx: handle_stream_unary(test, req, ctx)+        elif self.response_streaming:+            self.unary_stream = lambda req, ctx: handle_unary_stream(test, req, ctx)+        else:+            self.unary_unary = lambda req, ctx: handle_unary_unary(test, req, ctx)+++class _GenericHandler(grpc.GenericRpcHandler):++    def __init__(self, test):+        self._test = test++    def service(self, handler_call_details):+        if handler_call_details.method == _UNARY_UNARY:+            return _MethodHandler(self._test, False, False)+        elif handler_call_details.method == _UNARY_STREAM:+            return _MethodHandler(self._test, False, True)+        elif handler_call_details.method == _STREAM_UNARY:+            return _MethodHandler(self._test, True, False)+        elif handler_call_details.method == _STREAM_STREAM:+            return _MethodHandler(self._test, True, True)+        else:+            return None+++def get_free_loopback_tcp_port():+    tcp = socket.socket(socket.AF_INET6)+    tcp.bind(('', 0))+    address_tuple = tcp.getsockname()+    return tcp, ""[::1]:%s"" % (address_tuple[1])+++def create_dummy_channel():+    """"""Creating dummy channels is a walkaround for retries""""""+    _, addr = get_free_loopback_tcp_port()+    return grpc.insecure_channel(addr)+++def perform_unary_unary_call(channel, wait_for_ready=None):+    channel.unary_unary(_UNARY_UNARY).__call__(+        _REQUEST,+        # timeout=test_constants.SHORT_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_unary_unary_with_call(channel, wait_for_ready=None):+    channel.unary_unary(_UNARY_UNARY).with_call(+        _REQUEST,+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_unary_unary_future(channel, wait_for_ready=None):+    channel.unary_unary(_UNARY_UNARY).future(+        _REQUEST,+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready).result(+            timeout=test_constants.LONG_TIMEOUT)+++def perform_unary_stream_call(channel, wait_for_ready=None):+    response_iterator = channel.unary_stream(_UNARY_STREAM).__call__(+        _REQUEST,+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+    for _ in response_iterator:+        pass+++def perform_stream_unary_call(channel, wait_for_ready=None):+    channel.stream_unary(_STREAM_UNARY).__call__(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_stream_unary_with_call(channel, wait_for_ready=None):+    channel.stream_unary(_STREAM_UNARY).with_call(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_stream_unary_future(channel, wait_for_ready=None):+    channel.stream_unary(_STREAM_UNARY).future(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready).result(+            timeout=test_constants.LONG_TIMEOUT)+++def perform_stream_stream_call(channel, wait_for_ready=None):+    response_iterator = channel.stream_stream(_STREAM_STREAM).__call__(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+    for _ in response_iterator:+        pass+++_ALL_CALL_CASES = [+    perform_unary_unary_call, perform_unary_unary_with_call,+    perform_unary_unary_future, perform_unary_stream_call,+    perform_stream_unary_call, perform_stream_unary_with_call,+    perform_stream_unary_future, perform_stream_stream_call+]+++class MetadataFlagsTest(unittest.TestCase):++    def check_connection_does_failfast(self, fn, channel, wait_for_ready=None):+        try:+            fn(channel, wait_for_ready)+        except BaseException as e:  # pylint: disable=broad-except+            self.assertIn('StatusCode.UNAVAILABLE', str(e))++    def test_call_wait_for_ready_default(self):+        for perform_call in _ALL_CALL_CASES:",You might consider using [a parametrization library](https://github.com/wolever/parameterized) for this.,OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/16919,230954640,2018-11-05T23:38:27Z,src/python/grpcio_tests/tests/unit/_metadata_flags_test.py,"@@ -0,0 +1,244 @@+# Copyright 2018 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Tests metadata flags feature by testing wait-for-ready semantics""""""++import time+import weakref+import unittest+import threading+import socket+try:+    import queue as queue+except ImportError:+    import Queue as queue++import grpc++from tests.unit import test_common+from tests.unit.framework.common import test_constants++_UNARY_UNARY = '/test/UnaryUnary'+_UNARY_STREAM = '/test/UnaryStream'+_STREAM_UNARY = '/test/StreamUnary'+_STREAM_STREAM = '/test/StreamStream'++_REQUEST = b'\x00\x00\x00'+_RESPONSE = b'\x00\x00\x00'+++def handle_unary_unary(test, request, servicer_context):+    return _RESPONSE+++def handle_unary_stream(test, request, servicer_context):+    for _ in range(test_constants.STREAM_LENGTH):+        yield _RESPONSE+++def handle_stream_unary(test, request_iterator, servicer_context):+    for _ in request_iterator:+        pass+    return _RESPONSE+++def handle_stream_stream(test, request_iterator, servicer_context):+    for _ in request_iterator:+        yield _RESPONSE+++class _MethodHandler(grpc.RpcMethodHandler):++    def __init__(self, test, request_streaming, response_streaming):+        self.request_streaming = request_streaming+        self.response_streaming = response_streaming+        self.request_deserializer = None+        self.response_serializer = None+        self.unary_unary = None+        self.unary_stream = None+        self.stream_unary = None+        self.stream_stream = None+        if self.request_streaming and self.response_streaming:+            self.stream_stream = lambda req, ctx: handle_stream_stream(test, req, ctx)+        elif self.request_streaming:+            self.stream_unary = lambda req, ctx: handle_stream_unary(test, req, ctx)+        elif self.response_streaming:+            self.unary_stream = lambda req, ctx: handle_unary_stream(test, req, ctx)+        else:+            self.unary_unary = lambda req, ctx: handle_unary_unary(test, req, ctx)+++class _GenericHandler(grpc.GenericRpcHandler):++    def __init__(self, test):+        self._test = test++    def service(self, handler_call_details):+        if handler_call_details.method == _UNARY_UNARY:+            return _MethodHandler(self._test, False, False)+        elif handler_call_details.method == _UNARY_STREAM:+            return _MethodHandler(self._test, False, True)+        elif handler_call_details.method == _STREAM_UNARY:+            return _MethodHandler(self._test, True, False)+        elif handler_call_details.method == _STREAM_STREAM:+            return _MethodHandler(self._test, True, True)+        else:+            return None+++def get_free_loopback_tcp_port():+    tcp = socket.socket(socket.AF_INET6)+    tcp.bind(('', 0))+    address_tuple = tcp.getsockname()+    return tcp, ""[::1]:%s"" % (address_tuple[1])+++def create_dummy_channel():+    """"""Creating dummy channels is a walkaround for retries""""""+    _, addr = get_free_loopback_tcp_port()+    return grpc.insecure_channel(addr)+++def perform_unary_unary_call(channel, wait_for_ready=None):+    channel.unary_unary(_UNARY_UNARY).__call__(+        _REQUEST,+        # timeout=test_constants.SHORT_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_unary_unary_with_call(channel, wait_for_ready=None):+    channel.unary_unary(_UNARY_UNARY).with_call(+        _REQUEST,+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_unary_unary_future(channel, wait_for_ready=None):+    channel.unary_unary(_UNARY_UNARY).future(+        _REQUEST,+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready).result(+            timeout=test_constants.LONG_TIMEOUT)+++def perform_unary_stream_call(channel, wait_for_ready=None):+    response_iterator = channel.unary_stream(_UNARY_STREAM).__call__(+        _REQUEST,+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+    for _ in response_iterator:+        pass+++def perform_stream_unary_call(channel, wait_for_ready=None):+    channel.stream_unary(_STREAM_UNARY).__call__(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_stream_unary_with_call(channel, wait_for_ready=None):+    channel.stream_unary(_STREAM_UNARY).with_call(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_stream_unary_future(channel, wait_for_ready=None):+    channel.stream_unary(_STREAM_UNARY).future(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready).result(+            timeout=test_constants.LONG_TIMEOUT)+++def perform_stream_stream_call(channel, wait_for_ready=None):+    response_iterator = channel.stream_stream(_STREAM_STREAM).__call__(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+    for _ in response_iterator:+        pass+++_ALL_CALL_CASES = [+    perform_unary_unary_call, perform_unary_unary_with_call,+    perform_unary_unary_future, perform_unary_stream_call,+    perform_stream_unary_call, perform_stream_unary_with_call,+    perform_stream_unary_future, perform_stream_stream_call+]+++class MetadataFlagsTest(unittest.TestCase):++    def check_connection_does_failfast(self, fn, channel, wait_for_ready=None):+        try:+            fn(channel, wait_for_ready)+        except BaseException as e:  # pylint: disable=broad-except+            self.assertIn('StatusCode.UNAVAILABLE', str(e))",It looks like this test will pass in the case that no exception is thrown. Is that the intended behavior?,
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/16919,230958726,2018-11-05T23:58:27Z,src/python/grpcio_tests/tests/unit/_metadata_flags_test.py,"@@ -0,0 +1,244 @@+# Copyright 2018 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Tests metadata flags feature by testing wait-for-ready semantics""""""++import time+import weakref+import unittest+import threading+import socket+try:+    import queue as queue+except ImportError:+    import Queue as queue++import grpc++from tests.unit import test_common+from tests.unit.framework.common import test_constants++_UNARY_UNARY = '/test/UnaryUnary'+_UNARY_STREAM = '/test/UnaryStream'+_STREAM_UNARY = '/test/StreamUnary'+_STREAM_STREAM = '/test/StreamStream'++_REQUEST = b'\x00\x00\x00'+_RESPONSE = b'\x00\x00\x00'+++def handle_unary_unary(test, request, servicer_context):+    return _RESPONSE+++def handle_unary_stream(test, request, servicer_context):+    for _ in range(test_constants.STREAM_LENGTH):+        yield _RESPONSE+++def handle_stream_unary(test, request_iterator, servicer_context):+    for _ in request_iterator:+        pass+    return _RESPONSE+++def handle_stream_stream(test, request_iterator, servicer_context):+    for _ in request_iterator:+        yield _RESPONSE+++class _MethodHandler(grpc.RpcMethodHandler):++    def __init__(self, test, request_streaming, response_streaming):+        self.request_streaming = request_streaming+        self.response_streaming = response_streaming+        self.request_deserializer = None+        self.response_serializer = None+        self.unary_unary = None+        self.unary_stream = None+        self.stream_unary = None+        self.stream_stream = None+        if self.request_streaming and self.response_streaming:+            self.stream_stream = lambda req, ctx: handle_stream_stream(test, req, ctx)+        elif self.request_streaming:+            self.stream_unary = lambda req, ctx: handle_stream_unary(test, req, ctx)+        elif self.response_streaming:+            self.unary_stream = lambda req, ctx: handle_unary_stream(test, req, ctx)+        else:+            self.unary_unary = lambda req, ctx: handle_unary_unary(test, req, ctx)+++class _GenericHandler(grpc.GenericRpcHandler):++    def __init__(self, test):+        self._test = test++    def service(self, handler_call_details):+        if handler_call_details.method == _UNARY_UNARY:+            return _MethodHandler(self._test, False, False)+        elif handler_call_details.method == _UNARY_STREAM:+            return _MethodHandler(self._test, False, True)+        elif handler_call_details.method == _STREAM_UNARY:+            return _MethodHandler(self._test, True, False)+        elif handler_call_details.method == _STREAM_STREAM:+            return _MethodHandler(self._test, True, True)+        else:+            return None+++def get_free_loopback_tcp_port():+    tcp = socket.socket(socket.AF_INET6)+    tcp.bind(('', 0))+    address_tuple = tcp.getsockname()+    return tcp, ""[::1]:%s"" % (address_tuple[1])+++def create_dummy_channel():+    """"""Creating dummy channels is a walkaround for retries""""""+    _, addr = get_free_loopback_tcp_port()+    return grpc.insecure_channel(addr)+++def perform_unary_unary_call(channel, wait_for_ready=None):+    channel.unary_unary(_UNARY_UNARY).__call__(+        _REQUEST,+        # timeout=test_constants.SHORT_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_unary_unary_with_call(channel, wait_for_ready=None):+    channel.unary_unary(_UNARY_UNARY).with_call(+        _REQUEST,+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_unary_unary_future(channel, wait_for_ready=None):+    channel.unary_unary(_UNARY_UNARY).future(+        _REQUEST,+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready).result(+            timeout=test_constants.LONG_TIMEOUT)+++def perform_unary_stream_call(channel, wait_for_ready=None):+    response_iterator = channel.unary_stream(_UNARY_STREAM).__call__(+        _REQUEST,+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+    for _ in response_iterator:+        pass+++def perform_stream_unary_call(channel, wait_for_ready=None):+    channel.stream_unary(_STREAM_UNARY).__call__(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_stream_unary_with_call(channel, wait_for_ready=None):+    channel.stream_unary(_STREAM_UNARY).with_call(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_stream_unary_future(channel, wait_for_ready=None):+    channel.stream_unary(_STREAM_UNARY).future(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready).result(+            timeout=test_constants.LONG_TIMEOUT)+++def perform_stream_stream_call(channel, wait_for_ready=None):+    response_iterator = channel.stream_stream(_STREAM_STREAM).__call__(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+    for _ in response_iterator:+        pass+++_ALL_CALL_CASES = [+    perform_unary_unary_call, perform_unary_unary_with_call,+    perform_unary_unary_future, perform_unary_stream_call,+    perform_stream_unary_call, perform_stream_unary_with_call,+    perform_stream_unary_future, perform_stream_stream_call+]+++class MetadataFlagsTest(unittest.TestCase):++    def check_connection_does_failfast(self, fn, channel, wait_for_ready=None):+        try:+            fn(channel, wait_for_ready)+        except BaseException as e:  # pylint: disable=broad-except+            self.assertIn('StatusCode.UNAVAILABLE', str(e))++    def test_call_wait_for_ready_default(self):+        for perform_call in _ALL_CALL_CASES:+            self.check_connection_does_failfast(perform_call,+                                                create_dummy_channel())++    def test_call_wait_for_ready_disabled(self):+        for perform_call in _ALL_CALL_CASES:+            self.check_connection_does_failfast(+                perform_call, create_dummy_channel(), wait_for_ready=False)++    def test_call_wait_for_ready_enabled(self):+        # To test the wait mechanism, Python thread is required to make+        #   client set up first without handling them case by case.+        # Also, Python thread don't pass the unhandled exceptions to",The threading logic here is for this unit test case specifically. User have the freedom to create their own exception handling logic.,
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/16919,230959439,2018-11-06T00:02:44Z,src/python/grpcio_tests/tests/unit/_metadata_flags_test.py,"@@ -0,0 +1,244 @@+# Copyright 2018 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Tests metadata flags feature by testing wait-for-ready semantics""""""++import time+import weakref+import unittest+import threading+import socket+try:+    import queue as queue+except ImportError:+    import Queue as queue++import grpc++from tests.unit import test_common+from tests.unit.framework.common import test_constants++_UNARY_UNARY = '/test/UnaryUnary'+_UNARY_STREAM = '/test/UnaryStream'+_STREAM_UNARY = '/test/StreamUnary'+_STREAM_STREAM = '/test/StreamStream'++_REQUEST = b'\x00\x00\x00'+_RESPONSE = b'\x00\x00\x00'+++def handle_unary_unary(test, request, servicer_context):+    return _RESPONSE+++def handle_unary_stream(test, request, servicer_context):+    for _ in range(test_constants.STREAM_LENGTH):+        yield _RESPONSE+++def handle_stream_unary(test, request_iterator, servicer_context):+    for _ in request_iterator:+        pass+    return _RESPONSE+++def handle_stream_stream(test, request_iterator, servicer_context):+    for _ in request_iterator:+        yield _RESPONSE+++class _MethodHandler(grpc.RpcMethodHandler):++    def __init__(self, test, request_streaming, response_streaming):+        self.request_streaming = request_streaming+        self.response_streaming = response_streaming+        self.request_deserializer = None+        self.response_serializer = None+        self.unary_unary = None+        self.unary_stream = None+        self.stream_unary = None+        self.stream_stream = None+        if self.request_streaming and self.response_streaming:+            self.stream_stream = lambda req, ctx: handle_stream_stream(test, req, ctx)+        elif self.request_streaming:+            self.stream_unary = lambda req, ctx: handle_stream_unary(test, req, ctx)+        elif self.response_streaming:+            self.unary_stream = lambda req, ctx: handle_unary_stream(test, req, ctx)+        else:+            self.unary_unary = lambda req, ctx: handle_unary_unary(test, req, ctx)+++class _GenericHandler(grpc.GenericRpcHandler):++    def __init__(self, test):+        self._test = test++    def service(self, handler_call_details):+        if handler_call_details.method == _UNARY_UNARY:+            return _MethodHandler(self._test, False, False)+        elif handler_call_details.method == _UNARY_STREAM:+            return _MethodHandler(self._test, False, True)+        elif handler_call_details.method == _STREAM_UNARY:+            return _MethodHandler(self._test, True, False)+        elif handler_call_details.method == _STREAM_STREAM:+            return _MethodHandler(self._test, True, True)+        else:+            return None+++def get_free_loopback_tcp_port():+    tcp = socket.socket(socket.AF_INET6)+    tcp.bind(('', 0))+    address_tuple = tcp.getsockname()+    return tcp, ""[::1]:%s"" % (address_tuple[1])+++def create_dummy_channel():+    """"""Creating dummy channels is a walkaround for retries""""""+    _, addr = get_free_loopback_tcp_port()+    return grpc.insecure_channel(addr)+++def perform_unary_unary_call(channel, wait_for_ready=None):+    channel.unary_unary(_UNARY_UNARY).__call__(+        _REQUEST,+        # timeout=test_constants.SHORT_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_unary_unary_with_call(channel, wait_for_ready=None):+    channel.unary_unary(_UNARY_UNARY).with_call(+        _REQUEST,+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_unary_unary_future(channel, wait_for_ready=None):+    channel.unary_unary(_UNARY_UNARY).future(+        _REQUEST,+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready).result(+            timeout=test_constants.LONG_TIMEOUT)+++def perform_unary_stream_call(channel, wait_for_ready=None):+    response_iterator = channel.unary_stream(_UNARY_STREAM).__call__(+        _REQUEST,+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+    for _ in response_iterator:+        pass+++def perform_stream_unary_call(channel, wait_for_ready=None):+    channel.stream_unary(_STREAM_UNARY).__call__(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_stream_unary_with_call(channel, wait_for_ready=None):+    channel.stream_unary(_STREAM_UNARY).with_call(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_stream_unary_future(channel, wait_for_ready=None):+    channel.stream_unary(_STREAM_UNARY).future(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready).result(+            timeout=test_constants.LONG_TIMEOUT)+++def perform_stream_stream_call(channel, wait_for_ready=None):+    response_iterator = channel.stream_stream(_STREAM_STREAM).__call__(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+    for _ in response_iterator:+        pass+++_ALL_CALL_CASES = [+    perform_unary_unary_call, perform_unary_unary_with_call,+    perform_unary_unary_future, perform_unary_stream_call,+    perform_stream_unary_call, perform_stream_unary_with_call,+    perform_stream_unary_future, perform_stream_stream_call+]+++class MetadataFlagsTest(unittest.TestCase):++    def check_connection_does_failfast(self, fn, channel, wait_for_ready=None):+        try:+            fn(channel, wait_for_ready)+        except BaseException as e:  # pylint: disable=broad-except+            self.assertIn('StatusCode.UNAVAILABLE', str(e))++    def test_call_wait_for_ready_default(self):+        for perform_call in _ALL_CALL_CASES:+            self.check_connection_does_failfast(perform_call,+                                                create_dummy_channel())++    def test_call_wait_for_ready_disabled(self):+        for perform_call in _ALL_CALL_CASES:+            self.check_connection_does_failfast(+                perform_call, create_dummy_channel(), wait_for_ready=False)++    def test_call_wait_for_ready_enabled(self):+        # To test the wait mechanism, Python thread is required to make+        #   client set up first without handling them case by case.+        # Also, Python thread don't pass the unhandled exceptions to+        #   main thread. So, it need another method to store the+        #   exceptions and raise them again in main thread.+        self.unhandled_exceptions = queue.Queue()+        tcp, addr = get_free_loopback_tcp_port()++        def test_call(perform_call=None):+            try:+                channel = grpc.insecure_channel(addr)+                perform_call(channel, wait_for_ready=True)+            except BaseException as e:  # pylint: disable=broad-except+                self.unhandled_exceptions.put(e, True)++        test_threads = []+        for perform_call in _ALL_CALL_CASES:+            test_thread = threading.Thread(+                target=test_call, args=(perform_call,))+            test_thread.exception = None+            test_thread.start()+            test_threads.append(test_thread)++        # Start the server after the connections are waiting+        time.sleep(2)","This one is a little bit awkward. If the program doesn't sleep here, even wait-for-ready set to `False` can pass the test. So I choose a sleep time larger then the retries, which is half of the  timeout. I think this is the balanced point to avoid flaky test.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/16919,230959863,2018-11-06T00:04:55Z,src/python/grpcio_tests/tests/unit/_metadata_flags_test.py,"@@ -0,0 +1,244 @@+# Copyright 2018 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Tests metadata flags feature by testing wait-for-ready semantics""""""++import time+import weakref+import unittest+import threading+import socket+try:+    import queue as queue+except ImportError:+    import Queue as queue++import grpc++from tests.unit import test_common+from tests.unit.framework.common import test_constants++_UNARY_UNARY = '/test/UnaryUnary'+_UNARY_STREAM = '/test/UnaryStream'+_STREAM_UNARY = '/test/StreamUnary'+_STREAM_STREAM = '/test/StreamStream'++_REQUEST = b'\x00\x00\x00'+_RESPONSE = b'\x00\x00\x00'+++def handle_unary_unary(test, request, servicer_context):+    return _RESPONSE+++def handle_unary_stream(test, request, servicer_context):+    for _ in range(test_constants.STREAM_LENGTH):+        yield _RESPONSE+++def handle_stream_unary(test, request_iterator, servicer_context):+    for _ in request_iterator:+        pass+    return _RESPONSE+++def handle_stream_stream(test, request_iterator, servicer_context):+    for _ in request_iterator:+        yield _RESPONSE+++class _MethodHandler(grpc.RpcMethodHandler):++    def __init__(self, test, request_streaming, response_streaming):+        self.request_streaming = request_streaming+        self.response_streaming = response_streaming+        self.request_deserializer = None+        self.response_serializer = None+        self.unary_unary = None+        self.unary_stream = None+        self.stream_unary = None+        self.stream_stream = None+        if self.request_streaming and self.response_streaming:+            self.stream_stream = lambda req, ctx: handle_stream_stream(test, req, ctx)+        elif self.request_streaming:+            self.stream_unary = lambda req, ctx: handle_stream_unary(test, req, ctx)+        elif self.response_streaming:+            self.unary_stream = lambda req, ctx: handle_unary_stream(test, req, ctx)+        else:+            self.unary_unary = lambda req, ctx: handle_unary_unary(test, req, ctx)+++class _GenericHandler(grpc.GenericRpcHandler):++    def __init__(self, test):+        self._test = test++    def service(self, handler_call_details):+        if handler_call_details.method == _UNARY_UNARY:+            return _MethodHandler(self._test, False, False)+        elif handler_call_details.method == _UNARY_STREAM:+            return _MethodHandler(self._test, False, True)+        elif handler_call_details.method == _STREAM_UNARY:+            return _MethodHandler(self._test, True, False)+        elif handler_call_details.method == _STREAM_STREAM:+            return _MethodHandler(self._test, True, True)+        else:+            return None+++def get_free_loopback_tcp_port():+    tcp = socket.socket(socket.AF_INET6)+    tcp.bind(('', 0))+    address_tuple = tcp.getsockname()+    return tcp, ""[::1]:%s"" % (address_tuple[1])+++def create_dummy_channel():+    """"""Creating dummy channels is a walkaround for retries""""""+    _, addr = get_free_loopback_tcp_port()+    return grpc.insecure_channel(addr)+++def perform_unary_unary_call(channel, wait_for_ready=None):+    channel.unary_unary(_UNARY_UNARY).__call__(+        _REQUEST,+        # timeout=test_constants.SHORT_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_unary_unary_with_call(channel, wait_for_ready=None):+    channel.unary_unary(_UNARY_UNARY).with_call(+        _REQUEST,+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_unary_unary_future(channel, wait_for_ready=None):+    channel.unary_unary(_UNARY_UNARY).future(+        _REQUEST,+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready).result(+            timeout=test_constants.LONG_TIMEOUT)+++def perform_unary_stream_call(channel, wait_for_ready=None):+    response_iterator = channel.unary_stream(_UNARY_STREAM).__call__(+        _REQUEST,+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+    for _ in response_iterator:+        pass+++def perform_stream_unary_call(channel, wait_for_ready=None):+    channel.stream_unary(_STREAM_UNARY).__call__(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_stream_unary_with_call(channel, wait_for_ready=None):+    channel.stream_unary(_STREAM_UNARY).with_call(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+++def perform_stream_unary_future(channel, wait_for_ready=None):+    channel.stream_unary(_STREAM_UNARY).future(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready).result(+            timeout=test_constants.LONG_TIMEOUT)+++def perform_stream_stream_call(channel, wait_for_ready=None):+    response_iterator = channel.stream_stream(_STREAM_STREAM).__call__(+        iter([_REQUEST] * test_constants.STREAM_LENGTH),+        timeout=test_constants.LONG_TIMEOUT,+        wait_for_ready=wait_for_ready)+    for _ in response_iterator:+        pass+++_ALL_CALL_CASES = [+    perform_unary_unary_call, perform_unary_unary_with_call,+    perform_unary_unary_future, perform_unary_stream_call,+    perform_stream_unary_call, perform_stream_unary_with_call,+    perform_stream_unary_future, perform_stream_stream_call+]+++class MetadataFlagsTest(unittest.TestCase):++    def check_connection_does_failfast(self, fn, channel, wait_for_ready=None):+        try:+            fn(channel, wait_for_ready)+        except BaseException as e:  # pylint: disable=broad-except+            self.assertIn('StatusCode.UNAVAILABLE', str(e))","Yeah, good catch. I thought the server wasn't there, so it must have some kind of exception.",
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/16946,230960188,2018-11-06T00:06:55Z,tools/run_tests/run_interop_tests.py,"@@ -1315,7 +1317,7 @@ def aggregate_http2_results(stdout):             for language in languages:                 for test_case in _TEST_CASES:                     if not test_case in language.unimplemented_test_cases():-                        if not test_case in _SKIP_ADVANCED + _SKIP_COMPRESSION:+                        if not test_case in _SKIP_ADVANCED + _SKIP_COMPRESSION + _SKIP_SPECIAL_STATUS_MESSAGE:",Seems like this list of three is repeated a whole lot. Any way to factor it out?,OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/17124,231294287,2018-11-06T21:11:57Z,src/core/lib/gprpp/sync.h,"@@ -0,0 +1,79 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++/* Inline implementation of synchronization primitives, preferred over the C+   public API for C++ code. */++#ifndef GRPC_CORE_LIB_GPRPP_SYNC+#define GRPC_CORE_LIB_GPRPP_SYNC++#include <grpc/support/port_platform.h>++#include <grpc/support/atm.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include <assert.h>++namespace grpc_core {++inline void RefInit(gpr_refcount* r, int n) {","This is a brilliant move... but can I suggest that since this is all for deep-core use, is there any reason that we need to use the API structs of gpr_refcount? Or can this instead be a full C++ class with normal methods, etc? The free functions feel a little unusual for our C++ style.",
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17124,231296339,2018-11-06T21:18:19Z,src/core/lib/gprpp/sync.h,"@@ -0,0 +1,79 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++/* Inline implementation of synchronization primitives, preferred over the C+   public API for C++ code. */++#ifndef GRPC_CORE_LIB_GPRPP_SYNC+#define GRPC_CORE_LIB_GPRPP_SYNC++#include <grpc/support/port_platform.h>++#include <grpc/support/atm.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include <assert.h>++namespace grpc_core {++inline void RefInit(gpr_refcount* r, int n) {","thank you @vjpai! Sure, I can implement a class for this.I added the free functions to share the same implementation with the C `gpr_(ref|unref)*` helper. In other words, if I add a C++ class without the free functions, the implementation wouldn't be shared with the C API.So, to create a C++ class, I can think of two options:1) Introduce a new C++ class and use it everywhere in C++ code. Keep the C API for `gpr_refcount` untouched.2) Get rid of `gpr_refcount` from the public API (assuming there is no backwards compatibility concerns) and use the new C++ class.Which one would you prefer?",
10131044,nathanielmanistaatgoogle,https://api.github.com/repos/grpc/grpc/pulls/17074,231305031,2018-11-06T21:46:18Z,doc/python/sphinx/api.rst,"@@ -0,0 +1,123 @@+API Reference","> I list the sections there because I saw the interfaces was> separated into those sections in code.Yeah, but I'm saying _it's not a good thing that they're separated into those sections in code_. I feel that that section-division is _bad_, and it should not be used as an example.One of the things that's done in the code that's good and perhaps worth repeating in the reference is that all the code elements are in [definitions-before-uses order](https://www.youtube.com/watch?v=aOEfIrC07XA&t=27m21s). Did you notice that? Do you have any particular feelings about it? Something that I definitely don't like about the current order is the way the reader can see a function that returns a `grpc.Future` and then ask ""well what's a `grpc.Future`?"" and not see the specification of `grpc.Future` until all the way at the bottom.An important question we should ask is whether this document is a _tutorial_ or a _reference_. I'm pretty sure that in its current state it's a reference. If we wanted it to be a tutorial, we'd have to add a lot more prose and examples (and besides, we already have tutorials on [grpc.io](https://grpc.io)! Something important about _reference_ documentation is that it's not really meant to be read start to finish; users are expected that they'll just jump to whatever element it is about which they need to read. So the page could even be in alphabetical order.Here's another thing to consider: the sections currently don't have any prose attached to them. They don't have any sentences describing their area of concern or any sort of larger ideas. That's a sign that maybe their existence isn't really justified.",
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17128,231339199,2018-11-06T23:58:55Z,src/python/grpcio/commands.py,"@@ -253,6 +253,10 @@ class BuildExt(build_ext.build_ext):     LINK_OPTIONS = {}      def build_extensions(self):+        # This special conditioning is here due to difference of compiler","I'm not sure I fully follow the reasoning presented in this comment. It sounds like this comment describes a difference in behavior between gcc and clang, but the special condition here (`if ""darwin"" in sys.platform`) is distinguishing mac from other systems. Could you clarify why this explains the special casing of mac builds? Would a simpler statement like ""Darwin builds use a clang toolchain, while other systems use gcc"" convey the same information?",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/17125,231342847,2018-11-07T00:18:32Z,src/core/ext/filters/client_channel/lb_policy/xds/xds.cc,"@@ -1323,6 +1323,8 @@ void XdsLb::UpdateLocked(const grpc_channel_args& args) {   ProcessChannelArgsLocked(args);   // If fallback is configured and the RR policy already exists, update   // it with the new fallback addresses.+  // Note: We have disable fallback mode in the code, so this will only happen","Note that the condition at line 1327 is an and operation. So if fallback is disabled, the block under that condition should never happen.Also, I realized that the condition check here is wrong; it should be something like in https://github.com/grpc/grpc/pull/17131.I think after that PR is merged, we should just add some ERROR log in the block instead of calling `CreateOrUpdateRoundRobinPolicyLocked()`.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/17125,231591244,2018-11-07T16:59:30Z,src/core/ext/filters/client_channel/lb_policy/xds/xds.cc,"@@ -1323,6 +1323,8 @@ void XdsLb::UpdateLocked(const grpc_channel_args& args) {   ProcessChannelArgsLocked(args);   // If fallback is configured and the RR policy already exists, update   // it with the new fallback addresses.+  // Note: We have disable fallback mode in the code, so this will only happen","Yeah, I can understand you are turning the previous fallback behavior into a noop. The code here meant to update the RR policy with the new fallback addresses if we are in fallback mode (the condition check here is not very right, #17131 should make it clearer, please take a look at that PR). So, if fallback mode will never be triggered after this PR, the check here will always fail, instead of ""will only happen when ..."".That said, I think in the future the xds plugin still needs to update the fallback info in `UpdateLocked()`, so maybe just remove line 1324 to 1330 and add a TODO instead.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/17125,231593036,2018-11-07T17:04:08Z,src/core/ext/filters/client_channel/lb_policy/xds/xds.cc,"@@ -1646,13 +1647,9 @@ grpc_channel_args* XdsLb::CreateRoundRobinPolicyArgsLocked() {     addresses = ProcessServerlist(serverlist_);     is_backend_from_grpclb_load_balancer = true;   } else {-    // If CreateOrUpdateRoundRobinPolicyLocked() is invoked when we haven't-    // received any serverlist from the balancer, we use the fallback backends-    // returned by the resolver. Note that the fallback backend list may be-    // empty, in which case the new round_robin policy will keep the requested-    // picks pending.-    GPR_ASSERT(fallback_backend_addresses_ != nullptr);-    addresses = grpc_lb_addresses_copy(fallback_backend_addresses_);+    // This should never be invoked if we do not have serverlist_, as fallback","If so, we can remove this `if`branch, and add `GPR_ASSERT(serverlist_ != nullptr);` above.",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/17148,231731906,2018-11-08T00:45:07Z,src/core/lib/surface/call.cc,"@@ -694,6 +694,10 @@ static void cancel_with_error(grpc_call* c, grpc_error* error) {   execute_batch(c, op, &state->start_batch); } +void grpc_call_cancel_and_execute(grpc_call* call) {","Instead of `grpc_call_cancel_and_execute`, name this `grpc_call_cancel_internal`. And put it in an internal header, rather than a surface header? I think this could be similar to [slice_ref_internal.h](https://github.com/grpc/grpc/blob/master/src/core/lib/slice/slice_internal.h#L28)",OK
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/17125,232011052,2018-11-08T18:30:39Z,src/core/ext/filters/client_channel/lb_policy/xds/xds.cc,"@@ -1321,11 +1321,10 @@ void XdsLb::ProcessChannelArgsLocked(const grpc_channel_args& args) {  void XdsLb::UpdateLocked(const grpc_channel_args& args) {   ProcessChannelArgsLocked(args);-  // If fallback is configured and the RR policy already exists, update-  // it with the new fallback addresses.-  if (lb_fallback_timeout_ms_ > 0 && rr_policy_ != nullptr) {-    CreateOrUpdateRoundRobinPolicyLocked();-  }+  // Note: We have disable fallback mode in the code, so we dont need to update","Nit: disable -> disabled. dont-> don't. ""update the policy"" is ambiguous here; suggest saying that "", so we don't need to handle the fallback address changes.""",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/17148,232117292,2018-11-09T01:16:57Z,src/core/tsi/transport_security.cc,"@@ -213,10 +213,10 @@ tsi_result tsi_handshaker_next(  void tsi_handshaker_shutdown(tsi_handshaker* self) {   if (self == nullptr || self->vtable == nullptr) return;-  self->handshake_shutdown = true;   if (self->vtable->shutdown != nullptr) {     self->vtable->shutdown(self);   }+  self->handshake_shutdown = true;","Trying to figure out this part. It looked to me like the ""shutdown no-op"" was because of [this conditional within ALTS](https://github.com/grpc/grpc/blob/master/src/core/tsi/alts/handshaker/alts_tsi_handshaker.cc#L357). Why make the change here rather than within ALTS?",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/16971,232310920,2018-11-09T16:23:19Z,src/python/grpcio_tests/tests/unit/_surface_exceptions_test.py,"@@ -0,0 +1,46 @@+# Copyright 2018 The gRPC Authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Tests known exceptions from Cython cdef to be surfaced properly.""""""++import unittest++import grpc++import six++from tests.unit import test_common+from tests.unit.framework.common import test_constants+++class SurfaceExceptionsTest(unittest.TestCase):++    def testStrCredentials(self):+        """"""For Python 3 Only.""""""+        if six.PY3:+            credentials = grpc.ssl_channel_credentials(+                root_certificates=""HELLO"")","I think we should probably revamp this and add an explicit check when you create the `ssl_channel_credentials` to check the argument types and raise an exception right away if they don't match. This is currently a bit non-intuitive as you will fail on the next line, but the error is on the first. Granted, this could be in a followup PR.",
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/17148,232325389,2018-11-09T17:05:27Z,src/core/tsi/transport_security.cc,"@@ -213,10 +213,10 @@ tsi_result tsi_handshaker_next(  void tsi_handshaker_shutdown(tsi_handshaker* self) {   if (self == nullptr || self->vtable == nullptr) return;-  self->handshake_shutdown = true;   if (self->vtable->shutdown != nullptr) {     self->vtable->shutdown(self);   }+  self->handshake_shutdown = true;","Good point. I think the conditional statement in ALTS does not have a problem, since we want to make the successive ALTS `handshaker_shutdown` to be no-op. It then requires the wrapper API to set the flag, which I think should also happen after the shutdown action takes place. Only ALTS has a need to implement `handshaker_shutdown` API, and for all other transport securities, the operation is no-op. ",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17131,232373969,2018-11-09T19:51:00Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc,"@@ -1333,9 +1333,10 @@ void GrpcLb::ProcessChannelArgsLocked(const grpc_channel_args& args) {  void GrpcLb::UpdateLocked(const grpc_channel_args& args) {   ProcessChannelArgsLocked(args);-  // If fallback is configured and the RR policy already exists, update-  // it with the new fallback addresses.-  if (lb_fallback_timeout_ms_ > 0 && rr_policy_ != nullptr) {+  // If we are in fallback mode (i.e., we haven't received any serverlist yet,+  // but we have an RR policy), update the RR policy with the new fallback+  // addresses.+  if (serverlist_ == nullptr && rr_policy_ != nullptr) {","The resolver might have changed channel args other than the fallback addresses, so I think we do want to update the RR policy even if the serverlist is set.  The code in `CreateOrUpdateRoundRobinPolicyLocked()` will do the right thing either way.Also, if fallback mode is disabled (i.e., `lb_fallback_timeout_ms_` is 0), then we don't want to create the RR policy here.I think the code is correct as-is, without this PR.",OK
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/17131,232385446,2018-11-09T20:33:05Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc,"@@ -1333,9 +1333,10 @@ void GrpcLb::ProcessChannelArgsLocked(const grpc_channel_args& args) {  void GrpcLb::UpdateLocked(const grpc_channel_args& args) {   ProcessChannelArgsLocked(args);-  // If fallback is configured and the RR policy already exists, update-  // it with the new fallback addresses.-  if (lb_fallback_timeout_ms_ > 0 && rr_policy_ != nullptr) {+  // If we are in fallback mode (i.e., we haven't received any serverlist yet,+  // but we have an RR policy), update the RR policy with the new fallback+  // addresses.+  if (serverlist_ == nullptr && rr_policy_ != nullptr) {","Yes, the update includes more than just the fallback addresses. If fallback mode is disabled and the RR policy is created from the serverlist, we should still update the RR policy, right? So I think the right thing to do is to update the RR policy with the new channel args as long as we have an RR policy.",OK
3991732,vishalpowar,https://api.github.com/repos/grpc/grpc/pulls/17163,232426905,2018-11-10T00:00:23Z,src/core/ext/filters/client_channel/lb_policy/xds/xds.cc,"@@ -273,7 +273,7 @@ class XdsLb : public LoadBalancingPolicy {   bool PickFromRoundRobinPolicyLocked(bool force_async, PendingPick* pp,                                       grpc_error** error);   void UpdateConnectivityStateFromRoundRobinPolicyLocked(-      grpc_error* rr_state_error);+      grpc_error* state_error);","Juanli had the same comment, and i could not see a reason why.With both of you pointing out the same naming change, has convinced me to make the change. So I will.",OK
2573025,liutongxuan,https://api.github.com/repos/grpc/grpc/pulls/17154,232438296,2018-11-10T02:29:21Z,src/cpp/client/client_context.cc,"@@ -41,9 +41,10 @@ class DefaultGlobalClientCallbacks final };  static internal::GrpcLibraryInitializer g_gli_initializer;-static DefaultGlobalClientCallbacks g_default_client_callbacks;+static DefaultGlobalClientCallbacks* g_default_client_callbacks =+    new DefaultGlobalClientCallbacks();","It's not a truly leak here, g_default_client_callbacks is only initialize once, there's only one allocation of g_default_client_callbacks. Both previous solution & this one are cleaned when process exit. This solution is cleaned when process is cleaned by kernel not as global variables. For this case, this solution is not overhead and clean enough for me. Probably another solution is g_default_client_callbacks is member variable of ClientContext, then could be destroyed as ClientContext destructed. Such as follows:```ClientContext::ClientContext()    : initial_metadata_received_(false),      wait_for_ready_(false),      wait_for_ready_explicitly_set_(false),      idempotent_(false),      cacheable_(false),      call_(nullptr),      call_canceled_(false),      deadline_(gpr_inf_future(GPR_CLOCK_REALTIME)),      census_context_(nullptr),      propagate_from_call_(nullptr),      initial_metadata_corked_(false) {  if (g_client_callbacks == nullptr) {    g_client_callbacks = &default_client_callbacks;  }  g_client_callbacks->DefaultConstructor(this);}```default_client_callbacks is member variable in ClientContext.This solution would introduce 8 more bytes in ClientContext and one branch prediction is constructor in ClientContext. ",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/16987,232650467,2018-11-12T13:08:50Z,src/csharp/Grpc.Core/Grpc.Core.csproj,"@@ -8,7 +8,7 @@     <AssemblyTitle>gRPC C# Core</AssemblyTitle>     <VersionPrefix>$(GrpcCsharpVersion)</VersionPrefix>     <Authors>Google Inc.</Authors>-    <TargetFrameworks>net45;netstandard1.5</TargetFrameworks>+    <TargetFrameworks>net45;netstandard2.0</TargetFrameworks>","If someone still uses .NET core 1.x  and  Grpc.Core suddenly becomes `netstandard2.0` (i.e the `netstandard1.5` directory with the Grpc.Core.dll  assembly disappears from the nuget package and `netstandard2.0` will be add), I'm pretty sure that will break the users. You can't run 2.0 libraries on older .NET core installation. I think the article you highlighted just says that if you have a netstandard1.5 library, you can run it on .NET core 2.x which supports netstandard2.0 and it will work (which makes sense), it doesn't mean that netstandard2.0 libraries (which require more APIs) will magically work on older .NET core installations (which AFAIK is not the case).",OK
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17147,232763840,2018-11-12T18:21:51Z,src/php/ext/grpc/php_grpc.c,"@@ -86,6 +88,109 @@ ZEND_GET_MODULE(grpc)    } */ /* }}} */+void create_new_channel(+    wrapped_grpc_channel *channel,+    char *target,+    grpc_channel_args args,+    wrapped_grpc_channel_credentials *creds) {+  if (creds == NULL) {+    channel->wrapper->wrapped = grpc_insecure_channel_create(target, &args,+                                                             NULL);+  } else {+    channel->wrapper->wrapped =+        grpc_secure_channel_create(creds->wrapped, target, &args, NULL);+  }+}++void acquire_persistent_locks() {+  zval *data;+  PHP_GRPC_HASH_FOREACH_VAL_START(&grpc_persistent_list, data)+    php_grpc_zend_resource *rsrc  =+                (php_grpc_zend_resource*) PHP_GRPC_HASH_VALPTR_TO_VAL(data)+    if (rsrc == NULL) {+      break;+    }+    channel_persistent_le_t* le = rsrc->ptr;++    gpr_mu_lock(&le->channel->mu);+  PHP_GRPC_HASH_FOREACH_END()+}++void release_persistent_locks() {+  zval *data;+  PHP_GRPC_HASH_FOREACH_VAL_START(&grpc_persistent_list, data)+    php_grpc_zend_resource *rsrc  =+                (php_grpc_zend_resource*) PHP_GRPC_HASH_VALPTR_TO_VAL(data)+    if (rsrc == NULL) {+      break;+    }+    channel_persistent_le_t* le = rsrc->ptr;++    gpr_mu_unlock(&le->channel->mu);+  PHP_GRPC_HASH_FOREACH_END()+}++void prefork() {+  acquire_persistent_locks();+}++void postfork_child() {+  // loop through persistant list and destroy all underlying grpc_channel objs+  zval *data;+  PHP_GRPC_HASH_FOREACH_VAL_START(&grpc_persistent_list, data)+    php_grpc_zend_resource *rsrc  =+                (php_grpc_zend_resource*) PHP_GRPC_HASH_VALPTR_TO_VAL(data)+    if (rsrc == NULL) {+      break;+    }+    channel_persistent_le_t* le = rsrc->ptr;++    wrapped_grpc_channel wrapped_channel;+    wrapped_channel.wrapper = le->channel;+    grpc_channel_wrapper *channel = wrapped_channel.wrapper;+    grpc_channel_destroy(channel->wrapped);+  PHP_GRPC_HASH_FOREACH_END()++  // clean-up grpc_core+  grpc_shutdown();","It looks like `grpc_init()` is called in the PHP layer only once (in ext/grpc/php_grpc.c). If so, this `grpc_shutdown()` call matches that. However, it appears that all resources have not been freed at this point, so the call here does not meet the conditions stated in https://github.com/grpc/grpc/blob/master/include/grpc/grpc.h#L79, specifically ""Prior to calling, all application owned grpc objects must have been destroyed.""",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17191,232811763,2018-11-12T21:07:15Z,src/core/lib/surface/server.cc,"@@ -128,38 +132,61 @@ typedef enum { typedef struct request_matcher request_matcher;  struct call_data {+  call_data(grpc_call_element* elem, const grpc_call_element_args& args)+      : call(grpc_call_from_top_element(elem)),+        call_combiner(args.call_combiner) {+    GRPC_CLOSURE_INIT(&server_on_recv_initial_metadata,+                      ::server_on_recv_initial_metadata, elem,+                      grpc_schedule_on_exec_ctx);+    GRPC_CLOSURE_INIT(&recv_trailing_metadata_ready,+                      server_recv_trailing_metadata_ready, elem,+                      grpc_schedule_on_exec_ctx);+  }+  ~call_data() {+    GPR_ASSERT(state != PENDING);+    GRPC_ERROR_UNREF(recv_initial_metadata_error);+    if (host_set) {+      grpc_slice_unref_internal(host);+    }+    if (path_set) {+      grpc_slice_unref_internal(path);+    }+    grpc_metadata_array_destroy(&initial_metadata);+    grpc_byte_buffer_destroy(payload);+  }+   grpc_call* call; -  gpr_atm state;+  gpr_atm state = NOT_STARTED; -  bool path_set;-  bool host_set;+  bool path_set = false;+  bool host_set = false;   grpc_slice path;   grpc_slice host;-  grpc_millis deadline;+  grpc_millis deadline = GRPC_MILLIS_INF_FUTURE; -  grpc_completion_queue* cq_new;+  grpc_completion_queue* cq_new = nullptr; -  grpc_metadata_batch* recv_initial_metadata;-  uint32_t recv_initial_metadata_flags;-  grpc_metadata_array initial_metadata;+  grpc_metadata_batch* recv_initial_metadata = nullptr;+  uint32_t recv_initial_metadata_flags = 0;+  grpc_metadata_array initial_metadata = grpc_metadata_array();","This should have a comment explaining the syntax, similar to what you added in other locations in the previous PR.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17188,232816544,2018-11-12T21:23:57Z,src/core/lib/gprpp/sync.h,"@@ -0,0 +1,126 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++/* Inline implementation of synchronization primitives, preferred over the C+   public API for C++ code. */++#ifndef GRPC_CORE_LIB_GPRPP_SYNC_H+#define GRPC_CORE_LIB_GPRPP_SYNC_H++#include <grpc/support/port_platform.h>++#include <grpc/support/atm.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include <assert.h>+#include <stdint.h>+#include <atomic>+#include <type_traits>++#include ""src/core/lib/gprpp/memory.h""++namespace grpc_core {++class RefCount {+ public:+  explicit RefCount(intptr_t init = 1) : val(init) {}++  // Reinitializes the ref-count.+  void Reset(intptr_t init) { val.store(init, std::memory_order_relaxed); }++  void Ref(intptr_t n = 1) { val.fetch_add(n, std::memory_order_relaxed); }++  void RefNonZero() {+#ifndef NDEBUG+    const intptr_t prior = val.fetch_add(1, std::memory_order_relaxed);+    assert(prior > 0);+#else+    Ref();+#endif+  }++  bool RefIfNonZero() {+    intptr_t prior = val.load(std::memory_order_relaxed);+    do {+      if (prior == 0) return false;+    } while (!val.compare_exchange_weak(prior, prior + 1,+                                        std::memory_order_release,+                                        std::memory_order_relaxed));+    return true;+  }++  // Returns whether there is only one reference tracked in this refcount.+  bool IsUnique() const { return val.load(std::memory_order_acquire); }++  bool Unref() {+    const intptr_t prior = val.fetch_sub(1, std::memory_order_acq_rel);+    GPR_DEBUG_ASSERT(prior > 0);+    return prior == 1;+  }++  intptr_t get() const { return val.load(std::memory_order_relaxed); }++ private:+  std::atomic<intptr_t> val;","Does `std::atomic<>` introduce any link-time dependencies on the C++ standard library?  It's okay if it's a header-only use, but we currently can't support using anything that requires linking against the C++ standard library.Alternatively, consider using our existing `gpr_atm` API:https://github.com/grpc/grpc/blob/master/include/grpc/impl/codegen/atm.h",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17188,232818876,2018-11-12T21:31:49Z,src/core/lib/gprpp/sync.h,"@@ -0,0 +1,126 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++/* Inline implementation of synchronization primitives, preferred over the C+   public API for C++ code. */++#ifndef GRPC_CORE_LIB_GPRPP_SYNC_H+#define GRPC_CORE_LIB_GPRPP_SYNC_H++#include <grpc/support/port_platform.h>++#include <grpc/support/atm.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include <assert.h>+#include <stdint.h>+#include <atomic>+#include <type_traits>++#include ""src/core/lib/gprpp/memory.h""++namespace grpc_core {++class RefCount {","This could use a long comment explaining the intended usage, with some detailed examples.In particular, I would like to understand why this is necessary, given that we already have a `RefCounted` class:https://github.com/grpc/grpc/blob/master/src/core/lib/gprpp/ref_counted.h",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17188,232820393,2018-11-12T21:37:19Z,src/core/lib/gprpp/sync.h,"@@ -0,0 +1,126 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++/* Inline implementation of synchronization primitives, preferred over the C+   public API for C++ code. */++#ifndef GRPC_CORE_LIB_GPRPP_SYNC_H+#define GRPC_CORE_LIB_GPRPP_SYNC_H++#include <grpc/support/port_platform.h>++#include <grpc/support/atm.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include <assert.h>+#include <stdint.h>+#include <atomic>+#include <type_traits>++#include ""src/core/lib/gprpp/memory.h""++namespace grpc_core {++class RefCount {+ public:+  explicit RefCount(intptr_t init = 1) : val(init) {}++  // Reinitializes the ref-count.+  void Reset(intptr_t init) { val.store(init, std::memory_order_relaxed); }++  void Ref(intptr_t n = 1) { val.fetch_add(n, std::memory_order_relaxed); }++  void RefNonZero() {+#ifndef NDEBUG+    const intptr_t prior = val.fetch_add(1, std::memory_order_relaxed);+    assert(prior > 0);+#else+    Ref();+#endif+  }++  bool RefIfNonZero() {+    intptr_t prior = val.load(std::memory_order_relaxed);+    do {+      if (prior == 0) return false;+    } while (!val.compare_exchange_weak(prior, prior + 1,+                                        std::memory_order_release,+                                        std::memory_order_relaxed));+    return true;+  }++  // Returns whether there is only one reference tracked in this refcount.+  bool IsUnique() const { return val.load(std::memory_order_acquire); }++  bool Unref() {+    const intptr_t prior = val.fetch_sub(1, std::memory_order_acq_rel);+    GPR_DEBUG_ASSERT(prior > 0);+    return prior == 1;+  }++  intptr_t get() const { return val.load(std::memory_order_relaxed); }++ private:+  std::atomic<intptr_t> val;+};++template <typename Child, typename Delete = grpc_core::DefaultDelete<Child>>+class IntrusivelyRefCounted {","This could also use a long comment explaining the intended use-cases, along with examples.It looks like the main difference between this and `RefCount` is that this deletes itself when the refcount goes to zero.  So doesn't this basically do the same thing as our existing `RefCounted` class?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17188,232821246,2018-11-12T21:40:43Z,src/core/lib/iomgr/resource_quota.cc,"@@ -121,26 +123,45 @@ struct grpc_resource_user {   char* name; }; -struct grpc_resource_quota {-  /* refcount */-  gpr_refcount refs;+static void rq_step(void* rq, grpc_error* error);+static void rq_reclamation_done(void* rq, grpc_error* error);++struct grpc_resource_quota : grpc_core::IntrusivelyRefCounted<grpc_resource_quota> {","If we're going to C++-ify this, let's do it all the way: make it a class, convert the standalone functions into methods, use C++ naming conventions, etc.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17188,232821645,2018-11-12T21:41:59Z,src/core/lib/iomgr/resource_quota.cc,"@@ -121,26 +123,45 @@ struct grpc_resource_user {   char* name; }; -struct grpc_resource_quota {-  /* refcount */-  gpr_refcount refs;+static void rq_step(void* rq, grpc_error* error);+static void rq_reclamation_done(void* rq, grpc_error* error);++struct grpc_resource_quota : grpc_core::IntrusivelyRefCounted<grpc_resource_quota> {","All inheritance should be `public`, as per:https://google.github.io/styleguide/cppguide.html#Inheritance",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17188,232822528,2018-11-12T21:44:34Z,src/core/lib/iomgr/resource_quota.cc,"@@ -430,39 +451,53 @@ static bool rq_reclaim(grpc_resource_quota* resource_quota, bool destructive) {  * ru_slice: a slice implementation that is backed by a grpc_resource_user  */ -typedef struct {+static void ru_slice_ref(void* p);+static void ru_slice_unref(void* p);+static const grpc_slice_refcount_vtable ru_slice_vtable = {+    ru_slice_ref, ru_slice_unref, grpc_slice_default_eq_impl,+    grpc_slice_default_hash_impl};++namespace {+struct ru_slice_refcount {","Can this just use our existing `RefCounted` implementation?I would understand if there are some problems here, since the slice refcounting API is C style.  But it's worth trying to avoid the duplicate refcounting code if possible.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/17144,232884372,2018-11-13T03:10:25Z,test/cpp/end2end/test_service_impl.cc,"@@ -464,44 +526,247 @@ Status TestServiceImpl::BidiStream(   return Status::OK; } -namespace {-int GetIntValueFromMetadataHelper(-    const char* key,-    const std::multimap<grpc::string_ref, grpc::string_ref>& metadata,-    int default_value) {-  if (metadata.find(key) != metadata.end()) {-    std::istringstream iss(ToString(metadata.find(key)->second));-    iss >> default_value;-    gpr_log(GPR_INFO, ""%s : %d"", key, default_value);-  }+void CallbackTestServiceImpl::RequestStream(","Right, which leads to hideousness like RequestRequestStream in the CQ-based api.",OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17191,232891661,2018-11-13T04:06:46Z,src/core/lib/surface/server.cc,"@@ -128,38 +132,61 @@ typedef enum { typedef struct request_matcher request_matcher;  struct call_data {+  call_data(grpc_call_element* elem, const grpc_call_element_args& args)+      : call(grpc_call_from_top_element(elem)),+        call_combiner(args.call_combiner) {+    GRPC_CLOSURE_INIT(&server_on_recv_initial_metadata,+                      ::server_on_recv_initial_metadata, elem,+                      grpc_schedule_on_exec_ctx);+    GRPC_CLOSURE_INIT(&recv_trailing_metadata_ready,+                      server_recv_trailing_metadata_ready, elem,+                      grpc_schedule_on_exec_ctx);+  }+  ~call_data() {+    GPR_ASSERT(state != PENDING);+    GRPC_ERROR_UNREF(recv_initial_metadata_error);+    if (host_set) {+      grpc_slice_unref_internal(host);+    }+    if (path_set) {+      grpc_slice_unref_internal(path);+    }+    grpc_metadata_array_destroy(&initial_metadata);+    grpc_byte_buffer_destroy(payload);+  }+   grpc_call* call; -  gpr_atm state;+  gpr_atm state = NOT_STARTED; -  bool path_set;-  bool host_set;+  bool path_set = false;+  bool host_set = false;   grpc_slice path;   grpc_slice host;-  grpc_millis deadline;+  grpc_millis deadline = GRPC_MILLIS_INF_FUTURE; -  grpc_completion_queue* cq_new;+  grpc_completion_queue* cq_new = nullptr; -  grpc_metadata_batch* recv_initial_metadata;-  uint32_t recv_initial_metadata_flags;-  grpc_metadata_array initial_metadata;+  grpc_metadata_batch* recv_initial_metadata = nullptr;+  uint32_t recv_initial_metadata_flags = 0;+  grpc_metadata_array initial_metadata = grpc_metadata_array();",Thank you. I added a similar comment for C-struct initialization.,
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17188,232901091,2018-11-13T05:26:04Z,src/core/lib/gprpp/sync.h,"@@ -0,0 +1,126 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++/* Inline implementation of synchronization primitives, preferred over the C+   public API for C++ code. */++#ifndef GRPC_CORE_LIB_GPRPP_SYNC_H+#define GRPC_CORE_LIB_GPRPP_SYNC_H++#include <grpc/support/port_platform.h>++#include <grpc/support/atm.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include <assert.h>+#include <stdint.h>+#include <atomic>+#include <type_traits>++#include ""src/core/lib/gprpp/memory.h""++namespace grpc_core {++class RefCount {+ public:+  explicit RefCount(intptr_t init = 1) : val(init) {}++  // Reinitializes the ref-count.+  void Reset(intptr_t init) { val.store(init, std::memory_order_relaxed); }++  void Ref(intptr_t n = 1) { val.fetch_add(n, std::memory_order_relaxed); }++  void RefNonZero() {+#ifndef NDEBUG+    const intptr_t prior = val.fetch_add(1, std::memory_order_relaxed);+    assert(prior > 0);+#else+    Ref();+#endif+  }++  bool RefIfNonZero() {+    intptr_t prior = val.load(std::memory_order_relaxed);+    do {+      if (prior == 0) return false;+    } while (!val.compare_exchange_weak(prior, prior + 1,+                                        std::memory_order_release,+                                        std::memory_order_relaxed));+    return true;+  }++  // Returns whether there is only one reference tracked in this refcount.+  bool IsUnique() const { return val.load(std::memory_order_acquire); }++  bool Unref() {+    const intptr_t prior = val.fetch_sub(1, std::memory_order_acq_rel);+    GPR_DEBUG_ASSERT(prior > 0);+    return prior == 1;+  }++  intptr_t get() const { return val.load(std::memory_order_relaxed); }++ private:+  std::atomic<intptr_t> val;+};++template <typename Child, typename Delete = grpc_core::DefaultDelete<Child>>+class IntrusivelyRefCounted {",Thank you for the pointer. I removed this class. We cannot always use `RefCounted` because it's a virtual base class and would add complications for PODs. I gave up on this class and will use RefCount directly,OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17188,232901161,2018-11-13T05:26:32Z,src/core/lib/gprpp/sync.h,"@@ -0,0 +1,126 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++/* Inline implementation of synchronization primitives, preferred over the C+   public API for C++ code. */++#ifndef GRPC_CORE_LIB_GPRPP_SYNC_H+#define GRPC_CORE_LIB_GPRPP_SYNC_H++#include <grpc/support/port_platform.h>++#include <grpc/support/atm.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include <assert.h>+#include <stdint.h>+#include <atomic>+#include <type_traits>++#include ""src/core/lib/gprpp/memory.h""++namespace grpc_core {++class RefCount {+ public:+  explicit RefCount(intptr_t init = 1) : val(init) {}++  // Reinitializes the ref-count.+  void Reset(intptr_t init) { val.store(init, std::memory_order_relaxed); }++  void Ref(intptr_t n = 1) { val.fetch_add(n, std::memory_order_relaxed); }++  void RefNonZero() {+#ifndef NDEBUG+    const intptr_t prior = val.fetch_add(1, std::memory_order_relaxed);+    assert(prior > 0);+#else+    Ref();+#endif+  }++  bool RefIfNonZero() {+    intptr_t prior = val.load(std::memory_order_relaxed);+    do {+      if (prior == 0) return false;+    } while (!val.compare_exchange_weak(prior, prior + 1,+                                        std::memory_order_release,+                                        std::memory_order_relaxed));+    return true;+  }++  // Returns whether there is only one reference tracked in this refcount.+  bool IsUnique() const { return val.load(std::memory_order_acquire); }++  bool Unref() {+    const intptr_t prior = val.fetch_sub(1, std::memory_order_acq_rel);+    GPR_DEBUG_ASSERT(prior > 0);+    return prior == 1;+  }++  intptr_t get() const { return val.load(std::memory_order_relaxed); }++ private:+  std::atomic<intptr_t> val;","oops. yes, thanks. I changed struct to class and forgot to do add trailing underscore.",
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17188,232901541,2018-11-13T05:29:12Z,src/core/lib/gprpp/sync.h,"@@ -0,0 +1,126 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++/* Inline implementation of synchronization primitives, preferred over the C+   public API for C++ code. */++#ifndef GRPC_CORE_LIB_GPRPP_SYNC_H+#define GRPC_CORE_LIB_GPRPP_SYNC_H++#include <grpc/support/port_platform.h>++#include <grpc/support/atm.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include <assert.h>+#include <stdint.h>+#include <atomic>+#include <type_traits>++#include ""src/core/lib/gprpp/memory.h""++namespace grpc_core {++class RefCount {+ public:+  explicit RefCount(intptr_t init = 1) : val(init) {}++  // Reinitializes the ref-count.+  void Reset(intptr_t init) { val.store(init, std::memory_order_relaxed); }++  void Ref(intptr_t n = 1) { val.fetch_add(n, std::memory_order_relaxed); }++  void RefNonZero() {+#ifndef NDEBUG+    const intptr_t prior = val.fetch_add(1, std::memory_order_relaxed);+    assert(prior > 0);+#else+    Ref();+#endif+  }++  bool RefIfNonZero() {",Sorry if these are not clear. The code was copy/pasted from a larger WIP PR. This is the main user of this method:https://github.com/grpc/grpc/blob/master/src/core/ext/transport/chttp2/transport/writing.cc#L165The implementation here is actually 3x faster due to only have one locked atomic op. :-),OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17188,232901736,2018-11-13T05:30:49Z,src/core/lib/gprpp/sync.h,"@@ -0,0 +1,126 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++/* Inline implementation of synchronization primitives, preferred over the C+   public API for C++ code. */++#ifndef GRPC_CORE_LIB_GPRPP_SYNC_H+#define GRPC_CORE_LIB_GPRPP_SYNC_H++#include <grpc/support/port_platform.h>++#include <grpc/support/atm.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include <assert.h>+#include <stdint.h>+#include <atomic>+#include <type_traits>++#include ""src/core/lib/gprpp/memory.h""++namespace grpc_core {++class RefCount {+ public:+  explicit RefCount(intptr_t init = 1) : val(init) {}++  // Reinitializes the ref-count.+  void Reset(intptr_t init) { val.store(init, std::memory_order_relaxed); }",Here is the main user:https://github.com/grpc/grpc/blob/b41a44dc2e001358602e8e885c674ddc49387edd/src/core/lib/surface/call.cc#L1851,
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17188,232901882,2018-11-13T05:31:50Z,src/core/lib/gprpp/sync.h,"@@ -0,0 +1,126 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++/* Inline implementation of synchronization primitives, preferred over the C+   public API for C++ code. */++#ifndef GRPC_CORE_LIB_GPRPP_SYNC_H+#define GRPC_CORE_LIB_GPRPP_SYNC_H++#include <grpc/support/port_platform.h>++#include <grpc/support/atm.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include <assert.h>+#include <stdint.h>+#include <atomic>+#include <type_traits>++#include ""src/core/lib/gprpp/memory.h""++namespace grpc_core {++class RefCount {","Thank you for the pointer. `RefCount` is a direct replacement for gpr_refcount, with a significantly better performance and binary size.I removed the `IntrusivelyRefCounted` class because it's a can of worms.",OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17188,232902188,2018-11-13T05:33:34Z,src/core/lib/gprpp/sync.h,"@@ -0,0 +1,126 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++/* Inline implementation of synchronization primitives, preferred over the C+   public API for C++ code. */++#ifndef GRPC_CORE_LIB_GPRPP_SYNC_H+#define GRPC_CORE_LIB_GPRPP_SYNC_H++#include <grpc/support/port_platform.h>++#include <grpc/support/atm.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include <assert.h>+#include <stdint.h>+#include <atomic>+#include <type_traits>++#include ""src/core/lib/gprpp/memory.h""++namespace grpc_core {++class RefCount {+ public:+  explicit RefCount(intptr_t init = 1) : val(init) {}++  // Reinitializes the ref-count.+  void Reset(intptr_t init) { val.store(init, std::memory_order_relaxed); }++  void Ref(intptr_t n = 1) { val.fetch_add(n, std::memory_order_relaxed); }++  void RefNonZero() {+#ifndef NDEBUG+    const intptr_t prior = val.fetch_add(1, std::memory_order_relaxed);+    assert(prior > 0);+#else+    Ref();+#endif+  }++  bool RefIfNonZero() {+    intptr_t prior = val.load(std::memory_order_relaxed);+    do {+      if (prior == 0) return false;+    } while (!val.compare_exchange_weak(prior, prior + 1,+                                        std::memory_order_release,+                                        std::memory_order_relaxed));+    return true;+  }++  // Returns whether there is only one reference tracked in this refcount.+  bool IsUnique() const { return val.load(std::memory_order_acquire); }++  bool Unref() {+    const intptr_t prior = val.fetch_sub(1, std::memory_order_acq_rel);+    GPR_DEBUG_ASSERT(prior > 0);+    return prior == 1;+  }++  intptr_t get() const { return val.load(std::memory_order_relaxed); }++ private:+  std::atomic<intptr_t> val;+};++template <typename Child, typename Delete = grpc_core::DefaultDelete<Child>>+class IntrusivelyRefCounted {+ public:+  explicit IntrusivelyRefCounted(intptr_t init = 1) : refs(init) {}++  void ResetRefCount(intptr_t init) { refs.Reset(init); }++  void Ref(intptr_t n = 1) { refs.Ref(n); }++  void RefNonZero() { refs.RefNonZero(); }++  bool RefIfNonZero() { return refs.RefIfNonZero(); }++  // Returns whether there is only one reference tracked in this refcount.+  bool RefCountIsUnique() const { return refs.IsUnique(); }++  bool Unref() {+    if (!refs.Unref()) return false;+    Delete()(static_cast<Child*>(this));+    return true;+  }++  intptr_t ref_count() const { return refs.get(); }++ private:+  RefCount refs;",My bad. This class is removed now.,OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17188,232902215,2018-11-13T05:33:44Z,src/core/lib/gprpp/sync.h,"@@ -0,0 +1,126 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++/* Inline implementation of synchronization primitives, preferred over the C+   public API for C++ code. */++#ifndef GRPC_CORE_LIB_GPRPP_SYNC_H+#define GRPC_CORE_LIB_GPRPP_SYNC_H++#include <grpc/support/port_platform.h>++#include <grpc/support/atm.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include <assert.h>+#include <stdint.h>+#include <atomic>+#include <type_traits>++#include ""src/core/lib/gprpp/memory.h""++namespace grpc_core {++class RefCount {+ public:+  explicit RefCount(intptr_t init = 1) : val(init) {}++  // Reinitializes the ref-count.+  void Reset(intptr_t init) { val.store(init, std::memory_order_relaxed); }++  void Ref(intptr_t n = 1) { val.fetch_add(n, std::memory_order_relaxed); }++  void RefNonZero() {+#ifndef NDEBUG+    const intptr_t prior = val.fetch_add(1, std::memory_order_relaxed);+    assert(prior > 0);+#else+    Ref();+#endif+  }++  bool RefIfNonZero() {+    intptr_t prior = val.load(std::memory_order_relaxed);+    do {+      if (prior == 0) return false;+    } while (!val.compare_exchange_weak(prior, prior + 1,+                                        std::memory_order_release,+                                        std::memory_order_relaxed));+    return true;+  }++  // Returns whether there is only one reference tracked in this refcount.+  bool IsUnique() const { return val.load(std::memory_order_acquire); }++  bool Unref() {+    const intptr_t prior = val.fetch_sub(1, std::memory_order_acq_rel);+    GPR_DEBUG_ASSERT(prior > 0);+    return prior == 1;+  }++  intptr_t get() const { return val.load(std::memory_order_relaxed); }++ private:+  std::atomic<intptr_t> val;+};++template <typename Child, typename Delete = grpc_core::DefaultDelete<Child>>+class IntrusivelyRefCounted {+ public:+  explicit IntrusivelyRefCounted(intptr_t init = 1) : refs(init) {}++  void ResetRefCount(intptr_t init) { refs.Reset(init); }++  void Ref(intptr_t n = 1) { refs.Ref(n); }++  void RefNonZero() { refs.RefNonZero(); }++  bool RefIfNonZero() { return refs.RefIfNonZero(); }++  // Returns whether there is only one reference tracked in this refcount.+  bool RefCountIsUnique() const { return refs.IsUnique(); }++  bool Unref() {+    if (!refs.Unref()) return false;+    Delete()(static_cast<Child*>(this));+    return true;+  }++  intptr_t ref_count() const { return refs.get(); }++ private:+  RefCount refs;+};++inline void StatsInit(gpr_stats_counter* c, intptr_t n) {","Yes, these are from the larger PR. I removed them.",
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17188,232902726,2018-11-13T05:36:27Z,src/core/lib/iomgr/resource_quota.cc,"@@ -121,26 +123,45 @@ struct grpc_resource_user {   char* name; }; -struct grpc_resource_quota {-  /* refcount */-  gpr_refcount refs;+static void rq_step(void* rq, grpc_error* error);+static void rq_reclamation_done(void* rq, grpc_error* error);++struct grpc_resource_quota : grpc_core::IntrusivelyRefCounted<grpc_resource_quota> {","Yes, sure. The base class is now removed.",
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17188,232902926,2018-11-13T05:37:54Z,src/core/lib/iomgr/resource_quota.cc,"@@ -121,26 +123,45 @@ struct grpc_resource_user {   char* name; }; -struct grpc_resource_quota {-  /* refcount */-  gpr_refcount refs;+static void rq_step(void* rq, grpc_error* error);+static void rq_reclamation_done(void* rq, grpc_error* error);++struct grpc_resource_quota : grpc_core::IntrusivelyRefCounted<grpc_resource_quota> {","I removed `grpc_core::IntrusivelyRefCounted`. This CL is just a demo of a much larger change that replaces `gpr_refcount` with a C++ class that is significantly more efficient. If you look at the original intent, there are 66 files changed in basically all modules:https://github.com/grpc/grpc/pull/17124/filesJust to use this class I have to convert all of the structs in the 66 files to C++ classes with ctor/dtor similar to memset(0). Full C++ification would be great, but as separate clean up CLs IMHO.",
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17188,232903351,2018-11-13T05:40:52Z,src/core/lib/iomgr/resource_quota.cc,"@@ -121,26 +123,45 @@ struct grpc_resource_user {   char* name; }; -struct grpc_resource_quota {-  /* refcount */-  gpr_refcount refs;+static void rq_step(void* rq, grpc_error* error);+static void rq_reclamation_done(void* rq, grpc_error* error);++struct grpc_resource_quota : grpc_core::IntrusivelyRefCounted<grpc_resource_quota> {","`RefCounted` uses `gpr_refcount` with the same performance problems, and it also adds a vtable. So, that would be a non-trivial changes for the POD classes. For this performance enhancing patch, my intent is to replace gpr_refcount with a faster C++ grpc_core::RefCount.",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/17167,232915073,2018-11-13T06:54:25Z,src/csharp/Grpc.Core/Marshaller.cs,"@@ -57,10 +59,10 @@ public Marshaller(Action<T, SerializationContext> serializer, Func<Deserializati         {             this.contextualSerializer = GrpcPreconditions.CheckNotNull(serializer, nameof(serializer));             this.contextualDeserializer = GrpcPreconditions.CheckNotNull(deserializer, nameof(deserializer));-            // TODO(jtattermusch): once gRPC C# library switches to using contextual (de)serializer,-            // emulating the simple (de)serializer will become unnecessary.-            this.serializer = EmulateSimpleSerializer;-            this.deserializer = EmulateSimpleDeserializer;+            // gRPC only uses contextual serializer/deserializer internally, so emulating the legacy+            // (de)serializer is not necessary.+            this.serializer = (msg) => { throw new NotImplementedException(); };","can we just get rid of the `serializer` and `deserializer` fields entirely, since they are no longer used now?",OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17188,233074654,2018-11-13T15:05:51Z,src/core/lib/iomgr/resource_quota.cc,"@@ -430,39 +451,53 @@ static bool rq_reclaim(grpc_resource_quota* resource_quota, bool destructive) {  * ru_slice: a slice implementation that is backed by a grpc_resource_user  */ -typedef struct {+static void ru_slice_ref(void* p);+static void ru_slice_unref(void* p);+static const grpc_slice_refcount_vtable ru_slice_vtable = {+    ru_slice_ref, ru_slice_unref, grpc_slice_default_eq_impl,+    grpc_slice_default_hash_impl};++namespace {+struct ru_slice_refcount {","Sorry I missed this one I think. There are many of such structs in the code. The problem is many of these structs have to be castable to their base, so if we wanted to add a refcounted base class we would need multiple inheritance, which doesn't feel right.This is somewhat similar to your comment here, which I found while replacing `gpr_refcount` with `grpc_core::RefCount`:https://github.com/grpc/grpc/blob/618a3f561d4a93f263cca23abad086ed8f4d5e86/src/core/ext/transport/chttp2/transport/internal.h#L222The case here is even worse due to the ""base"" in this structure.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17188,233140123,2018-11-13T17:13:54Z,src/core/lib/gprpp/sync.h,"@@ -0,0 +1,126 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++/* Inline implementation of synchronization primitives, preferred over the C+   public API for C++ code. */++#ifndef GRPC_CORE_LIB_GPRPP_SYNC_H+#define GRPC_CORE_LIB_GPRPP_SYNC_H++#include <grpc/support/port_platform.h>++#include <grpc/support/atm.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include <assert.h>+#include <stdint.h>+#include <atomic>+#include <type_traits>++#include ""src/core/lib/gprpp/memory.h""++namespace grpc_core {++class RefCount {+ public:+  explicit RefCount(intptr_t init = 1) : val(init) {}++  // Reinitializes the ref-count.+  void Reset(intptr_t init) { val.store(init, std::memory_order_relaxed); }","If that's the main use-case, is there a way we could restructure the code there such that we can just instantiate a new `RefCount` whenever we start a batch?  For example, when we re-use an existing `batch_control` struct, we can use placement-new to instantiate it, and then call its dtor when it gets unreffed.  Then maybe we can change `call_start_batch()` to do two passes over the passed-in ops, so that we know how many refs we need before we instantiate the `batch_control` struct.  Or, if that two-pass approach is too expensive, maybe we can instead use `grpc_core::ManualConstructor<>`, so that we can instantiate the `RefCount` after the `batch_control` is already instantiated.If there is no alternative that doesn't come with performance penalties, I can live with this.  But having an explicit reset method feels fairly ugly to me from an API perspective, since the only time it should ever be used is when the previous refcount has already gone to zero and we are now re-using the same object.  So I'd prefer to avoid it if possible.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17188,233142104,2018-11-13T17:19:09Z,src/core/lib/gprpp/sync.h,"@@ -0,0 +1,126 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++/* Inline implementation of synchronization primitives, preferred over the C+   public API for C++ code. */++#ifndef GRPC_CORE_LIB_GPRPP_SYNC_H+#define GRPC_CORE_LIB_GPRPP_SYNC_H++#include <grpc/support/port_platform.h>++#include <grpc/support/atm.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include <assert.h>+#include <stdint.h>+#include <atomic>+#include <type_traits>++#include ""src/core/lib/gprpp/memory.h""++namespace grpc_core {++class RefCount {+ public:+  explicit RefCount(intptr_t init = 1) : val(init) {}++  // Reinitializes the ref-count.+  void Reset(intptr_t init) { val.store(init, std::memory_order_relaxed); }++  void Ref(intptr_t n = 1) { val.fetch_add(n, std::memory_order_relaxed); }++  void RefNonZero() {+#ifndef NDEBUG+    const intptr_t prior = val.fetch_add(1, std::memory_order_relaxed);+    assert(prior > 0);+#else+    Ref();+#endif+  }++  bool RefIfNonZero() {+    intptr_t prior = val.load(std::memory_order_relaxed);+    do {+      if (prior == 0) return false;+    } while (!val.compare_exchange_weak(prior, prior + 1,+                                        std::memory_order_release,+                                        std::memory_order_relaxed));+    return true;+  }++  // Returns whether there is only one reference tracked in this refcount.+  bool IsUnique() const { return val.load(std::memory_order_acquire); }++  bool Unref() {+    const intptr_t prior = val.fetch_sub(1, std::memory_order_acq_rel);+    GPR_DEBUG_ASSERT(prior > 0);+    return prior == 1;+  }++  intptr_t get() const { return val.load(std::memory_order_relaxed); }++ private:+  std::atomic<intptr_t> val;+};++template <typename Child, typename Delete = grpc_core::DefaultDelete<Child>>+class IntrusivelyRefCounted {","Can you say more about what the complications are here?I would really prefer to use `RefCounted` as much as possible.  One of our goals of that API is to avoid manual ref-counting whenever possible; instead, we want to use `RefCountedPtr<>` and have the compiler enforce the ref-counting.  (This is related to the discussion we had separately about wanting to get the `ClosureRef` change in, so that we can start passing refs along with closures.)  If we instead directly use `RefCount`, then we're not really any better off in that regard than we are with the current `gpr_refcount` API.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17188,233144334,2018-11-13T17:24:52Z,src/core/lib/gprpp/ref_counted.h,"@@ -34,6 +36,63 @@  namespace grpc_core { +// RefCount is a simple atomic ref-count.+//+// This is a C++ implementation of gpr_refcount, with inline functions. Due to+// inline functions, this class is significantly more efficient than+// gpr_refcount and hence is a major performance win.+//+// TODO(soheil): Remove gpr_refcount after submitting the GRFC and the paragraph+//               above.+class RefCount {+ public:+  // `init` is the initial refcount stored in this object.+  explicit RefCount(intptr_t init = 1) : val_(init) {}++  // Reinitializes the ref-count.+  void Reset(intptr_t init) { val_.store(init, std::memory_order_relaxed); }++  // Increases the ref-count by `n`.+  void Ref(intptr_t n = 1) { val_.fetch_add(n, std::memory_order_relaxed); }++  // Similar to Ref() with an assert on the ref-count being non-zero.+  void RefNonZero() {+#ifndef NDEBUG+    const intptr_t prior = val_.fetch_add(1, std::memory_order_relaxed);+    assert(prior > 0);+#else+    Ref();+#endif+  }++  // Increments the ref-count only if the ref-count is not 0.+  bool RefIfNonZero() {+    intptr_t prior = val_.load(std::memory_order_relaxed);+    do {+      if (prior == 0) return false;+    } while (!val_.compare_exchange_weak(prior, prior + 1,+                                        std::memory_order_release,+                                        std::memory_order_relaxed));+    return true;+  }++  // Returns whether there is only one reference tracked in this refcount.+  bool IsUnique() const { return val_.load(std::memory_order_acquire); }++  // Decrements the ref-count and returns true if the ref-count reaches 0.+  bool Unref() {+    const intptr_t prior = val_.fetch_sub(1, std::memory_order_acq_rel);+    GPR_DEBUG_ASSERT(prior > 0);+    return prior == 1;+  }++  // Returns the current value of the ref-count without any ordering guarantees.+  intptr_t get() const { return val_.load(std::memory_order_relaxed); }","This probably shouldn't be a public method.  It looks like the main use-case is `RefCountedWithTracing` below.  How about simply making that class a friend of this?Might need to do the same thing for `InternallyRefCountedWithTracing`, which is defined in orphanable.h.",OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17188,233153702,2018-11-13T17:47:58Z,src/core/lib/gprpp/sync.h,"@@ -0,0 +1,126 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++/* Inline implementation of synchronization primitives, preferred over the C+   public API for C++ code. */++#ifndef GRPC_CORE_LIB_GPRPP_SYNC_H+#define GRPC_CORE_LIB_GPRPP_SYNC_H++#include <grpc/support/port_platform.h>++#include <grpc/support/atm.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>++#include <assert.h>+#include <stdint.h>+#include <atomic>+#include <type_traits>++#include ""src/core/lib/gprpp/memory.h""++namespace grpc_core {++class RefCount {+ public:+  explicit RefCount(intptr_t init = 1) : val(init) {}++  // Reinitializes the ref-count.+  void Reset(intptr_t init) { val.store(init, std::memory_order_relaxed); }++  void Ref(intptr_t n = 1) { val.fetch_add(n, std::memory_order_relaxed); }++  void RefNonZero() {+#ifndef NDEBUG+    const intptr_t prior = val.fetch_add(1, std::memory_order_relaxed);+    assert(prior > 0);+#else+    Ref();+#endif+  }++  bool RefIfNonZero() {+    intptr_t prior = val.load(std::memory_order_relaxed);+    do {+      if (prior == 0) return false;+    } while (!val.compare_exchange_weak(prior, prior + 1,+                                        std::memory_order_release,+                                        std::memory_order_relaxed));+    return true;+  }++  // Returns whether there is only one reference tracked in this refcount.+  bool IsUnique() const { return val.load(std::memory_order_acquire); }++  bool Unref() {+    const intptr_t prior = val.fetch_sub(1, std::memory_order_acq_rel);+    GPR_DEBUG_ASSERT(prior > 0);+    return prior == 1;+  }++  intptr_t get() const { return val.load(std::memory_order_relaxed); }++ private:+  std::atomic<intptr_t> val;+};++template <typename Child, typename Delete = grpc_core::DefaultDelete<Child>>+class IntrusivelyRefCounted {","Yes, I'd definitely agree that the API is identical and no better than `gpr_refcount`. But, in terms of performance and adding the ctor/dtor, it'd be a step in the right direction IMO.The complication of RefCountedPtr is virtual base class which can hurt performance, where we don't need polymorphism, as we discussed offline.",
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17188,233158143,2018-11-13T17:59:56Z,src/core/lib/gprpp/ref_counted.h,"@@ -34,6 +36,63 @@  namespace grpc_core { +// RefCount is a simple atomic ref-count.+//+// This is a C++ implementation of gpr_refcount, with inline functions. Due to+// inline functions, this class is significantly more efficient than+// gpr_refcount and hence is a major performance win.+//+// TODO(soheil): Remove gpr_refcount after submitting the GRFC and the paragraph+//               above.+class RefCount {+ public:+  // `init` is the initial refcount stored in this object.+  explicit RefCount(intptr_t init = 1) : val_(init) {}++  // Reinitializes the ref-count.+  void Reset(intptr_t init) { val_.store(init, std::memory_order_relaxed); }++  // Increases the ref-count by `n`.+  void Ref(intptr_t n = 1) { val_.fetch_add(n, std::memory_order_relaxed); }++  // Similar to Ref() with an assert on the ref-count being non-zero.+  void RefNonZero() {+#ifndef NDEBUG+    const intptr_t prior = val_.fetch_add(1, std::memory_order_relaxed);+    assert(prior > 0);+#else+    Ref();+#endif+  }++  // Increments the ref-count only if the ref-count is not 0.+  bool RefIfNonZero() {+    intptr_t prior = val_.load(std::memory_order_relaxed);+    do {+      if (prior == 0) return false;+    } while (!val_.compare_exchange_weak(prior, prior + 1,+                                        std::memory_order_release,+                                        std::memory_order_relaxed));+    return true;+  }++  // Returns whether there is only one reference tracked in this refcount.+  bool IsUnique() const { return val_.load(std::memory_order_acquire); }++  // Decrements the ref-count and returns true if the ref-count reaches 0.+  bool Unref() {+    const intptr_t prior = val_.fetch_sub(1, std::memory_order_acq_rel);+    GPR_DEBUG_ASSERT(prior > 0);+    return prior == 1;+  }++  // Returns the current value of the ref-count without any ordering guarantees.+  intptr_t get() const { return val_.load(std::memory_order_relaxed); }","Yes, this is mostly for debug tracing. I can add ""RefWithTracing"" and ""UnrefWithTracing"" in place of this, similar to what you have in InternallyRefCountedWithTracing. Would that be reasonable?",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/17104,233185516,2018-11-13T19:16:26Z,include/grpcpp/impl/codegen/client_callback.h,"@@ -88,6 +89,510 @@ class CallbackUnaryCallImpl {     call.PerformOps(ops);   } };+}  // namespace internal++namespace experimental {++// The user must implement this reactor interface with reactions to each event+// type that gets called by the library. An empty reaction is provided by+// default+",do we add a blank line between the comment and the class?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17205,233245764,2018-11-13T22:22:25Z,src/core/lib/gprpp/ref_counted_ptr.h,"@@ -74,6 +75,8 @@ class RefCountedPtr {   }   template <typename Y>   RefCountedPtr(const RefCountedPtr<Y>& other) {+    static_assert(std::has_virtual_destructor<T>::value,",I assume that use of `std::has_virtual_destructor<>` is a header-only use of the C++ standard library?,
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/17144,233255282,2018-11-13T22:56:30Z,test/cpp/end2end/test_service_impl.cc,"@@ -464,44 +526,247 @@ Status TestServiceImpl::BidiStream(   return Status::OK; } -namespace {-int GetIntValueFromMetadataHelper(-    const char* key,-    const std::multimap<grpc::string_ref, grpc::string_ref>& metadata,-    int default_value) {-  if (metadata.find(key) != metadata.end()) {-    std::istringstream iss(ToString(metadata.find(key)->second));-    iss >> default_value;-    gpr_log(GPR_INFO, ""%s : %d"", key, default_value);-  }+void CallbackTestServiceImpl::RequestStream(+    ServerContext* context, EchoResponse* response,+    experimental::ServerCallbackReader<EchoRequest>* reader) {+  class Reactor : public ::grpc::experimental::ServerReadReactor {+   public:+    Reactor(ServerContext* context,+            experimental::ServerCallbackReader<EchoRequest>* reader,+            EchoResponse* response)+        : ctx_(context), reader_(reader), response_(response) {+      reader->BindReactor(this);",Is this always the intended place to bind? Any way this could be done in the base class ctor?,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/17144,233283858,2018-11-14T01:16:20Z,include/grpcpp/impl/codegen/server_callback.h,"@@ -81,9 +156,8 @@ class CallbackUnaryHandler : public MethodHandler {      if (status.ok()) {       // Call the actual function handler and expect the user to call finish-      CatchingCallback(std::move(func_), param.server_context,-                       controller->request(), controller->response(),-                       controller);+      CatchingCallback(func_, param.server_context, controller->request(),","We should have never had the move. That leaves an object in undefined state and that wasn't valid for this class since the func_ is per-method and not per-rpc. However, maybe we can change this to take a reference argument.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/17144,233284265,2018-11-14T01:18:53Z,include/grpcpp/impl/codegen/server_callback.h,"@@ -117,79 +191,575 @@ class CallbackUnaryHandler : public MethodHandler {       : public experimental::ServerCallbackRpcController {    public:     void Finish(Status s) override {-      finish_tag_.Set(-          call_.call(),-          [this](bool) {-            grpc_call* call = call_.call();-            auto call_requester = std::move(call_requester_);-            this->~ServerCallbackRpcControllerImpl();  // explicitly call-                                                       // destructor-            g_core_codegen_interface->grpc_call_unref(call);-            call_requester();-          },-          &finish_buf_);+      finish_tag_.Set(call_.call(), [this](bool) { MaybeDone(); },+                      &finish_ops_);       if (!ctx_->sent_initial_metadata_) {-        finish_buf_.SendInitialMetadata(&ctx_->initial_metadata_,+        finish_ops_.SendInitialMetadata(&ctx_->initial_metadata_,                                         ctx_->initial_metadata_flags());         if (ctx_->compression_level_set()) {-          finish_buf_.set_compression_level(ctx_->compression_level());+          finish_ops_.set_compression_level(ctx_->compression_level());         }         ctx_->sent_initial_metadata_ = true;       }       // The response is dropped if the status is not OK.       if (s.ok()) {-        finish_buf_.ServerSendStatus(&ctx_->trailing_metadata_,-                                     finish_buf_.SendMessage(resp_));+        finish_ops_.ServerSendStatus(&ctx_->trailing_metadata_,+                                     finish_ops_.SendMessage(resp_));       } else {-        finish_buf_.ServerSendStatus(&ctx_->trailing_metadata_, s);+        finish_ops_.ServerSendStatus(&ctx_->trailing_metadata_, s);       }-      finish_buf_.set_core_cq_tag(&finish_tag_);-      call_.PerformOps(&finish_buf_);+      finish_ops_.set_core_cq_tag(&finish_tag_);+      call_.PerformOps(&finish_ops_);     }      void SendInitialMetadata(std::function<void(bool)> f) override {       GPR_CODEGEN_ASSERT(!ctx_->sent_initial_metadata_);--      meta_tag_.Set(call_.call(), std::move(f), &meta_buf_);-      meta_buf_.SendInitialMetadata(&ctx_->initial_metadata_,+      callbacks_outstanding_++;+      meta_tag_.Set(call_.call(),+                    [this, f](bool ok) {+                      f(ok);+                      MaybeDone();+                    },+                    &meta_ops_);+      meta_ops_.SendInitialMetadata(&ctx_->initial_metadata_,                                     ctx_->initial_metadata_flags());       if (ctx_->compression_level_set()) {-        meta_buf_.set_compression_level(ctx_->compression_level());+        meta_ops_.set_compression_level(ctx_->compression_level());       }       ctx_->sent_initial_metadata_ = true;-      meta_buf_.set_core_cq_tag(&meta_tag_);-      call_.PerformOps(&meta_buf_);+      meta_ops_.set_core_cq_tag(&meta_tag_);+      call_.PerformOps(&meta_ops_);     }     private:-    template <class SrvType, class ReqType, class RespType>-    friend class CallbackUnaryHandler;+    friend class CallbackUnaryHandler<RequestType, ResponseType>;      ServerCallbackRpcControllerImpl(ServerContext* ctx, Call* call,-                                    RequestType* req,+                                    const RequestType* req,                                     std::function<void()> call_requester)         : ctx_(ctx),           call_(*call),           req_(req),-          call_requester_(std::move(call_requester)) {}+          call_requester_(std::move(call_requester)) {+      ctx_->BeginCompletionOp(call, [this](bool) { MaybeDone(); });+    }      ~ServerCallbackRpcControllerImpl() { req_->~RequestType(); } -    RequestType* request() { return req_; }+    const RequestType* request() { return req_; }     ResponseType* response() { return &resp_; } -    CallOpSet<CallOpSendInitialMetadata> meta_buf_;+    void MaybeDone() {+      if (--callbacks_outstanding_ == 0) {+        grpc_call* call = call_.call();+        auto call_requester = std::move(call_requester_);+        this->~ServerCallbackRpcControllerImpl();  // explicitly call destructor","We're destructing all the member objects, not just the request explicitly listed in the destructor.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/17144,233285616,2018-11-14T01:26:39Z,test/cpp/end2end/test_service_impl.cc,"@@ -464,44 +526,247 @@ Status TestServiceImpl::BidiStream(   return Status::OK; } -namespace {-int GetIntValueFromMetadataHelper(-    const char* key,-    const std::multimap<grpc::string_ref, grpc::string_ref>& metadata,-    int default_value) {-  if (metadata.find(key) != metadata.end()) {-    std::istringstream iss(ToString(metadata.find(key)->second));-    iss >> default_value;-    gpr_log(GPR_INFO, ""%s : %d"", key, default_value);-  }+void CallbackTestServiceImpl::RequestStream(+    ServerContext* context, EchoResponse* response,+    experimental::ServerCallbackReader<EchoRequest>* reader) {+  class Reactor : public ::grpc::experimental::ServerReadReactor {+   public:+    Reactor(ServerContext* context,+            experimental::ServerCallbackReader<EchoRequest>* reader,+            EchoResponse* response)+        : ctx_(context), reader_(reader), response_(response) {+      reader->BindReactor(this);",The base class doesn't currently know the existence of the stream objects (which would let us use them for other API variants of we later choose). Additionally that would require the derived class constructor to explicitly call the base class constructor with the stream object as an argument but without revealing its purpose explicitly. I'd prefer not to do this. That said there may be a different route that I'll cc you on internally.,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17157,233561752,2018-11-14T18:16:33Z,src/csharp/Grpc.Examples/MathGrpc.cs,"@@ -287,6 +287,17 @@ protected override MathClient NewInstance(ClientBaseConfiguration configuration)           .AddMethod(__Method_Sum, serviceImpl.Sum).Build();     } +    /// <summary>Register service method implementations with a service binder. Useful when customizing the service binding logic.</summary>","I thought of that, but it seemed problematic for `grpc::ServerServiceDefinition::Builder` to inherit from `ServiceBinderBase`:- I'd need to change methods in Builder from non-virtual to virtual which I think is a breaking change.- I'm not sure if adding a base class to an existing class is fully backwards compatible.- The AddMethod methods actually return Builder instance, which makes things a bit more complicated.Another approach would be to keep the existing AddMethod() methods in Builder and add new methods which override the ones declared by ServiceBinderBase, but that's only possible if ServiceBinderBase is an interface (without explicit impl, there is a name clash) and we don't want ServiceBinderBase to be an interfaces as that is risky for future backward compatibility (no default methods implementations for interfaces).Overall, I'm open to changing, but I'm not sure how to do things cleanly other than with the approach currently used in the PR.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17167,233593598,2018-11-14T19:45:19Z,src/csharp/Grpc.Core/DeserializationContext.cs,"@@ -41,6 +43,9 @@ public abstract class DeserializationContext         /// (as there is no practical reason for doing so) and <c>DeserializationContext</c> implementations are free to assume so.         /// </summary>         /// <returns>byte array containing the entire payload.</returns>-        public abstract byte[] PayloadAsNewBuffer();+        public virtual byte[] PayloadAsNewBuffer()+        {+            throw new NotImplementedException();","This has been done with the idea that in the future more methods will be added (e.g. to access the payload with more efficiency) and when added, they will be added as virtual methods with a default implementation so that the backward compatibility is not broken (=classes inheriting from DeserializationContext won't break if they don't provide implementation for all methods).So I changed the method to virtual with default implementation mostly for consistency with the methods that will be added in the future.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17188,233617986,2018-11-14T21:01:02Z,src/core/lib/gprpp/ref_counted.h,"@@ -58,6 +60,73 @@ class NonPolymorphicRefCount {   ~NonPolymorphicRefCount() {} }; +// RefCount is a simple atomic ref-count.+//+// This is a C++ implementation of gpr_refcount, with inline functions. Due to+// inline functions, this class is significantly more efficient than+// gpr_refcount and should be preferred over gpr_refcount whenever possible.+//+// TODO(soheil): Remove gpr_refcount after submitting the GRFC and the paragraph+//               above.+class RefCount {+ public:+  using Value = intptr_t;++  // `init` is the initial refcount stored in this object.+  explicit RefCount(Value init = 1) : val_(init) {}++  // Reinitializes the ref-count.+  void Reset(Value init) { val_.store(init, std::memory_order_relaxed); }++  // Increases the ref-count by `n`.+  void Ref(Value n = 1) { val_.fetch_add(n, std::memory_order_relaxed); }++  // Increases the ref-count by `n` with a trace log.+  void Ref(const DebugLocation& location, const char* reason,","This seems like a fairly ugly method for the public API.  If this is only needed by `RefCountedWithTracing`, then I suggest just making that a friend of this class and having it directly access `val_`.",OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17188,233631879,2018-11-14T21:45:10Z,src/core/lib/gprpp/ref_counted.h,"@@ -58,6 +60,73 @@ class NonPolymorphicRefCount {   ~NonPolymorphicRefCount() {} }; +// RefCount is a simple atomic ref-count.+//+// This is a C++ implementation of gpr_refcount, with inline functions. Due to+// inline functions, this class is significantly more efficient than+// gpr_refcount and should be preferred over gpr_refcount whenever possible.+//+// TODO(soheil): Remove gpr_refcount after submitting the GRFC and the paragraph+//               above.+class RefCount {+ public:+  using Value = intptr_t;++  // `init` is the initial refcount stored in this object.+  explicit RefCount(Value init = 1) : val_(init) {}++  // Reinitializes the ref-count.+  void Reset(Value init) { val_.store(init, std::memory_order_relaxed); }++  // Increases the ref-count by `n`.+  void Ref(Value n = 1) { val_.fetch_add(n, std::memory_order_relaxed); }++  // Increases the ref-count by `n` with a trace log.+  void Ref(const DebugLocation& location, const char* reason,","I ack that it's not a pleasant looking API but, unfortunately, this is a very common pattern in gRPC and some can not be easily transferred to RefCountedWithTracing.Here is an example, but you can find them by ""gpr_log.*ref"":https://github.com/grpc/grpc/blob/b41a44dc2e001358602e8e885c674ddc49387edd/src/core/ext/transport/chttp2/transport/chttp2_transport.cc#L205I'm happy to add the get() method back and add the friend class, but will have to do that for quite a few occurrences. Please just let me know.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/17144,233668724,2018-11-15T00:02:56Z,include/grpcpp/impl/codegen/server_callback.h,"@@ -117,79 +191,575 @@ class CallbackUnaryHandler : public MethodHandler {       : public experimental::ServerCallbackRpcController {    public:     void Finish(Status s) override {-      finish_tag_.Set(-          call_.call(),-          [this](bool) {-            grpc_call* call = call_.call();-            auto call_requester = std::move(call_requester_);-            this->~ServerCallbackRpcControllerImpl();  // explicitly call-                                                       // destructor-            g_core_codegen_interface->grpc_call_unref(call);-            call_requester();-          },-          &finish_buf_);+      finish_tag_.Set(call_.call(), [this](bool) { MaybeDone(); },+                      &finish_ops_);       if (!ctx_->sent_initial_metadata_) {-        finish_buf_.SendInitialMetadata(&ctx_->initial_metadata_,+        finish_ops_.SendInitialMetadata(&ctx_->initial_metadata_,                                         ctx_->initial_metadata_flags());         if (ctx_->compression_level_set()) {-          finish_buf_.set_compression_level(ctx_->compression_level());+          finish_ops_.set_compression_level(ctx_->compression_level());         }         ctx_->sent_initial_metadata_ = true;       }       // The response is dropped if the status is not OK.       if (s.ok()) {-        finish_buf_.ServerSendStatus(&ctx_->trailing_metadata_,-                                     finish_buf_.SendMessage(resp_));+        finish_ops_.ServerSendStatus(&ctx_->trailing_metadata_,+                                     finish_ops_.SendMessage(resp_));       } else {-        finish_buf_.ServerSendStatus(&ctx_->trailing_metadata_, s);+        finish_ops_.ServerSendStatus(&ctx_->trailing_metadata_, s);       }-      finish_buf_.set_core_cq_tag(&finish_tag_);-      call_.PerformOps(&finish_buf_);+      finish_ops_.set_core_cq_tag(&finish_tag_);+      call_.PerformOps(&finish_ops_);     }      void SendInitialMetadata(std::function<void(bool)> f) override {       GPR_CODEGEN_ASSERT(!ctx_->sent_initial_metadata_);--      meta_tag_.Set(call_.call(), std::move(f), &meta_buf_);-      meta_buf_.SendInitialMetadata(&ctx_->initial_metadata_,+      callbacks_outstanding_++;+      meta_tag_.Set(call_.call(),+                    [this, f](bool ok) {+                      f(ok);+                      MaybeDone();+                    },+                    &meta_ops_);+      meta_ops_.SendInitialMetadata(&ctx_->initial_metadata_,                                     ctx_->initial_metadata_flags());       if (ctx_->compression_level_set()) {-        meta_buf_.set_compression_level(ctx_->compression_level());+        meta_ops_.set_compression_level(ctx_->compression_level());       }       ctx_->sent_initial_metadata_ = true;-      meta_buf_.set_core_cq_tag(&meta_tag_);-      call_.PerformOps(&meta_buf_);+      meta_ops_.set_core_cq_tag(&meta_tag_);+      call_.PerformOps(&meta_ops_);     }     private:-    template <class SrvType, class ReqType, class RespType>-    friend class CallbackUnaryHandler;+    friend class CallbackUnaryHandler<RequestType, ResponseType>;      ServerCallbackRpcControllerImpl(ServerContext* ctx, Call* call,-                                    RequestType* req,+                                    const RequestType* req,                                     std::function<void()> call_requester)         : ctx_(ctx),           call_(*call),           req_(req),-          call_requester_(std::move(call_requester)) {}+          call_requester_(std::move(call_requester)) {+      ctx_->BeginCompletionOp(call, [this](bool) { MaybeDone(); });+    }      ~ServerCallbackRpcControllerImpl() { req_->~RequestType(); } -    RequestType* request() { return req_; }+    const RequestType* request() { return req_; }     ResponseType* response() { return &resp_; } -    CallOpSet<CallOpSendInitialMetadata> meta_buf_;+    void MaybeDone() {+      if (--callbacks_outstanding_ == 0) {+        grpc_call* call = call_.call();+        auto call_requester = std::move(call_requester_);+        this->~ServerCallbackRpcControllerImpl();  // explicitly call destructor+        g_core_codegen_interface->grpc_call_unref(call);+        call_requester();+      }+    }++    CallOpSet<CallOpSendInitialMetadata> meta_ops_;     CallbackWithSuccessTag meta_tag_;     CallOpSet<CallOpSendInitialMetadata, CallOpSendMessage,               CallOpServerSendStatus>-        finish_buf_;+        finish_ops_;     CallbackWithSuccessTag finish_tag_;      ServerContext* ctx_;     Call call_;-    RequestType* req_;+    const RequestType* req_;     ResponseType resp_;     std::function<void()> call_requester_;+    std::atomic_int callbacks_outstanding_{+        2};  // reserve for Finish and CompletionOp+  };+};++template <class RequestType, class ResponseType>+class CallbackClientStreamingHandler : public MethodHandler {+ public:+  CallbackClientStreamingHandler(+      std::function<void(ServerContext*, ResponseType*,+                         experimental::ServerCallbackReader<RequestType>*)>+          func)+      : func_(func) {}+  void RunHandler(const HandlerParameter& param) final {+    // Arena allocate a reader structure (that includes response)+    g_core_codegen_interface->grpc_call_ref(param.call->call());+    auto* reader = new (g_core_codegen_interface->grpc_call_arena_alloc(+        param.call->call(), sizeof(ServerCallbackReaderImpl)))+        ServerCallbackReaderImpl(param.server_context, param.call,+                                 std::move(param.call_requester));+    Status status = param.status;++    if (status.ok()) {+      // Call the actual function handler and expect the user to call finish+      CatchingCallback(func_, param.server_context, reader->response(), reader);+    } else {+      // if deserialization failed, we need to fail the call+      reader->Finish(status);+    }+  }++ private:+  std::function<void(ServerContext*, ResponseType*,+                     experimental::ServerCallbackReader<RequestType>*)>+      func_;++  class ServerCallbackReaderImpl+      : public experimental::ServerCallbackReader<RequestType> {+   public:+    void BindReactor(experimental::ServerReadReactor* reactor) override {+      reactor_ = reactor;+    }+    void Finish(Status s) override {+      finish_tag_.Set(call_.call(), [this](bool) { MaybeDone(); },+                      &finish_ops_);+      if (!ctx_->sent_initial_metadata_) {+        finish_ops_.SendInitialMetadata(&ctx_->initial_metadata_,+                                        ctx_->initial_metadata_flags());+        if (ctx_->compression_level_set()) {+          finish_ops_.set_compression_level(ctx_->compression_level());+        }+        ctx_->sent_initial_metadata_ = true;+      }+      // The response is dropped if the status is not OK.+      if (s.ok()) {+        finish_ops_.ServerSendStatus(&ctx_->trailing_metadata_,+                                     finish_ops_.SendMessage(resp_));+      } else {+        finish_ops_.ServerSendStatus(&ctx_->trailing_metadata_, s);+      }+      finish_ops_.set_core_cq_tag(&finish_tag_);+      call_.PerformOps(&finish_ops_);+    }++    void SendInitialMetadata() override {+      GPR_CODEGEN_ASSERT(!ctx_->sent_initial_metadata_);+      callbacks_outstanding_++;+      meta_tag_.Set(call_.call(),+                    [this](bool ok) {+                      if (reactor_ != nullptr) {+                        reactor_->OnSendInitialMetadataDone(ok);+                      }+                      MaybeDone();+                    },+                    &meta_ops_);+      meta_ops_.SendInitialMetadata(&ctx_->initial_metadata_,+                                    ctx_->initial_metadata_flags());+      if (ctx_->compression_level_set()) {+        meta_ops_.set_compression_level(ctx_->compression_level());+      }+      ctx_->sent_initial_metadata_ = true;+      meta_ops_.set_core_cq_tag(&meta_tag_);+      call_.PerformOps(&meta_ops_);+    }++    void Read(RequestType* req) override {+      callbacks_outstanding_++;+      read_ops_.RecvMessage(req);+      call_.PerformOps(&read_ops_);+    }++   private:+    friend class CallbackClientStreamingHandler<RequestType, ResponseType>;++    ServerCallbackReaderImpl(ServerContext* ctx, Call* call,+                             std::function<void()> call_requester)+        : ctx_(ctx),+          call_(*call),+          call_requester_(std::move(call_requester)),+          reactor_(nullptr) {+      ctx_->BeginCompletionOp(call, [this](bool) { MaybeDone(); });+      read_tag_.Set(call_.call(),+                    [this](bool ok) {+                      if (reactor_ != nullptr) {+                        reactor_->OnReadDone(ok);+                      }+                      MaybeDone();+                    },+                    &read_ops_);+      read_ops_.set_core_cq_tag(&read_tag_);+    }++    ~ServerCallbackReaderImpl() {}++    ResponseType* response() { return &resp_; }++    void MaybeDone() {+      if (--callbacks_outstanding_ == 0) {+        grpc_call* call = call_.call();+        auto call_requester = std::move(call_requester_);+        this->~ServerCallbackReaderImpl();  // explicitly call destructor+        g_core_codegen_interface->grpc_call_unref(call);+        call_requester();+      }+    }++    CallOpSet<CallOpSendInitialMetadata> meta_ops_;+    CallbackWithSuccessTag meta_tag_;+    CallOpSet<CallOpSendInitialMetadata, CallOpSendMessage,+              CallOpServerSendStatus>+        finish_ops_;+    CallbackWithSuccessTag finish_tag_;+    CallOpSet<CallOpRecvMessage<RequestType>> read_ops_;+    CallbackWithSuccessTag read_tag_;++    ServerContext* ctx_;+    Call call_;+    ResponseType resp_;+    std::function<void()> call_requester_;+    experimental::ServerReadReactor* reactor_;+    std::atomic_int callbacks_outstanding_{+        2};  // reserve for Finish and CompletionOp+  };+};++template <class RequestType, class ResponseType>+class CallbackServerStreamingHandler : public MethodHandler {+ public:+  CallbackServerStreamingHandler(+      std::function<void(ServerContext*, const RequestType*,+                         experimental::ServerCallbackWriter<ResponseType>*)>+          func)+      : func_(func) {}+  void RunHandler(const HandlerParameter& param) final {+    // Arena allocate a writer structure+    g_core_codegen_interface->grpc_call_ref(param.call->call());+    auto* writer = new (g_core_codegen_interface->grpc_call_arena_alloc(+        param.call->call(), sizeof(ServerCallbackWriterImpl)))+        ServerCallbackWriterImpl(param.server_context, param.call,+                                 static_cast<RequestType*>(param.request),+                                 std::move(param.call_requester));+    Status status = param.status;++    if (status.ok()) {+      // Call the actual function handler and expect the user to call finish+      CatchingCallback(func_, param.server_context, writer->request(), writer);+    } else {+      // if deserialization failed, we need to fail the call+      writer->Finish(status);+    }+  }++  void* Deserialize(grpc_call* call, grpc_byte_buffer* req,",https://github.com/grpc/grpc/blob/84e763f10a1e10d36c7de35970f9d25958ee2e16/src/cpp/server/server_cc.cc#L430,
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17188,233956771,2018-11-15T18:23:38Z,src/core/lib/gprpp/ref_counted.h,"@@ -111,7 +180,7 @@ class RefCounted : public Impl {  protected:   GPRC_ALLOW_CLASS_TO_USE_NON_PUBLIC_DELETE -  RefCounted() { gpr_ref_init(&refs_, 1); }+  RefCounted() = default;","That's a good approach, but AFAICT even if we make it constexpr, the ctor would be a no-op because this class can have a virtual d-tor. Also non of the `std::atomic` options are constexpr (load and store are not const expr), and as a result this class cannot be made constexpr.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/17188,233960229,2018-11-15T18:34:34Z,src/core/lib/gprpp/ref_counted.h,"@@ -111,7 +180,7 @@ class RefCounted : public Impl {  protected:   GPRC_ALLOW_CLASS_TO_USE_NON_PUBLIC_DELETE -  RefCounted() { gpr_ref_init(&refs_, 1); }+  RefCounted() = default;","Wait, isn't the std::atomic constructor constexpr when used with a default value? cppreference seems to suggest that it is. And, oh, sorry about not realizing that this is a derived class. Yeah, that makes it irrelevant.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17229,233989655,2018-11-15T20:04:58Z,tools/distrib/python/docgen.py,"@@ -109,17 +103,16 @@     print('Cloning your repository...')     subprocess.check_call(         [-            'git', 'clone', 'https://{}@github.com/{}/grpc'.format(-                github_user, github_repository_owner)+            'git',+            'clone',+            '--depth',+            '1',+            '--branch',+            'gh-pages',+            'git@github.com:%s/grpc.git' % (github_repository_owner),","Thanks for mentioning that, I didn't know that context. The `--submit` flag is used to automate the submit process, and with public key set the SSH clone should be more handy, since it doesn't ask the password or two-factor authentication every time.",
4062751,nlopezgi,https://api.github.com/repos/grpc/grpc/pulls/17110,234029708,2018-11-15T22:19:27Z,third_party/toolchains/BUILD,"@@ -16,37 +16,82 @@ licenses([""notice""])  # Apache v2  package(default_visibility = [""//visibility:public""]) -exports_files([""RBE_USE_MACHINE_TYPE_LARGE"",])- # Latest RBE Ubuntu16_04 container # Update every time when a new container is released. alias(     name = ""rbe_ubuntu1604"",-    actual = "":rbe_ubuntu1604_r328903"",+    actual = "":rbe_ubuntu1604_r340178"",+)++alias(+    name = ""rbe_ubuntu1604_large"",+    actual = "":rbe_ubuntu1604_r340178_large"", ) -# RBE Ubuntu16_04 r328903+# RBE Ubuntu16_04 r340178 platform(-    name = ""rbe_ubuntu1604_r328903"",+    name = ""rbe_ubuntu1604_r340178"",     constraint_values = [         ""@bazel_tools//platforms:x86_64"",         ""@bazel_tools//platforms:linux"",         ""@bazel_tools//tools/cpp:clang"",-        ""@com_github_bazelbuild_bazeltoolchains//constraints:xenial"",-        ""@com_github_bazelbuild_bazeltoolchains//constraints/sanitizers:support_msan"",+        ""@bazel_toolchains//constraints:xenial"",+        ""@bazel_toolchains//constraints/sanitizers:support_msan"",+        ""//third_party/toolchains/machine_size:standard"",     ],     remote_execution_properties = """"""         properties: {           name: ""container-image""-          value:""docker://gcr.io/cloud-marketplace/google/rbe-ubuntu16-04@sha256:59bf0e191a6b5cc1ab62c2224c810681d1326bad5a27b1d36c9f40113e79da7f""+          value:""docker://gcr.io/cloud-marketplace/google/rbe-ubuntu16-04@sha256:9bd8ba020af33edb5f11eff0af2f63b3bcb168cd6566d7b27c6685e717787928""         }         properties: {           name: ""gceMachineType""  # Small machines for majority of tests.           value: ""n1-highmem-2""         }+        """""",+)++# RBE Ubuntu16_04 r340178 large+platform(+    name = ""rbe_ubuntu1604_r340178_large"",+    constraint_values = [+        ""@bazel_tools//platforms:x86_64"",+        ""@bazel_tools//platforms:linux"",+        ""@bazel_tools//tools/cpp:clang"",+        ""@bazel_toolchains//constraints:xenial"",+        ""@@bazel_toolchains//constraints/sanitizers:support_msan"",+        ""//third_party/toolchains/machine_size:large"",+    ],+    remote_execution_properties = """"""         properties: {-          name: ""gceMachineType_LARGE""  # Large machines for a small set of resource-consuming tests such as combiner_tests under TSAN.+          name: ""container-image""+          value:""docker://gcr.io/cloud-marketplace/google/rbe-ubuntu16-04@sha256:9bd8ba020af33edb5f11eff0af2f63b3bcb168cd6566d7b27c6685e717787928""+        }+        properties: {+          name: ""gceMachineType""  # Small machines for majority of tests.           value: ""n1-standard-8""         }         """""", )++# This target is auto-generated from release/cpp.tpl and should not be+# modified directly.+toolchain(+    name = ""cc-toolchain-clang-x86_64-default"",+    exec_compatible_with = [+        ""@bazel_tools//platforms:linux"",+        ""@bazel_tools//platforms:x86_64"",+        ""@bazel_tools//tools/cpp:clang"",+        ""//constraints:xenial"",",this should likely be@bazel_toolchains//constraints:xenial,
4062751,nlopezgi,https://api.github.com/repos/grpc/grpc/pulls/17110,234030374,2018-11-15T22:21:57Z,third_party/toolchains/BUILD,"@@ -16,37 +16,82 @@ licenses([""notice""])  # Apache v2  package(default_visibility = [""//visibility:public""]) -exports_files([""RBE_USE_MACHINE_TYPE_LARGE"",])- # Latest RBE Ubuntu16_04 container # Update every time when a new container is released. alias(     name = ""rbe_ubuntu1604"",-    actual = "":rbe_ubuntu1604_r328903"",+    actual = "":rbe_ubuntu1604_r340178"",+)++alias(+    name = ""rbe_ubuntu1604_large"",+    actual = "":rbe_ubuntu1604_r340178_large"", ) -# RBE Ubuntu16_04 r328903+# RBE Ubuntu16_04 r340178 platform(-    name = ""rbe_ubuntu1604_r328903"",+    name = ""rbe_ubuntu1604_r340178"",     constraint_values = [         ""@bazel_tools//platforms:x86_64"",         ""@bazel_tools//platforms:linux"",         ""@bazel_tools//tools/cpp:clang"",-        ""@com_github_bazelbuild_bazeltoolchains//constraints:xenial"",-        ""@com_github_bazelbuild_bazeltoolchains//constraints/sanitizers:support_msan"",+        ""@bazel_toolchains//constraints:xenial"",+        ""@bazel_toolchains//constraints/sanitizers:support_msan"",+        ""//third_party/toolchains/machine_size:standard"",     ],     remote_execution_properties = """"""         properties: {           name: ""container-image""-          value:""docker://gcr.io/cloud-marketplace/google/rbe-ubuntu16-04@sha256:59bf0e191a6b5cc1ab62c2224c810681d1326bad5a27b1d36c9f40113e79da7f""+          value:""docker://gcr.io/cloud-marketplace/google/rbe-ubuntu16-04@sha256:9bd8ba020af33edb5f11eff0af2f63b3bcb168cd6566d7b27c6685e717787928""         }         properties: {           name: ""gceMachineType""  # Small machines for majority of tests.           value: ""n1-highmem-2""         }+        """""",+)++# RBE Ubuntu16_04 r340178 large+platform(+    name = ""rbe_ubuntu1604_r340178_large"",+    constraint_values = [+        ""@bazel_tools//platforms:x86_64"",+        ""@bazel_tools//platforms:linux"",+        ""@bazel_tools//tools/cpp:clang"",+        ""@bazel_toolchains//constraints:xenial"",+        ""@@bazel_toolchains//constraints/sanitizers:support_msan"",+        ""//third_party/toolchains/machine_size:large"",+    ],+    remote_execution_properties = """"""         properties: {-          name: ""gceMachineType_LARGE""  # Large machines for a small set of resource-consuming tests such as combiner_tests under TSAN.+          name: ""container-image""+          value:""docker://gcr.io/cloud-marketplace/google/rbe-ubuntu16-04@sha256:9bd8ba020af33edb5f11eff0af2f63b3bcb168cd6566d7b27c6685e717787928""+        }+        properties: {+          name: ""gceMachineType""  # Small machines for majority of tests.           value: ""n1-standard-8""         }         """""", )++# This target is auto-generated from release/cpp.tpl and should not be+# modified directly.+toolchain(+    name = ""cc-toolchain-clang-x86_64-default"",+    exec_compatible_with = [+        ""@bazel_tools//platforms:linux"",+        ""@bazel_tools//platforms:x86_64"",+        ""@bazel_tools//tools/cpp:clang"",+        ""//constraints:xenial"",+        ""//third_party/toolchains/machine_size:standard"",","you probably also need ""@bazel_toolchains//constraints/sanitizers:support_msan"" in this list",
4062751,nlopezgi,https://api.github.com/repos/grpc/grpc/pulls/17110,234031111,2018-11-15T22:24:39Z,third_party/toolchains/BUILD,"@@ -16,37 +16,82 @@ licenses([""notice""])  # Apache v2  package(default_visibility = [""//visibility:public""]) -exports_files([""RBE_USE_MACHINE_TYPE_LARGE"",])- # Latest RBE Ubuntu16_04 container # Update every time when a new container is released. alias(     name = ""rbe_ubuntu1604"",-    actual = "":rbe_ubuntu1604_r328903"",+    actual = "":rbe_ubuntu1604_r340178"",+)++alias(+    name = ""rbe_ubuntu1604_large"",+    actual = "":rbe_ubuntu1604_r340178_large"", ) -# RBE Ubuntu16_04 r328903+# RBE Ubuntu16_04 r340178 platform(-    name = ""rbe_ubuntu1604_r328903"",+    name = ""rbe_ubuntu1604_r340178"",     constraint_values = [         ""@bazel_tools//platforms:x86_64"",         ""@bazel_tools//platforms:linux"",         ""@bazel_tools//tools/cpp:clang"",-        ""@com_github_bazelbuild_bazeltoolchains//constraints:xenial"",-        ""@com_github_bazelbuild_bazeltoolchains//constraints/sanitizers:support_msan"",+        ""@bazel_toolchains//constraints:xenial"",",If you change this from @com_github_bazelbuild_bazeltoolchainsto @bazel_toolchainsyou probably also need to update https://github.com/grpc/grpc/blob/master/bazel/grpc_deps.bzl#L169,OK
4062751,nlopezgi,https://api.github.com/repos/grpc/grpc/pulls/17110,234031290,2018-11-15T22:25:20Z,third_party/toolchains/BUILD,"@@ -16,37 +16,82 @@ licenses([""notice""])  # Apache v2  package(default_visibility = [""//visibility:public""]) -exports_files([""RBE_USE_MACHINE_TYPE_LARGE"",])- # Latest RBE Ubuntu16_04 container # Update every time when a new container is released. alias(     name = ""rbe_ubuntu1604"",-    actual = "":rbe_ubuntu1604_r328903"",+    actual = "":rbe_ubuntu1604_r340178"",+)++alias(+    name = ""rbe_ubuntu1604_large"",+    actual = "":rbe_ubuntu1604_r340178_large"", ) -# RBE Ubuntu16_04 r328903+# RBE Ubuntu16_04 r340178 platform(-    name = ""rbe_ubuntu1604_r328903"",+    name = ""rbe_ubuntu1604_r340178"",     constraint_values = [         ""@bazel_tools//platforms:x86_64"",         ""@bazel_tools//platforms:linux"",         ""@bazel_tools//tools/cpp:clang"",-        ""@com_github_bazelbuild_bazeltoolchains//constraints:xenial"",-        ""@com_github_bazelbuild_bazeltoolchains//constraints/sanitizers:support_msan"",+        ""@bazel_toolchains//constraints:xenial"",+        ""@bazel_toolchains//constraints/sanitizers:support_msan"",+        ""//third_party/toolchains/machine_size:standard"",     ],     remote_execution_properties = """"""         properties: {           name: ""container-image""-          value:""docker://gcr.io/cloud-marketplace/google/rbe-ubuntu16-04@sha256:59bf0e191a6b5cc1ab62c2224c810681d1326bad5a27b1d36c9f40113e79da7f""+          value:""docker://gcr.io/cloud-marketplace/google/rbe-ubuntu16-04@sha256:9bd8ba020af33edb5f11eff0af2f63b3bcb168cd6566d7b27c6685e717787928""         }         properties: {           name: ""gceMachineType""  # Small machines for majority of tests.           value: ""n1-highmem-2""         }+        """""",+)++# RBE Ubuntu16_04 r340178 large+platform(+    name = ""rbe_ubuntu1604_r340178_large"",+    constraint_values = [+        ""@bazel_tools//platforms:x86_64"",+        ""@bazel_tools//platforms:linux"",+        ""@bazel_tools//tools/cpp:clang"",+        ""@bazel_toolchains//constraints:xenial"",+        ""@@bazel_toolchains//constraints/sanitizers:support_msan"",+        ""//third_party/toolchains/machine_size:large"",+    ],+    remote_execution_properties = """"""         properties: {-          name: ""gceMachineType_LARGE""  # Large machines for a small set of resource-consuming tests such as combiner_tests under TSAN.+          name: ""container-image""+          value:""docker://gcr.io/cloud-marketplace/google/rbe-ubuntu16-04@sha256:9bd8ba020af33edb5f11eff0af2f63b3bcb168cd6566d7b27c6685e717787928""+        }+        properties: {+          name: ""gceMachineType""  # Small machines for majority of tests.           value: ""n1-standard-8""         }         """""", )++# This target is auto-generated from release/cpp.tpl and should not be+# modified directly.+toolchain(+    name = ""cc-toolchain-clang-x86_64-default"",+    exec_compatible_with = [+        ""@bazel_tools//platforms:linux"",+        ""@bazel_tools//platforms:x86_64"",+        ""@bazel_tools//tools/cpp:clang"",+        ""//constraints:xenial"",+        ""//third_party/toolchains/machine_size:standard"",+        ""//third_party/toolchains/machine_size:large"",+    ],+    target_compatible_with = [+        ""//third_party/toolchains:rbe_ubuntu1604"",+        ""//third_party/toolchains:rbe_ubuntu1604_large"",+        ""@bazel_tools//platforms:linux"",+        ""@bazel_tools//platforms:x86_64"",+    ],+    toolchain = ""//configs/ubuntu16_04_clang/1.1/bazel_0.16.1/default:cc-compiler-k8"",",this needs the @bazel_toolchains prefix,
4062751,nlopezgi,https://api.github.com/repos/grpc/grpc/pulls/17110,234031477,2018-11-15T22:26:09Z,third_party/toolchains/BUILD,"@@ -16,37 +16,82 @@ licenses([""notice""])  # Apache v2  package(default_visibility = [""//visibility:public""]) -exports_files([""RBE_USE_MACHINE_TYPE_LARGE"",])- # Latest RBE Ubuntu16_04 container # Update every time when a new container is released. alias(     name = ""rbe_ubuntu1604"",-    actual = "":rbe_ubuntu1604_r328903"",+    actual = "":rbe_ubuntu1604_r340178"",+)++alias(+    name = ""rbe_ubuntu1604_large"",+    actual = "":rbe_ubuntu1604_r340178_large"", ) -# RBE Ubuntu16_04 r328903+# RBE Ubuntu16_04 r340178 platform(-    name = ""rbe_ubuntu1604_r328903"",+    name = ""rbe_ubuntu1604_r340178"",     constraint_values = [         ""@bazel_tools//platforms:x86_64"",         ""@bazel_tools//platforms:linux"",         ""@bazel_tools//tools/cpp:clang"",-        ""@com_github_bazelbuild_bazeltoolchains//constraints:xenial"",-        ""@com_github_bazelbuild_bazeltoolchains//constraints/sanitizers:support_msan"",+        ""@bazel_toolchains//constraints:xenial"",+        ""@bazel_toolchains//constraints/sanitizers:support_msan"",+        ""//third_party/toolchains/machine_size:standard"",     ],     remote_execution_properties = """"""         properties: {           name: ""container-image""-          value:""docker://gcr.io/cloud-marketplace/google/rbe-ubuntu16-04@sha256:59bf0e191a6b5cc1ab62c2224c810681d1326bad5a27b1d36c9f40113e79da7f""+          value:""docker://gcr.io/cloud-marketplace/google/rbe-ubuntu16-04@sha256:9bd8ba020af33edb5f11eff0af2f63b3bcb168cd6566d7b27c6685e717787928""         }         properties: {           name: ""gceMachineType""  # Small machines for majority of tests.           value: ""n1-highmem-2""         }+        """""",+)++# RBE Ubuntu16_04 r340178 large+platform(+    name = ""rbe_ubuntu1604_r340178_large"",+    constraint_values = [+        ""@bazel_tools//platforms:x86_64"",+        ""@bazel_tools//platforms:linux"",+        ""@bazel_tools//tools/cpp:clang"",+        ""@bazel_toolchains//constraints:xenial"",+        ""@@bazel_toolchains//constraints/sanitizers:support_msan"",+        ""//third_party/toolchains/machine_size:large"",+    ],+    remote_execution_properties = """"""         properties: {-          name: ""gceMachineType_LARGE""  # Large machines for a small set of resource-consuming tests such as combiner_tests under TSAN.+          name: ""container-image""+          value:""docker://gcr.io/cloud-marketplace/google/rbe-ubuntu16-04@sha256:9bd8ba020af33edb5f11eff0af2f63b3bcb168cd6566d7b27c6685e717787928""+        }+        properties: {+          name: ""gceMachineType""  # Small machines for majority of tests.           value: ""n1-standard-8""         }         """""", )++# This target is auto-generated from release/cpp.tpl and should not be+# modified directly.+toolchain(+    name = ""cc-toolchain-clang-x86_64-default"",+    exec_compatible_with = [+        ""@bazel_tools//platforms:linux"",+        ""@bazel_tools//platforms:x86_64"",+        ""@bazel_tools//tools/cpp:clang"",+        ""//constraints:xenial"",+        ""//third_party/toolchains/machine_size:standard"",+        ""//third_party/toolchains/machine_size:large"",+    ],+    target_compatible_with = [+        ""//third_party/toolchains:rbe_ubuntu1604"",",these probably also need the @bazel_toolchains prefix (unless you have them declared in you repo under //third_party/toolchains?),
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17229,234041014,2018-11-15T23:03:53Z,tools/distrib/python/docgen.py,"@@ -109,17 +103,16 @@     print('Cloning your repository...')     subprocess.check_call(         [-            'git', 'clone', 'https://{}@github.com/{}/grpc'.format(-                github_user, github_repository_owner)+            'git',+            'clone',+            '--depth',+            '1',+            '--branch',+            'gh-pages',+            'git@github.com:%s/grpc.git' % (github_repository_owner),","Tried in docker container, the `https://` will request for```git config --global user.email ""you@example.com""git config --global user.name ""Your Name""```If the the local git environment doesn't support clone, it will not able to support push for sure. And since the created clone folder was a temp folder, we can't expect the user to reuse the cloned copy to push. The optimization may only valid for user who sort of half done with git configuration...",OK
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/17229,234046938,2018-11-15T23:32:56Z,tools/distrib/python/docgen.py,"@@ -109,17 +103,16 @@     print('Cloning your repository...')     subprocess.check_call(         [-            'git', 'clone', 'https://{}@github.com/{}/grpc'.format(-                github_user, github_repository_owner)+            'git',+            'clone',+            '--depth',+            '1',+            '--branch',+            'gh-pages',+            'git@github.com:%s/grpc.git' % (github_repository_owner),","Are you saying the following does not work:```git clone https://github.com/grpc/grpc -b gh-pages .# on submit onlygit remote add grpc git@github.com:USERNAME/grpcgit push grpc gh-pages```It's strange: the complaint about `git config` should not have anything to do with whether you are cloning from http or ssh, but whether your user has a `.gitconfig` already configured. I'm pretty sure if you don't have a `.gitconfig` in your container you will get the same thing even with `git@...` URL.",
4062751,nlopezgi,https://api.github.com/repos/grpc/grpc/pulls/17110,234047229,2018-11-15T23:34:31Z,tools/remote_build/rbe_common.bazelrc,"@@ -18,12 +18,12 @@  startup --host_jvm_args=-Dbazel.DigestFunction=SHA256 -build --crosstool_top=@com_github_bazelbuild_bazeltoolchains//configs/ubuntu16_04_clang/1.0/bazel_0.16.1/default:toolchain-build --extra_toolchains=@com_github_bazelbuild_bazeltoolchains//configs/ubuntu16_04_clang/1.0/bazel_0.16.1/cpp:cc-toolchain-clang-x86_64-default+build --crosstool_top=@bazel_toolchains//configs/ubuntu16_04_clang/1.1/bazel_0.16.1/default:toolchain",this should probably be @com_github_bazelbuild_bazeltoolchains,
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/17229,234065182,2018-11-16T01:26:32Z,tools/distrib/python/docgen.py,"@@ -109,17 +103,16 @@     print('Cloning your repository...')     subprocess.check_call(         [-            'git', 'clone', 'https://{}@github.com/{}/grpc'.format(-                github_user, github_repository_owner)+            'git',+            'clone',+            '--depth',+            '1',+            '--branch',+            'gh-pages',+            'git@github.com:%s/grpc.git' % (github_repository_owner),","> The user of this script will be the person who does the release process, and they supposed to be able to push to GitHub. Do you have more detailed fail cases?I have had things falling apart when my SSH key was on my Security Key for some reason.--I actually am noticing a bigger issue. You are checking out `USER/grpc.git` and committing on top of it. You should checkout `grpc/grpc.git` and push to `USER/grpc.git`. Otherwise, `USER/grpc.git` might be outdated.Both of these issues can be fixed simply by applying the steps I listed above: use `https://github.com/grpc/grpc` when checking out, add the remote `git@github.com:$USER/grpc.git`, and push to that remote.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17229,234067187,2018-11-16T01:40:55Z,tools/distrib/python/docgen.py,"@@ -109,17 +103,16 @@     print('Cloning your repository...')     subprocess.check_call(         [-            'git', 'clone', 'https://{}@github.com/{}/grpc'.format(-                github_user, github_repository_owner)+            'git',+            'clone',+            '--depth',+            '1',+            '--branch',+            'gh-pages',+            'git@github.com:%s/grpc.git' % (github_repository_owner),","Thank you for reviewing and suggesting. Yeah, this will be a problem if the user has modification on their own repository's `gh-pages` branch. And I also found that shallow clone cannot be pushed to new repo, even if it is forked  [Stackoverflow](https://stackoverflow.com/questions/28983842/remote-rejected-shallow-update-not-allowed-after-changing-git-remote-url). Fixed.",OK
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17223,234093494,2018-11-16T05:26:55Z,src/python/grpcio/grpc/_server.py,"@@ -828,7 +828,7 @@ def stop(self, grace):         return _stop(self._state, grace)      def __del__(self):-        _stop(self._state, None)+        _stop(self._state, 0)","Let's hold off on this change (for now) until we better understand why the hang in #17214 is occurring. Currently `__del__` is equivalent to calling `server.stop(None)`, which is explicitly supposed to block until the last RPC handler terminates:https://grpc.io/grpc/python/grpc.html#grpc.Server.stop```If a grace period is not specified (by passing None for grace), all existing RPCs are aborted immediately and this method blocks until the last RPC handler terminates```Whether `__del__` *should* wait for all RPC handlers to terminate is a separate matter, but changing its semantics in response to #17214 seems like we may just be obscuring a bug elsewhere.",OK
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/16455,234661539,2018-11-19T15:26:00Z,src/core/ext/transport/chttp2/transport/context_list.cc,"@@ -0,0 +1,50 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/support/port_platform.h>++#include ""src/core/ext/transport/chttp2/transport/context_list.h""++namespace {+void (*cb)(void*, grpc_core::Timestamps*) = nullptr;+}++namespace grpc_core {+void ContextList::Execute(void* arg, grpc_core::Timestamps* ts,+                          grpc_error* error) {+  ContextList* head = static_cast<ContextList*>(arg);+  ContextList* ptr;+  while (head != nullptr) {+    if (error == GRPC_ERROR_NONE && ts != nullptr) {+      if (cb) {+        cb(head->s_->context, ts);+      }+    }+    GRPC_CHTTP2_STREAM_UNREF(static_cast<grpc_chttp2_stream*>(head->s_),+                             ""timestamp"");+    ptr = head;","nit; suggest renaming this `to_be_freed` or something similar, since that is its purpose",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/16455,234662705,2018-11-19T15:28:32Z,src/core/ext/transport/chttp2/transport/context_list.h,"@@ -0,0 +1,72 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_EXT_TRANSPORT_CONTEXT_LIST_H+#define GRPC_CORE_EXT_TRANSPORT_CONTEXT_LIST_H++#include <grpc/support/port_platform.h>++#include ""src/core/lib/iomgr/buffer_list.h""++#include ""src/core/ext/transport/chttp2/transport/internal.h""++namespace grpc_core {+/** A list of RPC Contexts */+class ContextList {+ public:+  /* Creates a new element with \a context as the value and appends it to the+   * list. */+  static void Append(ContextList** head, grpc_chttp2_stream* s) {+    /* Make sure context is not already present */+    ContextList* ptr = *head;+    GRPC_CHTTP2_STREAM_REF(s, ""timestamp"");+    while (ptr != nullptr) {",Must we traverse the list every time we append?? Seems inefficient unless there is a very strict bound on the size of ContextList. Is this something that we could make DBG only? or get more clever about somehow?,
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/16455,234665470,2018-11-19T15:34:51Z,src/core/ext/transport/chttp2/transport/context_list.h,"@@ -0,0 +1,72 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_EXT_TRANSPORT_CONTEXT_LIST_H+#define GRPC_CORE_EXT_TRANSPORT_CONTEXT_LIST_H++#include <grpc/support/port_platform.h>++#include ""src/core/lib/iomgr/buffer_list.h""++#include ""src/core/ext/transport/chttp2/transport/internal.h""++namespace grpc_core {+/** A list of RPC Contexts */+class ContextList {+ public:+  /* Creates a new element with \a context as the value and appends it to the+   * list. */+  static void Append(ContextList** head, grpc_chttp2_stream* s) {+    /* Make sure context is not already present */+    ContextList* ptr = *head;+    GRPC_CHTTP2_STREAM_REF(s, ""timestamp"");+    while (ptr != nullptr) {+      if (ptr->s_ == s) {+        GPR_ASSERT(+            false &&+            ""Trying to append a stream that is already present in the list"");+      }+      ptr = ptr->next_;+    }+    ContextList* elem = grpc_core::New<ContextList>();+    elem->s_ = s;+    if (*head == nullptr) {+      *head = elem;+      return;+    }+    ptr = *head;+    while (ptr->next_ != nullptr) {","Any problem with appending to the front to avoid having to do an O(n) traverse for every Append?It would need some restructuring. For example, Append could return a pointer to the new head of the list.  And then calling code would dofoo->cl = foo->cl->Append(....);Other option would be to split up the idea of ContextList and ContextNode and then callers hold onto ContextList",OK
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/16455,235180331,2018-11-20T21:45:19Z,src/core/lib/iomgr/buffer_list.cc,"@@ -55,10 +55,16 @@ void fill_gpr_from_timestamp(gpr_timespec* gts, const struct timespec* ts) {   gts->clock_type = GPR_CLOCK_REALTIME; } +void default_timestamps_callback(void* arg, grpc_core::Timestamps* ts,+                                 grpc_error* shudown_err) {+  gpr_log(GPR_DEBUG, ""Timestamps callback has not been registered"");","wouldn't that be a source of data races since there can be multiple subchannels? Also, this log is not helpful for open source yet, and for google3 we would be registering one",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/16455,235180468,2018-11-20T21:45:46Z,src/core/lib/iomgr/endpoint.cc,"@@ -61,3 +61,10 @@ int grpc_endpoint_get_fd(grpc_endpoint* ep) { return ep->vtable->get_fd(ep); } grpc_resource_user* grpc_endpoint_get_resource_user(grpc_endpoint* ep) {   return ep->vtable->get_resource_user(ep); }++bool grpc_endpoint_can_track_err(grpc_endpoint* ep) {+  if (ep->vtable->can_track_err != nullptr) {","Yes, I should do that. I was being too lazy.",
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17259,235206967,2018-11-20T23:28:17Z,src/python/grpcio/grpc/_server.py,"@@ -829,6 +829,7 @@ def stop(self, grace):      def __del__(self):         _stop(self._state, None)+        del self._state","I don't follow how this relates to step (3), the invocation of `grpc_server_destroy`, from https://github.com/grpc/grpc/issues/17258. Isn't that handled in the Cython layer [here](https://github.com/grpc/grpc/blob/master/src/python/grpcio/grpc/_cython/_cygrpc/server.pyx.pxi#L148)?",
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17259,235492420,2018-11-21T18:10:48Z,src/python/grpcio/grpc/_server.py,"@@ -829,6 +829,7 @@ def stop(self, grace):      def __del__(self):         _stop(self._state, None)+        del self._state","I agree that you shouldn't just call `grpc_server_destroy` here. From the Cython [docs](http://docs.cython.org/en/latest/src/userguide/special_methods.html#finalization-method-dealloc), `__dealloc__` is the correct place to deallocate C data that's created in the Cython object's `__cinit__` method.  `Server.__cinit__` calls [`grpc_server_create`](https://github.com/grpc/grpc/blob/abbfd89dfc7e140fb1658f671b36e3276bfc37ce/src/python/grpcio/grpc/_cython/_cygrpc/server.pyx.pxi#L35), so it seems to also make sense to have the corresponding `grpc_server_destroy` in the `__dealloc__` method.What I think the root issue described in #17258 is that you are observing that sometimes `__dealloc__` isn't called. It seems like this is expected behavior for the garbage collector: see https://stackoverflow.com/questions/15974561/i-cant-get-dealloc-be-called-when-deleting-an-object, and also one of the reasons Nathaniel dropped `Channel.__dealloc__` when the channel close method was introduced.So, it seems like this PR is trying to get around this garbage collection behavior by forcing `__dealloc__` to be called - I'm not sure this will work 100% of the time, and even if so, whether this is the correct solution as opposed to something like moving towards the `close()` direction chosen for client-side channels.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17280,236392597,2018-11-26T19:22:56Z,tools/distrib/pylint_code.sh,"@@ -46,4 +46,10 @@ for dir in ""${TEST_DIRS[@]}""; do   $PYTHON -m pylint --rcfile=.pylintrc-tests -rn ""$dir"" || EXIT=1 done +find examples/python \+  -iname ""*.py"" \+  -not -name ""*_pb2.py"" \+  -not -name ""*_pb2_grpc.py"" \+  | xargs $PYTHON -m pylint --rcfile=.pylintrc-tests -rn","Good point. I use the `.pylintrc-tests` because they share most of the disabling rules, and adding another set of rules will result in increasing complexity of the code formatting mechanism. How about using one `pylintrc` file for both tests and examples, like renaming to `.pylintrc-tests-examples` or `.pylintrc-peripheral`?  ",OK
28123841,guantaol,https://api.github.com/repos/grpc/grpc/pulls/17244,236487939,2018-11-27T01:11:07Z,src/core/lib/iomgr/tcp_posix.cc,"@@ -260,10 +260,17 @@ static void notify_on_write(grpc_tcp* tcp) {   if (grpc_tcp_trace.enabled()) {     gpr_log(GPR_INFO, ""TCP:%p notify_on_write"", tcp);   }-  cover_self(tcp);-  GRPC_CLOSURE_INIT(&tcp->write_done_closure,-                    tcp_drop_uncovered_then_handle_write, tcp,-                    grpc_schedule_on_exec_ctx);+  if (grpc_event_engine_run_in_background()) {","So I think it should be fine to call grpc_event_engine_run_in_background() in the if condition, right? Given that grpc_event_engine_run_in_background() only accesses a boolean member of a global struct, it should not be very costly.",OK
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/17266,236544948,2018-11-27T07:27:26Z,src/python/grpcio/grpc/_cython/_cygrpc/channelz.pyx.pxi,"@@ -0,0 +1,58 @@+# Copyright 2018 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++cdef class Channelz:",Why is this a class? All the functions seem stateless. Please just make them module-scoped functions. Emulating Java in Python is not a good idea.,OK
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/17266,236545328,2018-11-27T07:29:08Z,src/python/grpcio/grpc/_cython/_cygrpc/channelz.pyx.pxi,"@@ -0,0 +1,58 @@+# Copyright 2018 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++cdef class Channelz:++    def GetTopChannels(self, start_channel_id):","Please name the functions `snake_case` like the rest of the code base. The only exception would be the actual `Servicer` implementation class, which adheres to different conventions due to the way the protobuf stub layer works. The functions in this file are internal and should be `snake_cased` instead.",OK
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/17266,236545538,2018-11-27T07:30:03Z,src/python/grpcio/grpc/_cython/_cygrpc/channelz.pyx.pxi,"@@ -0,0 +1,58 @@+# Copyright 2018 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++cdef class Channelz:++    def GetTopChannels(self, start_channel_id):+        cdef char *c_returned_str = grpc_channelz_get_top_channels(start_channel_id)+        if c_returned_str == NULL:+            raise ValueError('Failed to get top channels, please ensure your start_channel_id==%s is valid' % start_channel_id)+        return c_returned_str+    +    def GetServers(self, start_server_id):+        cdef char *c_returned_str = grpc_channelz_get_servers(start_server_id)+        if c_returned_str == NULL:+            raise ValueError('Failed to get servers, please ensure your start_server_id==%s is valid' % start_server_id)","I'm still unclear on the `except` semantics of Cython. Will this propagate automatically as the function is declared `def` and not `cdef`? If not, would `except *` annotation be necessary?",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/17266,236546517,2018-11-27T07:34:19Z,src/python/grpcio/grpc/_cython/_cygrpc/grpc.pxi,"@@ -21,6 +21,7 @@ ctypedef unsigned char uint8_t ctypedef int int32_t ctypedef unsigned uint32_t ctypedef long int64_t+ctypedef ssize_t intptr_t",Any reason we are defining these here? Please consider replacing this typedef (and the above) with `from libc.stdint cimport intptr_t` instead of redefining here if nothing breaks. [`libc.stdint` in Cython](https://github.com/cython/cython/blob/master/Cython/Includes/libc/stdint.pxd) already has these definitions.,OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17266,236791258,2018-11-27T18:31:56Z,src/python/grpcio/grpc/_cython/_cygrpc/channelz.pyx.pxi,"@@ -0,0 +1,58 @@+# Copyright 2018 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++cdef class Channelz:++    def GetTopChannels(self, start_channel_id):+        cdef char *c_returned_str = grpc_channelz_get_top_channels(start_channel_id)+        if c_returned_str == NULL:+            raise ValueError('Failed to get top channels, please ensure your start_channel_id==%s is valid' % start_channel_id)+        return c_returned_str+    +    def GetServers(self, start_server_id):+        cdef char *c_returned_str = grpc_channelz_get_servers(start_server_id)+        if c_returned_str == NULL:+            raise ValueError('Failed to get servers, please ensure your start_server_id==%s is valid' % start_server_id)","In my tests, under only one scenario will Cython ignore the exceptions in functions, it is `cdef` member function of a `cdef class` which is not returning Python object. So, it doesn't require `except *` here.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17266,236869820,2018-11-27T22:19:00Z,src/python/grpcio_tests/tests/channelz/_channelz_servicer_test.py,"@@ -0,0 +1,412 @@+# Copyright 2018 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Tests of grpc_channelz.v1.channelz.""""""++import unittest++from concurrent import futures++import grpc+from grpc_channelz.v1 import channelz+from grpc_channelz.v1 import channelz_pb2+from grpc_channelz.v1 import channelz_pb2_grpc++from tests.unit import test_common+from tests.unit.framework.common import test_constants++_SUCCESSFUL_UNARY_UNARY = '/test/SuccessfulUnaryUnary'+_FAILED_UNARY_UNARY = '/test/FailedUnaryUnary'+_SUCCESSFUL_STREAM_STREAM = '/test/SuccessfulStreamStream'++_REQUEST = b'\x00\x00\x00'+_RESPONSE = b'\x01\x01\x01'++_DISABLE_REUSE_PORT = (('grpc.so_reuseport', 0),)+_ENABLE_CHANNELZ = (('grpc.enable_channelz', 1),)+_DISABLE_CHANNELZ = (('grpc.enable_channelz', 0),)+++def _successful_unary_unary(request, servicer_context):+    return _RESPONSE+++def _failed_unary_unary(request, servicer_context):+    servicer_context.set_code(grpc.StatusCode.INTERNAL)+    servicer_context.set_details(""Channelz Test Intended Failure"")+++def _successful_stream_stream(request_iterator, servicer_context):+    for _ in request_iterator:+        yield _RESPONSE+++class _GenericHandler(grpc.GenericRpcHandler):++    def service(self, handler_call_details):+        if handler_call_details.method == _SUCCESSFUL_UNARY_UNARY:+            return grpc.unary_unary_rpc_method_handler(_successful_unary_unary)+        elif handler_call_details.method == _FAILED_UNARY_UNARY:+            return grpc.unary_unary_rpc_method_handler(_failed_unary_unary)+        elif handler_call_details.method == _SUCCESSFUL_STREAM_STREAM:+            return grpc.stream_stream_rpc_method_handler(+                _successful_stream_stream)+        else:+            return None+++class _ChannelServerPair(object):++    def __init__(self):+        # Server will not enable channelz service+        # Bind as attribute to make it gc properly+        self._server = grpc.server(+            futures.ThreadPoolExecutor(max_workers=3),+            options=_DISABLE_REUSE_PORT + _ENABLE_CHANNELZ)","My bad, the comment is wrong, fixed in new commit.",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/17266,237153335,2018-11-28T16:12:58Z,src/python/grpcio_channelz/grpc_channelz/v1/channelz.py,"@@ -0,0 +1,114 @@+# Copyright 2018 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Channelz debug service implementation in gRPC Python.""""""++import grpc+from grpc._cython import cygrpc++import grpc_channelz.v1.channelz_pb2 as _channelz_pb2+import grpc_channelz.v1.channelz_pb2_grpc as _channelz_pb2_grpc++from google.protobuf import json_format+++class ChannelzServicer(_channelz_pb2_grpc.ChannelzServicer):+    """"""Servicer handling RPCs for service statuses.""""""++    # pylint: disable=no-self-use+    def GetTopChannels(self, request, context):+        try:+            return json_format.Parse(+                cygrpc.channelz_get_top_channels(request.start_channel_id),+                _channelz_pb2.GetTopChannelsResponse(),+            )+        except ValueError as e:+            context.set_code(grpc.StatusCode.INVALID_ARGUMENT)+            context.set_details(str(e))++    # pylint: disable=no-self-use+    def GetServers(self, request, context):+        try:+            return json_format.Parse(+                cygrpc.channelz_get_servers(request.start_server_id),+                _channelz_pb2.GetServersResponse(),+            )+        except ValueError as e:+            context.set_code(grpc.StatusCode.INVALID_ARGUMENT)+            context.set_details(str(e))++    # pylint: disable=no-self-use+    def GetServer(self, request, context):+        try:+            return json_format.Parse(+                cygrpc.channelz_get_server(request.server_id),+                _channelz_pb2.GetServerResponse(),+            )+        except ValueError as e:+            context.set_code(grpc.StatusCode.INVALID_ARGUMENT)","From the spec, this should be NOT_FOUNDsee https://github.com/grpc/proposal/blob/master/A14-channelz.md#getserver",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/17266,237154745,2018-11-28T16:16:04Z,src/python/grpcio_channelz/grpc_channelz/v1/channelz.py,"@@ -0,0 +1,114 @@+# Copyright 2018 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Channelz debug service implementation in gRPC Python.""""""++import grpc+from grpc._cython import cygrpc++import grpc_channelz.v1.channelz_pb2 as _channelz_pb2+import grpc_channelz.v1.channelz_pb2_grpc as _channelz_pb2_grpc++from google.protobuf import json_format+++class ChannelzServicer(_channelz_pb2_grpc.ChannelzServicer):+    """"""Servicer handling RPCs for service statuses.""""""++    # pylint: disable=no-self-use+    def GetTopChannels(self, request, context):+        try:+            return json_format.Parse(","What happens if this parse fails? Is an exception raised?This would only happen if core was returning misformattesd JSON, but I would rather be safe agains that it possible. C++ layer handles bad JSON and returns INTERNAL",
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17266,237177217,2018-11-28T17:06:49Z,src/python/grpcio_channelz/grpc_channelz/v1/channelz.py,"@@ -0,0 +1,114 @@+# Copyright 2018 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Channelz debug service implementation in gRPC Python.""""""++import grpc+from grpc._cython import cygrpc++import grpc_channelz.v1.channelz_pb2 as _channelz_pb2+import grpc_channelz.v1.channelz_pb2_grpc as _channelz_pb2_grpc++from google.protobuf import json_format+++class ChannelzServicer(_channelz_pb2_grpc.ChannelzServicer):+    """"""Servicer handling RPCs for service statuses.""""""++    # pylint: disable=no-self-use+    def GetTopChannels(self, request, context):+        try:+            return json_format.Parse(","I believe it will be caught [here](https://github.com/grpc/grpc/blob/aa00e06b65c2e238e6c178134f964ea269a2231b/src/python/grpcio/grpc/_server.py#L398) in the python server implementation and, by default, converted to UNKNOWN. Matching C++'s behavior here and returning INTERNAL here sounds good. json_format.Parse will throw a [`ParseError`](https://github.com/protocolbuffers/protobuf/blob/f22be4ddb0c8b8f81f84d106c74a812ee87f4c6b/python/google/protobuf/json_format.py#L395) which can be caught here.",
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17266,237213287,2018-11-28T18:46:53Z,src/python/grpcio/grpc/_server.py,"@@ -828,7 +828,9 @@ def stop(self, grace):         return _stop(self._state, grace)      def __del__(self):-        _stop(self._state, None)+        if hasattr(self, '_state'):","This is not the same content as https://github.com/grpc/grpc/pull/17259, which still needs further review/investigation. Please don't embed one active PR into another without calling attention to this fact somewhere (e.g., ""this depends on a bug fix in #..."").Another option would be to adjust the unit tests here to take into account current (albeit suboptimal) behavior, which we believe to still be possible even with the call to `del` here anyways. How many tests rely on this?",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17266,237229220,2018-11-28T19:32:10Z,src/python/grpcio/grpc/_server.py,"@@ -828,7 +828,9 @@ def stop(self, grace):         return _stop(self._state, grace)      def __del__(self):-        _stop(self._state, None)+        if hasattr(self, '_state'):","5 tests maybe affected by this change, all the tests involving a gRPC server. I don't think testing based on a faulty behavior is a good idea. It is hackable to make it pass. We can count how many server is created and use a counter to label as removed.The `del` need to be called during the deconstruction process to trigger the `__dealloc__` in Cython. Calling the `del _server._state` inside the unit test will be a noop. Also, the added condition is for checking the existence of `_state`, without it, CPython will complain:```Exception AttributeError: ""'_Server' object has no attribute '_state'"" in <bound method _ChannelServerPair.__del__ of <__main__._ChannelServerPair object at 0x109b7e090>> ignoredException AttributeError: ""'_Server' object has no attribute '_state'"" in <bound method _Server.__del__ of <grpc._server._Server object at 0x109b7e110>> ignoredException AttributeError: ""'_Server' object has no attribute '_state'"" in <bound method _Server.__del__ of <grpc._server._Server object at 0x109b7ea50>> ignored```I didn't add this check in #17259, because Google version of Python doesn't complain.Do you think adding a comment can be a valid option here?```# TODO(lidiz): Depends on issue #17258 which is not solved yet```",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17316,237233387,2018-11-28T19:43:49Z,bazel/grpc_deps.bzl,"@@ -8,6 +8,11 @@ def grpc_deps():         actual = ""@com_github_nanopb_nanopb//:nanopb"",     ) +    native.bind(","Okay, as long as we have a viable story that will eventually allow this to work with both, that's fine.",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/17317,237248603,2018-11-28T20:28:46Z,AUTHORS,"@@ -1,2 +1,3 @@+Dropbox, Inc.","@lidizheng Please check the [contribution guidelines](https://github.com/grpc/grpc/blob/master/CONTRIBUTING.md#guidelines-for-pull-requests) which specifically tells you to do it in a change PR so you can at least find an associated change (although it would have been ideal for that to have been added in various larger changes like dynamic SSL, etc., but it's never too late).> If you have non-trivial contributions, please consider adding an entry to the AUTHORS file listing the copyright holder for the contribution (yourself, if you are signing the individual CLA, or your company, for corporate CLAs) **in the same PR** as your contribution. This needs to be done only once, for each company, or individual.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17323,237285711,2018-11-28T22:24:36Z,src/core/lib/gprpp/inlined_vector.h,"@@ -158,17 +168,13 @@ class InlinedVector {     v.init_data();   } -  size_t size() const { return size_; }-  bool empty() const { return size_ == 0; }--  size_t capacity() const { return capacity_; }--  void clear() {-    destroy_elements();-    init_data();+  static void move_elements(T* src, T* dst, size_t num_elements) {+    for (size_t i = 0; i < num_elements; ++i) {+      new (&dst[i]) T(std::move(src[i]));+      src[i].~T();","The move operation resets the contents of the source object but does not destroy it.  There could be an object whose move semantics leave some internal data structure allocated that is not cleaned up until destruction time, so we need to call the dtor here.",
8228229,kkm000,https://api.github.com/repos/grpc/grpc/pulls/14684,237377995,2018-11-29T07:38:40Z,examples/csharp/Helloworld/GreeterClient/GreeterClient.csproj,"@@ -1,12 +1,8 @@-﻿<Project Sdk=""Microsoft.NET.Sdk"">+<Project Sdk=""Microsoft.NET.Sdk"">    <PropertyGroup>-    <AssemblyTitle>GreeterClient</AssemblyTitle>","The thing is, there is a dozen or more parameters set by the build process, based one on the other, with sensible defaults. This randomly changes one of them--to its default (all of these base off the directory name in the end). So it just looked kind of random to me.EDIT: This is in line with the SDK philosophy: the ""classic"" VS-maintained .csproj files became a monstrosity, so they decided to make these files for the SDK as simple as possible for human manipulation (as much as XML allows for that); basically, add sources and it ""just works"". And even the ""add sources"" is still automatic by default, although rather un-hermetizing, to say the least.",
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17266,237638039,2018-11-29T19:59:21Z,src/python/grpcio_channelz/grpc_channelz/v1/channelz.py,"@@ -0,0 +1,129 @@+# Copyright 2018 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Channelz debug service implementation in gRPC Python.""""""++import grpc+from grpc._cython import cygrpc++import grpc_channelz.v1.channelz_pb2 as _channelz_pb2+import grpc_channelz.v1.channelz_pb2_grpc as _channelz_pb2_grpc++from google.protobuf import json_format+++class ChannelzServicer(_channelz_pb2_grpc.ChannelzServicer):+    """"""Servicer handling RPCs for service statuses.""""""++    @staticmethod+    def GetTopChannels(request, context):+        try:+            return json_format.Parse(+                cygrpc.channelz_get_top_channels(request.start_channel_id),+                _channelz_pb2.GetTopChannelsResponse(),+            )+        except (ValueError, json_format.ParseError) as e:+            context.set_code(grpc.StatusCode.INTERNAL)+            context.set_details(str(e))++    @staticmethod+    def GetServers(request, context):+        try:+            return json_format.Parse(+                cygrpc.channelz_get_servers(request.start_server_id),+                _channelz_pb2.GetServersResponse(),+            )+        except (ValueError, json_format.ParseError) as e:+            context.set_code(grpc.StatusCode.INTERNAL)+            context.set_details(str(e))++    @staticmethod+    def GetServer(request, context):+        try:+            return json_format.Parse(+                cygrpc.channelz_get_server(request.server_id),+                _channelz_pb2.GetServerResponse(),+            )+        except ValueError as e:+            context.set_code(grpc.StatusCode.NOT_FOUND)+            context.set_details(str(e))+        except json_format.ParseError as e:+            context.set_code(grpc.StatusCode.INTERNAL)+            context.set_details(str(e))++    @staticmethod+    def GetServerSockets(request, context):+        try:+            return json_format.Parse(+                cygrpc.channelz_get_server_sockets(request.server_id,+                                                   request.start_socket_id),+                _channelz_pb2.GetServerSocketsResponse(),+            )+        except ValueError as e:+            context.set_code(grpc.StatusCode.NOT_FOUND)+            context.set_details(str(e))+        except json_format.ParseError as e:+            context.set_code(grpc.StatusCode.INTERNAL)+            context.set_details(str(e))++    @staticmethod+    def GetChannel(request, context):+        try:+            return json_format.Parse(+                cygrpc.channelz_get_channel(request.channel_id),+                _channelz_pb2.GetChannelResponse(),+            )+        except ValueError as e:+            context.set_code(grpc.StatusCode.NOT_FOUND)+            context.set_details(str(e))+        except json_format.ParseError as e:+            context.set_code(grpc.StatusCode.INTERNAL)+            context.set_details(str(e))++    @staticmethod+    def GetSubchannel(request, context):+        try:+            return json_format.Parse(+                cygrpc.channelz_get_subchannel(request.subchannel_id),+                _channelz_pb2.GetSubchannelResponse(),+            )+        except ValueError as e:+            context.set_code(grpc.StatusCode.NOT_FOUND)+            context.set_details(str(e))+        except json_format.ParseError as e:+            context.set_code(grpc.StatusCode.INTERNAL)+            context.set_details(str(e))++    @staticmethod+    def GetSocket(request, context):+        try:+            return json_format.Parse(+                cygrpc.channelz_get_socket(request.socket_id),+                _channelz_pb2.GetSocketResponse(),+            )+        except ValueError as e:+            context.set_code(grpc.StatusCode.NOT_FOUND)+            context.set_details(str(e))+        except json_format.ParseError as e:+            context.set_code(grpc.StatusCode.INTERNAL)+            context.set_details(str(e))+++def enable_channelz(server):+    """"""Enables Channelz on a server.",@lidizheng Please update the docstring too. @ncteisen core's channelz APIs are not exactly labeled as experimental but described as subject to churn [here](https://github.com/grpc/grpc/blob/5cf95f0b52c21e6ebd0a7917d619da7b545d86c7/include/grpc/grpc.h). Two questions:(1) Should we add a test here that will fail if Core ever switches the default back to disabled?(2) Should this Python API be itself labeled as experimental?,
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17266,237650740,2018-11-29T20:41:22Z,src/python/grpcio_channelz/grpc_channelz/v1/channelz.py,"@@ -0,0 +1,129 @@+# Copyright 2018 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Channelz debug service implementation in gRPC Python.""""""++import grpc+from grpc._cython import cygrpc++import grpc_channelz.v1.channelz_pb2 as _channelz_pb2+import grpc_channelz.v1.channelz_pb2_grpc as _channelz_pb2_grpc++from google.protobuf import json_format+++class ChannelzServicer(_channelz_pb2_grpc.ChannelzServicer):+    """"""Servicer handling RPCs for service statuses.""""""++    @staticmethod+    def GetTopChannels(request, context):+        try:+            return json_format.Parse(+                cygrpc.channelz_get_top_channels(request.start_channel_id),+                _channelz_pb2.GetTopChannelsResponse(),+            )+        except (ValueError, json_format.ParseError) as e:+            context.set_code(grpc.StatusCode.INTERNAL)+            context.set_details(str(e))++    @staticmethod+    def GetServers(request, context):+        try:+            return json_format.Parse(+                cygrpc.channelz_get_servers(request.start_server_id),+                _channelz_pb2.GetServersResponse(),+            )+        except (ValueError, json_format.ParseError) as e:+            context.set_code(grpc.StatusCode.INTERNAL)+            context.set_details(str(e))++    @staticmethod+    def GetServer(request, context):+        try:+            return json_format.Parse(+                cygrpc.channelz_get_server(request.server_id),+                _channelz_pb2.GetServerResponse(),+            )+        except ValueError as e:+            context.set_code(grpc.StatusCode.NOT_FOUND)+            context.set_details(str(e))+        except json_format.ParseError as e:+            context.set_code(grpc.StatusCode.INTERNAL)+            context.set_details(str(e))++    @staticmethod+    def GetServerSockets(request, context):+        try:+            return json_format.Parse(+                cygrpc.channelz_get_server_sockets(request.server_id,+                                                   request.start_socket_id),+                _channelz_pb2.GetServerSocketsResponse(),+            )+        except ValueError as e:+            context.set_code(grpc.StatusCode.NOT_FOUND)+            context.set_details(str(e))+        except json_format.ParseError as e:+            context.set_code(grpc.StatusCode.INTERNAL)+            context.set_details(str(e))++    @staticmethod+    def GetChannel(request, context):+        try:+            return json_format.Parse(+                cygrpc.channelz_get_channel(request.channel_id),+                _channelz_pb2.GetChannelResponse(),+            )+        except ValueError as e:+            context.set_code(grpc.StatusCode.NOT_FOUND)+            context.set_details(str(e))+        except json_format.ParseError as e:+            context.set_code(grpc.StatusCode.INTERNAL)+            context.set_details(str(e))++    @staticmethod+    def GetSubchannel(request, context):+        try:+            return json_format.Parse(+                cygrpc.channelz_get_subchannel(request.subchannel_id),+                _channelz_pb2.GetSubchannelResponse(),+            )+        except ValueError as e:+            context.set_code(grpc.StatusCode.NOT_FOUND)+            context.set_details(str(e))+        except json_format.ParseError as e:+            context.set_code(grpc.StatusCode.INTERNAL)+            context.set_details(str(e))++    @staticmethod+    def GetSocket(request, context):+        try:+            return json_format.Parse(+                cygrpc.channelz_get_socket(request.socket_id),+                _channelz_pb2.GetSocketResponse(),+            )+        except ValueError as e:+            context.set_code(grpc.StatusCode.NOT_FOUND)+            context.set_details(str(e))+        except json_format.ParseError as e:+            context.set_code(grpc.StatusCode.INTERNAL)+            context.set_details(str(e))+++def enable_channelz(server):+    """"""Enables Channelz on a server.",Channelz is label EXPERIMENTAL in C++ [channelz_service_plugin.h#L32](https://github.com/grpc/grpc/blob/2a52d0ddef5c9a84e28aeda948eff33e33f0fa79/include/grpcpp/ext/channelz_service_plugin.h#L32).I will update the docstring here to identify it is EXPERIMENTAL as well.,OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17266,237655842,2018-11-29T20:58:05Z,src/python/grpcio_tests/tests/channelz/_channelz_servicer_test.py,"@@ -0,0 +1,476 @@+# Copyright 2018 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Tests of grpc_channelz.v1.channelz.""""""++import unittest++from concurrent import futures++import grpc+from grpc_channelz.v1 import channelz+from grpc_channelz.v1 import channelz_pb2+from grpc_channelz.v1 import channelz_pb2_grpc++from tests.unit import test_common+from tests.unit.framework.common import test_constants++_SUCCESSFUL_UNARY_UNARY = '/test/SuccessfulUnaryUnary'+_FAILED_UNARY_UNARY = '/test/FailedUnaryUnary'+_SUCCESSFUL_STREAM_STREAM = '/test/SuccessfulStreamStream'++_REQUEST = b'\x00\x00\x00'+_RESPONSE = b'\x01\x01\x01'++_DISABLE_REUSE_PORT = (('grpc.so_reuseport', 0),)+_ENABLE_CHANNELZ = (('grpc.enable_channelz', 1),)+_DISABLE_CHANNELZ = (('grpc.enable_channelz', 0),)+++def _successful_unary_unary(request, servicer_context):+    return _RESPONSE+++def _failed_unary_unary(request, servicer_context):+    servicer_context.set_code(grpc.StatusCode.INTERNAL)+    servicer_context.set_details(""Channelz Test Intended Failure"")+++def _successful_stream_stream(request_iterator, servicer_context):+    for _ in request_iterator:+        yield _RESPONSE+++class _GenericHandler(grpc.GenericRpcHandler):++    def service(self, handler_call_details):+        if handler_call_details.method == _SUCCESSFUL_UNARY_UNARY:+            return grpc.unary_unary_rpc_method_handler(_successful_unary_unary)+        elif handler_call_details.method == _FAILED_UNARY_UNARY:+            return grpc.unary_unary_rpc_method_handler(_failed_unary_unary)+        elif handler_call_details.method == _SUCCESSFUL_STREAM_STREAM:+            return grpc.stream_stream_rpc_method_handler(+                _successful_stream_stream)+        else:+            return None+++class _ChannelServerPair(object):++    def __init__(self):+        # Server will enable channelz service+        # Bind as attribute to make it gc properly+        self._server = grpc.server(+            futures.ThreadPoolExecutor(max_workers=3),+            options=_DISABLE_REUSE_PORT + _ENABLE_CHANNELZ)+        port = self._server.add_insecure_port('[::]:0')+        self._server.add_generic_rpc_handlers((_GenericHandler(),))+        self._server.start()++        # Channel will enable channelz service...+        self.channel = grpc.insecure_channel('localhost:%d' % port,+                                             _ENABLE_CHANNELZ)++    def __del__(self):+        self._server.__del__()+        self.channel.close()+++def _generate_channel_server_pairs(n):+    return [_ChannelServerPair() for i in range(n)]+++def _clean_channel_server_pairs(pairs):+    for pair in pairs:+        pair.__del__()+++class ChannelzServicerTest(unittest.TestCase):++    def _send_successful_unary_unary(self, idx):+        _, r = self._pairs[idx].channel.unary_unary(+            _SUCCESSFUL_UNARY_UNARY).with_call(_REQUEST)+        self.assertEqual(r.code(), grpc.StatusCode.OK)++    def _send_failed_unary_unary(self, idx):+        try:+            self._pairs[idx].channel.unary_unary(_FAILED_UNARY_UNARY).with_call(+                _REQUEST)+        except grpc.RpcError:+            return+        else:+            self.fail(""This call supposed to fail"")++    def _send_successful_stream_stream(self, idx):+        response_iterator = self._pairs[idx].channel.stream_stream(+            _SUCCESSFUL_STREAM_STREAM).__call__(+                iter([_REQUEST] * test_constants.STREAM_LENGTH))+        cnt = 0+        for _ in response_iterator:+            cnt += 1+        self.assertEqual(cnt, test_constants.STREAM_LENGTH)++    def _get_channel_id(self, idx):+        """"""Channel id may not be consecutive""""""+        resp = self._channelz_stub.GetTopChannels(+            channelz_pb2.GetTopChannelsRequest(start_channel_id=0))+        self.assertGreater(len(resp.channel), idx)+        return resp.channel[idx].ref.channel_id++    def setUp(self):+        # This server is for Channelz info fetching only+        # It self should not enable Channelz+        self._server = grpc.server(+            futures.ThreadPoolExecutor(max_workers=3),+            options=_DISABLE_REUSE_PORT + _DISABLE_CHANNELZ)+        port = self._server.add_insecure_port('[::]:0')+        channelz_pb2_grpc.add_ChannelzServicer_to_server(+            channelz.ChannelzServicer(),+            self._server,+        )+        self._server.start()++        # This channel is used to fetch Channelz info only+        # Channelz should not be enabled+        self._channel = grpc.insecure_channel('localhost:%d' % port,+                                              _DISABLE_CHANNELZ)+        self._channelz_stub = channelz_pb2_grpc.ChannelzStub(self._channel)++    def tearDown(self):+        self._server.__del__()+        self._channel.close()+        # _pairs may not exist, if the test crashed during setup","I set it to an empty list `[]`, so it can be safely passed down to the for loop inside `_clean_channel_server_pairs`.",
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/17303,237682784,2018-11-29T22:25:00Z,templates/tools/dockerfile/test/sanity/Dockerfile.template,"@@ -14,28 +14,22 @@   # See the License for the specific language governing permissions and   # limitations under the License.   -  FROM debian:jessie-  -  <%include file=""../../apt_get_basic.include""/>-  <%include file=""../../gcp_api_libraries.include""/>-  <%include file=""../../python_deps.include""/>+  <%include file=""../../python_stretch.include""/>   <%include file=""../../cxx_deps.include""/>   #========================   # Sanity test dependencies+  RUN apt-get update && apt-get -t testing install -y python3.7 python3-all-dev+  RUN curl https://bootstrap.pypa.io/get-pip.py | python3.7   RUN apt-get update && apt-get install -y ${""\\""}-        python-pip ${""\\""}         autoconf ${""\\""}         automake ${""\\""}         libtool ${""\\""}         curl ${""\\""}-        python-virtualenv ${""\\""}-        python-lxml ${""\\""}         shellcheck-  RUN pip install simplejson mako-  +  RUN python2.7 -m pip install simplejson mako virtualenv lxml",Is there a way we can factor out this package list to a string so we don't have to repeat it?,OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17303,237688701,2018-11-29T22:47:21Z,templates/tools/dockerfile/test/sanity/Dockerfile.template,"@@ -14,28 +14,22 @@   # See the License for the specific language governing permissions and   # limitations under the License.   -  FROM debian:jessie-  -  <%include file=""../../apt_get_basic.include""/>-  <%include file=""../../gcp_api_libraries.include""/>-  <%include file=""../../python_deps.include""/>+  <%include file=""../../python_stretch.include""/>   <%include file=""../../cxx_deps.include""/>   #========================   # Sanity test dependencies+  RUN apt-get update && apt-get -t testing install -y python3.7 python3-all-dev+  RUN curl https://bootstrap.pypa.io/get-pip.py | python3.7   RUN apt-get update && apt-get install -y ${""\\""}-        python-pip ${""\\""}         autoconf ${""\\""}         automake ${""\\""}         libtool ${""\\""}         curl ${""\\""}-        python-virtualenv ${""\\""}-        python-lxml ${""\\""}         shellcheck-  RUN pip install simplejson mako-  +  RUN python2.7 -m pip install simplejson mako virtualenv lxml","Many build scripts install their ad-hoc list of packages, I agree with you that we should have several `requirements.txt` placed in the project, and install packages accordingly.",
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/17303,237691437,2018-11-29T22:58:10Z,tools/dockerfile/test/sanity/Dockerfile,"@@ -53,37 +53,36 @@ RUN apt-get update && apt-get install -y time && apt-get clean RUN apt-get update && apt-get install -y python-pip && apt-get clean RUN pip install --upgrade google-api-python-client oauth2client -#====================-# Python dependencies+# Install Python 2.7+RUN apt-get update && apt-get install -y python2.7 python-all-dev+RUN curl https://bootstrap.pypa.io/get-pip.py | python2.7 -# Install dependencies+# Add Debian 'testing' repository+RUN echo 'deb http://ftp.de.debian.org/debian testing main' >> /etc/apt/sources.list+RUN echo 'APT::Default-Release ""stable"";' | tee -a /etc/apt/apt.conf.d/00local -RUN apt-get update && apt-get install -y \-    python-all-dev \-    python3-all-dev \-    python-pip -# Install Python packages from PyPI-RUN pip install --upgrade pip==10.0.1-RUN pip install virtualenv-RUN pip install futures==2.2.0 enum34==1.0.4 protobuf==3.5.2.post1 six==1.10.0 twisted==17.5.0+RUN mkdir /var/local/jenkins++# Define the default command.+CMD [""bash""]  #================= # C++ dependencies RUN apt-get update && apt-get -y install libgflags-dev libgtest-dev libc++-dev clang && apt-get clean  #======================== # Sanity test dependencies+RUN apt-get update && apt-get -t testing install -y python3.7 python3-all-dev+RUN curl https://bootstrap.pypa.io/get-pip.py | python3.7 RUN apt-get update && apt-get install -y \-      python-pip \       autoconf \       automake \       libtool \       curl \-      python-virtualenv \-      python-lxml \       shellcheck-RUN pip install simplejson mako+RUN python2.7 -m pip install simplejson mako virtualenv lxml","The .template file is in fact the thing that generates the non-template file. So you're in fact maintaining only one list, and the tooling is what outputs this line here automatically.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17354,237992104,2018-11-30T20:24:17Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc,"@@ -645,10 +646,13 @@ static void grpc_resolve_address_invoke_dns_lookup_ares_locked(     void* arg, grpc_error* unused_error) {   grpc_resolve_address_ares_request* r =       static_cast<grpc_resolve_address_ares_request*>(arg);+  // TODO(apolcyn): rather than force default for grpc_resolve_address API,",Looks like we actually already have a TODO for this:https://github.com/grpc/grpc/blob/master/src/core/lib/iomgr/resolve_address.h#L68Feel free to reassign it to yourself instead of adding a duplicate here. :),
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/17104,238031505,2018-11-30T23:18:49Z,include/grpcpp/impl/codegen/client_callback.h,"@@ -88,6 +89,646 @@ class CallbackUnaryCallImpl {     call.PerformOps(ops);   } };+}  // namespace internal++namespace experimental {++// Forward declarations+template <class Request, class Response>+class ClientBidiReactor;+template <class Response>+class ClientReadReactor;+template <class Request>+class ClientWriteReactor;++// NOTE: The streaming objects are not actually implemented in the public API.+//       These interfaces are provided for mocking only. Typical applications+//       will interact exclusively with the reactors that they define.+template <class Request, class Response>+class ClientCallbackReaderWriter {+ public:+  virtual ~ClientCallbackReaderWriter() {}+  virtual void StartCall() = 0;+  virtual void Write(const Request* req, WriteOptions options) = 0;+  virtual void WritesDone() = 0;+  virtual void Read(Response* resp) = 0;++ protected:+  void BindReactor(ClientBidiReactor<Request, Response>* reactor) {+    reactor->BindStream(this);+  }+};++template <class Response>+class ClientCallbackReader {+ public:+  virtual ~ClientCallbackReader() {}+  virtual void StartCall() = 0;+  virtual void Read(Response* resp) = 0;++ protected:+  void BindReactor(ClientReadReactor<Response>* reactor) {+    reactor->BindReader(this);+  }+};++template <class Request>+class ClientCallbackWriter {+ public:+  virtual ~ClientCallbackWriter() {}+  virtual void StartCall() = 0;+  void Write(const Request* req) { Write(req, WriteOptions()); }+  virtual void Write(const Request* req, WriteOptions options) = 0;+  void WriteLast(const Request* req, WriteOptions options) {+    Write(req, options.set_last_message());+  }+  virtual void WritesDone() = 0;++ protected:+  void BindReactor(ClientWriteReactor<Request>* reactor) {+    reactor->BindWriter(this);+  }+};++// The user must implement this reactor interface with reactions to each event+// type that gets called by the library. An empty reaction is provided by+// default+template <class Request, class Response>+class ClientBidiReactor {+ public:+  virtual ~ClientBidiReactor() {}+  virtual void OnDone(const Status& s) {}+  virtual void OnReadInitialMetadataDone(bool ok) {}+  virtual void OnReadDone(bool ok) {}+  virtual void OnWriteDone(bool ok) {}+  virtual void OnWritesDoneDone(bool ok) {}++  void StartCall() { stream_->StartCall(); }+  void StartRead(Response* resp) { stream_->Read(resp); }+  void StartWrite(const Request* req) { StartWrite(req, WriteOptions()); }+  void StartWrite(const Request* req, WriteOptions options) {+    stream_->Write(req, std::move(options));+  }+  void StartWriteLast(const Request* req, WriteOptions options) {+    StartWrite(req, std::move(options.set_last_message()));+  }+  void StartWritesDone() { stream_->WritesDone(); }++ private:+  friend class ClientCallbackReaderWriter<Request, Response>;+  void BindStream(ClientCallbackReaderWriter<Request, Response>* stream) {+    stream_ = stream;+  }+  ClientCallbackReaderWriter<Request, Response>* stream_;+};++template <class Response>+class ClientReadReactor {+ public:+  virtual ~ClientReadReactor() {}+  virtual void OnDone(const Status& s) {}+  virtual void OnReadInitialMetadataDone(bool ok) {}+  virtual void OnReadDone(bool ok) {}++  void StartCall() { reader_->StartCall(); }+  void StartRead(Response* resp) { reader_->Read(resp); }++ private:+  friend class ClientCallbackReader<Response>;+  void BindReader(ClientCallbackReader<Response>* reader) { reader_ = reader; }+  ClientCallbackReader<Response>* reader_;+};++template <class Request>+class ClientWriteReactor {+ public:+  virtual ~ClientWriteReactor() {}+  virtual void OnDone(const Status& s) {}+  virtual void OnReadInitialMetadataDone(bool ok) {}+  virtual void OnWriteDone(bool ok) {}+  virtual void OnWritesDoneDone(bool ok) {}++  void StartCall() { writer_->StartCall(); }+  void StartWrite(const Request* req) { StartWrite(req, WriteOptions()); }+  void StartWrite(const Request* req, WriteOptions options) {+    writer_->Write(req, std::move(options));+  }+  void StartWriteLast(const Request* req, WriteOptions options) {+    StartWrite(req, std::move(options.set_last_message()));+  }+  void StartWritesDone() { writer_->WritesDone(); }++ private:+  friend class ClientCallbackWriter<Request>;+  void BindWriter(ClientCallbackWriter<Request>* writer) { writer_ = writer; }+  ClientCallbackWriter<Request>* writer_;+};++}  // namespace experimental++namespace internal {++// Forward declare factory classes for friendship+template <class Request, class Response>+class ClientCallbackReaderWriterFactory;+template <class Response>+class ClientCallbackReaderFactory;+template <class Request>+class ClientCallbackWriterFactory;++template <class Request, class Response>+class ClientCallbackReaderWriterImpl+    : public ::grpc::experimental::ClientCallbackReaderWriter<Request,+                                                              Response> {+ public:+  // always allocated against a call arena, no memory free required+  static void operator delete(void* ptr, std::size_t size) {+    assert(size == sizeof(ClientCallbackReaderWriterImpl));+  }++  // This operator should never be called as the memory should be freed as part+  // of the arena destruction. It only exists to provide a matching operator+  // delete to the operator new so that some compilers will not complain (see+  // https://github.com/grpc/grpc/issues/11301) Note at the time of adding this+  // there are no tests catching the compiler warning.+  static void operator delete(void*, void*) { assert(0); }++  void MaybeFinish() {+    if (--callbacks_outstanding_ == 0) {+      reactor_->OnDone(finish_status_);+      auto* call = call_.call();+      this->~ClientCallbackReaderWriterImpl();+      g_core_codegen_interface->grpc_call_unref(call);+    }+  }++  void StartCall() override {+    // This call initiates two batches, plus any backlog, each with a callback+    // 1. Send initial metadata (unless corked) + recv initial metadata+    // 2. Any read backlog+    // 3. Recv trailing metadata, on_completion callback+    // 4. Any write backlog+    started_ = true;++    start_tag_.Set(call_.call(),+                   [this](bool ok) {+                     reactor_->OnReadInitialMetadataDone(ok);+                     MaybeFinish();+                   },+                   &start_ops_);+    if (!start_corked_) {+      start_ops_.SendInitialMetadata(&context_->send_initial_metadata_,+                                     context_->initial_metadata_flags());+    }+    start_ops_.RecvInitialMetadata(context_);+    start_ops_.set_core_cq_tag(&start_tag_);+    call_.PerformOps(&start_ops_);++    // Also set up the read and write tags so that they don't have to be set up+    // each time+    write_tag_.Set(call_.call(),+                   [this](bool ok) {+                     reactor_->OnWriteDone(ok);+                     MaybeFinish();+                   },+                   &write_ops_);+    write_ops_.set_core_cq_tag(&write_tag_);++    read_tag_.Set(call_.call(),+                  [this](bool ok) {+                    reactor_->OnReadDone(ok);+                    MaybeFinish();+                  },+                  &read_ops_);+    read_ops_.set_core_cq_tag(&read_tag_);+    if (read_ops_at_start_) {+      call_.PerformOps(&read_ops_);+    }++    finish_tag_.Set(call_.call(), [this](bool ok) { MaybeFinish(); },+                    &finish_ops_);+    finish_ops_.ClientRecvStatus(context_, &finish_status_);+    finish_ops_.set_core_cq_tag(&finish_tag_);+    call_.PerformOps(&finish_ops_);++    if (write_ops_at_start_) {+      call_.PerformOps(&write_ops_);+    }++    if (writes_done_ops_at_start_) {+      call_.PerformOps(&writes_done_ops_);+    }+  }++  void Read(Response* msg) override {+    read_ops_.RecvMessage(msg);+    callbacks_outstanding_++;+    if (started_) {+      call_.PerformOps(&read_ops_);+    } else {+      read_ops_at_start_ = true;+    }+  }++  void Write(const Request* msg, WriteOptions options) override {+    if (start_corked_) {+      write_ops_.SendInitialMetadata(&context_->send_initial_metadata_,+                                     context_->initial_metadata_flags());+      start_corked_ = false;+    }+    // TODO(vjpai): don't assert+    GPR_CODEGEN_ASSERT(write_ops_.SendMessage(*msg).ok());++    if (options.is_last_message()) {+      options.set_buffer_hint();+      write_ops_.ClientSendClose();+    }+    callbacks_outstanding_++;+    if (started_) {+      call_.PerformOps(&write_ops_);+    } else {+      write_ops_at_start_ = true;+    }+  }+  void WritesDone() override {+    if (start_corked_) {+      writes_done_ops_.SendInitialMetadata(&context_->send_initial_metadata_,+                                           context_->initial_metadata_flags());+      start_corked_ = false;+    }+    writes_done_ops_.ClientSendClose();+    writes_done_tag_.Set(call_.call(),+                         [this](bool ok) {+                           reactor_->OnWritesDoneDone(ok);","In practice, I don't expect people to override this. I'm not a big fan either, but it's consistent with the other uses.",OK
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/17303,238049905,2018-12-01T03:04:58Z,.pylintrc,"@@ -82,3 +82,8 @@ disable= 	# if:/else: and for:/else:. 	useless-else-on-loop, 	no-else-return,+	useless-object-inheritance,","Are you certain that you want to globally disable these warnings? If there are specific issues, you should favor refactoring and/or suppressing warnings at those specific code points, not a global suppression. As you can see all of the above suppressions are either accompanied with justifications (or rationalization depending on your PoV) or TODO's. You shouldn't suppress warnings globally just because they are hard to fix. Ideally we should remove from this list, not add it. Some issues were grandfathered because `pylint` was introduced relatively late to the process.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/17348,238075853,2018-12-01T20:34:47Z,src/ruby/lib/grpc/generic/rpc_server.rb,"@@ -354,6 +354,51 @@ def run      alias_method :run_till_terminated, :run +    # runs the server with signal handlers+    def run_till_terminated_or_interrupted(signals)+      valid_signals = Signal.list++      stop_server = false+      stop_server_cv = ConditionVariable.new+      stop_server_mu = Mutex.new+      stop_server_thread = Thread.new do+        loop do+          break if stop_server+          stop_server_mu.synchronize { stop_server_cv.wait(stop_server_mu, 60) }",please make this wait interval parameterized,OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/17350,238461157,2018-12-03T22:21:30Z,src/proto/grpc/testing/simple_messages.proto,"@@ -0,0 +1,26 @@++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++syntax = ""proto3"";++package grpc.testing;++message SimpleRequest {+  string message = 1;","If this message field isn't actually used in this request, why is it present? Just let this be an empty message (no members). Or alternatively, make the message have the expected key and value so that the test case isn't just bound to the constant metadata value.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17367,238464368,2018-12-03T22:31:49Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -2188,6 +2191,7 @@ static void on_complete(void* arg, grpc_error* error) {                                                   &closures);     }   }+  calld->call_combiner->TsanUnlock();","How do we know that this is the right place to put this?  At first glance, I would think it needs to go further down, because we are still accessing data in `calld` that is protected by the call combiner.  (Technically, we should probably do this inside of `CallCombinerClosureList::RunClosures()`.)Note that I am asking here less in terms of how we know this is right in this specific case and more in terms of how an engineer seeing this in the future will decide where to put it.  Or, to say this another way, we need to improve the documentation on the `TsanLock()` and `TsanUnlock()` API so that future engineers can figure out how it's actually supposed to be used.",OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/17350,238474083,2018-12-03T23:08:00Z,src/proto/grpc/testing/simple_messages.proto,"@@ -0,0 +1,26 @@++// Copyright 2018 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++syntax = ""proto3"";++package grpc.testing;++message SimpleRequest {+  string message = 1;","I think we talked about this before, but the reason why I am using a constant metadata value here rather than putting the expected value in the message is because I don't want to communicate the expected value through the same mechanism that I'm testing. If there's something wrong with the mechanism, then we could end up with a false positive test result. ",
21096727,toc007,https://api.github.com/repos/grpc/grpc/pulls/17348,238487173,2018-12-04T00:08:26Z,src/ruby/lib/grpc/generic/rpc_server.rb,"@@ -354,6 +354,51 @@ def run      alias_method :run_till_terminated, :run +    # runs the server with signal handlers+    def run_till_terminated_or_interrupted(signals)+      valid_signals = Signal.list++      stop_server = false+      stop_server_cv = ConditionVariable.new+      stop_server_mu = Mutex.new+      stop_server_thread = Thread.new do+        loop do+          break if stop_server+          stop_server_mu.synchronize { stop_server_cv.wait(stop_server_mu, 60) }",Parameterized to run_till_terminated_or_interrupted. Added an optional parameter for user to specify the timeout.,OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17367,238526862,2018-12-04T04:30:53Z,include/grpc/support/dynamic_annotations.h,"@@ -0,0 +1,67 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_SUPPORT_DYNAMIC_ANNOTATIONS_H+#define GRPC_SUPPORT_DYNAMIC_ANNOTATIONS_H++#include <grpc/support/port_platform.h>++#ifdef GRPC_TSAN_ENABLED++#define TSAN_ANNOTATE_HAPPENS_BEFORE(addr) \+  AnnotateHappensBefore(__FILE__, __LINE__, (void*)(addr))+#define TSAN_ANNOTATE_HAPPENS_AFTER(addr) \+  AnnotateHappensAfter(__FILE__, __LINE__, (void*)(addr))+#define TSAN_ANNOTATE_RWLOCK_CREATE(addr) \+  AnnotateRWLockCreate(__FILE__, __LINE__, (void*)(addr))+#define TSAN_ANNOTATE_RWLOCK_DESTROY(addr) \+  AnnotateRWLockDestroy(__FILE__, __LINE__, (void*)(addr))+#define TSAN_ANNOTATE_RWLOCK_ACQUIRED(addr, is_w) \+  AnnotateRWLockAcquired(__FILE__, __LINE__, (void*)(addr), (is_w))+#define TSAN_ANNOTATE_RWLOCK_RELEASED(addr, is_w) \+  AnnotateRWLockReleased(__FILE__, __LINE__, (void*)(addr), (is_w))++#ifdef __cplusplus+extern ""C"" {+#endif+void AnnotateHappensBefore(const char* file, int line, const volatile void* cv);","That's a great question. So, there is not much document on this, but I'm vaguely familiar with the history. These functions are historically from Helgrind, that would basically use the following state machine to detect races:http://valgrind.org/docs/manual/hg-manual.html#hg-manual.data-races.algorithmThese used to be weak symbols and linked by valgrind.tsan used the same annotations and mechanisms, basically using identical function calls, but with a nice idea. These functions are translated into tsan instructions at compiled time and removed completely by clang and gcc when compiled using tsan. In other words, they don't have to be implemented, and unfortunately they don't have any headers to include.Some libraries provide a default empty implementation for these functions in case they wanted to change the implementation at link time. I didn't add those because I thought they are not necessary, but if you think that would help readability, I'm happy to add those. Please let me know.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17368,238714559,2018-12-04T15:38:17Z,src/core/lib/iomgr/call_combiner.cc,"@@ -39,10 +39,42 @@ static gpr_atm encode_cancel_state_error(grpc_error* error) {   return static_cast<gpr_atm>(1) | (gpr_atm)error; } +#ifdef GRPC_TSAN_ENABLED+static void tsan_closure(void* user_data, grpc_error* error) {+  grpc_call_combiner* call_combiner =+      static_cast<grpc_call_combiner*>(user_data);+  grpc_core::RefCountedPtr<grpc_call_combiner::TsanLock> lock;+  if (!call_combiner->tsan_lock->taken.load(std::memory_order_relaxed)) {+    lock = call_combiner->tsan_lock;+    TSAN_ANNOTATE_RWLOCK_ACQUIRED(lock.get(), true);+    lock->taken.store(true, std::memory_order_relaxed);+  }+  GRPC_CLOSURE_RUN(call_combiner->original_closure, GRPC_ERROR_REF(error));+  if (lock != nullptr) {+    lock->taken.store(false, std::memory_order_relaxed);+    TSAN_ANNOTATE_RWLOCK_RELEASED(lock.get(), true);+  }+}+#endif++static void combiner_sched_closure(grpc_call_combiner* combiner,","Please change ""combiner"" to ""call_combiner"" in both the function name and the name of the first parameter.  (Confusingly, we have a separate data structure called combiner, which is actually unrelated to call_combiner.)",OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17368,238829571,2018-12-04T20:40:02Z,src/core/lib/iomgr/call_combiner.cc,"@@ -39,10 +39,42 @@ static gpr_atm encode_cancel_state_error(grpc_error* error) {   return static_cast<gpr_atm>(1) | (gpr_atm)error; } +#ifdef GRPC_TSAN_ENABLED+static void tsan_closure(void* user_data, grpc_error* error) {+  grpc_call_combiner* call_combiner =+      static_cast<grpc_call_combiner*>(user_data);+  grpc_core::RefCountedPtr<grpc_call_combiner::TsanLock> lock;+  if (!call_combiner->tsan_lock->taken.load(std::memory_order_relaxed)) {+    lock = call_combiner->tsan_lock;+    TSAN_ANNOTATE_RWLOCK_ACQUIRED(lock.get(), true);+    lock->taken.store(true, std::memory_order_relaxed);+  }+  GRPC_CLOSURE_RUN(call_combiner->original_closure, GRPC_ERROR_REF(error));","That's a good question. If the callback is scheduled via the call_combiner's start/finish, we will get the locking annotations, but if they go via other mechanism and happen to access the fields in parallel to other threads, these annotations wouldn't help. Running all the TSAN tests, I don't think we have a case where TSAN is complaining about. If later we hit an error like that, we would need to add an extra API for such callbacks (either explicit lock/unlock or something like call_combiner_sched_closure).",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/17370,238886270,2018-12-04T23:57:17Z,src/core/lib/security/security_connector/local/local_security_connector.cc,"@@ -124,19 +129,51 @@ static grpc_security_status local_auth_context_create(grpc_auth_context** ctx) { }  static void local_check_peer(grpc_security_connector* sc, tsi_peer peer,+                             grpc_endpoint* ep,                              grpc_auth_context** auth_context,                              grpc_closure* on_peer_checked) {+  int fd = grpc_endpoint_get_fd(ep);+  grpc_resolved_address resolved_addr;+  resolved_addr.len = static_cast<socklen_t>(sizeof(struct sockaddr_storage));+  bool is_endpoint_ok = false;+  if (getsockname(fd, reinterpret_cast<grpc_sockaddr*>(resolved_addr.addr),+                  &resolved_addr.len) == 0) {+    grpc_sockaddr_in* addr4 =+        reinterpret_cast<grpc_sockaddr_in*>(resolved_addr.addr);+    grpc_sockaddr_in6* addr6 =+        reinterpret_cast<grpc_sockaddr_in6*>(resolved_addr.addr);+    // UDS+    if (grpc_is_unix_socket(&resolved_addr)) {+      is_endpoint_ok = true;",nit: renaming to is_endpoint_local has better readability,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17393,239048693,2018-12-05T12:40:47Z,tools/internal_ci/linux/grpc_run_tests_matrix.sh,"@@ -22,6 +22,7 @@ source tools/internal_ci/helper_scripts/prepare_build_linux_rc  # If this is a PR using RUN_TESTS_FLAGS var, then add flags to filter tests if [ -n ""$KOKORO_GITHUB_PULL_REQUEST_NUMBER"" ] && [ -n ""$RUN_TESTS_FLAGS"" ]; then+  sudo apt-get update","nit: installing this here is pretty dirty, ideally we would do this in a cleaner way. Let's keep this in mind when addressing technical debt.",OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17401,239218756,2018-12-05T20:06:16Z,src/core/lib/surface/server.cc,"@@ -1433,30 +1448,40 @@ static grpc_call_error queue_call_request(grpc_server* server, size_t cq_idx,       rm = &rc->data.registered.method->matcher;       break;   }-  if (gpr_locked_mpscq_push(&rm->requests_per_cq[cq_idx], &rc->request_link)) {-    /* this was the first queued request: we need to lock and start-       matching calls */-    gpr_mu_lock(&server->mu_call);-    while ((calld = rm->pending_head) != nullptr) {-      rc = reinterpret_cast<requested_call*>(-          gpr_locked_mpscq_pop(&rm->requests_per_cq[cq_idx]));-      if (rc == nullptr) break;-      rm->pending_head = calld->pending_next;-      gpr_mu_unlock(&server->mu_call);-      if (!gpr_atm_full_cas(&calld->state, PENDING, ACTIVATED)) {-        // Zombied Call-        GRPC_CLOSURE_INIT(-            &calld->kill_zombie_closure, kill_zombie,-            grpc_call_stack_element(grpc_call_get_call_stack(calld->call), 0),-            grpc_schedule_on_exec_ctx);-        GRPC_CLOSURE_SCHED(&calld->kill_zombie_closure, GRPC_ERROR_NONE);-      } else {-        publish_call(server, calld, cq_idx, rc);-      }-      gpr_mu_lock(&server->mu_call);-    }++  // Fast path: if there is no pending request to be processed, immediately+  // return.+  if (!gpr_locked_mpscq_push(&rm->requests_per_cq[cq_idx], &rc->request_link) ||+      // Note: pending_head is written using order_release in publish_new_rpc().+      //       Here we are reading the pointer without holding the sever call+      //       mutex. The reset of stores and loads in this function are under+      //       server call mutex and can use order_relaxed.+      rm->pending_head.load(std::memory_order_acquire) == nullptr) {","Thank you. Yes, agreed. I was going too pedantic. Also, there are already barriers around this.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17364,239261044,2018-12-05T22:23:23Z,WORKSPACE,"@@ -8,11 +8,12 @@ grpc_deps() grpc_test_only_deps()  register_execution_platforms(-    ""//third_party/toolchains:all"",+    ""//third_party/toolchains:rbe_ubuntu1604"",","Are these changes intentional, or the result of a bad merge?  ISTR that @nicolasnoble was changing this recently.",
3991732,vishalpowar,https://api.github.com/repos/grpc/grpc/pulls/17364,239264059,2018-12-05T22:34:18Z,WORKSPACE,"@@ -8,11 +8,12 @@ grpc_deps() grpc_test_only_deps()  register_execution_platforms(-    ""//third_party/toolchains:all"",+    ""//third_party/toolchains:rbe_ubuntu1604"",","bad merge, fixing it.",
5769600,stevewolter,https://api.github.com/repos/grpc/grpc/pulls/17398,239352926,2018-12-06T07:45:32Z,src/core/lib/security/credentials/google_default/google_default_credentials.cc,"@@ -202,16 +295,25 @@ grpc_channel_credentials* grpc_google_default_credentials_create(void) {   error = grpc_error_add_child(error, err);    gpr_mu_lock(&g_state_mu);-  /* At last try to see if we're on compute engine (do the detection only once-     since it requires a network test). */-  if (!g_compute_engine_detection_done) {-    g_need_compute_engine_creds = g_gce_tenancy_checker();-    g_compute_engine_detection_done = 1;++  /* Try a platform-provided hint for GCE. */+  if (!g_metadata_server_detection_done) {+    g_is_on_gce = g_gce_tenancy_checker();+    g_metadata_server_detection_done = g_is_on_gce;","The two g_metadata_server variables are redundant: Whenever detection_done is true, available is true, and they only differ after flush(), at which time we'll overwrite available before the next read. Should we keep only g_metadata_server_available?",OK
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17384,239509854,2018-12-06T16:02:29Z,src/python/grpcio_status/grpc_status/rpc_status.py,"@@ -0,0 +1,60 @@+# Copyright 2018 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Reference implementation for status mapping in gRPC Python.""""""++import grpc++# Have to import google.protobuf before google.rpc, otherwise Python will fail+#   to locate module rpc under google.","What exactly fails? Why do we need an unused import? Importing just status_pb2 in a local interpreter seems to work fine.Also, and less importantly, I don't think the second line of this comment should have the additional indentation.",OK
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17384,239512532,2018-12-06T16:09:05Z,src/python/grpcio_status/grpc_status/rpc_status.py,"@@ -0,0 +1,60 @@+# Copyright 2018 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Reference implementation for status mapping in gRPC Python.""""""++import grpc++# Have to import google.protobuf before google.rpc, otherwise Python will fail+#   to locate module rpc under google.+import google.protobuf  # pylint: disable=unused-import+from google.rpc import status_pb2++_CODE_TO_GRPC_CODE_MAPPING = dict([(x.value[0], x) for x in grpc.StatusCode])+_GRPC_CODE_TO_CODE_MAPPING = dict([(x, x.value[0]) for x in grpc.StatusCode])++_GRPC_DETAILS_METADATA_KEY = 'grpc-status-details-bin'+++def from_call(call):+    """"""Returns a google.rpc.status.Status message corresponding to a given call.++    Args:+      call: A grpc.Call instance representing an RPC.++    Returns:+      A google.rpc.status.Status message representing the status of the RPC.+    """"""+    for metadatum in call.trailing_metadata():+        if metadatum.key == _GRPC_DETAILS_METADATA_KEY:+            return status_pb2.Status.FromString(metadatum.value)","Please follow Java's behavior here and throw an exception if the code in the `status_pb2` instance does not match the code in the `grpc_status` (i.e., `call.code()`)",
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17384,239519061,2018-12-06T16:25:34Z,src/python/grpcio_status/grpc_status/rpc_status.py,"@@ -0,0 +1,60 @@+# Copyright 2018 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Reference implementation for status mapping in gRPC Python.""""""++import grpc++# Have to import google.protobuf before google.rpc, otherwise Python will fail+#   to locate module rpc under google.+import google.protobuf  # pylint: disable=unused-import+from google.rpc import status_pb2++_CODE_TO_GRPC_CODE_MAPPING = dict([(x.value[0], x) for x in grpc.StatusCode])+_GRPC_CODE_TO_CODE_MAPPING = dict([(x, x.value[0]) for x in grpc.StatusCode])++_GRPC_DETAILS_METADATA_KEY = 'grpc-status-details-bin'+++def from_call(call):+    """"""Returns a google.rpc.status.Status message corresponding to a given call.++    Args:+      call: A grpc.Call instance representing an RPC.++    Returns:+      A google.rpc.status.Status message representing the status of the RPC.+    """"""+    for metadatum in call.trailing_metadata():+        if metadatum.key == _GRPC_DETAILS_METADATA_KEY:+            return status_pb2.Status.FromString(metadatum.value)+    return status_pb2.Status(",Why generate a `status_pb2.Status` instance if none existed in the trailing metadata?,OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/17425,239540074,2018-12-06T17:19:54Z,src/core/lib/debug/trace.h,"@@ -53,7 +53,8 @@ void grpc_tracer_enable_flag(grpc_core::TraceFlag* flag); class TraceFlag {  public:   TraceFlag(bool default_enabled, const char* name);-  ~TraceFlag() {}+  // This needs to be trivially destructible as it is used as global variable.+  ~TraceFlag() = default;",Let me suggest that there's an explicit `static_assert(std::is_trivially_destructible` to make sure that this never arises in the future and that we don't make this a class with virtual destructor etc.,OK
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17384,239544836,2018-12-06T17:33:27Z,src/python/grpcio_status/grpc_status/rpc_status.py,"@@ -0,0 +1,60 @@+# Copyright 2018 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Reference implementation for status mapping in gRPC Python.""""""++import grpc++# Have to import google.protobuf before google.rpc, otherwise Python will fail+#   to locate module rpc under google.+import google.protobuf  # pylint: disable=unused-import+from google.rpc import status_pb2++_CODE_TO_GRPC_CODE_MAPPING = dict([(x.value[0], x) for x in grpc.StatusCode])+_GRPC_CODE_TO_CODE_MAPPING = dict([(x, x.value[0]) for x in grpc.StatusCode])","Can you just use `grpc.StatusCode[code].value[0]` instead of making this mapping? I would prefer something similar instead of `_CODE_TO_GRPC_CODE_MAPPING` as well, but don't immediately see that we have this available (would be very nice if we could do `grpc.StatusCode(0)` instead of `grpc.StatusCode((0, 'ok'))`).",
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/17398,239555429,2018-12-06T18:05:10Z,src/core/lib/security/credentials/google_default/google_default_credentials.cc,"@@ -202,16 +295,25 @@ grpc_channel_credentials* grpc_google_default_credentials_create(void) {   error = grpc_error_add_child(error, err);    gpr_mu_lock(&g_state_mu);-  /* At last try to see if we're on compute engine (do the detection only once-     since it requires a network test). */-  if (!g_compute_engine_detection_done) {-    g_need_compute_engine_creds = g_gce_tenancy_checker();-    g_compute_engine_detection_done = 1;++  /* Try a platform-provided hint for GCE. */+  if (!g_metadata_server_detection_done) {+    g_is_on_gce = g_gce_tenancy_checker();+    g_metadata_server_detection_done = g_is_on_gce;",Good catch. I removed the redundancy by using `g_metadata_server_available` only.,
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/17391,239580936,2018-12-06T19:22:09Z,test/cpp/end2end/client_lb_end2end_test.cc,"@@ -507,6 +507,46 @@ TEST_F(ClientLbEnd2endTest, PickFirstResetConnectionBackoff) {   EXPECT_LT(waited_ms, kInitialBackOffMs); } +TEST_F(ClientLbEnd2endTest,+       PickFirstResetConnectionBackoffNextAttemptStartsImmediately) {+  ChannelArguments args;+  constexpr int kInitialBackOffMs = 1000;+  args.SetInt(GRPC_ARG_INITIAL_RECONNECT_BACKOFF_MS, kInitialBackOffMs);+  const std::vector<int> ports = {grpc_pick_unused_port_or_die()};+  auto channel = BuildChannel(""pick_first"", args);+  auto stub = BuildStub(channel);+  SetNextResolution(ports);+  // Wait for connect, which should fail ~immediately, because the server+  // is not up.+  gpr_log(GPR_INFO, ""=== INITIAL CONNECTION ATTEMPT"");+  EXPECT_FALSE(+      channel->WaitForConnected(grpc_timeout_milliseconds_to_deadline(10)));+  // Reset connection backoff.+  gpr_log(GPR_INFO, ""=== RESETTING BACKOFF"");+  experimental::ChannelResetConnectionBackoff(channel.get());+  // Trigger a second connection attempt.  This should also fail+  // ~immediately, but the retry should be scheduled for+  // kInitialBackOffMs instead of applying the multiplier.+  gpr_log(GPR_INFO, ""=== TRIGGERING SECOND CONNECTION ATTEMPT"");+  EXPECT_FALSE(+      channel->WaitForConnected(grpc_timeout_milliseconds_to_deadline(10)));+  // Bring up a server on the chosen port.+  gpr_log(GPR_INFO, ""=== STARTING BACKEND"");+  StartServers(1, ports);+  // Wait for connect.  Should happen within kInitialBackOffMs.+  gpr_log(GPR_INFO, ""=== TRIGGERING THIRD CONNECTION ATTEMPT"");+  const gpr_timespec t0 = gpr_now(GPR_CLOCK_MONOTONIC);+  EXPECT_TRUE(channel->WaitForConnected(+      grpc_timeout_milliseconds_to_deadline(kInitialBackOffMs)));+  const gpr_timespec t1 = gpr_now(GPR_CLOCK_MONOTONIC);+  const grpc_millis waited_ms = gpr_time_to_millis(gpr_time_sub(t1, t0));+  gpr_log(GPR_DEBUG, ""Waited %"" PRId64 "" milliseconds"", waited_ms);+  // Give an extra 100ms for timing slack.+  // (This is still far less than the 1.6x increase we would see if the+  // backoff state was not reset properly.)+  EXPECT_LT(waited_ms, kInitialBackOffMs + 100);","If the suggestion above is taken, this check looks fine. Otherwise, I think we can just change line 539 to```EXPECT_TRUE(channel->WaitForConnected(      grpc_timeout_milliseconds_to_deadline(kInitialBackOffMs + 100)));```",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17303,239583457,2018-12-06T19:29:01Z,.pylintrc,"@@ -82,3 +90,14 @@ disable= 	# if:/else: and for:/else:. 	useless-else-on-loop, 	no-else-return,+	# NOTE(lidiz): Python 3 make object inheritance default, but not PY2+	useless-object-inheritance,+	# NOTE(lidiz): Limit the length of function doesn't mean reducing+	# complexity.+	too-many-statements,","It only failed in one place in our current code base. As I reasoned above, I make it globally disabled because I don't think it is a correct thing to do to restrict length of functions. If the function is too long, it is very likely it has design problem. And the design problem should be caught by code reviews...",OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/17303,239605309,2018-12-06T20:37:17Z,.pylintrc,"@@ -82,3 +90,14 @@ disable= 	# if:/else: and for:/else:. 	useless-else-on-loop, 	no-else-return,+	# NOTE(lidiz): Python 3 make object inheritance default, but not PY2+	useless-object-inheritance,+	# NOTE(lidiz): Limit the length of function doesn't mean reducing+	# complexity.+	too-many-statements,","I think I'm with @ericgribkoff  on this one. Even if it should be caught by code review, it's nice to have a linter as a safety net. If we consciously decide to make an exception, adding an exception comment isn't very burdensome.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17430,239615920,2018-12-06T21:12:07Z,test/cpp/end2end/server_interceptors_end2end_test.cc,"@@ -44,7 +44,32 @@ namespace {  class LoggingInterceptor : public experimental::Interceptor {  public:-  LoggingInterceptor(experimental::ServerRpcInfo* info) { info_ = info; }+  LoggingInterceptor(experimental::ServerRpcInfo* info) {+    info_ = info;++    // Check the method name and compare to the type+    const char* method = info->method();+    experimental::ServerRpcInfo::Type type = info->type();++    // Check that we use one of our standard methods with expected type.+    // We accept BIDI_STREAMING for Echo in case it's an AsyncGenericService",Would it make sense to do this conditionally based on which test is being run?  Or is it too hard to instrument that?,
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17303,239616792,2018-12-06T21:15:01Z,.pylintrc,"@@ -82,3 +90,14 @@ disable= 	# if:/else: and for:/else:. 	useless-else-on-loop, 	no-else-return,+	# NOTE(lidiz): Python 3 make object inheritance default, but not PY2+	useless-object-inheritance,+	# NOTE(lidiz): Limit the length of function doesn't mean reducing+	# complexity.+	too-many-statements,","The failure for this check looks like it's for `_consume_request_iterator` in `_channel.py`, and that is a *long* method - let's leave this enabled globally, as it would be nice not to have more methods of similar size getting introduced",
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17303,239619166,2018-12-06T21:22:52Z,.pylintrc-tests,"@@ -115,3 +119,14 @@ disable= 	# if:/else: and for:/else:. 	useless-else-on-loop, 	no-else-return,+	# NOTE(lidiz): Python 3 make object inheritance default, but not PY2+	useless-object-inheritance,+	# NOTE(lidiz): Limit the length of function doesn't mean reducing","As with the `.pylintrc`, I don't see sufficient reason to disable any of these (other than `useless-object-inheritance`) globally",OK
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/17391,239637461,2018-12-06T22:23:53Z,test/cpp/end2end/client_lb_end2end_test.cc,"@@ -507,6 +507,46 @@ TEST_F(ClientLbEnd2endTest, PickFirstResetConnectionBackoff) {   EXPECT_LT(waited_ms, kInitialBackOffMs); } +TEST_F(ClientLbEnd2endTest,+       PickFirstResetConnectionBackoffNextAttemptStartsImmediately) {+  ChannelArguments args;+  constexpr int kInitialBackOffMs = 1000;+  args.SetInt(GRPC_ARG_INITIAL_RECONNECT_BACKOFF_MS, kInitialBackOffMs);+  const std::vector<int> ports = {grpc_pick_unused_port_or_die()};+  auto channel = BuildChannel(""pick_first"", args);+  auto stub = BuildStub(channel);+  SetNextResolution(ports);+  // Wait for connect, which should fail ~immediately, because the server+  // is not up.+  gpr_log(GPR_INFO, ""=== INITIAL CONNECTION ATTEMPT"");+  EXPECT_FALSE(+      channel->WaitForConnected(grpc_timeout_milliseconds_to_deadline(10)));+  // Reset connection backoff.+  gpr_log(GPR_INFO, ""=== RESETTING BACKOFF"");+  experimental::ChannelResetConnectionBackoff(channel.get());+  // Trigger a second connection attempt.  This should also fail+  // ~immediately, but the retry should be scheduled for+  // kInitialBackOffMs instead of applying the multiplier.+  gpr_log(GPR_INFO, ""=== TRIGGERING SECOND CONNECTION ATTEMPT"");+  EXPECT_FALSE(+      channel->WaitForConnected(grpc_timeout_milliseconds_to_deadline(10)));+  // Bring up a server on the chosen port.+  gpr_log(GPR_INFO, ""=== STARTING BACKEND"");+  StartServers(1, ports);+  // Wait for connect.  Should happen within kInitialBackOffMs.+  gpr_log(GPR_INFO, ""=== TRIGGERING THIRD CONNECTION ATTEMPT"");+  const gpr_timespec t0 = gpr_now(GPR_CLOCK_MONOTONIC);","The time that the timer is scheduled is not that important. It's the time that the next attempt time is determined that is important. Hmm.. I know this sounds confusing. Actually, when we start the second connection attempt in step 2, we determine the next attempt time (a deadline), which is now + initial backoff. https://github.com/grpc/grpc/blob/e97c9457e2f4e6733873ea2975d3b90432fdfdc1/src/core/ext/filters/client_channel/subchannel.cc#L667 So I think we should record `t0` right before step 2.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/17430,239651001,2018-12-06T23:20:23Z,include/grpcpp/impl/codegen/server_interface.h,"@@ -174,13 +174,14 @@ class ServerInterface : public internal::CallHook {     bool done_intercepting_;   }; +  /// RegisteredAsyncRequest is not part of the C++ API",It's not internal. This is a protected member of `grpc::ServerInterface` which is API. These request classes should be cleaned up a bit. I don't think there are any external users but this should become part of an API cleanup/internalization.,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/17425,239665299,2018-12-07T00:42:14Z,src/core/lib/debug/trace.h,"@@ -53,7 +53,8 @@ void grpc_tracer_enable_flag(grpc_core::TraceFlag* flag); class TraceFlag {  public:   TraceFlag(bool default_enabled, const char* name);","""Dynamic initialization of nonlocal variables is discouraged, and in general it is forbidden. However, we do permit it if no aspect of the program depends on the sequencing of this initialization with respect to all other initializations. Under those restrictions, the ordering of the initialization does not make an observable difference.""So I guess having a non-constexpr constructor is ok in this case so long as no other static variable uses anything from `TraceFlag`. Is this true?",OK
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/17425,239669572,2018-12-07T01:11:06Z,src/core/lib/debug/trace.h,"@@ -53,7 +53,8 @@ void grpc_tracer_enable_flag(grpc_core::TraceFlag* flag); class TraceFlag {  public:   TraceFlag(bool default_enabled, const char* name);","I guess it is true as in the ctor it adds itself to a global list of tracers, for which the order does not matter...I would like to make the globals pointers rather than relying on the trivially destructible part, but it is going to be a larger change.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/17348,239906922,2018-12-07T18:46:17Z,examples/ruby/greeter_server_with_interrupt.rb,"@@ -0,0 +1,47 @@+#!/usr/bin/env ruby++# Copyright 2015 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++# Sample gRPC server that implements the Greeter::Helloworld service.+#+# Usage: $ path/to/greeter_server.rb++this_dir = File.expand_path(File.dirname(__FILE__))+lib_dir = File.join(this_dir, 'lib')+$LOAD_PATH.unshift(lib_dir) unless $LOAD_PATH.include?(lib_dir)++require 'grpc'+require 'helloworld_services_pb'++# GreeterServer is simple server that implements the Helloworld Greeter server.+class GreeterServer < Helloworld::Greeter::Service+  # say_hello implements the SayHello rpc method.+  def say_hello(hello_req, _unused_call)+    Helloworld::HelloReply.new(message: ""Hello #{hello_req.name}"")+  end+end++# main starts an RpcServer that receives requests to GreeterServer at the sample+# server port.+def main+  s = GRPC::RpcServer.new+  s.add_http2_port('0.0.0.0:50051', :this_port_is_insecure)+  s.handle(GreeterServer)+  # will register signal handlers for signals SIGHUP, SIGINT and SIGQUIT to +  # shut down server gracefully+  s.run_till_terminated_or_interrupted([1, 'sigint', 'quit'])","nit: rather than add this new `greeter_server_with_interrupt.rb` server, can we just change `greeter_server.rb` to use the new API? Also same for the rest of the example servers like `route_guide_server.rb`.We could then just add a comment to above the method invocation in these example servers that we could also use `run_till_terminated`, but are using `run_till_terminated_or_interrupted` because we want to gracefully shutdown on these signals.... something along those lines.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/17348,239907203,2018-12-07T18:47:19Z,src/ruby/end2end/graceful_sig_handling_client.rb,"@@ -0,0 +1,78 @@+#!/usr/bin/env ruby++# Copyright 2015 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++require_relative './end2end_common'++# Test client. Sends RPC's as normal but process also has signal handlers+class SigHandlingClientController < ClientControl::ClientController::Service+  def initialize(srv, stub)+    @srv = srv+    @stub = stub+  end++  def do_echo_rpc(req, _)+    response = @stub.echo(Echo::EchoRequest.new(request: req.request))+    fail 'bad response' unless response.response == req.request+    ClientControl::Void.new+  end++  def shutdown(_, _)+    # Spawn a new thread because RpcServer#stop is+    # synchronous and blocks until either this RPC has finished,+    # or the server's ""poll_period"" seconds have passed.+    @shutdown_thread = Thread.new do+      @srv.stop+    end+    ClientControl::Void.new+  end++  def join_shutdown_thread",nit: this method s unused?,
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17444,239925740,2018-12-07T19:44:36Z,src/python/grpcio/grpc/_server.py,"@@ -705,8 +709,13 @@ def _on_call_completed(state):  def _serve(state):     while True:-        event = state.completion_queue.poll()-        if event.tag is _SHUTDOWN_TAG:+        timeout = time.time() + _DEALLOCATED_SERVER_CHECK_PERIOD_S",There is already a periodic timeout inside the completion queue. Do you think they can be merged together? (https://github.com/grpc/grpc/blob/master/src/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi#L23),
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17444,239948184,2018-12-07T21:14:56Z,src/python/grpcio/grpc/_server.py,"@@ -705,8 +709,13 @@ def _on_call_completed(state):  def _serve(state):     while True:-        event = state.completion_queue.poll()-        if event.tag is _SHUTDOWN_TAG:+        timeout = time.time() + _DEALLOCATED_SERVER_CHECK_PERIOD_S","I think that would get too confusing. There doesn't seem to be a good reason to couple these things together: The completion queue has not been deallocated, and the completion queue class is used in other places then in `_server.py`. The completion queue already supports a timeout mechanism and this change now uses it; this is separate from the additional `_INTERRUPT_CHECK_PERIOD_MS` used internally in the completion queue.",OK
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17444,239991124,2018-12-08T03:10:12Z,src/python/grpcio/grpc/_server.py,"@@ -705,8 +709,13 @@ def _on_call_completed(state):  def _serve(state):     while True:-        event = state.completion_queue.poll()-        if event.tag is _SHUTDOWN_TAG:+        timeout = time.time() + _DEALLOCATED_SERVER_CHECK_PERIOD_S","The timeout parameter is already part of the completion queue API, and this is very much how that API  is intended to be used. So this approach already can be applied to client channels or any other use of completion queues. Pushing the clean up logic for the _server.py deallocation down to a lower level just to try to piggyback on the internal CQ hack for handling an interrupt signal doesn't seem like a good idea to me, from a separation of concerns standpoint.Since this is a correct use of the CQ API, I would prefer to defer attempts at optimizing this to a separate PR or discussion elsewhere. This is a significant enough change already, without throwing in an alteration to the CQ API as well.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17444,240323537,2018-12-10T18:18:19Z,src/python/grpcio/grpc/_server.py,"@@ -705,8 +709,13 @@ def _on_call_completed(state):  def _serve(state):     while True:-        event = state.completion_queue.poll()-        if event.tag is _SHUTDOWN_TAG:+        timeout = time.time() + _DEALLOCATED_SERVER_CHECK_PERIOD_S","My suggestion is make CQ deallocation more nature. Cython server deallocation will deallocate its CQ. If we link those two deallocation procedure, the timeout is not pass down from Python layer, only the deallocation procedure is carried out. The idea here is similar to inverse of control, let the lower layer component able handle their own life cycle.But the problem this PR is solving is already very complicate. I agree we should defer modification to CQ API.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/17348,240508028,2018-12-11T08:20:02Z,src/ruby/end2end/graceful_sig_handling_client.rb,"@@ -0,0 +1,63 @@+#!/usr/bin/env ruby++# Copyright 2015 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++require_relative './end2end_common'++# Test client. Sends RPC's as normal but process also has signal handlers+class SigHandlingClientController < ClientControl::ClientController::Service+  def initialize(srv, stub)+    @srv = srv+    @stub = stub+  end++  def do_echo_rpc(req, _)+    response = @stub.echo(Echo::EchoRequest.new(request: req.request))+    fail 'bad response' unless response.response == req.request+    ClientControl::Void.new+  end+end++def main+  client_control_port = ''+  server_port = ''+  OptionParser.new do |opts|+    opts.on('--client_control_port=P', String) do |p|+      client_control_port = p+    end+    opts.on('--server_port=P', String) do |p|+      server_port = p+    end+  end.parse!++  # The ""shutdown"" RPC should end very quickly.+  # Allow a few seconds to be safe.+  srv = new_rpc_server_for_testing(poll_period: 3)","nit: I believe this longer `poll_period` is for the shutdown logic, which this server doesn't need. Can we just use the default `poll_period` here?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/17348,240512424,2018-12-11T08:35:42Z,src/ruby/lib/grpc/generic/rpc_server.rb,"@@ -354,6 +354,59 @@ def run      alias_method :run_till_terminated, :run +    # runs the server with signal handlers+    # @param signals+    #     List of String, Integer or both representing signals that the user+    #     would like to send to the server for graceful shutdown+    # @param wait_interval (optional)+    #     Integer seconds that user would like stop_server_thread to poll+    #     stop_server+    def run_till_terminated_or_interrupted(signals, wait_interval = 60)+      valid_signals = Signal.list++      stop_server = false+      stop_server_cv = ConditionVariable.new+      stop_server_mu = Mutex.new+      stop_server_thread = Thread.new do+        loop do+          break if stop_server","Realizing one edge case in this API: this probably <i>should</i> also handle the case where the server was one stopped the server with by calling the `stop` method on it, rather than necessarily interrupting it with a signal. For example, if one used this API to start their server, they should be able to interrupt it and/or call `stop` on it, and it should then begin shut down.One idea for how that could be done is we could change `stop_server_cv`, `stop_server_mu`, and `stop_server` from local vars of this function to instance-state for the whole `RpcServer`. Then, `RpcServer#stop` could then broadcast the condition variable and set `stop_server = true`. Currently, I think it will just hang if `stop` is used, until a signal is received.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/17348,240512809,2018-12-11T08:37:05Z,src/ruby/end2end/graceful_sig_handling_driver.rb,"@@ -0,0 +1,83 @@+#!/usr/bin/env ruby++# Copyright 2016 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++# smoke test for a grpc-using app that receives and+# handles process-ending signals++require_relative './end2end_common'+",this test looks good! we just need to plumb it in to the Kokoro build/test automation by adding it to [this list](https://github.com/grpc/grpc/blob/master/tools/run_tests/helper_scripts/run_ruby_end2end_tests.sh#L22),
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17384,240759788,2018-12-11T19:31:52Z,src/python/grpcio_status/grpc_status/rpc_status.py,"@@ -0,0 +1,60 @@+# Copyright 2018 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Reference implementation for status mapping in gRPC Python.""""""++import grpc++# Have to import google.protobuf before google.rpc, otherwise Python will fail+#   to locate module rpc under google.","The comment is updated with a link point to the unresolved issue and state the problem clearer.```# NOTE(https://github.com/bazelbuild/bazel/issues/6844)# Due to Bazel issue, the namespace packages won't resolve correctly.# Adding this unused-import as a workaround to avoid module-not-found error# under Bazel builds.```",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17384,240760369,2018-12-11T19:33:31Z,src/python/grpcio_status/grpc_status/rpc_status.py,"@@ -0,0 +1,60 @@+# Copyright 2018 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Reference implementation for status mapping in gRPC Python.""""""++import grpc++# Have to import google.protobuf before google.rpc, otherwise Python will fail+#   to locate module rpc under google.+import google.protobuf  # pylint: disable=unused-import+from google.rpc import status_pb2++_CODE_TO_GRPC_CODE_MAPPING = dict([(x.value[0], x) for x in grpc.StatusCode])+_GRPC_CODE_TO_CODE_MAPPING = dict([(x, x.value[0]) for x in grpc.StatusCode])++_GRPC_DETAILS_METADATA_KEY = 'grpc-status-details-bin'+++def from_call(call):+    """"""Returns a google.rpc.status.Status message corresponding to a given call.++    Args:+      call: A grpc.Call instance representing an RPC.++    Returns:+      A google.rpc.status.Status message representing the status of the RPC.+    """"""+    for metadatum in call.trailing_metadata():+        if metadatum.key == _GRPC_DETAILS_METADATA_KEY:+            return status_pb2.Status.FromString(metadatum.value)","In the newer version, I adopted the most strict check for both status code and status message. If they are inconsistent with the proto message, a `ValueError` exception will be raised.",
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17303,240778396,2018-12-11T20:26:26Z,src/python/grpcio/grpc/_channel.py,"@@ -745,10 +745,10 @@ def __new__(cls, value=_EMPTY_FLAGS):     def with_wait_for_ready(self, wait_for_ready):         if wait_for_ready is not None:             if wait_for_ready:-                self = self.__class__(self | cygrpc.InitialMetadataFlags.wait_for_ready | \+                return self.__class__(self | cygrpc.InitialMetadataFlags.wait_for_ready | \","I know this isn't introduced in this PR, but: why is `_InitialMetadataFlags` extending `int` rather than keeping an int as an instance variable?",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17444,240797198,2018-12-11T21:27:32Z,src/python/grpcio/grpc/_server.py,"@@ -703,61 +707,77 @@ def _on_call_completed(state):         state.active_rpc_count -= 1  -def _serve(state):-    while True:-        event = state.completion_queue.poll()-        if event.tag is _SHUTDOWN_TAG:+def _process_event_and_continue(state, event):+    should_continue = True+    if event.tag is _SHUTDOWN_TAG:+        with state.lock:+            state.due.remove(_SHUTDOWN_TAG)+            if _stop_serving(state):+                should_continue = False+    elif event.tag is _REQUEST_CALL_TAG:+        with state.lock:+            state.due.remove(_REQUEST_CALL_TAG)+            concurrency_exceeded = (+                state.maximum_concurrent_rpcs is not None and+                state.active_rpc_count >= state.maximum_concurrent_rpcs)+            rpc_state, rpc_future = _handle_call(+                event, state.generic_handlers, state.interceptor_pipeline,+                state.thread_pool, concurrency_exceeded)+            if rpc_state is not None:+                state.rpc_states.add(rpc_state)+            if rpc_future is not None:+                state.active_rpc_count += 1+                rpc_future.add_done_callback(+                    lambda unused_future: _on_call_completed(state))+            if state.stage is _ServerStage.STARTED:+                _request_call(state)+            elif _stop_serving(state):+                should_continue = False+    else:+        rpc_state, callbacks = event.tag(event)+        for callback in callbacks:+            callable_util.call_logging_exceptions(callback,+                                                  'Exception calling callback!')+        if rpc_state is not None:             with state.lock:-                state.due.remove(_SHUTDOWN_TAG)+                state.rpc_states.remove(rpc_state)                 if _stop_serving(state):-                    return-        elif event.tag is _REQUEST_CALL_TAG:-            with state.lock:-                state.due.remove(_REQUEST_CALL_TAG)-                concurrency_exceeded = (-                    state.maximum_concurrent_rpcs is not None and-                    state.active_rpc_count >= state.maximum_concurrent_rpcs)-                rpc_state, rpc_future = _handle_call(-                    event, state.generic_handlers, state.interceptor_pipeline,-                    state.thread_pool, concurrency_exceeded)-                if rpc_state is not None:-                    state.rpc_states.add(rpc_state)-                if rpc_future is not None:-                    state.active_rpc_count += 1-                    rpc_future.add_done_callback(-                        lambda unused_future: _on_call_completed(state))-                if state.stage is _ServerStage.STARTED:-                    _request_call(state)-                elif _stop_serving(state):-                    return-        else:-            rpc_state, callbacks = event.tag(event)-            for callback in callbacks:-                callable_util.call_logging_exceptions(-                    callback, 'Exception calling callback!')-            if rpc_state is not None:-                with state.lock:-                    state.rpc_states.remove(rpc_state)-                    if _stop_serving(state):-                        return+                    should_continue = False+    return should_continue+++def _serve(state):+    while True:+        timeout = time.time() + _DEALLOCATED_SERVER_CHECK_PERIOD_S+        event = state.completion_queue.poll(timeout)+        if state.server_deallocated:","This `server_deallocated` seems a noop to me. If the server is under deallocation process, thanks to the timeout, it will not deadlock in both Python 2/3. I removed `server_deallocated` and the unit tests still pass for Python 2/3. Did I miss some details?",
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/17364,240811048,2018-12-11T22:11:41Z,src/upb/gen_build_yaml.py,"@@ -0,0 +1,67 @@+#!/usr/bin/env python2.7++# Copyright 2015 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import re+import os+import sys+import yaml++srcs = [",We probably want a TODO here mentionning @haberman that we should fold this into upb itself instead of hardcoding the lists here.,
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17384,240831952,2018-12-11T23:31:38Z,src/python/grpcio_status/grpc_status/rpc_status.py,"@@ -0,0 +1,78 @@+# Copyright 2018 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Reference implementation for status mapping in gRPC Python.""""""++import grpc++# NOTE(https://github.com/bazelbuild/bazel/issues/6844)+# Due to Bazel issue, the namespace packages won't resolve correctly.+# Adding this unused-import as a workaround to avoid module-not-found error+# under Bazel builds.+import google.protobuf  # pylint: disable=unused-import+from google.rpc import status_pb2++_CODE_TO_GRPC_CODE_MAPPING = dict([(x.value[0], x) for x in grpc.StatusCode])++_GRPC_DETAILS_METADATA_KEY = 'grpc-status-details-bin'+++def _code_to_grpc_status_code(code):+    try:+        return _CODE_TO_GRPC_CODE_MAPPING[code]+    except KeyError:+        raise ValueError('Invalid status code %s' % code)+++def from_rpc_error(rpc_error):+    """"""Returns a google.rpc.status.Status message corresponding to a given grpc.RpcError.++    Args:+      call: A grpc.RpcError instance raised by an RPC.","This seems like the wrong type. An RpcError is just an exception, we actually need the Call",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17303,240842569,2018-12-12T00:22:04Z,src/python/grpcio/grpc/_channel.py,"@@ -745,10 +745,10 @@ def __new__(cls, value=_EMPTY_FLAGS):     def with_wait_for_ready(self, wait_for_ready):         if wait_for_ready is not None:             if wait_for_ready:-                self = self.__class__(self | cygrpc.InitialMetadataFlags.wait_for_ready | \+                return self.__class__(self | cygrpc.InitialMetadataFlags.wait_for_ready | \","My initial thought is make the flag be Python `int` compatible. And extending from `int` is intended to bind helper member methods to manipulate the value. I think the ideal way is to make it a function instead, since there will be only few initial metadata flags be used each time and it won't mutate.",OK
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17303,241127688,2018-12-12T18:15:44Z,tools/run_tests/dockerize/docker_run_tests.sh,"@@ -18,6 +18,7 @@  set -e +# shellcheck disable=SC2154","You could not export it if it's empty or unset. (it may also be reasonable to assign it a default of opt, as done in e.g https://github.com/grpc/grpc/blob/master/tools/run_tests/helper_scripts/build_php.sh, but that would require confirming empty=opt)",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17467,241189568,2018-12-12T21:21:54Z,tools/dockerfile/grpc_clang_format/clang_format_all_the_things.sh,"@@ -16,7 +16,7 @@ set -e  # directories to run against-DIRS=""src/core/lib src/core/tsi src/core/ext src/cpp test/core test/cpp include src/compiler src/csharp src/ruby third_party/address_sorting src/objective-c""+DIRS=""src/core/lib src/core/tsi src/core/ext/filters src/core/ext/transport src/cpp test/core test/cpp include src/compiler src/csharp src/ruby third_party/address_sorting src/objective-c""","Instead of restricting the set of directories under ext that get checked, let's change the `find` command below to exclude files ending in `.upb.h` or `.upb.c`.  That way, we won't be accidentally skipping this check if we add a new directory under ext in the future.",OK
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17481,241208145,2018-12-12T22:24:54Z,src/python/grpcio/grpc/__init__.py,"@@ -266,6 +266,23 @@ class StatusCode(enum.Enum):     UNAUTHENTICATED = (_cygrpc.StatusCode.unauthenticated, 'unauthenticated')  +#############################  gRPC Status  ################################+++class Status(six.with_metaclass(abc.ABCMeta)):+    """"""Describes the status of an RPC.++    This is an EXPERIMENTAL API.++    Attributes:+      code: A StatusCode object to be sent to the client.+        It must not be StatusCode.OK.","I don't think this should allow StatusCode.OK as well. I think the restriction should be placed on the input to abort_with_status() instead. We don't control implementations of this class, so it's a weak constraint here anyways, I would prefer we state this only when we can actually validate a concrete instance",OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/17481,241213043,2018-12-12T22:44:20Z,src/python/grpcio/grpc/__init__.py,"@@ -266,6 +266,22 @@ class StatusCode(enum.Enum):     UNAUTHENTICATED = (_cygrpc.StatusCode.unauthenticated, 'unauthenticated')  +#############################  gRPC Status  ################################+++class Status(six.with_metaclass(abc.ABCMeta)):",We briefly discussed having accessors on this class so that we could use either `get_details()` or `get_message()`. Do we still want to do that?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17495,241451810,2018-12-13T15:46:54Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc,"@@ -96,21 +96,19 @@ static void log_address_sorting_list(const ServerAddressList& addresses,   for (size_t i = 0; i < addresses.size(); i++) {     char* addr_str;     if (grpc_sockaddr_to_string(&addr_str, &addresses[i].address(), true)) {-      gpr_log(GPR_DEBUG, ""c-ares address sorting: %s[%"" PRIuPTR ""]=%s"",-              input_output_str, i, addr_str);+      GRPC_CARES_TRACE_LOG(""c-ares address sorting: %s[%"" PRIuPTR ""]=%s"",+                           input_output_str, i, addr_str);       gpr_free(addr_str);     } else {-      gpr_log(GPR_DEBUG,-              ""c-ares address sorting: %s[%"" PRIuPTR ""]=<unprintable>"",-              input_output_str, i);+      GRPC_CARES_TRACE_LOG(""c-ares address sorting: %s[%"" PRIuPTR+                           ""]=<unprintable>"",+                           input_output_str, i);     }   } }  void grpc_cares_wrapper_address_sorting_sort(ServerAddressList* addresses) {-  if (grpc_trace_cares_address_sorting.enabled()) {","We should keep this check and leave the log messages in `log_address_sorting_list()` using `gpr_log(GPR_INFO)` instead of `GRPC_CARES_TRACE_LOG()`.  That way, we're not doing extra work we don't need when the tracer is disabled.",OK
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/17311,241518765,2018-12-13T18:48:12Z,src/core/ext/filters/client_channel/http_proxy.cc,"@@ -81,12 +73,31 @@ static char* get_http_proxy_server(char** user_cred) {     proxy_name = nullptr;   }   gpr_free(authority_strs);-done:-  gpr_free(uri_str);   grpc_uri_destroy(uri);   return proxy_name; } +grpc_uri* get_proxy_uri(char* proxy_env_var) {",Can we pass the input as `const char*`?Suggest naming the parameter as `proxy_env_var_name` or `proxy_env_var_key`.,
109690,davidben,https://api.github.com/repos/grpc/grpc/pulls/17500,241604268,2018-12-13T23:53:57Z,src/core/tsi/ssl_transport_security.cc,"@@ -1850,31 +1850,30 @@ tsi_result tsi_create_ssl_server_handshaker_factory_with_options(           break;         }         SSL_CTX_set_client_CA_list(impl->ssl_contexts[i], root_names);-        switch (options->client_certificate_request) {-          case TSI_DONT_REQUEST_CLIENT_CERTIFICATE:-            SSL_CTX_set_verify(impl->ssl_contexts[i], SSL_VERIFY_NONE, nullptr);-            break;-          case TSI_REQUEST_CLIENT_CERTIFICATE_BUT_DONT_VERIFY:-            SSL_CTX_set_verify(impl->ssl_contexts[i], SSL_VERIFY_PEER,-                               NullVerifyCallback);-            break;-          case TSI_REQUEST_CLIENT_CERTIFICATE_AND_VERIFY:-            SSL_CTX_set_verify(impl->ssl_contexts[i], SSL_VERIFY_PEER, nullptr);-            break;-          case TSI_REQUEST_AND_REQUIRE_CLIENT_CERTIFICATE_BUT_DONT_VERIFY:-            SSL_CTX_set_verify(-                impl->ssl_contexts[i],-                SSL_VERIFY_PEER | SSL_VERIFY_FAIL_IF_NO_PEER_CERT,-                NullVerifyCallback);-            break;-          case TSI_REQUEST_AND_REQUIRE_CLIENT_CERTIFICATE_AND_VERIFY:-            SSL_CTX_set_verify(-                impl->ssl_contexts[i],-                SSL_VERIFY_PEER | SSL_VERIFY_FAIL_IF_NO_PEER_CERT, nullptr);-            break;-        }-        /* TODO(jboeuf): Add revocation verification. */       }+      switch (options->client_certificate_request) {+        case TSI_DONT_REQUEST_CLIENT_CERTIFICATE:+          SSL_CTX_set_verify(impl->ssl_contexts[i], SSL_VERIFY_NONE, nullptr);+          break;+        case TSI_REQUEST_CLIENT_CERTIFICATE_BUT_DONT_VERIFY:+          SSL_CTX_set_verify(impl->ssl_contexts[i], SSL_VERIFY_PEER,+                             NullVerifyCallback);+          break;+        case TSI_REQUEST_CLIENT_CERTIFICATE_AND_VERIFY:+          SSL_CTX_set_verify(impl->ssl_contexts[i], SSL_VERIFY_PEER, nullptr);",Did you check it's not accidentally configuring some system default list? (I don't actually know what OpenSSL's verifier does by default.),
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/17503,241620518,2018-12-14T01:33:52Z,examples/cpp/load_balancing/README.md,"@@ -0,0 +1,64 @@+# gRPC C++ Load Balancing Tutorial++### Prerequisite+Make sure you have run the [hello world example](../helloworld) or understood the basics of gRPC. We will not dive into the details that have been discussed in the hello world example.++### Get the tutorial source code++The example code for this and our other examples lives in the `examples` directory. Clone this repository to your local machine by running the following command:+++```sh+$ git clone -b $(curl -L https://grpc.io/release) https://github.com/grpc/grpc+```++Change your current directory to examples/cpp/load_balancing++```sh+$ cd examples/cpp/load_balancing/+```++### Generating gRPC code++To generate the client and server side interfaces:++```sh+$ make helloworld.grpc.pb.cc helloworld.pb.cc+```+Which internally invokes the proto-compiler as:++```sh+$ protoc -I ../../protos/ --grpc_out=. --plugin=protoc-gen-grpc=grpc_cpp_plugin ../../protos/helloworld.proto+$ protoc -I ../../protos/ --cpp_out=. ../../protos/helloworld.proto+```++### Writing a client and a server++The client and the server can be based on the hello world example.++Additionally, we can configure the load balancing policy.++In the client, set the load balancing policy of the channel via the channel arg (to, for example, Round Robin).++```cpp+  ChannelArguments args;+  // Set the load balancing policy for the channel.+  args.SetLoadBalancingPolicyName(""round_robin"");","It might be nice to point to where the list of available lb policies is, but I suppose the user could just look at the code",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/17348,241922130,2018-12-14T23:47:48Z,src/ruby/end2end/graceful_sig_stop_client.rb,"@@ -0,0 +1,73 @@+#!/usr/bin/env ruby++# Copyright 2015 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++require_relative './end2end_common'++# Test client. Sends RPC's as normal but process also has signal handlers+class SigHandlingClientController < ClientControl::ClientController::Service+  def initialize(srv, stub)+    @srv = srv+    @stub = stub+  end++  def do_echo_rpc(req, _)+    response = @stub.echo(Echo::EchoRequest.new(request: req.request))+    fail 'bad response' unless response.response == req.request+    ClientControl::Void.new+  end++  def shutdown(_, _)+    # Spawn a new thread because RpcServer#stop is+    # synchronous and blocks until either this RPC has finished,+    # or the server's ""poll_period"" seconds have passed.+    @shutdown_thread = Thread.new do","nit: can you please make sure to join this `shutdown_thread`? probably at the end of this script, after `server_thread.join`, similarly to https://github.com/grpc/grpc/blob/master/src/ruby/end2end/sig_handling_client.rb#L83",
42048362,mhaidrygoog,https://api.github.com/repos/grpc/grpc/pulls/17461,241928884,2018-12-15T00:48:30Z,test/cpp/qps/client_callback.cc,"@@ -193,17 +200,157 @@ class CallbackUnaryClient final : public CallbackClient {             ctx_[vector_idx].reset(                 new CallbackClientRpcContext(ctx_[vector_idx]->stub_));             // Schedule a new RPC-            ScheduleRpc(t, thread_idx, vector_idx);+            ScheduleRpc(t, vector_idx);           }         });   } }; +class CallbackStreamingClient : public CallbackClient {+ public:+  CallbackStreamingClient(const ClientConfig& config)+      : CallbackClient(config),+        messages_per_stream_(config.messages_per_stream()) {+    for (int ch = 0; ch < config.client_channels(); ch++) {+      for (int i = 0; i < config.outstanding_rpcs_per_channel(); i++) {+        ctx_.emplace_back(+            new CallbackClientRpcContext(channels_[ch].get_stub()));+      }+    }+    StartThreads(num_threads_);+  }+  ~CallbackStreamingClient() {}++  void AddHistogramEntry(double start_, bool ok, void* thread_ptr) {+    // Update Histogram with data from the callback run+    HistogramEntry entry;+    if (ok) {+      entry.set_value((UsageTimer::Now() - start_) * 1e9);+    }+    ((Client::Thread*)thread_ptr)->UpdateHistogram(&entry);+  }++  int messages_per_stream() { return messages_per_stream_; }++ protected:+  const int messages_per_stream_;+};++class CallbackStreamingPingPongClient : public CallbackStreamingClient {+ public:+  CallbackStreamingPingPongClient(const ClientConfig& config)+      : CallbackStreamingClient(config) {}+  ~CallbackStreamingPingPongClient() {}+};++class CallbackStreamingPingPongReactor final+    : public grpc::experimental::ClientBidiReactor<SimpleRequest,+                                                   SimpleResponse> {+ public:+  CallbackStreamingPingPongReactor(+      CallbackStreamingPingPongClient* client,+      std::unique_ptr<CallbackClientRpcContext> ctx)+      : client_(client), ctx_(std::move(ctx)), messages_issued_(0) {}++  void StartNewRpc() {+    if (client_->ThreadCompleted()) return;+    start_ = UsageTimer::Now();+    ctx_->stub_->experimental_async()->StreamingCall(&(ctx_->context_), this);+    StartWrite(client_->request());+    StartCall();+  }++  void OnWriteDone(bool ok) override {+    if (!ok || client_->ThreadCompleted()) {+      if (!ok) gpr_log(GPR_ERROR, ""Error writing RPC"");+      StartWritesDone();+      return;+    }+    StartRead(&ctx_->response_);+  }++  void OnReadDone(bool ok) override {+    client_->AddHistogramEntry(start_, ok, thread_ptr_);++    if (client_->ThreadCompleted() || !ok ||+        (client_->messages_per_stream() != 0 &&+         ++messages_issued_ >= client_->messages_per_stream())) {+      if (!ok) {+        gpr_log(GPR_ERROR, ""Error reading RPC"");+      }+      StartWritesDone();+      return;+    }+    StartWrite(client_->request());+  }++  void OnDone(const Status& s) override {+    if (client_->ThreadCompleted() || !s.ok()) {+      client_->NotifyMainThreadOfThreadCompletion();+      return;+    }+    ctx_.reset(new CallbackClientRpcContext(ctx_->stub_));+    ScheduleRpc();+  }++  void ScheduleRpc() {+    if (client_->ThreadCompleted()) return;++    if (!client_->IsClosedLoop()) {+      gpr_timespec next_issue_time = client_->NextIssueTime();+      // Start an alarm callback to run the internal callback after+      // next_issue_time+      ctx_->alarm_.experimental().Set(next_issue_time,+                                      [this](bool ok) { StartNewRpc(); });+    } else {+      StartNewRpc();+    }+  }++  void set_thread_ptr(void* ptr) { thread_ptr_ = ptr; }",Because Thread is embedded in Client class and is not directly accessible to the CallbackClientRpcContext. The client class is a super class in client.h,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/17461,242067454,2018-12-17T09:06:25Z,test/cpp/qps/client_callback.cc,"@@ -66,13 +66,35 @@ class CallbackClient             config, BenchmarkStubCreator) {     num_threads_ = NumThreads(config);     rpcs_done_ = 0;-    SetupLoadTest(config, num_threads_);++    //  Don't divide the fixed load among threads as the user threads+    //  only bootstrap the RPCs+    SetupLoadTest(config, 1);","Sorry, by ""value"", I meant ""purpose"" . Is there still any use of the num_threads parameter in this particular client implementation? Possibly the answer is no; I believe that it's no for the sync client, for example. I just want a clarification about it.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/17461,242068411,2018-12-17T09:09:44Z,test/cpp/qps/client_callback.cc,"@@ -193,17 +200,157 @@ class CallbackUnaryClient final : public CallbackClient {             ctx_[vector_idx].reset(                 new CallbackClientRpcContext(ctx_[vector_idx]->stub_));             // Schedule a new RPC-            ScheduleRpc(t, thread_idx, vector_idx);+            ScheduleRpc(t, vector_idx);           }         });   } }; +class CallbackStreamingClient : public CallbackClient {+ public:+  CallbackStreamingClient(const ClientConfig& config)+      : CallbackClient(config),+        messages_per_stream_(config.messages_per_stream()) {+    for (int ch = 0; ch < config.client_channels(); ch++) {+      for (int i = 0; i < config.outstanding_rpcs_per_channel(); i++) {+        ctx_.emplace_back(+            new CallbackClientRpcContext(channels_[ch].get_stub()));+      }+    }+    StartThreads(num_threads_);+  }+  ~CallbackStreamingClient() {}++  void AddHistogramEntry(double start_, bool ok, void* thread_ptr) {+    // Update Histogram with data from the callback run+    HistogramEntry entry;+    if (ok) {+      entry.set_value((UsageTimer::Now() - start_) * 1e9);+    }+    ((Client::Thread*)thread_ptr)->UpdateHistogram(&entry);+  }++  int messages_per_stream() { return messages_per_stream_; }++ protected:+  const int messages_per_stream_;+};++class CallbackStreamingPingPongClient : public CallbackStreamingClient {+ public:+  CallbackStreamingPingPongClient(const ClientConfig& config)+      : CallbackStreamingClient(config) {}+  ~CallbackStreamingPingPongClient() {}+};++class CallbackStreamingPingPongReactor final+    : public grpc::experimental::ClientBidiReactor<SimpleRequest,+                                                   SimpleResponse> {+ public:+  CallbackStreamingPingPongReactor(+      CallbackStreamingPingPongClient* client,+      std::unique_ptr<CallbackClientRpcContext> ctx)+      : client_(client), ctx_(std::move(ctx)), messages_issued_(0) {}++  void StartNewRpc() {+    if (client_->ThreadCompleted()) return;+    start_ = UsageTimer::Now();+    ctx_->stub_->experimental_async()->StreamingCall(&(ctx_->context_), this);+    StartWrite(client_->request());+    StartCall();+  }++  void OnWriteDone(bool ok) override {+    if (!ok || client_->ThreadCompleted()) {+      if (!ok) gpr_log(GPR_ERROR, ""Error writing RPC"");+      StartWritesDone();+      return;+    }+    StartRead(&ctx_->response_);+  }++  void OnReadDone(bool ok) override {+    client_->AddHistogramEntry(start_, ok, thread_ptr_);++    if (client_->ThreadCompleted() || !ok ||+        (client_->messages_per_stream() != 0 &&+         ++messages_issued_ >= client_->messages_per_stream())) {+      if (!ok) {+        gpr_log(GPR_ERROR, ""Error reading RPC"");+      }+      StartWritesDone();+      return;+    }+    StartWrite(client_->request());+  }++  void OnDone(const Status& s) override {+    if (client_->ThreadCompleted() || !s.ok()) {+      client_->NotifyMainThreadOfThreadCompletion();+      return;+    }+    ctx_.reset(new CallbackClientRpcContext(ctx_->stub_));+    ScheduleRpc();+  }++  void ScheduleRpc() {+    if (client_->ThreadCompleted()) return;++    if (!client_->IsClosedLoop()) {+      gpr_timespec next_issue_time = client_->NextIssueTime();+      // Start an alarm callback to run the internal callback after+      // next_issue_time+      ctx_->alarm_.experimental().Set(next_issue_time,+                                      [this](bool ok) { StartNewRpc(); });+    } else {+      StartNewRpc();+    }+  }++  void set_thread_ptr(void* ptr) { thread_ptr_ = ptr; }","I'd rather see `Client::Thread` promoted from `protected` to `public` : this is just a test so there's less strict of a reason for protection, and using the proper class helps to make the code easier to read.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17444,242361002,2018-12-17T23:51:13Z,src/python/grpcio_tests/tests/tests.json,"@@ -55,6 +55,7 @@   ""unit._reconnect_test.ReconnectTest"",   ""unit._resource_exhausted_test.ResourceExhaustedTest"",   ""unit._rpc_test.RPCTest"",+  ""unit._server_shutdown_test.ServerShutdown"",",Seems you need to add the scenario file as dependency in the same way as `exit_scenarios.py` to make Bazel happy.,
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17303,243019046,2018-12-19T18:05:19Z,tools/run_tests/performance/run_worker_go.sh,"@@ -17,6 +17,7 @@ set -ex  cd ""$(dirname ""$0"")/../../.."" -export GOPATH=$(pwd)/../gopath+GOPATH=$(pwd)/../gopath","[SC2155](https://github.com/koalaman/shellcheck/wiki/SC2155)> Declare and assign separately to avoid masking return values.> > In the original code, the return value of mycmd is ignored, and export will instead always return true. This may prevent conditionals, set -e and traps from working correctly.> > When first marked for export and assigned separately, the return value of the assignment will be that of mycmd. This avoids the problem.I fixed it as the shellcheck wiki suggested, because it is better than noop.",OK
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17580,243704680,2018-12-21T22:22:08Z,src/python/grpcio_tests/tests/unit/_version_test.py,"@@ -0,0 +1,33 @@+# Copyright 2018 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Test for grpc.__version__""""""++from __future__ import absolute_import+from __future__ import division+from __future__ import print_function++import unittest+import grpc+import logging+++class VersionTest(unittest.TestCase):++    def test_get_version(self):+        self.assertIsInstance(grpc.__version__, str)",This would be more useful if it could compare against `VERSION` from https://github.com/grpc/grpc/blob/master/src/python/grpcio/grpc_version.py#L17,OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/17580,243706436,2018-12-21T22:35:17Z,src/python/grpcio/grpc/__init__.py,"@@ -23,6 +23,11 @@  logging.getLogger(__name__).addHandler(logging.NullHandler()) +try:+    from _grpcio_metadata import __version__",`_grpcio_metadata` is generated from a template located [here](https://github.com/grpc/grpc/blob/4d5c3102a1b1bd440f22d4889e3afd146997fb6d/templates/src/python/grpcio/grpc/_grpcio_metadata.py.template). It looks like all of the templates in the `templates/` directory are being rendered by a script located [here](https://github.com/grpc/grpc/blob/806c1e0b7abcde983827db1ef1dd6a3785f0a5c8/tools/buildgen/generate_projects.sh).,OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17607,245081171,2019-01-03T17:55:46Z,tools/dockerfile/distribtest/ruby_centos7_x64/Dockerfile,"@@ -14,6 +14,24 @@  FROM centos:7 -RUN yum install -y ruby+RUN yum update","btw, in dockerfiles  ""yum update"" and ""yum install"" as separate commands are considered a bad practice (because it makes caching behave weirdly)",OK
12038583,matoro,https://api.github.com/repos/grpc/grpc/pulls/17606,245194559,2019-01-04T03:31:26Z,src/ruby/ext/grpc/extconf.rb,"@@ -24,10 +24,18 @@  ENV['MACOSX_DEPLOYMENT_TARGET'] = '10.7' -ENV['AR'] = RbConfig::CONFIG['AR'] + ' rcs'-ENV['CC'] = RbConfig::CONFIG['CC']-ENV['CXX'] = RbConfig::CONFIG['CXX']-ENV['LD'] = ENV['CC']+if ENV['AR'].nil?","@apolcyn Thank you for taking a look at this.  I can see the merits for that, however I believe that it's probably the weaker solution for the following reasons:- it is pretty rare and difficult to accidentally override these variables.  if they are overridden, the user probably meant to do it, and in the unlikely event that they didn't mean to, far more than just grpc will be broken.  it's more than fair to say that messing with the build toolchain puts any issues you might have at the bottom of the priority list.- `CFLAGS`, `CC` and so-forth have well-known purposes that are standardized across the C/C++ ecosystem.  nonstandard variables would require documentation and the assumption that users will actually find and read said documentation, in the same way that users should be able to expect that `make` with no targets will reasonably build the project, rather than having to read the documentation for some weird invocation.- it breaks package managers that rely on these standardized variables to control the build environment, such as portage (the original reason for this PR).",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/17609,245398629,2019-01-04T19:34:51Z,include/grpcpp/impl/codegen/interceptor.h,"@@ -109,7 +109,13 @@ class InterceptorBatchMethods {   /// Returns a modifable ByteBuffer holding the serialized form of the message   /// that is going to be sent. Valid for PRE_SEND_MESSAGE interceptions.   /// A return value of nullptr indicates that this ByteBuffer is not valid.-  virtual ByteBuffer* GetSendMessage() = 0;+  virtual ByteBuffer* GetSerializedSendMessage() = 0;++  /// Returns a non-modifiable pointer to the original non-serialized form of","True, the semantics are being updated in a subsequent PR https://github.com/grpc/grpc/pull/17630",
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17621,245424321,2019-01-04T21:23:51Z,src/python/grpcio_tests/tests/unit/_interpreter_exit_test.py,"@@ -0,0 +1,60 @@+# Copyright 2015 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Tests to ensure that gRPC does not segfault or hang on interpreter exit""""""++import logging+import subprocess+import sys+import unittest++import grpc++INTERPRETER = sys.executable+++class InterpreterExitTest(unittest.TestCase):++    # NOTE: We  avoid Python daemon threads due to potential for segfaults after+    # the main thread exits. See https://bugs.python.org/issue1856, although+    # issues were also observed with Python3 (see also+    # https://github.com/grpc/grpc/issues/11804).+    def test_server_cleanup_exits_cleanly(self):+        script = """"""if True:+            import sys++            import grpc+            from tests.unit import test_common++            servers = []+            while len(servers) < 1000:+                server = test_common.test_server()+                server.add_insecure_port('[::]:0')+                server.start()+                servers.append(server)+            sys.exit(0)++        """"""","It makes the test a lot simpler to keep it inline, IMO, as it removes the need to cross-reference two separate files. The ""_server_shutdown_scenarios.py"" pattern we use elsewhere means the tests are split across separate files, and the *_scenarios file has to deal with argument parsing etc as it corresponds to multiple actual tests. This pattern is lifted from CPython's own tests, see https://github.com/python/cpython/blob/31ec52a9afedd77e36a3ddc31c4c45664b8ac410/Lib/test/test_threading.py#L778",
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17640,245445524,2019-01-04T23:05:53Z,src/core/lib/surface/server.cc,"@@ -1435,30 +1452,40 @@ static grpc_call_error queue_call_request(grpc_server* server, size_t cq_idx,       rm = &rc->data.registered.method->matcher;       break;   }-  if (gpr_locked_mpscq_push(&rm->requests_per_cq[cq_idx], &rc->request_link)) {-    /* this was the first queued request: we need to lock and start-       matching calls */-    gpr_mu_lock(&server->mu_call);-    while ((calld = rm->pending_head) != nullptr) {-      rc = reinterpret_cast<requested_call*>(-          gpr_locked_mpscq_pop(&rm->requests_per_cq[cq_idx]));-      if (rc == nullptr) break;-      rm->pending_head = calld->pending_next;-      gpr_mu_unlock(&server->mu_call);-      if (!gpr_atm_full_cas(&calld->state, PENDING, ACTIVATED)) {-        // Zombied Call-        GRPC_CLOSURE_INIT(-            &calld->kill_zombie_closure, kill_zombie,-            grpc_call_stack_element(grpc_call_get_call_stack(calld->call), 0),-            grpc_schedule_on_exec_ctx);-        GRPC_CLOSURE_SCHED(&calld->kill_zombie_closure, GRPC_ERROR_NONE);-      } else {-        publish_call(server, calld, cq_idx, rc);-      }-      gpr_mu_lock(&server->mu_call);-    }++  // Fast path: if this is not the first request or there is no pending request+  //            to be processed, immediately return.+  if (!gpr_locked_mpscq_push(&rm->requests_per_cq[cq_idx], &rc->request_link) ||+      // Note: We are reading the process_pending_head without holding the+      //       server's call mutex. We need to gaurantee that this load is not+      //       reordered with the store in publish_new_rpc(). Otherwise, we may+      //       read a false value and miss processing the pending head.+      !rm->process_pending_head.load(std::memory_order_acquire)) {+    return GRPC_CALL_OK;+  }+  // Slow path: This was the first queued request and there are pendings:+  //            We need to lock and start matching calls.+  gpr_mu_lock(&server->mu_call);+  while ((calld = rm->pending_head) != nullptr) {+    rc = reinterpret_cast<requested_call*>(+        gpr_locked_mpscq_pop(&rm->requests_per_cq[cq_idx]));+    if (rc == nullptr) break;+    rm->pending_head = calld->pending_next;     gpr_mu_unlock(&server->mu_call);+    if (!gpr_atm_full_cas(&calld->state, PENDING, ACTIVATED)) {+      // Zombied Call+      GRPC_CLOSURE_INIT(+          &calld->kill_zombie_closure, kill_zombie,+          grpc_call_stack_element(grpc_call_get_call_stack(calld->call), 0),+          grpc_schedule_on_exec_ctx);+      GRPC_CLOSURE_SCHED(&calld->kill_zombie_closure, GRPC_ERROR_NONE);+    } else {+      publish_call(server, calld, cq_idx, rc);+    }+    gpr_mu_lock(&server->mu_call);   }+  rm->process_pending_head.store(false, std::memory_order_relaxed);","Thank you. That's a great question. I thought of that scenario and could explain it as infeasible, because Thread A at Step 3, will see a non empty queue and won't add to the pending_head:https://github.com/grpc/grpc/blob/master/src/core/lib/surface/server.cc#L553..L570In other words, as long as, Thread B loads the boolean *after* adding something to the queue, we can't have that scenario.That said, while writing this comment, it occurred to me that my argument only applies if there is only one thread A. This is completely broken if we have thread A1 and A2 doing the same steps you mentioned, back to back. A1 will see a non-empty queue, so it's safe. But A2, will see empty queues and process_pending_head is false.To fix this I think I should use an atomic counter, that is incremented/decremented instead of boolean. We can only bypass the mutex if the counter is 0. Can you please double check this idea?",OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/17640,245467826,2019-01-05T05:38:03Z,src/core/lib/surface/server.cc,"@@ -1435,30 +1452,40 @@ static grpc_call_error queue_call_request(grpc_server* server, size_t cq_idx,       rm = &rc->data.registered.method->matcher;       break;   }-  if (gpr_locked_mpscq_push(&rm->requests_per_cq[cq_idx], &rc->request_link)) {-    /* this was the first queued request: we need to lock and start-       matching calls */-    gpr_mu_lock(&server->mu_call);-    while ((calld = rm->pending_head) != nullptr) {-      rc = reinterpret_cast<requested_call*>(-          gpr_locked_mpscq_pop(&rm->requests_per_cq[cq_idx]));-      if (rc == nullptr) break;-      rm->pending_head = calld->pending_next;-      gpr_mu_unlock(&server->mu_call);-      if (!gpr_atm_full_cas(&calld->state, PENDING, ACTIVATED)) {-        // Zombied Call-        GRPC_CLOSURE_INIT(-            &calld->kill_zombie_closure, kill_zombie,-            grpc_call_stack_element(grpc_call_get_call_stack(calld->call), 0),-            grpc_schedule_on_exec_ctx);-        GRPC_CLOSURE_SCHED(&calld->kill_zombie_closure, GRPC_ERROR_NONE);-      } else {-        publish_call(server, calld, cq_idx, rc);-      }-      gpr_mu_lock(&server->mu_call);-    }++  // Fast path: if this is not the first request or there is no pending request+  //            to be processed, immediately return.+  if (!gpr_locked_mpscq_push(&rm->requests_per_cq[cq_idx], &rc->request_link) ||+      // Note: We are reading the process_pending_head without holding the+      //       server's call mutex. We need to gaurantee that this load is not+      //       reordered with the store in publish_new_rpc(). Otherwise, we may+      //       read a false value and miss processing the pending head.+      !rm->process_pending_head.load(std::memory_order_acquire)) {+    return GRPC_CALL_OK;+  }+  // Slow path: This was the first queued request and there are pendings:+  //            We need to lock and start matching calls.+  gpr_mu_lock(&server->mu_call);+  while ((calld = rm->pending_head) != nullptr) {+    rc = reinterpret_cast<requested_call*>(+        gpr_locked_mpscq_pop(&rm->requests_per_cq[cq_idx]));+    if (rc == nullptr) break;+    rm->pending_head = calld->pending_next;     gpr_mu_unlock(&server->mu_call);+    if (!gpr_atm_full_cas(&calld->state, PENDING, ACTIVATED)) {+      // Zombied Call+      GRPC_CLOSURE_INIT(+          &calld->kill_zombie_closure, kill_zombie,+          grpc_call_stack_element(grpc_call_get_call_stack(calld->call), 0),+          grpc_schedule_on_exec_ctx);+      GRPC_CLOSURE_SCHED(&calld->kill_zombie_closure, GRPC_ERROR_NONE);+    } else {+      publish_call(server, calld, cq_idx, rc);+    }+    gpr_mu_lock(&server->mu_call);   }+  rm->process_pending_head.store(false, std::memory_order_relaxed);","My suggestion is to tie the atomic counter to the size of the pending list. The current implementation (where it's not tied to the size) has a few problems:1) Let's say Threads A1 and A2 reach line 1463 `gpr_atm_no_barrier_load(&rm->process_pending_head) == 0) ` and they are dealing with different cq indices. Let's say `&rm->process_pending_head` = 1. Then, A1 and A2 will both fall through and try to process the pending request. They will both eventually decrement `rm->process_pending_head` and it will be equal to -1. This is problematic because the next time something gets added to the pending list, the atomic will be updated to zero, and that request could get starved because queue_call_request will return early.2) The other problem is that the atomic might get incremented in line 567, but a request may not get added to the pending list because we might return early around line 580. In queue_call_request, we might spuriously attempt to process the pending list, which kind of defeats the performance optimization. It probably won't happen often since we do double-check locking there, but it's a possibility.One concern with this suggestion is that it could degrade performance with the extra atomic increments and decrements. You could probably get around this by keeping a local variable in the while loop at line 1469 to keep track of how many pending requests were handled and then just do one atomic decrement when the loop is finished. ",OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17640,245522930,2019-01-06T21:24:20Z,src/core/lib/surface/server.cc,"@@ -1435,30 +1452,40 @@ static grpc_call_error queue_call_request(grpc_server* server, size_t cq_idx,       rm = &rc->data.registered.method->matcher;       break;   }-  if (gpr_locked_mpscq_push(&rm->requests_per_cq[cq_idx], &rc->request_link)) {-    /* this was the first queued request: we need to lock and start-       matching calls */-    gpr_mu_lock(&server->mu_call);-    while ((calld = rm->pending_head) != nullptr) {-      rc = reinterpret_cast<requested_call*>(-          gpr_locked_mpscq_pop(&rm->requests_per_cq[cq_idx]));-      if (rc == nullptr) break;-      rm->pending_head = calld->pending_next;-      gpr_mu_unlock(&server->mu_call);-      if (!gpr_atm_full_cas(&calld->state, PENDING, ACTIVATED)) {-        // Zombied Call-        GRPC_CLOSURE_INIT(-            &calld->kill_zombie_closure, kill_zombie,-            grpc_call_stack_element(grpc_call_get_call_stack(calld->call), 0),-            grpc_schedule_on_exec_ctx);-        GRPC_CLOSURE_SCHED(&calld->kill_zombie_closure, GRPC_ERROR_NONE);-      } else {-        publish_call(server, calld, cq_idx, rc);-      }-      gpr_mu_lock(&server->mu_call);-    }++  // Fast path: if this is not the first request or there is no pending request+  //            to be processed, immediately return.+  if (!gpr_locked_mpscq_push(&rm->requests_per_cq[cq_idx], &rc->request_link) ||+      // Note: We are reading the process_pending_head without holding the+      //       server's call mutex. We need to gaurantee that this load is not+      //       reordered with the store in publish_new_rpc(). Otherwise, we may+      //       read a false value and miss processing the pending head.+      !rm->process_pending_head.load(std::memory_order_acquire)) {+    return GRPC_CALL_OK;+  }+  // Slow path: This was the first queued request and there are pendings:+  //            We need to lock and start matching calls.+  gpr_mu_lock(&server->mu_call);+  while ((calld = rm->pending_head) != nullptr) {+    rc = reinterpret_cast<requested_call*>(+        gpr_locked_mpscq_pop(&rm->requests_per_cq[cq_idx]));+    if (rc == nullptr) break;+    rm->pending_head = calld->pending_next;     gpr_mu_unlock(&server->mu_call);+    if (!gpr_atm_full_cas(&calld->state, PENDING, ACTIVATED)) {+      // Zombied Call+      GRPC_CLOSURE_INIT(+          &calld->kill_zombie_closure, kill_zombie,+          grpc_call_stack_element(grpc_call_get_call_stack(calld->call), 0),+          grpc_schedule_on_exec_ctx);+      GRPC_CLOSURE_SCHED(&calld->kill_zombie_closure, GRPC_ERROR_NONE);+    } else {+      publish_call(server, calld, cq_idx, rc);+    }+    gpr_mu_lock(&server->mu_call);   }+  rm->process_pending_head.store(false, std::memory_order_relaxed);","@hcaseyal I think I found a solution to fix the issue with the ""atomic<boolean>"" version. Please see the last push.The idea is to also set the flag to true when we set `pending_head`. With that, in the scenario in your first comment, we will have ""Thread A acquires the mutex and publishes the rpc such that we have a pending request, and set the flag if needed."" So, the flag is guaranteed to true, if `pending_head` is not nullptr.Windows tests pass, along with all all other tests. Could you PTAL?",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/17549,245731302,2019-01-07T17:17:18Z,include/grpc/grpc_security.h,"@@ -609,6 +609,192 @@ GRPCAPI grpc_channel_credentials* grpc_local_credentials_create( GRPCAPI grpc_server_credentials* grpc_local_server_credentials_create(     grpc_local_connect_type type); +/** --- SPIFFE and HTTPS-based TLS channel/server credentials --- **/++/** Config for TLS key materials. */+typedef struct grpc_tls_key_materials_config grpc_tls_key_materials_config;++/** Config for TLS credential reload. */+typedef struct grpc_tls_credential_reload_config+    grpc_tls_credential_reload_config;++/** Config for TLS server authorization check. */+typedef struct grpc_tls_server_authorization_check_config+    grpc_tls_server_authorization_check_config;++/** TLS credentials options. */+typedef struct grpc_tls_credentials_options grpc_tls_credentials_options;++/** Create an empty TLS credentials options. */+GRPCAPI grpc_tls_credentials_options* grpc_tls_credentials_options_create();++/** Set grpc_ssl_client_certificate_request_type field in credentials options+    with the provided type. */+GRPCAPI void grpc_tls_credentials_options_set_cert_request_type(+    grpc_tls_credentials_options* options,+    grpc_ssl_client_certificate_request_type type);++/** Set grpc_tls_key_materials_config field in credentials options+    with the provided config struct whose ownership is transferred. */+GRPCAPI void grpc_tls_credentials_options_set_key_materials_config(+    grpc_tls_credentials_options* options,+    grpc_tls_key_materials_config* config);++/** Set grpc_tls_credential_reload_config field in credentials options+    with the provided config struct whose ownership is transferred. */+GRPCAPI void grpc_tls_credentials_options_set_credential_reload_config(+    grpc_tls_credentials_options* options,+    grpc_tls_credential_reload_config* config);++/** Set grpc_tls_server_authorization_check_config field in credentials options+    with the provided config struct whose ownership is transferred. */+GRPCAPI void grpc_tls_credentials_options_set_server_authorization_check_config(+    grpc_tls_credentials_options* options,+    grpc_tls_server_authorization_check_config* config);++/** --- TLS key materials config. --- **/++/** Create an empty grpc_tls_key_materials_config instance. */+GRPCAPI grpc_tls_key_materials_config* grpc_tls_key_materials_config_create();++/** Set grpc_tls_key_materials_config instance with provided a TLS certificate.+ */+GRPCAPI void grpc_tls_key_materials_config_set_key_materials(+    grpc_tls_key_materials_config* config,+    const grpc_ssl_pem_key_cert_pair* pem_key_cert_pairs,+    const char* pem_root_certs, size_t num_key_cert_pairs);",Parameters pem_key_cert_pairs and num_key_cert_pairs should be grouped together. Move pem_root_certs as the 2nd parameter or 4th parameter.,
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/17643,245767086,2019-01-07T19:17:17Z,test/core/bad_connection/close_fd_test.cc,"@@ -0,0 +1,731 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""test/core/util/test_config.h""++#include <stdio.h>+#include <string.h>+#include <unistd.h>++#include <grpc/byte_buffer.h>+#include <grpc/byte_buffer_reader.h>+#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/time.h>+#include ""src/core/ext/transport/chttp2/transport/chttp2_transport.h""+#include ""src/core/lib/iomgr/endpoint_pair.h""+#include ""src/core/lib/surface/channel.h""+#include ""src/core/lib/surface/completion_queue.h""+#include ""src/core/lib/surface/server.h""++static void* tag(intptr_t t) { return (void*)t; }++typedef struct test_ctx test_ctx;++struct test_ctx {+  grpc_completion_queue* cq;+  grpc_completion_queue* shutdown_cq;+  grpc_completion_queue* client_cq;+  grpc_completion_queue* bound_cq;+  grpc_server* server;+  grpc_channel* client;+  grpc_endpoint_pair* ep;+};++/* chttp2 transport that is immediately available (used for testing+   connected_channel without a client_channel */++static void server_setup_transport(test_ctx* ctx, grpc_transport* transport) {+  grpc_core::ExecCtx exec_ctx;+  grpc_endpoint_add_to_pollset(ctx->ep->server, grpc_cq_pollset(ctx->cq));+  grpc_server_setup_transport(ctx->server, transport, nullptr,+                              grpc_server_get_channel_args(ctx->server),+                              nullptr);+}++static void client_setup_transport(test_ctx* ctx, grpc_transport* transport) {+  grpc_arg authority_arg = grpc_channel_arg_string_create(+      const_cast<char*>(GRPC_ARG_DEFAULT_AUTHORITY),+      const_cast<char*>(""test-authority""));+  grpc_channel_args* args =+      grpc_channel_args_copy_and_add(nullptr, &authority_arg, 1);+  /* TODO (pjaikumar): use GRPC_CLIENT_CHANNEL instead of+   * GRPC_CLIENT_DIRECT_CHANNEL */+  ctx->client = grpc_channel_create(""socketpair-target"", args,+                                    GRPC_CLIENT_DIRECT_CHANNEL, transport);+  grpc_channel_args_destroy(args);+}++static void init_client(test_ctx* ctx) {+  grpc_core::ExecCtx exec_ctx;+  grpc_transport* transport;+  transport = grpc_create_chttp2_transport(nullptr, ctx->ep->client, true);+  client_setup_transport(ctx, transport);+  GPR_ASSERT(ctx->client);+  grpc_chttp2_transport_start_reading(transport, nullptr, nullptr);+}++static void init_server(test_ctx* ctx) {+  grpc_core::ExecCtx exec_ctx;+  grpc_transport* transport;+  GPR_ASSERT(!ctx->server);+  ctx->server = grpc_server_create(nullptr, nullptr);+  grpc_server_register_completion_queue(ctx->server, ctx->cq, nullptr);+  grpc_server_start(ctx->server);+  transport = grpc_create_chttp2_transport(nullptr, ctx->ep->server, false);+  server_setup_transport(ctx, transport);+  grpc_chttp2_transport_start_reading(transport, nullptr, nullptr);+}++static void test_init(test_ctx* ctx) {+  grpc_endpoint_pair* sfd =+      static_cast<grpc_endpoint_pair*>(gpr_malloc(sizeof(grpc_endpoint_pair)));+  memset(ctx, 0, sizeof(*ctx));+  ctx->ep = sfd;+  ctx->cq = grpc_completion_queue_create_for_next(nullptr);+  ctx->shutdown_cq = grpc_completion_queue_create_for_pluck(nullptr);+  ctx->bound_cq = grpc_completion_queue_create_for_next(nullptr);+  ctx->client_cq = grpc_completion_queue_create_for_next(nullptr);++  /* Create endpoints */+  *sfd = grpc_iomgr_create_endpoint_pair(""fixture"", nullptr);+  /* Create client, server and setup transport over endpoint pair */+  init_server(ctx);+  init_client(ctx);+}++static void drain_cq(grpc_completion_queue* cq) {+  grpc_event ev;+  do {+    ev = grpc_completion_queue_next(cq, grpc_timeout_seconds_to_deadline(1),+                                    nullptr);+  } while (ev.type != GRPC_QUEUE_SHUTDOWN);+}++static void drain_and_destroy_cq(grpc_completion_queue* cq) {+  grpc_completion_queue_shutdown(cq);+  drain_cq(cq);+  grpc_completion_queue_destroy(cq);+}++static void shutdown_server(test_ctx* ctx) {+  if (!ctx->server) return;+  grpc_server_shutdown_and_notify(ctx->server, ctx->shutdown_cq, tag(1000));+  GPR_ASSERT(grpc_completion_queue_pluck(ctx->shutdown_cq, tag(1000),+                                         grpc_timeout_seconds_to_deadline(1),+                                         nullptr)+                 .type == GRPC_OP_COMPLETE);+  grpc_server_destroy(ctx->server);+  ctx->server = nullptr;+}++static void shutdown_client(test_ctx* ctx) {+  if (!ctx->client) return;+  grpc_channel_destroy(ctx->client);+  ctx->client = nullptr;+}++static void end_test(test_ctx* ctx) {+  shutdown_server(ctx);+  shutdown_client(ctx);++  drain_and_destroy_cq(ctx->cq);+  drain_and_destroy_cq(ctx->client_cq);+  drain_and_destroy_cq(ctx->bound_cq);+  grpc_completion_queue_destroy(ctx->shutdown_cq);+  gpr_free(ctx->ep);+}++typedef enum fd_type { CLIENT_FD, SERVER_FD } fd_type;++static const char* fd_type_str(fd_type f) {+  if (f == CLIENT_FD) {+    return ""client"";+  } else if (f == SERVER_FD) {+    return ""server"";+  } else {+    gpr_log(GPR_ERROR, ""Unexpected fd_type %d"", f);+    abort();+  }+}++static void _test_close_before_server_recv(fd_type f) {+  grpc_core::ExecCtx exec_ctx;+  grpc_call* c;+  grpc_call* s;+  grpc_event e;+  grpc_slice request_payload_slice =+      grpc_slice_from_copied_string(""hello world"");+  grpc_slice response_payload_slice =+      grpc_slice_from_copied_string(""hello you"");+  grpc_byte_buffer* request_payload =+      grpc_raw_byte_buffer_create(&request_payload_slice, 1);+  grpc_byte_buffer* response_payload =+      grpc_raw_byte_buffer_create(&response_payload_slice, 1);+  gpr_log(GPR_INFO, ""Running test: test_close_%s_before_server_recv"",+          fd_type_str(f));+  test_ctx ctx;+  test_init(&ctx);++  grpc_op ops[6];+  grpc_op* op;+  grpc_metadata_array initial_metadata_recv;+  grpc_metadata_array trailing_metadata_recv;+  grpc_metadata_array request_metadata_recv;+  grpc_byte_buffer* request_payload_recv = nullptr;+  grpc_byte_buffer* response_payload_recv = nullptr;+  grpc_call_details call_details;+  grpc_status_code status = GRPC_STATUS__DO_NOT_USE;+  grpc_call_error error;+  grpc_slice details;++  gpr_timespec deadline = grpc_timeout_seconds_to_deadline(1);+  grpc_endpoint_add_to_pollset(ctx.ep->client, grpc_cq_pollset(ctx.client_cq));",This looks like something that belongs to `test_init`,
26072277,dfawley,https://api.github.com/repos/grpc/grpc/pulls/17427,245800295,2019-01-07T21:16:35Z,tools/interop_matrix/client_matrix.py,"@@ -110,52 +125,89 @@ def should_build_docker_interop_image_from_release_tag(lang):     ],     'go': [         {-            'v1.0.5': None+            'v1.0.5': {+                'skip_runtime': ['go1.11']",Could this be inverted so you specify runtimes used instead of skipped?  Otherwise this list will need to continually grow as we add runtimes.,
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/17640,245851076,2019-01-08T01:13:30Z,src/core/lib/surface/server.cc,"@@ -1435,30 +1452,40 @@ static grpc_call_error queue_call_request(grpc_server* server, size_t cq_idx,       rm = &rc->data.registered.method->matcher;       break;   }-  if (gpr_locked_mpscq_push(&rm->requests_per_cq[cq_idx], &rc->request_link)) {-    /* this was the first queued request: we need to lock and start-       matching calls */-    gpr_mu_lock(&server->mu_call);-    while ((calld = rm->pending_head) != nullptr) {-      rc = reinterpret_cast<requested_call*>(-          gpr_locked_mpscq_pop(&rm->requests_per_cq[cq_idx]));-      if (rc == nullptr) break;-      rm->pending_head = calld->pending_next;-      gpr_mu_unlock(&server->mu_call);-      if (!gpr_atm_full_cas(&calld->state, PENDING, ACTIVATED)) {-        // Zombied Call-        GRPC_CLOSURE_INIT(-            &calld->kill_zombie_closure, kill_zombie,-            grpc_call_stack_element(grpc_call_get_call_stack(calld->call), 0),-            grpc_schedule_on_exec_ctx);-        GRPC_CLOSURE_SCHED(&calld->kill_zombie_closure, GRPC_ERROR_NONE);-      } else {-        publish_call(server, calld, cq_idx, rc);-      }-      gpr_mu_lock(&server->mu_call);-    }++  // Fast path: if this is not the first request or there is no pending request+  //            to be processed, immediately return.+  if (!gpr_locked_mpscq_push(&rm->requests_per_cq[cq_idx], &rc->request_link) ||+      // Note: We are reading the process_pending_head without holding the+      //       server's call mutex. We need to gaurantee that this load is not+      //       reordered with the store in publish_new_rpc(). Otherwise, we may+      //       read a false value and miss processing the pending head.+      !rm->process_pending_head.load(std::memory_order_acquire)) {+    return GRPC_CALL_OK;+  }+  // Slow path: This was the first queued request and there are pendings:+  //            We need to lock and start matching calls.+  gpr_mu_lock(&server->mu_call);+  while ((calld = rm->pending_head) != nullptr) {+    rc = reinterpret_cast<requested_call*>(+        gpr_locked_mpscq_pop(&rm->requests_per_cq[cq_idx]));+    if (rc == nullptr) break;+    rm->pending_head = calld->pending_next;     gpr_mu_unlock(&server->mu_call);+    if (!gpr_atm_full_cas(&calld->state, PENDING, ACTIVATED)) {+      // Zombied Call+      GRPC_CLOSURE_INIT(+          &calld->kill_zombie_closure, kill_zombie,+          grpc_call_stack_element(grpc_call_get_call_stack(calld->call), 0),+          grpc_schedule_on_exec_ctx);+      GRPC_CLOSURE_SCHED(&calld->kill_zombie_closure, GRPC_ERROR_NONE);+    } else {+      publish_call(server, calld, cq_idx, rc);+    }+    gpr_mu_lock(&server->mu_call);   }+  rm->process_pending_head.store(false, std::memory_order_relaxed);","The latest commit looks fine to me. It solves problem 1 in my above comment, but still encounters problem 2. As long as the performance numbers show a win, this is okay. ",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17427,246115034,2019-01-08T19:05:11Z,tools/interop_matrix/client_matrix.py,"@@ -110,52 +125,89 @@ def should_build_docker_interop_image_from_release_tag(lang):     ],     'go': [         {-            'v1.0.5': None+            'v1.0.5': {+                'skip_runtime': ['go1.11']","I'd say choosing the runtimes to use is up to the language owners - Ideally we would test everything, but than the test suite would take very long to run, thus limiting the usefulness. So it's a tradeoff between the number of runtimes to test vs infrastructure complexity and time to run.Ad ""removing the concept of runtimes entirely"": I'm totally fine with removing some runtimes  if you think that's a good choice for grpc-go (leaving up to you). But there still needs to be some logic that decides which dockerfiles/runtimes will be used with which release tag (right now that's declared explicitly in the data structures in client_matrix.py, which makes sense IMHO). So even if we only test one runtime per release tag, there will still be a concept of runtime in the interop_matrix scripts (so this wouldn't really simplify the test scripts much).Are you ok with me merging this PR?",
26072277,dfawley,https://api.github.com/repos/grpc/grpc/pulls/17427,246125646,2019-01-08T19:38:20Z,tools/interop_matrix/client_matrix.py,"@@ -110,52 +125,89 @@ def should_build_docker_interop_image_from_release_tag(lang):     ],     'go': [         {-            'v1.0.5': None+            'v1.0.5': {+                'skip_runtime': ['go1.11']","For Go, I don't think there's much value in testing multiple runtimes per release.  As long as we have one that works for every grpc-go version, we should be fine.  There are not substantial differences across Go releases, and they are supposed to be ~100% backward compatible.> Are you ok with me merging this PR?Yes, since it unblocks testing grpc-go 1.17 in interop.  But please invert the way this works to specify good grpc+runtime combinations in a follow-up soon to avoid the long-term maintenance costs as the number of runtimes and releases grow.",OK
4779759,dapengzhang0,https://api.github.com/repos/grpc/grpc/pulls/17578,246173835,2019-01-08T22:26:08Z,src/objective-c/RxLibrary/GRXConcurrentWriteable.m,"@@ -56,35 +64,49 @@ - (void)enqueueValue:(id)value completionHandler:(void (^)(void))handler {       return;     } +    @synchronized (self) {+       if (self->_cancelled) {+         return;+       }+    }+     [self.writeable writeValue:value];     handler();   }); }  - (void)enqueueSuccessfulCompletion {   dispatch_async(_writeableQueue, ^{-    @synchronized(self) {-      if (self->_alreadyFinished) {+    if (self->_alreadyFinished) {+      return;+    }+    @synchronized (self) {+      if (self->_cancelled) {","Ditto.  `@synchronized(self) {}` here does not help much in a race condition. Without `@synchronized(self) {}`, simply declaring `cancelled` as a volatile field or an atomic property will work essentially the same.",OK
4779759,dapengzhang0,https://api.github.com/repos/grpc/grpc/pulls/17578,246191426,2019-01-08T22:58:43Z,src/objective-c/RxLibrary/GRXConcurrentWriteable.m,"@@ -51,78 +60,65 @@ - (instancetype)initWithWriteable:(id<GRXWriteable>)writeable {  - (void)enqueueValue:(id)value completionHandler:(void (^)(void))handler {   dispatch_async(_writeableQueue, ^{-    // We're racing a possible cancellation performed by another thread. To turn all already--    // enqueued messages into noops, cancellation nillifies the writeable property. If we get it-    // before it's nil, we won the race.-    id<GRXWriteable> writeable = self.writeable;-    if (writeable) {-      [writeable writeValue:value];-      handler();+    if (self->_alreadyFinished) {+      return;+    }++    @synchronized(self) {+      if (self->_cancelled) {"," `@synchronized(self) {}` here does not help much in a race condition. Without `@synchronized(self) {}`, simply declaring `cancelled` as a volatile field or an atomic property will work essentially the same.",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/17578,246205477,2019-01-08T23:37:46Z,src/objective-c/GRPCClient/GRPCCall.m,"@@ -572,19 +570,7 @@ - (void)cancel {                                      userInfo:@{NSLocalizedDescriptionKey : @""Canceled by app""}]];     [_wrappedCall cancel];   }-}--- (void)maybeFinishWithError:(NSError *)errorOrNil {-  BOOL toFinish = NO;-  @synchronized(self) {-    if (_finished == NO) {-      _finished = YES;",No longer used in `GRPCCall`. Good catch.,OK
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17617,246468736,2019-01-09T17:20:38Z,src/python/grpcio_channelz/grpc_channelz/v1/channelz.py,"@@ -140,3 +143,35 @@ def add_channelz_servicer(server):     """"""     _channelz_pb2_grpc.add_ChannelzServicer_to_server(ChannelzServicer(),                                                       server)+++def serve_channelz_page(host=None, port=None):+    """"""Start an HTTP server serving Channelz Pages.++    The pages will be served under: http://<URL>/gdebug/channelz/+    The gRPC server/client have to be started prior to requesting the server.+    Otherwise, the gRPC C-Core won't be started, and it will throw SIGABORT+    terminating the process.++    To close the HTTP server cleanly, you need to call 'shutdown()' and+    'server_close()' on the returned HTTP server instance. For more details,+    please check the definition of Python's BaseServer:+    https://docs.python.org/3/library/socketserver.html#socketserver.BaseServer++    This is an EXPERIMENTAL API.++    Args:+      host: a str indicates the address of the HTTP server.","How about `host: A string specifying the host on which the HTTP server should listen` (similar change for `port`)The address is a `host, port` pair so we probably don't want to call the host an address here.",
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17617,246469189,2019-01-09T17:21:55Z,src/python/grpcio_channelz/grpc_channelz/v1/_channelz_page.py,"@@ -0,0 +1,277 @@+# Copyright 2019 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import os+import pkgutil+import collections+import traceback+from six.moves.BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer+from six.moves.urllib.parse import parse_qs, urlparse++from grpc._cython import cygrpc+import grpc_channelz.v1.channelz_pb2 as _channelz_pb2+from google.protobuf import json_format++from ._renderer import _Renderer",Don't use import statements for individual classes (http://google.github.io/styleguide/pyguide.html#22-imports). This should also not use `from ._renderer` and instead should be `from grpc_channelz.v1 import _renderer`.Which leads to the follow-up: why is this importing a private class from another module? Should `_Renderer` be renamed to `Renderer`?,OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/17617,246482015,2019-01-09T17:58:52Z,src/python/grpcio_channelz/grpc_channelz/v1/_channelz_page.py,"@@ -0,0 +1,277 @@+# Copyright 2019 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import os+import pkgutil+import collections+import traceback+from six.moves.BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer+from six.moves.urllib.parse import parse_qs, urlparse++from grpc._cython import cygrpc+import grpc_channelz.v1.channelz_pb2 as _channelz_pb2+from google.protobuf import json_format++from ._renderer import _Renderer++_TEMPLATE_FOLDER = './templates'++_PAGE = collections.namedtuple('_PAGE', ['title', 'template', 'handler'])+_SERVER_N_SOCKETS = collections.namedtuple('_SERVER_N_SOCKETS',+                                           ['server', 'listen_sockets'])++_renderer = _Renderer()+++def _fetch_template(template_name):+    return pkgutil.get_data(__name__,+                            os.path.join(_TEMPLATE_FOLDER,","I wonder if this will work on Windows.[ `pkgutil.get_data` uses `/` as a separator](https://docs.python.org/3/library/pkgutil.html#pkgutil.get_data), seemingly regardless of platform. I'm not sure if `os.path.join` is what we want in this particular case.",
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/17617,246488721,2019-01-09T18:20:52Z,src/python/grpcio_tests/tests/channelz/_channelz_page_test.py,"@@ -0,0 +1,212 @@+# Copyright 2019 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Tests of Serving HTTPS Channelz Page.""""""++import unittest+import time+import logging+import re++import requests++import grpc+from grpc_channelz.v1 import channelz++from tests.unit import test_common+from tests.unit.framework.common import test_constants++# Matches first link inside of a table+_table_a_href_re = re.compile(r'<table.+?<a href=[\'""](.+?)[\'""]', re.DOTALL)","If it works, it works. But in general, I would recommend [an HTML parser](https://docs.python.org/2/library/htmlparser.html) to regexes.",OK
4779759,dapengzhang0,https://api.github.com/repos/grpc/grpc/pulls/17578,246491107,2019-01-09T18:28:47Z,src/objective-c/RxLibrary/GRXConcurrentWriteable.m,"@@ -51,78 +60,65 @@ - (instancetype)initWithWriteable:(id<GRXWriteable>)writeable {  - (void)enqueueValue:(id)value completionHandler:(void (^)(void))handler {   dispatch_async(_writeableQueue, ^{-    // We're racing a possible cancellation performed by another thread. To turn all already--    // enqueued messages into noops, cancellation nillifies the writeable property. If we get it-    // before it's nil, we won the race.-    id<GRXWriteable> writeable = self.writeable;-    if (writeable) {-      [writeable writeValue:value];-      handler();+    if (self->_alreadyFinished) {+      return;+    }++    @synchronized(self) {+      if (self->_cancelled) {","The document http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n2016.html says `volatile` in c does not provide **inter-thread visibility** in general platforms. While when restricted to iOS/MacOS obj-c platforms it does provides inter-thread visibility: https://developer.apple.com/library/archive/documentation/Cocoa/Conceptual/Multithreading/ThreadSafety/ThreadSafety.htmlDue to its subtlety, I'm okay with not to risk using `volatile`.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17617,246531907,2019-01-09T20:34:34Z,src/python/grpcio_channelz/grpc_channelz/v1/_channelz_page.py,"@@ -0,0 +1,277 @@+# Copyright 2019 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import os+import pkgutil+import collections+import traceback+from six.moves.BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer+from six.moves.urllib.parse import parse_qs, urlparse++from grpc._cython import cygrpc+import grpc_channelz.v1.channelz_pb2 as _channelz_pb2+from google.protobuf import json_format++from ._renderer import _Renderer++_TEMPLATE_FOLDER = './templates'++_PAGE = collections.namedtuple('_PAGE', ['title', 'template', 'handler'])+_SERVER_N_SOCKETS = collections.namedtuple('_SERVER_N_SOCKETS',+                                           ['server', 'listen_sockets'])++_renderer = _Renderer()+++def _fetch_template(template_name):+    return pkgutil.get_data(__name__,+                            os.path.join(_TEMPLATE_FOLDER,+                                         template_name)).decode('ASCII')+++_base_template = _fetch_template('base.html')+++def _parse_args(path):+    args = parse_qs(urlparse(path).query)+    for key in args:+        if isinstance(args[key], list) and len(args[key]) == 1:+            args[key] = args[key][0]+    return args+++class _NotFound(Exception):+    pass+++class _BadRequest(Exception):+    pass+++def _homepage_handler(render, unused_args):+    return render()+++def _topchannels_handler(render, args):+    start_channel_id = int(args.get('start_channel_id', '0'))+    topchannels = json_format.Parse(+        cygrpc.channelz_get_top_channels(start_channel_id),+        _channelz_pb2.GetTopChannelsResponse(),+    ).channel+    if not topchannels:+        raise _NotFound(+            'No channel found for ""start_channel_id""==%d' % start_channel_id)+    return render(+        topchannels=topchannels,+        num_channel=len(topchannels),+        min_id=min(channel.ref.channel_id for channel in topchannels),+        max_id=max(channel.ref.channel_id for channel in topchannels))+++def _channel_handler(render, args):+    if 'channel_id' not in args:+        raise _BadRequest('""channel_id"" cannot be empty')+    channel_id = int(args.get('channel_id'))+    channel = json_format.Parse(+        cygrpc.channelz_get_channel(channel_id),+        _channelz_pb2.GetChannelResponse(),+    ).channel++    nested_channels = []+    for ref in channel.channel_ref:+        nested_channels.append(+            json_format.Parse(+                cygrpc.channelz_get_channel(ref.channel_id),+                _channelz_pb2.GetChannelResponse(),+            ).channel)++    subchannels = []+    for ref in channel.subchannel_ref:+        subchannels.append(+            json_format.Parse(+                cygrpc.channelz_get_subchannel(ref.subchannel_id),+                _channelz_pb2.GetSubchannelResponse(),+            ).subchannel)++    return render(+        channel=channel,+        nested_channels=nested_channels,+        subchannels=subchannels)+++def _subchannel_handler(render, args):+    if 'subchannel_id' not in args:+        raise _BadRequest('""subchannel_id"" cannot be empty')+    subchannel_id = int(args.get('subchannel_id'))+    subchannel = json_format.Parse(+        cygrpc.channelz_get_subchannel(subchannel_id),+        _channelz_pb2.GetSubchannelResponse(),+    ).subchannel++    sockets = []+    for ref in subchannel.socket_ref:+        sockets.append(+            json_format.Parse(+                cygrpc.channelz_get_socket(ref.socket_id),+                _channelz_pb2.GetSocketResponse(),+            ).socket)++    return render(subchannel=subchannel, sockets=sockets)+++def _socket_handler(render, args):+    if 'socket_id' not in args:+        raise _BadRequest('""socket_id"" cannot be empty')+    socket_id = int(args.get('socket_id'))+    socket = json_format.Parse(+        cygrpc.channelz_get_socket(socket_id),+        _channelz_pb2.GetSocketResponse(),+    ).socket++    return render(socket=socket)+++def _servers_handler(render, args):+    start_server_id = int(args.get('start_server_id', '0'))+    servers = json_format.Parse(+        cygrpc.channelz_get_servers(start_server_id),+        _channelz_pb2.GetServersResponse(),+    ).server++    if not servers:+        raise _NotFound(+            'No server found for ""start_server_id""==%d' % start_server_id)++    servers_n_sockets = []+    for server in servers:+        listen_sockets = []+        for ref in server.listen_socket:+            listen_sockets.append(+                json_format.Parse(+                    cygrpc.channelz_get_socket(ref.socket_id),+                    _channelz_pb2.GetSocketResponse(),+                ).socket)+        servers_n_sockets.append(_SERVER_N_SOCKETS(server, listen_sockets))++    return render(+        num_servers=len(servers),+        min_id=min(server.ref.server_id for server in servers),+        max_id=max(server.ref.server_id for server in servers),+        servers_n_sockets=servers_n_sockets)+++def _serversockets_handler(render, args):+    if 'server_id' not in args:+        raise _BadRequest('""server_id"" cannot be empty')+    server_id = int(args.get('server_id'))+    start_socket_id = int(args.get('start_socket_id', '0'))+    server = json_format.Parse(+        cygrpc.channelz_get_server(server_id),+        _channelz_pb2.GetServerResponse(),+    ).server+    serversocket_refs = json_format.Parse(+        cygrpc.channelz_get_server_sockets(server_id, start_socket_id, 0),+        _channelz_pb2.GetServerSocketsResponse(),+    ).socket_ref++    if not serversocket_refs:+        raise _NotFound(+            'No server socket found for ""server_id""==%d' % server_id)++    serversockets = []+    for ref in serversocket_refs:+        serversockets.append(+            json_format.Parse(+                cygrpc.channelz_get_socket(ref.socket_id),+                _channelz_pb2.GetSocketResponse(),+            ).socket)++    return render(+        server=server,+        serversockets=serversockets,+        num_serversockets=len(serversockets),+        min_id=min(ref.socket_id for ref in serversocket_refs),+        max_id=max(ref.socket_id for ref in serversocket_refs))+++_SERVING_PAGES = {+    '':+    _PAGE('<nil>', 'index.html', _homepage_handler),+    'channel':+    _PAGE('Channel', 'channel.html', _channel_handler),+    'servers':+    _PAGE('Servers', 'servers.html', _servers_handler),+    'serversockets':+    _PAGE('ServerSockets', 'serversockets.html', _serversockets_handler),+    'socket':+    _PAGE('Socket', 'socket.html', _socket_handler),+    'subchannel':+    _PAGE('Subchannel', 'subchannel.html', _subchannel_handler),+    'topchannels':+    _PAGE('TopChannels', 'topchannels.html', _topchannels_handler),+}+++class _RequestHandler(BaseHTTPRequestHandler):++    def _set_ok_headers(self):+        self.send_response(200)+        self.send_header('Content-type', 'text/html')+        self.end_headers()++    def _handle(self):+        if not self.path.startswith('/gdebug/channelz/'):+            raise _NotFound()++        request_page = self.path[17:].split('?', 1)[0]+        if request_page not in _SERVING_PAGES:+            raise _NotFound('Page not found')+        serving_page = _SERVING_PAGES[request_page]++        base_page = _renderer.format(+            _base_template,+            title=serving_page.title,+            content=_fetch_template(serving_page.template))++        # Encapsulate _renderer and base_page into an enclosure+        def render(*args, **kwargs):+            return _renderer.format(base_page, *args, **kwargs)++        full_page = serving_page.handler(render, _parse_args(self.path))+        self._set_ok_headers()+        self.wfile.write(full_page.encode('ASCII'))++    def do_GET(self):+        try:+            self._handle()+        except _BadRequest as e:+            self.send_error(400, str(e))+        except _NotFound as e:+            self.send_error(404, str(e))+        except ValueError as e:+            stack_str = traceback.format_exc()+            if '_cython.cygrpc.channelz' in stack_str:","Alternatively, we can derive a new exception class in Cython layer. But I found it is not the common pattern in our Cython layer. Do you have better idea?",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17617,246535765,2019-01-09T20:42:22Z,src/python/grpcio_channelz/grpc_channelz/v1/_channelz_page.py,"@@ -0,0 +1,277 @@+# Copyright 2019 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import os+import pkgutil+import collections+import traceback+from six.moves.BaseHTTPServer import BaseHTTPRequestHandler, HTTPServer+from six.moves.urllib.parse import parse_qs, urlparse++from grpc._cython import cygrpc+import grpc_channelz.v1.channelz_pb2 as _channelz_pb2+from google.protobuf import json_format++from ._renderer import _Renderer","Updated. I thought the `_Renderer` class is not intended to expose to our users, so it should just be marked as private. Since the module name itself is started with `_`, I guess it is fine.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17617,246538389,2019-01-09T20:51:36Z,src/python/grpcio_channelz/grpc_channelz/v1/_renderer.py,"@@ -0,0 +1,55 @@+# Copyright 2019 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import string+import grpc_channelz.v1.channelz_pb2 as _channelz_pb2++_EMPTY_TIME_STR = '1970-01-01T00:00:00Z'+++def _sanitize(text):","Aha, I didn't find this package, that's handy.Update: The `cgi.escape` is deprecated in Python 3.2... I switched back to replace.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17617,246549048,2019-01-09T21:18:00Z,src/python/grpcio_channelz/grpc_channelz/v1/channelz.py,"@@ -140,3 +143,35 @@ def add_channelz_servicer(server):     """"""     _channelz_pb2_grpc.add_ChannelzServicer_to_server(ChannelzServicer(),                                                       server)+++def serve_channelz_page(host=None, port=None):+    """"""Start an HTTP server serving Channelz Pages.++    The pages will be served under: http://<URL>/gdebug/channelz/+    The gRPC server/client have to be started prior to requesting the server.+    Otherwise, the gRPC C-Core won't be started, and it will throw SIGABORT+    terminating the process.++    To close the HTTP server cleanly, you need to call 'shutdown()' and+    'server_close()' on the returned HTTP server instance. For more details,+    please check the definition of Python's BaseServer:+    https://docs.python.org/3/library/socketserver.html#socketserver.BaseServer++    This is an EXPERIMENTAL API.++    Args:+      host: a str indicates the address of the HTTP server.","Updated to `host: a str specifying the host on which the HTTP server should listen.`.Yeah, that's more accurate.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17617,246550818,2019-01-09T21:23:45Z,src/python/grpcio_channelz/grpc_channelz/v1/channelz.py,"@@ -140,3 +143,35 @@ def add_channelz_servicer(server):     """"""     _channelz_pb2_grpc.add_ChannelzServicer_to_server(ChannelzServicer(),                                                       server)+++def serve_channelz_page(host=None, port=None):+    """"""Start an HTTP server serving Channelz Pages.++    The pages will be served under: http://<URL>/gdebug/channelz/+    The gRPC server/client have to be started prior to requesting the server.+    Otherwise, the gRPC C-Core won't be started, and it will throw SIGABORT+    terminating the process.++    To close the HTTP server cleanly, you need to call 'shutdown()' and+    'server_close()' on the returned HTTP server instance. For more details,+    please check the definition of Python's BaseServer:+    https://docs.python.org/3/library/socketserver.html#socketserver.BaseServer++    This is an EXPERIMENTAL API.++    Args:+      host: a str indicates the address of the HTTP server.+      port: a int indicates the tcp port of the HTTP server.++    Returns:+      An http.Server.HTTPServer instance that is already started serving.","Semantic updated. It will not start another thread for user, and the comment updated to:```An http.Server.HTTPServer instance with Channelz Page handler.```The test script's `setUp`/`tearDown` is also updated.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17617,246552869,2019-01-09T21:30:04Z,src/python/grpcio_tests/tests/channelz/_channelz_page_test.py,"@@ -0,0 +1,212 @@+# Copyright 2019 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Tests of Serving HTTPS Channelz Page.""""""++import unittest+import time+import logging+import re++import requests++import grpc+from grpc_channelz.v1 import channelz++from tests.unit import test_common+from tests.unit.framework.common import test_constants++# Matches first link inside of a table+_table_a_href_re = re.compile(r'<table.+?<a href=[\'""](.+?)[\'""]', re.DOTALL)","HTML parser doesn't require `lxml`, so it can be use in our environment.Sadly, its semantics is too simple to fulfill our need. We have to add a state machine with HTMLParser to locate the information we want. What do you think...?",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17617,246553664,2019-01-09T21:32:35Z,src/python/grpcio_tests/tests/channelz/_channelz_page_test.py,"@@ -0,0 +1,212 @@+# Copyright 2019 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Tests of Serving HTTPS Channelz Page.""""""++import unittest+import time+import logging+import re++import requests++import grpc+from grpc_channelz.v1 import channelz++from tests.unit import test_common+from tests.unit.framework.common import test_constants++# Matches first link inside of a table+_table_a_href_re = re.compile(r'<table.+?<a href=[\'""](.+?)[\'""]', re.DOTALL)+# Matches first link inside the second table+_table_eq1_a_href_re = re.compile(r'<table.+?<table.+?<a href=[\'""](.+?)[\'""]',+                                  re.DOTALL)+# Matches all table rows+_tr_re = re.compile(r'<tr>(.+?)</tr>', re.DOTALL)+# Matches first link if there is at least two links+_a_href_a_re = re.compile(r'<a href=[\'""](.+?)[\'""].+?<a', re.DOTALL)++_CHANNELZ_URL_PREFIX_TEMPLATE = 'http://localhost:%d/gdebug/channelz/'++_REQUEST = b'\x00\x00\x00'+_RESPONSE = b'\x01\x01\x01'++_SUCCESSFUL_UNARY_UNARY = '/test/SuccessfulUnaryUnary'+_FAILED_UNARY_UNARY = '/test/FailedUnaryUnary'+_SUCCESSFUL_STREAM_STREAM = '/test/SuccessfulStreamStream'+++def _successful_unary_unary(request, servicer_context):+    return _RESPONSE+++def _failed_unary_unary(request, servicer_context):+    servicer_context.abort(grpc.StatusCode.INTERNAL, 'Intended Failure')+++def _successful_stream_stream(request_iterator, servicer_context):+    for _ in request_iterator:+        yield _RESPONSE+++class _GenericHandler(grpc.GenericRpcHandler):++    def service(self, handler_call_details):+        if handler_call_details.method == _SUCCESSFUL_UNARY_UNARY:+            return grpc.unary_unary_rpc_method_handler(_successful_unary_unary)+        elif handler_call_details.method == _FAILED_UNARY_UNARY:+            return grpc.unary_unary_rpc_method_handler(_failed_unary_unary)+        elif handler_call_details.method == _SUCCESSFUL_STREAM_STREAM:+            return grpc.stream_stream_rpc_method_handler(+                _successful_stream_stream)+        else:+            return None+++class ChannelzPageTest(unittest.TestCase):++    def _send_successful_unary_unary(self):+        _, r = self._channel.unary_unary(_SUCCESSFUL_UNARY_UNARY).with_call(+            _REQUEST)+        self.assertEqual(r.code(), grpc.StatusCode.OK)++    def _send_failed_unary_unary(self):+        try:+            self._channel.unary_unary(_FAILED_UNARY_UNARY)(_REQUEST)+        except grpc.RpcError:+            return++    def _send_successful_stream_stream(self):+        response_iterator = self._channel.stream_stream(+            _SUCCESSFUL_STREAM_STREAM).__call__(+                iter([_REQUEST] * test_constants.STREAM_LENGTH))+        cnt = 0+        for _ in response_iterator:+            cnt += 1+        self.assertEqual(cnt, test_constants.STREAM_LENGTH)++    def setUp(self):+        super(ChannelzPageTest, self).setUp()+        self._server = test_common.test_server()+        port = self._server.add_insecure_port('[::]:0')+        self._server.add_generic_rpc_handlers((_GenericHandler(),))+        self._server.start()++        self._channel = grpc.insecure_channel('localhost:%d' % port)++        self._page_server = channelz.serve_channelz_page('', 0)+        self._page_url_prefix = _CHANNELZ_URL_PREFIX_TEMPLATE % self._page_server.server_address[+            1]++        # Emit RPCs to make sure sockets are created+        self._send_successful_unary_unary()+        self._send_failed_unary_unary()+        self._send_successful_stream_stream()++    def tearDown(self):+        self._page_server.shutdown()+        self._page_server.server_close()+        self._server.stop(None)+        self._channel.close()+        super(ChannelzPageTest, self).tearDown()++    def test_homepage(self):+        resp = requests.get(self._page_url_prefix)+        self.assertEqual(resp.status_code, 200)++    def test_channel(self):+        # Page of list of channels+        resp = requests.get(self._page_url_prefix + 'topchannels')+        self.assertEqual(resp.status_code, 200)++        # Page of detail of a channel+        surffix = _table_a_href_re.search(resp.text).group(1)",TIL. Spelled it wrong for a long time.,OK
26072277,dfawley,https://api.github.com/repos/grpc/grpc/pulls/17671,246575128,2019-01-09T22:44:55Z,tools/interop_matrix/client_matrix.py,"@@ -35,14 +35,15 @@ def get_release_tags(lang):  def get_runtimes_for_lang_release(lang, release):     """"""Get list of valid runtimes for given release of lang.""""""-    runtimes_to_skip = []-    release_info = LANG_RELEASE_MATRIX[lang][release]-    if release_info:-        runtimes_to_skip = release_info.skip_runtime-    return [-        runtime for runtime in LANG_RUNTIME_MATRIX[lang]-        if runtime not in runtimes_to_skip-    ]+    runtimes = list(LANG_RUNTIME_MATRIX[lang])+    release_info = LANG_RELEASE_MATRIX[lang].get(release)+    if release_info and release_info.runtime_subset:","Minor point: you could avoid a little unnecessary validation work when runtime_subset is not set.  Something like:```pydef get_runtimes_for_lang_release(lang, release):    """"""Get list of valid runtimes for given release of lang.""""""   release_info = LANG_RELEASE_MATRIX[lang].get(release)   if not release_info or not release_info.runtime_subset:       return list(LANG_RUNTIME_MATRIX[lang])   runtimes = list(release_info.runtime_subset)   # check that ....```",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/17578,246583420,2019-01-09T23:19:08Z,src/objective-c/GRPCClient/GRPCCall.m,"@@ -794,112 +793,114 @@ - (void)invokeCall {               [userInfo addEntriesFromDictionary:error.userInfo];             }             userInfo[kGRPCTrailersKey] = strongSelf.responseTrailers;-            // TODO(jcanizales): The C gRPC library doesn't guarantee that the headers block will be-            // called before this one, so an error might end up with trailers but no headers. We-            // shouldn't call finishWithError until ater both blocks are called. It is also when-            // this is done that we can provide a merged view of response headers and trailers in a-            // thread-safe way.-            if (strongSelf.responseHeaders) {-              userInfo[kGRPCHeadersKey] = strongSelf.responseHeaders;-            }+            // Since gRPC core does not guarantee the headers block being called before this block,+            // responseHeaders might be nil.+            userInfo[kGRPCHeadersKey] = strongSelf.responseHeaders;             error = [NSError errorWithDomain:error.domain code:error.code userInfo:userInfo];           }-          [strongSelf maybeFinishWithError:error];+          [strongSelf finishWithError:error];+          strongSelf->_requestWriter.state = GRXWriterStateFinished;         }       }];-  // Now that the RPC has been initiated, request writes can start.-  @synchronized(_requestWriter) {-    [_requestWriter startWithWriteable:self];-  } }  #pragma mark GRXWriter implementation +// Lock acquired inside startWithWriteable: - (void)startCallWithWriteable:(id<GRXWriteable>)writeable {-  _responseWriteable =-      [[GRXConcurrentWriteable alloc] initWithWriteable:writeable dispatchQueue:_responseQueue];--  GRPCPooledChannel *channel =-      [[GRPCChannelPool sharedInstance] channelWithHost:_host callOptions:_callOptions];-  GRPCWrappedCall *wrappedCall = [channel wrappedCallWithPath:_path-                                              completionQueue:[GRPCCompletionQueue completionQueue]-                                                  callOptions:_callOptions];--  if (wrappedCall == nil) {-    [self maybeFinishWithError:[NSError errorWithDomain:kGRPCErrorDomain-                                                   code:GRPCErrorCodeUnavailable-                                               userInfo:@{-                                                 NSLocalizedDescriptionKey :-                                                     @""Failed to create call or channel.""-                                               }]];-    return;-  }-   @synchronized(self) {-    _wrappedCall = wrappedCall;-  }+    if (_state == GRXWriterStateFinished) {+      return;+    }++    _responseWriteable =+        [[GRXConcurrentWriteable alloc] initWithWriteable:writeable dispatchQueue:_responseQueue];++    GRPCPooledChannel *channel =+        [[GRPCChannelPool sharedInstance] channelWithHost:_host callOptions:_callOptions];+    _wrappedCall = [channel wrappedCallWithPath:_path+                                completionQueue:[GRPCCompletionQueue completionQueue]",Chatted offline. It should stay in the block (no deadlock issue; needs to guarantee state consistency of `GRPCCall`),
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17678,246695466,2019-01-10T09:53:59Z,third_party/toolchains/BUILD,"@@ -20,17 +20,17 @@ package(default_visibility = [""//visibility:public""]) # Update every time when a new container is released. alias(","I can still see reference to bazel_0.16.1 lower in this filehttps://github.com/grpc/grpc/blob/8b7323df1c36bb855b749985ca301c5531d2e263/third_party/toolchains/BUILD#L85Not sure what the comment at https://github.com/grpc/grpc/blob/8b7323df1c36bb855b749985ca301c5531d2e263/third_party/toolchains/BUILD#L77 means, but it seems that this was added by you in https://github.com/grpc/grpc/pull/17110, so you probably know.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17671,246761467,2019-01-10T13:42:07Z,tools/interop_matrix/client_matrix.py,"@@ -35,14 +35,15 @@ def get_release_tags(lang):  def get_runtimes_for_lang_release(lang, release):     """"""Get list of valid runtimes for given release of lang.""""""-    runtimes_to_skip = []-    release_info = LANG_RELEASE_MATRIX[lang][release]-    if release_info:-        runtimes_to_skip = release_info.skip_runtime-    return [-        runtime for runtime in LANG_RUNTIME_MATRIX[lang]-        if runtime not in runtimes_to_skip-    ]+    runtimes = list(LANG_RUNTIME_MATRIX[lang])+    release_info = LANG_RELEASE_MATRIX[lang].get(release)+    if release_info and release_info.runtime_subset:","makes sense, but I think the complexity of what you're proposing is about the same as what I currently have, so I'll leave as to avoid a second round of testing.",
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/17643,246950432,2019-01-10T22:51:55Z,test/core/bad_connection/close_fd_test.cc,"@@ -0,0 +1,731 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""test/core/util/test_config.h""++#include <stdio.h>+#include <string.h>+#include <unistd.h>++#include <grpc/byte_buffer.h>+#include <grpc/byte_buffer_reader.h>+#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/time.h>+#include ""src/core/ext/transport/chttp2/transport/chttp2_transport.h""+#include ""src/core/lib/iomgr/endpoint_pair.h""+#include ""src/core/lib/surface/channel.h""+#include ""src/core/lib/surface/completion_queue.h""+#include ""src/core/lib/surface/server.h""++static void* tag(intptr_t t) { return (void*)t; }++typedef struct test_ctx test_ctx;++struct test_ctx {+  grpc_completion_queue* cq;+  grpc_completion_queue* shutdown_cq;+  grpc_completion_queue* client_cq;+  grpc_completion_queue* bound_cq;+  grpc_server* server;+  grpc_channel* client;+  grpc_endpoint_pair* ep;+};++/* chttp2 transport that is immediately available (used for testing+   connected_channel without a client_channel */++static void server_setup_transport(test_ctx* ctx, grpc_transport* transport) {+  grpc_core::ExecCtx exec_ctx;+  grpc_endpoint_add_to_pollset(ctx->ep->server, grpc_cq_pollset(ctx->cq));+  grpc_server_setup_transport(ctx->server, transport, nullptr,+                              grpc_server_get_channel_args(ctx->server),+                              nullptr);+}++static void client_setup_transport(test_ctx* ctx, grpc_transport* transport) {+  grpc_arg authority_arg = grpc_channel_arg_string_create(+      const_cast<char*>(GRPC_ARG_DEFAULT_AUTHORITY),+      const_cast<char*>(""test-authority""));+  grpc_channel_args* args =+      grpc_channel_args_copy_and_add(nullptr, &authority_arg, 1);+  /* TODO (pjaikumar): use GRPC_CLIENT_CHANNEL instead of+   * GRPC_CLIENT_DIRECT_CHANNEL */+  ctx->client = grpc_channel_create(""socketpair-target"", args,+                                    GRPC_CLIENT_DIRECT_CHANNEL, transport);+  grpc_channel_args_destroy(args);+}++static void init_client(test_ctx* ctx) {+  grpc_core::ExecCtx exec_ctx;+  grpc_transport* transport;+  transport = grpc_create_chttp2_transport(nullptr, ctx->ep->client, true);+  client_setup_transport(ctx, transport);+  GPR_ASSERT(ctx->client);+  grpc_chttp2_transport_start_reading(transport, nullptr, nullptr);+}++static void init_server(test_ctx* ctx) {+  grpc_core::ExecCtx exec_ctx;+  grpc_transport* transport;+  GPR_ASSERT(!ctx->server);+  ctx->server = grpc_server_create(nullptr, nullptr);+  grpc_server_register_completion_queue(ctx->server, ctx->cq, nullptr);+  grpc_server_start(ctx->server);+  transport = grpc_create_chttp2_transport(nullptr, ctx->ep->server, false);+  server_setup_transport(ctx, transport);+  grpc_chttp2_transport_start_reading(transport, nullptr, nullptr);+}++static void test_init(test_ctx* ctx) {+  grpc_endpoint_pair* sfd =+      static_cast<grpc_endpoint_pair*>(gpr_malloc(sizeof(grpc_endpoint_pair)));+  memset(ctx, 0, sizeof(*ctx));+  ctx->ep = sfd;+  ctx->cq = grpc_completion_queue_create_for_next(nullptr);+  ctx->shutdown_cq = grpc_completion_queue_create_for_pluck(nullptr);+  ctx->bound_cq = grpc_completion_queue_create_for_next(nullptr);+  ctx->client_cq = grpc_completion_queue_create_for_next(nullptr);++  /* Create endpoints */+  *sfd = grpc_iomgr_create_endpoint_pair(""fixture"", nullptr);+  /* Create client, server and setup transport over endpoint pair */+  init_server(ctx);+  init_client(ctx);+}++static void drain_cq(grpc_completion_queue* cq) {+  grpc_event ev;+  do {+    ev = grpc_completion_queue_next(cq, grpc_timeout_seconds_to_deadline(1),+                                    nullptr);+  } while (ev.type != GRPC_QUEUE_SHUTDOWN);+}++static void drain_and_destroy_cq(grpc_completion_queue* cq) {+  grpc_completion_queue_shutdown(cq);+  drain_cq(cq);+  grpc_completion_queue_destroy(cq);+}++static void shutdown_server(test_ctx* ctx) {+  if (!ctx->server) return;+  grpc_server_shutdown_and_notify(ctx->server, ctx->shutdown_cq, tag(1000));+  GPR_ASSERT(grpc_completion_queue_pluck(ctx->shutdown_cq, tag(1000),+                                         grpc_timeout_seconds_to_deadline(1),+                                         nullptr)+                 .type == GRPC_OP_COMPLETE);+  grpc_server_destroy(ctx->server);+  ctx->server = nullptr;+}++static void shutdown_client(test_ctx* ctx) {+  if (!ctx->client) return;+  grpc_channel_destroy(ctx->client);+  ctx->client = nullptr;+}++static void end_test(test_ctx* ctx) {+  shutdown_server(ctx);+  shutdown_client(ctx);++  drain_and_destroy_cq(ctx->cq);+  drain_and_destroy_cq(ctx->client_cq);+  drain_and_destroy_cq(ctx->bound_cq);+  grpc_completion_queue_destroy(ctx->shutdown_cq);+  gpr_free(ctx->ep);+}++typedef enum fd_type { CLIENT_FD, SERVER_FD } fd_type;++static const char* fd_type_str(fd_type f) {+  if (f == CLIENT_FD) {+    return ""client"";+  } else if (f == SERVER_FD) {+    return ""server"";+  } else {+    gpr_log(GPR_ERROR, ""Unexpected fd_type %d"", f);+    abort();+  }+}++static void _test_close_before_server_recv(fd_type f) {+  grpc_core::ExecCtx exec_ctx;+  grpc_call* c;+  grpc_call* s;+  grpc_event e;+  grpc_slice request_payload_slice =+      grpc_slice_from_copied_string(""hello world"");+  grpc_slice response_payload_slice =+      grpc_slice_from_copied_string(""hello you"");+  grpc_byte_buffer* request_payload =+      grpc_raw_byte_buffer_create(&request_payload_slice, 1);+  grpc_byte_buffer* response_payload =+      grpc_raw_byte_buffer_create(&response_payload_slice, 1);+  gpr_log(GPR_INFO, ""Running test: test_close_%s_before_server_recv"",+          fd_type_str(f));+  test_ctx ctx;+  test_init(&ctx);++  grpc_op ops[6];+  grpc_op* op;+  grpc_metadata_array initial_metadata_recv;+  grpc_metadata_array trailing_metadata_recv;+  grpc_metadata_array request_metadata_recv;+  grpc_byte_buffer* request_payload_recv = nullptr;+  grpc_byte_buffer* response_payload_recv = nullptr;+  grpc_call_details call_details;+  grpc_status_code status = GRPC_STATUS__DO_NOT_USE;+  grpc_call_error error;+  grpc_slice details;++  gpr_timespec deadline = grpc_timeout_seconds_to_deadline(1);+  grpc_endpoint_add_to_pollset(ctx.ep->client, grpc_cq_pollset(ctx.client_cq));+  c = grpc_channel_create_call(+      ctx.client, nullptr, GRPC_PROPAGATE_DEFAULTS, ctx.client_cq,+      grpc_slice_from_static_string(""/foo""), nullptr, deadline, nullptr);+  GPR_ASSERT(c);++  grpc_metadata_array_init(&initial_metadata_recv);+  grpc_metadata_array_init(&trailing_metadata_recv);+  grpc_metadata_array_init(&request_metadata_recv);+  grpc_call_details_init(&call_details);++  memset(ops, 0, sizeof(ops));+  op = ops;+  op->op = GRPC_OP_SEND_INITIAL_METADATA;+  op->data.send_initial_metadata.count = 0;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  op->op = GRPC_OP_SEND_MESSAGE;+  op->data.send_message.send_message = request_payload;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  op->op = GRPC_OP_SEND_CLOSE_FROM_CLIENT;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  op->op = GRPC_OP_RECV_INITIAL_METADATA;+  op->data.recv_initial_metadata.recv_initial_metadata = &initial_metadata_recv;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  op->op = GRPC_OP_RECV_MESSAGE;+  op->data.recv_message.recv_message = &response_payload_recv;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  op->op = GRPC_OP_RECV_STATUS_ON_CLIENT;+  op->data.recv_status_on_client.trailing_metadata = &trailing_metadata_recv;+  op->data.recv_status_on_client.status = &status;+  op->data.recv_status_on_client.status_details = &details;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  error = grpc_call_start_batch(c, ops, static_cast<size_t>(op - ops), tag(1),+                                nullptr);+  GPR_ASSERT(GRPC_CALL_OK == error);++  error = grpc_server_request_call(ctx.server, &s, &call_details,+                                   &request_metadata_recv, ctx.bound_cq, ctx.cq,+                                   tag(101));+  GPR_ASSERT(GRPC_CALL_OK == error);+  e = grpc_completion_queue_next(+      ctx.cq, grpc_timeout_milliseconds_to_deadline(100), nullptr);+  GPR_ASSERT(e.success == 1);+  GPR_ASSERT(e.tag == tag(101));+  GPR_ASSERT(e.type == GRPC_OP_COMPLETE);++  memset(ops, 0, sizeof(ops));+  op = ops;+  op->op = GRPC_OP_SEND_INITIAL_METADATA;+  op->data.send_initial_metadata.count = 0;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  op->op = GRPC_OP_RECV_MESSAGE;+  op->data.recv_message.recv_message = &request_payload_recv;+  op->flags = 0;+  op->reserved = nullptr;+  op++;++  grpc_endpoint_pair* sfd = ctx.ep;+  int fd;+  if (f == SERVER_FD) {+    fd = sfd->server->vtable->get_fd(sfd->server);+  } else {+    GPR_ASSERT(f == CLIENT_FD);+    fd = sfd->client->vtable->get_fd(sfd->client);+  }+  /* Connection is closed before the server receives the client's message. */+  close(fd);++  error = grpc_call_start_batch(s, ops, static_cast<size_t>(op - ops), tag(102),+                                nullptr);+  GPR_ASSERT(GRPC_CALL_OK == error);++  /* Batch operation succeeds on the server side */+  e = grpc_completion_queue_next(+      ctx.bound_cq, grpc_timeout_milliseconds_to_deadline(100), nullptr);+  GPR_ASSERT(e.type == GRPC_OP_COMPLETE);+  GPR_ASSERT(e.success == 1);+  GPR_ASSERT(e.tag == tag(102));++  e = grpc_completion_queue_next(+      ctx.client_cq, grpc_timeout_milliseconds_to_deadline(100), nullptr);+  if (f == CLIENT_FD) {+    /* Timeout is returned to the client whe the client (local) fd is closed */+    GPR_ASSERT(e.type == GRPC_QUEUE_TIMEOUT);","Looks like `GRPC_QUEUE_TIMEOUT` in  a couple of cases:1. Deadline exceeded, i.e. socket didn't emit any event. https://github.com/grpc/grpc/blob/master/src/core/lib/surface/completion_queue.cc#L10312. Completion queue next failed. I'm not sure when that condition will be hit. https://github.com/grpc/grpc/blob/master/src/core/lib/surface/completion_queue.cc#L1049",
28123841,guantaol,https://api.github.com/repos/grpc/grpc/pulls/17686,247299573,2019-01-12T02:31:54Z,src/cpp/server/server_cc.cc,"@@ -410,11 +415,27 @@ class Server::CallbackRequest final : public internal::CompletionQueueTag {       GPR_ASSERT(ignored == req_);        if (!ok) {-        // The call has been shutdown-        req_->Clear();+        // The call has been shutdown. Let it stay in the list+        // since the server shutdown will delete and Clear it.+        req_->Done();         return;       } +      bool may_spawn_new = false;+      {+        std::lock_guard<std::mutex> l(req_->req_list_->reqs_mu);+        req_->req_list_->reqs_list.erase(req_->req_list_iterator_);+        // If this was the last request in the list, set up a new one+        if (req_->req_list_->reqs_list.empty()) {","For my own knowledge, is this when a new RPC starts in the server, and we are picking a pre-registered request from the list?",
28123841,guantaol,https://api.github.com/repos/grpc/grpc/pulls/17686,247749245,2019-01-15T02:52:03Z,src/cpp/server/server_cc.cc,"@@ -410,11 +415,27 @@ class Server::CallbackRequest final : public internal::CompletionQueueTag {       GPR_ASSERT(ignored == req_);        if (!ok) {-        // The call has been shutdown-        req_->Clear();+        // The call has been shutdown. Let it stay in the list+        // since the server shutdown will delete and Clear it.+        req_->Done();         return;       } +      bool may_spawn_new = false;+      {+        std::lock_guard<std::mutex> l(req_->req_list_->reqs_mu);+        req_->req_list_->reqs_list.erase(req_->req_list_iterator_);+        // If this was the last request in the list, set up a new one+        if (req_->req_list_->reqs_list.empty()) {","Is it too late to spawn and register a new CallbackRequest here? If I understand it correctly, queue_call_request() is where we add pre-registered requests into the mpscq of each method, and publish_new_rpc() is where we take a pre-registered request from the mpscq, and if we fail to get one from the mpscq, the new RPC is blocked.As now CallbackTag::Run() will be executed when the bottom ApplicationCallbackExecCtx is destructed, this may be delayed for a long time, which may cause the regression we see in the benchmark. Can we erase the pre-registered request from the list and spawn a new one if needed in the publish_new_rpc() where we take the pre-registered request from the mpscq?",
28123841,guantaol,https://api.github.com/repos/grpc/grpc/pulls/17686,247759706,2019-01-15T04:16:33Z,src/cpp/server/server_cc.cc,"@@ -462,17 +483,25 @@ class Server::CallbackRequest final : public internal::CompletionQueueTag {           internal::MethodHandler::HandlerParameter(               call_, &req_->ctx_, req_->request_, req_->request_status_,               [this] {-                req_->Reset();+                // Recycle this request if there aren't too many outstanding.+                // Note that we don't have to worry about a case where there+                // are no requests waiting to match for this method since that+                // is already taken care of when binding a request to a call.+                if (req_->server_->callback_reqs_outstanding_ <+                    MAXIMUM_CALLBACK_REQS_OUTSTANDING) {","I was thinking whether we want to keep the same number of requests (and memory overhead) around for a server no matter how many methods it exposes. For servers exposing very few methods, I was thinking how we can decrease the number of live requests and the memory overhead.On the other hand, I am not sure whether the naming is precise here. In my understanding, outstanding RPCs are those being processed by the server at any time. callback_reqs_outstanding_ covers both started RPCs and those not-yet-matched free requests. MAXIMUM_CALLBACK_REQS_OUTSTANDING mainly constraints the capacity of the freelist, and I am wondering whether 30,000 is too large for general cases.I agree in the circumstance you described, per-method limit is not a good option. But can we use a smaller freelist to reduce the memory overhead, and check whether any RPC for a specific method is pending before deleting the request?",OK
43831800,sheenaqotj,https://api.github.com/repos/grpc/grpc/pulls/17689,247780663,2019-01-15T07:01:59Z,examples/cpp/keyvaluestore/caching_interceptor.h,"@@ -0,0 +1,128 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <map>++#include <grpcpp/support/client_interceptor.h>++#ifdef BAZEL_BUILD+#include ""examples/protos/keyvaluestore.grpc.pb.h""+#else+#include ""keyvaluestore.grpc.pb.h""+#endif++// This is a naive implementation of a cache. A new cache is for each call. For+// each new key request, the key is first searched in the map and if found. Only+// if the key is not found in the cache do we make a request.+class CachingInterceptor : public grpc::experimental::Interceptor {+ public:+  CachingInterceptor(grpc::experimental::ClientRpcInfo* info) {}++  void Intercept(+      ::grpc::experimental::InterceptorBatchMethods* methods) override {+    bool hijack = false;+    if (methods->QueryInterceptionHookPoint(+            grpc::experimental::InterceptionHookPoints::+                PRE_SEND_INITIAL_METADATA)) {+      // Hijack all calls+      hijack = true;","As far as the interface goes, I don't understand why we have a limitation that we can only hijack at pre_send_initial_metadata. I guess the idea is that then the server has not gotten any day, but at any given point after we hijack, we could send partial data over to the server anyway, so that's not the argument.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/17686,247977134,2019-01-15T16:56:34Z,src/cpp/server/server_cc.cc,"@@ -462,17 +483,25 @@ class Server::CallbackRequest final : public internal::CompletionQueueTag {           internal::MethodHandler::HandlerParameter(               call_, &req_->ctx_, req_->request_, req_->request_status_,               [this] {-                req_->Reset();+                // Recycle this request if there aren't too many outstanding.+                // Note that we don't have to worry about a case where there+                // are no requests waiting to match for this method since that+                // is already taken care of when binding a request to a call.+                if (req_->server_->callback_reqs_outstanding_ <+                    MAXIMUM_CALLBACK_REQS_OUTSTANDING) {","No, this is not really intended as a freelist size. It was originally inspired by the Stubby freelist code but it went in its own direction after that. `callback_reqs_outstanding_` counts both started RPCs and RPCs that are not yet matched. It is a soft limit in the sense that if there are already MAXIMUM_CALLBACK_REQS_OUTSTANDING outstanding and a new request comes in that is the last unmatched request for its method, another new request will be created. Maybe we need a hard limit also (after which we start rejecting RPCs with errors) but that's another matter.I would like to allow the size to reduce dynamically as well when we no longer need that many RPCs for the load. I think we need to discuss how to measure the load. One way would be to do a weighted exponential moving average to establish a ""target"" RPC count and decrease whenever we are above target. I also thought that we might want to increase the count by more than 1 at a time when the load is increasing (perhaps by doubling until we go over a limit, or something like that).",OK
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/17689,248074373,2019-01-15T21:43:51Z,examples/cpp/keyvaluestore/caching_interceptor.h,"@@ -0,0 +1,128 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <map>++#include <grpcpp/support/client_interceptor.h>++#ifdef BAZEL_BUILD+#include ""examples/protos/keyvaluestore.grpc.pb.h""+#else+#include ""keyvaluestore.grpc.pb.h""+#endif++// This is a naive implementation of a cache. A new cache is for each call. For+// each new key request, the key is first searched in the map and if found. Only+// if the key is not found in the cache do we make a request.+class CachingInterceptor : public grpc::experimental::Interceptor {+ public:+  CachingInterceptor(grpc::experimental::ClientRpcInfo* info) {}++  void Intercept(+      ::grpc::experimental::InterceptorBatchMethods* methods) override {+    bool hijack = false;+    if (methods->QueryInterceptionHookPoint(+            grpc::experimental::InterceptionHookPoints::+                PRE_SEND_INITIAL_METADATA)) {+      // Hijack all calls+      hijack = true;","At pre_send_initial_metadata, the interceptor should have all information to decide whether it needs to hijack or not. Having it hijack later means that we need to take care of doing some cleanup since the server has probably already done some work.. and that seems unnecessary",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17728,248192741,2019-01-16T08:46:53Z,templates/tools/dockerfile/php7_deps.include,"@@ -19,6 +19,7 @@ RUN apt-get update && apt-get install -y ${'\\'}   re2c ${'\\'}   time ${'\\'}   unzip ${'\\'}+  valgrind ${'\\'}","I'm not convinced valgrind should be part of PHP's standard testing dependencies (it then bubbles up e.g. into interop test images, where it is not needed). How big is valgrind installation?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/17652,248206636,2019-01-16T09:30:37Z,src/compiler/ruby_generator.cc,"@@ -37,16 +38,61 @@ using std::vector; namespace grpc_ruby_generator { namespace { +// returns the full canonical message name+grpc::string GetCanonicalMessageType(const Descriptor* msg) {+  const Descriptor* top_level_msg;+  const FileDescriptor* file_containing_msg;+  grpc::string msg_full_name;+  grpc::string msg_name;+  grpc::string msg_proto_pkg;+  grpc::string resolved_namespace;+  grpc::string res(msg->full_name());++  // If msg is nested, find the topmost message+  top_level_msg = msg;+  while (top_level_msg->containing_type()) {+    top_level_msg = top_level_msg->containing_type();+  }+  file_containing_msg = top_level_msg->file();++  msg_full_name = top_level_msg->full_name();+  msg_name = top_level_msg->name();+  msg_proto_pkg =+      msg_full_name.substr(0, msg_full_name.length() - msg_name.length());++  if (file_containing_msg->options().has_ruby_package()) {+    resolved_namespace = file_containing_msg->options().ruby_package();+  } else {+    return res;+  }++  // remove trailing period, prevent it from being replaced+  if (msg_proto_pkg.length() > 0) {+    if (msg_proto_pkg.back() == '.') {","nit: if `_msg_proto_pkg.length() > 0` then `msg_proto_pkg.back()` always is `.`, right? At least I can't think of when it's not.Can we remove this conditional if so and just always delete the trailing period instead?",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17734,248441349,2019-01-16T20:36:44Z,tools/distrib/python/grpcio_tools/grpc_tools/command.py,"@@ -63,3 +118,26 @@ def run(self):         # to `self.distribution.package_dir` (and get a key error if it's not         # there).         build_package_protos(self.distribution.package_dir[''])+++class BuildPackageProtosStrict(setuptools.Command):+    """"""Command to strictly generate project *_pb2.py modules from proto files.++    The generation will abort if any of the proto files contains error.+    """"""++    description = 'strictly build grpc protobuf modules'+    user_options = []++    def initialize_options(self):+        pass++    def finalize_options(self):+        pass++    def run(self):+        # due to limitations of the proto generator, we require that only *one*+        # directory is provided as an 'include' directory. We assume it's the '' key+        # to `self.distribution.package_dir` (and get a key error if it's not+        # there).+        build_package_protos_strict(self.distribution.package_dir[''])","That’s the design for grpc_tools and the magical key is set to “” for a long time. I don’t really like it, but I can’t come up with a backward compatible improvement.If user is compiling with multiple package_dir, they will have no way to fix it...",
2030323,JunTaoLuo,https://api.github.com/repos/grpc/grpc/pulls/17733,248498616,2019-01-17T00:09:08Z,src/csharp/Grpc.Core/ServerCallContext.cs,"@@ -29,45 +30,49 @@ namespace Grpc.Core     /// </summary>     public class ServerCallContext     {-        private readonly CallSafeHandle callHandle;+        private readonly object extraData;","Though this probably works but I'm not sure if it's the best way to separate the native types.I assume this implementation is mostly concerned with back compat but ideally everything (types and methods) exposed publicly on `ServerCallContext` could have been defined on a `IServerCallContext` interface and a `NativeServerCallContext` would implement the interface with its own mechanism of storing the extra data and getters/setters for `WriteOptions`, `Peer`, `AuthContext`, etc.Since we probably can't change all the generated code now to start accepting a `IServerCallContext` interface in the call handlers since that would be a major breaking change. I'm wondering if it's possible to make ServerCallContext an abstract class and move all the implementation into a `NativeServerCallContext` that extends from it?I haven't tried this yet so I'm not sure about the ramifications but I'd like to explore that possibility before resorting to this mechanism with `objects` types and `Func` that you pass to the constructor to specify how to retrieve properties.Though changing `ServerCallContext` from a POCO to an abstract base class is technically breaking, I think it's small enough of a breaking change to be worth it.What do you think @shirhatti @jamesNK?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/17733,248563632,2019-01-17T07:38:00Z,src/csharp/Grpc.Core/Internal/ServerCallContextExtraData.cs,"@@ -0,0 +1,97 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Threading;+using System.Threading.Tasks;++namespace Grpc.Core.Internal+{+    /// <summary>+    /// Additional state for <c>ServerCallContext</c>.+    /// Storing the extra state outside of <c>ServerCallContext</c> allows it to be implementation-agnostic.+    /// </summary>+    internal class ServerCallContextExtraData+    {+        readonly CallSafeHandle callHandle;+        readonly IServerResponseStream serverResponseStream;+        readonly Lazy<AuthContext> cachedAuthContext;++        public ServerCallContextExtraData(CallSafeHandle callHandle, IServerResponseStream serverResponseStream)+        {+            this.callHandle = callHandle;+            this.serverResponseStream = serverResponseStream;+            // TODO(jtattermusch): avoid unnecessary allocation of factory function and the lazy object.+            this.cachedAuthContext = new Lazy<AuthContext>(GetAuthContextEager);+        }++        public ServerCallContext NewServerCallContext(ServerRpcNew newRpc, CancellationToken cancellationToken)+        {+            DateTime realtimeDeadline = newRpc.Deadline.ToClockType(ClockType.Realtime).ToDateTime();++            return new ServerCallContext(this, newRpc.Method, newRpc.Host, realtimeDeadline,+                newRpc.RequestMetadata, cancellationToken,+                ServerCallContext_WriteHeadersFunc, ServerCallContext_WriteOptionsGetter, ServerCallContext_WriteOptionsSetter,+                ServerCallContext_PeerGetter, ServerCallContext_AuthContextGetter, ServerCallContext_ContextPropagationTokenFactory);+        }++        private AuthContext GetAuthContextEager()+        {+            using (var authContextNative = callHandle.GetAuthContext())+            {+                return authContextNative.ToAuthContext();+            }+        }++        // Implementors of ServerCallContext's members are pre-allocated to avoid unneccessary delegate allocations.+        readonly static Func<ServerCallContext, object, Metadata, Task> ServerCallContext_WriteHeadersFunc = (ctx, extraData, headers) =>+        {+            return ((ServerCallContextExtraData)extraData).serverResponseStream.WriteResponseHeadersAsync(headers);+        };++        readonly static Func<ServerCallContext, object, WriteOptions> ServerCallContext_WriteOptionsGetter = (ctx, extraData) =>+        {++            return ((ServerCallContextExtraData)extraData).serverResponseStream.WriteOptions;+        };++        readonly static Action<ServerCallContext, object, WriteOptions> ServerCallContext_WriteOptionsSetter = (ctx, extraData, options) =>","Optional alternative: have you considered threading the `ServerCallContextExtraData` through these `ServerCallContext` plugin functions more implicitly, e.g. roughly like creating lambdas from the current  current `ServerCallContextExtraData` object that close over itself? Could get rid of the extra `object` parameter in the `ServerCallContext` plugin functions.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/17733,248566332,2019-01-17T07:50:33Z,src/csharp/Grpc.Core/ServerCallContext.cs,"@@ -29,45 +30,49 @@ namespace Grpc.Core     /// </summary>     public class ServerCallContext     {-        private readonly CallSafeHandle callHandle;+        private readonly object extraData;         private readonly string method;         private readonly string host;         private readonly DateTime deadline;         private readonly Metadata requestHeaders;         private readonly CancellationToken cancellationToken;         private readonly Metadata responseTrailers = new Metadata();-        private readonly Func<Metadata, Task> writeHeadersFunc;-        private readonly IHasWriteOptions writeOptionsHolder;-        private readonly Lazy<AuthContext> authContext;-        private readonly Func<string> testingOnlyPeerGetter;-        private readonly Func<AuthContext> testingOnlyAuthContextGetter;-        private readonly Func<ContextPropagationToken> testingOnlyContextPropagationTokenFactory;+        private readonly Func<ServerCallContext, object, Metadata, Task> writeHeadersFunc;+        private readonly Func<ServerCallContext, object, WriteOptions> writeOptionsGetter;+        private readonly Action<ServerCallContext, object, WriteOptions> writeOptionsSetter; -        private Status status = Status.DefaultSuccess;+        private readonly Func<ServerCallContext, object, string> peerGetter;+        private readonly Func<ServerCallContext, object, AuthContext> authContextGetter;+        private readonly Func<ServerCallContext, object, ContextPropagationOptions, ContextPropagationToken> contextPropagationTokenFactory; -        internal ServerCallContext(CallSafeHandle callHandle, string method, string host, DateTime deadline, Metadata requestHeaders, CancellationToken cancellationToken,-            Func<Metadata, Task> writeHeadersFunc, IHasWriteOptions writeOptionsHolder)-            : this(callHandle, method, host, deadline, requestHeaders, cancellationToken, writeHeadersFunc, writeOptionsHolder, null, null, null)-        {-        }+        private Status status = Status.DefaultSuccess; -        // Additional constructor params should be used for testing only-        internal ServerCallContext(CallSafeHandle callHandle, string method, string host, DateTime deadline, Metadata requestHeaders, CancellationToken cancellationToken,-            Func<Metadata, Task> writeHeadersFunc, IHasWriteOptions writeOptionsHolder,-            Func<string> testingOnlyPeerGetter, Func<AuthContext> testingOnlyAuthContextGetter, Func<ContextPropagationToken> testingOnlyContextPropagationTokenFactory)+        /// <summary>+        /// Creates a new instance of <c>ServerCallContext</c>.+        /// To allow reuse of ServerCallContext API by different gRPC implementations, the implementation of some members is provided externally.+        /// To provide state, this <c>ServerCallContext</c> instance and <c>extraData</c> will be passed to the member implementations.+        /// </summary>+        internal ServerCallContext(object extraData,",naming nit: might call this `userData` instead of `extraData` (personally that name seems more common for this type of opaque state plumbing),OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17733,248582775,2019-01-17T08:53:33Z,src/csharp/Grpc.Core/Internal/ServerCallContextExtraData.cs,"@@ -0,0 +1,97 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Threading;+using System.Threading.Tasks;++namespace Grpc.Core.Internal+{+    /// <summary>+    /// Additional state for <c>ServerCallContext</c>.+    /// Storing the extra state outside of <c>ServerCallContext</c> allows it to be implementation-agnostic.+    /// </summary>+    internal class ServerCallContextExtraData+    {+        readonly CallSafeHandle callHandle;+        readonly IServerResponseStream serverResponseStream;+        readonly Lazy<AuthContext> cachedAuthContext;++        public ServerCallContextExtraData(CallSafeHandle callHandle, IServerResponseStream serverResponseStream)+        {+            this.callHandle = callHandle;+            this.serverResponseStream = serverResponseStream;+            // TODO(jtattermusch): avoid unnecessary allocation of factory function and the lazy object.+            this.cachedAuthContext = new Lazy<AuthContext>(GetAuthContextEager);+        }++        public ServerCallContext NewServerCallContext(ServerRpcNew newRpc, CancellationToken cancellationToken)+        {+            DateTime realtimeDeadline = newRpc.Deadline.ToClockType(ClockType.Realtime).ToDateTime();++            return new ServerCallContext(this, newRpc.Method, newRpc.Host, realtimeDeadline,+                newRpc.RequestMetadata, cancellationToken,+                ServerCallContext_WriteHeadersFunc, ServerCallContext_WriteOptionsGetter, ServerCallContext_WriteOptionsSetter,+                ServerCallContext_PeerGetter, ServerCallContext_AuthContextGetter, ServerCallContext_ContextPropagationTokenFactory);+        }++        private AuthContext GetAuthContextEager()+        {+            using (var authContextNative = callHandle.GetAuthContext())+            {+                return authContextNative.ToAuthContext();+            }+        }++        // Implementors of ServerCallContext's members are pre-allocated to avoid unneccessary delegate allocations.+        readonly static Func<ServerCallContext, object, Metadata, Task> ServerCallContext_WriteHeadersFunc = (ctx, extraData, headers) =>+        {+            return ((ServerCallContextExtraData)extraData).serverResponseStream.WriteResponseHeadersAsync(headers);+        };++        readonly static Func<ServerCallContext, object, WriteOptions> ServerCallContext_WriteOptionsGetter = (ctx, extraData) =>+        {++            return ((ServerCallContextExtraData)extraData).serverResponseStream.WriteOptions;+        };++        readonly static Action<ServerCallContext, object, WriteOptions> ServerCallContext_WriteOptionsSetter = (ctx, extraData, options) =>","I considered both of these and decided not to do what you're suggesting:- The extra ""ServerCallContext"" and ""object"" parameters in the lambdas is there to avoid unnecessary lambda allocations every time we create a ServerCallContext (the lambdas like ServerCallContext_WriteHeadersFunc need to be static.- ServerCallContext.GetExtraData would have needed to be public and it would be visible to all the users writing the server side handlers - and I don't know that. If it was internal, every alternative grpc implementation using this API would need an [InternalsVisibleTo] annotation added to Grpc.Core.Api",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17733,248602311,2019-01-17T09:52:33Z,src/csharp/Grpc.Core/ServerCallContext.cs,"@@ -29,45 +30,49 @@ namespace Grpc.Core     /// </summary>     public class ServerCallContext     {-        private readonly CallSafeHandle callHandle;+        private readonly object extraData;","You're right, this is all about backward compatibility, otherwise this change would be trivial.Ad `IServerCallContext` interface:- we definitely can't change `ServerCallContext` to `IServerCallContext` in the generated code. `ServerCallContext` is exposed in every server-side handler so a change would break a large portion of current users.- using an interface for server call context is not right in general as there might be more members added to `ServerCallContext` over time (e.g. long time ago we added AuthContext) and adding new members to an interface is a breaking change (using ServerCallContext as a base class would be better as it could have default implementations for newly added members).Ad changing `ServerCallContext` to an abstract class base:- this is something we *could* consider, because currently there are no public constructors so the only instances of ServerCallContext in existence are the ones created in Grpc.Core or by Grpc.Core.Testing. I'd be worried about breaking the binary compatibility though (this has the potential to break all of the many existing nuget packages that depend on Grpc.Core).See ""adding virtual to a member"" in https://github.com/dotnet/corefx/blob/master/Documentation/coding-guidelines/breaking-change-rules.md#members- I agree that just changing `ServerCallContext` to a base class is much simpler, but the solution I'm proposing is safer from the perspective of backward compatibility.One possible solution would be to change ServerCallContext into a base class, leave the existing non-virtual members as is (adding ""virtual"" is breaking) and make them call a newly added protected virtual or abstract member (even abstract is fine as there are currently no accessible constructors outside of our control). These members can be then overridden by subclasses like 'NativeServerCallContext' that would provide the right behavior for each grpc implementation.@apolcyn  @JunTaoLuo  WDYT?",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17738,248698261,2019-01-17T14:45:29Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc,"@@ -1207,8 +1207,9 @@ void GrpcLb::FillChildRefsForChannelz(     channelz::ChildRefsList* child_subchannels,     channelz::ChildRefsList* child_channels) {   // delegate to the RoundRobin to fill the children subchannels.-  rr_policy_->FillChildRefsForChannelz(child_subchannels, child_channels);-  MutexLock lock(&lb_channel_mu_);","Why is it unnecessary to take this lock here?  It looks to me like we do need to do so to ensure that `lb_channel_` is not in the process of being destroyed when we get here (see the code in `ShutdownLocked()`).Conversely, if there is a reason why we don't actually need this lock here, then the lock is useless, since it's not being used for anything else.  In that case, we should remove it completely.",OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/17735,248787192,2019-01-17T18:25:18Z,test/core/util/fuzzer_corpus_test.cc,"@@ -70,12 +70,14 @@ class ExampleGenerator     if (examples_.empty()) {       if (!FLAGS_file.empty()) examples_.push_back(FLAGS_file);       if (!FLAGS_directory.empty()) {+#ifndef BAZEL_BUILD",I was following the example from **https://github.com/grpc/grpc/blob/master/examples/cpp/helloworld/greeter_client.cc#L25**. What's the right way to fix this?,OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/17731,248853031,2019-01-17T21:45:09Z,templates/src/objective-c/BoringSSL-GRPC.podspec.template,"@@ -1558,5 +1560,2976 @@     # symbols are src/objective-c/grpc_shadow_boringssl_symbol_list.     # This is the last part of this file.     s.prefix_header_contents = -      ${expand_symbol_list(settings.grpc_shadow_boringssl_symbols)}",The original idea is that the `expand_symbol_list` will generate the list of symbols rather than you filling them in yourself. Did the generated list not work?,
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17734,248865788,2019-01-17T22:28:14Z,tools/distrib/python/grpcio_tools/grpc_tools/command.py,"@@ -63,3 +118,26 @@ def run(self):         # to `self.distribution.package_dir` (and get a key error if it's not         # there).         build_package_protos(self.distribution.package_dir[''])+++class BuildPackageProtosStrict(setuptools.Command):+    """"""Command to strictly generate project *_pb2.py modules from proto files.++    The generation will abort if any of the proto files contains error.+    """"""++    description = 'strictly build grpc protobuf modules'+    user_options = []","The `BuildPackageProtos` is a `setuptools.Command` class which is passed directly to the `cmdclass` parameter of `setuptools.setup` function. If we want to add a `strict_mode`, I presume we need a class factory function to make that happen? Or a global state that indicates the strictness?What do you think is the better approach?",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17741,248866453,2019-01-17T22:30:36Z,tools/run_tests/python_utils/check_on_pr.py,"@@ -118,3 +119,12 @@ def check_on_pr(name, summary, success=True):         })     print('Result of Creating/Updating Check on PR:',           json.dumps(resp.json(), indent=2))+++if __name__ == ""__main__"":+    if len(sys.argv) != 2:+        print('Please specify the name of the check item.')","Hahaha. My bad, I guess the ideal way is to introduce the `ArgParser`.",OK
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17734,248868741,2019-01-17T22:39:59Z,tools/distrib/python/grpcio_tools/grpc_tools/command.py,"@@ -63,3 +118,26 @@ def run(self):         # to `self.distribution.package_dir` (and get a key error if it's not         # there).         build_package_protos(self.distribution.package_dir[''])+++class BuildPackageProtosStrict(setuptools.Command):+    """"""Command to strictly generate project *_pb2.py modules from proto files.++    The generation will abort if any of the proto files contains error.+    """"""++    description = 'strictly build grpc protobuf modules'+    user_options = []","I had in mind using the built-in options functionality of `Command`, which our current `initialize_options()`/`finalize_options()` methods are not taking advantage of. I think this would allow the user to set an `strict_mode` option (via command-line flag, maybe programmatically) when this is invoked. I did not find great documentation around this part of `setuptools`/`distutils`, but code search turned up Tensor Flow's https://github.com/tensorflow/tensorflow/blob/3fa896d2aa9f67f88c825c3a05eff2cf01b5546a/tensorflow/tools/pip_package/setup.py#L160 which looks like it's doing something similar",
12038583,matoro,https://api.github.com/repos/grpc/grpc/pulls/17606,249046223,2019-01-18T13:42:37Z,src/ruby/ext/grpc/extconf.rb,"@@ -24,10 +24,18 @@  ENV['MACOSX_DEPLOYMENT_TARGET'] = '10.7' -ENV['AR'] = RbConfig::CONFIG['AR'] + ' rcs'-ENV['CC'] = RbConfig::CONFIG['CC']-ENV['CXX'] = RbConfig::CONFIG['CXX']-ENV['LD'] = ENV['CC']+if ENV['AR'].nil? || ENV['AR'].size == 0+    ENV['AR'] = RbConfig::CONFIG['AR'] + ' rcs'+end+if ENV['CC'].nil? || ENV['CC'].size == 0+    ENV['CC'] = RbConfig::CONFIG['CC']+end+if ENV['CXX'].nil? || ENV['CXX'].size == 0+    ENV['CXX'] = RbConfig::CONFIG['CXX']+end+if ENV['LD'].nil? || ENV['LD'].size == 0+    ENV['LD'] = ENV['CC']","I changed that, and while I agree that the linker should be able to be specified separately, I originally wrote it that way to respect the original code, just in case there was a an unknown reason for requiring the linker to have the same invocation as the compiler.  See:  https://github.com/grpc/grpc/blob/master/src/ruby/ext/grpc/extconf.rb#L30",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17740,249179085,2019-01-18T20:39:01Z,src/core/lib/channel/handshaker_registry.cc,"@@ -28,74 +30,85 @@ // grpc_handshaker_factory_list // -typedef struct {-  grpc_handshaker_factory** list;-  size_t num_factories;-} grpc_handshaker_factory_list;--static void grpc_handshaker_factory_list_register(-    grpc_handshaker_factory_list* list, bool at_start,-    grpc_handshaker_factory* factory) {-  list->list = static_cast<grpc_handshaker_factory**>(gpr_realloc(-      list->list,-      (list->num_factories + 1) * sizeof(grpc_handshaker_factory*)));+namespace grpc_core {++namespace {++class HandshakerFactoryList {+ public:+  void Register(bool at_start, UniquePtr<HandshakerFactory> factory);+  void AddHandshakers(const grpc_channel_args* args,+                      grpc_pollset_set* interested_parties,+                      HandshakeManager* handshake_mgr);++ private:+  LinkedList<UniquePtr<HandshakerFactory>> factories_;","There are cases where new handshakers are added to the front of the list, which are slightly more efficient when using a linked list.  But this will generally only be done at grpc initialization time, so efficiency probably doesn't matter much.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17740,249186220,2019-01-18T21:09:20Z,src/core/lib/channel/handshaker_registry.cc,"@@ -28,74 +30,85 @@ // grpc_handshaker_factory_list // -typedef struct {-  grpc_handshaker_factory** list;-  size_t num_factories;-} grpc_handshaker_factory_list;--static void grpc_handshaker_factory_list_register(-    grpc_handshaker_factory_list* list, bool at_start,-    grpc_handshaker_factory* factory) {-  list->list = static_cast<grpc_handshaker_factory**>(gpr_realloc(-      list->list,-      (list->num_factories + 1) * sizeof(grpc_handshaker_factory*)));+namespace grpc_core {++namespace {++class HandshakerFactoryList {+ public:+  void Register(bool at_start, UniquePtr<HandshakerFactory> factory);+  void AddHandshakers(const grpc_channel_args* args,+                      grpc_pollset_set* interested_parties,+                      HandshakeManager* handshake_mgr);++ private:+  LinkedList<UniquePtr<HandshakerFactory>> factories_;","Actually, I think that's a good argument: it seems better to optimize for things that happen at connection-establishment time rather than things that happen only at grpc initialization time.Arjun, let's go ahead and use `InlinedVector<>` here.  That way, there's no need for a linked list implementation.",
2030323,JunTaoLuo,https://api.github.com/repos/grpc/grpc/pulls/17766,249204264,2019-01-18T22:27:29Z,src/csharp/Grpc.Core/ContextPropagationToken.cs,"@@ -32,124 +26,10 @@ namespace Grpc.Core     /// The gRPC native layer provides some other contexts (like tracing context) that     /// are not accessible to explicitly C# layer, but this token still allows propagating them.     /// </summary>-    public class ContextPropagationToken-    {-        /// <summary>-        /// Default propagation mask used by C core.-        /// </summary>-        private const ContextPropagationFlags DefaultCoreMask = (ContextPropagationFlags)0xffff;--        /// <summary>-        /// Default propagation mask used by C# - we want to propagate deadline -        /// and cancellation token by our own means.-        /// </summary>-        internal const ContextPropagationFlags DefaultMask = DefaultCoreMask-            & ~ContextPropagationFlags.Deadline & ~ContextPropagationFlags.Cancellation;--        readonly CallSafeHandle parentCall;-        readonly DateTime deadline;-        readonly CancellationToken cancellationToken;-        readonly ContextPropagationOptions options;--        internal ContextPropagationToken(CallSafeHandle parentCall, DateTime deadline, CancellationToken cancellationToken, ContextPropagationOptions options)-        {-            this.parentCall = GrpcPreconditions.CheckNotNull(parentCall);-            this.deadline = deadline;-            this.cancellationToken = cancellationToken;-            this.options = options ?? ContextPropagationOptions.Default;-        }--        /// <summary>-        /// Gets the native handle of the parent call.-        /// </summary>-        internal CallSafeHandle ParentCall-        {-            get-            {-                return this.parentCall;-            }-        }--        /// <summary>-        /// Gets the parent call's deadline.-        /// </summary>-        internal DateTime ParentDeadline-        {-            get-            {-                return this.deadline;-            }-        }--        /// <summary>-        /// Gets the parent call's cancellation token.-        /// </summary>-        internal CancellationToken ParentCancellationToken-        {-            get-            {-                return this.cancellationToken;-            }-        }--        /// <summary>-        /// Get the context propagation options.-        /// </summary>-        internal ContextPropagationOptions Options-        {-            get-            {-                return this.options;-            }-        }-    }--    /// <summary>-    /// Options for <see cref=""ContextPropagationToken""/>.-    /// </summary>-    public class ContextPropagationOptions+    public abstract class ContextPropagationToken     {-        /// <summary>-        /// The context propagation options that will be used by default.-        /// </summary>-        public static readonly ContextPropagationOptions Default = new ContextPropagationOptions();--        bool propagateDeadline;-        bool propagateCancellation;--        /// <summary>-        /// Creates new context propagation options.-        /// </summary>-        /// <param name=""propagateDeadline"">If set to <c>true</c> parent call's deadline will be propagated to the child call.</param>-        /// <param name=""propagateCancellation"">If set to <c>true</c> parent call's cancellation token will be propagated to the child call.</param>-        public ContextPropagationOptions(bool propagateDeadline = true, bool propagateCancellation = true)-        {-            this.propagateDeadline = propagateDeadline;-            this.propagateCancellation = propagateCancellation;-        }-            -        /// <summary><c>true</c> if parent call's deadline should be propagated to the child call.</summary>-        public bool IsPropagateDeadline+        internal ContextPropagationToken()","> Token for propagating context of server side handlers to child calls. In situations when a backend is making calls to another backend, it makes sense to propagate properties like deadline and cancellation token of the server call to the child call. So if we don't have this mechanism, we'd be breaking the propagation chain right? For example, if a c-core service calls an aspnet service that calls a c-core service?",OK
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/17740,249213764,2019-01-18T23:22:26Z,src/core/lib/gprpp/linked_list.h,"@@ -0,0 +1,149 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_GPRPP_LINKED_LIST_H+#define GRPC_CORE_LIB_GPRPP_LINKED_LIST_H++#include ""src/core/lib/gprpp/memory.h""++namespace grpc_core {++template<typename T> class LinkedList {+ public:+  ~LinkedList() {+    clear();+  }++  struct ListNode {+    template<typename... Args>+    ListNode(Args&&... args) {+      new (&val) T(std::forward<Args>(args)...);+    }++    ListNode *prev_ = nullptr;+    ListNode *next_ = nullptr;+    T val;+  };++  struct Iter+  {+      LinkedList<T>& list_;+      ListNode *node_;++      Iter(LinkedList<T>& list) : list_(list), node_(list.head_) {}+      Iter(LinkedList<T>& list, ListNode *node) : list_(list), node_(node) {}++      bool operator!=(const Iter& other) const+      {+          return !(*this == other);+      }++      bool operator==(const Iter& other) const+      {+          return node_ == other.node_;+      }++      Iter& operator++()+      {+          if (node_) {+            node_ = node_->next_;+          }+          return *this;+      }++      T& operator*() const+      {+          return node_->val;+      }+  };",Ack; removing this class. I did add an Iter to InlinedVector that should be fine.,OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17728,249250423,2019-01-19T16:50:16Z,templates/tools/dockerfile/php7_deps.include,"@@ -19,6 +19,7 @@ RUN apt-get update && apt-get install -y ${'\\'}   re2c ${'\\'}   time ${'\\'}   unzip ${'\\'}+  valgrind ${'\\'}","Let's only add `<%include file=""../../valgrind.include""/>` in the right docker images where they are useful. E.g. only add here after this line: https://github.com/grpc/grpc/blob/3278bdceda8030d5aa130f12765e5f07263c860d/templates/tools/dockerfile/test/php7_jessie_x64/Dockerfile.template#L21`",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17051,249396291,2019-01-21T10:31:54Z,src/csharp/Grpc.Core/ChannelCredentials.cs,"@@ -104,40 +104,71 @@ internal override ChannelCredentialsSafeHandle CreateNativeCredentials()         }     } +    /// <summary>+    /// Callback invoked with the expected targetHost and the peer's certificate.+    /// If a non-zero value is returned by this callback then it is treated as a+    /// verification failure. Invocation of the callback is blocking, so any+    /// implementation should be light-weight.+    /// </summary>+    /// <param name=""targetHost"">string containing the host name of the peer.</param>+    /// <param name=""targetPem"">string containint PEM encoded certificate of the peer.</param>+    /// <returns>0 is verification succeeded, non 0 otherwise.</returns>",command not updated to bool semantics,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17051,249400988,2019-01-21T10:45:01Z,src/csharp/Grpc.Core/ChannelCredentials.cs,"@@ -104,40 +104,71 @@ internal override ChannelCredentialsSafeHandle CreateNativeCredentials()         }     } +    /// <summary>+    /// Callback invoked with the expected targetHost and the peer's certificate.+    /// If a non-zero value is returned by this callback then it is treated as a+    /// verification failure. Invocation of the callback is blocking, so any+    /// implementation should be light-weight.+    /// </summary>+    /// <param name=""targetHost"">string containing the host name of the peer.</param>+    /// <param name=""targetPem"">string containint PEM encoded certificate of the peer.</param>+    /// <returns>0 is verification succeeded, non 0 otherwise.</returns>+    public delegate bool VerifyPeerCallback(string targetHost, string targetPem);","To allow adding more fields in the future if needed without breaking the API,I'd suggest wrapping all the params in `VerifyPeerContext` class (adding fields to a class is backwards compatible).The idea is the same as e.g. here: https://github.com/grpc/grpc/blob/3278bdceda8030d5aa130f12765e5f07263c860d/src/csharp/Grpc.Core/AsyncAuthInterceptor.cs#L34 ",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17051,249401863,2019-01-21T10:47:18Z,src/csharp/Grpc.Core/ChannelCredentials.cs,"@@ -104,40 +104,71 @@ internal override ChannelCredentialsSafeHandle CreateNativeCredentials()         }     } +    /// <summary>+    /// Callback invoked with the expected targetHost and the peer's certificate.+    /// If a non-zero value is returned by this callback then it is treated as a+    /// verification failure. Invocation of the callback is blocking, so any+    /// implementation should be light-weight.+    /// </summary>+    /// <param name=""targetHost"">string containing the host name of the peer.</param>+    /// <param name=""targetPem"">string containint PEM encoded certificate of the peer.</param>+    /// <returns>0 is verification succeeded, non 0 otherwise.</returns>+    public delegate bool VerifyPeerCallback(string targetHost, string targetPem);++    internal delegate int VerifyPeerCallbackInternal(",move the internal delegate to https://github.com/grpc/grpc/blob/master/src/csharp/Grpc.Core/Internal/ChannelCredentialsSafeHandle.cs,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17051,249402955,2019-01-21T10:50:32Z,src/csharp/Grpc.Core/ChannelCredentials.cs,"@@ -104,40 +104,71 @@ internal override ChannelCredentialsSafeHandle CreateNativeCredentials()         }     } +    /// <summary>+    /// Callback invoked with the expected targetHost and the peer's certificate.+    /// If a non-zero value is returned by this callback then it is treated as a+    /// verification failure. Invocation of the callback is blocking, so any+    /// implementation should be light-weight.+    /// </summary>+    /// <param name=""targetHost"">string containing the host name of the peer.</param>+    /// <param name=""targetPem"">string containint PEM encoded certificate of the peer.</param>+    /// <returns>0 is verification succeeded, non 0 otherwise.</returns>+    public delegate bool VerifyPeerCallback(string targetHost, string targetPem);++    internal delegate int VerifyPeerCallbackInternal(+        string targetHost,+        string targetPem,+        IntPtr userData);+     /// <summary>     /// Client-side SSL credentials.     /// </summary>     public sealed class SslCredentials : ChannelCredentials     {         readonly string rootCertificates;         readonly KeyCertificatePair keyCertificatePair;+        readonly VerifyPeerCallbackInternal verifyPeerCallback;          /// <summary>         /// Creates client-side SSL credentials loaded from         /// disk file pointed to by the GRPC_DEFAULT_SSL_ROOTS_FILE_PATH environment variable.         /// If that fails, gets the roots certificates from a well known place on disk.         /// </summary>-        public SslCredentials() : this(null, null)+        public SslCredentials() : this(null, null, null)         {         }          /// <summary>         /// Creates client-side SSL credentials from         /// a string containing PEM encoded root certificates.         /// </summary>-        public SslCredentials(string rootCertificates) : this(rootCertificates, null)+        public SslCredentials(string rootCertificates) :+            this(rootCertificates, null, null)         {         }-            ++        /// <summary>+        /// Creates client-side SSL credentials.+        /// </summary>+        /// <param name=""rootCertificates"">string containing PEM encoded server root certificates.</param>+        /// <param name=""keyCertificatePair"">a key certificate pair.</param>+        public SslCredentials(string rootCertificates, KeyCertificatePair keyCertificatePair) :+            this(rootCertificates, keyCertificatePair, null)+        {+        }+         /// <summary>         /// Creates client-side SSL credentials.         /// </summary>         /// <param name=""rootCertificates"">string containing PEM encoded server root certificates.</param>         /// <param name=""keyCertificatePair"">a key certificate pair.</param>-        public SslCredentials(string rootCertificates, KeyCertificatePair keyCertificatePair)+        /// <param name=""verifyPeerCallback"">a callback to verify peer's target name and certificate.</param>+        public SslCredentials(string rootCertificates, KeyCertificatePair keyCertificatePair, VerifyPeerCallback verifyPeerCallback)","Let's mark the newly added constructor as ""experimental"" to allow API changes if adjustments are needed (we can fixate the API after a while).E.g. like this: https://github.com/grpc/grpc/blob/3278bdceda8030d5aa130f12765e5f07263c860d/src/csharp/Grpc.Core/Marshaller.cs#L80",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17051,249410902,2019-01-21T11:15:20Z,src/csharp/Grpc.Core/ChannelCredentials.cs,"@@ -104,40 +104,71 @@ internal override ChannelCredentialsSafeHandle CreateNativeCredentials()         }     } +    /// <summary>+    /// Callback invoked with the expected targetHost and the peer's certificate.+    /// If a non-zero value is returned by this callback then it is treated as a+    /// verification failure. Invocation of the callback is blocking, so any+    /// implementation should be light-weight.+    /// </summary>+    /// <param name=""targetHost"">string containing the host name of the peer.</param>+    /// <param name=""targetPem"">string containint PEM encoded certificate of the peer.</param>+    /// <returns>0 is verification succeeded, non 0 otherwise.</returns>+    public delegate bool VerifyPeerCallback(string targetHost, string targetPem);++    internal delegate int VerifyPeerCallbackInternal(+        string targetHost,+        string targetPem,+        IntPtr userData);+     /// <summary>     /// Client-side SSL credentials.     /// </summary>     public sealed class SslCredentials : ChannelCredentials     {         readonly string rootCertificates;         readonly KeyCertificatePair keyCertificatePair;+        readonly VerifyPeerCallbackInternal verifyPeerCallback;          /// <summary>         /// Creates client-side SSL credentials loaded from         /// disk file pointed to by the GRPC_DEFAULT_SSL_ROOTS_FILE_PATH environment variable.         /// If that fails, gets the roots certificates from a well known place on disk.         /// </summary>-        public SslCredentials() : this(null, null)+        public SslCredentials() : this(null, null, null)         {         }          /// <summary>         /// Creates client-side SSL credentials from         /// a string containing PEM encoded root certificates.         /// </summary>-        public SslCredentials(string rootCertificates) : this(rootCertificates, null)+        public SslCredentials(string rootCertificates) :+            this(rootCertificates, null, null)         {         }-            ++        /// <summary>+        /// Creates client-side SSL credentials.+        /// </summary>+        /// <param name=""rootCertificates"">string containing PEM encoded server root certificates.</param>+        /// <param name=""keyCertificatePair"">a key certificate pair.</param>+        public SslCredentials(string rootCertificates, KeyCertificatePair keyCertificatePair) :+            this(rootCertificates, keyCertificatePair, null)+        {+        }+         /// <summary>         /// Creates client-side SSL credentials.         /// </summary>         /// <param name=""rootCertificates"">string containing PEM encoded server root certificates.</param>         /// <param name=""keyCertificatePair"">a key certificate pair.</param>-        public SslCredentials(string rootCertificates, KeyCertificatePair keyCertificatePair)+        /// <param name=""verifyPeerCallback"">a callback to verify peer's target name and certificate.</param>+        public SslCredentials(string rootCertificates, KeyCertificatePair keyCertificatePair, VerifyPeerCallback verifyPeerCallback)         {             this.rootCertificates = rootCertificates;             this.keyCertificatePair = keyCertificatePair;+            this.verifyPeerCallback = verifyPeerCallback == null ?+                null : new VerifyPeerCallbackInternal((host, pem, userData) => verifyPeerCallback(host, pem) ? 0 : 1);","this is actually not safe - the problem is that the delegate can be garbage collected at some point but the native layer won't know about it and will try to invoke it, which will result in segfault.Native to managed callbacks are tricky.Look at https://github.com/grpc/grpc/blob/3278bdceda8030d5aa130f12765e5f07263c860d/src/csharp/Grpc.Core/Internal/NativeMetadataCredentialsPlugin.cs#L47 to see how the destruction logic is handled (it's not that simple).",
44597042,tlg-bf,https://api.github.com/repos/grpc/grpc/pulls/17051,249645478,2019-01-22T05:31:46Z,src/csharp/Grpc.Core/ChannelCredentials.cs,"@@ -104,40 +104,71 @@ internal override ChannelCredentialsSafeHandle CreateNativeCredentials()         }     } +    /// <summary>+    /// Callback invoked with the expected targetHost and the peer's certificate.+    /// If a non-zero value is returned by this callback then it is treated as a+    /// verification failure. Invocation of the callback is blocking, so any+    /// implementation should be light-weight.+    /// </summary>+    /// <param name=""targetHost"">string containing the host name of the peer.</param>+    /// <param name=""targetPem"">string containint PEM encoded certificate of the peer.</param>",No longer relevant after changes to `VerifyPeerContext`.,
44597042,tlg-bf,https://api.github.com/repos/grpc/grpc/pulls/17051,249646886,2019-01-22T05:41:44Z,src/csharp/Grpc.Core/ChannelCredentials.cs,"@@ -104,40 +104,71 @@ internal override ChannelCredentialsSafeHandle CreateNativeCredentials()         }     } +    /// <summary>+    /// Callback invoked with the expected targetHost and the peer's certificate.+    /// If a non-zero value is returned by this callback then it is treated as a+    /// verification failure. Invocation of the callback is blocking, so any+    /// implementation should be light-weight.+    /// </summary>+    /// <param name=""targetHost"">string containing the host name of the peer.</param>+    /// <param name=""targetPem"">string containint PEM encoded certificate of the peer.</param>+    /// <returns>0 is verification succeeded, non 0 otherwise.</returns>+    public delegate bool VerifyPeerCallback(string targetHost, string targetPem);++    internal delegate int VerifyPeerCallbackInternal(+        string targetHost,+        string targetPem,+        IntPtr userData);+     /// <summary>     /// Client-side SSL credentials.     /// </summary>     public sealed class SslCredentials : ChannelCredentials     {         readonly string rootCertificates;         readonly KeyCertificatePair keyCertificatePair;+        readonly VerifyPeerCallbackInternal verifyPeerCallback;          /// <summary>         /// Creates client-side SSL credentials loaded from         /// disk file pointed to by the GRPC_DEFAULT_SSL_ROOTS_FILE_PATH environment variable.         /// If that fails, gets the roots certificates from a well known place on disk.         /// </summary>-        public SslCredentials() : this(null, null)+        public SslCredentials() : this(null, null, null)         {         }          /// <summary>         /// Creates client-side SSL credentials from         /// a string containing PEM encoded root certificates.         /// </summary>-        public SslCredentials(string rootCertificates) : this(rootCertificates, null)+        public SslCredentials(string rootCertificates) :+            this(rootCertificates, null, null)         {         }-            ++        /// <summary>+        /// Creates client-side SSL credentials.+        /// </summary>+        /// <param name=""rootCertificates"">string containing PEM encoded server root certificates.</param>+        /// <param name=""keyCertificatePair"">a key certificate pair.</param>+        public SslCredentials(string rootCertificates, KeyCertificatePair keyCertificatePair) :+            this(rootCertificates, keyCertificatePair, null)+        {+        }+         /// <summary>         /// Creates client-side SSL credentials.         /// </summary>         /// <param name=""rootCertificates"">string containing PEM encoded server root certificates.</param>         /// <param name=""keyCertificatePair"">a key certificate pair.</param>-        public SslCredentials(string rootCertificates, KeyCertificatePair keyCertificatePair)+        /// <param name=""verifyPeerCallback"">a callback to verify peer's target name and certificate.</param>+        public SslCredentials(string rootCertificates, KeyCertificatePair keyCertificatePair, VerifyPeerCallback verifyPeerCallback)",Added this note to a couple of places where I thought it made sense:* The `VerifyPeerCallback` delegate definition (https://github.com/grpc/grpc/pull/17051/files#diff-4281d7ff0b726dd27c1d9f64ee85fca6R128).* This constructor (https://github.com/grpc/grpc/pull/17051/files#diff-4281d7ff0b726dd27c1d9f64ee85fca6R174).* The `VerifyPeerContext` class (https://github.com/grpc/grpc/pull/17051/files#diff-9a333bdf5d97c42cae8e54ecae812730R5).,OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/17788,249907171,2019-01-22T18:32:30Z,tools/interop_matrix/run_interop_matrix_tests.py,"@@ -171,25 +171,35 @@ def _generate_test_case_jobspecs(lang, runtime, release, suite_name):     for line in testcase_lines:         # TODO(jtattermusch): revisit the logic for updating test case commands         # what it currently being done seems fragile.-        m = re.search('--test_case=(.*)""', line)-        shortname = m.group(1) if m else 'unknown_test'-        m = re.search('--server_host_override=(.*).sandbox.googleapis.com',-                      line)++        # Extract test case name from the command line+        m = re.search(r'--test_case=(\w+)', line)+        testcase_name = m.group(1) if m else 'unknown_test'++        # Extract the server name from the command line+        if '--server_host_override=' in line:","nit: as far as I can see, `--server_host_override`, if set, would always set to the same value as `--server_host`In that case, can, this conditional be simplified to just `m = re.search(r'--server_host=((.*).sandbox.googleapis.com)', line)` ?",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/17652,250083840,2019-01-23T07:51:12Z,src/compiler/ruby_generator.cc,"@@ -37,16 +38,60 @@ using std::vector; namespace grpc_ruby_generator { namespace { +// returns the full canonical message name+grpc::string GetCanonicalMessageType(const Descriptor* msg) {+  const Descriptor* top_level_msg;+  const FileDescriptor* file_containing_msg;+  grpc::string resolved_namespace;++  // If msg is nested, find the topmost message+  top_level_msg = msg;+  while (top_level_msg->containing_type()) {+    top_level_msg = top_level_msg->containing_type();+  }+  file_containing_msg = top_level_msg->file();++  grpc::string msg_full_name;+  grpc::string msg_name;+  grpc::string msg_proto_pkg;++  msg_full_name = top_level_msg->full_name();+  msg_name = top_level_msg->name();+  msg_proto_pkg =+      msg_full_name.substr(0, msg_full_name.length() - msg_name.length());++  if (file_containing_msg->options().has_ruby_package()) {","style nit: can we please move this conditional up to the top of this function, and just make it a guard on the rest of the function? Something like:```if (!file_containing_msg->options().has_ruby_package()) {  return msg->full_name();}...// handle ruby package...```",OK
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17644,250347296,2019-01-23T19:49:15Z,third_party/py/python_configure.bzl,"@@ -138,10 +138,8 @@ def _symlink_genrule_for_dir(repository_ctx,  def _get_python_bin(repository_ctx):     """"""Gets the python bin path.""""""-    python_bin = repository_ctx.os.environ.get(_PYTHON_BIN_PATH)-    if python_bin != None:-        return python_bin-    python_bin_path = repository_ctx.which(""python"")+    python_bin = repository_ctx.os.environ.get(_PYTHON_BIN_PATH, 'python')",Why is this changing the semantics of the `PYTHON_BIN_PATH` environment variable?,
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17793,250359609,2019-01-23T20:28:20Z,src/python/grpcio_tests/tests/qps/README.md,"@@ -0,0 +1,100 @@+# Python Benchmark Tools++## Scenarios++In `src/proto/grpc/testing/control.proto`, it defines the fields of a scenario.+In `tools/run_tests/performance/scenario_config.py`, the script generates actual scenario content that usually in json format, or piped to another script.++All Python related benchmark scenarios are:+* netperf+* python_generic_sync_streaming_ping_pong+* python_protobuf_sync_streaming_ping_pong+* python_protobuf_async_unary_ping_pong+* python_protobuf_sync_unary_ping_pong+* python_protobuf_sync_unary_qps_unconstrained+* python_protobuf_sync_streaming_qps_unconstrained+* python_protobuf_sync_unary_ping_pong_1MB++Here I picked the top 2 most representative scenarios of them, and reduce their benchmark duration from 30 seconds to 10 seconds:+* python_protobuf_async_unary_ping_pong+* python_protobuf_sync_streaming_ping_pong++## Why keep the scenario file if it can be generated?++Well... The `tools/run_tests/performance/scenario_config.py` is 1274 lines long. The intention of building these benchmark tools is reducing the complexity of existing infrastructure code. Depending on something that is ","Thanks for pointing out. The updated version:Well... The `tools/run_tests/performance/scenario_config.py` is 1274 lines long. The intention of building these benchmark tools is reducing the complexity of existing infrastructure code. So, instead of calling layers of abstraction to generate the scenario file, keeping a valid static copy is more preferable.",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/17644,250363008,2019-01-23T20:38:36Z,third_party/py/python_configure.bzl,"@@ -138,10 +138,8 @@ def _symlink_genrule_for_dir(repository_ctx,  def _get_python_bin(repository_ctx):     """"""Gets the python bin path.""""""-    python_bin = repository_ctx.os.environ.get(_PYTHON_BIN_PATH)-    if python_bin != None:-        return python_bin-    python_bin_path = repository_ctx.which(""python"")+    python_bin = repository_ctx.os.environ.get(_PYTHON_BIN_PATH, 'python')","This library is forked from TensorFlow's repo. The main purpose of this package is locating the CPython header files to help Cython compile. In its original logic, to use Python 3, we need to set `PYTHON_BIN_PATH` to a absolute path like `/usr/bin/python3` or `/usr/local/bin/python3`. It's not very adaptive across environments. So, in the new logic, even if the `PYTHON_BIN_PATH` is not given an absolute path, it can try to find the correct path using `which`.Also, it doesn't break backward compatibility, developers who used this flag should observe no behavior change, because `which` command will return the exact same path as input if the input is an absolute path.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/17796,250375370,2019-01-23T21:17:19Z,test/cpp/end2end/BUILD,"@@ -219,6 +219,7 @@ grpc_cc_test(  grpc_cc_test(     name = ""end2end_test"",+    timeout = ""long"",","I think ideally this long timeout would only get applied for the poll-cv cases, because the other pollers seem to be ok with the shorter timeout. I could also imagine that we might find out some other tests (possibly also only under poll-cv) might need the ""long"" timeout.What do you think about centralizing this timeout config, and adding some helper into `bazel/grpc_build_system.bzl`, e.g. `get_timeout_for_test_case` (which for now would apply the ""long"" timeout basically only if it is this test under poll-cv) which we could use around https://github.com/grpc/grpc/blob/master/bazel/grpc_build_system.bzl#L161.",
41599993,billfeng327,https://api.github.com/repos/grpc/grpc/pulls/17796,250391960,2019-01-23T22:08:54Z,test/cpp/end2end/BUILD,"@@ -219,6 +219,7 @@ grpc_cc_test(  grpc_cc_test(     name = ""end2end_test"",+    timeout = ""long"",","A query of recent dbg RBE runs (from 1/10) shows that only end2end_test with poll-cv poller has the timeout issue. Modifying the grpc_cc_test() function to accept poller-specific timeouts requires changes of many other targets, making it impractical. This should be a one-f case, as other targets with poll-cv did not demonstrate similar timeout issues.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17803,250657955,2019-01-24T15:41:19Z,src/core/ext/filters/client_channel/subchannel.cc,"@@ -202,6 +202,7 @@ class ConnectedSubchannelStateWatcher   // Must be instantiated while holding c->mu.   explicit ConnectedSubchannelStateWatcher(grpc_subchannel* c)       : subchannel_(c) {+    gpr_mu_init(&mu_);","I'm not keen on adding a new mutex here, since this class already holds the subchannel's mutex in various places (look for `c->mu`), and I don't want to introduce the possibility of a deadlock between the two.Instead, how about the following:- Add a `gpr_atm shutdown_` member.- Set `shutdown_` to true in `Orphan()`.- In `OnHealthChanged()`, when we check that the reported status is `GRPC_CHANNEL_SHUTDOWN`, also check the value of `shutdown_`.  If either one is true, then we do the same thing.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17803,250788758,2019-01-24T21:44:50Z,src/core/ext/filters/client_channel/subchannel.cc,"@@ -202,6 +202,7 @@ class ConnectedSubchannelStateWatcher   // Must be instantiated while holding c->mu.   explicit ConnectedSubchannelStateWatcher(grpc_subchannel* c)       : subchannel_(c) {+    gpr_mu_init(&mu_);","Yeah, I think you're right.So I guess we need a mutex of some sort here.  I would still prefer to avoid introducing a new one if possible, because I fear deadlocks between the two.  See if you can find a reasonable way to make use of the existing `c->mu` for this.  I suspect that this may be challenging, since `Orphan()` may be called in a context where we're already holding `c->mu`.  But if that's the case, then maybe we don't need to acquire it inside of `Orphan()` anyway.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17798,250990810,2019-01-25T13:51:47Z,templates/tools/dockerfile/bazel.include,"@@ -2,5 +2,5 @@ # Bazel installation  RUN apt-get update && apt-get install -y wget && apt-get clean-RUN wget -q https://github.com/bazelbuild/bazel/releases/download/0.17.1/bazel-0.17.1-linux-x86_64 -O /usr/local/bin/bazel-RUN chmod 755 /usr/local/bin/bazel+RUN wget https://github.com/bazelbuild/bazel/releases/download/0.20.0/bazel-0.20.0-installer-linux-x86_64.sh","nit:  to reduce docker image size (the installer is 163MB big), we could do`RUN wget https://github.com/bazelbuild/bazel/releases/download/0.20.0/bazel-0.20.0-installer-linux-x86_64.sh &&  bash ./bazel-0.20.0-installer-linux-x86_64.sh && rm bazel-0.20.0-installer-linux-x86_64.sh`it must be done in a single command due to how docker image layering works.",
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/17728,251089853,2019-01-25T18:35:58Z,src/php/bin/run_tests.sh,"@@ -22,9 +22,19 @@ cd src/php/bin source ./determine_extension_dir.sh # in some jenkins macos machine, somehow the PHP build script can't find libgrpc.dylib export DYLD_LIBRARY_PATH=$root/libs/$CONFIG+ php $extension_dir -d max_execution_time=300 $(which phpunit) -v --debug \   --exclude-group persistent_list_bound_tests ../tests/unit_tests  php $extension_dir -d max_execution_time=300 $(which phpunit) -v --debug \   ../tests/unit_tests/PersistentChannelTests +export ZEND_DONT_UNLOAD_MODULES=1+export USE_ZEND_ALLOC=0+# Detect whether valgrind is executable+if ! [ -x ""$(command -v valgrind)"" ]; then+  echo 'Error: valgrind is not installed and is not executable' >&2+  exit 1","Let's do `exit 0`. Or, we can just move the main `valgrind` command below inside the `if` here, and flip the conditional. Like```if <valgrind is installed>  run valgrind commandfi```",
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/17728,251097121,2019-01-25T18:56:30Z,src/php/tests/unit_tests/CallTest.php,"@@ -86,6 +86,26 @@ public function testAddSingleAndMultiValueMetadata()         $this->assertTrue($result->send_metadata);     } +    public function testAddMultiAndMultiValueMetadata()+    {+        $batch = [+            Grpc\OP_SEND_INITIAL_METADATA => ['key1' => ['value1', 'value2'],+                                              'key2' => ['value3', 'value4'],],+        ];+        $result = $this->call->startBatch($batch);+        $this->assertTrue($result->send_metadata);+    }++    public function testAddMultiAndMultiValueMetadata()",Please remove one of these. They seem to be duplicate,OK
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17789,251147640,2019-01-25T21:50:34Z,src/python/grpcio/grpc/_interceptor.py,"@@ -235,8 +236,8 @@ def continuation(new_details, request):                     credentials=new_credentials,                     wait_for_ready=new_wait_for_ready)                 return _UnaryOutcome(response, call)-            except grpc.RpcError as rpc_error:-                return rpc_error+            except _Rendezvous as rendezvous:","Don't we also need to implement the `Future` interface to actually have the requisite `exception` attribute? The doc says:> In the event of RPC completion, the return Call-Future’s result value will be the response message of the RPC. Should the event terminate with non-OK status, the returned Call-Future’s exception value will be an RpcError.Omitting the special casing altogether looks like it would lead to swallowing the rpc error code, as mentioned by the reviewer on your original change [here](https://github.com/grpc/grpc/pull/14639#pullrequestreview-102314676).The docs on `with_call` allow it to raise an `RpcError` which will also be a `Call`, which we must then ensure is also a `Future` when we return it here. I am fully willing to believe the current implementation will/should always result in a `_Rendezvous` here, but we should program to the API, not the (underscore-prefixed) `_Rendezvous` implementation.This code and the potential for type errors here definitely warrant a test. We can take over (PR-as-issue?) but it would be helpful when prioritizing this for us to know if you're sending this change to fix a known breakage (PR-as-bug) or if this is purely intended to future proof the code in correcting an oversight from the last change (PR-as-P2).  ",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/17789,251152225,2019-01-25T22:09:16Z,src/python/grpcio/grpc/_interceptor.py,"@@ -235,8 +236,8 @@ def continuation(new_details, request):                     credentials=new_credentials,                     wait_for_ready=new_wait_for_ready)                 return _UnaryOutcome(response, call)-            except grpc.RpcError as rpc_error:-                return rpc_error+            except _Rendezvous as rendezvous:","@ericgribkoff There's definitely a bug there that might bite other users, but if what you are asking is whether I encountered it in real usage, the answer is no, so I don't have a concrete real-world test-case to contribute here; just realized that the code is definitely buggy. There might be other bugs or a better way to fundamentally resolve it. There's definitely complexity and room for error that's rooted in `_Rendezvous`'s plethora of interfaces that is hard to understand or enforce without proper typechecking.  I agree that proper testing is warranted, perhaps with clarification on the documentation if there's anything missing.  Looks like `grpc.Future` is indeed necessary as well, so an adapter class might be needed here. That said, special casing `_Rendezvous` as an *optimization* so that you don't construct intermediate classes in the common case might still be a valid thing to do. Please feel free to do what's best in your opinion to resolve (the whole thing is still marked as experimental, so even minor design changes may still be appropriate).",OK
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17644,251531735,2019-01-28T18:13:30Z,third_party/py/python_configure.bzl,"@@ -138,10 +138,8 @@ def _symlink_genrule_for_dir(repository_ctx,  def _get_python_bin(repository_ctx):     """"""Gets the python bin path.""""""-    python_bin = repository_ctx.os.environ.get(_PYTHON_BIN_PATH)-    if python_bin != None:-        return python_bin-    python_bin_path = repository_ctx.which(""python"")+    python_bin = repository_ctx.os.environ.get(_PYTHON_BIN_PATH, 'python')","I see that this is used by the `build:python3 --action_env=PYTHON_BIN_PATH=python3` addition in tools/bazel.rc. If the error reported above is indeed valid, I would suggest instead adding a new environment variable (`PYTHON_BIN_NAME`, or something similar, which defaults to `python`) that can be set in `bazel.rc` to `python3`, and pass this value to the existing `which` query.",OK
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17644,251532325,2019-01-28T18:15:07Z,src/python/grpcio_tests/tests/bazel_patch.py,"@@ -0,0 +1,32 @@+# Copyright 2019 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import os+import site+import sys+++# TODO(https://github.com/bazelbuild/bazel/issues/6844) Bazel failed to+# interpret namespace packages correctly. This monkey patch will force the+# Python process to parse the .pth file in the sys.path to resolve namespace+# package in the right place.+# Analysis in depth: https://github.com/bazelbuild/rules_python/issues/55+def bazel_patch():","This should also sound scarier than patch, e.g., `sys_path_to_site_dir_hack` or similar",OK
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/17644,251532821,2019-01-28T18:16:28Z,src/python/grpcio_tests/tests/BUILD.bazel,"@@ -0,0 +1,8 @@+py_library(+    name = ""bazel_patch"",+    srcs = [""bazel_patch.py""],+    visibility = [""//visibility:public""],",Please keep this visibility restricted to a whitelist of specific tests that need it.,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17836,251561051,2019-01-28T19:32:18Z,tools/internal_ci/helper_scripts/prepare_build_linux_perf_rc,"@@ -21,7 +21,13 @@ ulimit -c unlimited  # Performance PR testing needs GH API key and PR metadata to comment results if [ -n ""$KOKORO_GITHUB_PULL_REQUEST_NUMBER"" ]; then-  sudo apt-get install -y jq+  retry=0",this is ok as a short term fix but I'd like something cleaner and more maintainable in the long run.let's add a TODO to find a better way to do this.another nit: doest `sudo apt-get install -y jq || (sleep 5; sudo apt-get install -y jq) || (sleep 5; sudo apt-get install -y jq)` look more readable?,OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/17806,251569779,2019-01-28T19:56:06Z,include/grpcpp/impl/codegen/interceptor_common.h,"@@ -219,10 +219,28 @@ class InterceptorBatchMethodsImpl   // Alternatively, RunInterceptors(std::function<void(void)> f) can be used.   void SetCallOpSetInterface(CallOpSetInterface* ops) { ops_ = ops; } -  // Returns true if no interceptors are run. This should be used only by-  // subclasses of CallOpSetInterface. SetCall and SetCallOpSetInterface should-  // have been called before this. After all the interceptors are done running,-  // either ContinueFillOpsAfterInterception or+  // Returns true if the interceptors list is empty",This code and `RunInterceptors` are so similar that it screams of a need for code reuse.,OK
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/17806,251650828,2019-01-29T00:34:49Z,include/grpcpp/impl/codegen/interceptor_common.h,"@@ -219,10 +219,28 @@ class InterceptorBatchMethodsImpl   // Alternatively, RunInterceptors(std::function<void(void)> f) can be used.   void SetCallOpSetInterface(CallOpSetInterface* ops) { ops_ = ops; } -  // Returns true if no interceptors are run. This should be used only by-  // subclasses of CallOpSetInterface. SetCall and SetCallOpSetInterface should-  // have been called before this. After all the interceptors are done running,-  // either ContinueFillOpsAfterInterception or+  // Returns true if the interceptors list is empty",I could do some reuse but that ends up doing some unnecessary condition checks.,
25445066,jerrycmh,https://api.github.com/repos/grpc/grpc/pulls/17728,251717815,2019-01-29T07:31:51Z,src/php/tests/MemoryLeakTest/MemoryLeakTest.php,,"sorry, this is my bad.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/17875,252492713,2019-01-31T00:22:06Z,src/core/lib/surface/server.cc,"@@ -997,10 +997,12 @@ void grpc_server_register_completion_queue(grpc_server* server,       ""grpc_server_register_completion_queue(server=%p, cq=%p, reserved=%p)"", 3,       (server, cq, reserved)); -  if (grpc_get_cq_completion_type(cq) != GRPC_CQ_NEXT) {+  auto cq_type = grpc_get_cq_completion_type(cq);+  if (cq_type != GRPC_CQ_NEXT && cq_type != GRPC_CQ_CALLBACK) {     gpr_log(GPR_INFO,-            ""Completion queue which is not of type GRPC_CQ_NEXT is being ""-            ""registered as a server-completion-queue"");+            ""Completion queue of type %d is being registered as a ""+            ""server-completion-queue"",+            static_cast<int>(cq_type));","So, here cq_type is explicitly _not_ async or callback. It should be pluckable, but I'm leaving open the possibility that we introduce some other new cq type in the future that is also unsuitable for server CQ.Now, note that pluckable is technically not unsuitable as a server CQ: Ruby uses it anyway. So maybe this log and test should just be eliminated altogether. WDYT?",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17778,252595338,2019-01-31T09:43:47Z,src/csharp/Grpc.Core/ForwardedTypes.cs,"@@ -0,0 +1,56 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System.Runtime.CompilerServices;+using Grpc.Core;+using Grpc.Core.Logging;+using Grpc.Core.Utils;++// API types that used to be in Grpc.Core package, but were moved to Grpc.Core.Api+// https://docs.microsoft.com/en-us/dotnet/framework/app-domains/type-forwarding-in-the-common-language-runtime++// TODO(jtattermusch): move types needed for implementing a client+// TODO(jtattermusch): ServerServiceDefinition depends on IServerCallHandler (which depends on other stuff)","It is possible to add an option, but I think it's not what we want.- supporting more options in Grpc.Tools adds complexity and makes delivering ""one size fits all"" solution harder- relying on codegen option will make it impossible to use both Grpc.Core server and Grpc.AspNetCore.Server in the same project (one requires the BindService() method and the other one forbids it).I've done some experimenting and I think I'll be able to refactor ServerServiceDefinition so it can be moved to Grpc.Core.Api as well - so far I'm quite happy with my WIP and I think I'll have a PR for that soon.",
2030323,JunTaoLuo,https://api.github.com/repos/grpc/grpc/pulls/17889,252836988,2019-01-31T20:55:19Z,src/csharp/Grpc.Core.Api/ServerServiceDefinition.cs,"@@ -62,7 +60,10 @@ public static Builder CreateBuilder()         /// </summary>         public class Builder         {-            readonly Dictionary<string, IServerCallHandler> callHandlers = new Dictionary<string, IServerCallHandler>();+            // to maintain legacy behavior, we need to detect duplicate keys and throw the same exception as before","I think this is a little redundant here. I think you can just make it a `Dictionary<string, Action<ServiceBinderBase>>` and then get the list of addMethodActions via dictionary.Keys which is read-only.",OK
2030323,JunTaoLuo,https://api.github.com/repos/grpc/grpc/pulls/17889,252888169,2019-01-31T23:49:48Z,src/csharp/Grpc.Core.Api/ServerServiceDefinition.cs,"@@ -18,33 +18,31 @@  using System; using System.Collections.Generic;-using System.Collections.ObjectModel;-using System.Linq;-using Grpc.Core.Interceptors;-using Grpc.Core.Internal;-using Grpc.Core.Utils;  namespace Grpc.Core {     /// <summary>-    /// Mapping of method names to server call handlers.+    /// Stores mapping of methods to server call handlers.     /// Normally, the <c>ServerServiceDefinition</c> objects will be created by the <c>BindService</c> factory method      /// that is part of the autogenerated code for a protocol buffers service definition.     /// </summary>     public class ServerServiceDefinition     {-        readonly ReadOnlyDictionary<string, IServerCallHandler> callHandlers;+        readonly IReadOnlyList<Action<ServiceBinderBase>> addMethodActions; -        internal ServerServiceDefinition(Dictionary<string, IServerCallHandler> callHandlers)+        internal ServerServiceDefinition(List<Action<ServiceBinderBase>> addMethodActions)         {-            this.callHandlers = new ReadOnlyDictionary<string, IServerCallHandler>(callHandlers);+            this.addMethodActions = addMethodActions.AsReadOnly();         } -        internal IDictionary<string, IServerCallHandler> CallHandlers+        /// <summary>+        /// Forwards all the previously stored <c>AddMethod</c> calls to the service binder.+        /// </summary>+        internal void BindService(ServiceBinderBase serviceBinder)","This sounds interesting and I would definitely prefer reducing duplication. I have a couple of questions though I think I already know the answer.1. Why keep the Builder class? Seems like `ServerServiceDefinition` is just a container for a set of actions to be taken during `BindService`. In which case it's simpler to just add the `AddMethod` methods to the `ServerServiceDefinition` class itself. This will require a bit of tweeking of the generated code but otherwise feasible. I'm assuming  back compat must be maintained since the Builder is public and therefore already exposed?2. The naming makes the usage a little odd. What you end up with is needing to invoke `Foo.BindService(new FooImpl()).BindService(new ServiceBinderImpl())` The chain of `.BindService` looks odd and unintuitive but it does work. Logically, it should look like `Foo.CollectServices(new FooImpl()).BindServices(new ServiceBinderImpl())`. I'm assuming we'd want to avoid it because it would require regenerating the code.",OK
109690,davidben,https://api.github.com/repos/grpc/grpc/pulls/17664,253136754,2019-02-01T17:37:56Z,src/core/tsi/ssl_transport_security.cc,"@@ -619,10 +619,15 @@ static tsi_result x509_store_load_certs(X509_STORE* cert_store,       sk_X509_NAME_push(*root_names, root_name);       root_name = nullptr;     }+    ERR_clear_error();     if (!X509_STORE_add_cert(cert_store, root)) {-      gpr_log(GPR_ERROR, ""Could not add root certificate to ssl context."");-      result = TSI_INTERNAL_ERROR;-      break;+      size_t error = ERR_get_error();","Nit: `size_t` isn't really the right type here. OpenSSL returns an `unsigned long`, so that's probably what you want. (BoringSSL uses `uint32_t` because it really should be a fixed-width integer and Windows makes `long` 32-bit. But `unsigned long` will work with both.",OK
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/17664,253177493,2019-02-01T19:46:37Z,test/core/tsi/ssl_transport_security_test.cc,"@@ -776,10 +776,24 @@ void ssl_tsi_test_handshaker_factory_internals() {   test_tsi_ssl_client_handshaker_factory_bad_params(); } +void ssl_tsi_test_duplicate_root_certificates() {+  const char* root_cert = load_file(SSL_TSI_TEST_CREDENTIALS_DIR, ""ca.pem"");","Yes, exactly. I duplicated the content of root cert and appended it to the root cert file. I also confirmed that `X509_STORE_add_cert` is invoked twice. I probably need to dig further into the Openssl code. Yes, it ends in a new line.",
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/17664,253219584,2019-02-01T22:25:06Z,test/core/tsi/ssl_transport_security_test.cc,"@@ -776,10 +776,24 @@ void ssl_tsi_test_handshaker_factory_internals() {   test_tsi_ssl_client_handshaker_factory_bad_params(); } +void ssl_tsi_test_duplicate_root_certificates() {+  const char* root_cert = load_file(SSL_TSI_TEST_CREDENTIALS_DIR, ""ca.pem"");","The reason that I did not observe the test failure (i.e., the one customer observed) is that I linked to openssl, whose implementation of `X509_STORE_add_cert` still returns success even if a duplicate is found: https://github.com/openssl/openssl/blob/master/crypto/x509/x509_lu.c#L347. In boringssl however, it returns a failure when a duplicate is found (confirmed internally).",
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/17643,253236921,2019-02-02T00:01:54Z,test/core/bad_connection/close_fd_test.cc,"@@ -0,0 +1,762 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ * close_fd_test tests the behavior of grpc core when the transport gets+ * disconnected.+ * The test creates an http2 transport over a socket pair and closes the+ * client or server file descriptor to simulate connection breakage while+ * an RPC call is in progress.+ *+ */+#include ""src/core/lib/iomgr/port.h""++// This test won't work except with posix sockets enabled+#ifdef GRPC_POSIX_SOCKET++#include ""test/core/util/test_config.h""++#include <stdio.h>+#include <string.h>+#include <unistd.h>++#include <grpc/byte_buffer.h>+#include <grpc/byte_buffer_reader.h>+#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/time.h>+#include ""src/core/ext/transport/chttp2/transport/chttp2_transport.h""+#include ""src/core/lib/gpr/env.h""+#include ""src/core/lib/iomgr/endpoint_pair.h""+#include ""src/core/lib/surface/channel.h""+#include ""src/core/lib/surface/completion_queue.h""+#include ""src/core/lib/surface/server.h""++static void* tag(intptr_t t) { return (void*)t; }++typedef struct test_ctx test_ctx;++struct test_ctx {+  /* completion queue for call notifications on the server */+  grpc_completion_queue* cq;+  /* completion queue registered to server for shutdown events */+  grpc_completion_queue* shutdown_cq;+  /* client's completion queue */+  grpc_completion_queue* client_cq;+  /* completion queue bound to call on the server */+  grpc_completion_queue* bound_cq;+  /* Server responds to client calls */+  grpc_server* server;+  /* Client calls are sent over the channel */+  grpc_channel* client;+  /* encapsulates client, server endpoints */+  grpc_endpoint_pair* ep;+};++static test_ctx g_ctx;++/* chttp2 transport that is immediately available (used for testing+   connected_channel without a client_channel */++static void server_setup_transport(grpc_transport* transport) {+  grpc_core::ExecCtx exec_ctx;+  grpc_endpoint_add_to_pollset(g_ctx.ep->server, grpc_cq_pollset(g_ctx.cq));+  grpc_server_setup_transport(g_ctx.server, transport, nullptr,+                              grpc_server_get_channel_args(g_ctx.server),+                              nullptr);+}++static void client_setup_transport(grpc_transport* transport) {+  grpc_core::ExecCtx exec_ctx;+  grpc_endpoint_add_to_pollset(g_ctx.ep->client,+                               grpc_cq_pollset(g_ctx.client_cq));+  grpc_arg authority_arg = grpc_channel_arg_string_create(+      const_cast<char*>(GRPC_ARG_DEFAULT_AUTHORITY),+      const_cast<char*>(""test-authority""));+  grpc_channel_args* args =+      grpc_channel_args_copy_and_add(nullptr, &authority_arg, 1);+  /* TODO (pjaikumar): use GRPC_CLIENT_CHANNEL instead of+   * GRPC_CLIENT_DIRECT_CHANNEL */+  g_ctx.client = grpc_channel_create(""socketpair-target"", args,+                                     GRPC_CLIENT_DIRECT_CHANNEL, transport);+  grpc_channel_args_destroy(args);+}++static void init_client() {+  grpc_core::ExecCtx exec_ctx;+  grpc_transport* transport;+  transport = grpc_create_chttp2_transport(nullptr, g_ctx.ep->client, true);+  client_setup_transport(transport);+  GPR_ASSERT(g_ctx.client);+  grpc_chttp2_transport_start_reading(transport, nullptr, nullptr);+}++static void init_server() {+  grpc_core::ExecCtx exec_ctx;+  grpc_transport* transport;+  GPR_ASSERT(!g_ctx.server);+  g_ctx.server = grpc_server_create(nullptr, nullptr);+  grpc_server_register_completion_queue(g_ctx.server, g_ctx.cq, nullptr);+  grpc_server_start(g_ctx.server);+  transport = grpc_create_chttp2_transport(nullptr, g_ctx.ep->server, false);+  server_setup_transport(transport);+  grpc_chttp2_transport_start_reading(transport, nullptr, nullptr);+}++static void test_init() {+  grpc_endpoint_pair* sfd =+      static_cast<grpc_endpoint_pair*>(gpr_malloc(sizeof(grpc_endpoint_pair)));+  memset(&g_ctx, 0, sizeof(g_ctx));+  g_ctx.ep = sfd;+  g_ctx.cq = grpc_completion_queue_create_for_next(nullptr);+  g_ctx.shutdown_cq = grpc_completion_queue_create_for_pluck(nullptr);+  g_ctx.bound_cq = grpc_completion_queue_create_for_next(nullptr);+  g_ctx.client_cq = grpc_completion_queue_create_for_next(nullptr);++  /* Create endpoints */+  *sfd = grpc_iomgr_create_endpoint_pair(""fixture"", nullptr);+  /* Create client, server and setup transport over endpoint pair */+  init_server();+  init_client();+}++static void drain_cq(grpc_completion_queue* cq) {+  grpc_event event;+  do {+    event = grpc_completion_queue_next(cq, grpc_timeout_seconds_to_deadline(1),+                                       nullptr);+  } while (event.type != GRPC_QUEUE_SHUTDOWN);+}++static void drain_and_destroy_cq(grpc_completion_queue* cq) {+  grpc_completion_queue_shutdown(cq);+  drain_cq(cq);+  grpc_completion_queue_destroy(cq);+}++static void shutdown_server() {+  if (!g_ctx.server) return;+  grpc_server_shutdown_and_notify(g_ctx.server, g_ctx.shutdown_cq, tag(1000));+  GPR_ASSERT(grpc_completion_queue_pluck(g_ctx.shutdown_cq, tag(1000),+                                         grpc_timeout_seconds_to_deadline(1),+                                         nullptr)+                 .type == GRPC_OP_COMPLETE);+  grpc_server_destroy(g_ctx.server);+  g_ctx.server = nullptr;+}++static void shutdown_client() {+  if (!g_ctx.client) return;+  grpc_channel_destroy(g_ctx.client);+  g_ctx.client = nullptr;+}++static void end_test() {+  shutdown_server();+  shutdown_client();++  drain_and_destroy_cq(g_ctx.cq);+  drain_and_destroy_cq(g_ctx.client_cq);+  drain_and_destroy_cq(g_ctx.bound_cq);+  grpc_completion_queue_destroy(g_ctx.shutdown_cq);+  gpr_free(g_ctx.ep);+}++typedef enum fd_type { CLIENT_FD, SERVER_FD } fd_type;++static const char* fd_type_str(fd_type fdtype) {+  if (fdtype == CLIENT_FD) {+    return ""client"";+  } else if (fdtype == SERVER_FD) {+    return ""server"";+  } else {+    gpr_log(GPR_ERROR, ""Unexpected fd_type %d"", fdtype);+    abort();+  }+}++static void _test_close_before_server_recv(fd_type fdtype) {+  grpc_core::ExecCtx exec_ctx;+  grpc_call* call;+  grpc_call* server_call;+  grpc_event event;+  grpc_slice request_payload_slice =+      grpc_slice_from_copied_string(""hello world"");+  grpc_slice response_payload_slice =+      grpc_slice_from_copied_string(""hello you"");+  grpc_byte_buffer* request_payload =+      grpc_raw_byte_buffer_create(&request_payload_slice, 1);+  grpc_byte_buffer* response_payload =+      grpc_raw_byte_buffer_create(&response_payload_slice, 1);+  gpr_log(GPR_INFO, ""Running test: test_close_%s_before_server_recv"",+          fd_type_str(fdtype));+  test_init();++  grpc_op ops[6];+  grpc_op* op;+  grpc_metadata_array initial_metadata_recv;+  grpc_metadata_array trailing_metadata_recv;+  grpc_metadata_array request_metadata_recv;+  grpc_byte_buffer* request_payload_recv = nullptr;+  grpc_byte_buffer* response_payload_recv = nullptr;+  grpc_call_details call_details;+  grpc_status_code status = GRPC_STATUS__DO_NOT_USE;+  grpc_call_error error;+  grpc_slice details;++  gpr_timespec deadline = grpc_timeout_seconds_to_deadline(1);+  call = grpc_channel_create_call(+      g_ctx.client, nullptr, GRPC_PROPAGATE_DEFAULTS, g_ctx.client_cq,+      grpc_slice_from_static_string(""/foo""), nullptr, deadline, nullptr);+  GPR_ASSERT(call);++  grpc_metadata_array_init(&initial_metadata_recv);+  grpc_metadata_array_init(&trailing_metadata_recv);+  grpc_metadata_array_init(&request_metadata_recv);+  grpc_call_details_init(&call_details);++  memset(ops, 0, sizeof(ops));+  op = ops;+  op->op = GRPC_OP_SEND_INITIAL_METADATA;+  op->data.send_initial_metadata.count = 0;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  op->op = GRPC_OP_SEND_MESSAGE;+  op->data.send_message.send_message = request_payload;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  op->op = GRPC_OP_SEND_CLOSE_FROM_CLIENT;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  op->op = GRPC_OP_RECV_INITIAL_METADATA;+  op->data.recv_initial_metadata.recv_initial_metadata = &initial_metadata_recv;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  op->op = GRPC_OP_RECV_MESSAGE;+  op->data.recv_message.recv_message = &response_payload_recv;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  op->op = GRPC_OP_RECV_STATUS_ON_CLIENT;+  op->data.recv_status_on_client.trailing_metadata = &trailing_metadata_recv;+  op->data.recv_status_on_client.status = &status;+  op->data.recv_status_on_client.status_details = &details;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  error = grpc_call_start_batch(call, ops, static_cast<size_t>(op - ops),+                                tag(1), nullptr);+  GPR_ASSERT(GRPC_CALL_OK == error);++  error = grpc_server_request_call(g_ctx.server, &server_call, &call_details,+                                   &request_metadata_recv, g_ctx.bound_cq,+                                   g_ctx.cq, tag(101));+  GPR_ASSERT(GRPC_CALL_OK == error);+  event = grpc_completion_queue_next(+      g_ctx.cq, grpc_timeout_milliseconds_to_deadline(100), nullptr);+  GPR_ASSERT(event.success == 1);+  GPR_ASSERT(event.tag == tag(101));+  GPR_ASSERT(event.type == GRPC_OP_COMPLETE);++  memset(ops, 0, sizeof(ops));+  op = ops;+  op->op = GRPC_OP_SEND_INITIAL_METADATA;+  op->data.send_initial_metadata.count = 0;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  op->op = GRPC_OP_RECV_MESSAGE;+  op->data.recv_message.recv_message = &request_payload_recv;+  op->flags = 0;+  op->reserved = nullptr;+  op++;++  grpc_endpoint_pair* sfd = g_ctx.ep;+  int fd;+  if (fdtype == SERVER_FD) {+    fd = sfd->server->vtable->get_fd(sfd->server);+  } else {+    GPR_ASSERT(fdtype == CLIENT_FD);+    fd = sfd->client->vtable->get_fd(sfd->client);+  }+  /* Connection is closed before the server receives the client's message. */+  close(fd);++  error = grpc_call_start_batch(server_call, ops, static_cast<size_t>(op - ops),+                                tag(102), nullptr);+  GPR_ASSERT(GRPC_CALL_OK == error);++  event = grpc_completion_queue_next(+      g_ctx.bound_cq, grpc_timeout_milliseconds_to_deadline(100), nullptr);++  /* Batch operation completes on the server side.+   * event.success will be true if the op completes successfully.+   * event.success will be false if the op completes with an error. This can+   * happen due to a race with closing the fd resulting in pending writes+   * failing due to stream closure.+   * */+  GPR_ASSERT(event.type == GRPC_OP_COMPLETE);+  GPR_ASSERT(event.tag == tag(102));++  event = grpc_completion_queue_next(+      g_ctx.client_cq, grpc_timeout_milliseconds_to_deadline(100), nullptr);+  /* When the client fd is closed, the server gets EPIPE.+   * When server fd is closed, server gets EBADF.+   * In both cases server sends GRPC_STATUS_UNAVALABLE to the client. However,+   * the client may not receive this grpc_status as it's socket is being closed.+   * If the client didn't get grpc_status from the server it will time out+   * waiting on the completion queue+   */+  if (event.type == GRPC_QUEUE_TIMEOUT) {","Talked with Muxi offline. When an fd is closed the server gets an error on write and it sends GRPC_STATUS_UNAVAILABLE to the client. The server side error looks like this:```{""created"":""@1549064622.947201486"",""description"":""FD Shutdown"",""file"":""src/core/lib/iomgr/lockfree_event.cc"",""file_line"":194,""referenced_errors"":[{""created"":""@1549064622.947194884"",""description"":""Delayed close due to in-progress write"",""file"":""src/core/ext/transport/chttp2/transport/chttp2_transport.cc"",""file_line"":587,""referenced_errors"":[{""created"":""@1549064622.947191634"",""description"":""Bad file descriptor"",""errno"":9,""fd"":6,""file"":""src/core/lib/iomgr/tcp_posix.cc"",""file_line"":912,""grpc_status"":14,""os_error"":""Bad file descriptor"",""syscall"":""sendmsg"",""target_address"":""socketpair-server""}]}]}```Since the fd is being closed, the client may or may not receive the server's response. That's why we have the `if` condition. The interesting thing here is that it looks like the client doing a read doesn't get notified that the socket has been closed.",OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/17643,253239494,2019-02-02T00:22:56Z,test/core/bad_connection/close_fd_test.cc,"@@ -0,0 +1,762 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ * close_fd_test tests the behavior of grpc core when the transport gets+ * disconnected.+ * The test creates an http2 transport over a socket pair and closes the+ * client or server file descriptor to simulate connection breakage while+ * an RPC call is in progress.+ *+ */+#include ""src/core/lib/iomgr/port.h""++// This test won't work except with posix sockets enabled+#ifdef GRPC_POSIX_SOCKET++#include ""test/core/util/test_config.h""++#include <stdio.h>+#include <string.h>+#include <unistd.h>++#include <grpc/byte_buffer.h>+#include <grpc/byte_buffer_reader.h>+#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/time.h>+#include ""src/core/ext/transport/chttp2/transport/chttp2_transport.h""+#include ""src/core/lib/gpr/env.h""+#include ""src/core/lib/iomgr/endpoint_pair.h""+#include ""src/core/lib/surface/channel.h""+#include ""src/core/lib/surface/completion_queue.h""+#include ""src/core/lib/surface/server.h""++static void* tag(intptr_t t) { return (void*)t; }++typedef struct test_ctx test_ctx;++struct test_ctx {+  /* completion queue for call notifications on the server */+  grpc_completion_queue* cq;+  /* completion queue registered to server for shutdown events */+  grpc_completion_queue* shutdown_cq;+  /* client's completion queue */+  grpc_completion_queue* client_cq;+  /* completion queue bound to call on the server */+  grpc_completion_queue* bound_cq;+  /* Server responds to client calls */+  grpc_server* server;+  /* Client calls are sent over the channel */+  grpc_channel* client;+  /* encapsulates client, server endpoints */+  grpc_endpoint_pair* ep;+};++static test_ctx g_ctx;++/* chttp2 transport that is immediately available (used for testing+   connected_channel without a client_channel */++static void server_setup_transport(grpc_transport* transport) {+  grpc_core::ExecCtx exec_ctx;+  grpc_endpoint_add_to_pollset(g_ctx.ep->server, grpc_cq_pollset(g_ctx.cq));+  grpc_server_setup_transport(g_ctx.server, transport, nullptr,+                              grpc_server_get_channel_args(g_ctx.server),+                              nullptr);+}++static void client_setup_transport(grpc_transport* transport) {+  grpc_core::ExecCtx exec_ctx;+  grpc_endpoint_add_to_pollset(g_ctx.ep->client,+                               grpc_cq_pollset(g_ctx.client_cq));+  grpc_arg authority_arg = grpc_channel_arg_string_create(+      const_cast<char*>(GRPC_ARG_DEFAULT_AUTHORITY),+      const_cast<char*>(""test-authority""));+  grpc_channel_args* args =+      grpc_channel_args_copy_and_add(nullptr, &authority_arg, 1);+  /* TODO (pjaikumar): use GRPC_CLIENT_CHANNEL instead of+   * GRPC_CLIENT_DIRECT_CHANNEL */+  g_ctx.client = grpc_channel_create(""socketpair-target"", args,+                                     GRPC_CLIENT_DIRECT_CHANNEL, transport);+  grpc_channel_args_destroy(args);+}++static void init_client() {+  grpc_core::ExecCtx exec_ctx;+  grpc_transport* transport;+  transport = grpc_create_chttp2_transport(nullptr, g_ctx.ep->client, true);+  client_setup_transport(transport);+  GPR_ASSERT(g_ctx.client);+  grpc_chttp2_transport_start_reading(transport, nullptr, nullptr);+}++static void init_server() {+  grpc_core::ExecCtx exec_ctx;+  grpc_transport* transport;+  GPR_ASSERT(!g_ctx.server);+  g_ctx.server = grpc_server_create(nullptr, nullptr);+  grpc_server_register_completion_queue(g_ctx.server, g_ctx.cq, nullptr);+  grpc_server_start(g_ctx.server);+  transport = grpc_create_chttp2_transport(nullptr, g_ctx.ep->server, false);+  server_setup_transport(transport);+  grpc_chttp2_transport_start_reading(transport, nullptr, nullptr);+}++static void test_init() {+  grpc_endpoint_pair* sfd =+      static_cast<grpc_endpoint_pair*>(gpr_malloc(sizeof(grpc_endpoint_pair)));+  memset(&g_ctx, 0, sizeof(g_ctx));+  g_ctx.ep = sfd;+  g_ctx.cq = grpc_completion_queue_create_for_next(nullptr);+  g_ctx.shutdown_cq = grpc_completion_queue_create_for_pluck(nullptr);+  g_ctx.bound_cq = grpc_completion_queue_create_for_next(nullptr);+  g_ctx.client_cq = grpc_completion_queue_create_for_next(nullptr);++  /* Create endpoints */+  *sfd = grpc_iomgr_create_endpoint_pair(""fixture"", nullptr);+  /* Create client, server and setup transport over endpoint pair */+  init_server();+  init_client();+}++static void drain_cq(grpc_completion_queue* cq) {+  grpc_event event;+  do {+    event = grpc_completion_queue_next(cq, grpc_timeout_seconds_to_deadline(1),+                                       nullptr);+  } while (event.type != GRPC_QUEUE_SHUTDOWN);+}++static void drain_and_destroy_cq(grpc_completion_queue* cq) {+  grpc_completion_queue_shutdown(cq);+  drain_cq(cq);+  grpc_completion_queue_destroy(cq);+}++static void shutdown_server() {+  if (!g_ctx.server) return;+  grpc_server_shutdown_and_notify(g_ctx.server, g_ctx.shutdown_cq, tag(1000));+  GPR_ASSERT(grpc_completion_queue_pluck(g_ctx.shutdown_cq, tag(1000),+                                         grpc_timeout_seconds_to_deadline(1),+                                         nullptr)+                 .type == GRPC_OP_COMPLETE);+  grpc_server_destroy(g_ctx.server);+  g_ctx.server = nullptr;+}++static void shutdown_client() {+  if (!g_ctx.client) return;+  grpc_channel_destroy(g_ctx.client);+  g_ctx.client = nullptr;+}++static void end_test() {+  shutdown_server();+  shutdown_client();++  drain_and_destroy_cq(g_ctx.cq);+  drain_and_destroy_cq(g_ctx.client_cq);+  drain_and_destroy_cq(g_ctx.bound_cq);+  grpc_completion_queue_destroy(g_ctx.shutdown_cq);+  gpr_free(g_ctx.ep);+}++typedef enum fd_type { CLIENT_FD, SERVER_FD } fd_type;++static const char* fd_type_str(fd_type fdtype) {+  if (fdtype == CLIENT_FD) {+    return ""client"";+  } else if (fdtype == SERVER_FD) {+    return ""server"";+  } else {+    gpr_log(GPR_ERROR, ""Unexpected fd_type %d"", fdtype);+    abort();+  }+}++static void _test_close_before_server_recv(fd_type fdtype) {+  grpc_core::ExecCtx exec_ctx;+  grpc_call* call;+  grpc_call* server_call;+  grpc_event event;+  grpc_slice request_payload_slice =+      grpc_slice_from_copied_string(""hello world"");+  grpc_slice response_payload_slice =+      grpc_slice_from_copied_string(""hello you"");+  grpc_byte_buffer* request_payload =+      grpc_raw_byte_buffer_create(&request_payload_slice, 1);+  grpc_byte_buffer* response_payload =+      grpc_raw_byte_buffer_create(&response_payload_slice, 1);+  gpr_log(GPR_INFO, ""Running test: test_close_%s_before_server_recv"",+          fd_type_str(fdtype));+  test_init();++  grpc_op ops[6];+  grpc_op* op;+  grpc_metadata_array initial_metadata_recv;+  grpc_metadata_array trailing_metadata_recv;+  grpc_metadata_array request_metadata_recv;+  grpc_byte_buffer* request_payload_recv = nullptr;+  grpc_byte_buffer* response_payload_recv = nullptr;+  grpc_call_details call_details;+  grpc_status_code status = GRPC_STATUS__DO_NOT_USE;+  grpc_call_error error;+  grpc_slice details;++  gpr_timespec deadline = grpc_timeout_seconds_to_deadline(1);+  call = grpc_channel_create_call(+      g_ctx.client, nullptr, GRPC_PROPAGATE_DEFAULTS, g_ctx.client_cq,+      grpc_slice_from_static_string(""/foo""), nullptr, deadline, nullptr);+  GPR_ASSERT(call);++  grpc_metadata_array_init(&initial_metadata_recv);+  grpc_metadata_array_init(&trailing_metadata_recv);+  grpc_metadata_array_init(&request_metadata_recv);+  grpc_call_details_init(&call_details);++  memset(ops, 0, sizeof(ops));+  op = ops;+  op->op = GRPC_OP_SEND_INITIAL_METADATA;+  op->data.send_initial_metadata.count = 0;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  op->op = GRPC_OP_SEND_MESSAGE;+  op->data.send_message.send_message = request_payload;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  op->op = GRPC_OP_SEND_CLOSE_FROM_CLIENT;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  op->op = GRPC_OP_RECV_INITIAL_METADATA;+  op->data.recv_initial_metadata.recv_initial_metadata = &initial_metadata_recv;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  op->op = GRPC_OP_RECV_MESSAGE;+  op->data.recv_message.recv_message = &response_payload_recv;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  op->op = GRPC_OP_RECV_STATUS_ON_CLIENT;+  op->data.recv_status_on_client.trailing_metadata = &trailing_metadata_recv;+  op->data.recv_status_on_client.status = &status;+  op->data.recv_status_on_client.status_details = &details;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  error = grpc_call_start_batch(call, ops, static_cast<size_t>(op - ops),+                                tag(1), nullptr);+  GPR_ASSERT(GRPC_CALL_OK == error);++  error = grpc_server_request_call(g_ctx.server, &server_call, &call_details,+                                   &request_metadata_recv, g_ctx.bound_cq,+                                   g_ctx.cq, tag(101));+  GPR_ASSERT(GRPC_CALL_OK == error);+  event = grpc_completion_queue_next(+      g_ctx.cq, grpc_timeout_milliseconds_to_deadline(100), nullptr);+  GPR_ASSERT(event.success == 1);+  GPR_ASSERT(event.tag == tag(101));+  GPR_ASSERT(event.type == GRPC_OP_COMPLETE);++  memset(ops, 0, sizeof(ops));+  op = ops;+  op->op = GRPC_OP_SEND_INITIAL_METADATA;+  op->data.send_initial_metadata.count = 0;+  op->flags = 0;+  op->reserved = nullptr;+  op++;+  op->op = GRPC_OP_RECV_MESSAGE;+  op->data.recv_message.recv_message = &request_payload_recv;+  op->flags = 0;+  op->reserved = nullptr;+  op++;++  grpc_endpoint_pair* sfd = g_ctx.ep;+  int fd;+  if (fdtype == SERVER_FD) {+    fd = sfd->server->vtable->get_fd(sfd->server);+  } else {+    GPR_ASSERT(fdtype == CLIENT_FD);+    fd = sfd->client->vtable->get_fd(sfd->client);+  }+  /* Connection is closed before the server receives the client's message. */+  close(fd);++  error = grpc_call_start_batch(server_call, ops, static_cast<size_t>(op - ops),+                                tag(102), nullptr);+  GPR_ASSERT(GRPC_CALL_OK == error);++  event = grpc_completion_queue_next(+      g_ctx.bound_cq, grpc_timeout_milliseconds_to_deadline(100), nullptr);++  /* Batch operation completes on the server side.+   * event.success will be true if the op completes successfully.+   * event.success will be false if the op completes with an error. This can+   * happen due to a race with closing the fd resulting in pending writes+   * failing due to stream closure.+   * */+  GPR_ASSERT(event.type == GRPC_OP_COMPLETE);+  GPR_ASSERT(event.tag == tag(102));++  event = grpc_completion_queue_next(+      g_ctx.client_cq, grpc_timeout_milliseconds_to_deadline(100), nullptr);+  /* When the client fd is closed, the server gets EPIPE.+   * When server fd is closed, server gets EBADF.+   * In both cases server sends GRPC_STATUS_UNAVALABLE to the client. However,+   * the client may not receive this grpc_status as it's socket is being closed.+   * If the client didn't get grpc_status from the server it will time out+   * waiting on the completion queue+   */+  if (event.type == GRPC_QUEUE_TIMEOUT) {",I have updated the comment to clarify why we have the `if` condition.,OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/17842,253714664,2019-02-05T01:54:36Z,test/cpp/end2end/time_change_test.cc,"@@ -0,0 +1,364 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/grpc.h>+#include <grpc/support/log.h>+#include <grpc/support/time.h>+#include <grpcpp/channel.h>+#include <grpcpp/client_context.h>+#include <grpcpp/create_channel.h>+#include <grpcpp/server.h>+#include <grpcpp/server_builder.h>+#include <grpcpp/server_context.h>++#include ""src/core/lib/iomgr/timer.h""+#include ""src/proto/grpc/testing/echo.grpc.pb.h""+#include ""test/core/util/port.h""+#include ""test/core/util/test_config.h""+#include ""test/cpp/end2end/test_service_impl.h""+#include ""test/cpp/util/subprocess.h""++#include <gtest/gtest.h>+#include <pthread.h>+#include <sys/time.h>+#include <thread>++using grpc::testing::EchoRequest;+using grpc::testing::EchoResponse;++static std::string g_root;++extern gpr_timespec (*gpr_now_impl)(gpr_clock_type clock_type);+gpr_timespec (*gpr_now_impl_orig)(gpr_clock_type clock_type) = gpr_now_impl;+static int g_time_shift_sec = 0;+static int g_time_shift_nsec = 0;+static gpr_timespec now_impl(gpr_clock_type clock) {+  auto ts = gpr_now_impl_orig(clock);+  // We only manipulate the realtime clock to simulate changes in wall-clock+  // time+  if (clock != GPR_CLOCK_REALTIME) {+    return ts;+  }+  GPR_ASSERT(ts.tv_nsec >= 0);+  GPR_ASSERT(ts.tv_nsec < GPR_NS_PER_SEC);+  ts.tv_sec += g_time_shift_sec;+  ts.tv_nsec += g_time_shift_nsec;+  if (ts.tv_nsec >= GPR_NS_PER_SEC) {+    ts.tv_nsec -= GPR_NS_PER_SEC;+    ++ts.tv_sec;+  } else if (ts.tv_nsec < 0) {+    --ts.tv_sec;+    ts.tv_nsec = GPR_NS_PER_SEC + ts.tv_nsec;+  }+  return ts;+}++// offset the value returned by gpr_now(GPR_CLOCK_REALTIME) by msecs+// milliseconds+static void set_now_offset(int msecs) {+  g_time_shift_sec = msecs / 1000;+  g_time_shift_nsec = (msecs % 1000) * 1e6;+}++// restore the original implementation of gpr_now()+static void reset_now_offset() {+  g_time_shift_sec = 0;+  g_time_shift_nsec = 0;+}++namespace grpc {+namespace testing {++namespace {++// gpr_now() is called with invalid clock_type+TEST(TimespecTest, GprNowInvalidClockType) {+  // initialize to some junk value+  gpr_clock_type invalid_clock_type = (gpr_clock_type)32641;+  EXPECT_DEATH(gpr_now(invalid_clock_type), "".*"");+}++// Add timespan with negative nanoseconds+TEST(TimespecTest, GprTimeAddNegativeNs) {+  gpr_timespec now = gpr_now(GPR_CLOCK_MONOTONIC);+  gpr_timespec bad_ts = {1, -1000, GPR_TIMESPAN};+  EXPECT_DEATH(gpr_time_add(now, bad_ts), "".*"");+}++// Subtract timespan with negative nanoseconds+TEST(TimespecTest, GprTimeSubNegativeNs) {+  // Nanoseconds must always be positive. Negative timestamps are represented by+  // (negative seconds, positive nanoseconds)+  gpr_timespec now = gpr_now(GPR_CLOCK_MONOTONIC);+  gpr_timespec bad_ts = {1, -1000, GPR_TIMESPAN};+  EXPECT_DEATH(gpr_time_sub(now, bad_ts), "".*"");+}++// Add negative milliseconds to gpr_timespec+TEST(TimespecTest, GrpcNegativeMillisToTimespec) {+  // -1500 milliseconds converts to timespec (-2 secs, 5 * 10^8 nsec)+  gpr_timespec ts = grpc_millis_to_timespec(-1500, GPR_CLOCK_MONOTONIC);+  GPR_ASSERT(ts.tv_sec = -2);+  GPR_ASSERT(ts.tv_nsec = 5e8);+  GPR_ASSERT(ts.clock_type == GPR_CLOCK_MONOTONIC);+}++class TimeChangeTest : public ::testing::Test {+ protected:+  TimeChangeTest() {}++  void SetUp() {+    auto port = grpc_pick_unused_port_or_die();+    std::ostringstream addr_stream;+    addr_stream << ""localhost:"" << port;+    auto addr = addr_stream.str();+    server_.reset(new SubProcess({+        g_root + ""/client_crash_test_server"",+        ""--address="" + addr,+    }));+    GPR_ASSERT(server_);+    channel_ = CreateChannel(addr, InsecureChannelCredentials());+    GPR_ASSERT(channel_);+    stub_ = grpc::testing::EchoTestService::NewStub(channel_);+  }++  void TearDown() {+    server_.reset();+    reset_now_offset();+  }++  std::unique_ptr<grpc::testing::EchoTestService::Stub> CreateStub() {+    return grpc::testing::EchoTestService::NewStub(channel_);+  }++  std::shared_ptr<Channel> GetChannel() { return channel_; }++  std::unique_ptr<SubProcess> server_;+  std::shared_ptr<Channel> channel_;+  std::unique_ptr<grpc::testing::EchoTestService::Stub> stub_;+};++// Wall-clock time jumps forward on client before bidi stream is created+TEST_F(TimeChangeTest, TimeJumpForwardBeforeStreamCreated) {+  EchoRequest request;+  EchoResponse response;+  ClientContext context;+  context.set_deadline(grpc_timeout_milliseconds_to_deadline(5000));+  context.AddMetadata(kServerResponseStreamsToSend, ""1"");++  auto channel = GetChannel();+  GPR_ASSERT(channel);+  EXPECT_TRUE(+      channel->WaitForConnected(grpc_timeout_milliseconds_to_deadline(5000)));+  auto stub = CreateStub();++  // time jumps forward by 20.123 seconds.+  set_now_offset(20123);",Suggest make this a constant and define it somewhere else. Same for similar places below.,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17932,254079119,2019-02-05T22:50:47Z,src/core/ext/filters/client_channel/health/health_check_client.cc,"@@ -21,13 +21,14 @@ #include <stdint.h> #include <stdio.h> +#include <grpcpp/impl/codegen/sync.h>",I don't think it's okay for code in core to depend on headers in the grpcpp directory.  We might need to duplicate this code in src/core/lib/gprpp.,OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/17932,254080980,2019-02-05T22:57:31Z,src/core/ext/filters/client_channel/health/health_check_client.cc,"@@ -21,13 +21,14 @@ #include <stdint.h> #include <stdio.h> +#include <grpcpp/impl/codegen/sync.h>","So @soheilhy and I were discussing this, and this is an interesting point. This looks unkosher, but it's no more unkosher than using std::unique_ptr as this is a headers-only library. There is no linkage involved.",
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17932,254081260,2019-02-05T22:58:35Z,src/core/ext/filters/client_channel/health/health_check_client.cc,"@@ -21,13 +21,14 @@ #include <stdint.h> #include <stdio.h> +#include <grpcpp/impl/codegen/sync.h>","Yes, that's a great point. @vjpai and I discussed this offline before I created the patch.The idea that I'm proposing is that , instead of duplicating the code, we can allow usage of header from ""<grpcpp/...>"" only when (a) they are header-only and (b) have no run-time stdlib dependency.Could you please let me know your thoughts? Does this sound reasonable to you?",
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/17957,254812843,2019-02-07T18:31:35Z,test/cpp/end2end/end2end_test.cc,"@@ -337,7 +338,11 @@ class End2endTest : public ::testing::TestWithParam<TestScenario> {     }   } -  void ResetStub() {+  bool ResetStub() {+    if (GetParam().callback_server && !GetParam().inproc &&",Any reason this can't be done in SetUp like the callback test suite ? When will this change in the middle of test run,
6148140,ncteisen,https://api.github.com/repos/grpc/grpc/pulls/17957,254813229,2019-02-07T18:32:39Z,test/cpp/end2end/end2end_test.cc,"@@ -337,7 +338,11 @@ class End2endTest : public ::testing::TestWithParam<TestScenario> {     }   } -  void ResetStub() {+  bool ResetStub() {",I don't know if this check belongs in ResetStub. Maybe a macro would be more readable?`MAYBE_SKIP_TEST_IF_NEEDED` with a comment about why we can only test TCP callback if there is a bg poller,
303201,JamesNK,https://api.github.com/repos/grpc/grpc/pulls/17972,254889903,2019-02-07T22:17:32Z,src/csharp/expand_dev_version.sh,"@@ -0,0 +1,25 @@+#!/bin/bash+# Copyright 2019 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++# Updates the GrpcSharpVersion property so that we can build+# dev nuget packages differentiated by timestamp.++set -e++cd ""$(dirname ""$0"")""++DEV_DATETIME_SUFFIX=$(date -u ""+%Y%m%d%H%M"")+# expand the -dev suffix to contain current timestamp+sed -ibak ""s/-dev<\/GrpcCsharpVersion>/-dev${DEV_DATETIME_SUFFIX}<\/GrpcCsharpVersion>/"" Grpc.Core/Version.csproj.include","That is a good point.This line updating the `Version.csproj.include` file on disk right? (sorry, not a Linux guy 😄). Is there a reason why you are doing this over passing `GrpcCsharpVersion` as a parameter to the build. MSBuild will then update the variable.",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/17939,254924679,2019-02-08T00:55:35Z,src/core/lib/gpr/sync_posix.cc,"@@ -105,10 +137,29 @@ void gpr_cv_init(gpr_cv* cv) { #if GPR_LINUX   GPR_ASSERT(pthread_condattr_setclock(&attr, CLOCK_MONOTONIC) == 0); #endif  // GPR_LINUX++#ifdef GRPC_ASAN_ENABLED+  GPR_ASSERT(pthread_cond_init(&cv->cond_var, &attr) == 0);+  cv->leak_checker = (int*)gpr_malloc(sizeof(*cv->leak_checker));+  GPR_ASSERT(cv->leak_checker != nullptr);+  /* Initial it with a magic number, make no sense, just use the memory.",This is similar to the above comment that I flagged. I have the same question here.,OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/17965,254937106,2019-02-08T02:10:49Z,test/cpp/microbenchmarks/bm_alarm.cc,"@@ -0,0 +1,64 @@+/*+ *+ * Copyright 2015 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++/* This benchmark exists to ensure that immediately-firing alarms are fast */",Great question. There's no baseline since we've never tested it before. I want this in here to prevent a regression in the future since I've just recommended it to an outside user on grpc-io as a way of injecting events into the CQ (which we knew already that other people were doing). The current speed on my Mac laptop was something like 311 ns so that's not a bad start IMO. (and I assume that it was faster in the actual test environment),
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17984,255209462,2019-02-08T19:33:42Z,src/core/lib/iomgr/exec_ctx.h,"@@ -80,10 +80,13 @@ namespace grpc_core {  *  CONVENTIONS:  *  - Instance of this must ALWAYS be constructed on the stack, never  *    heap allocated.- *  - Exactly one instance of ExecCtx must be created per thread. Instances must","I don't think we should remove this, since we want to eventually get back to a mode where this is true.  Instead, we should document the fact that we currently have violations of this but that we are going to work toward making those violations go away, and all new code should conform to this restriction to avoid making the problem worse.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/17984,255269659,2019-02-08T23:48:08Z,src/core/lib/iomgr/exec_ctx.h,"@@ -227,6 +230,48 @@ class ExecCtx {   ExecCtx* last_exec_ctx_ = Get(); }; +/** Application-callback execution context.+ *  A bag of data that collects information along a callstack.+ *  It is created on the stack at core entry points, and stored internally+ *  as a thread-local variable.+ *+ *  There are three key differences between this structure and ExecCtx:+ *    1. ApplicationCallbackExecCtx builds a list of application-level+ *       callbacks, but ExecCtx builds a list of internal callbacks to invoke.+ *    2. If more than one ApplicationCallbackExecCtx is created on the thread's","This is essentially ~~impossible~~inconvenient with no benefit since ApplicationCallbackExecCtx causes application code to run, which can re-enter core which would then need another ApplicationCallbackExecCtx. In practice because nothing ever gets enqueued on the next one, the maximum depth of this will only ever be 2, so there's no circumstance under which we can see the stack crashes that we used to see. Maintaining this invariant would require refactoring every ApplicationCallbackExecCtx entry point into a separate internal function that gets invoked in the code twice (similar to the few places where we do this with ExecCtx like https://github.com/grpc/grpc/blob/a64cb54de152017d6c3c968ec9c22a98c405a8ba/src/core/lib/slice/slice.cc#L71-L78 ), which either adds the overhead of a function call or (worse) gets inlined and blows up the cache footprint. This is feasible in cases like the linked one since the code being invoked really isn't all that much to inline, which is not the case for some of the uses of ApplicationCallbackExecCtx (or even ExecCtx as we consider moving to stage 2 of the TODO above).",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17948,255291508,2019-02-09T08:07:31Z,tools/internal_ci/helper_scripts/prepare_build_macos_rc,"@@ -48,6 +48,10 @@ set -ex  # cocoapods export LANG=en_US.UTF-8+# pre-fetch cocoapods master repo with HEAD only+mkdir -p ~/.cocoapods/repos+git clone --depth 1 https://github.com/CocoaPods/Specs.git ~/.cocoapods/repos/master","let's add `time` to see how long the clone takes. Btw, it this supposed to reduce the time needed for the next command ""pod repo update"" or is this for a subsequent step sometimes later in objc tests?",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17948,255291696,2019-02-09T08:15:06Z,tools/internal_ci/helper_scripts/prepare_build_macos_rc,"@@ -48,6 +48,10 @@ set -ex  # cocoapods export LANG=en_US.UTF-8+# pre-fetch cocoapods master repo with HEAD only","I don't quite understand the remark that it fetches with ""HEAD"" only - it's not clear from thecommand line that this is what's being done.I'm not an expert, but it sounds like you're wanting to do `--single-branch` to only fetch the master branch and you actually might be doing that, as --depth seems to imply `--single-branch` but without further investigation, that's probably not going to be obvious to someone who looks at this script.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17948,255292085,2019-02-09T08:31:46Z,tools/internal_ci/helper_scripts/prepare_build_macos_rc,"@@ -48,6 +48,10 @@ set -ex  # cocoapods export LANG=en_US.UTF-8+# pre-fetch cocoapods master repo with HEAD only+mkdir -p ~/.cocoapods/repos+git clone --depth 1 https://github.com/CocoaPods/Specs.git ~/.cocoapods/repos/master","From the comment on the PR is seems this is speeding up ObjC's `build_tests.sh` and not the `pod repo update` command. The speedup is great, but I'm confused here.From the logs it looks like the first thing ""pod repo update"" does is *Updating spec repo `master`Performing a deep fetch of the `master` specs repo to improve future performance* by running the command `/usr/local/bin/git -C /Users/kbuilder/.cocoapods/repos/master fetch origin --progress`, which seems to take 9 minutes.So it looks like that even when we first clone only what we need, the `pod repo update` command fetches everything anyway right after that.  In which case  it seems that the first command should basically no effect, in which case I don't understand how `build_tests.sh` could actually be getting sped up. Something doesn't add up here IMHO. ",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17948,255292265,2019-02-09T08:39:01Z,tools/internal_ci/helper_scripts/prepare_build_macos_rc,"@@ -48,6 +48,10 @@ set -ex  # cocoapods export LANG=en_US.UTF-8+# pre-fetch cocoapods master repo with HEAD only+mkdir -p ~/.cocoapods/repos+git clone --depth 1 https://github.com/CocoaPods/Specs.git ~/.cocoapods/repos/master",What's even more odd is that the 9min run of `pod repo update` seems to be triggered by the newly added git clone command - I looked at the tests on master and the usual duration of `pod repo update` is only a few seconds. And such regression is definitely not ok (partly because it would also slow down all other non-objc mac tests by 9mins).,
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/17948,255324312,2019-02-10T05:46:59Z,tools/internal_ci/helper_scripts/prepare_build_macos_rc,"@@ -48,6 +48,10 @@ set -ex  # cocoapods export LANG=en_US.UTF-8+# pre-fetch cocoapods master repo with HEAD only+mkdir -p ~/.cocoapods/repos+git clone --depth 1 https://github.com/CocoaPods/Specs.git ~/.cocoapods/repos/master+ time pod repo update  # needed by python","> it this is only required for ObjC tests (which would seem logical and the comment is a typo)Not necessarily true. Once we set up CI for C++ on iOS that needs this too. In summary, any library that runs on iOS, or on Mac and uses Cocoapods, will need this.",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/17948,255324892,2019-02-10T06:21:42Z,tools/internal_ci/helper_scripts/prepare_build_macos_rc,"@@ -48,6 +48,10 @@ set -ex  # cocoapods export LANG=en_US.UTF-8+# pre-fetch cocoapods master repo with HEAD only","> but it sounds like you're wanting to do `--single-branch` to only fetch the master branch and you actually might be doing that`-depth 1` only fetches one commit in the history tree. According to the [doc](https://git-scm.com/docs/git-clone), it indeed implies `--single-branch`, but that does not matter much in this case because the cocoapods master repo only has a single branch AFAIK.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17948,255326422,2019-02-10T07:44:01Z,tools/internal_ci/helper_scripts/prepare_build_macos_rc,"@@ -48,6 +48,10 @@ set -ex  # cocoapods export LANG=en_US.UTF-8+# pre-fetch cocoapods master repo with HEAD only+mkdir -p ~/.cocoapods/repos+git clone --depth 1 https://github.com/CocoaPods/Specs.git ~/.cocoapods/repos/master","We can remove that line, but I'd like to understand how this works. It seems that having a shallow vs deep clone influence what later happens in `pod install` (which seems to be also cloning or updating the repo under some circumstances) and it has big impact on the duration of build_tests.sh - and without understanding this, I don't think we can actually fix this well(in a way that would be effective and will continue working in the future and will be maintainable).",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17948,255326513,2019-02-10T07:47:47Z,tools/internal_ci/helper_scripts/prepare_build_macos_rc,"@@ -48,6 +48,10 @@ set -ex  # cocoapods export LANG=en_US.UTF-8+# pre-fetch cocoapods master repo with HEAD only","Ok, but perhaps the comment could be clearer. I'd like to also see a comment that explains how the particular type of clone we do later interacts with whatever happens in `pod install` (which also seems to clone/update under some circumstances) and how that affect the total runtime of the tests.",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/17948,255431622,2019-02-11T09:41:35Z,tools/internal_ci/helper_scripts/prepare_build_macos_rc,"@@ -48,6 +48,10 @@ set -ex  # cocoapods export LANG=en_US.UTF-8+# pre-fetch cocoapods master repo with HEAD only+mkdir -p ~/.cocoapods/repos+git clone --depth 1 https://github.com/CocoaPods/Specs.git ~/.cocoapods/repos/master","I have a vague memory that after a certain version of Cocoapods, `pod install` no longer pulls the master repo (and it now has an option `--repo-update` to force that). I did not find any reference to that right now though; will post it later. Assuming this is true, then this PR helps because:* In the old script, `pod repo update` acted like no-op because there is no repo exist in directory `~/.cocoapods/repos/master` (because it's a fresh mac image). The actual downloading of master repo is put off into `build_tests.sh` when it invokes `pod install` and took about 12 minutes to finish.* In the new script, `git clone --depth 1 ...` command fetches the latest commit of the master repo into `~/.cocoapods/repos/master`. Later in `build_tests.sh`, `pod install` command does not force a `pod repo update`, so it just uses the pods in the latest commit of master repo, saved the 12 minutes of download of full repo.",OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/18031,256188851,2019-02-12T23:20:40Z,tools/run_tests/python_utils/check_on_pr.py,"@@ -46,13 +49,28 @@ def _jwt_token(): def _access_token():     global _ACCESS_TOKEN_CACHE     if _ACCESS_TOKEN_CACHE == None or _ACCESS_TOKEN_CACHE['exp'] < time.time():-        resp = requests.post(-            url='https://api.github.com/app/installations/%s/access_tokens' %-            _INSTALLATION_ID,-            headers={-                'Authorization': 'Bearer %s' % _jwt_token().decode('ASCII'),-                'Accept': 'application/vnd.github.machine-man-preview+json',-            })+        for i in range(_ACCESS_TOKEN_FETCH_RETRIES):+            resp = requests.post(+                url='https://api.github.com/app/installations/%s/access_tokens'+                % _INSTALLATION_ID,+                headers={+                    'Authorization': 'Bearer %s' % _jwt_token().decode('ASCII'),+                    'Accept': 'application/vnd.github.machine-man-preview+json',+                })+            if resp.status_code == 200:+                break+            else:+                print(""Fetch access token from Github API failed:"")+                print(resp.json())","This could throw an exception if the response is not valid json, which is more likely in the case of a 5XX server error. Maybe `resp.text` instead?",
14166415,sanjaypujare,https://api.github.com/repos/grpc/grpc/pulls/18033,256261454,2019-02-13T06:26:53Z,gRPC-C++.podspec,"@@ -23,15 +23,15 @@ Pod::Spec.new do |s|   s.name     = 'gRPC-C++'   # TODO (mxyan): use version that match gRPC version when pod is stabilized-  # version = '1.19.0-dev'+  # version = '1.20.0-dev'   version = '0.0.8-dev'","Should this ""-dev"" suffix also be removed similar to core-version ?",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17872,256416627,2019-02-13T14:24:21Z,tools/internal_ci/macos/grpc_cfstream.cfg,"@@ -0,0 +1,18 @@+# Copyright 2019 gRPC authors.","""2019 The gRPC Authors"" + no dot.https://github.com/grpc/grpc/blob/7ef8fc826c52b0c4abeaead633d464197fc0bdf8/doc/python/sphinx/conf.py#L1",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18021,256444242,2019-02-13T15:23:41Z,src/core/ext/filters/client_channel/lb_policy/xds/xds.cc,"@@ -1178,23 +1139,23 @@ void XdsLb::ProcessChannelArgsLocked(const grpc_channel_args& args) {   args_ = grpc_channel_args_copy_and_add_and_remove(       &args, args_to_remove, GPR_ARRAY_SIZE(args_to_remove), &new_arg, 1);   // Construct args for balancer channel.-  grpc_channel_args* lb_channel_args =-      BuildBalancerChannelArgs(*addresses, response_generator_.get(), &args);-  // Create balancer channel if needed.-  if (lb_channel_ == nullptr) {-    char* uri_str;-    gpr_asprintf(&uri_str, ""fake:///%s"", server_name_);-    gpr_mu_lock(&lb_channel_mu_);-    lb_channel_ = grpc_client_channel_factory_create_channel(-        client_channel_factory(), uri_str,-        GRPC_CLIENT_CHANNEL_TYPE_LOAD_BALANCING, lb_channel_args);-    gpr_mu_unlock(&lb_channel_mu_);-    GPR_ASSERT(lb_channel_ != nullptr);-    gpr_free(uri_str);+  grpc_channel_args* lb_channel_args = BuildBalancerChannelArgs(&args);+  // Create or update balancer channel if needed.+  if (balancer_name_changed_) {","I think that if the balancer name changes, we should try to avoid having any period of time when we are not in contact with a balancer.  If we get the new name when the call to the old balancer is still functioning properly, then we should start up the new channel, start the balancer call on that new channel, and then wait for that call to be started and get its first serverlist before we swap out the old channel for the new channel.  However, if the call to the old balancer is not currently functioning properly (i.e., it is in retry delay), then we can swap them out immediately.",
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/17872,256536642,2019-02-13T18:48:54Z,test/cpp/end2end/cfstream_test.cc,"@@ -0,0 +1,275 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/core/lib/iomgr/port.h""++#include <algorithm>+#include <memory>+#include <mutex>+#include <random>+#include <thread>++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/atm.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>+#include <grpc/support/time.h>+#include <grpcpp/channel.h>+#include <grpcpp/client_context.h>+#include <grpcpp/create_channel.h>+#include <grpcpp/health_check_service_interface.h>+#include <grpcpp/server.h>+#include <grpcpp/server_builder.h>+#include <gtest/gtest.h>++#include ""src/core/lib/backoff/backoff.h""+#include ""src/core/lib/gpr/env.h""++#include ""src/proto/grpc/testing/echo.grpc.pb.h""+#include ""test/core/util/port.h""+#include ""test/core/util/test_config.h""+#include ""test/cpp/end2end/test_service_impl.h""++#ifdef GRPC_CFSTREAM+using grpc::testing::EchoRequest;+using grpc::testing::EchoResponse;+using std::chrono::system_clock;++namespace grpc {+namespace testing {+namespace {++class CFStreamTest : public ::testing::Test {+ protected:+  CFStreamTest()+      : server_host_(""grpctest""),+        interface_(""lo0""),+        ipv4_address_(""10.0.0.1""),+        netmask_(""/32""),+        kRequestMessage_(""🖖"") {}","It's the[ Vulcan salute](https://en.wikipedia.org/wiki/Vulcan_salute) emoji :smile:This test is a modified version of `test/cpp/end2end/client_lb_end2end_test.cc` which has this string:```kRequestMessage_(""Live long and prosper.""),```",
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17939,256590529,2019-02-13T21:11:44Z,include/grpc/impl/codegen/sync_posix.h,"@@ -25,8 +25,26 @@  #include <pthread.h> +#ifdef GRPC_ASAN_ENABLED+/* The member |leak_checker| is used to check whether there is a memory leak","Instead of changing the structure and all the methods due for ASAN and non-ASAN builds, I would try using  `__lsan_register_root_region()` and `__lsan_unregister_root_region()` first:https://github.com/llvm-mirror/compiler-rt/blob/master/include/sanitizer/lsan_interface.h#L29-L41Basically, we would need to define macros for this:```#if ASAN_ENABLED#define LSAN_REGISTER_ROOT_REGION(x, s) __lsan_register_root_region(x, s)#define LSAN_UNREGISTER_ROOT_REGION(x, s) __lsan_unregister_root_region(x, s)#else #define LSAN_REGISTER_ROOT_REGION(x, s)#define LSAN_UNREGISTER_ROOT_REGION(x, s)#endif```I believe this should work. If that didn't pan out, using the current approach would be fine.",OK
980728,cxxtao,https://api.github.com/repos/grpc/grpc/pulls/17939,256672206,2019-02-14T02:39:01Z,include/grpc/impl/codegen/sync_posix.h,"@@ -25,8 +25,26 @@  #include <pthread.h> +#ifdef GRPC_ASAN_ENABLED+/* The member |leak_checker| is used to check whether there is a memory leak","@soheilhy I found there's a [leak_checker](https://github.com/abseil/abseil-cpp/blob/cc4bed2d74f7c8717e31f9579214ab52a9c9c610/absl/debugging/leak_check.cc#L26) has wrapped the LSAN interfaces under the MACRO `LEAK_SANITIZER`. I'm a little confused that these test codes are written under the MACRO `GRPC_ASAN_ENABLED`, should we move the codes to LSAN region?",
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17939,256866643,2019-02-14T14:55:56Z,src/core/lib/gpr/sync_posix.cc,"@@ -74,53 +72,32 @@ gpr_atm gpr_counter_atm_add = 0; #endif  void gpr_mu_init(gpr_mu* mu) {-#ifdef GRPC_ASAN_ENABLED-  GPR_ASSERT(pthread_mutex_init(&mu->mutex, nullptr) == 0);-  mu->leak_checker = (int*)gpr_malloc(sizeof(*mu->leak_checker));-  GPR_ASSERT(mu->leak_checker != nullptr);-#else   GPR_ASSERT(pthread_mutex_init(mu, nullptr) == 0);-#endif+  LSAN_REGISTER_ROOT_REGION(mu, 1); }  void gpr_mu_destroy(gpr_mu* mu) {-#ifdef GRPC_ASAN_ENABLED-  GPR_ASSERT(pthread_mutex_destroy(&mu->mutex) == 0);-  gpr_free(mu->leak_checker);-#else   GPR_ASSERT(pthread_mutex_destroy(mu) == 0);-#endif+  //LSAN_UNREGISTER_ROOT_REGION(mu, 1);","why is this commented? did you see test failures?similarly this probably should be `REGION(mu, sizeof(*mu))`",OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/17939,256866834,2019-02-14T14:56:21Z,src/core/lib/gpr/sync_posix.cc,"@@ -133,23 +110,13 @@ void gpr_cv_init(gpr_cv* cv) { #if GPR_LINUX   GPR_ASSERT(pthread_condattr_setclock(&attr, CLOCK_MONOTONIC) == 0); #endif  // GPR_LINUX--#ifdef GRPC_ASAN_ENABLED-  GPR_ASSERT(pthread_cond_init(&cv->cond_var, &attr) == 0);-  cv->leak_checker = (int*)gpr_malloc(sizeof(*cv->leak_checker));-  GPR_ASSERT(cv->leak_checker != nullptr);-#else   GPR_ASSERT(pthread_cond_init(cv, &attr) == 0);-#endif+  LSAN_REGISTER_ROOT_REGION(cv, 1);","similarly please use sizeof(*cv) if possible, here and below",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/17979,256940589,2019-02-14T17:47:26Z,src/core/tsi/ssl_transport_security.h,"@@ -178,6 +196,17 @@ void tsi_ssl_client_handshaker_factory_unref( typedef struct tsi_ssl_server_handshaker_factory     tsi_ssl_server_handshaker_factory; +/* Creates a TLS server TSI handshaker.+  - options: TLS credential options instance.+  - factory: address of server handshaker factory to be created.+  - handshaker: address of the handshaker pointer to be created.+  This method returns TSI_OK on success or TSI_INVALID_PARAMETER in the case+  where a parameter is invalid. Note that some fields of handshaker will be+  populated once credential reload is finished. */+tsi_result tls_tsi_server_handshaker_create(+    const grpc_tls_credentials_options* options,+    tsi_ssl_server_handshaker_factory** factory, tsi_handshaker** handshaker);","This API is confusing because, in some cases, factory object is created during this call, whereas in other cases, the factory object is reused. For example, if caller passes a factory object, this function inside may destroy the factory and replace a new one. Same comment on the client side.I prefer to have a separate create functions. tsi_create_tls_server_handshaker_factory and tsi_tls_server_handshaker_create to be explicit. The credential reload shall be done at spiffe security connector. Keep SSL TSI simple. This would be similar to current credential logic in ssl security connector.The idea is:- When you create security connector, you try to create handshaker factory. It may not be possible, if there is no initial key material.- Every time add handshaker is called, you check credential reload and see if there are new credentials. If so, re-create handshaker factory.- Then you create handshaker from handshaker factory inside add handshaker.",OK
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/17979,256972873,2019-02-14T19:14:29Z,src/core/tsi/ssl_transport_security.h,"@@ -165,6 +167,22 @@ tsi_result tsi_ssl_client_handshaker_factory_create_handshaker(     tsi_ssl_client_handshaker_factory* self, const char* server_name_indication,     tsi_handshaker** handshaker); +/* Creates a TLS client TSI handshaker.+  - server_name_indication indicates the name of the server the client is+    trying to connect to which will be relayed to the server using the SNI+    extension.+  - session_cache: SSL session cache for sessions resumption.+  - options: TLS credential options instance.+  - factory: address of client handshaker factory to be created.+  - handshaker: address of the handshaker pointer to be created.+  This method returns TSI_OK on success or TSI_INVALID_PARAMETER in the case+  where a parameter is invalid. Note that some fields of handshaker will be+  populated once credential reload is finished. */+tsi_result tls_tsi_client_handshaker_create(+    const char* server_name_indication, tsi_ssl_session_cache* session_cache,+    const grpc_tls_credentials_options* options,","Sorry about SNI. I did not look carefully.TSI implementation supposes to be self-contained and parameter can be configurable by different caller of TSI. For example, envoy or other callers of TSI may have different set of cipher suites requirements. If TSI inside calls grpc_get_ssl_cipher_suites(), that means other users of TSI will be implicitly change cipher suites when gRPC changes cipher suites.",
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/18062,256973710,2019-02-14T19:16:58Z,test/core/tsi/ssl_transport_security_test.cc,"@@ -727,9 +727,18 @@ void test_tsi_ssl_server_handshaker_factory_refcounting() {   cert_pair.private_key =       load_file(SSL_TSI_TEST_CREDENTIALS_DIR, ""server0.key""); -  GPR_ASSERT(tsi_create_ssl_server_handshaker_factory(-                 &cert_pair, 1, cert_chain, 0, nullptr, nullptr, 0,-                 &server_handshaker_factory) == TSI_OK);+  tsi_ssl_server_handshaker_options options;+  memset(&options, 0, sizeof(options));","similarly, I this this memset would be unnecessary if you add 0 initialization to the definition of this struct.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18070,257189726,2019-02-15T10:54:07Z,tools/dockerfile/interoptest/grpc_interop_aspnetcore/build_interop.sh,"@@ -0,0 +1,29 @@+#!/bin/bash+# Copyright 2017 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+#+# Builds Grpc.AspNetCore.Server interop server in a base image.+set -e++mkdir -p /var/local/git+git clone /var/local/jenkins/grpc-dotnet /var/local/git/grpc-dotnet++# copy service account keys if available+cp -r /var/local/jenkins/service_account $HOME || true++cd /var/local/git/grpc-dotnet+./build/get-grpc.sh++cd testassets/InteropTestsWebsite+dotnet build --configuration Debug","Currently other C# interop clients and servers are also built in dbg, so I think I will stick with that for consistency https://github.com/grpc/grpc/blob/aa207933cb5f62b4726bbd52bd109f9e875a8ec0/templates/tools/dockerfile/csharp_build_interop.sh.include#L32.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18070,257190409,2019-02-15T10:55:58Z,tools/run_tests/run_interop_tests.py,"@@ -173,6 +174,36 @@ def __str__(self):         return 'csharpcoreclr'  +class AspNetCoreLanguage:++    def __init__(self):+        self.server_cwd = '../grpc-dotnet/testassets/InteropTestsWebsite/bin/Debug/netcoreapp3.0'+        self.safename = str(self)++    def cloud_to_prod_env(self):+        return {}++    def client_cmd(self, args):+        # client not supported+        return ['dotnet', 'exec', 'InteropClient.cll'] + args",I will replace with something that actually fails - silently passing unimplemented test cases are bad.,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18039,257191823,2019-02-15T11:00:28Z,src/csharp/unitypackage/unitypackage_skeleton/Plugins/Grpc.Core/runtimes/grpc_csharp_ext_dummy_stubs.c,"@@ -0,0 +1,116 @@++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++// When building for Unity Android with il2cpp backend, Unity tries to link+// the __Internal PInvoke definitions (which are required by iOS) even though+// the .so/.dll will be actually used. This file provides dummy stubs to+// make il2cpp happy.+// See https://github.com/grpc/grpc/issues/16012++void grpcsharp_init() {}","In general it is, but I didn't want do add a dependency on grpc libraries in order to log and abort in a portable way (this might end up in the static dummy library linking grpc). I'll give it a thought and if I come up with some reasonable way to abort, I'll do it.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17983,257279846,2019-02-15T15:32:28Z,src/csharp/README.md,"@@ -17,16 +17,16 @@ PREREQUISITES When using gRPC C# under .NET Core you only need to [install .NET Core](https://www.microsoft.com/net/core).  In addition to that, you can also use gRPC C# with these runtimes / IDEs-- Windows: .NET Framework 4.5+, Visual Studio 2013, 2015, 2017, Visual Studio Code-- Linux: Mono 4+, Visual Studio Code, MonoDevelop 5.9+ -- Mac OS X: Mono 4+, Visual Studio Code, Xamarin Studio 5.9++- Windows: .NET Framework 4.5+, Visual Studio 2013, 2015, 2017, Visual Studio Code, JetBrains Rider","I'm hesitant if we should add JetBrains rider to the list as we never tested with it nor do we ""officially"" support it.",
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/16513,257432381,2019-02-16T00:25:38Z,src/python/grpcio_tests/tests/fork/methods.py,"@@ -213,54 +218,59 @@ def _close_channel_before_fork(channel, args):      def child_target():         new_channel.close()-        child_channel = _channel(args)-        child_stub = test_pb2_grpc.TestServiceStub(child_channel)-        _blocking_unary(child_stub)-        child_channel.close()+        with _channel(args) as child_channel:+            child_stub = test_pb2_grpc.TestServiceStub(child_channel)+            _blocking_unary(child_stub)      stub = test_pb2_grpc.TestServiceStub(channel)     _blocking_unary(stub)     channel.close() -    new_channel = _channel(args)-    new_stub = test_pb2_grpc.TestServiceStub(new_channel)-    child_process = _ChildProcess(child_target)-    child_process.start()-    _blocking_unary(new_stub)-    child_process.finish()+    with _channel(args) as new_channel:+        new_stub = test_pb2_grpc.TestServiceStub(new_channel)+        child_process = _ChildProcess(child_target)+        child_process.start()+        _blocking_unary(new_stub)+        child_process.finish()   def _connectivity_watch(channel, args):      def child_target(): +        child_channel_ready_event = threading.Event()+         def child_connectivity_callback(state):-            child_states.append(state)+            if state is grpc.ChannelConnectivity.READY:","Nit: Seems like there's some parallelism in how state changes are gathered in the child and in the parent that could be factored out.Edit: I'm noticing now that there's actually asymmetry here. `child_connectivity_callback` never records the new state. In fact, `child_states` is initialized but never used.",OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/16513,257433491,2019-02-16T00:33:46Z,src/python/grpcio_tests/tests/fork/methods.py,"@@ -130,7 +134,9 @@ def start(self):         self._process.start()      def finish(self):-        self._process.join()+        self._process.join(timeout=_CHILD_FINISH_TIMEOUT_S)+        if self._process.is_alive():+            raise ValueError('Child process did not terminate')",[`ValueError` is meant for invalid input.](https://docs.python.org/2/library/exceptions.html#exceptions.ValueError) I'd recommend subclassing [`RuntimeError`](https://docs.python.org/2/library/exceptions.html#exceptions.RuntimeError).,OK
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/16513,257435470,2019-02-16T00:51:20Z,src/python/grpcio_tests/tests/fork/_fork_interop_test.py,"@@ -0,0 +1,152 @@+# Copyright 2019 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Client-side fork interop tests as a unit test.""""""++import six+import subprocess+import sys+import threading+import unittest+from grpc._cython import cygrpc+from tests.fork import methods++# New instance of multiprocessing.Process using fork without exec can and will+# hang if the Python process has any other threads running. This includes the+# additional thread spawned by our _runner.py class. So in order to test our+# compatibility with multiprocessing, we first fork+exec a new process to ensure+# we don't have any conflicting background threads.+_CLIENT_FORK_SCRIPT_TEMPLATE = """"""if True:+    import os+    import sys+    from grpc._cython import cygrpc+    from tests.fork import methods++    cygrpc._GRPC_ENABLE_FORK_SUPPORT = True+    os.environ['GRPC_POLL_STRATEGY'] = 'epoll1'+    methods.TestCase.%s.run_test({+      'server_host': 'localhost',+      'server_port': %d,+      'use_tls': False+    })+""""""+_SUBPROCESS_TIMEOUT_S = 30+++@unittest.skipUnless(+    sys.platform.startswith(""linux""),+    ""not supported on windows, and fork+exec networking blocked on mac"")+@unittest.skipUnless(six.PY2, ""https://github.com/grpc/grpc/issues/18075"")+class ForkInteropTest(unittest.TestCase):++    def setUp(self):+        start_server_script = """"""if True:+            import sys+            import time++            import grpc+            from src.proto.grpc.testing import test_pb2_grpc+            from tests.interop import methods as interop_methods+            from tests.unit import test_common++            server = test_common.test_server()+            test_pb2_grpc.add_TestServiceServicer_to_server(+                interop_methods.TestService(), server)+            port = server.add_insecure_port('[::]:0')+            server.start()+            print(port)+            sys.stdout.flush()+            while True:+                time.sleep(1)+        """"""+        self._server_process = subprocess.Popen(+            [sys.executable, '-c', start_server_script],+            stdout=subprocess.PIPE,+            stderr=subprocess.PIPE)",This is a class constructor,
2030323,JunTaoLuo,https://api.github.com/repos/grpc/grpc/pulls/18086,257482865,2019-02-17T00:25:53Z,src/csharp/Grpc.Core.Api/ServerCallContext.cs,"@@ -113,6 +114,12 @@ public WriteOptions WriteOptions         /// </summary>         public AuthContext AuthContext => AuthContextCore; +        /// <summary>+        /// Gets a dictionary that can be used by the various interceptors and handlers of this+        /// call to store arbitrary state.+        /// </summary>+        public IDictionary<object, object> UserSate => UserStateCore;","The only reason we had the Property and PropertyCore pattern was that we didn't want there to be a breaking change when we created an abstract base class. However, given that this is a new property I don't think this is necessary, just make it a virtual with a default implementation.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17051,257753534,2019-02-18T16:07:55Z,src/csharp/Grpc.Core/Channel.cs,"@@ -252,6 +260,7 @@ public async Task ShutdownAsync()             lock (myLock)             {                 handle.Dispose();+                cleanUpCredentials?.Invoke();",this is not the right time to cleanup the native callback.verify_peer_destruct  from verify_peer_options should provide the signal to free the gchandle.refer to https://github.com/grpc/grpc/blob/b3b5d634231ce2c5c0ec0c557b6844e1a43b482e/src/csharp/Grpc.Core/Internal/NativeMetadataCredentialsPlugin.cs#L57  for an example.IMHO there should be no changes in Channel.cs at all necessary.,
44597042,tlg-bf,https://api.github.com/repos/grpc/grpc/pulls/17051,257894475,2019-02-19T05:28:46Z,src/csharp/Grpc.Core/Channel.cs,"@@ -84,6 +85,13 @@ public Channel(string target, ChannelCredentials credentials, IEnumerable<Channe                     this.handle = ChannelSafeHandle.CreateInsecure(target, nativeChannelArgs);                 }             }++            if (credentials.HasGcHandle)+            {+                var gcHandle = credentials.GCHandle;+                cleanUpCredentials = () => gcHandle.Free();",No longer relevant on latest verison.,
44597042,tlg-bf,https://api.github.com/repos/grpc/grpc/pulls/17051,257903246,2019-02-19T06:28:56Z,src/csharp/Grpc.Core/Channel.cs,"@@ -252,6 +260,7 @@ public async Task ShutdownAsync()             lock (myLock)             {                 handle.Dispose();+                cleanUpCredentials?.Invoke();","Actually realized that I also needed a gcHandle for the destruct callback. But looking at it, I must say I am having trouble to understand how things work, even for the example your provided.In `NativeMetadataCredentialsPlugin`, the `NativeMetadataInterceptorHandler` references `gcHandle` which is a field in the class. But if an instance of the class gets GC'd, wouldn't it be collected as well? Or does it mean that the entire object will not be collected until the `GCHandle` is realeased?I tried to look for documentation but could not find much, I just want to make sure that my implementation makes sense.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18078,258253659,2019-02-19T22:16:07Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc,"@@ -1570,23 +1635,89 @@ grpc_channel_args* GrpcLb::CreateRoundRobinPolicyArgsLocked() {   return args; } -void GrpcLb::CreateOrUpdateRoundRobinPolicyLocked() {+void GrpcLb::CreateChildPolicyLocked(const char* name,+                                     grpc_channel_args* args) {+  OrphanablePtr<LoadBalancingPolicy>& lb_policy =+      child_policy_ == nullptr ? child_policy_ : pending_child_policy_;+  Helper* helper = New<Helper>(Ref());+  LoadBalancingPolicy::Args lb_policy_args;+  lb_policy_args.combiner = combiner();+  lb_policy_args.args = args;+  lb_policy_args.channel_control_helper =+      UniquePtr<ChannelControlHelper>(helper);+  lb_policy = LoadBalancingPolicyRegistry::CreateLoadBalancingPolicy(+      name, child_policy_config_, std::move(lb_policy_args));+  if (GPR_UNLIKELY(lb_policy == nullptr)) {+    gpr_log(GPR_ERROR, ""[grpclb %p] Failure creating child policy %s"", this,+            name);+    return;+  }+  helper->set_child(lb_policy.get());+  if (grpc_lb_glb_trace.enabled()) {+    gpr_log(GPR_INFO, ""[grpclb %p] Created new child policy %s (%p)"", this,+            name, lb_policy.get());+  }+  // Add the gRPC LB's interested_parties pollset_set to that of the newly+  // created child policy. This will make the child policy progress upon+  // activity on gRPC LB, which in turn is tied to the application's call.+  grpc_pollset_set_add_pollset_set(lb_policy->interested_parties(),+                                   interested_parties());+  lb_policy->ExitIdleLocked();+}++void GrpcLb::CreateOrUpdateChildPolicyLocked() {   if (shutting_down_) return;-  grpc_channel_args* args = CreateRoundRobinPolicyArgsLocked();+  grpc_channel_args* args = CreateChildPolicyArgsLocked();   GPR_ASSERT(args != nullptr);-  if (rr_policy_ != nullptr) {+  // There are several cases here:+  // 1. If we do not yet have any child policy, we create one and store+  //    it in child_policy_.+  // 2. If we have a child policy but no pending child policy, then:+  //    a. If the child policy's name equals child_policy_name, then we+  //       update the existing child policy.+  //    b. If the child policy's name does not equal child_policy_name,+  //       we create a new policy.  The policy will be stored in+  //       pending_child_policy_ and will later be swapped into+  //       child_policy_ by the helper when the new child transitions+  //       into state READY.+  // 3. If we have both a child policy and a pending child policy (i.e.,+  //    we created a new policy for a previous update that has not yet+  //    been moved from pending_child_policy_ to child_policy_), then:+  //    a. If the pending child policy's name equals child_policy_name,","I thought about that, but that case should be sufficiently rare that I didn't feel the need to optimize it.  I think the only way that could happen is if we change from the service config from LB policy A to LB policy B and then very quickly (before the client can complete the switch from A to B) switch back to A.  In that situation, I think it's fine to treat it like a new update and create a new policy.Keep in mind that in the common case, due to the subchannel pool, most child policies will switch almost instantaneously, because if there's a single READY subchannel under the old policy, the new policy will transition to state READY right away.  The only cases where that would not be true would be if there were no READY subchannels when the LB policy switches or if the list of subchannels changes to a completely disjoint set in the same update that gives us the new service config.  We could optimize this slightly by immediately swapping out the LB policy if the old policy is not currently in state READY, but again, it's not obvious that it's worth the complexity to do that right now.  We can always add it later if it turns out to be important.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/18078,258258583,2019-02-19T22:30:45Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc,"@@ -1570,23 +1635,89 @@ grpc_channel_args* GrpcLb::CreateRoundRobinPolicyArgsLocked() {   return args; } -void GrpcLb::CreateOrUpdateRoundRobinPolicyLocked() {+void GrpcLb::CreateChildPolicyLocked(const char* name,+                                     grpc_channel_args* args) {+  OrphanablePtr<LoadBalancingPolicy>& lb_policy =+      child_policy_ == nullptr ? child_policy_ : pending_child_policy_;+  Helper* helper = New<Helper>(Ref());+  LoadBalancingPolicy::Args lb_policy_args;+  lb_policy_args.combiner = combiner();+  lb_policy_args.args = args;+  lb_policy_args.channel_control_helper =+      UniquePtr<ChannelControlHelper>(helper);+  lb_policy = LoadBalancingPolicyRegistry::CreateLoadBalancingPolicy(+      name, child_policy_config_, std::move(lb_policy_args));+  if (GPR_UNLIKELY(lb_policy == nullptr)) {+    gpr_log(GPR_ERROR, ""[grpclb %p] Failure creating child policy %s"", this,+            name);+    return;+  }+  helper->set_child(lb_policy.get());+  if (grpc_lb_glb_trace.enabled()) {+    gpr_log(GPR_INFO, ""[grpclb %p] Created new child policy %s (%p)"", this,+            name, lb_policy.get());+  }+  // Add the gRPC LB's interested_parties pollset_set to that of the newly+  // created child policy. This will make the child policy progress upon+  // activity on gRPC LB, which in turn is tied to the application's call.+  grpc_pollset_set_add_pollset_set(lb_policy->interested_parties(),+                                   interested_parties());+  lb_policy->ExitIdleLocked();+}++void GrpcLb::CreateOrUpdateChildPolicyLocked() {   if (shutting_down_) return;-  grpc_channel_args* args = CreateRoundRobinPolicyArgsLocked();+  grpc_channel_args* args = CreateChildPolicyArgsLocked();   GPR_ASSERT(args != nullptr);-  if (rr_policy_ != nullptr) {+  // There are several cases here:+  // 1. If we do not yet have any child policy, we create one and store+  //    it in child_policy_.+  // 2. If we have a child policy but no pending child policy, then:+  //    a. If the child policy's name equals child_policy_name, then we+  //       update the existing child policy.+  //    b. If the child policy's name does not equal child_policy_name,+  //       we create a new policy.  The policy will be stored in+  //       pending_child_policy_ and will later be swapped into+  //       child_policy_ by the helper when the new child transitions+  //       into state READY.+  // 3. If we have both a child policy and a pending child policy (i.e.,+  //    we created a new policy for a previous update that has not yet+  //    been moved from pending_child_policy_ to child_policy_), then:+  //    a. If the pending child policy's name equals child_policy_name,","It's true that A->B->A update is rare, but I think the code won't be a lot more complex with that optimization. Well, I GUESS so, given the new branch discussion above. I will try implementing it concisely.",OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/18095,258274536,2019-02-19T23:25:22Z,src/python/grpcio_health_checking/grpc_health/v1/health.py,"@@ -59,20 +60,35 @@ def close(self):             self._condition.notify()  +def _watcher_to_on_next_adapter(watcher):++    def on_next(response):+        if response is None:+            watcher.close()+        else:+            watcher.add(response)++    return on_next++ class HealthServicer(_health_pb2_grpc.HealthServicer):     """"""Servicer handling RPCs for service statuses."""""" -    def __init__(self):+    def __init__(self,+                 experimental_non_blocking=True,+                 experimental_thread_pool=None):         self._lock = threading.RLock()         self._server_status = {}-        self._watchers = {}+        self._on_next_callbacks = {}+        self.Watch.__func__.experimental_non_blocking = experimental_non_blocking+        self.Watch.__func__.experimental_thread_pool = experimental_thread_pool","Since this is just intended to be an internal API, I definitely agree with @ericgribkoff .And even if it were public, I think you'd have lifecycle issues. Consider what would happen if you tried to turn this line into a decorator on `Watch`. It would maybe look something like this:```pythonclass HealthServicer(_health_pb2_grpc.HealthServicer):    def __init__(self, experimental_thread_pool, ...):        ...    @experimental_non_blocking    @experimental_thread_pool(thread_pool)    def Watch(self, ...):        ...```The decorator is evaluated at module load time. At that point, we don't have access to the thread pool. It won't be passed to us until we instantiate a specific `HealthServicer`. Seems like a non-starter.",
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/18095,258283803,2019-02-20T00:05:43Z,src/python/grpcio_health_checking/grpc_health/v1/health.py,"@@ -85,19 +101,28 @@ def Check(self, request, context):             else:                 return _health_pb2.HealthCheckResponse(status=status) -    def Watch(self, request, context):+    # pylint: disable=arguments-differ+    def Watch(self, request, context, on_next_callback=None):+        blocking_watcher = None+        if on_next_callback is None:+            # The server does not support the experimental_non_blocking+            # parameter. For backwards compatibility, return a blocking response+            # generator.+            blocking_watcher = _Watcher()+            on_next_callback = _watcher_to_on_next_callback_adapter(+                blocking_watcher)         service = request.service         with self._lock:             status = self._server_status.get(service)             if status is None:                 status = _health_pb2.HealthCheckResponse.SERVICE_UNKNOWN  # pylint: disable=no-member-            watcher = _Watcher()-            watcher.add(_health_pb2.HealthCheckResponse(status=status))-            if service not in self._watchers:-                self._watchers[service] = set()-            self._watchers[service].add(watcher)-            context.add_callback(self._on_close_callback(watcher, service))-        return watcher+            on_next_callback(_health_pb2.HealthCheckResponse(status=status))+            if service not in self._on_next_callbacks:","Suggestion inspired by Nathaniel:```pythonself._on_next_callbacks[service] = self._on_next_callbacks.get(service, set()) \    | {on_next_callback}```I'll leave up to you which is stylistically superior.",
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/18095,258285117,2019-02-20T00:11:26Z,src/python/grpcio_health_checking/grpc_health/v1/health.py,"@@ -27,7 +28,7 @@ class _Watcher():      def __init__(self):         self._condition = threading.Condition()-        self._responses = list()+        self._responses = collections.deque()","So, after suggesting `deque` here, I discovered that [`Queue` is basically just a `deque` and some locking machinery.](https://github.com/python/cpython/blob/master/Lib/queue.py#L205) It's also recommended as [the default inter-thread communication mechanism](https://github.com/google/styleguide/blob/gh-pages/pyguide.md#218-threading) by the style guide. Not wholly necessary, but a thought.",
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/18078,258324846,2019-02-20T03:48:48Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc,"@@ -1570,23 +1635,89 @@ grpc_channel_args* GrpcLb::CreateRoundRobinPolicyArgsLocked() {   return args; } -void GrpcLb::CreateOrUpdateRoundRobinPolicyLocked() {+void GrpcLb::CreateChildPolicyLocked(const char* name,+                                     grpc_channel_args* args) {+  OrphanablePtr<LoadBalancingPolicy>& lb_policy =+      child_policy_ == nullptr ? child_policy_ : pending_child_policy_;+  Helper* helper = New<Helper>(Ref());+  LoadBalancingPolicy::Args lb_policy_args;+  lb_policy_args.combiner = combiner();+  lb_policy_args.args = args;+  lb_policy_args.channel_control_helper =+      UniquePtr<ChannelControlHelper>(helper);+  lb_policy = LoadBalancingPolicyRegistry::CreateLoadBalancingPolicy(+      name, child_policy_config_, std::move(lb_policy_args));+  if (GPR_UNLIKELY(lb_policy == nullptr)) {+    gpr_log(GPR_ERROR, ""[grpclb %p] Failure creating child policy %s"", this,+            name);+    return;+  }+  helper->set_child(lb_policy.get());+  if (grpc_lb_glb_trace.enabled()) {+    gpr_log(GPR_INFO, ""[grpclb %p] Created new child policy %s (%p)"", this,+            name, lb_policy.get());+  }+  // Add the gRPC LB's interested_parties pollset_set to that of the newly+  // created child policy. This will make the child policy progress upon+  // activity on gRPC LB, which in turn is tied to the application's call.+  grpc_pollset_set_add_pollset_set(lb_policy->interested_parties(),+                                   interested_parties());+  lb_policy->ExitIdleLocked();+}++void GrpcLb::CreateOrUpdateChildPolicyLocked() {   if (shutting_down_) return;-  grpc_channel_args* args = CreateRoundRobinPolicyArgsLocked();+  grpc_channel_args* args = CreateChildPolicyArgsLocked();   GPR_ASSERT(args != nullptr);-  if (rr_policy_ != nullptr) {+  // There are several cases here:+  // 1. If we do not yet have any child policy, we create one and store+  //    it in child_policy_.+  // 2. If we have a child policy but no pending child policy, then:+  //    a. If the child policy's name equals child_policy_name, then we+  //       update the existing child policy.+  //    b. If the child policy's name does not equal child_policy_name,+  //       we create a new policy.  The policy will be stored in+  //       pending_child_policy_ and will later be swapped into+  //       child_policy_ by the helper when the new child transitions+  //       into state READY.+  // 3. If we have both a child policy and a pending child policy (i.e.,+  //    we created a new policy for a previous update that has not yet+  //    been moved from pending_child_policy_ to child_policy_), then:+  //    a. If the pending child policy's name equals child_policy_name,","Even with this optimization, the code is not complex or long. So I think it's worth adding.https://github.com/grpc/grpc/pull/18101/files#diff-19b9841b5d34408bb5328232a51f68d5R288 ",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18034,258428055,2019-02-20T10:51:37Z,tools/http2_interop/doc.go,"@@ -1,3 +1,17 @@+// Copyright 2019 gRPC authors.",The new format is `Copyright 2019 The gRPC Authors`as seen e.g. here: https://github.com/grpc/grpc/blob/906c12568e9bdf1d8306a2f2ab45efe8beb43f74/src/csharp/Grpc.Core.Api/Properties/AssemblyInfo.cs#L3,OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17051,258444750,2019-02-20T11:42:30Z,src/csharp/Grpc.Core/Channel.cs,"@@ -252,6 +260,7 @@ public async Task ShutdownAsync()             lock (myLock)             {                 handle.Dispose();+                cleanUpCredentials?.Invoke();","In NativeMetadataCredentialsPlugin I'm actually squashing more native callbacks into just one with more parameters. Ad releasing:   gcHandle is on the delegate object, but the delegate implicitly reference and instance of the class (""this"") so the class can't get garbage collected as long as the gcHandle is allocated. (I think referencing the class instance itself in the GCHandle would work too).",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17051,258445573,2019-02-20T11:45:21Z,src/csharp/Grpc.Core/ChannelCredentials.cs,"@@ -104,40 +105,74 @@ internal override ChannelCredentialsSafeHandle CreateNativeCredentials()         }     } +    /// <summary>+    /// Callback invoked with the expected targetHost and the peer's certificate.+    /// If a non-zero value is returned by this callback then it is treated as a+    /// verification failure. Invocation of the callback is blocking, so any+    /// implementation should be light-weight.+    /// </summary>+    /// <param name=""context"">The <see cref=""T:Grpc.Core.VerifyPeerContext""/> associated with the callback</param>+    /// <returns>true if verification succeeded, false otherwise.</returns>+    /// Note: experimental API that can change or be removed without any prior notice.+    public delegate bool VerifyPeerCallback(VerifyPeerContext context);+     /// <summary>     /// Client-side SSL credentials.     /// </summary>     public sealed class SslCredentials : ChannelCredentials     {         readonly string rootCertificates;         readonly KeyCertificatePair keyCertificatePair;+        readonly VerifyPeerCallbackInternal verifyPeerCallback;+        readonly VerifyPeerDestruct verifyPeerDestruct;+        readonly GCHandle gcHandle;",you don't need two GCHandle. - either you can use just one native callback (with more params)- or you can alloc GCHandle on the SslCredentials class instance itself (the instance references the delegates so they cannot be GC'd).,OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17051,258447004,2019-02-20T11:50:34Z,src/csharp/Grpc.Core/Internal/ChannelCredentialsSafeHandle.cs,"@@ -15,11 +15,16 @@ #endregion using System; using System.Runtime.InteropServices;-using System.Threading;-using System.Threading.Tasks;  namespace Grpc.Core.Internal {+    internal delegate int VerifyPeerCallbackInternal(",I think the targetHost and targetPem need to be IntPtr and you need to convert them to a string yourself (again see my example). the problem is that the automatic char* to string conversion might do copying or deallocation of the char* and that's something you don't want.https://github.com/grpc/grpc/blob/master/src/csharp/Grpc.Core/Internal/NativeMetadataCredentialsPlugin.cs#L65,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18059,258540129,2019-02-20T15:39:03Z,src/core/lib/surface/lame_client.cc,"@@ -54,9 +53,9 @@ struct ChannelData { static void fill_metadata(grpc_call_element* elem, grpc_metadata_batch* mdb) {   CallData* calld = static_cast<CallData*>(elem->call_data);   bool expected = false;-  if (!calld->filled_metadata.compare_exchange_strong(-          expected, true, grpc_core::memory_order_relaxed,-          grpc_core::memory_order_relaxed)) {+  if (!AtomicCompareExchangeStrong(&calld->filled_metadata, &expected, true,+                                   std::memory_order_relaxed,","So, I think @markdroth's comment applies here for consistency about preferring `grpc_core::` to `std::`outside of the `gprpp` directory, though I know that this is likely less important since it's guaranteed to be an enum and not some other sort of class afaik.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18059,258597860,2019-02-20T17:38:45Z,src/core/lib/gprpp/atomic.h,"@@ -21,10 +21,83 @@  #include <grpc/support/port_platform.h> -#ifdef GPR_HAS_CXX11_ATOMIC-#include ""src/core/lib/gprpp/atomic_with_std.h""-#else-#include ""src/core/lib/gprpp/atomic_with_atm.h""-#endif+#include <atomic>++namespace grpc_core {++template <typename T>+using Atomic = std::atomic<T>;","API suggestion: Instead of defining this as `std::atomic<>` and then requiring callers to use standalone functions instead of the methods that are exposed by `std::atomic<>`, would it make sense to instead make this a class containing a single `std::atomic<>` data member and providing the methods we want to expose?",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18059,258606103,2019-02-20T17:59:04Z,src/core/lib/gprpp/atomic.h,"@@ -25,9 +25,6 @@  namespace grpc_core { -template <typename T>-using Atomic = std::atomic<T>;- enum class MemoryOrder {","Maybe make this a public member of the `Atomic` class, so as to not unneccessarily pollute the namespace?",
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/18059,258609236,2019-02-20T18:07:38Z,src/core/lib/gprpp/atomic.h,"@@ -25,9 +25,6 @@  namespace grpc_core { -template <typename T>-using Atomic = std::atomic<T>;- enum class MemoryOrder {","The problem is that `Atomic` is a template class, and `Atomic::MemoryOrder` wouldn't compile. The enum would get repeated as as a symbol for all `T` of `Atomic<T>`. And callers will have to pass `Atomic<bool>::MemoryOrder` and `Atomic<int>::MemoryOrder`, which would be confusing to readers IMHO (e.g., why is there different memory order per type).Would you mind if we keep it as is?",OK
9540183,frazenshtein,https://api.github.com/repos/grpc/grpc/pulls/18060,258959595,2019-02-21T14:50:21Z,src/core/lib/iomgr/tcp_server_windows.cc,"@@ -255,7 +255,7 @@ static grpc_error* start_accept_locked(grpc_tcp_listener* port) {   }    sock = WSASocket(AF_INET6, SOCK_STREAM, IPPROTO_TCP, NULL, 0,-                   WSA_FLAG_OVERLAPPED);+                   WSA_FLAG_OVERLAPPED | WSA_FLAG_NO_HANDLE_INHERIT);","I'm not sure of the semantics and mechanics used elsewhere and have only tested this server-side diff with some long-running stress tests. I think it's a good idea to set this flag in src/core/lib/iomgr/tcp_client_windows.cc and other places unless they imply using some kind of magic to pass a socket to child processes for some reason. But I'm afraid I won't be able to verify them properly. I can update the review placing WSA_FLAG_NO_HANDLE_INHERIT everywhere, if you rely on automated tests.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18086,258971136,2019-02-21T15:15:08Z,src/csharp/Grpc.Core.Api/ServerCallContext.cs,"@@ -113,6 +116,23 @@ public WriteOptions WriteOptions         /// </summary>         public AuthContext AuthContext => AuthContextCore; +        /// <summary>+        /// Gets a dictionary that can be used by the various interceptors and handlers of this+        /// call to store arbitrary state.+        /// </summary>+        public virtual IDictionary<object, object> UserState",I'm wondering if we should aim for consistency and follow the pattern of having the properties non-virtual and delegating to UserStateCore property  or if current approach is better.,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18086,258974189,2019-02-21T15:21:30Z,src/csharp/Grpc.Core.Api/ServerCallContext.cs,"@@ -113,6 +116,23 @@ public WriteOptions WriteOptions         /// </summary>         public AuthContext AuthContext => AuthContextCore; +        /// <summary>+        /// Gets a dictionary that can be used by the various interceptors and handlers of this+        /// call to store arbitrary state.+        /// </summary>+        public virtual IDictionary<object, object> UserState","what are the arguments for using  IDictionary<object, object>  over Get<T>() and Set<T>()? I'm not a big fan of allowing the key to be of arbitrary type (and perhaps users using one that's not well suited to be a key in a dictionary). Also, I think not having a generic version of Get<T>() make retrieving typed values a bit clumsy because the user needs to use an explicit cast to get hold of the value.Btw, do we expect the pattern `UserState.Add(typeof(MyData), instanceOfMyData)` to be common?",OK
10605667,chwarr,https://api.github.com/repos/grpc/grpc/pulls/18086,259123293,2019-02-21T21:25:42Z,src/csharp/Grpc.Core.Api/ServerCallContext.cs,"@@ -113,6 +116,23 @@ public WriteOptions WriteOptions         /// </summary>         public AuthContext AuthContext => AuthContextCore; +        /// <summary>+        /// Gets a dictionary that can be used by the various interceptors and handlers of this+        /// call to store arbitrary state.+        /// </summary>+        public virtual IDictionary<object, object> UserState",The [Framework Design Guidelines](https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/virtual-members) suggests the pattern you mention. It will also be more consistent with what we already have. Let me update this.,OK
10605667,chwarr,https://api.github.com/repos/grpc/grpc/pulls/18086,259131183,2019-02-21T21:50:00Z,src/csharp/Grpc.Core.Api/ServerCallContext.cs,"@@ -113,6 +116,23 @@ public WriteOptions WriteOptions         /// </summary>         public AuthContext AuthContext => AuthContextCore; +        /// <summary>+        /// Gets a dictionary that can be used by the various interceptors and handlers of this+        /// call to store arbitrary state.+        /// </summary>+        public virtual IDictionary<object, object> UserState","I'm happy to implement `Get<T>`/`Set(T)`. As the maintainer of the library and the overall API shape, I'll defer to your for a final choice here.Do you want me to implement `Get<T>`/`Set(T)` so we can compare the APIs?Pros of `IDictionary<,>`:* Can store multiple values of the same type without needing to introduce wrapper types.* Works with any existing dictionary-based methods.* Can differentiate between not set and a stored null/default. I'd expect `Get<T>()` to return null/default if there hadn't been a call to `Set(T)` yet.* Very minor: `Dictionary<,>` is already implemented and tested. :-)Cons:* Explicit cast needed.* Can differentiate between not set and a stored null/default. (Yes, both a pro and a con.)My guess is that many people would use string constants for keys. For those who want to be robust against inadvertent collisions with arbitrary libraries, they'd probably use a private object instance (like is done for locking).",OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/18094,259139087,2019-02-21T22:14:07Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc,"@@ -562,15 +554,15 @@ GrpcLb::Picker::PickResult GrpcLb::Picker::Pick(PickState* pick,       abort();     }     grpc_mdelem lb_token = {reinterpret_cast<uintptr_t>(arg->value.pointer.p)};-    AddLbTokenToInitialMetadata(GRPC_MDELEM_REF(lb_token),-                                &pick->lb_token_mdelem_storage,-                                pick->initial_metadata);-    // Pass on client stats via context. Passes ownership of the reference.-    if (client_stats_ != nullptr) {-      pick->subchannel_call_context[GRPC_GRPCLB_CLIENT_STATS].value =-          client_stats_->Ref().release();-      pick->subchannel_call_context[GRPC_GRPCLB_CLIENT_STATS].destroy =-          DestroyClientStats;+    GPR_ASSERT(!GRPC_MDISNULL(lb_token));+    GPR_ASSERT(grpc_metadata_batch_add_tail(pick->initial_metadata,+                                            &pick->lb_token_mdelem_storage,+                                            GRPC_MDELEM_REF(lb_token))+                    == GRPC_ERROR_NONE);+    GrpcLbClientStats* client_stats = static_cast<GrpcLbClientStats*>(+        grpc_mdelem_get_user_data(lb_token, GrpcLbClientStats::Destroy));+    if (client_stats != nullptr) {+      client_stats->AddCallStarted();","Previously, we were calling this in the constructor of the call_data. Are there any implications to calling it here instead?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18078,259142995,2019-02-21T22:26:40Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc,"@@ -1570,23 +1635,89 @@ grpc_channel_args* GrpcLb::CreateRoundRobinPolicyArgsLocked() {   return args; } -void GrpcLb::CreateOrUpdateRoundRobinPolicyLocked() {+void GrpcLb::CreateChildPolicyLocked(const char* name,+                                     grpc_channel_args* args) {+  OrphanablePtr<LoadBalancingPolicy>& lb_policy =+      child_policy_ == nullptr ? child_policy_ : pending_child_policy_;+  Helper* helper = New<Helper>(Ref());+  LoadBalancingPolicy::Args lb_policy_args;+  lb_policy_args.combiner = combiner();+  lb_policy_args.args = args;+  lb_policy_args.channel_control_helper =+      UniquePtr<ChannelControlHelper>(helper);+  lb_policy = LoadBalancingPolicyRegistry::CreateLoadBalancingPolicy(+      name, child_policy_config_, std::move(lb_policy_args));+  if (GPR_UNLIKELY(lb_policy == nullptr)) {+    gpr_log(GPR_ERROR, ""[grpclb %p] Failure creating child policy %s"", this,+            name);+    return;+  }+  helper->set_child(lb_policy.get());+  if (grpc_lb_glb_trace.enabled()) {+    gpr_log(GPR_INFO, ""[grpclb %p] Created new child policy %s (%p)"", this,+            name, lb_policy.get());+  }+  // Add the gRPC LB's interested_parties pollset_set to that of the newly+  // created child policy. This will make the child policy progress upon+  // activity on gRPC LB, which in turn is tied to the application's call.+  grpc_pollset_set_add_pollset_set(lb_policy->interested_parties(),+                                   interested_parties());+  lb_policy->ExitIdleLocked();+}++void GrpcLb::CreateOrUpdateChildPolicyLocked() {   if (shutting_down_) return;-  grpc_channel_args* args = CreateRoundRobinPolicyArgsLocked();+  grpc_channel_args* args = CreateChildPolicyArgsLocked();   GPR_ASSERT(args != nullptr);-  if (rr_policy_ != nullptr) {+  // There are several cases here:+  // 1. If we do not yet have any child policy, we create one and store+  //    it in child_policy_.+  // 2. If we have a child policy but no pending child policy, then:+  //    a. If the child policy's name equals child_policy_name, then we+  //       update the existing child policy.+  //    b. If the child policy's name does not equal child_policy_name,+  //       we create a new policy.  The policy will be stored in+  //       pending_child_policy_ and will later be swapped into+  //       child_policy_ by the helper when the new child transitions+  //       into state READY.+  // 3. If we have both a child policy and a pending child policy (i.e.,+  //    we created a new policy for a previous update that has not yet+  //    been moved from pending_child_policy_ to child_policy_), then:+  //    a. If the pending child policy's name equals child_policy_name,","I agree that the individual change you're suggesting is not large, but I think this code is already fairly complex, and I think adding this case makes it harder to understand.  I would prefer to leave this out.To be honest, if I was going to add any optimization here, I'd be more likely to add the optimization of immediately swapping in the new policy if the old policy is not in state READY.  That one is more likely to get used and IMHO is a bit easier to explain.But neither of these is really necessary right now, so I'd prefer to stick to the basics.",OK
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/18115,259164548,2019-02-21T23:49:04Z,src/core/lib/security/security_connector/tls/spiffe_security_connector.cc,"@@ -0,0 +1,465 @@+/*+ *+ * Copyright 2018 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/support/port_platform.h>++#include ""src/core/lib/security/security_connector/tls/spiffe_security_connector.h""++#include <stdbool.h>+#include <string.h>++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>++#include ""src/core/lib/gpr/host_port.h""+#include ""src/core/lib/security/credentials/ssl/ssl_credentials.h""+#include ""src/core/lib/security/credentials/tls/spiffe_credentials.h""+#include ""src/core/lib/security/security_connector/ssl_utils.h""+#include ""src/core/lib/security/transport/security_handshaker.h""+#include ""src/core/lib/slice/slice_internal.h""+#include ""src/core/lib/transport/transport.h""+#include ""src/core/tsi/ssl_transport_security.h""+#include ""src/core/tsi/transport_security.h""++namespace {++static void ServerAuthorizationCheckDone(+    grpc_tls_server_authorization_check_arg* arg);++static tsi_ssl_pem_key_cert_pair* ConvertToTsiPemKeyCertPair(+    const grpc_tls_key_materials_config::PemKeyCertPairList& cert_pair_list) {+  tsi_ssl_pem_key_cert_pair* tsi_pairs = nullptr;+  size_t num_key_cert_pairs = cert_pair_list.size();+  if (num_key_cert_pairs > 0) {+    GPR_ASSERT(cert_pair_list.data() != nullptr);+    tsi_pairs = static_cast<tsi_ssl_pem_key_cert_pair*>(+        gpr_zalloc(num_key_cert_pairs * sizeof(tsi_ssl_pem_key_cert_pair)));+  }+  for (size_t i = 0; i < num_key_cert_pairs; i++) {+    GPR_ASSERT(cert_pair_list[i].private_key() != nullptr);+    GPR_ASSERT(cert_pair_list[i].cert_chain() != nullptr);+    tsi_pairs[i].cert_chain = gpr_strdup(cert_pair_list[i].cert_chain());+    tsi_pairs[i].private_key = gpr_strdup(cert_pair_list[i].private_key());+  }+  return tsi_pairs;+}++/** -- Util function to process server authorization check result. -- */+static grpc_error* ProcessServerAuthorizationCheckResult(+    grpc_tls_server_authorization_check_arg* arg) {+  grpc_error* error = GRPC_ERROR_NONE;+  char* msg = nullptr;+  /* Server authorization check is cancelled by caller. */+  if (arg->status == GRPC_STATUS_CANCELLED) {+    gpr_asprintf(&msg,+                 ""Server authorization check is cancelled by the caller with ""+                 ""error: %s"",+                 arg->error_details);+    error = GRPC_ERROR_CREATE_FROM_COPIED_STRING(msg);+  } else if (arg->status == GRPC_STATUS_OK) {+    /* Server authorization check completed successfully but returned check+     * failure. */+    if (!arg->result) {+      gpr_asprintf(&msg, ""Server authorization check failed with error: %s"",+                   arg->error_details);+      error = GRPC_ERROR_CREATE_FROM_COPIED_STRING(msg);+    }+    /* Server authorization check did not complete correctly. */+  } else {+    gpr_asprintf(+        &msg,+        ""Server authorization check did not finish correctly with error: %s"",+        arg->error_details);+    error = GRPC_ERROR_CREATE_FROM_COPIED_STRING(msg);+  }+  gpr_free(msg);+  return error;+}++/** -- Util function to populate SPIFFE server/channel credentials. -- */+static grpc_core::RefCountedPtr<grpc_tls_key_materials_config>+PopulateSpiffeCredentials(grpc_tls_credentials_options* options) {+  GPR_ASSERT(options != nullptr);+  GPR_ASSERT(options->credential_reload_config() != nullptr ||+             options->key_materials_config() != nullptr);+  grpc_core::RefCountedPtr<grpc_tls_key_materials_config> key_materials_config;+  /* Use credential reload config to fetch credentials. */+  if (options->credential_reload_config() != nullptr) {+    grpc_tls_credential_reload_arg* arg =+        static_cast<grpc_tls_credential_reload_arg*>(gpr_zalloc(sizeof(*arg)));+    key_materials_config = grpc_tls_key_materials_config_create()->Ref();+    arg->key_materials_config = key_materials_config.get();+    int result = options->credential_reload_config()->Schedule(arg);+    if (result) {+      /* Do not support async credential reload. */+      gpr_log(GPR_ERROR, ""Async credential reload is unsupported now."");+    } else {+      grpc_ssl_certificate_config_reload_status status = arg->status;+      if (status == GRPC_SSL_CERTIFICATE_CONFIG_RELOAD_UNCHANGED) {+        gpr_log(GPR_DEBUG, ""Credential does not change after reload."");+      } else if (status == GRPC_SSL_CERTIFICATE_CONFIG_RELOAD_FAIL) {+        gpr_log(GPR_ERROR, ""Credential reload failed with an error: %s"",+                arg->error_details);+      }+    }+    gpr_free((void*)arg->error_details);+    gpr_free(arg);+    /* Use existing key materials config. */+  } else {+    key_materials_config = const_cast<grpc_tls_credentials_options*>(options)+                               ->mutable_key_materials_config()+                               ->Ref();+  }+  return key_materials_config;+}++class grpc_tls_spiffe_channel_security_connector final+    : public grpc_channel_security_connector {+ public:+  grpc_tls_spiffe_channel_security_connector(+      grpc_core::RefCountedPtr<grpc_channel_credentials> channel_creds,+      grpc_core::RefCountedPtr<grpc_call_credentials> request_metadata_creds,+      const char* target_name, const char* overridden_target_name)+      : grpc_channel_security_connector(GRPC_SSL_URL_SCHEME,+                                        std::move(channel_creds),+                                        std::move(request_metadata_creds)),+        overridden_target_name_(overridden_target_name == nullptr+                                    ? nullptr+                                    : gpr_strdup(overridden_target_name)),+        client_handshaker_factory_(nullptr) {+    check_arg_ = ServerAuthorizationCheckArgCreate(this);+    char* port;+    gpr_split_host_port(target_name, &target_name_, &port);+    gpr_free(port);+  }++  ~grpc_tls_spiffe_channel_security_connector() override {+    if (target_name_ != nullptr) {+      gpr_free(target_name_);+    }+    if (overridden_target_name_ != nullptr) {+      gpr_free(overridden_target_name_);+    }+    if (client_handshaker_factory_ != nullptr) {+      tsi_ssl_client_handshaker_factory_unref(client_handshaker_factory_);+    }+    ServerAuthorizationCheckArgDestroy(check_arg_);+  }++  grpc_security_status InitializeHandshakerFactory(+      tsi_ssl_session_cache* ssl_session_cache) {+    const grpc_tls_spiffe_credentials* creds =+        static_cast<const grpc_tls_spiffe_credentials*>(channel_creds());+    GPR_ASSERT(creds->options() != nullptr);+    auto key_materials_config = PopulateSpiffeCredentials(+        const_cast<grpc_tls_credentials_options*>(creds->options()));+    if (!key_materials_config.get()->pem_key_cert_pair_list().size()) {+      key_materials_config.get()->Unref();+      return GRPC_SECURITY_ERROR;+    }+    tsi_ssl_pem_key_cert_pair* pem_key_cert_pair = ConvertToTsiPemKeyCertPair(+        key_materials_config.get()->pem_key_cert_pair_list());+    grpc_security_status status = grpc_init_tsi_ssl_client_handshaker_factory(+        pem_key_cert_pair, key_materials_config.get()->pem_root_certs(),+        ssl_session_cache, &client_handshaker_factory_);+    // Free memory.+    key_materials_config.get()->Unref();+    grpc_tsi_ssl_pem_key_cert_pairs_destroy(pem_key_cert_pair, 1);+    return status;+  }++  void add_handshakers(grpc_pollset_set* interested_parties,+                       grpc_core::HandshakeManager* handshake_mgr) override {+    // Instantiate TSI handshaker.+    tsi_handshaker* tsi_hs = nullptr;+    tsi_result result = tsi_ssl_client_handshaker_factory_create_handshaker(+        client_handshaker_factory_,+        overridden_target_name_ != nullptr ? overridden_target_name_+                                           : target_name_,+        &tsi_hs);+    if (result != TSI_OK) {+      gpr_log(GPR_ERROR, ""Handshaker creation failed with error %s."",+              tsi_result_to_string(result));+      return;+    }+    // Create handshakers.+    handshake_mgr->Add(grpc_core::SecurityHandshakerCreate(tsi_hs, this));+  }++  void check_peer(tsi_peer peer, grpc_endpoint* ep,+                  grpc_core::RefCountedPtr<grpc_auth_context>* auth_context,+                  grpc_closure* on_peer_checked) override {+    const char* target_name = overridden_target_name_ != nullptr+                                  ? overridden_target_name_+                                  : target_name_;+    grpc_error* error = grpc_ssl_check_peer(target_name, &peer, auth_context);+    const grpc_tls_spiffe_credentials* creds =+        static_cast<const grpc_tls_spiffe_credentials*>(channel_creds());+    GPR_ASSERT(creds->options() != nullptr);+    const grpc_tls_server_authorization_check_config* config =+        creds->options()->server_authorization_check_config();+    if (error == GRPC_ERROR_NONE && config != nullptr) {+      /* Peer property will contain a complete certificate chain. */+      const tsi_peer_property* p =+          tsi_peer_get_property_by_name(&peer, TSI_X509_PEM_CERT_PROPERTY);+      if (p == nullptr) {+        error = GRPC_ERROR_CREATE_FROM_STATIC_STRING(+            ""Cannot check peer: missing pem cert property."");+      } else {+        char* peer_pem = static_cast<char*>(gpr_malloc(p->value.length + 1));+        memcpy(peer_pem, p->value.data, p->value.length);+        peer_pem[p->value.length] = '\0';+        GPR_ASSERT(check_arg_ != nullptr);+        check_arg_->peer_cert = check_arg_->peer_cert == nullptr+                                    ? gpr_strdup(peer_pem)+                                    : check_arg_->peer_cert;+        check_arg_->target_name = check_arg_->target_name == nullptr+                                      ? gpr_strdup(target_name)+                                      : check_arg_->target_name;+        on_peer_checked_ = on_peer_checked;+        gpr_free(peer_pem);+        int callback_status = config->Schedule(check_arg_);+        /* Server authorization check is handled asynchronously. */+        if (callback_status) {+          tsi_peer_destruct(&peer);+          return;+        }+        /* Server authorization check is handled synchronously. */+        error = ProcessServerAuthorizationCheckResult(check_arg_);+      }+    }+    GRPC_CLOSURE_SCHED(on_peer_checked, error);+    tsi_peer_destruct(&peer);+  }++  int cmp(const grpc_security_connector* other_sc) const override {+    auto* other =+        reinterpret_cast<const grpc_tls_spiffe_channel_security_connector*>(+            other_sc);+    int c = channel_security_connector_cmp(other);+    if (c != 0) {+      return c;+    }+    c = strcmp(target_name_, other->target_name_);+    if (c != 0) {+      return c;+    }+    return (overridden_target_name_ == nullptr ||+            other->overridden_target_name_ == nullptr)+               ? GPR_ICMP(overridden_target_name_,+                          other->overridden_target_name_)+               : strcmp(overridden_target_name_,+                        other->overridden_target_name_);+  }++  bool check_call_host(const char* host, grpc_auth_context* auth_context,",This function and above cmp function has large code duplication. Either refactor into common function or add a TODO for future refactoring.,OK
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/18078,259180520,2019-02-22T01:10:40Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc,"@@ -1570,23 +1635,89 @@ grpc_channel_args* GrpcLb::CreateRoundRobinPolicyArgsLocked() {   return args; } -void GrpcLb::CreateOrUpdateRoundRobinPolicyLocked() {+void GrpcLb::CreateChildPolicyLocked(const char* name,+                                     grpc_channel_args* args) {+  OrphanablePtr<LoadBalancingPolicy>& lb_policy =+      child_policy_ == nullptr ? child_policy_ : pending_child_policy_;+  Helper* helper = New<Helper>(Ref());+  LoadBalancingPolicy::Args lb_policy_args;+  lb_policy_args.combiner = combiner();+  lb_policy_args.args = args;+  lb_policy_args.channel_control_helper =+      UniquePtr<ChannelControlHelper>(helper);+  lb_policy = LoadBalancingPolicyRegistry::CreateLoadBalancingPolicy(+      name, child_policy_config_, std::move(lb_policy_args));+  if (GPR_UNLIKELY(lb_policy == nullptr)) {+    gpr_log(GPR_ERROR, ""[grpclb %p] Failure creating child policy %s"", this,+            name);+    return;+  }+  helper->set_child(lb_policy.get());+  if (grpc_lb_glb_trace.enabled()) {+    gpr_log(GPR_INFO, ""[grpclb %p] Created new child policy %s (%p)"", this,+            name, lb_policy.get());+  }+  // Add the gRPC LB's interested_parties pollset_set to that of the newly+  // created child policy. This will make the child policy progress upon+  // activity on gRPC LB, which in turn is tied to the application's call.+  grpc_pollset_set_add_pollset_set(lb_policy->interested_parties(),+                                   interested_parties());+  lb_policy->ExitIdleLocked();+}++void GrpcLb::CreateOrUpdateChildPolicyLocked() {   if (shutting_down_) return;-  grpc_channel_args* args = CreateRoundRobinPolicyArgsLocked();+  grpc_channel_args* args = CreateChildPolicyArgsLocked();   GPR_ASSERT(args != nullptr);-  if (rr_policy_ != nullptr) {+  // There are several cases here:+  // 1. If we do not yet have any child policy, we create one and store+  //    it in child_policy_.+  // 2. If we have a child policy but no pending child policy, then:+  //    a. If the child policy's name equals child_policy_name, then we+  //       update the existing child policy.+  //    b. If the child policy's name does not equal child_policy_name,+  //       we create a new policy.  The policy will be stored in+  //       pending_child_policy_ and will later be swapped into+  //       child_policy_ by the helper when the new child transitions+  //       into state READY.+  // 3. If we have both a child policy and a pending child policy (i.e.,+  //    we created a new policy for a previous update that has not yet+  //    been moved from pending_child_policy_ to child_policy_), then:+  //    a. If the pending child policy's name equals child_policy_name,","I still think it's worth adding, because:1. It's an optimization, which is good to have.2. Adding it and reorganizing the condition branches makes the logic flow easier to understand.    1. The way we organize the condition branches in the comment now matches the initialization of `create_policy` better. It's kind of exact match now...    2. It reduces the number of sub-conditions from 4 to 3.3. This optimization is easier than the one to swap in the new policy if the old one is not in state READY, because it doesn't need to check any connectivity state. It's just checking the existence and the name of the LB policies, which are already checked even without this optimization. ",
44597042,tlg-bf,https://api.github.com/repos/grpc/grpc/pulls/17051,259204252,2019-02-22T03:42:18Z,src/csharp/Grpc.Core/Internal/ChannelCredentialsSafeHandle.cs,"@@ -15,11 +15,16 @@ #endregion using System; using System.Runtime.InteropServices;-using System.Threading;-using System.Threading.Tasks;  namespace Grpc.Core.Internal {+    internal delegate int VerifyPeerCallbackInternal(","Done. There was no `state` object like in the example you provided me, so I made use of the `userdata` pointer in the native code to keep track of the callback, I hope that's fine.",OK
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/18116,259404737,2019-02-22T16:06:29Z,src/python/grpcio/commands.py,"@@ -212,50 +214,39 @@ class BuildExt(build_ext.build_ext):     LINK_OPTIONS = {}      def build_extensions(self):++        def compiler_ok_with_extra_std():+            """"""Test if default compiler is okay with specifying c++ version+            when invokec in C mode. GCC is okay with this, while clang is not.+            """"""+            cc_test = subprocess.Popen(+                ['cc', '-x', 'c', '-std=c++11', '-'],+                stdout=subprocess.PIPE,+                stderr=subprocess.PIPE)+            _, cc_err = cc_test.communicate(input='int main(){return 0;}')+            return not 'invalid argument' in Text(cc_err)+         # This special conditioning is here due to difference of compiler         #   behavior in gcc and clang. The clang doesn't take --stdc++11         #   flags but gcc does. Since the setuptools of Python only support         #   all C or all C++ compilation, the mix of C and C++ will crash.-        #   *By default*, the macOS use clang and Linux use gcc, that's why-        #   the special condition here is checking platform.-        if ""darwin"" in sys.platform:","Since macosx is no longer launching a subprocess to use make, I think you'll also need to remove the `""darwin"" in sys.platform` part of the conditional in https://github.com/lifanov/grpc/blob/1d9a18407a539f02a45400b4a0b9cb839f69fc1f/setup.py#L268-L272. I think this is the cause of the failure in https://source.cloud.google.com/results/invocations/e2579ea9-d048-4e99-af90-9767f90cb3b6/targets/grpc%2Fcore%2Fpull_request%2Fmacos%2Fgrpc_basictests_opt/log",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17051,259408676,2019-02-22T16:16:04Z,src/csharp/Grpc.Core/Channel.cs,"@@ -252,6 +260,7 @@ public async Task ShutdownAsync()             lock (myLock)             {                 handle.Dispose();+                cleanUpCredentials?.Invoke();","I haven't read it in full, but it seems to talk about a different case (when you're passing a pointer to managed object to the native code and the native code directly accesses the representation of that object in memory). We're not doing that, we're only passing a delegate and the marshalling semantics of P/Invoke in that case is to translate the delegate into a native callback and pass that one to the native code (this transitions object is called the ""thunk"" in the docs btw).",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/17051,259413679,2019-02-22T16:27:52Z,src/csharp/Grpc.Core/ChannelCredentials.cs,"@@ -171,7 +204,20 @@ internal override bool IsComposable          internal override ChannelCredentialsSafeHandle CreateNativeCredentials()         {-            return ChannelCredentialsSafeHandle.CreateSslCredentials(rootCertificates, keyCertificatePair);+            return ChannelCredentialsSafeHandle.CreateSslCredentials(rootCertificates, keyCertificatePair, this.verifyPeerCallbackInternal);+        }++        private int VerifyPeerCallbackInternal(IntPtr host, IntPtr pem, IntPtr userData, bool isDestroy)+        {+            if (isDestroy)+            {+                this.gcHandle.Free();+                return 0;+            }++            var context = new VerifyPeerContext(Marshal.PtrToStringAnsi(host), Marshal.PtrToStringAnsi(pem));++            return this.verifyPeerCallback(context) ? 0 : 1;","you need to catch exceptions here, throwing from within a native callback will crash the application.See https://github.com/grpc/grpc/blob/8fd43c2e91d6fb4f2cd62b82ec1fe7b2218cd66f/src/csharp/Grpc.Core/Internal/NativeMetadataCredentialsPlugin.cs#L71",
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/18130,259470939,2019-02-22T19:00:48Z,test/cpp/end2end/client_lb_end2end_test.cc,"@@ -153,7 +153,6 @@ class ClientLbEnd2endTest : public ::testing::Test {     for (size_t i = 0; i < servers_.size(); ++i) {       servers_[i]->Shutdown();     }-    grpc_shutdown();","That would not work because the test class has some members such as server/channel/creds which all carry grpc_init/shutdown in their life time... The alternative I thought about is to add a clear method to the test class, which destroys all of those objects (and wait for grpc_shutdown to terminate). But I feel like that is a bit more fragile because someone may add a new object later but forgot to update the Clear method, and the test becomes flaky again for no clear reason...Another alternative Juanli proposed is for the next grpc_init wait for the on-going shutdown to finish before starting to init again. I think that could solve this issue but does not sound like the right thing to do. Since in general if we know we are going to init again there is no point to do a shutdown first.As I mentioned in the desc, I think it is likely a mistake to tie the lifetime of a registered lb policy factory to grpc_init/shutdown anyway. That is another reason I chose this approach.Sorry for the long reply...",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18078,259487328,2019-02-22T19:48:34Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc,"@@ -1570,23 +1635,89 @@ grpc_channel_args* GrpcLb::CreateRoundRobinPolicyArgsLocked() {   return args; } -void GrpcLb::CreateOrUpdateRoundRobinPolicyLocked() {+void GrpcLb::CreateChildPolicyLocked(const char* name,+                                     grpc_channel_args* args) {+  OrphanablePtr<LoadBalancingPolicy>& lb_policy =+      child_policy_ == nullptr ? child_policy_ : pending_child_policy_;+  Helper* helper = New<Helper>(Ref());+  LoadBalancingPolicy::Args lb_policy_args;+  lb_policy_args.combiner = combiner();+  lb_policy_args.args = args;+  lb_policy_args.channel_control_helper =+      UniquePtr<ChannelControlHelper>(helper);+  lb_policy = LoadBalancingPolicyRegistry::CreateLoadBalancingPolicy(+      name, child_policy_config_, std::move(lb_policy_args));+  if (GPR_UNLIKELY(lb_policy == nullptr)) {+    gpr_log(GPR_ERROR, ""[grpclb %p] Failure creating child policy %s"", this,+            name);+    return;+  }+  helper->set_child(lb_policy.get());+  if (grpc_lb_glb_trace.enabled()) {+    gpr_log(GPR_INFO, ""[grpclb %p] Created new child policy %s (%p)"", this,+            name, lb_policy.get());+  }+  // Add the gRPC LB's interested_parties pollset_set to that of the newly+  // created child policy. This will make the child policy progress upon+  // activity on gRPC LB, which in turn is tied to the application's call.+  grpc_pollset_set_add_pollset_set(lb_policy->interested_parties(),+                                   interested_parties());+  lb_policy->ExitIdleLocked();+}++void GrpcLb::CreateOrUpdateChildPolicyLocked() {   if (shutting_down_) return;-  grpc_channel_args* args = CreateRoundRobinPolicyArgsLocked();+  grpc_channel_args* args = CreateChildPolicyArgsLocked();   GPR_ASSERT(args != nullptr);-  if (rr_policy_ != nullptr) {+  // There are several cases here:+  // 1. If we do not yet have any child policy, we create one and store+  //    it in child_policy_.+  // 2. If we have a child policy but no pending child policy, then:+  //    a. If the child policy's name equals child_policy_name, then we+  //       update the existing child policy.+  //    b. If the child policy's name does not equal child_policy_name,+  //       we create a new policy.  The policy will be stored in+  //       pending_child_policy_ and will later be swapped into+  //       child_policy_ by the helper when the new child transitions+  //       into state READY.+  // 3. If we have both a child policy and a pending child policy (i.e.,+  //    we created a new policy for a previous update that has not yet+  //    been moved from pending_child_policy_ to child_policy_), then:+  //    a. If the pending child policy's name equals child_policy_name,","> 1. It's an optimization, which is good to have.I don't think that optimizations are inherently good; I think that they need to be approached using a cost/benefit analysis, just like any other code change.  In this case, the benefit is very small, and while the complexity of the optimization itself is not huge, it is IMHO large enough to outweigh the benefit we would get by having it.> 2. Adding it and reorganizing the condition branches makes the logic flow easier to understand.>    >    1. The way we organize the condition branches in the comment now matches the initialization of `create_policy` better. It's kind of exact match no ew...I don't actually think it's important for the branches in the comment to match the structure of the code.  I think comments should be structured in a way that makes it clear to a human reader what is actually happening, and code should be structured to be efficient and maintainable.  Those differing sets of goals often mean that the two will not match up.From a human reader's perspective, I think the important thing to understand is that there are basically 3 cases: (1) we don't yet have any LB policy, (2) we have a child policy but no pending child policy, and (3) we have both a child policy and a pending child policy.  The fact that cases (2) and (3) each have two branches is another level of detail.  That's why I structured the comment the way I did.If I had wanted the code to be structured the same way that the comment is, I would have written something like this:```if (child_policy_ == nullptr) {  // ...case 1...} else if (pending_child_policy_ == nullptr) {  // ...case 2...} else {  // ...case 3...}```But that would have resulted in duplicate code between the three branches, which is why I didn't do that.>    2. It reduces the number of sub-conditions from 4 to 3.I don't see how it actually does this.  There are actually 5 cases either way.> 3. This optimization is easier than the one to swap in the new policy if the old one is not in state READY, because it doesn't need to check any connectivity state. It's just checking the existence and the name of the LB policies, which are already checked even without this optimization.That's true.  But notice that I am not adding either optimization here. :)",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18130,259517233,2019-02-22T21:31:02Z,test/cpp/end2end/client_lb_end2end_test.cc,"@@ -153,7 +153,6 @@ class ClientLbEnd2endTest : public ::testing::Test {     for (size_t i = 0; i < servers_.size(); ++i) {       servers_[i]->Shutdown();     }-    grpc_shutdown();","So, I actually disagree that it's a mistake to tie the lifetime of a registered LB policy factory to grpc_init/shutdown.  We have tests (like this one) where we register something that's intended only for use in that one test, and we don't want it to be visible outside of the individual test.  Also, since most LB policies will be registered via a plugin init method, and plugin init methods run from grpc_init(), failing to de-register at shutdown would cause conflicts.I'm really not keen on requiring a static member of the class to point the policy at the right test instance.  This is effectively requiring global state, which seems fairly messy.Would it work to call `grpc_shutdown_blocking()` if we do it in the test class's dtor instead of in the `TearDown()` method?",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/18140,259535837,2019-02-22T22:47:09Z,src/core/ext/transport/chttp2/transport/hpack_parser.cc,"@@ -1451,7 +1451,7 @@ static grpc_error* begin_parse_string(grpc_chttp2_hpack_parser* p,                                       const uint8_t* cur, const uint8_t* end,                                       uint8_t binary,                                       grpc_chttp2_hpack_parser_string* str) {-  if (!p->huff && binary == NOT_BINARY &&+  if ((end > cur) && !p->huff && binary == NOT_BINARY &&","@vjpai @equinox1993 @yang-g I reviewed the stack traces and the code, and I still do not understand how we get into a state where we are trying to parse an empty string. However, what do you think about adding an end condition to the beginning of this function? `  if (cur == end) {`   `     p->state = begin_parse_string; // I'm not sure if this is the correct state to set here`   `     return GRPC_ERROR_NONE;``  } `This might fix the fuzzer issue and would prevent us from going down the code path below the if branch.I do think someone should look at the code and figure out its invariants, but it's so unnecessarily complex that I don't think anyone has time to / wants to.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18136,259539514,2019-02-22T23:05:21Z,test/cpp/end2end/client_callback_end2end_test.cc,"@@ -419,168 +457,484 @@ TEST_P(ClientCallbackEnd2endTest, CancelRpcBeforeStart) {   while (!done) {     cv.wait(l);   }+  if (GetParam().use_interceptors) {+    EXPECT_EQ(20, DummyInterceptor::GetNumTimesCancel());+  } } -TEST_P(ClientCallbackEnd2endTest, RequestStream) {+TEST_P(ClientCallbackEnd2endTest, RequestEchoServerCancel) {   MAYBE_SKIP_TEST;   ResetStub();-  class Client : public grpc::experimental::ClientWriteReactor<EchoRequest> {-   public:-    explicit Client(grpc::testing::EchoTestService::Stub* stub) {-      context_.set_initial_metadata_corked(true);-      stub->experimental_async()->RequestStream(&context_, &response_, this);-      StartCall();-      request_.set_message(""Hello server."");-      StartWrite(&request_);+  EchoRequest request;+  EchoResponse response;+  ClientContext context;+  request.set_message(""hello"");+  context.AddMetadata(kServerTryCancelRequest,+                      grpc::to_string(CANCEL_BEFORE_PROCESSING));++  std::mutex mu;+  std::condition_variable cv;+  bool done = false;+  stub_->experimental_async()->Echo(+      &context, &request, &response, [&done, &mu, &cv](Status s) {+        EXPECT_FALSE(s.ok());+        EXPECT_EQ(grpc::StatusCode::CANCELLED, s.error_code());+        std::lock_guard<std::mutex> l(mu);+        done = true;+        cv.notify_one();+      });+  std::unique_lock<std::mutex> l(mu);+  while (!done) {+    cv.wait(l);+  }+}++class WriteClient : public grpc::experimental::ClientWriteReactor<EchoRequest> {+ public:+  WriteClient(grpc::testing::EchoTestService::Stub* stub,+              ServerTryCancelRequestPhase server_try_cancel,+              int num_msgs_to_send)+      : server_try_cancel_(server_try_cancel),+        num_msgs_to_send_(num_msgs_to_send) {+    grpc::string msg{""Hello server.""};+    for (int i = 0; i < num_msgs_to_send; i++) {+      desired_ += msg;     }-    void OnWriteDone(bool ok) override {-      writes_left_--;-      if (writes_left_ > 1) {-        StartWrite(&request_);-      } else if (writes_left_ == 1) {-        StartWriteLast(&request_, WriteOptions());-      }+    if (server_try_cancel != DO_NOT_CANCEL) {+      // Send server_try_cancel value in the client metadata+      context_.AddMetadata(kServerTryCancelRequest,+                           grpc::to_string(server_try_cancel));     }-    void OnDone(const Status& s) override {+    context_.set_initial_metadata_corked(true);+    stub->experimental_async()->RequestStream(&context_, &response_, this);+    StartCall();+    request_.set_message(msg);+    MaybeWrite();+  }+  void OnWriteDone(bool ok) override {+    num_msgs_sent_++;+    if (ok) {+      MaybeWrite();+    }+  }+  void OnDone(const Status& s) override {+    gpr_log(GPR_INFO, ""Sent %d messages"", num_msgs_sent_);+    switch (server_try_cancel_) {+      case CANCEL_BEFORE_PROCESSING:+      case CANCEL_DURING_PROCESSING:+        // If the RPC is canceled by server before / during messages from the+        // client, it means that the client most likely did not get a chance to+        // send all the messages it wanted to send. i.e num_msgs_sent <=+        // num_msgs_to_send+        EXPECT_LE(num_msgs_sent_, num_msgs_to_send_);+        break;+      case DO_NOT_CANCEL:+      case CANCEL_AFTER_PROCESSING:+        // If the RPC was not canceled or canceled after all messages were read+        // by the server, the client did get a chance to send all its messages+        EXPECT_EQ(num_msgs_sent_, num_msgs_to_send_);+        break;+      default:+        assert(false);+        break;+    }+    if (server_try_cancel_ == DO_NOT_CANCEL) {       EXPECT_TRUE(s.ok());-      EXPECT_EQ(response_.message(), ""Hello server.Hello server.Hello server."");-      std::unique_lock<std::mutex> l(mu_);-      done_ = true;-      cv_.notify_one();+      EXPECT_EQ(response_.message(), desired_);+    } else {+      EXPECT_FALSE(s.ok());+      EXPECT_EQ(grpc::StatusCode::CANCELLED, s.error_code());     }-    void Await() {-      std::unique_lock<std::mutex> l(mu_);-      while (!done_) {-        cv_.wait(l);-      }+    std::unique_lock<std::mutex> l(mu_);+    done_ = true;+    cv_.notify_one();+  }+  void Await() {+    std::unique_lock<std::mutex> l(mu_);+    while (!done_) {+      cv_.wait(l);     }+  } -   private:-    EchoRequest request_;-    EchoResponse response_;-    ClientContext context_;-    int writes_left_{3};-    std::mutex mu_;-    std::condition_variable cv_;-    bool done_ = false;-  } test{stub_.get()};+ private:+  void MaybeWrite() {+    if (num_msgs_to_send_ > num_msgs_sent_ + 1) {+      StartWrite(&request_);+    } else if (num_msgs_to_send_ == num_msgs_sent_ + 1) {+      StartWriteLast(&request_, WriteOptions());+    }+  }+  EchoRequest request_;+  EchoResponse response_;+  ClientContext context_;+  const ServerTryCancelRequestPhase server_try_cancel_;+  int num_msgs_sent_{0};+  const int num_msgs_to_send_;+  grpc::string desired_;+  std::mutex mu_;+  std::condition_variable cv_;+  bool done_ = false;+}; +TEST_P(ClientCallbackEnd2endTest, RequestStream) {+  MAYBE_SKIP_TEST;+  ResetStub();+  WriteClient test{stub_.get(), DO_NOT_CANCEL, 3};   test.Await();+  // Make sure that the server interceptors were not notified to cancel+  if (GetParam().use_interceptors) {+    EXPECT_EQ(0, DummyInterceptor::GetNumTimesCancel());+  } } -TEST_P(ClientCallbackEnd2endTest, ResponseStream) {+// Server to cancel before doing reading the request+TEST_P(ClientCallbackEnd2endTest, RequestStreamServerCancelBeforeReads) {   MAYBE_SKIP_TEST;   ResetStub();-  class Client : public grpc::experimental::ClientReadReactor<EchoResponse> {-   public:-    explicit Client(grpc::testing::EchoTestService::Stub* stub) {-      request_.set_message(""Hello client "");-      stub->experimental_async()->ResponseStream(&context_, &request_, this);-      StartCall();-      StartRead(&response_);+  WriteClient test{stub_.get(), CANCEL_BEFORE_PROCESSING, 1};+  test.Await();+  // Make sure that the server interceptors were notified+  if (GetParam().use_interceptors) {+    EXPECT_EQ(20, DummyInterceptor::GetNumTimesCancel());+  }+}++// Server to cancel while reading a request from the stream in parallel+TEST_P(ClientCallbackEnd2endTest, RequestStreamServerCancelDuringRead) {+  MAYBE_SKIP_TEST;+  ResetStub();+  WriteClient test{stub_.get(), CANCEL_DURING_PROCESSING, 10};+  test.Await();+  // Make sure that the server interceptors were notified+  if (GetParam().use_interceptors) {+    EXPECT_EQ(20, DummyInterceptor::GetNumTimesCancel());+  }+}++// Server to cancel after reading all the requests but before returning to the+// client+TEST_P(ClientCallbackEnd2endTest, RequestStreamServerCancelAfterReads) {+  MAYBE_SKIP_TEST;+  ResetStub();+  WriteClient test{stub_.get(), CANCEL_AFTER_PROCESSING, 4};+  test.Await();+  // Make sure that the server interceptors were notified+  if (GetParam().use_interceptors) {+    EXPECT_EQ(20, DummyInterceptor::GetNumTimesCancel());+  }+}++class ReadClient : public grpc::experimental::ClientReadReactor<EchoResponse> {+ public:+  ReadClient(grpc::testing::EchoTestService::Stub* stub,+             ServerTryCancelRequestPhase server_try_cancel)+      : server_try_cancel_(server_try_cancel) {+    if (server_try_cancel_ != DO_NOT_CANCEL) {+      // Send server_try_cancel value in the client metadata+      context_.AddMetadata(kServerTryCancelRequest,+                           grpc::to_string(server_try_cancel));     }-    void OnReadDone(bool ok) override {-      if (!ok) {+    request_.set_message(""Hello client "");+    stub->experimental_async()->ResponseStream(&context_, &request_, this);+    StartRead(&response_);+    StartCall();+  }+  void OnReadDone(bool ok) override {+    if (!ok) {+      if (server_try_cancel_ == DO_NOT_CANCEL) {         EXPECT_EQ(reads_complete_, kServerDefaultResponseStreamsToSend);-      } else {-        EXPECT_LE(reads_complete_, kServerDefaultResponseStreamsToSend);-        EXPECT_EQ(response_.message(),-                  request_.message() + grpc::to_string(reads_complete_));-        reads_complete_++;-        StartRead(&response_);       }+    } else {+      EXPECT_LE(reads_complete_, kServerDefaultResponseStreamsToSend);+      EXPECT_EQ(response_.message(),+                request_.message() + grpc::to_string(reads_complete_));","So, the unary and bidi-streaming service is basically echo, but the single-sided streaming service is not.The RequestStream is basically a response concatenator (which becomes a multiplier in our test since we keep sending the same request): https://github.com/grpc/grpc/blob/master/test/cpp/end2end/test_service_impl.cc#L416And the ResponseStream appends the message count to the echo response: https://github.com/grpc/grpc/blob/master/test/cpp/end2end/test_service_impl.cc#L470So the second of those is what is being expected in the code that you're looking at above.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18130,259539729,2019-02-22T23:06:26Z,test/cpp/end2end/client_lb_end2end_test.cc,"@@ -153,7 +153,6 @@ class ClientLbEnd2endTest : public ::testing::Test {     for (size_t i = 0; i < servers_.size(); ++i) {       servers_[i]->Shutdown();     }-    grpc_shutdown();",How about just having the `TearDown()` method explicitly clear out any other data members of the test class before it calls `grpc_shutdown_blocking()`?,OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/17987,259989514,2019-02-25T19:48:19Z,src/core/ext/filters/client_channel/resolver/fake/fake_resolver.cc,"@@ -95,43 +99,48 @@ FakeResolver::~FakeResolver() {   grpc_channel_args_destroy(channel_args_); } -void FakeResolver::NextLocked(grpc_channel_args** target_result,-                              grpc_closure* on_complete) {-  GPR_ASSERT(next_completion_ == nullptr);-  next_completion_ = on_complete;-  target_result_ = target_result;-  MaybeFinishNextLocked();+void FakeResolver::StartLocked() {+  active_ = true;+  MaybeSendResultLocked(); }  void FakeResolver::RequestReresolutionLocked() {   if (reresolution_results_ != nullptr || return_failure_) {     grpc_channel_args_destroy(next_results_);     next_results_ = grpc_channel_args_copy(reresolution_results_);-    MaybeFinishNextLocked();+    // Return the result in a different closure, so that we don't call","If this is something should be generally required of any resolver, does it make sense to push this responsibility of post-poning the LB policy callback into the resolver result handler? I'd guess the fact that this explicit bounce isn't needed in other resolvers is probably because those resolvers just accidentally happen to complete their resolutions  using a closure sched somewhere along the way.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/17987,260000072,2019-02-25T20:16:28Z,src/core/ext/filters/client_channel/resolver/fake/fake_resolver.cc,"@@ -95,43 +99,48 @@ FakeResolver::~FakeResolver() {   grpc_channel_args_destroy(channel_args_); } -void FakeResolver::NextLocked(grpc_channel_args** target_result,-                              grpc_closure* on_complete) {-  GPR_ASSERT(next_completion_ == nullptr);-  next_completion_ = on_complete;-  target_result_ = target_result;-  MaybeFinishNextLocked();+void FakeResolver::StartLocked() {+  active_ = true;+  MaybeSendResultLocked(); }  void FakeResolver::RequestReresolutionLocked() {   if (reresolution_results_ != nullptr || return_failure_) {     grpc_channel_args_destroy(next_results_);     next_results_ = grpc_channel_args_copy(reresolution_results_);-    MaybeFinishNextLocked();+    // Return the result in a different closure, so that we don't call","This should work either way. But note, for example, that there are several situations in which the c-ares resolver doesn't actually perform any async I/O for a resolution - for example if the target is an ip literal, or if the target can be found in the hosts file. In either of those cases, that resolver does use a closure sched but only because that's how the the current ""on done"" from the wrapper is written: https://github.com/grpc/grpc/blob/master/src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc#L154. I'd imagine other resolvers could have similar cases.What do you think?",OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/18140,260051193,2019-02-25T22:41:10Z,src/core/ext/transport/chttp2/transport/hpack_parser.cc,"@@ -1451,7 +1451,7 @@ static grpc_error* begin_parse_string(grpc_chttp2_hpack_parser* p,                                       const uint8_t* cur, const uint8_t* end,                                       uint8_t binary,                                       grpc_chttp2_hpack_parser_string* str) {-  if (!p->huff && binary == NOT_BINARY &&+  if ((end > cur) && !p->huff && binary == NOT_BINARY &&","@vjpai, would you mind changing the code to the suggestion? I think it makes more sense to add in an end condition here (like elsewhere in the code) rather than just the ""end > cur"" check ",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/17987,260056891,2019-02-25T22:59:50Z,src/core/ext/filters/client_channel/resolver/fake/fake_resolver.cc,"@@ -95,43 +99,48 @@ FakeResolver::~FakeResolver() {   grpc_channel_args_destroy(channel_args_); } -void FakeResolver::NextLocked(grpc_channel_args** target_result,-                              grpc_closure* on_complete) {-  GPR_ASSERT(next_completion_ == nullptr);-  next_completion_ = on_complete;-  target_result_ = target_result;-  MaybeFinishNextLocked();+void FakeResolver::StartLocked() {+  active_ = true;+  MaybeSendResultLocked(); }  void FakeResolver::RequestReresolutionLocked() {   if (reresolution_results_ != nullptr || return_failure_) {     grpc_channel_args_destroy(next_results_);     next_results_ = grpc_channel_args_copy(reresolution_results_);-    MaybeFinishNextLocked();+    // Return the result in a different closure, so that we don't call","I think those are special cases that can be handled by the resolver implementation.  If a resolver is special-casing some request such that it doesn't need to do I/O, it can be responsible for returning the result in a closure.There are two reasons that I'd prefer not to put this in the result handler.  First, it would make the API a bit ugly by making it such that the method defined by the result handler implementation is different from the one called by the resolver.  In other words, it would need to look something like this:```class ResultHandler { public:  ResultHandler() {    GRPC_CLOSURE_INIT(&closure_, ReturnResultLocked, this,            grpc_combiner_scheduler(combiner()));  }  void ReturnResult(const grpc_channel_arg* result) {    current_result_ = result;    GRPC_CLOSURE_SCHED(&closure_, GRPC_ERROR_NONE);  } protected:  // Subclasses implement this.  virtual void ReturnResultImpl(const grpc_channel_args* result) GRPC_ABSTRACT; private:  static void ReturnResultLocked(void* arg, grpc_error* error) {    ResultHandler* self = static_cast<ResultHandler*>(arg);    self->ReturnResultImpl(self->current_result_);    self->current_result_ = nullptr;  }  const grpc_channel_args* current_result_ = nullptr;  grpc_closure closure_;};```The second problem is that it would require an additional memory allocation for each call to `ReturnResult()`; we could not simply use a closure allocated as a member of the result handler as shown above, because there is no guarantee that the previous result closure would be executed before the next one is requested.Now, this is on the control plane, not the data plane, so I am willing to go that route if we need to at some point in the future.  But until and unless we have a demonstrated need to do that, I would prefer to stick with making it the resolver's responsibility to deal with these special cases.",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/17987,260072714,2019-02-26T00:01:18Z,src/core/ext/filters/client_channel/resolving_lb_policy.cc,"@@ -248,27 +268,46 @@ void ResolvingLoadBalancingPolicy::OnResolverShutdownLocked(grpc_error* error) {               resolver_.get());     }     resolver_.reset();-    grpc_error* error = GRPC_ERROR_CREATE_REFERENCING_FROM_STATIC_STRING(-        ""Resolver spontaneous shutdown"", &error, 1);+    grpc_error* error =","Regarding the comment above about this code being defensive, because:a) This request router holds a ref on the resolverb) `OnResolverShutdownLocked` is called from the result handler's dtorc) The request router is a <i>private</i> `UniquePtr` owned by the `Resolver` base class... isn't it now impossible to reach `OnResolverShutdownLocked` unless this request router has already orphaned the resolver?",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/18172,260124898,2019-02-26T04:52:04Z,src/python/grpcio/grpc/_server.py,"@@ -565,8 +566,8 @@ def _send_message_callback_to_blocking_iterator_adapter(   def _select_thread_pool_for_behavior(behavior, default_thread_pool):-    if hasattr(behavior, 'experimental_thread_pool'-              ) and behavior.experimental_thread_pool is not None:+    if hasattr(behavior, 'experimental_thread_pool') and isinstance(+            behavior.experimental_thread_pool, futures.ThreadPoolExecutor):",Should we check for the base class https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.Executor?,
5067076,ericgribkoff,https://api.github.com/repos/grpc/grpc/pulls/18172,260125495,2019-02-26T04:56:31Z,src/python/grpcio/grpc/_server.py,"@@ -565,8 +566,8 @@ def _send_message_callback_to_blocking_iterator_adapter(   def _select_thread_pool_for_behavior(behavior, default_thread_pool):-    if hasattr(behavior, 'experimental_thread_pool'-              ) and behavior.experimental_thread_pool is not None:+    if hasattr(behavior, 'experimental_thread_pool') and isinstance(+            behavior.experimental_thread_pool, futures.ThreadPoolExecutor):","I'll let you and Richard make that call :-) I hadn't really considered it, but as evidence that maybe we should not check for the base class: our server explicitly requires a `ThreadPoolExecutor` already (https://grpc.io/grpc/python/grpc.html#grpc.server) and we are actually not compatible with the other stock implementation of the base class (`ProcessPoolExecutor`, which uses fork and will break us horribly)",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18173,260161669,2019-02-26T07:51:44Z,.github/PULL_REQUEST_TEMPLATE.md,"@@ -0,0 +1,13 @@+<!--+Thank you for contributing to GRPC!+Please provide the following information to help us make the most of your pull request:",there should be a link to https://github.com/grpc/grpc/blob/master/CONTRIBUTING.md,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18171,260179247,2019-02-26T08:47:36Z,src/python/grpcio/README.rst,"@@ -51,7 +51,7 @@ package named :code:`python-dev`).   $ git submodule update --init    # For the next two commands do `sudo pip install` if you get permission-denied errors-  $ pip install -rrequirements.txt+  $ pip install -r requirements.txt","no, this is not a typo. please revert this line completely.https://github.com/grpc/grpc/blob/d64fd75dd889edc41049a87d2f4345be689a9936/tools/run_tests/artifacts/build_artifact_python.sh#L97",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18169,260181744,2019-02-26T08:54:51Z,src/csharp/Grpc.Core/CallOptions.cs,"@@ -69,7 +69,7 @@ public Metadata Headers         /// <summary>         /// Call deadline.         /// </summary>-        public DateTime? Deadline+        public DateTimeOffset? Deadline","Note that all the API changes need to be backward compatible (otherwise the change breaks all users and that's not acceptable).  It might be ok to add new fields/extension methods  to allow specifying the deadline in form of DateTimeOffset or a timeout, but we can't break the existing API.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18176,260417964,2019-02-26T18:11:50Z,src/core/ext/filters/client_channel/lb_policy.h,"@@ -261,8 +260,7 @@ class LoadBalancingPolicy : public InternallyRefCounted<LoadBalancingPolicy> {   /// Note that the LB policy gets the set of addresses from the   /// GRPC_ARG_SERVER_ADDRESS_LIST channel arg.   virtual void UpdateLocked(const grpc_channel_args& args,-                            RefCountedPtr<Config> lb_config) {-    std::move(lb_config);  // Suppress clang-tidy complaint.+                            RefCountedPtr<Config> lb_config) {  // NOLINT","Why is `NOLINT` needed here, but not in the other locations?  Is it because the parameter has a name here?  If so, maybe just remove the parameter name and the `NOLINT` comment?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18176,260792384,2019-02-27T15:09:21Z,src/core/ext/filters/client_channel/lb_policy.h,"@@ -261,8 +260,7 @@ class LoadBalancingPolicy : public InternallyRefCounted<LoadBalancingPolicy> {   /// Note that the LB policy gets the set of addresses from the   /// GRPC_ARG_SERVER_ADDRESS_LIST channel arg.   virtual void UpdateLocked(const grpc_channel_args& args,-                            RefCountedPtr<Config> lb_config) {-    std::move(lb_config);  // Suppress clang-tidy complaint.+                            RefCountedPtr<Config> lb_config) {  // NOLINT","Isn't this exactly the same case as the other sites you're changing?  The `std::move()` call was added to work around this exact warning.  If removing the parameter name makes the warning go away in all of these other cases, why isn't that sufficient here?  Why is the `NOLINT` needed in this case but not the others?",
756205,tzik,https://api.github.com/repos/grpc/grpc/pulls/18176,260875755,2019-02-27T18:09:50Z,src/core/ext/filters/client_channel/lb_policy.h,"@@ -261,8 +260,7 @@ class LoadBalancingPolicy : public InternallyRefCounted<LoadBalancingPolicy> {   /// Note that the LB policy gets the set of addresses from the   /// GRPC_ARG_SERVER_ADDRESS_LIST channel arg.   virtual void UpdateLocked(const grpc_channel_args& args,-                            RefCountedPtr<Config> lb_config) {-    std::move(lb_config);  // Suppress clang-tidy complaint.+                            RefCountedPtr<Config> lb_config) {  // NOLINT","The [implementation of performance-unnecessary-value-param](https://github.com/llvm-mirror/clang-tools-extra/blob/0b9bba1a26c3862a0d6ac24bba7fb8b1a15f5c80/clang-tidy/performance/UnnecessaryValueParamCheck.cpp#L80) warns only when the parameter [isExpensiveToCopy](https://github.com/llvm-mirror/clang-tools-extra/blob/master/clang-tidy/utils/TypeTraits.cpp#L41). If the parameter has deleted copy ctor, it's not expensive to copy for clang-tidy.IIUC, LoadBalancingPolicy::Args and UniquePtr didn't hit the check because their copy ctor is deleted.",OK
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/18156,261287657,2019-02-28T16:52:36Z,test/cpp/interop/client.cc,"@@ -92,17 +93,68 @@ DEFINE_int32(soak_iterations, 1000, DEFINE_int32(iteration_interval, 10,              ""The interval in seconds between rpcs. This is used by ""              ""long_connection test"");+DEFINE_string(additional_metadata, """",+              ""Additional metadata to send in each request, as a ""+              ""semicolon-separated list of key:value pairs."");  using grpc::testing::CreateChannelForTestCase; using grpc::testing::GetServiceAccountJsonKey; using grpc::testing::UpdateActions; +namespace {++// Parse the contents of FLAGS_additional_metadata into a map. Allow+// alphanumeric characters and dashes in keys, and any character but semicolons+// in values.+std::multimap<grpc::string, grpc::string> ParseAdditionalMetadataFlag(+    const grpc::string& flag) {+  std::multimap<grpc::string, grpc::string> additional_metadata;++  // Key in group 1; value in group 2.+  std::regex re(""([-a-zA-Z0-9]+):([^;]*);?"");","We mostly just hand-rolled stuff...For a similar function, see https://github.com/grpc/grpc/blob/0fc01a302f03c313d33492439366821cb66e0eb6/test/cpp/util/grpc_tool.cc#L125",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18216,261789678,2019-03-01T23:25:23Z,src/core/lib/gprpp/memory.h,"@@ -71,7 +71,7 @@ inline UniquePtr<T> MakeUnique(Args&&... args) {  // an allocator that uses gpr_malloc/gpr_free template <class T>-class Allocator {+class Allocator : public std::allocator<T> {","Why is this needed?  This is only used in templates, so as long as `Allocator` provides the same API as `std::allocator`, it should not need to actually inherit from it.",OK
42048362,mhaidrygoog,https://api.github.com/repos/grpc/grpc/pulls/18216,261802339,2019-03-02T00:54:50Z,src/core/lib/gprpp/memory.h,"@@ -71,7 +71,7 @@ inline UniquePtr<T> MakeUnique(Args&&... args) {  // an allocator that uses gpr_malloc/gpr_free template <class T>-class Allocator {+class Allocator : public std::allocator<T> {","Your right, I assumed it must inherit to be a type of allocator but the code worked without the inheritance.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18199,262202680,2019-03-04T19:15:09Z,test/core/surface/byte_buffer_reader_test.cc,"@@ -271,6 +338,12 @@ int main(int argc, char** argv) {   test_read_one_slice();   test_read_one_slice_malloc();   test_read_none_compressed_slice();+  test_peek_one_slice();+  test_peek_one_slice_malloc();+  test_peek_none_compressed_slice();+  test_read_one_slice();+  test_read_one_slice_malloc();+  test_read_none_compressed_slice();",Why are the test_read tests duplicated?,
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/18222,262294210,2019-03-04T23:51:38Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -431,17 +448,20 @@ void PickFirst::PickFirstSubchannelData::ProcessConnectivityChangeLocked(       size_t next_index =           (sd->Index() + 1) % subchannel_list()->num_subchannels();       sd = subchannel_list()->subchannel(next_index);-      // Case 1: Only set state to TRANSIENT_FAILURE if we've tried-      // all subchannels.-      if (sd->Index() == 0 && subchannel_list() == p->subchannel_list_.get()) {+      // If we're tried all subchannels, set state to TRANSIENT_FAILURE.+      if (sd->Index() == 0) {         p->channel_control_helper()->RequestReresolution();","We should only re-resolve if this is the most recently created subchannel list, as discussed in https://github.com/grpc/grpc/pull/18021 https://reviewable.io/reviews/grpc/grpc/18021#-LZtoY2Q9PCo_dhxZNLm?",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/18246,262348301,2019-03-05T05:03:32Z,src/python/grpcio/grpc/_cython/_cygrpc/time.pyx.pxi,"@@ -12,14 +12,16 @@ # See the License for the specific language governing permissions and # limitations under the License. +from libc.math cimport modf as _cmodf, fabs as _cfabs  cdef gpr_timespec _timespec_from_time(object time):   cdef gpr_timespec timespec+  cdef double whole_part   if time is None:     return gpr_inf_future(GPR_CLOCK_REALTIME)   else:-    timespec.seconds = time-    timespec.nanoseconds = (time - float(timespec.seconds)) * 1e9+    timespec.nanoseconds = <int32_t>(_cfabs(_cmodf(time, &whole_part)) * 1e9)",Please check the `to_seconds_from_sub_second_time` function:https://github.com/grpc/grpc/blob/0d9e6d1e363846066b79dc41416ee374ca1657d1/src/core/lib/gpr/time.cc#L82Seems our team does spent a lot of time to design negative time representation.,OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/18246,262355871,2019-03-05T05:54:12Z,src/python/grpcio/grpc/_cython/_cygrpc/time.pyx.pxi,"@@ -12,14 +12,16 @@ # See the License for the specific language governing permissions and # limitations under the License. +from libc.math cimport modf as _cmodf, fabs as _cfabs  cdef gpr_timespec _timespec_from_time(object time):   cdef gpr_timespec timespec+  cdef double whole_part   if time is None:     return gpr_inf_future(GPR_CLOCK_REALTIME)   else:-    timespec.seconds = time-    timespec.nanoseconds = (time - float(timespec.seconds)) * 1e9+    timespec.nanoseconds = <int32_t>(_cfabs(_cmodf(time, &whole_part)) * 1e9)",How about testing if negative deadline for RPC `timeout` or Completion Queue `poll` will result in crashing the whole process?,
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/16457,262719094,2019-03-05T22:31:06Z,tools/distrib/python/grpcio_tools/setup.py,"@@ -193,6 +193,7 @@ def extension_modules():     url='https://grpc.io',     license='Apache License 2.0',     classifiers=CLASSIFIERS,+    long_description=open('README.rst').read(),",Can we add [`long_description_content_type='text/x-rst'`](https://packaging.python.org/guides/making-a-pypi-friendly-readme/#including-your-readme-in-your-package-s-metadata) to indicate that the `long_description` is restructured text?,
12239891,karthikravis,https://api.github.com/repos/grpc/grpc/pulls/18220,262733206,2019-03-05T23:20:35Z,test/cpp/end2end/end2end_test.cc,"@@ -64,6 +64,11 @@ using std::chrono::system_clock;     }                   \   } while (0) +namespace grpc_impl {++class ResourceQuota;","https://github.com/grpc/grpc/blob/6dcf6d164510a66efa831f2620e6511ffda0eba1/test/cpp/end2end/end2end_test.cc#L1941The class ResourceQuotaEnd2endTest has a member ""ResourceQuota server_resource_quota_;"" which requires this forward declaration. Since the whole other test is in namespace grpc, I moved the forward declaration out above this into namespace grpc_impl.",OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/18277,263060982,2019-03-06T17:55:43Z,src/python/grpcio/grpc/_cython/_cygrpc/call.pyx.pxi,"@@ -86,7 +86,8 @@ cdef class Call:    def __dealloc__(self):     if self.c_call != NULL:-      grpc_call_unref(self.c_call)+      with nogil:","You could also lift the `with nogil` statement up to include the conditional. It probably wouldn't make *too* big of an impact on performance, but it seems to be possible since `self.c_call` is `cdef`.",
41599993,billfeng327,https://api.github.com/repos/grpc/grpc/pulls/18285,263189407,2019-03-07T00:03:34Z,test/cpp/naming/generate_resolver_component_tests.bzl,"@@ -33,6 +33,7 @@ def generate_resolver_component_tests():             ""//:gpr"",             ""//test/cpp/util:test_config"",         ],+        tags = [""exclude_windows""],","They heavily rely on POSIX. Each target needs to go through significant changes on thread handling, network stack, file I/O, etc. to be able to run on Windows with MSVC. I'm not anticipating that to be done any time soon.",
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/18285,263192384,2019-03-07T00:17:46Z,test/cpp/naming/generate_resolver_component_tests.bzl,"@@ -33,6 +33,7 @@ def generate_resolver_component_tests():             ""//:gpr"",             ""//test/cpp/util:test_config"",         ],+        tags = [""exclude_windows""],","I mean, feel free to create issues to list what'd be left to do for Windows, yes :-) But don't flag it as P0 or P1.",OK
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/18285,263192609,2019-03-07T00:18:59Z,bazel/grpc_build_system.bzl,"@@ -180,7 +189,7 @@ def grpc_cc_test(name, srcs = [], deps = [], external_deps = [], args = [], data     else:         native.cc_test(**args) -def grpc_cc_binary(name, srcs = [], deps = [], external_deps = [], args = [], data = [], language = ""C++"", testonly = False, linkshared = False, linkopts = []):+def grpc_cc_binary(name, srcs = [], deps = [], external_deps = [], args = [], data = [], language = ""C++"", testonly = False, linkshared = False, linkopts = [], tags = []):",Please make an internal CL to add this parameter before merging this PR.,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18285,263202690,2019-03-07T01:08:06Z,test/cpp/naming/generate_resolver_component_tests.bzl,"@@ -33,6 +33,7 @@ def generate_resolver_component_tests():             ""//:gpr"",             ""//test/cpp/util:test_config"",         ],+        tags = [""exclude_windows""],","Actually, unless the tests have changed recently, we should be able to build and run `address_sorting_test*` and `resolver_component_test*` on Windows (I added Windows support to those tests a while back for manual runs). Is it possible to remove the `exclude_windows` tags from those targets?I definitely agree that the `resolver_component_tests_runner_invoker*` targets need significant refactoring to run on Windows though - I'll track that as something to do later.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18285,263203117,2019-03-07T01:10:13Z,test/cpp/naming/generate_resolver_component_tests.bzl,"@@ -33,6 +33,7 @@ def generate_resolver_component_tests():             ""//:gpr"",             ""//test/cpp/util:test_config"",         ],+        tags = [""exclude_windows""],","edit: for  `resolver_component_test*`, we can't ""run"" this target out of the box, but it should compile on Windows",
8525143,yanqd0,https://api.github.com/repos/grpc/grpc/pulls/16457,263405103,2019-03-07T14:27:30Z,tools/distrib/python/grpcio_tools/setup.py,"@@ -193,6 +193,7 @@ def extension_modules():     url='https://grpc.io',     license='Apache License 2.0',     classifiers=CLASSIFIERS,+    long_description=open('README.rst').read(),","Thanks for your advice.```shell$ twine check dist/*Checking distribution dist/grpcio_tools-1.20.0.dev0-py2-none-any.whl: warning: `long_description_content_type` missing.  defaulting to `text/x-rst`.PassedChecking distribution dist/grpcio_tools-1.20.0.dev0-py3-none-any.whl: warning: `long_description_content_type` missing.  defaulting to `text/x-rst`.Passed```My current solution is simple and working.- The default `long_description_content_type` is `text/x-rst`.- The file will be closed when this `setup.py` exited, which is not too long.Of course, I like to make it better. But the original forked repository was deleted by accident, I have to send a new pull request #18226 to update.Besides, `with` is not a good solution in this case. It will make the `setup.py` more complex. `setup.cfg` is a better solution, even when merging more files. For example:```cfg[metadata]long_description = file: README.rst, CHANGELOG.rstlong_description_content_type = text/x-rst```My new pull request is something like that.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18285,263448134,2019-03-07T15:59:02Z,tools/remote_build/windows.bazelrc,"@@ -0,0 +1,2 @@+build --test_tag_filters=-exclude_windows+build --build_tag_filters=-exclude_windows","if this file is really needed, it seems to be misplaced: the name `remote_build/windows.bazelrc` kind of implies that using this configuration will run a windows RBE build (which is currently not the case).Ideally, the windows RBE (and local bazel) runs will be run exactly in the same way as the linux  builds:- tools/remote_build/manual.bazelrc would be used to spin up RBE builds manually- tools/remote_build/kokoro.bazelrc would be used by kokoro jobs that run windows RBE builds.I understand this might be hard to achieve from the very start, but if we need some intermediate configuration files, we should make that clear (at least with a comment). ",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18285,263526394,2019-03-07T19:10:47Z,tools/remote_build/windows.bazelrc,"@@ -0,0 +1,2 @@+build --test_tag_filters=-exclude_windows+build --build_tag_filters=-exclude_windows","Yeah, I get this is not for RBE, that's why I'm complaining about adding windows.bazelrc file under ""remote_build"" (and I'm also trying to explain how the future configuration layout should look like and trying to make sure that this PR is aligned with that idea).Just a nit: ""not seeing any other place for .bazelrc files"" doesn't mean that the bazelrc file automatically belongs here.I'm probably fine with the windows.bazelrc file being here temporarily, but there needs to be a cleanup phase because I don't think the current layout of windows bazelrc files is the best one.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18285,263536665,2019-03-07T19:38:55Z,test/core/iomgr/BUILD,"@@ -81,6 +81,7 @@ grpc_cc_test(         ""//:grpc"",         ""//test/core/util:grpc_test_util"",     ],+    tags = [""exclude_windows""],","nit:e.g. tensorflow is using the tag name ""no_windows"" instead - maybe that's better naming for the tag? https://github.com/tensorflow/tensorflow/blob/ec2dc801e89547ef854b26bc7fe3f8c1adfad87a/tensorflow/compiler/tf2tensorrt/BUILD#L34""no_windows"" also seems to be used by the bazel team itself, so it feels to be a more standard choice than ""exclude_windows"":https://github.com/bazelbuild/bazel/blob/677ba95e881707b121ce6588883b3ab68ed4c533/src/test/shell/bazel/BUILD#L751I also noticed that we could define a bazel testsuite for windows tests, which would allow us to specify the tags to exclude directly - that's good to know:https://github.com/bazelbuild/bazel/blob/677ba95e881707b121ce6588883b3ab68ed4c533/src/test/shell/bazel/BUILD#L759",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18285,263539363,2019-03-07T19:46:30Z,bazel/grpc_build_system.bzl,"@@ -28,6 +28,12 @@ load(""//bazel:cc_grpc_library.bzl"", ""cc_grpc_library"") # The set of pollers to test against if a test exercises polling POLLERS = [""epollex"", ""epoll1"", ""poll"", ""poll-cv""] +def is_msvc():","I will leave up to you, but to me it feels that trying to suport cygwin gcc is asking for trouble - we don't really support it, so not worth the work trying to enable it here IMHO.this doc doesn't mention mingw or cygwin at all:https://github.com/grpc/grpc/blob/master/BUILDING.md#grpc-c---building-from-source",OK
14166415,sanjaypujare,https://api.github.com/repos/grpc/grpc/pulls/18301,263912854,2019-03-08T20:06:03Z,package.xml,"@@ -13,8 +13,8 @@  <date>2018-01-19</date>  <time>16:06:07</time>  <version>-  <release>1.19.0</release>-  <api>1.19.0</api>+  <release>1.19.1</release>+  <api>1.19.1</api>","@stanley-cheung do you know why we are updating both the api and release versions? If the api has not changed, we should not bump it up, right? Not a big issue for this PR though...",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/18246,263958208,2019-03-08T22:58:02Z,src/python/grpcio/grpc/_cython/_cygrpc/time.pyx.pxi,"@@ -15,10 +15,9 @@ cdef gpr_timespec _timespec_from_time(object time):   return (gpr_inf_future(GPR_CLOCK_REALTIME)           if time is None else-          gpr_time_from_nanos(<int64_t>(time * 1e9), GPR_CLOCK_REALTIME))+          gpr_time_from_millis(<int64_t>(int(float(time) * 1000)), GPR_CLOCK_REALTIME)","The clock-type mismatch is caused by the OverflowError. This version still causing test case to fail in Windows:```Cythongpr_time_from_nanos(<int64_t>(time * 1e9), GPR_CLOCK_REALTIME)```That one are just proposed fix... To see if the Windows test are passed.I guess Cython is converting Python `int` into Cpp `long` by default. The root cause is that the length of `long` is shorter in Windows.https://docs.microsoft.com/en-us/cpp/cpp/data-type-ranges?view=vs-2017What I can do now is trying various ways to make Cython to covert a Python `int` directly into `int64_t`.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/18312,263963433,2019-03-08T23:24:54Z,examples/python/multiprocessing/client.py,"@@ -0,0 +1,95 @@+# Copyright 2019 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""An example of multiprocessing concurrency with gRPC.""""""++from __future__ import absolute_import+from __future__ import division+from __future__ import print_function++import argparse+import atexit+import grpc+import logging+import multiprocessing+import operator+import os+import time+import sys++import prime_pb2+import prime_pb2_grpc++_PROCESS_COUNT = 8+_MAXIMUM_CANDIDATE = 10000++# Each worker process initializes a single channel after forking.+_worker_channel_singleton = None+_worker_stub_singleton = None++_LOGGER = logging.getLogger(__name__)+++def _initialize_worker(server_address):+    global _worker_channel_singleton+    global _worker_stub_singleton+    _LOGGER.info('Initializing worker process.')+    _worker_channel_singleton = grpc.insecure_channel(server_address)+    _worker_stub_singleton = prime_pb2_grpc.PrimeCheckerStub(+        _worker_channel_singleton)+    atexit.register(_shutdown_worker)+++def _shutdown_worker():","Should we move this function up to satisfy ""define-before-use"" pattern?",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/18246,263964712,2019-03-08T23:32:35Z,src/python/grpcio/grpc/_cython/_cygrpc/time.pyx.pxi,"@@ -15,10 +15,9 @@ cdef gpr_timespec _timespec_from_time(object time):   return (gpr_inf_future(GPR_CLOCK_REALTIME)           if time is None else-          gpr_time_from_nanos(<int64_t>(time * 1e9), GPR_CLOCK_REALTIME))+          gpr_time_from_millis(<int64_t>(int(float(time) * 1000)), GPR_CLOCK_REALTIME)","It's hard for me to experiment without Windows on hand, but can you please explain what does Cython try to convert to `long` that causes failure? `<int64_t>(time*1e9)` has an intermediate conversion to `long`?",
3584893,jadekler,https://api.github.com/repos/grpc/grpc/pulls/18003,264436611,2019-03-11T21:23:38Z,doc/statuscodes.md,"@@ -1,13 +1,35 @@ # Status codes and their use in gRPC -gRPC uses a set of well defined status codes as part of the RPC API. All-RPCs started at a client return  a `status` object composed of an integer+gRPC uses a set of well defined status codes as part of the RPC API. These+statuses are defined as such:++| Code | Number | Description | Closest HTTP Mapping |+|------------------|--------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------|+| OK | 0 | Not an error; returned on success. | 200 OK |+| CANCELLED | 1 | The operation was cancelled, typically by the caller. | 499 Client Closed Request |+| UNKNOWN | 2 | Unknown error. For example, this error may be returned when a `Status` value received from another address space belongs to an error space that is not known in this address space. Also errors raised by APIs that do not return enough error information may be converted to this error. | 500 Internal Server Error |+| INVALID_ARGUMENT | 3 | The client specified an invalid argument. Note that this differs from `FAILED_PRECONDITION`. `INVALID_ARGUMENT` indicates arguments that are problematic regardless of the state of the system (e.g., a malformed file name). | 400 Bad Request |     +| DEADLINE_EXCEEDED | 4 | The deadline expired before the operation could complete. For operations that change the state of the system, this error may be returned even if the operation has completed successfully. For example, a successful response from a server could have been delayed long | 504 Gateway Timeout |+| NOT_FOUND | 5 | Some requested entity (e.g., file or directory) was not found. Note to server developers: if a request is denied for an entire class of users, such as gradual feature rollout or undocumented whitelist, `NOT_FOUND` may be used. If a request is denied for some users within a class of users, such as user-based access control, `PERMISSION_DENIED` must be used. | 404 Not Found |+| ALREADY_EXISTS | 6 | The entity that a client attempted to create (e.g., file or directory) already exists. | 409 Conflict |+| PERMISSION_DENIED | 7 | The caller does not have permission to execute the specified operation. `PERMISSION_DENIED` must not be used for rejections caused by exhausting some resource (use `RESOURCE_EXHAUSTED` instead for those errors). `PERMISSION_DENIED` must not be used if the caller can not be identified (use `UNAUTHENTICATED` instead for those errors). This error code does not imply the request is valid or the requested entity exists or satisfies other pre-conditions. | 403 Forbidden |+| UNAUTHENTICATED | 16 | The request does not have valid authentication credentials for the operation. | 401 Unauthorized |",That's just how it's defined in codes.proto (internal and [external](https://github.com/googleapis/googleapis/blob/master/google/rpc/code.proto)). I figured being consistent is the best approach.,OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18329,264534180,2019-03-12T06:18:13Z,tools/run_tests/sanity/check_submodules.sh,"@@ -38,7 +38,7 @@ cat << EOF | awk '{ print $1 }' | sort > ""$want_submodules""  ec44c6c1675c25b9827aacd08c02433cccde7780 third_party/googletest (release-1.8.0)  6599cac0965be8e5a835ab7a5684bbef033d5ad0 third_party/libcxx (heads/release_60)  9245d481eb3e890f708ff2d7dadf2a10c04748ba third_party/libcxxabi (heads/release_60)- 48cb18e5c419ddd23d9badcfe4e9df7bde1979b2 third_party/protobuf (v3.6.0.1-37-g48cb18e5)+ 582743bf40c5d3639a70f98f183914a2c0cd0680 third_party/protobuf (v3.6.0.1-37-g48cb18e5)","nit: probably need to update `(v3.6.0.1-37-g48cb18e5)` to the new tag... Also, since it looks like these git ref's in parentheses are unused, maybe they can be removed, or placed in comments.",OK
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/18336,264776059,2019-03-12T16:46:11Z,include/grpc/grpc_security.h,"@@ -191,6 +191,12 @@ typedef struct {      try to get the roots set by grpc_override_ssl_default_roots. Eventually,      if all these fail, it will try to get the roots from a well-known place on      disk (in the grpc install directory).++     It is a known issue that when the default root certificates are offered+     with this parameter, occasionally an excessive amount of memory (~10MB) is","This is inaccurate and misleading.  The root cert store is ~1MB. But gRPC opens multiple subchannels, each subchannel has its own SSL context and root store. I would rephrase asgRPC has implemented root certificates cache if the underlying OpenSSL library supports it. The gRPC root certificates cache is only applicable on the default root certificates. If user provides his or her own pem_root_certs when creating an SSL credential object, gRPC would not be able to cache it.",OK
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/18156,265211014,2019-03-13T16:15:13Z,test/cpp/interop/client.cc,"@@ -92,17 +92,93 @@ DEFINE_int32(soak_iterations, 1000, DEFINE_int32(iteration_interval, 10,              ""The interval in seconds between rpcs. This is used by ""              ""long_connection test"");+DEFINE_string(additional_metadata, """",+              ""Additional metadata to send in each request, as a ""+              ""semicolon-separated list of key:value pairs."");  using grpc::testing::CreateChannelForTestCase; using grpc::testing::GetServiceAccountJsonKey; using grpc::testing::UpdateActions; +namespace {++// Parse the contents of FLAGS_additional_metadata into a map. Allow+// alphanumeric characters and dashes in keys, and any character but semicolons+// in values. On failure, log an error and return false.+bool ParseAdditionalMetadataFlag(+    const grpc::string& flag,+    std::multimap<grpc::string, grpc::string>* additional_metadata) {+  size_t start_pos = 0;+  while (start_pos < flag.length()) {+    size_t colon_pos = flag.find(':', start_pos);+    if (colon_pos == grpc::string::npos) {+      gpr_log(GPR_ERROR,+              ""Couldn't parse metadata flag: extra characters at end of flag"");+      return false;+    }+    size_t semicolon_pos = flag.find(';', colon_pos);++    grpc::string key = flag.substr(start_pos, colon_pos - start_pos);+    grpc::string value =+        flag.substr(colon_pos + 1, semicolon_pos - colon_pos - 1);++    constexpr char alphanum_and_hyphen[] =+        ""-0123456789""+        ""abcdefghijklmnopqrstuvwxyz""+        ""ABCDEFGHIJKLMNOPQRSTUVWXYZ"";",grpc does not support upper-case letters in metadata keys.,OK
2030323,JunTaoLuo,https://api.github.com/repos/grpc/grpc/pulls/18355,265270117,2019-03-13T18:23:44Z,src/csharp/Grpc.Tools/ProtoCompile.cs,"@@ -322,6 +322,7 @@ protected override string GenerateResponseFileCommands()             {                 cmd.AddArg(proto.ItemSpec);             }+            cmd.AddSwitchMaybe(""error_format"", ""msvs"");",@jtattermusch where is the source code for protoc.exe? I see it being downloaded from maven: https://github.com/protocolbuffers/protobuf/blob/master/csharp/build_tools.sh#L43 but I don't know where the source code lives. It looks like the error format is not correct so the Error list in VS cannot link to the correct location in code.,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18355,265638641,2019-03-14T15:51:33Z,src/csharp/Grpc.Tools/ProtoCompile.cs,"@@ -322,6 +322,7 @@ protected override string GenerateResponseFileCommands()             {                 cmd.AddArg(proto.ItemSpec);             }+            cmd.AddSwitchMaybe(""error_format"", ""msvs"");","Sources for protoc.exe are in https://github.com/protocolbuffers/protobuf, but we are actually building protoc.exe ourselves (from the third_party/protobuf git submodule) while building  the native artifacts before we proceed to building the nugets.https://github.com/grpc/grpc/blob/7095e051f2183b632aac241c27cf6b53b69d50e9/tools/run_tests/artifacts/artifact_targets.py#L301",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18356,265659613,2019-03-14T16:35:18Z,src/csharp/Grpc.Tools/build/_protobuf/Google.Protobuf.Tools.targets,"@@ -80,7 +80,7 @@            >$(Protobuf_PackagedToolsPath)/$(Protobuf_ToolsOs)_$(Protobuf_ToolsCpu)/protoc</Protobuf_ProtocFullPath>     </PropertyGroup> -    <Error Condition="" '$(DesignTimeBuild)' != 'true' and '$(PROTOBUF_PROTOC)' == ''+    <Error Condition="" '$(DisableGrpcDesignTimeBuild)' != 'true' and '$(PROTOBUF_PROTOC)' == ''","naming: this is for protobuf code generation, so probably shouldn't have  `Grpc` in the name.`DisableProtobufDesignTimeBuild`?",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18327,266091068,2019-03-15T18:00:28Z,src/csharp/Grpc.Core/Internal/NativeCallbackDispatcher.cs,"@@ -0,0 +1,121 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Concurrent;+using System.Diagnostics;+using System.IO;+using System.Runtime.InteropServices;+using System.Threading;+using System.Collections.Generic;+using Grpc.Core.Logging;++namespace Grpc.Core.Internal+{+    internal delegate int UniversalNativeCallback(IntPtr arg0, IntPtr arg1, IntPtr arg2, IntPtr arg3, IntPtr arg4, IntPtr arg5);++    internal delegate int NativeCallbackDispatcherCallback(IntPtr tag, IntPtr arg0, IntPtr arg1, IntPtr arg2, IntPtr arg3, IntPtr arg4, IntPtr arg5);++    internal class NativeCallbackDispatcher+    {+        static readonly ILogger Logger = GrpcEnvironment.Logger.ForType<NativeCallbackDispatcher>();+        static readonly object staticLock = new object();+        static readonly AtomicCounter atomicCounter = new AtomicCounter();+        static readonly ConcurrentDictionary<IntPtr, UniversalNativeCallback> registry = new ConcurrentDictionary<IntPtr, UniversalNativeCallback>();++        static NativeCallbackDispatcherCallback dispatcherCallback;++        public static void Init(NativeMethods native)+        {+            lock (staticLock)+            {+                if (dispatcherCallback == null)+                {+                    dispatcherCallback = new NativeCallbackDispatcherCallback(HandleDispatcherCallback);+                    native.grpcsharp_native_callback_dispatcher_init(dispatcherCallback);+                }+            }+        }++        public static NativeCallbackRegistration RegisterCallback(UniversalNativeCallback callback)+        {+            while (true)+            {+                // TODO: retries might not work well on 32-bit","I still need to address this one, in theory finding the next free available tag on 32-bit can take long time. (if more than 2 billion tags are used during the process' lifetime, which is unlikely, but could happen).On 64-bit we are basically guaranteed never to run out of tags.",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18384,266110335,2019-03-15T18:55:41Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc,"@@ -145,6 +143,8 @@ void grpc_ares_complete_request_locked(grpc_ares_request* r) {   ServerAddressList* addresses = r->addresses_out->get();   if (addresses != nullptr) {     grpc_cares_wrapper_address_sorting_sort(addresses);+    GRPC_ERROR_UNREF(r->error);","This is an interesting case, but in the example case that an A lookup fails, but the corresponding AAAA lookup succeeds, I think we want to only log the A lookup failure in the tracer.The reason being is that it's legitimate to have an ipv4-only or ipv6-only service, and for e.g. an ipv6-only service, A record queries will always result in a no-error/no-data responses. Specifically, A record queries will come back with a DNS rcodes of `NOERROR`,  but they will have a zero-length ANSWER section. When c-ares parses such a response, it will return a [c-ares status of ENODATA](https://github.com/c-ares/c-ares/blob/master/ares_query.c#L165), and then we'll trace log a ""DNS server returned answer with no data"" log message. So, if we turn that trace log into e.g. an ERROR log, then users of ipv4-only and ipv6-only services will get spam logs.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18384,266124719,2019-03-15T19:47:49Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc,"@@ -145,6 +143,8 @@ void grpc_ares_complete_request_locked(grpc_ares_request* r) {   ServerAddressList* addresses = r->addresses_out->get();   if (addresses != nullptr) {     grpc_cares_wrapper_address_sorting_sort(addresses);+    GRPC_ERROR_UNREF(r->error);","Makes sense.  I guess as long as we've got a tracer message for it, it's fine.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18327,266162926,2019-03-15T22:16:47Z,src/csharp/Grpc.Core/Internal/NativeCallbackDispatcher.cs,"@@ -0,0 +1,121 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Concurrent;+using System.Diagnostics;+using System.IO;+using System.Runtime.InteropServices;+using System.Threading;+using System.Collections.Generic;+using Grpc.Core.Logging;++namespace Grpc.Core.Internal+{+    internal delegate int UniversalNativeCallback(IntPtr arg0, IntPtr arg1, IntPtr arg2, IntPtr arg3, IntPtr arg4, IntPtr arg5);++    internal delegate int NativeCallbackDispatcherCallback(IntPtr tag, IntPtr arg0, IntPtr arg1, IntPtr arg2, IntPtr arg3, IntPtr arg4, IntPtr arg5);++    internal class NativeCallbackDispatcher+    {+        static readonly ILogger Logger = GrpcEnvironment.Logger.ForType<NativeCallbackDispatcher>();+        static readonly object staticLock = new object();+        static readonly AtomicCounter atomicCounter = new AtomicCounter();+        static readonly ConcurrentDictionary<IntPtr, UniversalNativeCallback> registry = new ConcurrentDictionary<IntPtr, UniversalNativeCallback>();++        static NativeCallbackDispatcherCallback dispatcherCallback;++        public static void Init(NativeMethods native)+        {+            lock (staticLock)+            {+                if (dispatcherCallback == null)+                {+                    dispatcherCallback = new NativeCallbackDispatcherCallback(HandleDispatcherCallback);+                    native.grpcsharp_native_callback_dispatcher_init(dispatcherCallback);+                }+            }+        }++        public static NativeCallbackRegistration RegisterCallback(UniversalNativeCallback callback)+        {+            while (true)+            {+                // TODO: retries might not work well on 32-bit","Very unlikely but do we have a guarantee that the native object allocator is limited to creating `sizeof(long)` objects (the range of `AtomicCounter`). That is, is the C# type `long` always guaranteed to be equal to e.g. the size of C type `void*`?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18327,266164198,2019-03-15T22:23:44Z,src/csharp/Grpc.Core/Internal/NativeCallbackDispatcher.cs,"@@ -0,0 +1,121 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Concurrent;+using System.Diagnostics;+using System.IO;+using System.Runtime.InteropServices;+using System.Threading;+using System.Collections.Generic;+using Grpc.Core.Logging;++namespace Grpc.Core.Internal+{+    internal delegate int UniversalNativeCallback(IntPtr arg0, IntPtr arg1, IntPtr arg2, IntPtr arg3, IntPtr arg4, IntPtr arg5);++    internal delegate int NativeCallbackDispatcherCallback(IntPtr tag, IntPtr arg0, IntPtr arg1, IntPtr arg2, IntPtr arg3, IntPtr arg4, IntPtr arg5);++    internal class NativeCallbackDispatcher+    {+        static readonly ILogger Logger = GrpcEnvironment.Logger.ForType<NativeCallbackDispatcher>();+        static readonly object staticLock = new object();+        static readonly AtomicCounter atomicCounter = new AtomicCounter();+        static readonly ConcurrentDictionary<IntPtr, UniversalNativeCallback> registry = new ConcurrentDictionary<IntPtr, UniversalNativeCallback>();++        static NativeCallbackDispatcherCallback dispatcherCallback;++        public static void Init(NativeMethods native)+        {+            lock (staticLock)+            {+                if (dispatcherCallback == null)+                {+                    dispatcherCallback = new NativeCallbackDispatcherCallback(HandleDispatcherCallback);+                    native.grpcsharp_native_callback_dispatcher_init(dispatcherCallback);+                }+            }+        }++        public static NativeCallbackRegistration RegisterCallback(UniversalNativeCallback callback)+        {+            while (true)+            {+                // TODO: retries might not work well on 32-bit+                var tag = NextTag();+                if (registry.TryAdd(tag, callback))+                {+                    return new NativeCallbackRegistration(tag);+                }+            }+        }++        public static void UnregisterCallback(IntPtr tag)+        {+            registry.TryRemove(tag, out UniversalNativeCallback callback);","similarly to the other comment, a failure of `TryRemove` here seems to be an internal corruption that should cause a fatal crash",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18397,266178672,2019-03-16T00:05:10Z,bazel/grpc_deps.bzl,"@@ -147,16 +147,15 @@ def grpc_deps():     if ""com_github_gflags_gflags"" not in native.existing_rules():         http_archive(             name = ""com_github_gflags_gflags"",-            strip_prefix = ""gflags-30dbc81fb5ffdc98ea9b14b1918bfe4e8779b26e"",","I'm a bit concerned about the bazel and git submodule dependency versions diverging - from looking, all dependencies existing as both bazel deps and submodules are currently at the same version (with the exception of abseil cpp). This would create a new divergence",OK
41599993,billfeng327,https://api.github.com/repos/grpc/grpc/pulls/18397,266183678,2019-03-16T01:23:11Z,bazel/grpc_deps.bzl,"@@ -147,16 +147,15 @@ def grpc_deps():     if ""com_github_gflags_gflags"" not in native.existing_rules():         http_archive(             name = ""com_github_gflags_gflags"",-            strip_prefix = ""gflags-30dbc81fb5ffdc98ea9b14b1918bfe4e8779b26e"",",dependency bumped per your request,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18410,266216356,2019-03-16T21:52:17Z,src/core/ext/filters/client_channel/channel_connectivity.cc,"@@ -152,15 +152,18 @@ static void partly_done(state_watcher* w, bool due_to_completion,         w->error = error;       }       w->phase = CALLING_BACK_AND_FINISHED;-      grpc_cq_end_op(w->cq, w->tag, w->error, finished_completion, w,-                     &w->completion_storage);       break;     case CALLING_BACK_AND_FINISHED:       GPR_UNREACHABLE_CODE(return );       break;   }   gpr_mu_unlock(&w->mu); +  if (w->phase == CALLING_BACK_AND_FINISHED) {","Generally, if a decision is being made under a lock and not taking effect until after a lock, the best way to represent that is to capture the decision and all its state into local variables while still under the lock, and then do the action using those local variables after the lock. Otherwise, it is likely to lead to races. So I would think a more common use pattern inside the lock would be```end_op = true;end_op_cq = w->cq;end_op_tag = w->tag;end_op_error = w->error;end_op_completion_storage = &w->completion_storage;```etcand then at this point something like``` if (end_op) {  grpc_cq_end_op(end_op_cq, end_op_tag, end_op_error, finished_completion, w, end_op_completion_storage);}```",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18327,266630562,2019-03-18T20:36:09Z,src/csharp/Grpc.Core/Internal/NativeCallbackDispatcher.cs,"@@ -0,0 +1,101 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Concurrent;+using System.Diagnostics;+using System.IO;+using System.Runtime.InteropServices;+using System.Threading;+using System.Collections.Generic;+using Grpc.Core.Logging;++namespace Grpc.Core.Internal+{+    internal delegate int UniversalNativeCallback(IntPtr arg0, IntPtr arg1, IntPtr arg2, IntPtr arg3, IntPtr arg4, IntPtr arg5);++    internal delegate int NativeCallbackDispatcherCallback(IntPtr tag, IntPtr arg0, IntPtr arg1, IntPtr arg2, IntPtr arg3, IntPtr arg4, IntPtr arg5);++    internal class NativeCallbackDispatcher+    {+        static readonly ILogger Logger = GrpcEnvironment.Logger.ForType<NativeCallbackDispatcher>();+        static readonly object staticLock = new object();++        static NativeCallbackDispatcherCallback dispatcherCallback;++        public static void Init(NativeMethods native)+        {+            lock (staticLock)+            {+                if (dispatcherCallback == null)","Because `NativeCallbackDispatcher.Init` is only used during instantiation of the `NativeExtension` singleton, and because `NativeExtension` singleton is already initialized once and only once, under a lock, I think both `staticLock` and the null check on `dispatcherCallback` can be removed. (maybe even replace the null check with an assert that `dispatcherCallback` is null)",OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/18341,266682050,2019-03-18T23:35:27Z,include/grpcpp/impl/codegen/server_callback.h,"@@ -69,6 +69,31 @@ class ServerCallbackRpcController {   // Allow the method handler to push out the initial metadata before   // the response and status are ready   virtual void SendInitialMetadata(std::function<void(bool)>) = 0;++  /// SetCancelCallback passes in a callback to be called when the RPC is+  /// canceled for whatever reason (streaming calls have OnCancel instead). This+  /// is an advanced and uncommon use with several important restrictions.+  ///+  /// If code calls SetCancelCallback on an RPC, it must also call+  /// ClearCancelCallback before calling Finish on the RPC controller.+  ///+  /// The callback should generally be lightweight and nonblocking and primarily+  /// concerned with clearing application state related to the RPC or causing+  /// operations (such as cancellations) to happen on dependent RPCs.+  ///+  /// If the RPC is already canceled at the time that SetCancelCallback is+  /// called, the callback is invoked immediately.+  ///+  /// The cancellation callback may be executed concurrently with the method+  /// handler that invokes it but will certainly not issue or execute after the",What if the cancel callback is running and the user calls SetCancelCallback concurrently?  Then the cancel callback that's actually invoked won't technically be the last registered callback. I guess that's just a user error then?,OK
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/18435,267087575,2019-03-19T20:40:54Z,src/core/lib/iomgr/tcp_uv.cc,"@@ -218,26 +243,52 @@ static grpc_error* uv_socket_init(grpc_custom_socket* socket, int domain) {   if (error != GRPC_ERROR_NONE) {     return error;   }-  uv_socket->handle->data = socket;+  ((uv_handle_t*)uv_socket->handle.ptr)->data = socket;   socket->impl = uv_socket;   return GRPC_ERROR_NONE; }  static grpc_error* uv_socket_getpeername(grpc_custom_socket* socket,                                          const grpc_sockaddr* addr,                                          int* addr_len) {+  int err;   uv_socket_t* uv_socket = (uv_socket_t*)socket->impl;-  int err = uv_tcp_getpeername(uv_socket->handle,-                               (struct sockaddr*)IGNORE_CONST(addr), addr_len);+  if (uv_socket->handle_type == HANDLE_TYPE_PIPE) {+#ifdef GRPC_HAVE_UNIX_SOCKET+    struct sockaddr_un* un_addr = (struct sockaddr_un*)addr;+    size_t len = sizeof(un_addr->sun_path) - 1;+    err = uv_pipe_getpeername(uv_socket->handle.pipe, un_addr->sun_path, &len);+    *addr_len = len + sizeof(un_addr->sun_family) + 1;+    un_addr->sun_family = AF_UNIX;+#else+    err = ENOTSUP;+#endif+  } else {+    err = uv_tcp_getpeername(uv_socket->handle.tcp,+                             (struct sockaddr*)IGNORE_CONST(addr), addr_len);+  }   return tcp_error_create(""getpeername failed"", err); }  static grpc_error* uv_socket_getsockname(grpc_custom_socket* socket,                                          const grpc_sockaddr* addr,                                          int* addr_len) {+  int err;   uv_socket_t* uv_socket = (uv_socket_t*)socket->impl;-  int err = uv_tcp_getsockname(uv_socket->handle,-                               (struct sockaddr*)IGNORE_CONST(addr), addr_len);+  if (uv_socket->handle_type == HANDLE_TYPE_PIPE) {","Maybe split this out to a helper function. You're already having a duplicate of this a few lines above, and the readability is seriously decreasing due to the added `#ifdef` in the middle.Please consider defining two helper functions that are mutually exclusive with an `#ifdef` around them.",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/18440,267125000,2019-03-19T22:35:59Z,src/core/lib/surface/call.cc,"@@ -1035,9 +1035,15 @@ static void recv_trailing_filter(void* args, grpc_metadata_batch* b,         grpc_get_status_code_from_metadata(b->idx.named.grpc_status->md);     grpc_error* error = GRPC_ERROR_NONE;     if (status_code != GRPC_STATUS_OK) {-      error = grpc_error_set_int(-          GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Error received from peer""),-          GRPC_ERROR_INT_GRPC_STATUS, static_cast<intptr_t>(status_code));+      char* peer_msg = nullptr;+      char* peer = grpc_call_get_peer(call);+      gpr_asprintf(&peer_msg, ""Error received from peer %s"",+                   grpc_call_get_peer(call));",I wasn't expecting reviews that soon. I was being lazy and actually wanted to use the github tests on github to verify that the peer is being printed properly :),
8228229,kkm000,https://api.github.com/repos/grpc/grpc/pulls/18356,267169568,2019-03-20T02:51:21Z,src/csharp/Grpc.Tools/build/_protobuf/Google.Protobuf.Tools.targets,"@@ -80,7 +80,7 @@            >$(Protobuf_PackagedToolsPath)/$(Protobuf_ToolsOs)_$(Protobuf_ToolsCpu)/protoc</Protobuf_ProtocFullPath>     </PropertyGroup> -    <Error Condition="" '$(DesignTimeBuild)' != 'true' and '$(PROTOBUF_PROTOC)' == ''+    <Error Condition="" '$(DisableGrpcDesignTimeBuild)' != 'true' and '$(PROTOBUF_PROTOC)' == ''","FWIW, I meticulously prefixed all protoc-proper tooling lists and properties with `Protobuf_`, and gRPC-only those with `Grpc_` (or resp. `_Protobuf_` and `_Grpc_` as an indication to be treated as ""private, which I understand is the convention, albeit not explicit). All of these names are dumped into the immense global namespace of a build. When e. g. the NuGet MSBuild tooling was introduced, all the variable there are just all random CamelCase names all across the board, short and long, and not very much in line with the previous scripts. Changes of this scale got me worried; my thought was rather let Microsoft do how they see fit, but the `Prefix_Ident` style is rarely if ever used. I do not know how you guys handle that internally, with a database of used MSBuild IDs or something, but as a 3rd-party SWE I am always mindful of possible clashes.Should we maybe keep this convention, or we may clash soon or later. If the `_` in the middle looks too weird, then maybe it is still better to keep the `Protobuf` and `Grpc` prefixes?(and for internal packages here we're using `Namespace::Ident` or `Namespace::_Ident` style, but I went against that for gRPC/Protobuf, for it looks unusual at best, even if complies with the MSBuild XSD).",OK
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/18445,267382148,2019-03-20T14:55:44Z,src/core/lib/transport/transport.h,"@@ -111,10 +111,11 @@ void grpc_transport_move_stats(grpc_transport_stream_stats* from, // currently handling the batch).  Once a filter or transport passes control // of the batch to the next handler, it cannot depend on the contents of // this struct anymore, because the next handler may reuse it.-typedef struct {-  void* extra_arg;+struct grpc_handler_private_op_data {+  void* extra_arg = nullptr;   grpc_closure closure;-} grpc_handler_private_op_data;+  grpc_handler_private_op_data() { memset(&closure, 0, sizeof(closure)); }","Right, but in this case, I am simply shifting one bigger memset into this. There's memset in closures all over the codebase, so it's either this, or a much larger change that affects every single instance of closures in the codebase. I'd rather do this now to solve gcc8 build failures, and maybe we can migrate closures later and thus get rid of this memset in the process. ",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18407,267441335,2019-03-20T16:50:49Z,src/core/lib/iomgr/resource_quota.cc,"@@ -430,41 +431,43 @@ static bool rq_reclaim(grpc_resource_quota* resource_quota, bool destructive) {  * ru_slice: a slice implementation that is backed by a grpc_resource_user  */ -typedef struct {-  grpc_slice_refcount base;-  gpr_refcount refs;-  grpc_resource_user* resource_user;-  size_t size;-} ru_slice_refcount;--static void ru_slice_ref(void* p) {-  ru_slice_refcount* rc = static_cast<ru_slice_refcount*>(p);-  gpr_ref(&rc->refs);-}+namespace grpc_core { -static void ru_slice_unref(void* p) {-  ru_slice_refcount* rc = static_cast<ru_slice_refcount*>(p);-  if (gpr_unref(&rc->refs)) {+class RuSliceRefcount {+ public:+  static void Destroy(void* p) {+    auto* rc = static_cast<RuSliceRefcount*>(p);     grpc_resource_user_free(rc->resource_user, rc->size);     gpr_free(rc);   }-}+  RuSliceRefcount(grpc_resource_user* resource_user, size_t size)+      : base(grpc_core::SliceRefcount::Type::REGULAR, &refs,+             /*ensureRefNonZero=*/false, Destroy, this, &base),","The internal comment looks strange. As a suggestion, if you feel that this isn't self-documenting enough, consider switching that bool to an enum class with names like ENSURE_REF_NON_ZERO, ALLOW_REF_ZERO or something like that",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18407,267446141,2019-03-20T17:00:58Z,src/core/lib/slice/slice_intern.cc,"@@ -39,14 +41,7 @@ #define TABLE_IDX(hash, capacity) (((hash) >> LOG2_SHARD_COUNT) % (capacity)) #define SHARD_IDX(hash) ((hash) & ((1 << LOG2_SHARD_COUNT) - 1)) -typedef struct interned_slice_refcount {-  grpc_slice_refcount base;-  grpc_slice_refcount sub;-  size_t length;-  gpr_atm refcnt;-  uint32_t hash;-  struct interned_slice_refcount* bucket_next;-} interned_slice_refcount;+typedef grpc_core::InternedSliceRefcount interned_slice_refcount;","I can understand that this is to minimize the diff, but it looks odd to typedef something with C++-style naming/behavior to something with C-style naming/behavior. ",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18397,267575661,2019-03-20T22:43:12Z,cmake/gflags.cmake,"@@ -18,19 +18,18 @@ if(""${gRPC_GFLAGS_PROVIDER}"" STREQUAL ""module"")   endif()   if(EXISTS ""${GFLAGS_ROOT_DIR}/CMakeLists.txt"")     add_subdirectory(${GFLAGS_ROOT_DIR} third_party/gflags)-    if(TARGET gflags_static)-      set(_gRPC_GFLAGS_LIBRARIES gflags_static)-      set(_gRPC_GFLAGS_INCLUDE_DIR ""${CMAKE_CURRENT_BINARY_DIR}/third_party/gflags/include"")-    endif()+    set(_gRPC_GFLAGS_LIBRARIES gflags::gflags)+    set(_gRPC_GFLAGS_INCLUDE_DIR ""${CMAKE_CURRENT_BINARY_DIR}/third_party/gflags/include"")   else()     message(WARNING ""gRPC_GFLAGS_PROVIDER is \""module\"" but GFLAGS_ROOT_DIR is wrong"")   endif() elseif(""${gRPC_GFLAGS_PROVIDER}"" STREQUAL ""package"")   # Use ""CONFIG"" as there is no built-in cmake module for gflags.   find_package(gflags REQUIRED CONFIG)   if(TARGET gflags)",update the if  condition too?,
41599993,billfeng327,https://api.github.com/repos/grpc/grpc/pulls/18397,267579309,2019-03-20T22:59:01Z,cmake/gflags.cmake,"@@ -18,19 +18,18 @@ if(""${gRPC_GFLAGS_PROVIDER}"" STREQUAL ""module"")   endif()   if(EXISTS ""${GFLAGS_ROOT_DIR}/CMakeLists.txt"")     add_subdirectory(${GFLAGS_ROOT_DIR} third_party/gflags)-    if(TARGET gflags_static)-      set(_gRPC_GFLAGS_LIBRARIES gflags_static)-      set(_gRPC_GFLAGS_INCLUDE_DIR ""${CMAKE_CURRENT_BINARY_DIR}/third_party/gflags/include"")-    endif()+    set(_gRPC_GFLAGS_LIBRARIES gflags::gflags)","because the changes in gflags CMakeLists (included in the version bump) added the alias gflags::gflags for gflags_static and defaulted gflags to static (https://github.com/gflags/gflags/blob/master/CMakeLists.txt#L496), which is essentially identical to the existing logic.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18370,267585686,2019-03-20T23:28:59Z,tools/run_tests/run_interop_tests.py,"@@ -800,9 +851,15 @@ def cloud_to_prod_jobspec(language,         transport_security_options = [             '--custom_credentials_type=google_default_credentials'         ]+    elif transport_security == 'compute_engine_channel_creds' and str(","This was a bit weird. I've removed `google_default_credentials` as an option for a value of `--transport_security` argument to the whole script, but it's still a possible value for the parameter to `cloud_to_prod_jobspec`, because we're still appending ""cloud_to_prod_jobspec with google default credentials"" [to the list of test cases](https://github.com/grpc/grpc/blob/master/tools/run_tests/run_interop_tests.py#L1408).",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18397,267624129,2019-03-21T04:42:39Z,templates/CMakeLists.txt.template,"@@ -53,7 +53,7 @@         deps.append(""${_gRPC_BENCHMARK_LIBRARIES}"")       else:         deps.append(d)-    if target_dict.build == 'test' and target_dict.language == 'c++':+    if target_dict.build == 'test' or target_dict.build == 'private' and target_dict.language == 'c++':","relying on `or` and `and` operator precedence is bad, use parenthesis to make it explicit.",
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/18407,267648542,2019-03-21T07:56:53Z,src/core/lib/slice/slice_internal.h,"@@ -23,17 +23,168 @@  #include <grpc/slice.h> #include <grpc/slice_buffer.h>+#include <string.h> -inline const grpc_slice& grpc_slice_ref_internal(const grpc_slice& slice) {+#include ""src/core/lib/gpr/murmur_hash.h""+#include ""src/core/lib/gprpp/ref_counted.h""+#include ""src/core/lib/transport/static_metadata.h""++extern uint32_t static_metadata_hash_values[GRPC_STATIC_MDSTR_COUNT];+extern uint32_t g_hash_seed;+namespace grpc_core {++class SliceRefcount {+ public:+  enum Type { STATIC, INTERNED, REGULAR };",please prefer enum classes instead of direct enums.,
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/18407,267650136,2019-03-21T08:03:23Z,src/core/lib/slice/slice_internal.h,"@@ -23,17 +23,168 @@  #include <grpc/slice.h> #include <grpc/slice_buffer.h>+#include <string.h> -inline const grpc_slice& grpc_slice_ref_internal(const grpc_slice& slice) {+#include ""src/core/lib/gpr/murmur_hash.h""+#include ""src/core/lib/gprpp/ref_counted.h""+#include ""src/core/lib/transport/static_metadata.h""++extern uint32_t static_metadata_hash_values[GRPC_STATIC_MDSTR_COUNT];+extern uint32_t g_hash_seed;+namespace grpc_core {++class SliceRefcount {+ public:+  enum Type { STATIC, INTERNED, REGULAR };+  typedef void (*DestroyerFn)(void*);++  SliceRefcount() = default;+  SliceRefcount(SliceRefcount::Type type, RefCount* ref, bool ensureRefNonZero,+                DestroyerFn destroyer_fn, void* destroyer_arg,+                grpc_slice_refcount* sub)+      : sub_refcount_(sub),+        ref_type_(type),+        ref_(ref),+#ifndef NDEBUG+        ensureRefNonZero_(ensureRefNonZero),+#endif+        dest_fn_(destroyer_fn),+        destroy_fn_arg_(destroyer_arg) {+    // Nothing to do here.+  }+  SliceRefcount(grpc_slice_refcount* sub, Type type)+      : sub_refcount_(sub), ref_type_(type) {+    // Initializer for static.+  }++  Type getType() const { return ref_type_; }++  int Eq(const grpc_slice& a, const grpc_slice& b);++  uint32_t Hash(const grpc_slice& slice);+  void Ref() {+    if (!ref_) return;+#ifndef NDEBUG+    if (ensureRefNonZero_) {+      ref_->RefNonZero();+      return;+    }+#endif+    ref_->Ref();+  }+  void Unref() {+    if (!ref_) return;+    if (ref_->Unref()) {+      dest_fn_(destroy_fn_arg_);+    }+  }++  bool Validate() const { return ref_ != nullptr; }++ private:+  friend struct ::grpc_slice_refcount;++  grpc_slice_refcount* sub_refcount_ = nullptr;+  Type ref_type_ = REGULAR;+  RefCount* ref_ = nullptr;+#ifndef NDEBUG+  bool ensureRefNonZero_ = false;+#endif+  DestroyerFn dest_fn_ = nullptr;+  void* destroy_fn_arg_ = nullptr;+};++}  // namespace grpc_core++struct grpc_slice_refcount {+  grpc_slice_refcount() { impl_.sub_refcount_ = this; }+  grpc_slice_refcount(grpc_core::SliceRefcount::Type type,+                      grpc_core::RefCount* ref, bool ensureRefNonZero,+                      grpc_core::SliceRefcount::DestroyerFn destroyer_fn,+                      void* destroyer_arg, grpc_slice_refcount* sub)+      : impl_(type, ref, ensureRefNonZero, destroyer_fn, destroyer_arg, sub) {+    // Nothing to do here.+  }+  grpc_slice_refcount(grpc_slice_refcount* sub,+                      grpc_core::SliceRefcount::Type type)+      : impl_(sub, type) {+    // Nothing to do here.+  }++  grpc_slice_refcount* sub_refcount() const { return impl_.sub_refcount_; }++  grpc_core::SliceRefcount impl_;+};++namespace grpc_core {++struct InternedSliceRefcount {+  static void Destroy(void* arg) {+    static_cast<InternedSliceRefcount*>(arg)->DestroyInstance();+  }++  InternedSliceRefcount(size_t length, uint32_t hash,+                        InternedSliceRefcount* bucket_next)+      : base(grpc_core::SliceRefcount::Type::INTERNED, &refcnt,+             /*ensureRefNonZero=*/false, Destroy, this, &sub),+        sub(grpc_core::SliceRefcount::Type::REGULAR, &refcnt,+            /*ensureRefNonZero=*/false, Destroy, this, &sub),+        length(length),+        hash(hash),+        bucket_next(bucket_next) {+    // Nothing else to do here.",nit: please remove similar comments here and elsewhere.,
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/18407,267650180,2019-03-21T08:03:35Z,src/core/lib/slice/slice_internal.h,"@@ -23,17 +23,168 @@  #include <grpc/slice.h> #include <grpc/slice_buffer.h>+#include <string.h> -inline const grpc_slice& grpc_slice_ref_internal(const grpc_slice& slice) {+#include ""src/core/lib/gpr/murmur_hash.h""+#include ""src/core/lib/gprpp/ref_counted.h""+#include ""src/core/lib/transport/static_metadata.h""++extern uint32_t static_metadata_hash_values[GRPC_STATIC_MDSTR_COUNT];+extern uint32_t g_hash_seed;+namespace grpc_core {++class SliceRefcount {+ public:+  enum Type { STATIC, INTERNED, REGULAR };+  typedef void (*DestroyerFn)(void*);++  SliceRefcount() = default;+  SliceRefcount(SliceRefcount::Type type, RefCount* ref, bool ensureRefNonZero,+                DestroyerFn destroyer_fn, void* destroyer_arg,+                grpc_slice_refcount* sub)+      : sub_refcount_(sub),+        ref_type_(type),+        ref_(ref),+#ifndef NDEBUG+        ensureRefNonZero_(ensureRefNonZero),+#endif+        dest_fn_(destroyer_fn),+        destroy_fn_arg_(destroyer_arg) {+    // Nothing to do here.+  }+  SliceRefcount(grpc_slice_refcount* sub, Type type)+      : sub_refcount_(sub), ref_type_(type) {+    // Initializer for static.+  }++  Type getType() const { return ref_type_; }++  int Eq(const grpc_slice& a, const grpc_slice& b);++  uint32_t Hash(const grpc_slice& slice);+  void Ref() {+    if (!ref_) return;+#ifndef NDEBUG+    if (ensureRefNonZero_) {+      ref_->RefNonZero();+      return;+    }+#endif+    ref_->Ref();+  }+  void Unref() {+    if (!ref_) return;+    if (ref_->Unref()) {+      dest_fn_(destroy_fn_arg_);+    }+  }++  bool Validate() const { return ref_ != nullptr; }++ private:+  friend struct ::grpc_slice_refcount;++  grpc_slice_refcount* sub_refcount_ = nullptr;+  Type ref_type_ = REGULAR;+  RefCount* ref_ = nullptr;+#ifndef NDEBUG+  bool ensureRefNonZero_ = false;+#endif+  DestroyerFn dest_fn_ = nullptr;+  void* destroy_fn_arg_ = nullptr;+};++}  // namespace grpc_core++struct grpc_slice_refcount {+  grpc_slice_refcount() { impl_.sub_refcount_ = this; }+  grpc_slice_refcount(grpc_core::SliceRefcount::Type type,+                      grpc_core::RefCount* ref, bool ensureRefNonZero,+                      grpc_core::SliceRefcount::DestroyerFn destroyer_fn,+                      void* destroyer_arg, grpc_slice_refcount* sub)+      : impl_(type, ref, ensureRefNonZero, destroyer_fn, destroyer_arg, sub) {+    // Nothing to do here.+  }+  grpc_slice_refcount(grpc_slice_refcount* sub,+                      grpc_core::SliceRefcount::Type type)+      : impl_(sub, type) {+    // Nothing to do here.+  }++  grpc_slice_refcount* sub_refcount() const { return impl_.sub_refcount_; }++  grpc_core::SliceRefcount impl_;+};++namespace grpc_core {++struct InternedSliceRefcount {+  static void Destroy(void* arg) {+    static_cast<InternedSliceRefcount*>(arg)->DestroyInstance();+  }++  InternedSliceRefcount(size_t length, uint32_t hash,+                        InternedSliceRefcount* bucket_next)+      : base(grpc_core::SliceRefcount::Type::INTERNED, &refcnt,+             /*ensureRefNonZero=*/false, Destroy, this, &sub),+        sub(grpc_core::SliceRefcount::Type::REGULAR, &refcnt,+            /*ensureRefNonZero=*/false, Destroy, this, &sub),+        length(length),+        hash(hash),+        bucket_next(bucket_next) {+    // Nothing else to do here.",nit: please remove similar comments here and elsewhere.,
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/18357,267972188,2019-03-21T21:55:06Z,src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc,"@@ -238,38 +237,19 @@ void PickFirst::UpdateChildRefsLocked() {   child_subchannels_ = std::move(cs); } -void PickFirst::UpdateLocked(const grpc_channel_args& args,-                             RefCountedPtr<Config> lb_config) {+void PickFirst::UpdateLocked(UpdateArgs args) {   AutoChildRefsUpdater guard(this);-  const ServerAddressList* addresses = FindServerAddressListChannelArg(&args);-  if (addresses == nullptr) {-    if (subchannel_list_ == nullptr) {-      // If we don't have a current subchannel list, go into TRANSIENT FAILURE.-      grpc_error* error =-          GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Missing update in args"");",We don't need to check for this any longer?,
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/18357,267972318,2019-03-21T21:55:34Z,src/core/ext/filters/client_channel/lb_policy/round_robin/round_robin.cc,"@@ -476,26 +475,11 @@ void RoundRobin::RoundRobinSubchannelData::ProcessConnectivityChangeLocked(   subchannel_list()->UpdateRoundRobinStateFromSubchannelStateCountsLocked(); } -void RoundRobin::UpdateLocked(const grpc_channel_args& args,-                              RefCountedPtr<Config> lb_config) {+void RoundRobin::UpdateLocked(UpdateArgs args) {   AutoChildRefsUpdater guard(this);-  const ServerAddressList* addresses = FindServerAddressListChannelArg(&args);-  if (addresses == nullptr) {-    gpr_log(GPR_ERROR, ""[RR %p] update provided no addresses; ignoring"", this);-    // If we don't have a current subchannel list, go into TRANSIENT_FAILURE.-    // Otherwise, keep using the current subchannel list (ignore this update).-    if (subchannel_list_ == nullptr) {-      grpc_error* error =-          GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Missing update in args"");-      channel_control_helper()->UpdateState(",same here. Don't need to do this any longer?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18357,267985224,2019-03-21T22:46:26Z,src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc,"@@ -1262,7 +1249,7 @@ grpc_channel_args* BuildBalancerChannelArgs(       args, args_to_remove, GPR_ARRAY_SIZE(args_to_remove), args_to_add,       GPR_ARRAY_SIZE(args_to_add));   // Make any necessary modifications for security.-  return grpc_lb_policy_grpclb_modify_lb_channel_args(new_args);+  return grpc_lb_policy_grpclb_modify_lb_channel_args(addresses, new_args);","Yeah.  This predates the conversion to C++.  Probably not worth changing at this point, since grpclb is deprecated.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18470,268193555,2019-03-22T14:31:03Z,src/csharp/Grpc.Tools/GeneratorServices.cs,"@@ -109,6 +108,26 @@ string LowerUnderscoreToUpperCamel(string str)             }             return result.ToString();         }++        // This is how the protoc codegen constructs its output filename.+        // See protobuf/compiler/csharp/csharp_helpers.cc:356.","for comparison,  the logic is here:https://github.com/protocolbuffers/protobuf/blob/3a3956e8a258784461270961c6577341356bce52/src/google/protobuf/compiler/csharp/csharp_helpers.cc#L137  with `cap_next_letter=true` and `preserve_period=false`",
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/18437,268216741,2019-03-22T15:22:06Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -511,8 +583,10 @@ static void cc_destroy_channel_elem(grpc_channel_element* elem) {   chand->method_params_table.reset();   grpc_client_channel_stop_backup_polling(chand->interested_parties);   grpc_pollset_set_destroy(chand->interested_parties);+  GRPC_COMBINER_UNREF(chand->data_plane_combiner, ""client_channel"");   GRPC_COMBINER_UNREF(chand->combiner, ""client_channel"");-  GRPC_ERROR_UNREF(chand->disconnect_error);+  GRPC_ERROR_UNREF(","Destroy can also be relaxed because we cannot call Destroy in parallel to CompareExchange and it has to be ordered. So, I would suggest using RELAXED here.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18486,268483716,2019-03-25T04:09:20Z,src/csharp/Grpc.Core.Api/Grpc.Core.Api.csproj,"@@ -22,6 +22,10 @@    <Import Project=""..\Grpc.Core\SourceLink.csproj.include"" /> +  <ItemGroup>","The version info file is generated from a template:https://github.com/grpc/grpc/blob/master/templates/src/csharp/Grpc.Core/VersionInfo.cs.template - if the file moves, the template needs to move as well (hence the sanity test failure).",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18484,268723852,2019-03-25T16:09:31Z,src/compiler/csharp_generator.cc,"@@ -382,6 +382,10 @@ void GenerateServerClass(Printer* out, const ServiceDescriptor* service) {       ""/// <summary>Base class for server-side implementations of ""       ""$servicename$</summary>\n"",       ""servicename"", GetServiceClassName(service));+  out->Print(+      ""[grpc::BindService(typeof($classname$), ""+      ""nameof($classname$.BindService))]\n"",","`GetServiceClassName(service)`  only gives the name of the class, but we should probably use a fully qualified name to eliminate potential name collisions. ",OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/18488,268778705,2019-03-25T17:59:52Z,examples/python/errors/error_handling_server.py,"@@ -0,0 +1,81 @@+# Copyright 2019 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""This example sends out rich error status from server-side.""""""++from concurrent import futures+import time+import logging+import threading++import grpc+from grpc_status import rpc_status++from google.protobuf import any_pb2+from google.rpc import code_pb2, status_pb2, error_details_pb2++import helloworld_pb2+import helloworld_pb2_grpc++_ONE_DAY_IN_SECONDS = 60 * 60 * 24+++def create_greet_limit_exceed_error_status(name):+    detail = any_pb2.Any()+    detail.Pack(+        error_details_pb2.QuotaFailure(+            violations=[+                error_details_pb2.QuotaFailure.Violation(+                    subject=""name:%s"" % name,+                    description=""Limit one greeting per person"",+                )+            ],))+    return status_pb2.Status(+        code=code_pb2.RESOURCE_EXHAUSTED,+        message='Request limit exceeded.',+        details=[detail],+    )+++class LimitedGreeter(helloworld_pb2_grpc.GreeterServicer):++    def __init__(self):+        self._lock = threading.RLock()+        self._greeted = set()++    def SayHello(self, request, context):+        with self._lock:+            if request.name in self._greeted:+                rich_status = create_greet_limit_exceed_error_status(+                    request.name)+                context.abort_with_status(rpc_status.to_status(rich_status))+            else:+                self._greeted.add(request.name)+        return helloworld_pb2.HelloReply(message='Hello, %s!' % request.name)+++def serve():+    server = grpc.server(futures.ThreadPoolExecutor())",I'm a fan of letting Python decide how many threads to use. We should probably expand this pattern to the rest of our examples. It's probably not within the scope of this PR though.,
303201,JamesNK,https://api.github.com/repos/grpc/grpc/pulls/18484,268816110,2019-03-25T19:33:03Z,src/compiler/csharp_generator.cc,"@@ -382,6 +382,10 @@ void GenerateServerClass(Printer* out, const ServiceDescriptor* service) {       ""/// <summary>Base class for server-side implementations of ""       ""$servicename$</summary>\n"",       ""servicename"", GetServiceClassName(service));+  out->Print(+      ""[grpc::BindService(typeof($classname$), ""+      ""nameof($classname$.BindService))]\n"",",> but we should probably use a fully qualified name to eliminate potential name collisions.I thought about that but there are other places in the generated service that reference class names without fully qualifying them.,OK
35056280,srini100,https://api.github.com/repos/grpc/grpc/pulls/18493,268874150,2019-03-25T22:12:56Z,include/grpcpp/impl/codegen/client_callback.h,"@@ -157,28 +157,95 @@ class ClientCallbackWriter {   } }; -// The user must implement this reactor interface with reactions to each event-// type that gets called by the library. An empty reaction is provided by-// default+// The following classes are the reactor interfaces that are to be implemented+// by the user. They are passed in to the library as an argument to a call on a+// stub (either a codegen-ed call or a generic call). The streaming RPC is+// activated by calling StartCall, possibly after initiating StartRead,+// StartWrite, or AddHold operations on the streaming object. Note that none of+// the classes are pure; all reactions have a default empty reaction so that the+// user class only needs to override those classes that it cares about.++/// \a ClientBidiReactor is the interface for a bidirectional streaming RPC. template <class Request, class Response> class ClientBidiReactor {  public:   virtual ~ClientBidiReactor() {}++  /// Notifies the application that all operations associated with this RPC+  /// have completed and provides the RPC status outcome.+  ///+  /// \param[in] s The status outcome of this RPC   virtual void OnDone(const Status& s) {}++  /// Notifies the application that a read of initial metadata from the+  /// server is done. If the application chooses not to implement this method,+  /// it can assume that the initial metadata has been read before the first+  /// call of OnReadDone or OnDone.+  ///+  /// \param[in] ok Was the initial metadata read successfully? If false, no+  ///               further read-side operation will succeed.   virtual void OnReadInitialMetadataDone(bool ok) {}++  /// Notifies the application that a Read operation completed.+  ///+  /// \param[in] ok Was it successful? If false, no further read-side operation+  ///               will succeed   virtual void OnReadDone(bool ok) {}++  /// Notifies the application that a Write operation completed.+  ///+  /// \param[in] ok Was it successful? If false, no further write-side operation+  ///               will succeed   virtual void OnWriteDone(bool ok) {}++  /// Notifies the application that a WritesDone operation completed. Note that+  /// this is only used on explicit WritesDone operations and not for those that+  /// are implicitly invoked as part of a StartWriteLast.+  ///+  /// \param[in] ok Was it successful?   virtual void OnWritesDoneDone(bool ok) {}","Nit: For a first time reader, it is easier to read if ""Start"" APIs are listed before ""On"" APIs. Consider rearranging the order.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18496,268877013,2019-03-25T22:22:21Z,src/core/ext/filters/client_channel/lb_policy.h,"@@ -272,6 +272,7 @@ class LoadBalancingPolicy : public InternallyRefCounted<LoadBalancingPolicy> {    grpc_pollset_set* interested_parties() const { return interested_parties_; } +  // Note: This must be invoked while holding the combiner.","I was going to suggest updating tests that directly instantiate `Resolver` instances to make sure to bounce into the combiner before orphaning, but then realized that `resolver_component_test`, `cancel_ares_query_test`, `dns_resolver_connectivity_test`, `fake_resolver_test`, and `sockaddr_resolver_test` are all already calling `StartLocked` without the combiner (but I suspect getting away with it in those tests since everything is happening on the main thread anyways).If not addressed in this PR (looks like a pre-existing issue), maybe a TODO?",
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/18381,268878291,2019-03-25T22:26:35Z,test/cpp/end2end/cfstream_test.cc,"@@ -261,6 +294,119 @@ TEST_F(CFStreamTest, NetworkTransition) {   sender.join(); } +// Network flaps while RPCs are in flight+TEST_F(CFStreamTest, NetworkFlapRpcsInFlight) {","Yes, this runs periodically in our internal CI. Test config is here: https://github.com/grpc/grpc/blob/master/tools/internal_ci/macos/grpc_cfstream.cfgAdded Yash as a reviewer as he's familiar with this issue.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18493,268898451,2019-03-25T23:52:30Z,include/grpcpp/impl/codegen/client_callback.h,"@@ -157,28 +157,95 @@ class ClientCallbackWriter {   } }; -// The user must implement this reactor interface with reactions to each event-// type that gets called by the library. An empty reaction is provided by-// default+// The following classes are the reactor interfaces that are to be implemented+// by the user. They are passed in to the library as an argument to a call on a+// stub (either a codegen-ed call or a generic call). The streaming RPC is+// activated by calling StartCall, possibly after initiating StartRead,+// StartWrite, or AddHold operations on the streaming object. Note that none of+// the classes are pure; all reactions have a default empty reaction so that the+// user class only needs to override those classes that it cares about.++/// \a ClientBidiReactor is the interface for a bidirectional streaming RPC. template <class Request, class Response> class ClientBidiReactor {  public:   virtual ~ClientBidiReactor() {}++  /// Notifies the application that all operations associated with this RPC+  /// have completed and provides the RPC status outcome.+  ///+  /// \param[in] s The status outcome of this RPC   virtual void OnDone(const Status& s) {}++  /// Notifies the application that a read of initial metadata from the+  /// server is done. If the application chooses not to implement this method,+  /// it can assume that the initial metadata has been read before the first+  /// call of OnReadDone or OnDone.+  ///+  /// \param[in] ok Was the initial metadata read successfully? If false, no+  ///               further read-side operation will succeed.   virtual void OnReadInitialMetadataDone(bool ok) {}++  /// Notifies the application that a Read operation completed.+  ///+  /// \param[in] ok Was it successful? If false, no further read-side operation+  ///               will succeed   virtual void OnReadDone(bool ok) {}++  /// Notifies the application that a Write operation completed.+  ///+  /// \param[in] ok Was it successful? If false, no further write-side operation+  ///               will succeed   virtual void OnWriteDone(bool ok) {}++  /// Notifies the application that a WritesDone operation completed. Note that+  /// this is only used on explicit WritesDone operations and not for those that+  /// are implicitly invoked as part of a StartWriteLast.+  ///+  /// \param[in] ok Was it successful?   virtual void OnWritesDoneDone(bool ok) {} +  /// Activate the RPC and initiate any reads or writes that have been Start'ed+  /// before this call.   void StartCall() { stream_->StartCall(); }++  /// Initiate a read operation (or post it for later initiation if StartCall+  /// has not yet been invoked).+  ///+  /// \param[out] msg Where to eventually store the read message. Valid when","Oops, bad copy-paste",
303201,JamesNK,https://api.github.com/repos/grpc/grpc/pulls/18446,268909421,2019-03-26T00:55:26Z,src/csharp/Grpc.Tools/ProtoCompile.cs,"@@ -123,6 +126,110 @@ public class ProtoCompile : ToolTask                                                         ""javanano"", ""js"", ""objc"",                                                         ""php"", ""python"", ""ruby"" }; +        static readonly TimeSpan RegexTimeout = TimeSpan.FromMilliseconds(100);",Should these new fields follow the `s_` naming standard from `s_supportedGenerators`,
2030323,JunTaoLuo,https://api.github.com/repos/grpc/grpc/pulls/18446,269252748,2019-03-26T18:23:07Z,src/csharp/Grpc.Tools.Tests/ProtoCompileCommandLineGeneratorTest.cs,"@@ -175,5 +175,86 @@ public void DirectorySlashTrimmingCases(string given, string expect)             Assert.That(_task.LastResponseFile,                         Does.Contain(""--csharp_out="" + expect));         }++        [TestCase(+            ""../Protos/greet.proto(19) : warning in column=5 : warning : When enum name is stripped and label is PascalCased (Zero) this value label conflicts with Zero."",+            ""../Protos/greet.proto"",+            19,+            5,+            ""warning : When enum name is stripped and label is PascalCased (Zero) this value label conflicts with Zero."")]","I found it not very standardized. The relevant logic is here:https://github.com/protocolbuffers/protobuf/blob/master/src/google/protobuf/compiler/command_line_interface.cc#L353-L357However, it's not entirely consistent what happens since the message might be prefixed with `warning : `. I was hoping to keep the logic as simple as possible and didn't want to modify the message in any way. I suppose removing that specific prefix might be safe though.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18446,269258804,2019-03-26T18:37:05Z,src/csharp/Grpc.Tools.Tests/ProtoCompileCommandLineGeneratorTest.cs,"@@ -175,5 +175,86 @@ public void DirectorySlashTrimmingCases(string given, string expect)             Assert.That(_task.LastResponseFile,                         Does.Contain(""--csharp_out="" + expect));         }++        [TestCase(+            ""../Protos/greet.proto(19) : warning in column=5 : warning : When enum name is stripped and label is PascalCased (Zero) this value label conflicts with Zero."",+            ""../Protos/greet.proto"",+            19,+            5,+            ""warning : When enum name is stripped and label is PascalCased (Zero) this value label conflicts with Zero."")]","I think it makes sense to merge as is and keep improving iteratively?  Warning messages starting with ""warning :"" prefix doesn't seem as a big problem to me. Being able to jump to the right location is much more important.",OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/18381,269259931,2019-03-26T18:40:07Z,test/cpp/end2end/cfstream_test.cc,"@@ -47,8 +47,10 @@ #include ""test/cpp/end2end/test_service_impl.h""  #ifdef GRPC_CFSTREAM+using grpc::ClientAsyncResponseReader; using grpc::testing::EchoRequest; using grpc::testing::EchoResponse;+using grpc::testing::RequestParams; using std::chrono::system_clock;  namespace grpc {",Thanks for pointing out the unused variable. I'll remove it and use 127.0.0.2 like you suggested.,
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/18407,269357176,2019-03-26T23:38:24Z,src/core/lib/slice/slice_intern.cc,"@@ -69,62 +64,27 @@ typedef struct { static static_metadata_hash_ent     static_metadata_hash[4 * GRPC_STATIC_MDSTR_COUNT]; static uint32_t max_static_metadata_hash_probe;-static uint32_t static_metadata_hash_values[GRPC_STATIC_MDSTR_COUNT];+uint32_t static_metadata_hash_values[GRPC_STATIC_MDSTR_COUNT]; -static void interned_slice_ref(void* p) {-  interned_slice_refcount* s = static_cast<interned_slice_refcount*>(p);-  GPR_ASSERT(gpr_atm_no_barrier_fetch_add(&s->refcnt, 1) > 0);-}+namespace grpc_core { -static void interned_slice_destroy(interned_slice_refcount* s) {-  slice_shard* shard = &g_shards[SHARD_IDX(s->hash)];-  gpr_mu_lock(&shard->mu);-  GPR_ASSERT(0 == gpr_atm_no_barrier_load(&s->refcnt));+void InternedSliceRefcount::DestroyInstance() {+  slice_shard* shard = &g_shards[SHARD_IDX(this->hash)];+  MutexLock lock(&shard->mu);+  // TODO(arjunroy) Really need this method+  // GPR_ASSERT(0 == gpr_atm_no_barrier_load(&this->refcnt));   interned_slice_refcount** prev_next;   interned_slice_refcount* cur;-  for (prev_next = &shard->strs[TABLE_IDX(s->hash, shard->capacity)],+  for (prev_next = &shard->strs[TABLE_IDX(this->hash, shard->capacity)],",Readability; since that class hasn't been converted to _ suffixes on member vars this makes it a bit more obvious.,OK
2030323,JunTaoLuo,https://api.github.com/repos/grpc/grpc/pulls/18532,269654581,2019-03-27T16:28:21Z,src/csharp/Grpc.Core.Api/LiteClientBase.cs,"@@ -0,0 +1,96 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using Grpc.Core.Utils;++namespace Grpc.Core+{+    /// <summary>+    /// Base class for lightweight client-side stubs.+    /// All calls are invoked via a <c>CallInvoker</c>.+    /// Lite client stubs have no configuration knobs, all configuration+    /// is provided by decorating the call invoker.+    /// </summary>+    public abstract class LiteClientBase",So we are taking the new base class approach and have codegen generate this base class instead right? Will that be done through a command line arg?,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18532,269657749,2019-03-27T16:35:14Z,src/csharp/Grpc.Core.Api/LiteClientBase.cs,"@@ -0,0 +1,96 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using Grpc.Core.Utils;++namespace Grpc.Core+{+    /// <summary>+    /// Base class for lightweight client-side stubs.+    /// All calls are invoked via a <c>CallInvoker</c>.+    /// Lite client stubs have no configuration knobs, all configuration+    /// is provided by decorating the call invoker.+    /// </summary>+    public abstract class LiteClientBase","I don't know that yet, it's a difficult decision :-(, but it's definitely one of the options.There are multiple things that come into play when talking about client side channels - context propagation, load balancing, credentials etc.I keep hearing that we'll need to do a more detailed API review with other stakeholders from the gRPC team.In parallel to that, I'm looking into resolving the problems with porting over CallOptions struct - currently I don't have a good answer there. ",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/18547,269785683,2019-03-27T21:52:52Z,src/python/grpcio_tests/tests/unit/_dns_resolver_test.py,"@@ -0,0 +1,58 @@+# Copyright 2019 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Tests for an actual dns resolution.""""""++import unittest+import logging+import six++import grpc+from tests.unit import test_common++_METHOD = '/ANY/METHOD'+_REQUEST = b'\x00\x00\x00'+_RESPONSE = _REQUEST+++class GenericHandler(grpc.GenericRpcHandler):++    def service(self, unused_handler_details):+        return grpc.unary_unary_rpc_method_handler(+            lambda request, unused_context: request,+        )+++class DNSResolverTest(unittest.TestCase):++    def setUp(self):+        self._server = test_common.test_server()+        self._server.add_generic_rpc_handlers((GenericHandler(),))+        self._port = self._server.add_insecure_port('[::]:0')+        self._server.start()++    def tearDown(self):+        self._server.stop(None)++    def test_connect_loopback(self):+        # NOTE(https://github.com/grpc/grpc/issues/18422)+        # In short, Gevent + C-Ares = Segfault. The C-Ares driver is not+        # supported by custom io manager like ""gevent"" or ""libuv"".+        with grpc.insecure_channel(+                'loopback4.unittest.grpc.io:%d' % self._port) as channel:","The `IPv6` fail log is caused by the second commit, here is the full log: https://source.cloud.google.com/results/invocations/3799a132-06ea-494c-91c4-6466f18fa304/targets/grpc%2Fcore%2Fpull_request%2Flinux%2Fgrpc_python_bazel_test/logHere is the highlight:```======================================================================ERROR: test_connect_loopback (__main__.DNSResolverTest)----------------------------------------------------------------------Traceback (most recent call last):  File ""/root/.cache/bazel/_bazel_root/d2dc70c3d9da3fab488ba0dcbbd35051/execroot/com_github_grpc_grpc/bazel-out/k8-fastbuild/bin/src/python/grpcio_tests/tests/unit/_dns_resolver_test.runfiles/com_github_grpc_grpc/src/python/grpcio_tests/tests/unit/_dns_resolver_test.py"", line 53, in test_connect_loopback    self.assertEqual(channel.unary_unary(_METHOD)(_REQUEST), _RESPONSE)  File ""/root/.cache/bazel/_bazel_root/d2dc70c3d9da3fab488ba0dcbbd35051/execroot/com_github_grpc_grpc/bazel-out/k8-fastbuild/bin/src/python/grpcio_tests/tests/unit/_dns_resolver_test.runfiles/com_github_grpc_grpc/src/python/grpcio/grpc/_channel.py"", line 562, in __call__    return _end_unary_response_blocking(state, call, False, None)  File ""/root/.cache/bazel/_bazel_root/d2dc70c3d9da3fab488ba0dcbbd35051/execroot/com_github_grpc_grpc/bazel-out/k8-fastbuild/bin/src/python/grpcio_tests/tests/unit/_dns_resolver_test.runfiles/com_github_grpc_grpc/src/python/grpcio/grpc/_channel.py"", line 466, in _end_unary_response_blocking    raise _Rendezvous(state, None, None, deadline)_Rendezvous: <_Rendezvous of RPC that terminated with:	status = StatusCode.UNAVAILABLE	details = ""DNS resolution failed""	debug_error_string = ""{""created"":""@1553714241.572645062"",""description"":""Failed to create subchannel"",""file"":""src/core/ext/filters/client_channel/client_channel.cc"",""file_line"":2715,""referenced_errors"":[{""created"":""@1553714241.572633454"",""description"":""Resolver transient failure"",""file"":""src/core/ext/filters/client_channel/resolving_lb_policy.cc"",""file_line"":335,""referenced_errors"":[{""created"":""@1553714241.572629488"",""description"":""DNS resolution failed"",""file"":""src/core/ext/filters/client_channel/resolver/dns/c_ares/dns_resolver_ares.cc"",""file_line"":327,""grpc_status"":14,""referenced_errors"":[{""created"":""@1553714241.572531047"",""description"":""C-ares status is not ARES_SUCCESS: DNS server returned answer with no data"",""file"":""src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc"",""file_line"":240}]}]}]}"">```What do you think is the best solution to satisfy both  Bazel in Kokoro/Docker and IPv6 only environment?",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/18547,269811315,2019-03-27T23:36:16Z,src/python/grpcio_tests/tests/unit/_dns_resolver_test.py,"@@ -50,7 +51,12 @@ def test_connect_loopback(self):         # supported by custom io manager like ""gevent"" or ""libuv"".         with grpc.insecure_channel(                 'loopback4.unittest.grpc.io:%d' % self._port) as channel:-            self.assertEqual(channel.unary_unary(_METHOD)(_REQUEST), _RESPONSE)+            response = channel.unary_unary(_METHOD)(+                _REQUEST,+                timeout=test_constants.SHORT_TIMEOUT,+                wait_for_ready=True,","The `gevent` on Windows failed in last commit, and I am not 100% sure about the root cause so I use `wait-for-ready` to de-flake.Test log highlight:```Traceback (most recent call last):  File ""C:\Python35\Lib\unittest\case.py"", line 59, in testPartExecutor    yield  File ""C:\Python35\Lib\unittest\case.py"", line 601, in run    testMethod()  File ""T:\src\github\grpc\workspace_python_windows_opt_gevent\src\python\grpcio_tests\tests\unit\_dns_resolver_test.py"", line 53, in test_connect_loopback    self.assertEqual(channel.unary_unary(_METHOD)(_REQUEST), _RESPONSE)  File ""T:\src\github\grpc\workspace_python_windows_opt_gevent\py35_gevent\lib\site-packages\grpc\_channel.py"", line 562, in __call__    return _end_unary_response_blocking(state, call, False, None)  File ""T:\src\github\grpc\workspace_python_windows_opt_gevent\py35_gevent\lib\site-packages\grpc\_channel.py"", line 466, in _end_unary_response_blocking    raise _Rendezvous(state, None, None, deadline)grpc._channel._Rendezvous: <_Rendezvous of RPC that terminated with:	status = StatusCode.UNAVAILABLE	details = ""Connect Failed""	debug_error_string = ""{""created"":""@1553726691.297000000"",""description"":""Failed to create subchannel"",""file"":""src/core/ext/filters/client_channel/client_channel.cc"",""file_line"":2715,""referenced_errors"":[{""created"":""@1553726691.297000000"",""description"":""failed to connect to all addresses"",""file"":""src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc"",""file_line"":444,""referenced_errors"":[{""created"":""@1553726691.297000000"",""description"":""Connect Failed"",""file"":""src/core/ext/filters/client_channel/subchannel.cc"",""file_line"":963,""grpc_status"":14,""referenced_errors"":[{""created"":""@1553726691.297000000"",""description"":""connect failed: [Errno 10061] [WinError 10061] No connection could be made because the target machine actively refused it."",""file"":"".\src/core/lib/iomgr/gevent_util.h"",""file_line"":33,""grpc_status"":14}]}]}]}"">```",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/18330,269814412,2019-03-27T23:52:08Z,src/objective-c/manual_tests/GrpcIosTestUITests/GrpcIosTestUITests.m,"@@ -71,41 +99,95 @@ - (void)setAirplaneMode:(BOOL)to {   [settingsApp activate];   XCUIElement *mySwitch = settingsApp.tables.element.cells.switches[@""Airplane Mode""];   BOOL from = [(NSString *)mySwitch.value boolValue];+  NSLog(@""Setting airplane from: %d to: %d"", from, to);   if (from != to) {     [mySwitch tap];     // wait for gRPC to detect the change-    sleep(10);+    [NSThread sleepForTimeInterval:20];",and 20 seconds looks like a long time. why do we need to wait that long?,
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/18330,269814626,2019-03-27T23:53:09Z,src/objective-c/manual_tests/GrpcIosTestUITests/GrpcIosTestUITests.m,"@@ -71,41 +99,95 @@ - (void)setAirplaneMode:(BOOL)to {   [settingsApp activate];   XCUIElement *mySwitch = settingsApp.tables.element.cells.switches[@""Airplane Mode""];   BOOL from = [(NSString *)mySwitch.value boolValue];+  NSLog(@""Setting airplane from: %d to: %d"", from, to);   if (from != to) {     [mySwitch tap];     // wait for gRPC to detect the change-    sleep(10);+    [NSThread sleepForTimeInterval:20];   }   XCTAssert([(NSString *)mySwitch.value boolValue] == to); }+- (void)setWifi:(BOOL)to {+  [settingsApp activate];+  [settingsApp.tables.element.cells.staticTexts[@""Wi-Fi""] tap];+  XCUIElement *wifiSwitch = settingsApp.tables.cells.switches[@""Wi-Fi""];+  BOOL from = [(NSString *)wifiSwitch.value boolValue];+  NSLog(@""Setting wifi from: %d to: %d"", from, to);+  if (from != to) {+    [wifiSwitch tap];+    // wait for change to be detected+    [NSThread sleepForTimeInterval:20];",same here. waiting for 20 seconds seems too long for me. if we have to wait for 20 seconds for something to work correctly then something is probably not working correctly...,
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/18330,269857218,2019-03-28T04:57:05Z,src/objective-c/manual_tests/GrpcIosTestUITests/GrpcIosTestUITests.m,"@@ -71,41 +99,95 @@ - (void)setAirplaneMode:(BOOL)to {   [settingsApp activate];   XCUIElement *mySwitch = settingsApp.tables.element.cells.switches[@""Airplane Mode""];   BOOL from = [(NSString *)mySwitch.value boolValue];+  NSLog(@""Setting airplane from: %d to: %d"", from, to);   if (from != to) {     [mySwitch tap];     // wait for gRPC to detect the change-    sleep(10);+    [NSThread sleepForTimeInterval:20];","It's pretty much the same as using `sleep`. I just changed it here for consistency because I had used `NSThread sleepForTimeInterval` in other places.Regarding the sleep time, what do you think is a reasonable amount of time to wait after flapping the network? We just need to wait long enough for the network state change to be detected by gRPC.",
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/17727,270235747,2019-03-28T23:25:21Z,examples/cpp/helloworld/greeter_async_client.cc,"@@ -23,7 +23,11 @@ #include <grpcpp/grpcpp.h> #include <grpc/support/log.h> +#ifdef BAZEL_BUILD","I think builds using make would fail if we just keep line 27. This ifdef is used in other examples. For example, see https://github.com/grpc/grpc/blob/master/examples/cpp/helloworld/greeter_client.cc#L25",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18467,270246817,2019-03-29T00:30:51Z,src/csharp/Grpc.Tools/Common.cs,"@@ -87,6 +87,16 @@ static Platform()              // Hope we are not building on ARM under Xamarin!             Cpu = Environment.Is64BitOperatingSystem ? CpuKind.X64 : CpuKind.X86;++            // See https://github.com/grpc/grpc/issues/18543+            // Problem: Is64BitOperatingSystem returns ""true"" inside a 32-bit docker container.+            // Workaround: Mono is 64-bit by default on linux, so we get around+            // this by assuming 32-bit mono linux process means+            // we should invoke 32-bit version of protoc.+            if (Os == OsKind.Linux && !Environment.Is64BitOperatingSystem)",Naive question: this conditional will only evaluate true if `Environment.Is64BitOperatingSystem` evaluates false.... so this doesn't actually fix the problem?,OK
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/18371,270436619,2019-03-29T14:36:45Z,include/grpcpp/health_check_service_interface.h,"@@ -19,39 +19,22 @@ #ifndef GRPCPP_HEALTH_CHECK_SERVICE_INTERFACE_H #define GRPCPP_HEALTH_CHECK_SERVICE_INTERFACE_H -#include <grpcpp/support/config.h>+#include <grpcpp/health_check_service_interface_impl.h>  namespace grpc {  const char kHealthCheckServiceInterfaceArg[] =","I'm... surprised this actually works. This is unrelated to this PR, but that's really not supposed to work like this.The proper way would be to define `kHealthCheckServiceInterfaceArg` in the header like so:```extern const char kHealthCheckServiceInterfaceArg[];```And then, in a .cc file, have the actual declaration. The way this is currently done means the symbol might get duplicated at link time.cc @vjpai.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18586,270895306,2019-04-01T14:30:06Z,src/core/ext/filters/client_channel/service_config.h,"@@ -120,9 +149,16 @@ class ServiceConfig : public RefCounted<ServiceConfig> {       grpc_json* json, CreateValue<T> create_value,       typename SliceHashTable<RefCountedPtr<T>>::Entry* entries, size_t* idx); +  static constexpr int kMaxParsers = 32;+  static int registered_parsers_count;+  static ServiceConfigParser registered_parsers[kMaxParsers];",We'll need a way to initialize and clear this list when `grpc_init()` and `grpc_shutdown()` run.  I suggest using the same pattern that we use to register resolvers and LB policies.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18586,270896329,2019-04-01T14:32:15Z,src/core/ext/filters/client_channel/service_config.h,"@@ -96,6 +105,26 @@ class ServiceConfig : public RefCounted<ServiceConfig> {   static RefCountedPtr<T> MethodConfigTableLookup(       const SliceHashTable<RefCountedPtr<T>>& table, const grpc_slice& path); +  /// Retrieves the parsed object at index \a index.+  ServiceConfigParsedObject* GetParsedServiceConfigObject(int index) {+    GPR_DEBUG_ASSERT(index < registered_parsers_count);+    return parsed_service_config_objects[index].get();+  }++  typedef UniquePtr<ServiceConfigParsedObject> (*ServiceConfigParser)(","Instead of making the parser a simple function, I suggest making it a class.  It will need at least two methods, one for parsing the global parameters (replacing the mechanism currently provided by `ParseGlobalParams()`) and one for parsing per-method parameters (replacing the mechanism currently provided by `CreateMethodConfigTable()`).  Also, this will make it possible for the caller to pass any necessary external state to the parsing object via its ctor.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/18564,270994363,2019-04-01T18:26:19Z,src/python/grpcio/grpc/BUILD.bazel,"@@ -31,12 +32,18 @@ py_library(     srcs = [""_auth.py""], ) +py_library(+    name = ""compression"",+    srcs = [""compression.py""],",Should we follow the naming pattern to make module files start with underscore?,
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/18564,270994789,2019-04-01T18:27:29Z,src/python/grpcio/grpc/_channel.py,"@@ -512,17 +513,19 @@ def __init__(self, channel, managed_call, method, request_serializer,         self._response_deserializer = response_deserializer         self._context = cygrpc.build_census_context() -    def _prepare(self, request, timeout, metadata, wait_for_ready):+    def _prepare(self, request, timeout, metadata, wait_for_ready, compression):         deadline, serialized_request, rendezvous = _start_unary_request(             request, timeout, self._request_serializer)         initial_metadata_flags = _InitialMetadataFlags().with_wait_for_ready(             wait_for_ready)+        augmented_metadata = grpc.compression._augment_metadata(",Maybe `_augment_metadata` should be `augment_metadata` since it is called outside of module.,OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/18564,271061505,2019-04-01T21:40:36Z,src/python/grpcio/grpc/_server.py,"@@ -259,14 +260,24 @@ def auth_context(self):                 cygrpc.auth_context(self._rpc_event.call))         } +    def set_compression(self, compression):+        with self._state.condition:+            self._state.compression_algorithm = compression+     def send_initial_metadata(self, initial_metadata):         with self._state.condition:             if self._state.client is _CANCELLED:                 _raise_rpc_error(self._state)             else:                 if self._state.initial_metadata_allowed:+                    compression_metadata = (+                    ) if not self._state.compression_algorithm else (+                        grpc.compression._compression_algorithm_to_metadata(+                            self._state.compression_algorithm),)+                    augmented_metadata = tuple(+                        initial_metadata) + compression_metadata",Should this part merge with `_augment_metadata` in `compression`?,
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/18564,271065220,2019-04-01T21:52:50Z,src/python/grpcio_tests/tests/unit/_tcp_proxy.py,"@@ -0,0 +1,141 @@+# Copyright 2019 the gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+"""""" Proxies a TCP connection between a single client-server pair.++This proxy is not suitable for production, but should work well for cases in+which a test needs to spy on the bytes put on the wire between a server and+a client.+""""""++from __future__ import absolute_import+from __future__ import division+from __future__ import print_function++import datetime+import select+import socket+import threading++_TCP_PROXY_BUFFER_SIZE = 1024+_TCP_PROXY_TIMEOUT = datetime.timedelta(milliseconds=500)+++def _init_listen_socket(bind_address):+    listen_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)+    listen_socket.bind((bind_address, 0))+    listen_socket.listen(1)",Is there a specific need to set backlog to 1?https://docs.python.org/2/library/socket.html#socket.socket.listen,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18591,271102320,2019-04-02T01:00:24Z,src/csharp/ext/grpc_csharp_ext.c,"@@ -927,20 +942,42 @@ grpcsharp_override_default_ssl_roots(const char* pem_root_certs) {   grpc_set_ssl_roots_override_callback(override_ssl_roots_handler); } +static void grpcsharp_verify_peer_destroy_handler(void* userdata) {+  native_callback_dispatcher(userdata, NULL, NULL, (void*)1, NULL, NULL, NULL);+}++static int grpcsharp_verify_peer_handler(const char* target_name,+                                         const char* peer_pem, void* userdata) {+  return native_callback_dispatcher(userdata, (void*)target_name,+                                    (void*)peer_pem, (void*)0, NULL, NULL,+                                    NULL);+}+ GPR_EXPORT grpc_channel_credentials* GPR_CALLTYPE grpcsharp_ssl_credentials_create(const char* pem_root_certs,                                  const char* key_cert_pair_cert_chain,-                                 const char* key_cert_pair_private_key) {+                                 const char* key_cert_pair_private_key,+                                 void* verify_peer_callback_tag) {   grpc_ssl_pem_key_cert_pair key_cert_pair;+  verify_peer_options verify_options;",Done (along with some refactoring of the create function).,
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/18564,271103558,2019-04-02T01:09:46Z,src/python/grpcio/grpc/__init__.py,"@@ -1788,6 +1843,12 @@ def _create_servicer_context(rpc_event, state, request_deserializer):     context._finalize_state()  # pylint: disable=protected-access  +class Compression(object):","Should we make it an `enum.Enum`? Also, should we add a docstring to this class?",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/18564,271104275,2019-04-02T01:15:00Z,src/python/grpcio/grpc/_server.py,"@@ -259,14 +261,20 @@ def auth_context(self):                 cygrpc.auth_context(self._rpc_event.call))         } +    def set_compression(self, compression):+        with self._state.condition:+            self._state.compression_algorithm = compression+     def send_initial_metadata(self, initial_metadata):         with self._state.condition:             if self._state.client is _CANCELLED:                 _raise_rpc_error(self._state)             else:                 if self._state.initial_metadata_allowed:+                    augmented_metadata = _compression.augment_metadata(+                        initial_metadata, self._state.compression_algorithm)","optional: Make `initial_metadata=()` by default, and change this line to `initial_metadata += _compression.create_compression_metadata(self._state.compression_algorithm)`.",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/18564,271107455,2019-04-02T01:37:30Z,src/python/grpcio_tests/tests/unit/_compression_test.py,"@@ -52,75 +148,242 @@ def __init__(self, request_streaming, response_streaming):         self.unary_stream = None         self.stream_unary = None         self.stream_stream = None+         if self.request_streaming and self.response_streaming:-            self.stream_stream = handle_stream+            self.stream_stream = _make_handle_stream_stream(+                pre_response_callback)         elif not self.request_streaming and not self.response_streaming:-            self.unary_unary = handle_unary+            self.unary_unary = _make_handle_unary_unary(pre_response_callback)+        elif not self.request_streaming and self.response_streaming:+            self.unary_stream = _make_handle_unary_stream(pre_response_callback)+        else:+            self.stream_unary = _make_handle_stream_unary(pre_response_callback)   class _GenericHandler(grpc.GenericRpcHandler): +    def __init__(self, pre_response_callback):+        self._pre_response_callback = pre_response_callback+     def service(self, handler_call_details):         if handler_call_details.method == _UNARY_UNARY:-            return _MethodHandler(False, False)+            return _MethodHandler(False, False, self._pre_response_callback)+        elif handler_call_details.method == _UNARY_STREAM:+            return _MethodHandler(False, True, self._pre_response_callback)+        elif handler_call_details.method == _STREAM_UNARY:+            return _MethodHandler(True, False, self._pre_response_callback)         elif handler_call_details.method == _STREAM_STREAM:-            return _MethodHandler(True, True)+            return _MethodHandler(True, True, self._pre_response_callback)         else:             return None  +@contextlib.contextmanager+def _instrumented_client_server_pair(channel_kwargs, server_kwargs,+                                     server_handler):+    host = 'localhost'+    server = grpc.server(futures.ThreadPoolExecutor(), **server_kwargs)+    server.add_generic_rpc_handlers((server_handler,))+    server_port = server.add_insecure_port('{}:0'.format(host))+    server.start()+    with _tcp_proxy.TcpProxy(host, host, server_port) as proxy:+        proxy_port = proxy.get_port()+        with grpc.insecure_channel('{}:{}'.format(host, proxy_port),+                                   **channel_kwargs) as client_channel:+            try:+                yield client_channel, proxy, server+            finally:+                server.stop(None)+++def _get_byte_counts(channel_kwargs, multicallable_kwargs, client_function,+                     server_kwargs, server_handler, message):+    with _instrumented_client_server_pair(channel_kwargs, server_kwargs,+                                          server_handler) as pipeline:+        client_channel, proxy, server = pipeline+        client_function(client_channel, multicallable_kwargs, message)+        return proxy.get_byte_count()+++def _get_compression_ratios(client_function, first_channel_kwargs,+                            first_multicallable_kwargs, first_server_kwargs,+                            first_server_handler, second_channel_kwargs,+                            second_multicallable_kwargs, second_server_kwargs,+                            second_server_handler, message):+    first_bytes_sent, first_bytes_received = _get_byte_counts(+        first_channel_kwargs, first_multicallable_kwargs, client_function,+        first_server_kwargs, first_server_handler, message)+    second_bytes_sent, second_bytes_received = _get_byte_counts(+        second_channel_kwargs, second_multicallable_kwargs, client_function,+        second_server_kwargs, second_server_handler, message)+    return ((second_bytes_sent - first_bytes_sent) / float(first_bytes_sent),+            (second_bytes_received - first_bytes_received) /+            float(first_bytes_received))+++def _unary_unary_client(channel, multicallable_kwargs, message):+    multi_callable = channel.unary_unary(_UNARY_UNARY)+    response = multi_callable(message, **multicallable_kwargs)+    if response != message:+        raise RuntimeError(""Request '{}' != Response '{}'"".format(+            message, response))+++def _unary_stream_client(channel, multicallable_kwargs, message):+    multi_callable = channel.unary_stream(_UNARY_STREAM)+    response_iterator = multi_callable(message, **multicallable_kwargs)+    for response in response_iterator:+        if response != message:+            raise RuntimeError(""Request '{}' != Response '{}'"".format(+                message, response))+++def _stream_unary_client(channel, multicallable_kwargs, message):+    multi_callable = channel.stream_unary(_STREAM_UNARY)+    requests = (_REQUEST for _ in range(_STREAM_LENGTH))+    response = multi_callable(requests, **multicallable_kwargs)+    if response != message:+        raise RuntimeError(""Request '{}' != Response '{}'"".format(+            message, response))+++def _stream_stream_client(channel, multicallable_kwargs, message):+    multi_callable = channel.stream_stream(_STREAM_STREAM)+    request_prefix = str(0).encode('ascii') * 100+    requests = (+        request_prefix + str(i).encode('ascii') for i in range(_STREAM_LENGTH))+    response_iterator = multi_callable(requests, **multicallable_kwargs)+    for i, response in enumerate(response_iterator):+        if int(response.decode('ascii')) != i:+            raise RuntimeError(""Request '{}' != Response '{}'"".format(+                i, response))++ class CompressionTest(unittest.TestCase): -    def setUp(self):-        self._server = test_common.test_server()-        self._server.add_generic_rpc_handlers((_GenericHandler(),))-        self._port = self._server.add_insecure_port('[::]:0')-        self._server.start()--    def tearDown(self):-        self._server.stop(None)--    def testUnary(self):-        request = b'\x00' * 100--        # Client -> server compressed through default client channel compression-        # settings. Server -> client compressed via server-side metadata setting.-        # TODO(https://github.com/grpc/grpc/issues/4078): replace the ""1"" integer-        # literal with proper use of the public API.-        compressed_channel = grpc.insecure_channel(-            'localhost:%d' % self._port,-            options=[('grpc.default_compression_algorithm', 1)])-        multi_callable = compressed_channel.unary_unary(_UNARY_UNARY)-        response = multi_callable(request)-        self.assertEqual(request, response)--        # Client -> server compressed through client metadata setting. Server ->-        # client compressed via server-side metadata setting.-        # TODO(https://github.com/grpc/grpc/issues/4078): replace the ""0"" integer-        # literal with proper use of the public API.-        uncompressed_channel = grpc.insecure_channel(-            'localhost:%d' % self._port,-            options=[('grpc.default_compression_algorithm', 0)])-        multi_callable = compressed_channel.unary_unary(_UNARY_UNARY)-        response = multi_callable(-            request, metadata=[('grpc-internal-encoding-request', 'gzip')])-        self.assertEqual(request, response)-        compressed_channel.close()--    def testStreaming(self):-        request = b'\x00' * 100--        # TODO(https://github.com/grpc/grpc/issues/4078): replace the ""1"" integer-        # literal with proper use of the public API.-        compressed_channel = grpc.insecure_channel(-            'localhost:%d' % self._port,-            options=[('grpc.default_compression_algorithm', 1)])-        multi_callable = compressed_channel.stream_stream(_STREAM_STREAM)-        call = multi_callable(iter([request] * test_constants.STREAM_LENGTH))-        for response in call:-            self.assertEqual(request, response)-        compressed_channel.close()+    def assertCompressed(self, compression_ratio):+        self.assertLess(+            compression_ratio,+            -1.0 * _COMPRESSION_RATIO_THRESHOLD,+            msg='Actual compression ratio: {}'.format(compression_ratio))++    def assertNotCompressed(self, compression_ratio):+        self.assertGreaterEqual(+            compression_ratio,+            -1.0 * _COMPRESSION_RATIO_THRESHOLD,+            msg='Actual compession ratio: {}'.format(compression_ratio))++    def assertConfigurationCompressed(+            self, client_streaming, server_streaming, channel_compression,+            multicallable_compression, server_compression,+            server_call_compression):+        client_side_compressed = channel_compression or multicallable_compression+        server_side_compressed = server_compression or server_call_compression+        channel_kwargs = {+            'compression': channel_compression,+        } if channel_compression else {}+        multicallable_kwargs = {+            'compression': multicallable_compression,+        } if multicallable_compression else {}++        client_function = None+        if not client_streaming and not server_streaming:+            client_function = _unary_unary_client+        elif not client_streaming and server_streaming:+            client_function = _unary_stream_client+        elif client_streaming and not server_streaming:+            client_function = _stream_unary_client+        else:+            client_function = _stream_stream_client++        server_kwargs = {+            'compression': server_compression,+        } if server_compression else {}+        server_handler = _GenericHandler(+            functools.partial(set_call_compression, grpc.Compression.Gzip)+        ) if server_call_compression else _GenericHandler(None)+        sent_ratio, received_ratio = _get_compression_ratios(+            client_function, {}, {}, {}, _GenericHandler(None), channel_kwargs,+            multicallable_kwargs, server_kwargs, server_handler, _REQUEST)++        if client_side_compressed:+            self.assertCompressed(sent_ratio)+        else:+            self.assertNotCompressed(sent_ratio)++        if server_side_compressed:+            self.assertCompressed(received_ratio)+        else:+            self.assertNotCompressed(received_ratio)++    def testDisableNextCompressionStreaming(self):+        server_kwargs = {+            'compression': grpc.Compression.Deflate,+        }+        _, received_ratio = _get_compression_ratios(+            _stream_stream_client, {}, {}, {}, _GenericHandler(None), {}, {},+            server_kwargs, _GenericHandler(disable_next_compression), _REQUEST)+        self.assertNotCompressed(received_ratio)++    def testDisableNextCompressionStreamingResets(self):+        server_kwargs = {+            'compression': grpc.Compression.Deflate,+        }+        _, received_ratio = _get_compression_ratios(+            _stream_stream_client, {}, {}, {}, _GenericHandler(None), {}, {},+            server_kwargs, _GenericHandler(disable_first_compression), _REQUEST)+        self.assertCompressed(received_ratio)+++def _get_compression_str(name, value):+    return '{}{}'.format(name, _COMPRESSION_NAMES[value])+++def _get_compression_test_name(client_streaming, server_streaming,+                               channel_compression, multicallable_compression,+                               server_compression, server_call_compression):+    client_arity = 'Stream' if client_streaming else 'Unary'+    server_arity = 'Stream' if server_streaming else 'Unary'+    arity = '{}{}'.format(client_arity, server_arity)+    channel_compression_str = _get_compression_str('Channel',+                                                   channel_compression)+    multicallable_compression_str = _get_compression_str(+        'Multicallable', multicallable_compression)+    server_compression_str = _get_compression_str('Server', server_compression)+    server_call_compression_str = _get_compression_str('ServerCall',+                                                       server_call_compression)+    return 'test{}{}{}{}{}'.format(+        arity, channel_compression_str, multicallable_compression_str,+        server_compression_str, server_call_compression_str)+++def _test_options(remaining_options=_TEST_OPTIONS, options={}):+    if len(remaining_options) == 0:+        yield options+    else:+        key = next(iter(remaining_options.keys()))+        new_remaining = dict(remaining_options)+        del new_remaining[key]+        values = remaining_options[key]+        for value in values:+            new_options = dict(options)+            new_options[key] = value+            for result in _test_options(new_remaining, new_options):+                yield result","My bad for suggesting generator. After searching, I found a Pythonic way to do this using [itertools.product](https://docs.python.org/2/library/itertools.html#itertools.product):```Pythonfrom itertools import productdef _test_options():    test_option_names, test_option_choices = zip(*_TEST_OPTIONS.items())    for test_option in product(*test_option_choices):        yield zip(test_option_names, test_option)```",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/18564,271107705,2019-04-02T01:39:27Z,src/python/grpcio/grpc/__init__.py,"@@ -1788,6 +1843,12 @@ def _create_servicer_context(rpc_event, state, request_deserializer):     context._finalize_state()  # pylint: disable=protected-access  +class Compression(object):","Also, can you add this class to Sphinx template located at `doc/python/sphinx/grpc.rst`?",
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/18564,271440694,2019-04-02T18:30:56Z,src/python/grpcio/grpc/_server.py,"@@ -504,6 +539,7 @@ def _unary_response_in_pool(rpc_event, state, behavior, argument_thunk,         if argument is not None:             response, proceed = _call_behavior(rpc_event, state, behavior,                                                argument, request_deserializer)+            _maybe_request_compression(state, rpc_event)",We definitely do need this here. Setting the `compression` attribute of the state object does nothing from core's perspective. `_maybe_request_compression` takes the value of the attribute and translates it into initial metadata interpretable by core.,OK
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/18586,271443671,2019-04-02T18:38:24Z,src/core/ext/filters/client_channel/service_config.h,"@@ -96,6 +105,26 @@ class ServiceConfig : public RefCounted<ServiceConfig> {   static RefCountedPtr<T> MethodConfigTableLookup(       const SliceHashTable<RefCountedPtr<T>>& table, const grpc_slice& path); +  /// Retrieves the parsed object at index \a index.+  ServiceConfigParsedObject* GetParsedServiceConfigObject(int index) {+    GPR_DEBUG_ASSERT(index < registered_parsers_count);+    return parsed_service_config_objects[index].get();+  }++  typedef UniquePtr<ServiceConfigParsedObject> (*ServiceConfigParser)(","I was thinking of using the parser function to invoke the existing ParseGlobalParams and CreateMethodConfigTable, but making it a class will also work",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18586,271450882,2019-04-02T18:57:51Z,src/core/ext/filters/client_channel/service_config.h,"@@ -120,9 +149,16 @@ class ServiceConfig : public RefCounted<ServiceConfig> {       grpc_json* json, CreateValue<T> create_value,       typename SliceHashTable<RefCountedPtr<T>>::Entry* entries, size_t* idx); +  static constexpr int kMaxParsers = 32;+  static int registered_parsers_count;+  static ServiceConfigParser registered_parsers[kMaxParsers];+   UniquePtr<char> service_config_json_;   UniquePtr<char> json_string_;  // Underlying storage for json_tree.   grpc_json* json_tree_;++  InlinedVector<UniquePtr<ServiceConfigParsedObject>, kMaxParsers>","That would mean that each filter would have its own method config table, which means that each filter would have to independently look up the call's method in their own instance of the table.  It seems like it would be better for performance to have a single method config table whose value contains the per-method data for every filter.  That way, we can do the method config table lookup only once per call, in the client_channel filter.  We would then pass the resulting array of parsed objects into the subchannel stack, so each filter could grab its data via the index of its parser.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18618,271504290,2019-04-02T21:32:38Z,src/core/ext/filters/client_channel/subchannel.cc,"@@ -58,12 +58,12 @@ #define INTERNAL_REF_BITS 16 #define STRONG_REF_MASK (~(gpr_atm)((1 << INTERNAL_REF_BITS) - 1)) -// Backoff parameters.-#define GRPC_SUBCHANNEL_INITIAL_CONNECT_BACKOFF_SECONDS 1","We should keep these names consistent with the ones in the backoff doc:https://github.com/grpc/grpc/blob/master/doc/connection-backoff.mdOtherwise, it's gets very confusing as to which ones are which when trying to verify if our behavior matches the documented behavior.  (There are a lot of subtleties here; we had to go through several iterations of the backoff code when we converted it to C++.)",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/18564,271529743,2019-04-02T23:13:23Z,src/python/grpcio/grpc/_server.py,"@@ -259,14 +261,20 @@ def auth_context(self):                 cygrpc.auth_context(self._rpc_event.call))         } +    def set_compression(self, compression):+        with self._state.condition:+            self._state.compression_algorithm = compression+     def send_initial_metadata(self, initial_metadata):         with self._state.condition:             if self._state.client is _CANCELLED:                 _raise_rpc_error(self._state)             else:                 if self._state.initial_metadata_allowed:+                    augmented_metadata = _compression.augment_metadata(+                        initial_metadata, self._state.compression_algorithm)","Is this path mergeable with `_get_default_initial_metadata_operation` like `initial_metadata` can be empty by default, but if supplied then merge it with compression metadata?",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/18564,271530146,2019-04-02T23:15:13Z,src/python/grpcio/grpc/_server.py,"@@ -390,6 +398,16 @@ def unary_request():     return unary_request  +def _get_default_initial_metadata_operation(state):","nit: Should we follow the define-before-use pattern, and move this function above `_abort`?",OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/18564,271532007,2019-04-02T23:24:50Z,src/python/grpcio/grpc/_server.py,"@@ -390,6 +398,16 @@ def unary_request():     return unary_request  +def _get_default_initial_metadata_operation(state):","Fair point. Counterpoint: This file is so large that ""comes-before"" and ""comes-after"" relationships have no meaning. It's not practical to scroll through. Every time I've navigated this file, I've done so by jumping between function definitions. Less of an argument against your suggestion and more of an argument against such large files. Fixed.",
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/18564,271533797,2019-04-02T23:34:42Z,src/python/grpcio/grpc/_server.py,"@@ -390,6 +398,16 @@ def unary_request():     return unary_request  +def _get_default_initial_metadata_operation(state):+    with state.condition:+        if state.initial_metadata_allowed:","Not strictly speaking, no. But `state.condition` is an `RLock`, so it should be fine here. The alternative, in my opinion would be to add a `_locked` suffix to the function to indicate that it should only be called when the condition is held, but I don't like that option as much.",OK
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/18618,271556707,2019-04-03T02:05:14Z,src/core/ext/filters/client_channel/subchannel.cc,"@@ -58,12 +58,12 @@ #define INTERNAL_REF_BITS 16 #define STRONG_REF_MASK (~(gpr_atm)((1 << INTERNAL_REF_BITS) - 1)) -// Backoff parameters.-#define GRPC_SUBCHANNEL_INITIAL_CONNECT_BACKOFF_SECONDS 1",Using the full name in the doc might be a little too verbose. I added the arg names for the configurable parameters.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18618,271747219,2019-04-03T13:40:10Z,src/core/ext/filters/client_channel/subchannel.cc,"@@ -503,6 +500,8 @@ BackOff::Options ParseArgsForBackoffValues(                 {static_cast<int>(initial_backoff_ms), 100, INT_MAX});       } else if (0 ==                  strcmp(args->args[i].key, GRPC_ARG_MIN_RECONNECT_BACKOFF_MS)) {+        // TODO(juanlishen): Consider rename GRPC_ARG_MIN_RECONNECT_BACKOFF_MS","I think it's fine to rename this.  We can do this in a backward-compatible way by defining the existing macro as a duplicate of the new one.If you do this, please add a note about removing the old macro to doc/core/pending_api_cleanups.md.",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/18623,271805573,2019-04-03T15:39:00Z,src/core/lib/iomgr/cfstream_handle.cc,"@@ -173,4 +173,11 @@ void CFStreamHandle::Unref(const char* file, int line, const char* reason) {   } } +#else++/* Creating a dummy function so that the grpc_cfstream library will be","nit, but I just noticed this and IIRC the multiline comment format should have an empty line on the top:```/* * Creating a dummy function so that the grpc_cfstream library will be * non-empty. */```",OK
12239891,karthikravis,https://api.github.com/repos/grpc/grpc/pulls/18458,271905137,2019-04-03T19:51:12Z,src/cpp/server/server_cc.cc,"@@ -106,43 +106,213 @@ class UnimplementedAsyncRequestContext {  }  // namespace +ServerInterface::BaseAsyncRequest::BaseAsyncRequest(","class ServerInterface is still in grpc namespace and class Server is moved to grpc_impl namespace. That is what is causing this movement as we have the grpc namespace declared above grpc_impl namespace and hence this move comes as a part of it. Does this make sense? Is it OK to leave it as-is now or should I move the grpc namespace below? (The diff doesn't show this change, but it is visible in line #276 on the new file on right hand side of diff).",
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/18458,271967214,2019-04-03T23:12:05Z,include/grpcpp/server_impl.h,"@@ -0,0 +1,360 @@+/*+ *+ * Copyright 2015 gRPC authors.","No, since this file is technically just a rename of `server.h`, it gets to keep its (c) value from there.",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18652,272777863,2019-04-06T01:10:49Z,src/csharp/Grpc.Core/Internal/DefaultCallCredentialsConfigurator.cs,"@@ -0,0 +1,85 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Generic;+using Grpc.Core.Utils;++namespace Grpc.Core.Internal+{+    /// <summary>+    /// Creates native call credential objects from instances of <c>CallCredentials</c>.+    /// </summary>+    internal class DefaultCallCredentialsConfigurator : CallCredentialsConfiguratorBase+    {+        CallCredentialsSafeHandle nativeCredentials;++        public CallCredentialsSafeHandle NativeCredentials => nativeCredentials;++        public override void SetAsyncAuthInterceptorCredentials(object state, AsyncAuthInterceptor interceptor)+        {+            GrpcPreconditions.CheckState(nativeCredentials == null);++            var plugin = new NativeMetadataCredentialsPlugin(interceptor);+            nativeCredentials = plugin.Credentials;+        }++        public override void SetCompositeCredentials(object state, IReadOnlyList<CallCredentials> credentials)+        {+            GrpcPreconditions.CheckState(nativeCredentials == null);++            GrpcPreconditions.CheckArgument(credentials.Count >= 2);+            nativeCredentials = CompositeToNativeRecursive(credentials, 0);+        }++        // Recursive descent makes managing lifetime of intermediate CredentialSafeHandle instances easier.+        // In practice, we won't usually see composites from more than two credentials anyway.+        private CallCredentialsSafeHandle CompositeToNativeRecursive(IReadOnlyList<CallCredentials> credentials, int startIndex)+        {+            if (startIndex == credentials.Count - 1)+            {+                return credentials[startIndex].ToNativeCredentials();+            }++            using (var cred1 = credentials[startIndex].ToNativeCredentials())+            using (var cred2 = CompositeToNativeRecursive(credentials, startIndex + 1))+            {+                var nativeComposite = CallCredentialsSafeHandle.CreateComposite(cred1, cred2);+                if (nativeComposite.IsInvalid)+                {+                    throw new ArgumentException(""Error creating native composite credentials. Likely, this is because you are trying to compose incompatible credentials."");+                }+                return nativeComposite;+            }+        }+    }++    internal static class CallCredentialsExtensions",A bit caught here - this new type is unused?,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18652,272779055,2019-04-06T01:43:30Z,src/csharp/Grpc.Core/Internal/DefaultCallCredentialsConfigurator.cs,"@@ -0,0 +1,85 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Generic;+using Grpc.Core.Utils;++namespace Grpc.Core.Internal+{+    /// <summary>+    /// Creates native call credential objects from instances of <c>CallCredentials</c>.+    /// </summary>+    internal class DefaultCallCredentialsConfigurator : CallCredentialsConfiguratorBase+    {+        CallCredentialsSafeHandle nativeCredentials;++        public CallCredentialsSafeHandle NativeCredentials => nativeCredentials;++        public override void SetAsyncAuthInterceptorCredentials(object state, AsyncAuthInterceptor interceptor)+        {+            GrpcPreconditions.CheckState(nativeCredentials == null);++            var plugin = new NativeMetadataCredentialsPlugin(interceptor);+            nativeCredentials = plugin.Credentials;+        }++        public override void SetCompositeCredentials(object state, IReadOnlyList<CallCredentials> credentials)+        {+            GrpcPreconditions.CheckState(nativeCredentials == null);++            GrpcPreconditions.CheckArgument(credentials.Count >= 2);+            nativeCredentials = CompositeToNativeRecursive(credentials, 0);+        }++        // Recursive descent makes managing lifetime of intermediate CredentialSafeHandle instances easier.+        // In practice, we won't usually see composites from more than two credentials anyway.+        private CallCredentialsSafeHandle CompositeToNativeRecursive(IReadOnlyList<CallCredentials> credentials, int startIndex)+        {+            if (startIndex == credentials.Count - 1)+            {+                return credentials[startIndex].ToNativeCredentials();+            }++            using (var cred1 = credentials[startIndex].ToNativeCredentials())+            using (var cred2 = CompositeToNativeRecursive(credentials, startIndex + 1))+            {+                var nativeComposite = CallCredentialsSafeHandle.CreateComposite(cred1, cred2);+                if (nativeComposite.IsInvalid)+                {+                    throw new ArgumentException(""Error creating native composite credentials. Likely, this is because you are trying to compose incompatible credentials."");+                }+                return nativeComposite;+            }+        }+    }++    internal static class CallCredentialsExtensions","Might be missing something but this also seems unused in #18532 - if this will be involved in a future change, can we add it into this PR?",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18651,272781184,2019-04-06T02:55:54Z,tools/dockerfile/interoptest/grpc_interop_java_oracle8/build_interop.sh,"@@ -16,16 +16,24 @@ # Builds Java interop server and client in a base image. set -e -mkdir -p /var/local/git-git clone --recursive --depth 1 /var/local/jenkins/grpc-java /var/local/git/grpc-java+cp -r /var/local/jenkins/grpc-java /tmp/grpc-java","Hmm, IMHO `git clone` is the the safest option over `cp`, since with `git clone`, it's easier to be sure that the resulting repo in the container is at a mint state.",
2811396,ejona86,https://api.github.com/repos/grpc/grpc/pulls/18651,273144466,2019-04-08T16:55:43Z,tools/dockerfile/interoptest/grpc_interop_java_oracle8/build_interop.sh,"@@ -16,16 +16,24 @@ # Builds Java interop server and client in a base image. set -e -mkdir -p /var/local/git-git clone --recursive --depth 1 /var/local/jenkins/grpc-java /var/local/git/grpc-java+cp -r /var/local/jenkins/grpc-java /tmp/grpc-java","During ""real"" builds, it will be a fresh checkout. In dev builds, it is bizarre to me to take the latest commit, which is likely a local-only dev commit, and ignore any changes in progress.I do agree it would be nice to ignore any build outputs already generated. Sort of like specifying $outdir to configure/make. I did toy with it a little for gradle, but it appears to be a very incomplete feature. In any case, gradle does a great job checking incremental builds, so there's little worry of it doing the wrong thing and it would only ""fail"" for dev builds, which wouldn't be unexpected.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18546,273144885,2019-04-08T16:56:46Z,tools/remote_build/windows.bazelrc,"@@ -1,3 +1,51 @@ # TODO(yfen): Merge with rbe_common.bazelrc and enable Windows RBE++startup --host_jvm_args=-Dbazel.DigestFunction=SHA256++build --remote_cache=remotebuildexecution.googleapis.com+build --remote_executor=remotebuildexecution.googleapis.com+build --tls_enabled=true++build --host_crosstool_top=//third_party/toolchains/bazel_0.23.2:toolchain+build --crosstool_top=//third_party/toolchains/bazel_0.23.2:toolchain+build --extra_toolchains=//third_party/toolchains/bazel_0.23.2:cc-toolchain-x64_windows+# Use custom execution platforms defined in third_party/toolchains+build --extra_execution_platforms=//third_party/toolchains:rbe_windows+build --host_platform=//third_party/toolchains:rbe_windows+build --platforms=//third_party/toolchains:rbe_windows++build --shell_executable=C:\\tools\\msys64\\usr\\bin\\bash.exe+build --python_path=C:\\Python27\\python.exe++build --spawn_strategy=remote+build --strategy=Javac=remote+build --strategy=Closure=remote+build --genrule_strategy=remote+build --remote_timeout=3600++build --remote_instance_name=projects/grpc-testing/instances/grpc-windows-rbe-test++build --verbose_failures=true++build --experimental_strict_action_env=true+build --action_env=BAZEL_DO_NOT_DETECT_CPP_TOOLCHAIN=1++# don't use port server+build --define GRPC_PORT_ISOLATED_RUNTIME=1 build --test_tag_filters=-no_windows build --build_tag_filters=-no_windows++# without verbose gRPC logs the test outputs are not very useful+test --test_env=GRPC_VERBOSITY=debug++# Set flags for uploading to BES in order to view results in the Bazel Build+# Results UI.+build --bes_backend=""buildeventservice.googleapis.com""+build --bes_timeout=60s+build --bes_results_url=""https://source.cloud.google.com/results/invocations/""+build --project_id=grpc-testing++build --jobs=30",qq: how large is our current windows cluster?,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18546,273147616,2019-04-08T17:03:19Z,third_party/toolchains/bazel_0.23.2/BUILD,"@@ -0,0 +1,188 @@+# Copyright 2018 The Bazel Authors. All rights reserved.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#    http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++# This becomes the BUILD file for @local_config_cc// under Windows.","to get some more context, where's the contents of bazel_0.23.2 directory coming from?  depending on the answer, it might be a good idea to add a README.md file under third_party/toolchains/bazel_0.23.2 that explains what is the the context: purpose of those files, why they were copied from external repo etc. Are the files defining the windows toolchain to stay or it is just temporary?",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18546,273148878,2019-04-08T17:06:50Z,tools/remote_build/windows.bazelrc,"@@ -1,3 +1,51 @@ # TODO(yfen): Merge with rbe_common.bazelrc and enable Windows RBE+","nit: the README.md file in this directory still says that this runs a ""local"" build, which is no longer true.",
8228229,kkm000,https://api.github.com/repos/grpc/grpc/pulls/18678,273156156,2019-04-08T17:24:09Z,src/csharp/Grpc.Tools/build/_protobuf/Google.Protobuf.Tools.targets,"@@ -38,6 +39,16 @@     <AvailableItemName Include=""Protobuf"" />   </ItemGroup> +  <!-- Design Time Build integration for Visual Studio -->+  <ItemGroup Condition="" '$(DisableProtobufDesignTimeBuild)' != 'true' "" >+    <!-- Add Protobuf items to Content if they are not added yet -->+    <UnaddedProtobufContent Include=""@(Protobuf)"" Exclude=""@(Content)"" />+    <Content Include=""@(UnaddedProtobufContent)"" />","Correct. There is a metadatum that controls this, CopyToOutputDirectory or similar. I'll be at my keyboard later today, but you'll quickly find the exact name, it's very commonly used. It's `true`  for Content and `false` for None by default, but can be set per-item, `<Content Include=... CTOD='false' />`. NuGet may also pack them, please check if it needs more metadata to disable this. I *think* it respects this copy to output value, but please better make sure.This kinda borders on a hack. I'm ok with this if there is really totally clearly no other way to trigger a design time build (DTB), but I'd rather make very sure. AFAICR, previously VS did respect the SourceFilesProjectOutputGroupOutput--or did it only for inter-project dependencies, but not for DTB? In any case, it would be super clean if you could make a request to the VS guys to add a similar supported mechanism for DTB. (I do not know whether the DTB support part is in the roslyn repo on GitHub, or internal to MS--do you, btw?) I'm not totally at ease with adding stuff to Content, as this has a potential of opening a Pandora box of strange behaviors in the field: This is a very old list (it has always been there, I believe), exists in all builds, and we cannot know how people use it in the wild, and where would .proto files end up in their setup. I would certainly feel bad if someone publishes internal sources on their Web site because of this just by upgrading the Tools package.Please rename `UnaddedProtobufContent` to `_Protobuf_TempUnaddedContent` or something in this vein. This list should not be non-`_` in any case. I remember we also agreed at some point to rename DisableProtobufDesignTimeBuild to Protobuf_... something, to go along with the existing ""namespace"" prefix convention.Tangentially, I would not bet my life on this statement, but I'm nearly sure `<Content Include='@(Something) Exclude='@(Content)' />` will do the trick w/o an intermediate list, i.e. the list augmentation is treated generally as `ListName += (Include - Exclude)`. I'll check later today, I'm myself wondering if this is so! :)",
8228229,kkm000,https://api.github.com/repos/grpc/grpc/pulls/18678,273294927,2019-04-09T01:22:45Z,src/csharp/Grpc.Tools/build/_protobuf/Google.Protobuf.Tools.targets,"@@ -28,6 +28,7 @@       <ProtoRoot Condition=""'%(Protobuf.ProtoRoot)' == '' "" />       <CompileOutputs Condition=""'%(Protobuf.CompileOutputs)' == ''"">True</CompileOutputs>       <OutputDir Condition=""'%(Protobuf.OutputDir)' == '' "">$(Protobuf_OutputPath)</OutputDir>+      <Generator Condition="" '$(DisableProtobufDesignTimeBuild)' != 'true' "" >MSBuild:Compile</Generator>","Does it make sense to follow the pattern and use ```xml<Generator Condition="" %(Protobuf.Generator)' == '' and '$(DisableProtobufDesignTimeBuild)' != 'true' "" >MSBuild:Compile</Generator>```? If the generator can change per item, why not allow setting it using a user's itemdefgroup? ",
8228229,kkm000,https://api.github.com/repos/grpc/grpc/pulls/18678,273298762,2019-04-09T01:47:03Z,src/csharp/Grpc.Tools/build/_protobuf/Google.Protobuf.Tools.targets,"@@ -28,6 +28,7 @@       <ProtoRoot Condition=""'%(Protobuf.ProtoRoot)' == '' "" />       <CompileOutputs Condition=""'%(Protobuf.CompileOutputs)' == ''"">True</CompileOutputs>       <OutputDir Condition=""'%(Protobuf.OutputDir)' == '' "">$(Protobuf_OutputPath)</OutputDir>+      <Generator Condition="" '$(DisableProtobufDesignTimeBuild)' != 'true' "" >MSBuild:Compile</Generator>","Sure, it's kind of half-way in the middle. If the generator may never change at all, or should be global, then a property would work better. But as long as it is among the item's metadata, the usual pattern is to allow a redefinition of defaults for the whole ItemGroup.I still had no time to play with MSBuild to see of a simpler syntax of list augmentation would cut it. Likely tomorrow.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18546,273332211,2019-04-09T05:43:58Z,tools/remote_build/windows.bazelrc,"@@ -1,3 +1,49 @@-# TODO(yfen): Merge with rbe_common.bazelrc and enable Windows RBE",nit: still worth looking into what .bazelrc files we can include to avoid duplication. Fine to do as a followup.,OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18688,273565488,2019-04-09T15:58:46Z,tools/run_tests/sanity/cpp_banned_constructs.sh,"@@ -0,0 +1,28 @@+#!/bin/sh+# Copyright 2019 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++set -e++cd ""$(dirname ""$0"")/../../..""++#+# Prevent the use of synchronization constructs from std:: since the code should+# be using grpc_core::Mutex, grpc::internal::Mutex, and related functions+#++egrep -Irn \+    'std::(mutex( |$)|condition_variable( |$)|lock_guard<|unique_lock<)' \","Actually, looking it over, I think the trying to detect tokenization thing was just a bad idea. Someone could always make a `std::unique_ptr<std::mutex>` and that would slip through. So I've just changed it to stop trying to do that since at least at the current time, there are no allowed members of `std::` that have these names as prefixes anyway. If such a thing arises in the future, we can change the script then.",
41599993,billfeng327,https://api.github.com/repos/grpc/grpc/pulls/18546,273636351,2019-04-09T18:16:24Z,tools/remote_build/windows.bazelrc,"@@ -1,3 +1,49 @@-# TODO(yfen): Merge with rbe_common.bazelrc and enable Windows RBE","This file has to exist as an independent config for a while, because we don't want to change the default Linux RBE behavior. With the combined file, it requires Linux RBE to have additional arguments.",
2030323,JunTaoLuo,https://api.github.com/repos/grpc/grpc/pulls/18652,273706514,2019-04-09T21:11:08Z,src/csharp/Grpc.Core/CallCredentialsConfiguratorBase.cs,"@@ -0,0 +1,38 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System.Collections.Generic;++namespace Grpc.Core+{+    /// <summary>+    /// Base class for objects that can consume configuration from <c>CallCredentials</c> objects.+    /// </summary>+    public abstract class CallCredentialsConfiguratorBase",Any reason this is an abstract class instead of an interface?,
303201,JamesNK,https://api.github.com/repos/grpc/grpc/pulls/18652,273710410,2019-04-09T21:22:47Z,src/csharp/Grpc.Core/CallCredentialsConfiguratorBase.cs,"@@ -0,0 +1,38 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System.Collections.Generic;++namespace Grpc.Core+{+    /// <summary>+    /// Base class for objects that can consume configuration from <c>CallCredentials</c> objects.+    /// </summary>+    public abstract class CallCredentialsConfiguratorBase",Any reason to make it an interface instead of an abstract class? 😋 You can't add new methods to an interface. Can we imagine a scenario where you would want to add new methods here?,OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/18687,273715197,2019-04-09T21:37:45Z,include/grpcpp/impl/codegen/server_callback.h,"@@ -588,6 +622,14 @@ class CallbackClientStreamingHandler : public MethodHandler {      reader->BindReactor(reactor);     reactor->OnStarted(param.server_context, reader->response());+    // Use release memory ordering on the cancellation state to make sure that+    // all stores that took place in OnStarted are seen when the cancellation+    // state is seen as being ON_STARTED_DONE. Not needed for failure case.","Thank you. Oh, I see. Yes, changes in `OnStarted` are safe. My (rather stupid) question was whether `reactor` can be modified in a separate thread in parallel to this thread? In other words, can `ServerContext::CompletionOp::FinalizeResult` race with this thread?I presumed the answer is yes, because otherwise you wouldn't have used atomics. Now, if that can happen, do we need the changes from the thread running `ServerContext::CompletionOp::FinalizeResult` be visible to this thread?",OK
2030323,JunTaoLuo,https://api.github.com/repos/grpc/grpc/pulls/18652,273736938,2019-04-09T23:02:29Z,src/csharp/Grpc.Core/CallCredentialsConfiguratorBase.cs,"@@ -0,0 +1,38 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System.Collections.Generic;++namespace Grpc.Core+{+    /// <summary>+    /// Base class for objects that can consume configuration from <c>CallCredentials</c> objects.+    /// </summary>+    public abstract class CallCredentialsConfiguratorBase","I suppose I'm too used to interfaces so the abstract base class seemed odd to me. But if serviceability is the reason, it seems fine.",
8228229,kkm000,https://api.github.com/repos/grpc/grpc/pulls/18678,273744144,2019-04-09T23:39:06Z,src/csharp/Grpc.Tools/build/_protobuf/Google.Protobuf.Tools.targets,"@@ -38,6 +39,16 @@     <AvailableItemName Include=""Protobuf"" />   </ItemGroup> +  <!-- Design Time Build integration for Visual Studio -->+  <ItemGroup Condition="" '$(DisableProtobufDesignTimeBuild)' != 'true' "" >+    <!-- Add Protobuf items to Content if they are not added yet -->+    <UnaddedProtobufContent Include=""@(Protobuf)"" Exclude=""@(Content)"" />+    <Content Include=""@(UnaddedProtobufContent)"" />","Just FYI, probably not relevant any more as the issue has been fixed in dotnetbuild, but, as I suspected, an intermediate list (like UnaddedProtobufContent here) is not required.test.xml```xml<Project DefaultTargets=""Build"">  <ItemGroup>    <Proto Include=""a;b;c;1"" />    <Content Include=""a;1;2;3"" />        <Content Include=""@(Proto)"" Exclude=""@(Content)"" />  </ItemGroup>    <Target Name=""Build"">    <Message Importance=""high"" Text=""@(Content)"" />  </Target></Project>```Result:```c:\temp>msbuild test.xmlMicrosoft (R) Build Engine version 15.9.21+g9802d43bc3 for .NET FrameworkCopyright (C) Microsoft Corporation. All rights reserved.Build started 19-04-09 16:24:13.Project ""c:\temp\test.xml"" on node 1 (default targets).Build:  a;1;2;3;b;cDone Building Project ""c:\temp\test.xml"" (default targets).```So the general pattern `<X Include=""@(Y)"" Exclude=""@(X) />` adds to the end of X only those items in Y that do not have corresponding identically named items in X already.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18652,273793939,2019-04-10T05:27:51Z,src/csharp/Grpc.Core/CallCredentialsConfiguratorBase.cs,"@@ -0,0 +1,38 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System.Collections.Generic;++namespace Grpc.Core+{+    /// <summary>+    /// Base class for objects that can consume configuration from <c>CallCredentials</c> objects.+    /// </summary>+    public abstract class CallCredentialsConfiguratorBase","Yes, being able to add more CallCredential types is the reason for choosing abstract class.Also more configuration args could be added for some of the credentials, in which case we would need to add a new method to the abstract class.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18652,273794475,2019-04-10T05:31:08Z,src/csharp/Grpc.Core/Internal/DefaultCallCredentialsConfigurator.cs,"@@ -0,0 +1,85 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Generic;+using Grpc.Core.Utils;++namespace Grpc.Core.Internal+{+    /// <summary>+    /// Creates native call credential objects from instances of <c>CallCredentials</c>.+    /// </summary>+    internal class DefaultCallCredentialsConfigurator : CallCredentialsConfiguratorBase+    {+        CallCredentialsSafeHandle nativeCredentials;++        public CallCredentialsSafeHandle NativeCredentials => nativeCredentials;++        public override void SetAsyncAuthInterceptorCredentials(object state, AsyncAuthInterceptor interceptor)","The state is currently unused. The idea was to add the state to allow future optimization that would avoid allocations (so yes, it's kind of a future proofing mechanism).",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18532,273801499,2019-04-10T06:09:38Z,src/csharp/Grpc.Core.Api/LiteClientBase.cs,"@@ -0,0 +1,96 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;++namespace Grpc.Core+{+    /// <summary>+    /// Base class for lightweight client-side stubs.+    /// All calls are invoked via a <c>CallInvoker</c>.+    /// Lite client stubs have no configuration knobs, all configuration+    /// is provided by decorating the call invoker.+    /// Note: experimental API that can change or be removed without any prior notice.+    /// </summary>+    public abstract class LiteClientBase+    {+        readonly CallInvoker callInvoker;++        /// <summary>+        /// Initializes a new instance of <c>ClientBase</c> class that",I removed the class from this PR and will add it in a separate PR (it has no reason for being here besides checking we have moved all the prerequisites to be able to implement it).,OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18705,273804431,2019-04-10T06:23:08Z,src/csharp/Grpc.Core.Api/LiteClientBase.cs,"@@ -0,0 +1,96 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;++namespace Grpc.Core+{+    /// <summary>+    /// Base class for lightweight client-side stubs.+    /// All calls are invoked via a <c>CallInvoker</c>.+    /// Lite client stubs have no configuration knobs, all configuration+    /// is provided by decorating the call invoker.+    /// Note: experimental API that can change or be removed without any prior notice.+    /// </summary>+    public abstract class LiteClientBase",the name of the class is TBD.,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/11221,273910631,2019-04-10T11:27:30Z,src/compiler/csharp_generator.cc,"@@ -49,7 +48,9 @@ using grpc::protobuf::Descriptor; using grpc::protobuf::ServiceDescriptor; using grpc::protobuf::MethodDescriptor; using grpc::protobuf::io::Printer;-using grpc::protobuf::io::StringOutputStream;+using grpc_generator::Printer;",how exactly are you planning to switch out the protobuf dependency and provide an flatbuffer-specific implementation of these?  It seems like ripping out individual .cc files from our codebase and trying to get them built elsewhere.,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/11221,273913302,2019-04-10T11:35:22Z,src/compiler/csharp_generator.cc,"@@ -49,7 +48,9 @@ using grpc::protobuf::Descriptor; using grpc::protobuf::ServiceDescriptor; using grpc::protobuf::MethodDescriptor; using grpc::protobuf::io::Printer;-using grpc::protobuf::io::StringOutputStream;+using grpc_generator::Printer;","To be honest, maintaining this in a working condition sounds like more work that just rewriting the codegen for grpc-flatbuffers C# from scratch (which isn't really that difficult, its a few hunded lines of code that fprintf stuff and the logic is rather trivial).  I'm happy to be convinced otherwise :-)",OK
2811396,ejona86,https://api.github.com/repos/grpc/grpc/pulls/18651,274055993,2019-04-10T16:41:35Z,tools/dockerfile/interoptest/grpc_interop_java/build_interop.sh,"@@ -16,16 +16,24 @@ # Builds Java interop server and client in a base image. set -e -mkdir -p /var/local/git-git clone --recursive --depth 1 /var/local/jenkins/grpc-java /var/local/git/grpc-java+cp -r /var/local/jenkins/grpc-java /tmp/grpc-java","Also FTR, the git dependency hid a dependency added by protobuf, because git brought in that dependency. https://github.com/protocolbuffers/protobuf/issues/5875 . After my changes the container notices that libatomic was incorrectly added as a dependency.",
303201,JamesNK,https://api.github.com/repos/grpc/grpc/pulls/18714,274142616,2019-04-10T20:29:30Z,templates/tools/dockerfile/interoptest/grpc_interop_aspnetcore/build_interop.sh.template,"@@ -25,14 +25,11 @@   cp -r /var/local/jenkins/service_account $HOME || true    cd /var/local/git/grpc-dotnet-  +   # If needed, update dotnet SDK and put it on path   ./build/get-dotnet.sh-  if [ -f $HOME/.dotnet/dotnet ]-  then-    ln -s $HOME/.dotnet/dotnet /usr/local/bin/dotnet-  fi-  +  source ./activate.sh",There is a circular dependency here between this PR and https://github.com/grpc/grpc-dotnet/pull/205. activate.sh doesn't exist in the grpc-dotnet repo yet.What is the best way to resolve this? Would merging activate.sh in a separate PR help?,OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18748,275309342,2019-04-15T11:05:32Z,tools/internal_ci/windows/bazel_rbe.bat,"@@ -0,0 +1,18 @@+@rem Copyright 2019 gRPC authors.+@rem+@rem Licensed under the Apache License, Version 2.0 (the ""License"");+@rem you may not use this file except in compliance with the License.+@rem You may obtain a copy of the License at+@rem+@rem     http://www.apache.org/licenses/LICENSE-2.0+@rem+@rem Unless required by applicable law or agreed to in writing, software+@rem distributed under the License is distributed on an ""AS IS"" BASIS,+@rem WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+@rem See the License for the specific language governing permissions and+@rem limitations under the License.++choco install bazel -y --version 0.23.2+cd github/grpc+set PATH=%PATH%;C:\python27\+bazel --bazelrc=tools/remote_build/windows.bazelrc build :all --incompatible_disallow_filetype=false --google_credentials=%KOKORO_GFILE_DIR%/rbe-windows-credentials.json","future improvements: I think in order to get a ""bazel"" link for the build in Fusion UI, you'll need to do something like this: https://github.com/grpc/grpc/blob/d5769552c6db5dea7c6c7c4e3d8aa6a0ab5368e8/tools/internal_ci/linux/grpc_bazel_on_foundry_base.sh#L37",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18748,275309904,2019-04-15T11:07:38Z,tools/internal_ci/windows/bazel_rbe.bat,"@@ -0,0 +1,18 @@+@rem Copyright 2019 gRPC authors.+@rem+@rem Licensed under the Apache License, Version 2.0 (the ""License"");+@rem you may not use this file except in compliance with the License.+@rem You may obtain a copy of the License at+@rem+@rem     http://www.apache.org/licenses/LICENSE-2.0+@rem+@rem Unless required by applicable law or agreed to in writing, software+@rem distributed under the License is distributed on an ""AS IS"" BASIS,+@rem WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+@rem See the License for the specific language governing permissions and+@rem limitations under the License.++choco install bazel -y --version 0.23.2+cd github/grpc+set PATH=%PATH%;C:\python27\","nit: to stay more consistent with  `prepare_build_widows.bat`, I'd do `set PATH=C:\Python27;%PATH%` instead. Fine to leave as ishttps://github.com/grpc/grpc/blob/d5769552c6db5dea7c6c7c4e3d8aa6a0ab5368e8/tools/internal_ci/helper_scripts/prepare_build_windows.bat#L17",
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/18750,275476146,2019-04-15T17:53:35Z,src/core/lib/security/transport/security_handshaker.cc,"@@ -317,6 +317,9 @@ grpc_error* SecurityHandshaker::OnHandshakeNextDoneLocked( void SecurityHandshaker::OnHandshakeNextDoneGrpcWrapper(     tsi_result result, void* user_data, const unsigned char* bytes_to_send,     size_t bytes_to_send_size, tsi_handshaker_result* handshaker_result) {+  // This callback may be invoked by TSI in a non-grpc thread, so it's safe to+  // create our own exec_ctx here.+  grpc_core::ExecCtx exec_ctx;","I suspect that adding a new `exec_ctx` will break ALTS TSI implementation. The `exec_ctx` is removed in  #16773 and the main reason is that since ALTS TSI is now a part of gRPC core which already has its own active `exec_ctx` and creating another will violate the policy - ""Only allow one ""active"" ExecCtx on a thread at the same time"". ",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18774,275965508,2019-04-16T19:53:38Z,include/grpcpp/impl/codegen/sync.h,"@@ -19,8 +19,15 @@ #ifndef GRPCPP_IMPL_CODEGEN_SYNC_H #define GRPCPP_IMPL_CODEGEN_SYNC_H -#include <grpc/impl/codegen/log.h> #include <grpc/impl/codegen/port_platform.h>++#ifndef GPR_WINDOWS",Hmm... Do we want this kind of conditional outside of port_platform.h?@nicolasnoble should weigh in on this.,
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/18774,275966736,2019-04-16T19:57:04Z,include/grpcpp/impl/codegen/sync.h,"@@ -19,8 +19,15 @@ #ifndef GRPCPP_IMPL_CODEGEN_SYNC_H #define GRPCPP_IMPL_CODEGEN_SYNC_H -#include <grpc/impl/codegen/log.h> #include <grpc/impl/codegen/port_platform.h>++#ifndef GPR_WINDOWS","Here, we have to include `<pthread>` directly without relying on `GPR_SYNC_POSIX` to make sure  the space is large enough wherever `pthread_mutex_t` can possibly be used in place of `gpr_mu`.",
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/18779,275967789,2019-04-16T19:59:43Z,examples/python/wait_for_ready/wait_for_ready_example.py,"@@ -0,0 +1,112 @@+# Copyright 2019 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""The Python example of utilizing wait-for-ready flag.""""""++from __future__ import print_function+import logging+from concurrent import futures+import socket+import threading++import grpc++from examples.protos import helloworld_pb2+from examples.protos import helloworld_pb2_grpc++_LOGGER = logging.getLogger(__name__)+_LOGGER.setLevel(logging.INFO)++_ONE_DAY_IN_SECONDS = 60 * 60 * 24+++def get_free_loopback_tcp_port():+    tcp = socket.socket(socket.AF_INET6)","This naming is a little bit weird. I think `sock` would be more conventional. I know it goes against our rule not to use abbreviations, but in this case, the appropriate name is taken.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18786,276039174,2019-04-17T00:17:19Z,src/core/lib/gpr/arena.h,"@@ -27,17 +27,82 @@  #include <grpc/support/port_platform.h> +#include <atomic>++#include <grpc/support/alloc.h>+#include <grpc/support/atm.h>+#include <grpc/support/sync.h>++#include ""src/core/lib/gpr/alloc.h""+ #include <stddef.h>  typedef struct gpr_arena gpr_arena;  // Create an arena, with \a initial_size bytes in the first allocated buffer gpr_arena* gpr_arena_create(size_t initial_size);-// Allocate \a size bytes from the arena-void* gpr_arena_alloc(gpr_arena* arena, size_t size); // Destroy an arena, returning the total number of bytes allocated size_t gpr_arena_destroy(gpr_arena* arena); // Initializes the Arena component. void gpr_arena_init(); +// Uncomment this to use a simple arena that simply allocates the+// requested amount of memory for each call to gpr_arena_alloc().  This+// effectively eliminates the efficiency gain of using an arena, but it+// may be useful for debugging purposes.+//#define SIMPLE_ARENA_FOR_DEBUGGING+#ifdef SIMPLE_ARENA_FOR_DEBUGGING++void* gpr_arena_alloc(gpr_arena* arena, size_t size);++#else  // SIMPLE_ARENA_FOR_DEBUGGING++typedef struct zone {",Move this class inside the definition of arena or something? So that it isn't polluting the header file?,OK
730,blowmage,https://api.github.com/repos/grpc/grpc/pulls/18752,276462919,2019-04-17T22:51:00Z,src/ruby/lib/grpc/errors.rb,"@@ -47,7 +48,20 @@ def initialize(code, details = 'unknown cause', metadata = {})     #     # @return [Status] with the same code and details     def to_status-      Struct::Status.new(code, details, @metadata)+      Struct::Status.new(code, details, metadata)+    end++    # Converts the exception to a deserialized Google::Rpc::Status proto.+    # Returns nil if the `grpc-status-details-bin` trailer could not be+    # converted to a {Google::Rpc::Status} due to the server not providing+    # the necessary trailers.+    #+    # Raises an error if the server did provide the necessary trailers+    # but they fail to deserialize into a {Google::Rpc::Status} protobuf.+    #+    # @return [Google::Rpc::Status] with the same code and details+    def to_rpc_status+      GoogleRpcStatusUtils.extract_google_rpc_status to_status","Right now `GoogleRpcStatusUtils.extract_google_rpc_status to_status` will raise if the metadata doesn't contains a serialized protobuf. I think it makes sense for `GoogleRpcStatusUtils.extract_google_rpc_status to_status` to raise, but I don't think it makes sense for `BadStatus#to_rpc_status` to raise. Would it be acceptable for this method to rescue from an error and return `nil` instead?",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/18795,276464181,2019-04-17T22:56:45Z,src/objective-c/tests/InteropTests.m,"@@ -341,6 +341,90 @@ - (void)testLargeUnaryRPCWithV2API {   [self waitForExpectationsWithTimeout:TEST_TIMEOUT handler:nil]; } +- (void)testConcurrentRPCsWithErrorsWithV2API {","As discussed offline, this test is a valid interop test case, but not really putting much load on the system. Maybe have a test like this but adds more load, run longer, and run separately from the interop test suite.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18752,276465238,2019-04-17T23:02:08Z,src/ruby/lib/grpc/errors.rb,"@@ -47,7 +48,20 @@ def initialize(code, details = 'unknown cause', metadata = {})     #     # @return [Status] with the same code and details     def to_status-      Struct::Status.new(code, details, @metadata)+      Struct::Status.new(code, details, metadata)+    end++    # Converts the exception to a deserialized Google::Rpc::Status proto.+    # Returns nil if the `grpc-status-details-bin` trailer could not be+    # converted to a {Google::Rpc::Status} due to the server not providing+    # the necessary trailers.+    #+    # Raises an error if the server did provide the necessary trailers+    # but they fail to deserialize into a {Google::Rpc::Status} protobuf.+    #+    # @return [Google::Rpc::Status] with the same code and details+    def to_rpc_status+      GoogleRpcStatusUtils.extract_google_rpc_status to_status","It's basically a server-side error if this fails to deserialize AFAICS, are we seeing this happen against real services?In any case, I'd tend to want to avoid a change like that, just since it's breaking. I different utility that has those semantics might be OK, but first I wonder if that raise is happening with real services.",
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/18795,276476411,2019-04-17T23:59:50Z,src/objective-c/tests/InteropTests.m,"@@ -341,6 +341,90 @@ - (void)testLargeUnaryRPCWithV2API {   [self waitForExpectationsWithTimeout:TEST_TIMEOUT handler:nil]; } +- (void)testConcurrentRPCsWithErrorsWithV2API {",I'll add a new stress test job for long running tests in another PR. The new job will run periodically (not on every PR).,OK
730,blowmage,https://api.github.com/repos/grpc/grpc/pulls/18752,276577564,2019-04-18T09:05:11Z,src/ruby/lib/grpc/errors.rb,"@@ -47,7 +48,20 @@ def initialize(code, details = 'unknown cause', metadata = {})     #     # @return [Status] with the same code and details     def to_status-      Struct::Status.new(code, details, @metadata)+      Struct::Status.new(code, details, metadata)+    end++    # Converts the exception to a deserialized Google::Rpc::Status proto.+    # Returns nil if the `grpc-status-details-bin` trailer could not be+    # converted to a {Google::Rpc::Status} due to the server not providing+    # the necessary trailers.+    #+    # Raises an error if the server did provide the necessary trailers+    # but they fail to deserialize into a {Google::Rpc::Status} protobuf.+    #+    # @return [Google::Rpc::Status] with the same code and details+    def to_rpc_status+      GoogleRpcStatusUtils.extract_google_rpc_status to_status","Well, since `BadStatus#to_rpc_status` doesn't exist, it isn't a breaking change. I don't mean to change the behavior of `GoogleRpcStatusUtils.extract_google_rpc_status`, I just mean to have `BadStatus#to_rpc_status` handle the exception and return `nil`. See my updated commits for what I mean.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18410,276681675,2019-04-18T14:12:40Z,test/core/end2end/tests/connectivity.cc,"@@ -33,6 +33,12 @@ typedef struct {   grpc_completion_queue* cq; } child_events; +typedef struct {+  grpc_experimental_completion_queue_functor functor;+  bool done;+  gpr_mu mu;","If the only purpose of this mutex is to protect `done`, then I suggest just making `done` an atomic.  You can use `grpc_core::Atomic<bool>` for that.https://github.com/grpc/grpc/blob/master/src/core/lib/gprpp/atomic.hBut see my comment below as to whether synchronization is actually needed here.",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18752,276876648,2019-04-19T00:47:28Z,src/ruby/lib/grpc/errors.rb,"@@ -47,7 +48,20 @@ def initialize(code, details = 'unknown cause', metadata = {})     #     # @return [Status] with the same code and details     def to_status-      Struct::Status.new(code, details, @metadata)+      Struct::Status.new(code, details, metadata)+    end++    # Converts the exception to a deserialized Google::Rpc::Status proto.+    # Returns nil if the `grpc-status-details-bin` trailer could not be+    # converted to a {Google::Rpc::Status} due to the server not providing+    # the necessary trailers.+    #+    # Raises an error if the server did provide the necessary trailers+    # but they fail to deserialize into a {Google::Rpc::Status} protobuf.+    #+    # @return [Google::Rpc::Status] with the same code and details+    def to_rpc_status+      GoogleRpcStatusUtils.extract_google_rpc_status to_status","I see, missed that. I think it's fine to have a different semantic for `to_rpc_status`",
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/18766,276915590,2019-04-19T06:57:39Z,examples/objective-c/route_guide/ViewControllers.m,"@@ -191,47 +220,63 @@ @implementation RecordRouteViewController {   RTGRouteGuide *_service; } +- (dispatch_queue_t)dispatchQueue {+  return dispatch_get_main_queue();+}+ - (void)execRequest {   NSString *dataBasePath = [NSBundle.mainBundle pathForResource:@""route_guide_db""                                                          ofType:@""json""];   NSData *dataBaseContent = [NSData dataWithContentsOfFile:dataBasePath];   NSArray *features = [NSJSONSerialization JSONObjectWithData:dataBaseContent options:0 error:NULL]; -  GRXWriter *locations = [[GRXWriter writerWithContainer:features] map:^id(id feature) {+  GRPCStreamingProtoCall *call = [_service recordRouteWithResponseHandler:self+                                                              callOptions:nil];+  [call start];+  for (id feature in features) {     RTGPoint *location = [RTGPoint message];     location.longitude = [((NSNumber *) feature[@""location""][@""longitude""]) intValue];     location.latitude = [((NSNumber *) feature[@""location""][@""latitude""]) intValue];     NSString *str =[NSString stringWithFormat:@""%@\nVisiting point %@"", self.outputLabel.text, location];     self.outputLabel.text = str;     NSLog(@""Visiting point %@"", location);-    return location;-  }];--  [_service recordRouteWithRequestsWriter:locations-                                 handler:^(RTGRouteSummary *response, NSError *error) {-    if (response) {-      NSString *str =[NSString stringWithFormat:-                      @""%@\nFinished trip with %i points\nPassed %i features\n""-                      ""Travelled %i meters\nIt took %i seconds"",-                      self.outputLabel.text, response.pointCount, response.featureCount,-                      response.distance, response.elapsedTime];-      self.outputLabel.text = str;-      NSLog(@""Finished trip with %i points"", response.pointCount);-      NSLog(@""Passed %i features"", response.featureCount);-      NSLog(@""Travelled %i meters"", response.distance);-      NSLog(@""It took %i seconds"", response.elapsedTime);-    } else {-      NSString *str =[NSString stringWithFormat:@""%@\nRPC error: %@"", self.outputLabel.text, error];-      self.outputLabel.text = str;-      NSLog(@""RPC error: %@"", error);-    }-  }];+    [call writeMessage:location];+  }+  [call finish];","Just for my understanding, what happens when `finish` is called? Does the client wait until the server sends responses followed by trailing metadata? ",
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/18766,276916518,2019-04-19T07:03:36Z,examples/objective-c/route_guide/ViewControllers.m,"@@ -191,47 +220,63 @@ @implementation RecordRouteViewController {   RTGRouteGuide *_service; } +- (dispatch_queue_t)dispatchQueue {+  return dispatch_get_main_queue();+}+ - (void)execRequest {   NSString *dataBasePath = [NSBundle.mainBundle pathForResource:@""route_guide_db""                                                          ofType:@""json""];   NSData *dataBaseContent = [NSData dataWithContentsOfFile:dataBasePath];   NSArray *features = [NSJSONSerialization JSONObjectWithData:dataBaseContent options:0 error:NULL]; -  GRXWriter *locations = [[GRXWriter writerWithContainer:features] map:^id(id feature) {+  GRPCStreamingProtoCall *call = [_service recordRouteWithResponseHandler:self+                                                              callOptions:nil];+  [call start];+  for (id feature in features) {","Might be a good idea to validate the JSON data is in expected format, and feature is an NSDictionary of dictionaries.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18807,277001408,2019-04-19T14:33:23Z,src/core/lib/transport/metadata.h,"@@ -160,4 +160,9 @@ void grpc_mdelem_unref(grpc_mdelem md); void grpc_mdctx_global_init(void); void grpc_mdctx_global_shutdown(); +inline bool grpc_mdelem_eq_static(grpc_mdelem a_static, grpc_mdelem b_static) {","Please move this up to line 128, next to `grpc_mdelem_eq()`, so that people looking at this file can tell that there are two alternatives.Also, please document how this function differs from `grpc_mdelem_eq()` (it only works on static metadata and only checks the value, not the key), so that it's clear to readers when to use one vs. the other.I suggest renaming this function to something like `grpc_mdelem_static_value_eq()` to make the behavior a bit more clear.",
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/18766,277054561,2019-04-19T18:12:40Z,examples/objective-c/helloworld/main.m,"@@ -25,20 +25,41 @@  static NSString * const kHostAddress = @""localhost:50051""; +@interface HLWResponseHandler : NSObject<GRPCProtoResponseHandler>++@end++// A response handler that only",Nit: incomplete sentence.,OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/18766,277054608,2019-04-19T18:12:53Z,examples/objective-c/helloworld_macos/main.m,"@@ -24,19 +24,40 @@  static NSString * const kHostAddress = @""localhost:50051""; +@interface HLWResponseHandler : NSObject<GRPCProtoResponseHandler>++@end++// A response handler that only",nit: incomplete sentence,
43831800,sheenaqotj,https://api.github.com/repos/grpc/grpc/pulls/18773,277059909,2019-04-19T18:35:00Z,include/grpcpp/generic/generic_stub_impl.h,"@@ -82,6 +82,12 @@ class GenericStub final {                    const grpc::ByteBuffer* request, grpc::ByteBuffer* response,                    std::function<void(grpc::Status)> on_completion); +    /// Setup and start a unary call to a named method \a method using","delete duplicate ""method""",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18773,277095381,2019-04-19T21:25:47Z,include/grpcpp/generic/generic_stub_impl.h,"@@ -82,6 +82,12 @@ class GenericStub final {                    const grpc::ByteBuffer* request, grpc::ByteBuffer* response,                    std::function<void(grpc::Status)> on_completion); +    /// Setup and start a unary call to a named method \a method using","The first method is the English word ""method"" and the second is the parameter `\a method` which gets interpreted by doc builders that we apply at release time.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18773,277095441,2019-04-19T21:26:00Z,include/grpcpp/generic/generic_stub_impl.h,"@@ -82,6 +82,12 @@ class GenericStub final {                    const grpc::ByteBuffer* request, grpc::ByteBuffer* response,                    std::function<void(grpc::Status)> on_completion); +    /// Setup and start a unary call to a named method \a method using","So it's not really a duplicate, is that cool?",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18809,277100437,2019-04-19T21:54:22Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_ev_driver_libuv.cc,"@@ -0,0 +1,132 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */+#include <grpc/support/port_platform.h>++#include ""src/core/lib/iomgr/port.h""+#if GRPC_ARES == 1 && defined(GRPC_UV)++#include <ares.h>+#include <uv.h>++#include ""src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_ev_driver.h""++#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>+#include <grpc/support/time.h>+#include ""src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.h""+#include ""src/core/lib/gpr/string.h""++namespace grpc_core {++void ares_uv_poll_cb(uv_poll_t* handle, int status, int events);++void ares_uv_poll_close_cb(uv_handle_t* handle) { Delete(handle); }++class GrpcPolledFdLibuv : public GrpcPolledFd {+ public:+  GrpcPolledFdLibuv(ares_socket_t as) : as_(as) {+    gpr_asprintf(&name_, ""c-ares socket: %"" PRIdPTR, (intptr_t)as);+    handle_ = New<uv_poll_t>();+    uv_poll_init_socket(uv_default_loop(), handle_, as);+    handle_->data = this;+  }++  ~GrpcPolledFdLibuv() { gpr_free(name_); }++  void RegisterForOnReadableLocked(grpc_closure* read_closure) override {+    GPR_ASSERT(read_closure_ == nullptr);+    GPR_ASSERT((poll_events_ & UV_READABLE) == 0);+    read_closure_ = read_closure;+    poll_events_ |= UV_READABLE;+    uv_poll_start(handle_, poll_events_, ares_uv_poll_cb);+  }++  void RegisterForOnWriteableLocked(grpc_closure* write_closure) override {+    GPR_ASSERT(write_closure_ == nullptr);+    GPR_ASSERT((poll_events_ & UV_WRITABLE) == 0);+    write_closure_ = write_closure;+    poll_events_ |= UV_WRITABLE;+    uv_poll_start(handle_, poll_events_, ares_uv_poll_cb);+  }++  bool IsFdStillReadableLocked() override {+    /* uv_poll_t is based on poll, which is level triggered. So, if cares+     * leaves some data unread, the event will trigger again. */+    return false;+  }++  void ShutdownLocked(grpc_error* error) override {+    uv_poll_stop(handle_);+    uv_close(reinterpret_cast<uv_handle_t*>(handle_), ares_uv_poll_close_cb);+  }++  ares_socket_t GetWrappedAresSocketLocked() override { return as_; }++  const char* GetName() override { return name_; }++  char* name_;+  ares_socket_t as_;+  uv_poll_t* handle_;+  grpc_closure* read_closure_ = nullptr;+  grpc_closure* write_closure_ = nullptr;+  int poll_events_ = 0;+};++void ares_uv_poll_cb(uv_poll_t* handle, int status, int events) {","The thread-safety of this UV poller callback would be slightly easier to reason about if it first bounced into the c-ares combiner before touching the rest of the `polled_fd` object state.I suggest something along the lines of:```void ares_uv_poll_cb(uv_poll_t* handle, int status, int events) {  grpc_core::ExecCtx exec_ctx;  arg = {handle, status, events};  GRPC_CLOSURE_SCHED(GRPC_CLOSURE_CREATE(inner_callback, arg, combiner));}void inner_callback(void* arg, grpc_error* error) {  // rest of existing callback....}",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18809,277101791,2019-04-19T22:02:59Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper_libuv.cc,"@@ -0,0 +1,103 @@+/*+ *+ * Copyright 2016 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/support/port_platform.h>++#include ""src/core/lib/iomgr/port.h""+#if GRPC_ARES == 1 && defined(GRPC_UV)++#include <grpc/support/string_util.h>++#include ""src/core/ext/filters/client_channel/parse_address.h""+#include ""src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.h""+#include ""src/core/ext/filters/client_channel/server_address.h""+#include ""src/core/lib/gpr/host_port.h""+#include ""src/core/lib/gpr/string.h""++bool grpc_ares_query_ipv6() {+  /* The libuv grpc code currently does not have the code to probe for this,+   * so we assume for now that IPv6 is always available in contexts where this+   * code will be used. */+  return true;+}++/* The following two functions were copied entirely from the Windows file. This+ * code can run on Windows so it can have the same problem. */+static bool inner_maybe_resolve_localhost_manually_locked(","nit: can we de-duplicate this function, and put it in some kind of utility function. I'd be fine putting this as a utility in `grpc_ares_wrapper.cc`. Perhaps it could also go into a shared libuv/windows util file.It would help to share the test coverage.",
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/18818,277384841,2019-04-22T18:28:19Z,src/core/lib/transport/metadata.h,"@@ -132,17 +134,135 @@ void* grpc_mdelem_get_user_data(grpc_mdelem md, void (*if_destroy_func)(void*)); void* grpc_mdelem_set_user_data(grpc_mdelem md, void (*destroy_func)(void*),                                 void* user_data); +void grpc_mdelem_trace_ref(void* md, const grpc_slice& key,+                           const grpc_slice& value, gpr_atm* refcnt,+                           const char* file, int line);+void grpc_mdelem_trace_unref(void* md, const grpc_slice& key,+                             const grpc_slice& value, gpr_atm* refcnt,+                             const char* file, int line);++typedef void (*destroy_user_data_func)(void* user_data);++struct UserData {+  gpr_mu mu_user_data;+  gpr_atm destroy_user_data;+  gpr_atm user_data;+};++typedef struct interned_metadata {+  /* must be byte compatible with grpc_mdelem_data */+  grpc_slice key;+  grpc_slice value;++  /* private only data */+  gpr_atm refcnt;+  uint32_t hash;++  UserData user_data;++  struct interned_metadata* bucket_next;+} interned_metadata;++/* Shadow structure for grpc_mdelem_data for allocated elements */+typedef struct allocated_metadata {+  /* must be byte compatible with grpc_mdelem_data */+  grpc_slice key;+  grpc_slice value;++  /* private only data */+  gpr_atm refcnt;++  UserData user_data;++  ~allocated_metadata();+} allocated_metadata;+ #ifndef NDEBUG #define GRPC_MDELEM_REF(s) grpc_mdelem_ref((s), __FILE__, __LINE__)-#define GRPC_MDELEM_UNREF(s) grpc_mdelem_unref((s), __FILE__, __LINE__)-grpc_mdelem grpc_mdelem_ref(grpc_mdelem md, const char* file, int line);-void grpc_mdelem_unref(grpc_mdelem md, const char* file, int line);+inline grpc_mdelem grpc_mdelem_ref(grpc_mdelem gmd, const char* file,+                                   int line) { #else #define GRPC_MDELEM_REF(s) grpc_mdelem_ref((s))+inline grpc_mdelem grpc_mdelem_ref(grpc_mdelem gmd) {+#endif+  switch (GRPC_MDELEM_STORAGE(gmd)) {+    case GRPC_MDELEM_STORAGE_EXTERNAL:+    case GRPC_MDELEM_STORAGE_STATIC:+      break;+    case GRPC_MDELEM_STORAGE_INTERNED: {+      interned_metadata* md =+          reinterpret_cast<interned_metadata*> GRPC_MDELEM_DATA(gmd);+#ifndef NDEBUG+      grpc_mdelem_trace_ref(md, md->key, md->value, &md->refcnt, file, line);+#endif+      /* we can assume the ref count is >= 1 as the application is calling+         this function - meaning that no adjustment to mdtab_free is necessary,+         simplifying the logic here to be just an atomic increment */+      /* use C assert to have this removed in opt builds */+      GPR_DEBUG_ASSERT(gpr_atm_no_barrier_load(&md->refcnt) >= 1);+      gpr_atm_no_barrier_fetch_add(&md->refcnt, 1);+      break;+    }+    case GRPC_MDELEM_STORAGE_ALLOCATED: {+      allocated_metadata* md =+          reinterpret_cast<allocated_metadata*> GRPC_MDELEM_DATA(gmd);+#ifndef NDEBUG+      grpc_mdelem_trace_ref(md, md->key, md->value, &md->refcnt, file, line);+#endif+      /* we can assume the ref count is >= 1 as the application is calling+         this function - meaning that no adjustment to mdtab_free is necessary,+         simplifying the logic here to be just an atomic increment */+      /* use C assert to have this removed in opt builds */+      gpr_atm_no_barrier_fetch_add(&md->refcnt, 1);+      break;+    }+  }+  return gmd;+}++void grpc_note_disposed_interned_metadata(uint32_t hash);+#ifndef NDEBUG+#define GRPC_MDELEM_UNREF(s) grpc_mdelem_unref((s), __FILE__, __LINE__)+inline void grpc_mdelem_unref(grpc_mdelem gmd, const char* file, int line) {+#else #define GRPC_MDELEM_UNREF(s) grpc_mdelem_unref((s))-grpc_mdelem grpc_mdelem_ref(grpc_mdelem md);-void grpc_mdelem_unref(grpc_mdelem md);+inline void grpc_mdelem_unref(grpc_mdelem gmd) {+#endif+  switch (GRPC_MDELEM_STORAGE(gmd)) {+    case GRPC_MDELEM_STORAGE_EXTERNAL:+    case GRPC_MDELEM_STORAGE_STATIC:+      break;+    case GRPC_MDELEM_STORAGE_INTERNED: {+      interned_metadata* md =+          reinterpret_cast<interned_metadata*> GRPC_MDELEM_DATA(gmd);+#ifndef NDEBUG+      grpc_mdelem_trace_unref(md, md->key, md->value, &md->refcnt, file, line);+#endif+      uint32_t hash = md->hash;","There will be an aliasing issue, but that's easy to work around:https://godbolt.org/z/1uISrP```void grpc_mdelem_destroy(grpc_mdelem gmd);void grpc_mdelem_unref(grpc_mdelem gmd) {  bool destroy = false;  switch (GRPC_MDELEM_STORAGE(gmd)) {    case GRPC_MDELEM_STORAGE_EXTERNAL:    case GRPC_MDELEM_STORAGE_STATIC:      break;    case GRPC_MDELEM_STORAGE_INTERNED: {      interned_metadata* md =          reinterpret_cast<interned_metadata*> GRPC_MDELEM_DATA(gmd);            const intptr_t prev_refcount = md->refcnt.fetch_sub(1, std::memory_order_acq_rel);      destroy = 1 == prev_refcount;      break;    }    case GRPC_MDELEM_STORAGE_ALLOCATED: {      allocated_metadata* md =          reinterpret_cast<allocated_metadata*> GRPC_MDELEM_DATA(gmd);      const intptr_t prev_refcount = md->refcnt.fetch_sub(1, std::memory_order_acq_rel);      destroy = 1 == prev_refcount;      break;    }  }  if (destroy) { grpc_mdelem_destroy(gmd); }}```",
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/17936,277463918,2019-04-22T22:46:29Z,src/objective-c/GRPCClient/GRPCCall.h,"@@ -263,6 +265,8 @@ extern NSString *const kGRPCTrailersKey;  */ - (void)finish; +- (void)receiveNextMessages:(NSUInteger)numberOfMessages;","Can we also add  `- (void)receiveNextMessage;` similar to what we have in ProtoRPC.h? Also, please add comments describing usage of `receiveNextMessages` and `didWriteData`",
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/18827,277472292,2019-04-22T23:29:09Z,tools/run_tests/helper_scripts/build_python.sh,"@@ -157,11 +157,11 @@ curl https://bootstrap.pypa.io/get-pip.py | $VENV_PYTHON # pip-installs the directory specified. Used because on MSYS the vanilla Windows # Python gets confused when parsing paths. pip_install_dir() {-  PWD=$(pwd)+  PREV_PWD=$(pwd)","Good catch! Although, looking at this pattern, I can't help but feel that we should be using [`pushd` and `popd`](https://www.gnu.org/software/bash/manual/html_node/Directory-Stack-Builtins.html).",
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/17936,277474917,2019-04-22T23:43:09Z,src/objective-c/GRPCClient/GRPCCall.m,"@@ -589,25 +664,30 @@ - (void)startReadWithHandler:(void (^)(grpc_byte_buffer *))handler { // If the call is currently paused, this is a noop. Restarting the call will invoke this // method. // TODO(jcanizales): Rename to readResponseIfNotPaused.-- (void)startNextRead {+- (void)maybeStartNextRead {   @synchronized(self) {     if (_state != GRXWriterStateStarted) {       return;     }+    if (_callOptions.enableFlowControl && (_pendingCoreRead || _pendingReceiveNextMessages == 0)) {+      return;+    }+    _pendingCoreRead = YES;+    _pendingReceiveNextMessages--;   }    dispatch_async(_callQueue, ^{     __weak GRPCCall *weakSelf = self;     [self startReadWithHandler:^(grpc_byte_buffer *message) {-      if (message == NULL) {-        // No more messages from the server-        return;-      }       __strong GRPCCall *strongSelf = weakSelf;       if (strongSelf == nil) {         grpc_byte_buffer_destroy(message);         return;       }+      if (message == NULL) {+        // No more messages from the server+        return;+      }       NSData *data = [NSData grpc_dataWithByteBuffer:message];       grpc_byte_buffer_destroy(message);       if (!data) {","Unrelated to your change, but just wanted to note this down before I forget: it would be nice if we could add a test for this condition (`[NSData grpc_dataWithByteBuffer:message]` returns nil). ",OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/17936,277475332,2019-04-22T23:45:30Z,src/objective-c/GRPCClient/GRPCCall.m,"@@ -616,6 +696,7 @@ - (void)startNextRead {         // that's on the hands of any server to have. Instead we finish and ask         // the server to cancel.         @synchronized(strongSelf) {+          strongSelf->_pendingReceiveNextMessages--;","We already decremented `_pendingReceiveNextMessages` in L676 above, do we need to decrement again here? Are we not setting `strongSelf->_pendingCoreRead = NO`  (similar to else case below) because the call is being canceled, so it doesn't matter?",OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/18818,277502336,2019-04-23T02:48:29Z,src/core/lib/transport/metadata.cc,"@@ -554,3 +444,49 @@ bool grpc_mdelem_eq(grpc_mdelem a, grpc_mdelem b) {   return grpc_slice_eq(GRPC_MDKEY(a), GRPC_MDKEY(b)) &&          grpc_slice_eq(GRPC_MDVALUE(a), GRPC_MDVALUE(b)); }++static void note_disposed_interned_metadata(uint32_t hash) {+  mdtab_shard* shard = &g_shards[SHARD_IDX(hash)];+  gpr_atm_no_barrier_fetch_add(&shard->free_estimate, 1);+}++#ifndef NDEBUG+void grpc_mdelem_do_unref(grpc_mdelem gmd, const char* file, int line) {+#else+void grpc_mdelem_do_unref(grpc_mdelem gmd) {+#endif+  switch (GRPC_MDELEM_STORAGE(gmd)) {+    case GRPC_MDELEM_STORAGE_EXTERNAL:+    case GRPC_MDELEM_STORAGE_STATIC:+      return;+    case GRPC_MDELEM_STORAGE_INTERNED: {+      interned_metadata* md =+          reinterpret_cast<interned_metadata*> GRPC_MDELEM_DATA(gmd);+#ifndef NDEBUG+      grpc_mdelem_trace_unref(md, md->key, md->value, &md->refcnt, file, line);+#endif  // ifndef NDEBUG+      uint32_t hash = md->hash;+      const gpr_atm prev_refcount = gpr_atm_full_fetch_add(&md->refcnt, -1);+      GPR_DEBUG_ASSERT(prev_refcount >= 1);+      if (1 == prev_refcount) {+        /* once the refcount hits zero, some other thread can come along and+           free md at any time: it's unsafe from this point on to access it */+        note_disposed_interned_metadata(hash);+      }+      break;+    }+    case GRPC_MDELEM_STORAGE_ALLOCATED: {+      allocated_metadata* md =+          reinterpret_cast<allocated_metadata*> GRPC_MDELEM_DATA(gmd);+#ifndef NDEBUG+      grpc_mdelem_trace_unref(md, md->key, md->value, &md->refcnt, file, line);+#endif  // ifndef NDEBUG+      const gpr_atm prev_refcount = gpr_atm_full_fetch_add(&md->refcnt, -1);+      GPR_DEBUG_ASSERT(prev_refcount >= 1);+      if (1 == prev_refcount) {+        md->~allocated_metadata();","We are not using the CTOR of allocated_metadata. I'd suggest converting this structure to C++, adding proper ctor and using grpc_core::New() and Delete() instead.",OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/18818,277502454,2019-04-23T02:49:20Z,src/core/lib/transport/metadata.h,"@@ -132,17 +134,111 @@ void* grpc_mdelem_get_user_data(grpc_mdelem md, void (*if_destroy_func)(void*)); void* grpc_mdelem_set_user_data(grpc_mdelem md, void (*destroy_func)(void*),                                 void* user_data); +typedef void (*destroy_user_data_func)(void* user_data);++struct UserData {+  gpr_mu mu_user_data;+  gpr_atm destroy_user_data;+  gpr_atm user_data;+};++struct interned_metadata {+  /* must be byte compatible with grpc_mdelem_data */+  grpc_slice key;+  grpc_slice value;++  /* private only data */+  gpr_atm refcnt;","I'd suggest converting this class to C++, adding a Ctor and using grpc_core::RefCount here and else where for refcount. It's probably another 10 lines of change but you'll get fully inlined ref counts.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18807,277741118,2019-04-23T15:34:21Z,src/core/ext/filters/http/server/http_server_filter.cc,"@@ -131,22 +131,23 @@ static grpc_error* hs_filter_incoming_metadata(grpc_call_element* elem,   static const char* error_name = ""Failed processing incoming headers"";    if (b->idx.named.method != nullptr) {-    if (grpc_mdelem_eq(b->idx.named.method->md, GRPC_MDELEM_METHOD_POST)) {+    if (grpc_mdelem_eq_static(b->idx.named.method->md,+                              GRPC_MDELEM_METHOD_GET)) {+      *calld->recv_initial_metadata_flags |=+          GRPC_INITIAL_METADATA_CACHEABLE_REQUEST;+      *calld->recv_initial_metadata_flags &=+          ~GRPC_INITIAL_METADATA_IDEMPOTENT_REQUEST;+    } else if (grpc_mdelem_eq_static(b->idx.named.method->md,+                                     GRPC_MDELEM_METHOD_POST)) {","> ...So most RPC calls (are expected to) make state changes?It's not actually a question of whether the call makes state changes; it's really a question of how we encode RPCs on the wire.  POST is the expected form for gRPC, as per https://github.com/grpc/grpc/blob/master/doc/PROTOCOL-HTTP2.md.  The GET and PUT alternatives here were added later to support cacheable and idempotent requests, but neither of those features are really first-class citizens in our code.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18784,277820779,2019-04-23T18:46:19Z,include/grpcpp/impl/codegen/message_allocator.h,"@@ -0,0 +1,53 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPCPP_IMPL_CODEGEN_MESSAGE_ALLOCATOR_H+#define GRPCPP_IMPL_CODEGEN_MESSAGE_ALLOCATOR_H++namespace grpc {++// This is per rpc struct for the allocator. We can potentially put the grpc+// call arena in here in the future.+template <typename RequestT, typename ResponseT>+struct RpcAllocatorInfo {+  RequestT* request = nullptr;+  ResponseT* response = nullptr;+  // per rpc allocator internal state. MessageAllocator can set it when+  // AllocateMessages is called and use it later.+  void* allocator_state = nullptr;+};","I'm going around trying to discourage the use of unused default initializers (or non-default initializers too) at the current time with the idea that they might hide latent bugs, whereas leaving them random lets msan take care of them for us. And I don't think that arena's are memset anymore.",OK
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/18784,277885085,2019-04-23T21:45:48Z,test/cpp/end2end/message_allocator_end2end_test.cc,"@@ -0,0 +1,405 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <algorithm>+#include <functional>+#include <memory>+#include <mutex>+#include <sstream>+#include <thread>++#include <google/protobuf/arena.h>++#include <gtest/gtest.h>++#include <grpcpp/channel.h>+#include <grpcpp/client_context.h>+#include <grpcpp/create_channel.h>+#include <grpcpp/server.h>+#include <grpcpp/server_builder.h>+#include <grpcpp/server_context.h>+#include <grpcpp/support/client_callback.h>+#include <grpcpp/support/message_allocator.h>++#include ""src/core/lib/iomgr/iomgr.h""+#include ""src/proto/grpc/testing/echo.grpc.pb.h""+#include ""test/core/util/port.h""+#include ""test/core/util/test_config.h""+#include ""test/cpp/util/test_credentials_provider.h""++// MAYBE_SKIP_TEST is a macro to determine if this particular test configuration+// should be skipped based on a decision made at SetUp time. In particular, any+// callback tests can only be run if the iomgr can run in the background or if+// the transport is in-process.+#define MAYBE_SKIP_TEST \+  do {                  \+    if (do_not_test_) { \+      return;           \+    }                   \+  } while (0)++namespace grpc {+namespace testing {+namespace {++class CallbackTestServiceImpl+    : public EchoTestService::ExperimentalCallbackService {+ public:+  explicit CallbackTestServiceImpl() {}++  void SetFreeRequest() { free_request_ = true; }++  void SetAllocatorMutator(+      std::function<void(void* allocator_state, const EchoRequest* req,+                         EchoResponse* resp)>+          mutator) {+    allocator_mutator_ = mutator;+  }++  void Echo(ServerContext* context, const EchoRequest* request,+            EchoResponse* response,+            experimental::ServerCallbackRpcController* controller) override {+    response->set_message(request->message());+    if (free_request_) {+      controller->FreeRequest();+    } else if (allocator_mutator_) {+      allocator_mutator_(controller->GetAllocatorState(), request, response);+    }+    controller->Finish(Status::OK);","For the request/response, I think once we reach the point where explicit DeallocateMessages is called, the custom allocator can handle the deallocation. As for the library, it should only call DeallocateMessages after any serialization is done.",OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/17936,277900638,2019-04-23T22:45:58Z,src/objective-c/GRPCClient/GRPCCall.m,"@@ -589,25 +664,30 @@ - (void)startReadWithHandler:(void (^)(grpc_byte_buffer *))handler { // If the call is currently paused, this is a noop. Restarting the call will invoke this // method. // TODO(jcanizales): Rename to readResponseIfNotPaused.-- (void)startNextRead {+- (void)maybeStartNextRead {   @synchronized(self) {     if (_state != GRXWriterStateStarted) {       return;     }+    if (_callOptions.enableFlowControl && (_pendingCoreRead || _pendingReceiveNextMessages == 0)) {+      return;+    }+    _pendingCoreRead = YES;+    _pendingReceiveNextMessages--;   }    dispatch_async(_callQueue, ^{     __weak GRPCCall *weakSelf = self;     [self startReadWithHandler:^(grpc_byte_buffer *message) {-      if (message == NULL) {-        // No more messages from the server-        return;-      }       __strong GRPCCall *strongSelf = weakSelf;       if (strongSelf == nil) {         grpc_byte_buffer_destroy(message);         return;       }+      if (message == NULL) {+        // No more messages from the server+        return;+      }       NSData *data = [NSData grpc_dataWithByteBuffer:message];       grpc_byte_buffer_destroy(message);       if (!data) {","Were you planning to remove the `if (!data)` block? If yes, what were you planning to replace it with? Error log msg? ",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/17936,277913845,2019-04-23T23:55:51Z,src/objective-c/GRPCClient/GRPCCall.m,"@@ -589,25 +664,30 @@ - (void)startReadWithHandler:(void (^)(grpc_byte_buffer *))handler { // If the call is currently paused, this is a noop. Restarting the call will invoke this // method. // TODO(jcanizales): Rename to readResponseIfNotPaused.-- (void)startNextRead {+- (void)maybeStartNextRead {   @synchronized(self) {     if (_state != GRXWriterStateStarted) {       return;     }+    if (_callOptions.enableFlowControl && (_pendingCoreRead || _pendingReceiveNextMessages == 0)) {+      return;+    }+    _pendingCoreRead = YES;+    _pendingReceiveNextMessages--;   }    dispatch_async(_callQueue, ^{     __weak GRPCCall *weakSelf = self;     [self startReadWithHandler:^(grpc_byte_buffer *message) {-      if (message == NULL) {-        // No more messages from the server-        return;-      }       __strong GRPCCall *strongSelf = weakSelf;       if (strongSelf == nil) {         grpc_byte_buffer_destroy(message);         return;       }+      if (message == NULL) {+        // No more messages from the server+        return;+      }       NSData *data = [NSData grpc_dataWithByteBuffer:message];       grpc_byte_buffer_destroy(message);       if (!data) {",NSAssert(data != nil);if (data == nil) {  // the same as current block},OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18809,278221766,2019-04-24T16:50:41Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_ev_driver_libuv.cc,"@@ -0,0 +1,165 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */+#include <grpc/support/port_platform.h>++#include ""src/core/lib/iomgr/port.h""+#if GRPC_ARES == 1 && defined(GRPC_UV)++#include <ares.h>+#include <uv.h>++#include ""src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_ev_driver.h""++#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>+#include <grpc/support/time.h>+#include ""src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.h""+#include ""src/core/lib/gpr/string.h""+#include ""src/core/lib/iomgr/combiner.h""++namespace grpc_core {++void ares_uv_poll_cb(uv_poll_t* handle, int status, int events);++void ares_uv_poll_close_cb(uv_handle_t* handle) { Delete(handle); }++class GrpcPolledFdLibuv : public GrpcPolledFd {+ public:+  GrpcPolledFdLibuv(ares_socket_t as, grpc_combiner* combiner)+      : as_(as), combiner_(combiner) {+    gpr_asprintf(&name_, ""c-ares socket: %"" PRIdPTR, (intptr_t)as);+    handle_ = New<uv_poll_t>();+    uv_poll_init_socket(uv_default_loop(), handle_, as);+    handle_->data = this;+  }++  ~GrpcPolledFdLibuv() { gpr_free(name_); }++  void RegisterForOnReadableLocked(grpc_closure* read_closure) override {+    GPR_ASSERT(read_closure_ == nullptr);+    GPR_ASSERT((poll_events_ & UV_READABLE) == 0);+    read_closure_ = read_closure;+    poll_events_ |= UV_READABLE;+    uv_poll_start(handle_, poll_events_, ares_uv_poll_cb);+  }++  void RegisterForOnWriteableLocked(grpc_closure* write_closure) override {+    GPR_ASSERT(write_closure_ == nullptr);+    GPR_ASSERT((poll_events_ & UV_WRITABLE) == 0);+    write_closure_ = write_closure;+    poll_events_ |= UV_WRITABLE;+    uv_poll_start(handle_, poll_events_, ares_uv_poll_cb);+  }++  bool IsFdStillReadableLocked() override {+    /* uv_poll_t is based on poll, which is level triggered. So, if cares+     * leaves some data unread, the event will trigger again. */+    return false;+  }++  void ShutdownLocked(grpc_error* error) override {+    grpc_core::ExecCtx exec_ctx;+    uv_poll_stop(handle_);+    uv_close(reinterpret_cast<uv_handle_t*>(handle_), ares_uv_poll_close_cb);+    if (read_closure_) {+      GRPC_CLOSURE_SCHED(read_closure_, GRPC_ERROR_CANCELLED);+    }+    if (write_closure_) {+      GRPC_CLOSURE_SCHED(write_closure_, GRPC_ERROR_CANCELLED);+    }+  }++  ares_socket_t GetWrappedAresSocketLocked() override { return as_; }++  const char* GetName() override { return name_; }++  char* name_;+  ares_socket_t as_;+  uv_poll_t* handle_;+  grpc_closure* read_closure_ = nullptr;+  grpc_closure* write_closure_ = nullptr;+  int poll_events_ = 0;+  grpc_combiner* combiner_;+};++struct AresUvPollCbArg {+  AresUvPollCbArg(uv_poll_t* handle, int status, int events)+      : handle(handle), status(status), events(events) {}++  uv_poll_t* handle;+  int status;+  int events;+};++static void inner_callback(void* arg, grpc_error* error) {",nit: suggest renaming this to `ares_uv_poll_cb_locked`,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18809,278227753,2019-04-24T17:05:52Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_ev_driver_libuv.cc,"@@ -0,0 +1,165 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */+#include <grpc/support/port_platform.h>++#include ""src/core/lib/iomgr/port.h""+#if GRPC_ARES == 1 && defined(GRPC_UV)++#include <ares.h>+#include <uv.h>++#include ""src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_ev_driver.h""++#include <grpc/support/alloc.h>+#include <grpc/support/log.h>+#include <grpc/support/string_util.h>+#include <grpc/support/time.h>+#include ""src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.h""+#include ""src/core/lib/gpr/string.h""+#include ""src/core/lib/iomgr/combiner.h""++namespace grpc_core {++void ares_uv_poll_cb(uv_poll_t* handle, int status, int events);++void ares_uv_poll_close_cb(uv_handle_t* handle) { Delete(handle); }++class GrpcPolledFdLibuv : public GrpcPolledFd {+ public:+  GrpcPolledFdLibuv(ares_socket_t as, grpc_combiner* combiner)+      : as_(as), combiner_(combiner) {+    gpr_asprintf(&name_, ""c-ares socket: %"" PRIdPTR, (intptr_t)as);+    handle_ = New<uv_poll_t>();+    uv_poll_init_socket(uv_default_loop(), handle_, as);+    handle_->data = this;+  }++  ~GrpcPolledFdLibuv() { gpr_free(name_); }++  void RegisterForOnReadableLocked(grpc_closure* read_closure) override {+    GPR_ASSERT(read_closure_ == nullptr);+    GPR_ASSERT((poll_events_ & UV_READABLE) == 0);+    read_closure_ = read_closure;+    poll_events_ |= UV_READABLE;+    uv_poll_start(handle_, poll_events_, ares_uv_poll_cb);+  }++  void RegisterForOnWriteableLocked(grpc_closure* write_closure) override {+    GPR_ASSERT(write_closure_ == nullptr);+    GPR_ASSERT((poll_events_ & UV_WRITABLE) == 0);+    write_closure_ = write_closure;+    poll_events_ |= UV_WRITABLE;+    uv_poll_start(handle_, poll_events_, ares_uv_poll_cb);+  }++  bool IsFdStillReadableLocked() override {+    /* uv_poll_t is based on poll, which is level triggered. So, if cares+     * leaves some data unread, the event will trigger again. */+    return false;+  }++  void ShutdownLocked(grpc_error* error) override {+    grpc_core::ExecCtx exec_ctx;","Can we assert that `ExecCtx::Get() == nullptr` here?If there's any cases where we can't prove the assertion, can we use a pattern like the one in https://github.com/grpc/grpc/blob/master/src/core/lib/iomgr/tcp_client_custom.cc#L104?",
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/18818,278295019,2019-04-24T20:03:54Z,src/core/lib/transport/metadata.h,"@@ -143,17 +146,203 @@ void* grpc_mdelem_get_user_data(grpc_mdelem md, void (*if_destroy_func)(void*)); void* grpc_mdelem_set_user_data(grpc_mdelem md, void (*destroy_func)(void*),                                 void* user_data); +// Defined in metadata.cc.+struct mdtab_shard;++#ifndef NDEBUG+void grpc_mdelem_trace_ref(void* md, const grpc_slice& key,+                           const grpc_slice& value, intptr_t refcnt,+                           const char* file, int line);+void grpc_mdelem_trace_unref(void* md, const grpc_slice& key,+                             const grpc_slice& value, intptr_t refcnt,+                             const char* file, int line);+#endif+namespace grpc_core {++typedef void (*destroy_user_data_func)(void* user_data);++struct UserData {+  UserData();+  ~UserData();++  gpr_mu mu_user_data;+  gpr_atm destroy_user_data = 0;+  gpr_atm user_data = 0;+};++class InternedMetadata {+ public:+  struct BucketLink {+    explicit BucketLink(InternedMetadata* md) : next(md) {}++    InternedMetadata* next = nullptr;+  };++  InternedMetadata(const grpc_slice& key, const grpc_slice& value,+                   uint32_t hash, InternedMetadata* next);+  ~InternedMetadata();++#ifndef NDEBUG+  void Ref(const char* file, int line) {+    grpc_mdelem_trace_ref(this, key_, value_, RefValue(), file, line);+    const intptr_t prior = refcnt_.FetchAdd(1, MemoryOrder::RELAXED);+    GPR_ASSERT(prior > 0);+  }+  bool Unref(const char* file, int line) {+    grpc_mdelem_trace_unref(this, key_, value_, RefValue(), file, line);+    return Unref();+  }+#else+  // We define a naked Ref() in the else-clause to make sure we don't+  // inadvertently skip the assert on debug builds.+  void Ref() {+    /* we can assume the ref count is >= 1 as the application is calling+       this function - meaning that no adjustment to mdtab_free is necessary,+       simplifying the logic here to be just an atomic increment */+    refcnt_.FetchAdd(1, MemoryOrder::RELAXED);+  }+#endif  // ifndef NDEBUG+  bool Unref() {+    const intptr_t prior = refcnt_.FetchSub(1, MemoryOrder::ACQ_REL);+    GPR_DEBUG_ASSERT(prior > 0);+    return prior == 1;+  }++  void RefWithShardLocked(mdtab_shard* shard);+  const grpc_slice& key() const { return key_; }+  const grpc_slice& value() const { return value_; }+  UserData& user_data() { return user_data_; }+  uint32_t hash() { return hash_; }+  InternedMetadata* bucket_next() { return link_.next; }+  void set_bucket_next(InternedMetadata* md) { link_.next = md; }++  static intptr_t CleanupLinkedMetadata(BucketLink* head);++ private:+  bool AllRefsDropped() { return refcnt_.Load(MemoryOrder::ACQUIRE) == 0; }+  bool FirstRef() { return refcnt_.FetchAdd(1, MemoryOrder::RELAXED) == 0; }+  intptr_t RefValue() { return refcnt_.Load(MemoryOrder::RELAXED); }++  /* must be byte compatible with grpc_mdelem_data */+  grpc_slice key_;+  grpc_slice value_;++  /* private only data */+  grpc_core::Atomic<intptr_t> refcnt_;+  uint32_t hash_;++  UserData user_data_;++  BucketLink link_;+};++/* Shadow structure for grpc_mdelem_data for allocated elements */+class AllocatedMetadata {+ public:+  AllocatedMetadata(const grpc_slice& key, const grpc_slice& value);+  ~AllocatedMetadata();++  const grpc_slice& key() const { return key_; }+  const grpc_slice& value() const { return value_; }+  UserData& user_data() { return user_data_; }","as per style guide this either should be a const function, or you should return a mutable pointer:```UserData* mutable_user_data() { return &user_data_; }```",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18865,278499806,2019-04-25T11:00:05Z,src/csharp/Grpc.Core.Api/DeserializationContext.cs,"@@ -39,13 +39,30 @@ public abstract class DeserializationContext         /// Also, allocating a new buffer each time can put excessive pressure on GC, especially if         /// the payload is more than 86700 bytes large (which means the newly allocated buffer will be placed in LOH,         /// and LOH object can only be garbage collected via a full (""stop the world"") GC run).-        /// NOTE: Deserializers are expected not to call this method more than once per received message+        /// NOTE: Deserializers are expected not to call this method (or other payload accessor methods) more than once per received message         /// (as there is no practical reason for doing so) and <c>DeserializationContext</c> implementations are free to assume so.         /// </summary>         /// <returns>byte array containing the entire payload.</returns>         public virtual byte[] PayloadAsNewBuffer()","For other platforms than `netstandard2.0`, one still needs to use this old method, which is inefficient and very GC heavy for large messages. With the machinery added in this PR, it would be very easy to add a new overload that still copies the data, but allows populating a buffer provided by the user (which can eliminate the GC overhead) - leaving that for followup PRs.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/18868,278608817,2019-04-25T15:31:22Z,tools/interop_matrix/testcases/csharp__v1.18.0,"@@ -0,0 +1,22 @@+#!/bin/bash","there actually need to be two files - csharp__v1.18.0  (which is a copy of the original csharp__master and csharpcoreclr__v1.18.0, which is a copy of old csharpcoreclr__master).The current contents of the file are wrong (netcoreapp1.1 corresponds to CoreCLR called ""csharpcoreclr"" here, not to .NET desktop called ""csharp"" here)See this snippet to understand how this workshttps://github.com/grpc/grpc/blob/a3062ca04afef15327512d343cbd1768326b7500/tools/interop_matrix/run_interop_matrix_tests.py#L141",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18870,278651570,2019-04-25T17:21:26Z,include/grpcpp/impl/codegen/client_callback.h,"@@ -174,6 +174,8 @@ class ClientCallbackUnary { // StartWrite, or AddHold operations on the streaming object. Note that none of // the classes are pure; all reactions have a default empty reaction so that the // user class only needs to override those classes that it cares about.+// The reactor must be passed to the stub invocation before any of the below+// operations can be called.","Isn't that redundant with the 2nd sentence of the paragraph? ""They are passed in to the library as an argument to a call on a stub."" ",OK
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/18857,278659538,2019-04-25T17:42:15Z,test/core/bad_connection/close_fd_test.cc,"@@ -328,7 +328,6 @@ static void _test_close_before_server_recv(fd_type fdtype) {    */   if (event.type == GRPC_QUEUE_TIMEOUT) {     GPR_ASSERT(event.success == 0);-    GPR_ASSERT(event.tag == nullptr);","Please also change the comment of `tag` (https://github.com/grpc/grpc/blob/a3062ca04afef15327512d343cbd1768326b7500/include/grpc/impl/codegen/grpc_types.h#L497) to state explicitly that other types can't assume `tag` initialized. Otherwise, readers may think other types' tag is null.",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/18870,278684687,2019-04-25T18:48:56Z,include/grpcpp/impl/codegen/client_callback.h,"@@ -174,6 +174,8 @@ class ClientCallbackUnary { // StartWrite, or AddHold operations on the streaming object. Note that none of // the classes are pure; all reactions have a default empty reaction so that the // user class only needs to override those classes that it cares about.+// The reactor must be passed to the stub invocation before any of the below+// operations can be called.","The 2nd sentence is weaker IMO. When reading this for the first time, it wasn't clear to me that I couldn't call these functions before passing the reactor to the library. For someone who knows how these things work, it's probably obvious, but it may not be completely clear to someone who is writing callback API stuff for the first time.",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/18870,278684964,2019-04-25T18:49:46Z,include/grpcpp/impl/codegen/client_callback.h,"@@ -174,6 +174,8 @@ class ClientCallbackUnary { // StartWrite, or AddHold operations on the streaming object. Note that none of // the classes are pure; all reactions have a default empty reaction so that the // user class only needs to override those classes that it cares about.+// The reactor must be passed to the stub invocation before any of the below+// operations can be called.","And when I say weaker, I mean a weaker guarantee / statement on semantics. Not weaker in terms of quality :)",OK
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/18875,279034203,2019-04-26T17:16:50Z,src/core/lib/gprpp/arena.cc,"@@ -31,19 +31,36 @@ #include ""src/core/lib/gpr/alloc.h"" #include ""src/core/lib/gprpp/memory.h"" +namespace grpc_core {+ template <size_t alignment>-static void* gpr_arena_malloc(size_t size) {+static void* _aligned_alloc(size_t size) {+#if defined(GPR_LINUX)","Right now the only callers are the grpc_call arena, and the global (initialization time allocated) handshaker list. No other users at present.My preference is to keep it here since:1) I already changed gpr_malloc_aligned/gpr_free_aligned to use this also anyways,2) If we use the function pointers method as you and Soheil spoke about, a call to arena destruction would do:- a call to perform gpr_free_aligned() which does a jump to a runtime-initialized function pointer that happens to be aligned_alloc (or whatever alternative) (2 calls)- on non windows/linux/posix platforms, that alternative would be our in house free_aligned() which does another jump to gpr_free and then another jump to free (4 calls)Rather, this way it's a single call to a statically known target. I'm not sure what the non-statically intialized global function pointer table actually buys us.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18809,279065756,2019-04-26T18:51:26Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper_libuv_windows.cc,"@@ -0,0 +1,83 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/support/port_platform.h>++#include ""src/core/lib/iomgr/port.h""+#if GRPC_ARES == 1 && (defined(GRPC_UV) || defined(GPR_WINDOWS))++#include <grpc/support/string_util.h>++#include ""src/core/ext/filters/client_channel/parse_address.h""+#include ""src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.h""+#include ""src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper_libuv_windows.h""+#include ""src/core/ext/filters/client_channel/server_address.h""+#include ""src/core/lib/gpr/host_port.h""+#include ""src/core/lib/gpr/string.h""++bool inner_maybe_resolve_localhost_manually_locked(+    const char* name, const char* default_port,+    grpc_core::UniquePtr<grpc_core::ServerAddressList>* addrs, char** host,+    char** port) {+  gpr_split_host_port(name, host, port);+  if (*host == nullptr) {+    gpr_log(GPR_ERROR,+            ""Failed to parse %s into host:port during Windows localhost ""","nit: `s/during Windows localhost/during manual localhost` ?this ""during Windows localhost"" log message might be confusing, since we're not longer always using this on Windows (it was probably never necessary).",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18818,279073622,2019-04-26T19:18:43Z,src/core/lib/transport/metadata.cc,"@@ -69,43 +100,87 @@ grpc_core::DebugOnlyTraceFlag grpc_trace_metadata(false, ""metadata""); #define TABLE_IDX(hash, capacity) (((hash) >> (LOG2_SHARD_COUNT)) % (capacity)) #define SHARD_IDX(hash) ((hash) & ((1 << (LOG2_SHARD_COUNT)) - 1)) -typedef void (*destroy_user_data_func)(void* user_data);--struct UserData {-  gpr_mu mu_user_data;-  gpr_atm destroy_user_data;-  gpr_atm user_data;-};--/* Shadow structure for grpc_mdelem_data for interned elements */-typedef struct interned_metadata {-  /* must be byte compatible with grpc_mdelem_data */-  grpc_slice key;-  grpc_slice value;--  /* private only data */-  gpr_atm refcnt;--  UserData user_data;+AllocatedMetadata::AllocatedMetadata(const grpc_slice& key,+                                     const grpc_slice& value)+    : key_(grpc_slice_ref_internal(key)),+      value_(grpc_slice_ref_internal(value)),+      refcnt_(1) {+#ifndef NDEBUG+  if (grpc_trace_metadata.enabled()) {+    char* key_str = grpc_slice_to_c_string(key_);+    char* value_str = grpc_slice_to_c_string(value_);+    gpr_log(GPR_DEBUG, ""ELM ALLOC:%p:%"" PRIdPTR "": '%s' = '%s'"", this,+            RefValue(), key_str, value_str);+    gpr_free(key_str);+    gpr_free(value_str);+  }+#endif+} -  struct interned_metadata* bucket_next;-} interned_metadata;+AllocatedMetadata::~AllocatedMetadata() {+  grpc_slice_unref_internal(key_);+  grpc_slice_unref_internal(value_);+  if (user_data_.user_data) {","Since user_data is an atomic, this looks unpleasant. I realize that this was already present in the previous code and not multithreaded at this point (since it's being destroyed), but if you do actually change this to grpc_core::Atomic (which I recommend since you're now defining UserData anyway and it's not API), then this will become seq_cst. I'd propose changing the type to Atomic and then making this an explicit load with the appropriate consistency model (which is probably relaxed since this is a destructor and there had better not be any threaded access to this variable by this point).",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/18881,279130142,2019-04-26T23:29:04Z,test/cpp/microbenchmarks/BUILD,"@@ -39,85 +39,85 @@ grpc_cc_library(     external_deps = [         ""benchmark"",     ],+    tags = [""no_windows""],",Nit: why is this added? Could this affect other tests that want to run on windows and are also using this library?,OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/18881,279130559,2019-04-26T23:32:42Z,test/cpp/microbenchmarks/bm_callback_streaming_ping_pong.cc,"@@ -0,0 +1,173 @@+/*+ *+ * Copyright 2016 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""test/cpp/microbenchmarks/callback_streaming_ping_pong.h""+#include ""test/cpp/util/test_config.h""++namespace grpc {+namespace testing {++// force library initialization+auto& force_library_initialization = Library::get();++/*******************************************************************************+ * CONFIGURATIONS+ */++// Replace ""benchmark::internal::Benchmark"" with ""::testing::Benchmark"" to use+// internal microbenchmarking tooling+static void StreamingPingPongArgs(benchmark::internal::Benchmark* b) {",Nit: Prefer not to use single letter names for parameters,OK
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/18818,279137494,2019-04-27T01:02:09Z,src/core/lib/transport/metadata.h,"@@ -141,19 +145,202 @@ inline bool grpc_mdelem_static_value_eq(grpc_mdelem a, grpc_mdelem b_static) {    is used as a type tag and is checked during user_data fetch. */ void* grpc_mdelem_get_user_data(grpc_mdelem md, void (*if_destroy_func)(void*)); void* grpc_mdelem_set_user_data(grpc_mdelem md, void (*destroy_func)(void*),-                                void* user_data);+                                void* data);++// Defined in metadata.cc.+struct mdtab_shard;++#ifndef NDEBUG+void grpc_mdelem_trace_ref(void* md, const grpc_slice& key,+                           const grpc_slice& value, intptr_t refcnt,+                           const char* file, int line);+void grpc_mdelem_trace_unref(void* md, const grpc_slice& key,+                             const grpc_slice& value, intptr_t refcnt,+                             const char* file, int line);+#endif+namespace grpc_core {++typedef void (*destroy_user_data_func)(void* data);++struct UserData {+  Mutex mu_user_data;+  grpc_core::Atomic<intptr_t> destroy_user_data;","The alternative is Atomic<void*> for the user data, and Atomic<destroy_user_data_func> for the destroy_user_data member.Historically gpr_atm is an intptr_t, so I kept it for commonality. I think it's a bit cleaner looking to leave it as intptr_t; fundamentally it doesn't make a difference in the generated code.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18894,279408459,2019-04-29T15:14:20Z,src/core/lib/gprpp/arena.h,"@@ -76,7 +83,9 @@ class Arena {     Zone* prev;   }; -  explicit Arena(size_t initial_size) : initial_zone_size_(initial_size) {}+  explicit Arena(size_t initial_size, size_t initial_alloc = 0)+      : total_used_(initial_alloc), initial_zone_size_(initial_size) {}",Nit: Can we use the same order for the ctor parameters and the data members?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18894,279408602,2019-04-29T15:14:40Z,src/core/lib/gprpp/arena.h,"@@ -76,7 +83,9 @@ class Arena {     Zone* prev;   }; -  explicit Arena(size_t initial_size) : initial_zone_size_(initial_size) {}+  explicit Arena(size_t initial_size, size_t initial_alloc = 0)",Please document the meaning of both parameters.,
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/18881,279434361,2019-04-29T16:14:55Z,test/cpp/microbenchmarks/callback_unary_ping_pong.h,"@@ -0,0 +1,84 @@+/*+ *+ * Copyright 2016 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++/* Benchmark gRPC end2end in various configurations */++#ifndef TEST_CPP_MICROBENCHMARKS_CALLBACK_UNARY_PING_PONG_H+#define TEST_CPP_MICROBENCHMARKS_CALLBACK_UNARY_PING_PONG_H++#include <benchmark/benchmark.h>+#include <sstream>+#include ""src/core/lib/profiling/timers.h""+#include ""src/proto/grpc/testing/echo.grpc.pb.h""+#include ""test/cpp/microbenchmarks/fullstack_context_mutators.h""+#include ""test/cpp/microbenchmarks/fullstack_fixtures.h""+#include ""test/cpp/microbenchmarks/callback_test_service.h""++namespace grpc {+namespace testing {++/*******************************************************************************+ * BENCHMARKING KERNELS+ */++template <class Fixture, class ClientContextMutator, class ServerContextMutator>+static void BM_CallbackUnaryPingPong(benchmark::State& state) {+  CallbackStreamingTestService service;+  std::unique_ptr<Fixture> fixture(new Fixture(&service));+  std::unique_ptr<EchoTestService::Stub> stub_(+      EchoTestService::NewStub(fixture->channel()));+  EchoRequest request;+  EchoResponse response;++  if (state.range(0) > 0) {+    request.set_message(std::string(state.range(0), 'a'));+  } else {+    request.set_message("""");+  }+  if (state.range(1) > 0) {+    response.set_message(std::string(state.range(1), 'a'));+  } else {+    response.set_message("""");+  }++  while (state.KeepRunning()) {","In terms of your error with passing in the benchmark state as a parameter, it looks like you are trying to copy construct the Benchmark state. Did you try:'const ::benchmark::State& state'?",OK
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/18894,279476530,2019-04-29T18:09:34Z,src/core/lib/gprpp/arena.h,"@@ -76,7 +83,9 @@ class Arena {     Zone* prev;   }; -  explicit Arena(size_t initial_size) : initial_zone_size_(initial_size) {}+  explicit Arena(size_t initial_size, size_t initial_alloc = 0)+      : total_used_(initial_alloc), initial_zone_size_(initial_size) {}","Unable - the initial_alloc parameter must be optional, so it must be second. But for performance reasons (for Alloc()) it's better to have total_user_  be the first element.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18875,279503846,2019-04-29T19:24:56Z,src/core/lib/gpr/alloc.h,"@@ -25,4 +25,12 @@ #define GPR_ROUND_UP_TO_ALIGNMENT_SIZE(x) \   (((x) + GPR_MAX_ALIGNMENT - 1u) & ~(GPR_MAX_ALIGNMENT - 1u)) +#define GPR_ROUND_UP_TO_CACHELINE_SIZE(x) \+  (((x) + GPR_CACHELINE_SIZE - 1u) & ~(GPR_CACHELINE_SIZE - 1u))++#define GPR_ROUND_UP_TO_SPECIFIED_SIZE(x, align) \+  (((x) + align - 1u) & ~(align - 1u))","Suggest parens around `align`, in both occurrences.  That way, if someone passes a complex expression as the `align` parameter of the macro, it won't break the expression due to operator precedence rules.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18410,279827308,2019-04-30T16:11:22Z,src/core/ext/filters/client_channel/channel_connectivity.cc,"@@ -152,15 +158,23 @@ static void partly_done(state_watcher* w, bool due_to_completion,         w->error = error;       }       w->phase = CALLING_BACK_AND_FINISHED;-      grpc_cq_end_op(w->cq, w->tag, w->error, finished_completion, w,-                     &w->completion_storage);+      end_op = true;+      end_op_cq = w->cq;",This is a common construct used in our code and many others when we have to make a decision while a struct is protected but not execute on that decision until the struct is no longer protected.,OK
31627465,nanahpang,https://api.github.com/repos/grpc/grpc/pulls/18881,279985606,2019-05-01T00:46:51Z,test/cpp/microbenchmarks/bm_callback_streaming_ping_pong.cc,"@@ -0,0 +1,173 @@+/*+ *+ * Copyright 2016 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""test/cpp/microbenchmarks/callback_streaming_ping_pong.h""+#include ""test/cpp/util/test_config.h""++namespace grpc {+namespace testing {++// force library initialization+auto& force_library_initialization = Library::get();++/*******************************************************************************+ * CONFIGURATIONS+ */++// Replace ""benchmark::internal::Benchmark"" with ""::testing::Benchmark"" to use+// internal microbenchmarking tooling+static void StreamingPingPongArgs(benchmark::internal::Benchmark* b) {+  int msg_size = 0;++  b->Args({0, 0});  // spl case: 0 ping-pong msgs (msg_size doesn't matter here)","Sorry about the ambiguous, I have updated the comments about what the args mean.",OK
31627465,nanahpang,https://api.github.com/repos/grpc/grpc/pulls/18881,279986102,2019-05-01T00:51:05Z,test/cpp/microbenchmarks/callback_streaming_ping_pong.h,"@@ -0,0 +1,70 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef TEST_CPP_MICROBENCHMARKS_CALLBACK_STREAMING_PING_PONG_H+#define TEST_CPP_MICROBENCHMARKS_CALLBACK_STREAMING_PING_PONG_H++#include <benchmark/benchmark.h>+#include <sstream>+#include ""src/core/lib/profiling/timers.h""+#include ""src/proto/grpc/testing/echo.grpc.pb.h""+#include ""test/cpp/microbenchmarks/callback_test_service.h""+#include ""test/cpp/microbenchmarks/fullstack_context_mutators.h""+#include ""test/cpp/microbenchmarks/fullstack_fixtures.h""++namespace grpc {+namespace testing {++/*******************************************************************************+ * BENCHMARKING KERNELS+ */++template <class Fixture, class ClientContextMutator, class ServerContextMutator>+static void BM_CallbackBidiStreaming(benchmark::State& state) {+  const int message_size = state.range(0);+  const int max_ping_pongs = state.range(1) > 0 ? 1 : state.range(1);","Yeah, that's a mistake. I have changed the test args. So no condition check needed now. Thanks for pointing this out!",
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/18926,279986642,2019-05-01T00:55:53Z,src/core/lib/slice/slice_buffer.cc,"@@ -370,6 +370,24 @@ grpc_slice grpc_slice_buffer_take_first(grpc_slice_buffer* sb) {   return slice; } +void grpc_slice_buffer_consume_first(grpc_slice_buffer* sb) {+  GPR_ASSERT(sb->count > 0);+  sb->length -= GRPC_SLICE_LENGTH(sb->slices[0]);+  grpc_slice_unref_internal(sb->slices[0]);+  sb->slices++;+  if (--sb->count == 0) {+    sb->slices = sb->base_slices;+  }+}++void grpc_slice_buffer_sub_first(grpc_slice_buffer* sb, size_t begin,",I wonder if a better name would be grpc_slice_buffer_peek_first() - but that's primarily stylistic.,OK
2030323,JunTaoLuo,https://api.github.com/repos/grpc/grpc/pulls/18705,280224501,2019-05-01T21:33:08Z,src/csharp/Grpc.Core.Api/LiteClientBase.cs,"@@ -0,0 +1,96 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;++namespace Grpc.Core+{+    /// <summary>+    /// Base class for lightweight client-side stubs.+    /// All calls are invoked via a <c>CallInvoker</c>.+    /// Lite client stubs have no configuration knobs, all configuration+    /// is provided by decorating the call invoker.+    /// Note: experimental API that can change or be removed without any prior notice.+    /// </summary>+    public abstract class LiteClientBase+    {+        readonly CallInvoker callInvoker;++        /// <summary>+        /// Initializes a new instance of <c>LiteClientBase</c> class that+        /// throws <c>NotImplementedException</c> upon invocation of any RPC.+        /// This constructor is only provided to allow creation of test doubles+        /// for client classes (e.g. mocking requires a parameterless constructor).+        /// </summary>+        protected LiteClientBase() : this(new UnimplementedCallInvoker())+        {+        }++        /// <summary>+        /// Initializes a new instance of <c>ClientBase</c> class.+        /// </summary>+        /// <param name=""callInvoker"">The <c>CallInvoker</c> for remote call invocation.</param>+        public LiteClientBase(CallInvoker callInvoker)+        {+            this.callInvoker = callInvoker;+        }++        /// <summary>+        /// Gets the call invoker.+        /// </summary>+        protected CallInvoker CallInvoker+        {+            get { return this.callInvoker; }+        }++        /// <summary>+        /// Call invoker that throws <c>NotImplementedException</c> for all requests.+        /// </summary>+        private class UnimplementedCallInvoker : CallInvoker",Maybe we can move UnimplementedCallInvoker from Grpc.Core to Grpc.Core.Api and reuse it here instead of creating a private class?,OK
6233680,wjywbs,https://api.github.com/repos/grpc/grpc/pulls/17511,280231150,2019-05-01T21:57:50Z,src/cpp/server/server_cc.cc,"@@ -77,14 +77,8 @@ class DefaultGlobalCallbacks final : public Server::GlobalCallbacks {   void PostSynchronousRequest(ServerContext* context) override {} }; -std::shared_ptr<Server::GlobalCallbacks> g_callbacks = nullptr;-gpr_once g_once_init_callbacks = GPR_ONCE_INIT;--void InitGlobalCallbacks() {-  if (!g_callbacks) {-    g_callbacks.reset(new DefaultGlobalCallbacks());-  }-}+DefaultGlobalCallbacks* g_default_callbacks = new DefaultGlobalCallbacks();+Server::GlobalCallbacks* g_callbacks = g_default_callbacks;","Thanks for your review. For consistency with client_context.cc, should I keep the g_ prefix or use global_ here?https://github.com/grpc/grpc/blob/master/src/cpp/client/client_context.cc#L45-L48",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18865,280628644,2019-05-02T23:20:09Z,src/csharp/Grpc.Core/Internal/ReusableSliceBuffer.cs,"@@ -0,0 +1,148 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++#if GRPC_CSHARP_SUPPORT_SYSTEM_MEMORY++using Grpc.Core.Utils;+using System;+using System.Threading;++using System.Buffers;++namespace Grpc.Core.Internal+{+    internal class ReusableSliceBuffer+    {+        public const int MaxCachedSegments = 1024;  // ~4MB payload for 4K slices++        readonly SliceSegment[] cachedSegments = new SliceSegment[MaxCachedSegments];+        int populatedSegmentCount = 0;++        public ReadOnlySequence<byte> PopulateFrom(IBufferReader bufferReader)+        {+            long offset = 0;+            int index = 0;+            SliceSegment prevSegment = null;+            while (bufferReader.TryGetNextSlice(out Slice slice))+            {+                // Initialize cached segment if still null or just allocate a new segment if we already reached MaxCachedSegments+                var current = index < cachedSegments.Length ? cachedSegments[index] : new SliceSegment();+                if (current == null)+                {+                    current = cachedSegments[index] = new SliceSegment();+                }++                current.Reset(slice, offset);+                prevSegment?.SetNext(current);++                index ++;+                offset += slice.Length;+                prevSegment = current;+            }+            populatedSegmentCount = index;","nit: IIC `populatedSegmentCount` is redundant with `index` here. Can we remove the `index` variable, initialize `populatedSegmentCount` to zero at the top, and then use `populatedSegmentCount` everywhere `index` us currently used? Removes the risk of a bad initialization or reset....",OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18865,280630013,2019-05-02T23:27:34Z,src/csharp/Grpc.Core/Internal/Slice.cs,"@@ -0,0 +1,68 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Runtime.InteropServices;+using System.Threading;+using Grpc.Core.Utils;++namespace Grpc.Core.Internal+{+    /// <summary>+    /// Slice of native memory.+    /// Rough equivalent of grpc_slice (but doesn't support inlined slices, just a pointer to data and length)+    /// </summary>+    internal struct Slice+    {+        private readonly IntPtr dataPtr;+        private readonly int length;+     +        public Slice(IntPtr dataPtr, int length)+        {+            this.dataPtr = dataPtr;+            this.length = length;+        }++        public int Length => length;++        // copies data of the slice to given span.+        // there needs to be enough space in the destination buffer+        public void CopyTo(ArraySegment<byte> destination)+        {+            Marshal.Copy(dataPtr, destination.Array, destination.Offset, length);+        }++#if GRPC_CSHARP_SUPPORT_SYSTEM_MEMORY+        public Span<byte> ToSpanUnsafe()+        {+            unsafe+            {+                return new Span<byte>((byte*) dataPtr, length);+            }+        }+#endif++        /// <summary>+        /// Returns a <see cref=""System.String""/> that represents the current <see cref=""Grpc.Core.Internal.Slice""/>.+        /// </summary>+        public override string ToString()+        {+            return string.Format(""[Slice: dataPtr={0}, length={1}]"", dataPtr, length);","nit: also log `this` ? E.g. something like `""[Slice(0): ...."", this, dataPtr, length)` ?",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18881,280834519,2019-05-03T16:01:37Z,test/cpp/microbenchmarks/callback_streaming_ping_pong.h,"@@ -0,0 +1,69 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef TEST_CPP_MICROBENCHMARKS_CALLBACK_STREAMING_PING_PONG_H+#define TEST_CPP_MICROBENCHMARKS_CALLBACK_STREAMING_PING_PONG_H++#include <benchmark/benchmark.h>+#include <sstream>+#include ""src/core/lib/profiling/timers.h""+#include ""src/proto/grpc/testing/echo.grpc.pb.h""+#include ""test/cpp/microbenchmarks/callback_test_service.h""+#include ""test/cpp/microbenchmarks/fullstack_context_mutators.h""+#include ""test/cpp/microbenchmarks/fullstack_fixtures.h""++namespace grpc {+namespace testing {++/*******************************************************************************+ * BENCHMARKING KERNELS+ */++template <class Fixture, class ClientContextMutator, class ServerContextMutator>+static void BM_CallbackBidiStreaming(benchmark::State& state) {+  const int message_size = state.range(0);+  const int max_ping_pongs = state.range(1);+  CallbackStreamingTestService service;+  std::unique_ptr<Fixture> fixture(new Fixture(&service));+  std::unique_ptr<EchoTestService::Stub> stub_(+      EchoTestService::NewStub(fixture->channel()));+  EchoRequest request;+  EchoResponse response;+  if (state.range(0) > 0) {+    request.set_message(std::string(state.range(0), 'a'));+  } else {+    request.set_message("""");+  }+  while (state.KeepRunning()) {+    GPR_TIMER_SCOPE(""BenchmarkCycle"", 0);+    ClientContext cli_ctx;+    cli_ctx.AddMetadata(kServerFinishAfterNReads,+                        grpc::to_string(max_ping_pongs));+    cli_ctx.AddMetadata(kServerMessageSize, grpc::to_string(message_size));+    BidiClient test{stub_.get(), &request, &response, &cli_ctx, max_ping_pongs};+    test.Await();","Can you make the termination condition here follow the same style as in unary and avoid using the Await (which has a lock, mutex, etc) in the microbenchmark loop.",
303201,JamesNK,https://api.github.com/repos/grpc/grpc/pulls/18897,280959418,2019-05-04T00:07:49Z,tools/run_tests/run_interop_tests.py,"@@ -210,8 +209,10 @@ def global_env(self):         return {}      def unimplemented_test_cases(self):-        # aspnetcore doesn't have a client so ignore all test cases.-        return _TEST_CASES + _AUTH_TEST_CASES+        return _SKIP_COMPRESSION + \+            _SKIP_SPECIAL_STATUS_MESSAGE + \+            _AUTH_TEST_CASES + \+            ['cancel_after_first_response', 'ping_pong']",This is temporary. When HttpClient streaming has been fixed these will be enabled.,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18865,281079981,2019-05-06T07:14:25Z,src/csharp/Grpc.Core/Internal/Slice.cs,"@@ -0,0 +1,68 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Runtime.InteropServices;+using System.Threading;+using Grpc.Core.Utils;++namespace Grpc.Core.Internal+{+    /// <summary>+    /// Slice of native memory.+    /// Rough equivalent of grpc_slice (but doesn't support inlined slices, just a pointer to data and length)+    /// </summary>+    internal struct Slice+    {+        private readonly IntPtr dataPtr;+        private readonly int length;+     +        public Slice(IntPtr dataPtr, int length)+        {+            this.dataPtr = dataPtr;+            this.length = length;+        }++        public int Length => length;++        // copies data of the slice to given span.+        // there needs to be enough space in the destination buffer+        public void CopyTo(ArraySegment<byte> destination)+        {+            Marshal.Copy(dataPtr, destination.Array, destination.Offset, length);+        }++#if GRPC_CSHARP_SUPPORT_SYSTEM_MEMORY+        public Span<byte> ToSpanUnsafe()+        {+            unsafe+            {+                return new Span<byte>((byte*) dataPtr, length);+            }+        }+#endif++        /// <summary>+        /// Returns a <see cref=""System.String""/> that represents the current <see cref=""Grpc.Core.Internal.Slice""/>.+        /// </summary>+        public override string ToString()+        {+            return string.Format(""[Slice: dataPtr={0}, length={1}]"", dataPtr, length);","Sorry, bad suggestion - I agree that because Slice is a struct, there wouldn't be benefits with that",OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/18955,281283131,2019-05-06T17:35:42Z,bazel/cc_grpc_library.bzl,"@@ -2,70 +2,94 @@  load(""//bazel:generate_cc.bzl"", ""generate_cc"") -def cc_grpc_library(name, srcs, deps, proto_only, well_known_protos, generate_mocks = False, use_external = False, **kwargs):-  """"""Generates C++ grpc classes from a .proto file.+def cc_grpc_library(+        name,+        srcs,+        deps,+        proto_only = False,+        well_known_protos = True,+        generate_mocks = False,+        use_external = False,+        grpc_only = False,+        **kwargs):+    """"""Generates C++ grpc classes for services defined in a proto file. -  Assumes the generated classes will be used in cc_api_version = 2.+    If grpc_only is True, this rule is compatible with proto_library and+    cc_proto_library native rules such that it expects proto_library target+    as srcs argument and generates only grpc library classes, expecting+    protobuf messages classes library (cc_proto_library target) to be passed in+    deps argument. By default grpc_only is False which makes this rule to behave+    in a backwards-compatible mode (trying to generate both proto and grpc+    classes). -  Arguments:-      name: name of rule.-      srcs: a single proto_library, which wraps the .proto files with services.-      deps: a list of C++ proto_library (or cc_proto_library) which provides-        the compiled code of any message that the services depend on.-      well_known_protos: Should this library additionally depend on well known-        protos-      use_external: When True the grpc deps are prefixed with //external. This-        allows grpc to be used as a dependency in other bazel projects.-      generate_mocks: When True, Google Mock code for client stub is generated.-      **kwargs: rest of arguments, e.g., compatible_with and visibility.-  """"""-  if len(srcs) > 1:-    fail(""Only one srcs value supported"", ""srcs"")+    Assumes the generated classes will be used in cc_api_version = 2. -  proto_target = ""_"" + name + ""_only""-  codegen_target = ""_"" + name + ""_codegen""-  codegen_grpc_target = ""_"" + name + ""_grpc_codegen""-  proto_deps = [""_"" + dep + ""_only"" for dep in deps if dep.find(':') == -1]-  proto_deps += [dep.split(':')[0] + ':' + ""_"" + dep.split(':')[1] + ""_only"" for dep in deps if dep.find(':') != -1]+    Args:+        name (str): Name of rule.+        srcs (list): A single .proto file which contains services definitions,","Adding type annotations in the docstring is definitely an improvement, but it seems that this is setting a precedent. Where possible, I think it's a good idea to follow PyType conventions. So, how do you feel about changing `list` to `List[str]`?",OK
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/18925,281310409,2019-05-06T18:48:00Z,src/core/ext/transport/chttp2/transport/writing.cc,"@@ -446,6 +470,13 @@ class StreamWriteContext {         ""send_initial_metadata_finished"");   } +  bool compressed_data_buffer_len() {",would it be better to just initialize compressed_data_buffer so that we get a length of 0 to avoid the comparison?,
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/18909,281324633,2019-05-06T19:27:15Z,include/grpcpp/server_builder_impl.h,"@@ -37,25 +37,39 @@ struct grpc_resource_quota;  namespace grpc_impl {-+class ExternalConnectionAcceptorImpl; class ResourceQuota; class ServerCredentials; }  // namespace grpc_impl+ namespace grpc {  class AsyncGenericService; class CompletionQueue; class ServerCompletionQueue; class Service;- namespace testing { class ServerBuilderPluginTest; }  // namespace testing  namespace experimental { class CallbackGenericService; }++class ExternalConnectionAcceptor {",some docs for this class?,OK
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/18909,281368411,2019-05-06T21:22:50Z,include/grpcpp/server_impl.h,"@@ -183,6 +184,8 @@ class Server : public grpc::ServerInterface, private grpc::GrpcLibraryCodegen {       std::shared_ptr<std::vector<std::unique_ptr<grpc::ServerCompletionQueue>>>           sync_server_cqs,       int min_pollers, int max_pollers, int sync_cq_timeout_msec,+      std::vector<std::shared_ptr<::grpc_impl::ExternalConnectionAcceptorImpl>>","I think it should be fine, as the ServerBuilder reference is handled in this PR and the internal subclass will be fixed once I import this change.",OK
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/18875,281385012,2019-05-06T22:19:49Z,src/core/lib/gpr/alloc.cc,"@@ -33,8 +34,56 @@ static void* zalloc_with_gpr_malloc(size_t sz) {   return p; } -static gpr_allocation_functions g_alloc_functions = {malloc, zalloc_with_calloc,-                                                     realloc, free};+#ifndef NDEBUG+static constexpr bool is_power_of_two(size_t value) {+  // 2^N =     100000...000+  // 2^N - 1 = 011111...111+  // (2^N) && ((2^N)-1)) = 0+  return (value & (value - 1)) == 0;+}+#endif++static void* platform_malloc_aligned(size_t size, size_t alignment) {+#if defined(GPR_HAS_ALIGNED_ALLOC)+  GPR_DEBUG_ASSERT(is_power_of_two(alignment));+  size = GPR_ROUND_UP_TO_ALIGNMENT_SIZE(size, alignment);+  void* ret = aligned_alloc(alignment, size);+  GPR_ASSERT(ret != nullptr);+  return ret;+#elif defined(GPR_HAS_ALIGNED_MALLOC)+  GPR_DEBUG_ASSERT(is_power_of_two(alignment));+  void* ret = _aligned_malloc(size, alignment);+  GPR_ASSERT(ret != nullptr);+  return ret;+#elif defined(GPR_HAS_POSIX_MEMALIGN)+  GPR_DEBUG_ASSERT(is_power_of_two(alignment));+  GPR_DEBUG_ASSERT(alignment % sizeof(void*) == 0);+  void* ret = nullptr;+  GPR_ASSERT(posix_memalign(&ret, alignment, size) == 0);+  return ret;+#else","Please do not use this pattern. No code should ever be behind a `#else`. Instead, we should have a `#error`. The ""default"" case should be another `#define` that we can toggle. For instance, due to #18905, we need to be able to toggle the default case for backward compatibility purpose when shipping binary files.",
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/18909,281789716,2019-05-07T19:12:27Z,include/grpcpp/server_impl.h,"@@ -183,6 +184,8 @@ class Server : public grpc::ServerInterface, private grpc::GrpcLibraryCodegen {       std::shared_ptr<std::vector<std::unique_ptr<grpc::ServerCompletionQueue>>>           sync_server_cqs,       int min_pollers, int max_pollers, int sync_cq_timeout_msec,+      std::vector<std::shared_ptr<::grpc_impl::ExternalConnectionAcceptorImpl>>","Right, it is a breaking change in that sense. What I was trying to say is that I know why it is marked protected and I will fix the internal subclass. I do not think it will affect users as this is not really public API.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18909,281853509,2019-05-07T22:27:56Z,include/grpcpp/server_builder_impl.h,"@@ -37,25 +37,39 @@ struct grpc_resource_quota;  namespace grpc_impl {-+class ExternalConnectionAcceptorImpl; class ResourceQuota; class ServerCredentials; }  // namespace grpc_impl+ namespace grpc {  class AsyncGenericService; class CompletionQueue; class ServerCompletionQueue; class Service;- namespace testing { class ServerBuilderPluginTest; }  // namespace testing  namespace experimental { class CallbackGenericService; }++class ExternalConnectionAcceptor {",Can you also move this class to namespace experimental?,OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18909,281854468,2019-05-07T22:31:55Z,include/grpcpp/server_builder_impl.h,"@@ -248,6 +265,16 @@ class ServerBuilder {     ServerBuilder& RegisterCallbackGenericService(         grpc::experimental::CallbackGenericService* service); +    enum ExternalConnectionType {",Let's use `enum class` for new `enum` types,OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18909,281855307,2019-05-07T22:35:41Z,include/grpcpp/server_builder_impl.h,"@@ -248,6 +265,16 @@ class ServerBuilder {     ServerBuilder& RegisterCallbackGenericService(         grpc::experimental::CallbackGenericService* service); +    enum ExternalConnectionType {+      CONNECTION_FROM_FD = 0  // in the form of a file descriptor+    };++    // Create an acceptor to take in external connections and pass them to the+    // gRPC server.","The above comment seems a little low on detail. What is the return value, how is it used, what do the parameters signify, etc.",
2030323,JunTaoLuo,https://api.github.com/repos/grpc/grpc/pulls/18705,281865788,2019-05-07T23:26:11Z,src/compiler/csharp_plugin.cc,"@@ -38,10 +38,14 @@ class CSharpGrpcGenerator : public grpc::protobuf::compiler::CodeGenerator {      bool generate_client = true;     bool generate_server = true;+    bool generate_lite_client = true;",If we were to have independent options to turn off client and lite client generation I think we should default this to false so there's no bloat for the existing projects.,OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/18981,281874693,2019-05-08T00:14:23Z,src/core/lib/surface/call.cc,"@@ -553,10 +553,10 @@ static void destroy_call(void* call, grpc_error* error) {                                             grpc_schedule_on_exec_ctx)); } -void grpc_call_ref(grpc_call* c) { gpr_ref(&c->ext_ref); }+void grpc_call_ref(grpc_call* c) { c->ext_ref.Ref(); }  void grpc_call_unref(grpc_call* c) {-  if (!gpr_unref(&c->ext_ref)) return;+  if (GPR_UNLIKELY(!c->ext_ref.Unref())) return;","Oh darn. Thanks for catching this . This is a typo. My brain said likely but my hand wrote unlikely. I'm away from desk, will fix tonight. ",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18909,281933349,2019-05-08T06:49:13Z,src/cpp/server/external_connection_acceptor_impl.cc,"@@ -0,0 +1,95 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/cpp/server/external_connection_acceptor_impl.h""++#include <memory>++#include <grpcpp/server_builder_impl.h>+#include <grpcpp/support/channel_arguments.h>++namespace grpc {+namespace internal {+namespace {+class InternalAcceptor : public experimental::ExternalConnectionAcceptor {",InternalAcceptor is a funny name for a class that implements ExternalConnectionAcceptor,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18909,281934122,2019-05-08T06:52:29Z,include/grpcpp/server_builder_impl.h,"@@ -37,25 +37,42 @@ struct grpc_resource_quota;  namespace grpc_impl {-+class ExternalConnectionAcceptorImpl; class ResourceQuota; class ServerCredentials; }  // namespace grpc_impl+ namespace grpc {  class AsyncGenericService; class CompletionQueue; class ServerCompletionQueue; class Service;- namespace testing { class ServerBuilderPluginTest; }  // namespace testing  namespace experimental { class CallbackGenericService; }++// EXPERIMENTAL API:+// Interface for a grpc server to handle connections created out of band.+// See ServerBuilder's AddExternalConnectionAcceptor API for usage.+class ExternalConnectionAcceptor {+ public:+  struct NewConnectionParameters {+    int fd = -1;","Yeah, templates seem infeasible since you need to make this the parameter of a virtual function. I'm ok with this for the time being with the understanding that it's Posix-only but I hope that a better path forward can be implemented in time for the gRFC.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18909,281937600,2019-05-08T07:05:41Z,include/grpcpp/server_builder_impl.h,"@@ -248,6 +265,16 @@ class ServerBuilder {     ServerBuilder& RegisterCallbackGenericService(         grpc::experimental::CallbackGenericService* service); +    enum ExternalConnectionType {+      CONNECTION_FROM_FD = 0  // in the form of a file descriptor",I would suggest renaming it to GRPC_HTTP2_FROM_FD since one of the possible ways that you'll see different connection types is if we decide to support different transports and thus different wire formats. The enum would indicate which wire format to use when interpreting the FD.,OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/18881,282156495,2019-05-08T16:55:16Z,test/cpp/microbenchmarks/callback_test_service.h,"@@ -0,0 +1,130 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef TEST_CPP_MICROBENCHMARKS_CALLBACK_TEST_SERVICE_H+#define TEST_CPP_MICROBENCHMARKS_CALLBACK_TEST_SERVICE_H++#include <benchmark/benchmark.h>+#include <condition_variable>+#include <memory>+#include <mutex>+#include <sstream>+#include ""src/proto/grpc/testing/echo.grpc.pb.h""+#include ""test/cpp/util/string_ref_helper.h""++namespace grpc {+namespace testing {++const char* const kServerFinishAfterNReads = ""server_finish_after_n_reads"";+const char* const kServerMessageSize = ""server_message_size"";++class CallbackStreamingTestService+    : public EchoTestService::ExperimentalCallbackService {+ public:+  CallbackStreamingTestService() {}+  void Echo(ServerContext* context, const EchoRequest* request,+            EchoResponse* response,+            experimental::ServerCallbackRpcController* controller) override;++  experimental::ServerBidiReactor<EchoRequest, EchoResponse>* BidiStream()+      override;+};++class BidiClient",Nit: Could the definition of this class go in the .cc file instead?,
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/18910,282178999,2019-05-08T17:54:48Z,src/core/lib/transport/metadata.h,"@@ -136,10 +136,15 @@ bool grpc_mdelem_eq(grpc_mdelem a, grpc_mdelem b);  * static, and that the keys match. This most commonly happens when processing  * metadata batch callouts in initial/trailing filters. In this case, fastpath  * grpc_mdelem_eq and remove unnecessary checks. */-bool grpc_slice_eq_static(const grpc_slice& a, const grpc_slice& b_static);+int grpc_slice_differs_slowpath(const grpc_slice& a,+                                const grpc_slice& b_not_inline); inline bool grpc_mdelem_static_value_eq(grpc_mdelem a, grpc_mdelem b_static) {   if (a.payload == b_static.payload) return true;-  return grpc_slice_eq_static(GRPC_MDVALUE(a), GRPC_MDVALUE(b_static));+  const grpc_slice& a_slice = GRPC_MDVALUE(a);+  const grpc_slice& b_slice = GRPC_MDVALUE(b_static);+  return a_slice.refcount == b_slice.refcount","So this will also tie into a comment that Mark made, regarding why I'm doing a forward declaration as opposed to a an include of slice_internal.h.Basically, there is a dependency cycle. slice_internal.h includes static_metadata.h which includes metadata.h. So this means we cannot include slice_internal.h here. So we have to forward declare.Since grpc_slice_eq_static is inlined in its definition in slice_internal.h, just forward declaring means that we'll get a linker error with just a forward declaration.However, the slow path is not declared inline, so my terrible hack here is to just duplicate a bit of implementation and then call the slow path method which won't throw a linker error.TLDR: I don't call it because it would fail during the link process, and this is a hack.",OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/18910,282186557,2019-05-08T18:14:24Z,src/core/lib/transport/metadata.h,"@@ -136,10 +136,15 @@ bool grpc_mdelem_eq(grpc_mdelem a, grpc_mdelem b);  * static, and that the keys match. This most commonly happens when processing  * metadata batch callouts in initial/trailing filters. In this case, fastpath  * grpc_mdelem_eq and remove unnecessary checks. */-bool grpc_slice_eq_static(const grpc_slice& a, const grpc_slice& b_static);+int grpc_slice_differs_slowpath(const grpc_slice& a,+                                const grpc_slice& b_not_inline); inline bool grpc_mdelem_static_value_eq(grpc_mdelem a, grpc_mdelem b_static) {   if (a.payload == b_static.payload) return true;-  return grpc_slice_eq_static(GRPC_MDVALUE(a), GRPC_MDVALUE(b_static));+  const grpc_slice& a_slice = GRPC_MDVALUE(a);+  const grpc_slice& b_slice = GRPC_MDVALUE(b_static);+  return a_slice.refcount == b_slice.refcount","Is there some other way to solve it so we don't have to use the hack? Could we move grpc_slice_eq_static to a different file, then have metadata.h include that file?",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/19001,282637730,2019-05-09T19:47:39Z,include/grpcpp/server_impl.h,"@@ -333,9 +333,15 @@ class Server : public grpc::ServerInterface, private grpc::GrpcLibraryCodegen {    std::unique_ptr<grpc_impl::ServerInitializer> server_initializer_; +  // This is needed for an internal change.+  // TODO(https://github.com/grpc/grpc/issues/19000): We should be able to move+  // this above the private section entirely instead of inserting it here, but+  // there's a bug.+ protected:",No protected data members according to the style guide. Can these just be methods instead?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19001,282673972,2019-05-09T21:31:26Z,include/grpcpp/server_impl.h,"@@ -199,6 +199,14 @@ class Server : public grpc::ServerInterface, private grpc::GrpcLibraryCodegen {    grpc_server* server() override { return server_; } + protected:+  void SetHealthCheckServiceInterface(+      grpc::HealthCheckServiceInterface* service) {","Any reason not to make this argument a `unique_ptr<>`?  That way the compiler can enforce ownership, and the ownership semantics of the API are clear to readers.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18881,282679177,2019-05-09T21:49:10Z,test/cpp/microbenchmarks/callback_streaming_ping_pong.h,"@@ -0,0 +1,154 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef TEST_CPP_MICROBENCHMARKS_CALLBACK_STREAMING_PING_PONG_H+#define TEST_CPP_MICROBENCHMARKS_CALLBACK_STREAMING_PING_PONG_H++#include <benchmark/benchmark.h>+#include <sstream>+#include ""src/core/lib/profiling/timers.h""+#include ""src/proto/grpc/testing/echo.grpc.pb.h""+#include ""test/cpp/microbenchmarks/callback_test_service.h""+#include ""test/cpp/microbenchmarks/fullstack_context_mutators.h""+#include ""test/cpp/microbenchmarks/fullstack_fixtures.h""++namespace grpc {+namespace testing {++/*******************************************************************************+ * BENCHMARKING KERNELS+ */++class BidiClient+    : public grpc::experimental::ClientBidiReactor<EchoRequest, EchoResponse> {+ public:+  BidiClient(benchmark::State* state, EchoTestService::Stub* stub,+             ClientContext* cli_ctx, EchoRequest* request,+             EchoResponse* response)+      : state_{state},+        stub_{stub},+        cli_ctx_{cli_ctx},+        request_{request},+        response_{response} {+    msgs_size_ = state->range(0);+    msgs_to_send_ = state->range(1);+    StartNewRpc();+  }++  void OnReadDone(bool ok) override {+    if (!ok) {+      gpr_log(GPR_ERROR, ""Client read failed"");+      return;+    }+    if (writes_complete_ < msgs_to_send_) {+      MaybeWrite();+    }+  }++  void OnWriteDone(bool ok) override {+    if (!ok) {+      gpr_log(GPR_ERROR, ""Client write failed"");+      return;+    }+    writes_complete_++;+    StartRead(response_);+  }++  void OnDone(const Status& s) override {+    GPR_ASSERT(s.ok());+    GPR_ASSERT(writes_complete_ == msgs_to_send_);+    if (state_->KeepRunning()) {+      writes_complete_ = 0;+      StartNewRpc();+    } else {+      std::unique_lock<std::mutex> l(mu);+      done = true;+      cv.notify_one();+    }+  }++  void StartNewRpc() {+    cli_ctx_->~ClientContext();+    new (cli_ctx_) ClientContext();+    cli_ctx_->AddMetadata(kServerFinishAfterNReads,+                          grpc::to_string(msgs_to_send_));","Why is this metadata being used at all? If the client is issuing WritesDone at the right time, then the server's next Read would fail and that would trigger the server to finish the RPC.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19001,282684378,2019-05-09T22:08:16Z,include/grpcpp/server_impl.h,"@@ -199,6 +199,16 @@ class Server : public grpc::ServerInterface, private grpc::GrpcLibraryCodegen {    grpc_server* server() override { return server_; } + protected:+  void set_health_check_service(+      std::unique_ptr<grpc::HealthCheckServiceInterface> service) {+    health_check_service_ = std::move(service);+  }++  bool is_health_check_service_disabled() {",No need for the `is_` prefix.  The style guide convention is that getters have the same name as the underlying data member.,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/19001,283009192,2019-05-10T19:08:28Z,include/grpcpp/server_impl.h,"@@ -199,6 +199,16 @@ class Server : public grpc::ServerInterface, private grpc::GrpcLibraryCodegen {    grpc_server* server() override { return server_; } + protected:+  void set_health_check_service(+      std::unique_ptr<grpc::HealthCheckServiceInterface> service) {+    health_check_service_ = std::move(service);+  }++  bool health_check_service_disabled() {+    return health_check_service_disabled_;+  }+",Can we get a comment then saying that these are for internal use only and not API. Because protected is normally considered API since anyone can derive a class based on this.,
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19012,283463473,2019-05-13T17:54:05Z,src/core/ext/transport/chttp2/transport/hpack_encoder.cc,"@@ -255,22 +263,20 @@ static void add_key_with_index(grpc_chttp2_hpack_compressor* c,  /* add an element to the decoder table */ static void add_elem_with_index(grpc_chttp2_hpack_compressor* c,-                                grpc_mdelem elem, uint32_t new_index) {+                                grpc_mdelem elem, uint32_t new_index,+                                uint32_t elem_hash, uint32_t key_hash) {   if (new_index == 0) {     return;   }-  GPR_ASSERT(GRPC_MDELEM_IS_INTERNED(elem));--  uint32_t key_hash = grpc_slice_hash(GRPC_MDKEY(elem));-  uint32_t value_hash = grpc_slice_hash(GRPC_MDVALUE(elem));-  uint32_t elem_hash = GRPC_MDSTR_KV_HASH(key_hash, value_hash);+  GPR_DEBUG_ASSERT(GRPC_MDELEM_IS_INTERNED(elem));    /* Store this element into {entries,indices}_elem */-  if (grpc_mdelem_eq(c->entries_elems[HASH_FRAGMENT_2(elem_hash)], elem)) {+  if (grpc_mdelem_both_interned_eq(c->entries_elems[HASH_FRAGMENT_2(elem_hash)],","For the second parameter, elem in add_elem_with_index(c, elem, new_idx, elem_hash, key_hash):add_elem_with_index is called by: add_elem(c, elem, elem_sz, elem_hash, key_hash)add_elem() has two callsites, both in: hpack_enc(c, elem, st).in hpack_enc(): we calculate the variables ""elem_interned"" and ""should_add_elem"". Should_add_elem checks if elem is interned as a requirement. Thus, elem is interned.Now, the 2nd parameter elem is interned is compared with the first parameter: something that is already in the cuckoo hash we're maintaining here. There are only two candidates for valid things that can be in the hash: an empty mdelem  or something that was added via a previous call to add_elem(). Thus, we are guaranteed that the first MD parameter is either interned, or null - both are valid candidates for the short-circuited check.I think it is fine to add GPR_DEBUG_ASSERT() verifying that this is the case, to guard against people accidentally breaking these assumptions in the future.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18881,283487667,2019-05-13T18:54:52Z,test/cpp/microbenchmarks/callback_test_service.cc,"@@ -0,0 +1,125 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""test/cpp/microbenchmarks/callback_test_service.h""++namespace grpc {+namespace testing {+namespace {++grpc::string ToString(const grpc::string_ref& r) {+  return grpc::string(r.data(), r.size());+}++int GetIntValueFromMetadataHelper(+    const char* key,+    const std::multimap<grpc::string_ref, grpc::string_ref>& metadata,+    int default_value) {+  if (metadata.find(key) != metadata.end()) {+    std::istringstream iss(ToString(metadata.find(key)->second));+    iss >> default_value;+  }++  return default_value;+}++int GetIntValueFromMetadata(+    const char* key,+    const std::multimap<grpc::string_ref, grpc::string_ref>& metadata,+    int default_value) {+  return GetIntValueFromMetadataHelper(key, metadata, default_value);+}+}  // namespace++void CallbackStreamingTestService::Echo(+    ServerContext* context, const EchoRequest* request, EchoResponse* response,+    experimental::ServerCallbackRpcController* controller) {+  int response_msgs_size = GetIntValueFromMetadata(+      kServerMessageSize, context->client_metadata(), 0);+  if (response_msgs_size > 0) {+    response->set_message(std::string(response_msgs_size, 'a'));+  } else {+    response->set_message("""");+  }+  controller->Finish(Status::OK);+}++experimental::ServerBidiReactor<EchoRequest, EchoResponse>*+CallbackStreamingTestService::BidiStream() {+  class Reactor+      : public experimental::ServerBidiReactor<EchoRequest, EchoResponse> {+   public:+    Reactor() {}+    void OnStarted(ServerContext* context) override {+      ctx_ = context;+      server_write_last_ = GetIntValueFromMetadata(+          kServerFinishAfterNReads, context->client_metadata(), 0);+      message_size_ = GetIntValueFromMetadata(kServerMessageSize,+                                              context->client_metadata(), 0);+      StartRead(&request_);+    }+    void OnDone() override {+      GPR_ASSERT(finished_);+      GPR_ASSERT(num_msgs_read_ == server_write_last_);+      delete this;+    }+    void OnCancel() override {}+    void OnReadDone(bool ok) override {+      if (!ok) {+        gpr_log(GPR_ERROR, ""Server read failed"");","So this is an interesting API hole that it looks like we've put ourselves into. In general.... the primary meaning of `!ok` for OnReadDone is that the client has nothing more to write. This is normally the only way of knowing that since it isn't always the case (unlike this code) that the client-to-server path has a specifiable finite number of messages.The client would know if this was because of a stream error since the client would then get an error status returned regardless of what the server tries to send as a Status. So how does the server figure it out? If the server does a write and the OnWriteDone gets a `!ok` there was a stream failure. If the server sends a Finish and there's a stream error, we technically get the info internally saying that the finish completed with an error but we're swallowing that for now. So we actually never get the info at the server side that the stream had an error. The way around this is to have OnDone take a bool or something like that indicating whether the finish completed successfully.Cc @sheenaqotj since we're discussing API implicationsSo I think the action items are1. @nanahpang to make this code look like the rest of the tests and benchmarks by having the microbenchmark use `!ok` as a termination condition for a stream rather than a count passed by metadata2. @vjpai to evaluate the API change needed to support the desired signalling",OK
961599,murgatroid99,https://api.github.com/repos/grpc/grpc/pulls/18435,283577835,2019-05-13T23:40:31Z,src/core/lib/iomgr/resolve_address_custom.cc,"@@ -88,15 +88,21 @@ void grpc_custom_resolve_callback(grpc_custom_resolver* r, static grpc_error* try_split_host_port(const char* name,                                        const char* default_port, char** host,                                        char** port) {-  /* parse name, splitting it into host and port parts */   grpc_error* error;-  gpr_split_host_port(name, host, port);-  if (*host == nullptr) {-    char* msg;-    gpr_asprintf(&msg, ""unparseable host:port: '%s'"", name);-    error = GRPC_ERROR_CREATE_FROM_COPIED_STRING(msg);-    gpr_free(msg);-    return error;+  *port = nullptr;+  // all hosts beginning with / are treated as unix domain sockets+  if (name[0] == '/') {",The logic for determining whether a name is a UDS name and for handling those names should be the same as in the other resolver implementation(s). See https://github.com/grpc/grpc/blob/master/src/core/lib/iomgr/resolve_address_posix.cc#L57.,OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/19016,283993070,2019-05-14T20:46:15Z,include/grpcpp/impl/codegen/message_allocator.h,"@@ -22,31 +22,42 @@ namespace grpc { namespace experimental { -// This is per rpc struct for the allocator. We can potentially put the grpc-// call arena in here in the future.+// NOTE: This is an API for advanced users who need custom allocators.+// Per rpc struct for the allocator. This is the interface to return to user.+class RpcAllocatorState {+ public:+  virtual ~RpcAllocatorState() = default;+  // Optionally deallocate request early to reduce the size of working set.+  // A custom MessageAllocator needs to be registered to make use of this.+  // This is not abstract because implementing it is optional.+  virtual void FreeRequest() {}+};++// This is the interface returned by the allocator.+// grpc library will call the methods to get request/response pointers and to+// release the object when it is done. template <typename RequestT, typename ResponseT>-struct RpcAllocatorInfo {-  RequestT* request;-  ResponseT* response;-  // per rpc allocator internal state. MessageAllocator can set it when-  // AllocateMessages is called and use it later.-  void* allocator_state;+class MessageHolder : public RpcAllocatorState {+ public:+  virtual void Release() { delete this; }+  RequestT* request() { return request_; }+  ResponseT* response() { return response_; }++ protected:",Protected data members are not consistent with the style guide; consider using public setters and private data members,OK
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/19010,284026473,2019-05-14T22:35:00Z,src/core/ext/filters/client_channel/resolver/dns/c_ares/grpc_ares_wrapper.cc,"@@ -522,6 +522,74 @@ static bool target_matches_localhost(const char* name) {   return out; } +#ifdef GRPC_ARES_RESOLVE_LOCALHOST_MANUALLY+static bool inner_maybe_resolve_localhost_manually_locked(+    const char* name, const char* default_port,+    grpc_core::UniquePtr<grpc_core::ServerAddressList>* addrs, char** host,+    char** port) {+  gpr_split_host_port(name, host, port);+  if (*host == nullptr) {+    gpr_log(GPR_ERROR,+            ""Failed to parse %s into host:port during manual localhost ""+            ""resolution check."",+            name);+    return false;+  }+  if (*port == nullptr) {+    if (default_port == nullptr) {+      gpr_log(GPR_ERROR,+              ""No port or default port for %s during manual localhost ""+              ""resolution check."",+              name);+      return false;+    }+    *port = gpr_strdup(default_port);+  }+  if (gpr_stricmp(*host, ""localhost"") == 0) {+    GPR_ASSERT(*addrs == nullptr);+    *addrs = grpc_core::MakeUnique<grpc_core::ServerAddressList>();+    uint16_t numeric_port = grpc_strhtons(*port);+    // Append the ipv6 loopback address.+    struct sockaddr_in6 ipv6_loopback_addr;+    memset(&ipv6_loopback_addr, 0, sizeof(ipv6_loopback_addr));+    ((char*)&ipv6_loopback_addr.sin6_addr)[15] = 1;+    ipv6_loopback_addr.sin6_family = AF_INET6;+    ipv6_loopback_addr.sin6_port = numeric_port;+    (*addrs)->emplace_back(&ipv6_loopback_addr, sizeof(ipv6_loopback_addr),+                           nullptr /* args */);+    // Append the ipv4 loopback address.+    struct sockaddr_in ipv4_loopback_addr;+    memset(&ipv4_loopback_addr, 0, sizeof(ipv4_loopback_addr));+    ((char*)&ipv4_loopback_addr.sin_addr)[0] = 0x7f;+    ((char*)&ipv4_loopback_addr.sin_addr)[3] = 0x01;+    ipv4_loopback_addr.sin_family = AF_INET;+    ipv4_loopback_addr.sin_port = numeric_port;+    (*addrs)->emplace_back(&ipv4_loopback_addr, sizeof(ipv4_loopback_addr),+                           nullptr /* args */);+    // Let the address sorter figure out which one should be tried first.+    grpc_cares_wrapper_address_sorting_sort(addrs->get());+    return true;+  }+  return false;+}+#endif /* GRPC_ARES_RESOLVE_LOCALHOST_MANUALLY */","Sorry to be annoying, but I think I'd rather see these mashed together:```C#ifdef xxxstatic bool inner_maybe_resolve_localhost_manually_locked(...)  [...]}static bool grpc_ares_maybe_resolve_localhost_manually_locked(...) {  [...]  inner_maybe_resolve_localhost_manually_locked(...)  return out;}#elsestatic bool grpc_ares_maybe_resolve_localhost_manually_locked(    const char* name, const char* default_port,    grpc_core::UniquePtr<grpc_core::ServerAddressList>* addrs) {  return false;}#endif```The ""bad"" part would be the duplication of the function signature, but between Windows and Linux, there's enough coverage between the two so that we'd catch any change in signature quickly.",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19023,284084918,2019-05-15T04:42:29Z,src/core/ext/filters/http/message_compress/message_compress_filter.cc,"@@ -366,6 +380,7 @@ static void start_send_message_batch(void* arg, grpc_error* unused) {           calld->send_initial_metadata_state == HAS_COMPRESSION_ALGORITHM)) {     send_message_batch_continue(elem);   } else {+    maybe_initialize(elem, calld);","How about putting this at the place where `calld->send_initial_metadata_state` is set to `HAS_COMPRESSION_ALGORITHM`? (currently it is at line 426). In that case you probably can avoid the ""maybe"" term and `state_initialized`.",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19023,284085882,2019-05-15T04:49:52Z,src/core/ext/filters/http/message_compress/message_compress_filter.cc,"@@ -60,31 +60,29 @@ struct call_data {     GRPC_CLOSURE_INIT(&start_send_message_batch_in_call_combiner,                       start_send_message_batch, elem,                       grpc_schedule_on_exec_ctx);-    grpc_slice_buffer_init(&slices);-    GRPC_CLOSURE_INIT(&send_message_on_complete, ::send_message_on_complete,-                      elem, grpc_schedule_on_exec_ctx);-    GRPC_CLOSURE_INIT(&on_send_message_next_done, ::on_send_message_next_done,-                      elem, grpc_schedule_on_exec_ctx);   }    ~call_data() {-    grpc_slice_buffer_destroy_internal(&slices);+    if (state_initialized) {+      grpc_slice_buffer_destroy_internal(&slices);+    }     GRPC_ERROR_UNREF(cancel_error);   }    grpc_core::CallCombiner* call_combiner;-  grpc_linked_mdelem compression_algorithm_storage;-  grpc_linked_mdelem stream_compression_algorithm_storage;-  grpc_linked_mdelem accept_encoding_storage;-  grpc_linked_mdelem accept_stream_encoding_storage;+  grpc_transport_stream_op_batch* send_message_batch = nullptr;",What is the reason to move this field and the *_storage fields around? (I believe you have a good reason but I failed to figure it out; my bad :),
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/19031,284284326,2019-05-15T14:26:17Z,src/core/lib/transport/metadata.h,"@@ -241,42 +268,34 @@ class AllocatedMetadata {   AllocatedMetadata(const grpc_slice& key, const grpc_slice& value);   ~AllocatedMetadata(); -  const grpc_slice& key() const { return key_; }-  const grpc_slice& value() const { return value_; }+  const grpc_slice& key() const { return common_.key; }+  const grpc_slice& value() const { return common_.value; }   UserData* user_data() { return &user_data_; }  #ifndef NDEBUG   void Ref(const char* file, int line) {-    grpc_mdelem_trace_ref(this, key_, value_, RefValue(), file, line);-    Ref();+    grpc_mdelem_trace_ref(this, common_.key, common_.value, RefValue(), file,+                          line);+    common_.Ref();   }   bool Unref(const char* file, int line) {-    grpc_mdelem_trace_unref(this, key_, value_, RefValue(), file, line);-    return Unref();+    grpc_mdelem_trace_unref(this, common_.key, common_.value, RefValue(), file,+                            line);+    return common_.Unref();   } #endif  // ifndef NDEBUG-  void Ref() {-    /* we can assume the ref count is >= 1 as the application is calling-       this function - meaning that no adjustment to mdtab_free is necessary,-       simplifying the logic here to be just an atomic increment */-    refcnt_.FetchAdd(1, MemoryOrder::RELAXED);-  }-  bool Unref() {-    const intptr_t prior = refcnt_.FetchSub(1, MemoryOrder::ACQ_REL);-    GPR_DEBUG_ASSERT(prior > 0);-    return prior == 1;+  void Ref() { common_.Ref(); }+  bool Unref() { return common_.Unref(); }++  static constexpr size_t offset() {+    return offsetof(AllocatedMetadata, common_);   }   private:-  intptr_t RefValue() { return refcnt_.Load(MemoryOrder::RELAXED); }+  intptr_t RefValue() { return common_.RefValue(); }    /* must be byte compatible with grpc_mdelem_data */-  grpc_slice key_;-  grpc_slice value_;--  /* private only data */-  grpc_core::Atomic<intptr_t> refcnt_;-+  MdCommon common_;",This is going to be fragile. I would suggest renaming this to `MdBase` inheriting from it so that we are sure all meta-data types have the same first fields. As a bonus you won't need to repeat methods like Ref()/Unref()/RefValue() everywhere.,OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/19023,284356577,2019-05-15T16:59:43Z,src/core/ext/filters/http/message_compress/message_compress_filter.cc,"@@ -366,6 +380,7 @@ static void start_send_message_batch(void* arg, grpc_error* unused) {           calld->send_initial_metadata_state == HAS_COMPRESSION_ALGORITHM)) {     send_message_batch_continue(elem);   } else {+    maybe_initialize(elem, calld);","That's a great idea, I tried that. Then it occurred to me that for channels with some default compression, when we send all RPCs with no-compress we will be initializing the state, right?  Is that common not to have compression algorithm in the initial metadata, and some default compression algorithm?I couldn't find a way to workaround this issue. Would you suggest any other technique?",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19023,284410354,2019-05-15T19:15:01Z,src/core/ext/filters/http/message_compress/message_compress_filter.cc,"@@ -366,6 +380,7 @@ static void start_send_message_batch(void* arg, grpc_error* unused) {           calld->send_initial_metadata_state == HAS_COMPRESSION_ALGORITHM)) {     send_message_batch_continue(elem);   } else {+    maybe_initialize(elem, calld);","> Is that common not to have compression algorithm in the initial metadata, and some default compression algorithm?Ah that is good point! In fact, I am suspecting it is *probably* a bug in the `process_send_initial_metadata`; `has_compression_algorithm` probably should not set to true if the [compression algorithm](https://github.com/grpc/grpc/blob/master/src/core/ext/filters/http/message_compress/message_compress_filter.cc#L166) parsed from the initial metadata is actually ""no compression"" (@AspirinSJL could you also take a look?). But you are totally right that under this situation, it should not initialize those variables.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19035,284438031,2019-05-15T20:31:34Z,test/cpp/client/client_channel_stress_test.cc,"@@ -289,10 +314,32 @@ class ClientChannelStressTest {           ""balancer"", server_host_, balancers_.back().get()));     }     // Start sending RPCs in multiple threads.-    CreateStub();-    for (size_t i = 0; i < kNumClientThreads; ++i) {-      client_threads_.emplace_back(-          std::thread(&ClientChannelStressTest::KeepSendingRequests, this));+    static const char* kServiceConfigs[] = {+        // No service config -- will use grpclb with no health checking.+        nullptr,+        // Use pick_first.+        ""{\""loadBalancingConfig\"":[{\""pick_first\"":{}}]}"",+        // Use round_robin with client-side health checking.+        ""{""+        ""  \""loadBalancingConfig\"":[{\""round_robin\"":{}}],""+        ""  \""healthCheckConfig\"": {\""serviceName\"": \""\""}""+        ""}"",+        // Same as pervious, but with a different (unhealthy) health+        // check service name.+        ""{""+        ""  \""loadBalancingConfig\"":[{\""round_robin\"":{}}],""+        ""  \""healthCheckConfig\"": {\""serviceName\"": \""unhealthy\""}""+        ""}"",+        };+    for (size_t j = 0; j < GPR_ARRAY_SIZE(kServiceConfigs); ++j) {+      std::unique_ptr<ClientHandle> client_handle =+          CreateClientHandle(kServiceConfigs[j]);+      for (size_t i = 0; i < kNumClientThreadsPerChannel; ++i) {+        client_threads_.emplace_back(+            std::thread(&ClientChannelStressTest::KeepSendingRequests, this,","I don't really want to inline all the code from `KeepSendingRequests()`, so taking the address seems fine here.I have removed the unnecessary `std::thread` class name here.",OK
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/19032,284541653,2019-05-16T05:15:56Z,src/core/lib/security/credentials/oauth2/oauth2_credentials.cc,"@@ -472,6 +474,140 @@ grpc_call_credentials* grpc_google_refresh_token_credentials_create(       .release(); } +//+// STS credentials.+//++namespace {++char* maybe_add_to_query(char* body, const char* field_name, char* field) {+  if (field == nullptr || strlen(field) == 0) return body;+  char* new_body;+  gpr_asprintf(&new_body, ""%s&%s=%s"", body, field_name, field);+  gpr_free(body);+  return new_body;+}++class grpc_sts_token_fetcher_credentials+    : public grpc_oauth2_token_fetcher_credentials {+ public:+  grpc_sts_token_fetcher_credentials(+      grpc_uri* sts_url,  // Ownership transfered.+      const grpc_sts_credentials_options* options)+      : sts_url_(sts_url),+        resource_(gpr_strdup(options->resource)),+        audience_(gpr_strdup(options->audience)),+        scope_(gpr_strdup(options->scope)),+        requested_token_type_(gpr_strdup(options->requested_token_type)),+        subject_token_(gpr_strdup(options->subject_token)),+        subject_token_type_(gpr_strdup(options->subject_token_type)),+        actor_token_(gpr_strdup(options->actor_token)),+        actor_token_type_(gpr_strdup(options->actor_token_type)) {}++  ~grpc_sts_token_fetcher_credentials() override { grpc_uri_destroy(sts_url_); }++ protected:+  void fetch_oauth2(grpc_credentials_metadata_request* metadata_req,+                    grpc_httpcli_context* http_context,+                    grpc_polling_entity* pollent,+                    grpc_iomgr_cb_func response_cb,+                    grpc_millis deadline) override {+    grpc_http_header header = {(char*)""Content-Type"",+                               (char*)""application/x-www-form-urlencoded""};+    grpc_httpcli_request request;+    char* body = nullptr;+    gpr_asprintf(&body, GRPC_STS_POST_MINIMAL_BODY_FORMAT_STRING,+                 subject_token_.get(), subject_token_type_.get());+    body = maybe_add_to_query(body, ""resource"", resource_.get());+    body = maybe_add_to_query(body, ""audience"", audience_.get());+    body = maybe_add_to_query(body, ""scope"", scope_.get());+    body = maybe_add_to_query(body, ""requested_token_type"",+                              requested_token_type_.get());+    body = maybe_add_to_query(body, ""actor_token"", actor_token_.get());+    body =+        maybe_add_to_query(body, ""actor_token_type"", actor_token_type_.get());++    memset(&request, 0, sizeof(grpc_httpcli_request));+    request.host = (char*)sts_url_->authority;+    request.http.path = (char*)sts_url_->path;+    request.http.hdr_count = 1;+    request.http.hdrs = &header;+    request.handshaker = (strcmp(sts_url_->scheme, ""https"") == 0)+                             ? &grpc_httpcli_ssl+                             : &grpc_httpcli_plaintext;+    /* TODO(ctiller): Carry the resource_quota in ctx and share it with the host+       channel. This would allow us to cancel an authentication query when under+       extreme memory pressure. */+    grpc_resource_quota* resource_quota =+        grpc_resource_quota_create(""oauth2_credentials_refresh"");+    grpc_httpcli_post(http_context, pollent, resource_quota, &request, body,+                      strlen(body), deadline,+                      GRPC_CLOSURE_CREATE(response_cb, metadata_req,+                                          grpc_schedule_on_exec_ctx),+                      &metadata_req->response);+    grpc_resource_quota_unref_internal(resource_quota);+    gpr_free(body);+  }++ private:+  grpc_uri* sts_url_;+  grpc_core::UniquePtr<char> resource_;+  grpc_core::UniquePtr<char> audience_;+  grpc_core::UniquePtr<char> scope_;+  grpc_core::UniquePtr<char> requested_token_type_;+  grpc_core::UniquePtr<char> subject_token_;+  grpc_core::UniquePtr<char> subject_token_type_;+  grpc_core::UniquePtr<char> actor_token_;+  grpc_core::UniquePtr<char> actor_token_type_;+};++}  // namespace++grpc_uri* grpc_validate_sts_credentials_options(+    const grpc_sts_credentials_options* options) {+  grpc_uri* sts_url = nullptr;+  if (options->sts_endpoint_url == nullptr ||+      strlen(options->sts_endpoint_url) == 0) {+    gpr_log(GPR_ERROR, ""sts_endpoint_url needs to be specified"");+    goto fail;",I thought about it but decided against it for the sake of consistency in the error handling pattern in this function. I can still do it if you feel strongly about it.,
6262765,jboeuf,https://api.github.com/repos/grpc/grpc/pulls/19032,284541749,2019-05-16T05:16:36Z,src/core/lib/security/credentials/oauth2/oauth2_credentials.cc,"@@ -472,6 +474,140 @@ grpc_call_credentials* grpc_google_refresh_token_credentials_create(       .release(); } +//+// STS credentials.+//++namespace {++char* maybe_add_to_query(char* body, const char* field_name, char* field) {+  if (field == nullptr || strlen(field) == 0) return body;+  char* new_body;+  gpr_asprintf(&new_body, ""%s&%s=%s"", body, field_name, field);+  gpr_free(body);+  return new_body;+}++class grpc_sts_token_fetcher_credentials+    : public grpc_oauth2_token_fetcher_credentials {+ public:+  grpc_sts_token_fetcher_credentials(+      grpc_uri* sts_url,  // Ownership transfered.+      const grpc_sts_credentials_options* options)+      : sts_url_(sts_url),+        resource_(gpr_strdup(options->resource)),+        audience_(gpr_strdup(options->audience)),+        scope_(gpr_strdup(options->scope)),+        requested_token_type_(gpr_strdup(options->requested_token_type)),+        subject_token_(gpr_strdup(options->subject_token)),+        subject_token_type_(gpr_strdup(options->subject_token_type)),+        actor_token_(gpr_strdup(options->actor_token)),+        actor_token_type_(gpr_strdup(options->actor_token_type)) {}++  ~grpc_sts_token_fetcher_credentials() override { grpc_uri_destroy(sts_url_); }++ protected:+  void fetch_oauth2(grpc_credentials_metadata_request* metadata_req,+                    grpc_httpcli_context* http_context,+                    grpc_polling_entity* pollent,+                    grpc_iomgr_cb_func response_cb,+                    grpc_millis deadline) override {+    grpc_http_header header = {(char*)""Content-Type"",+                               (char*)""application/x-www-form-urlencoded""};+    grpc_httpcli_request request;+    char* body = nullptr;+    gpr_asprintf(&body, GRPC_STS_POST_MINIMAL_BODY_FORMAT_STRING,+                 subject_token_.get(), subject_token_type_.get());+    body = maybe_add_to_query(body, ""resource"", resource_.get());+    body = maybe_add_to_query(body, ""audience"", audience_.get());+    body = maybe_add_to_query(body, ""scope"", scope_.get());+    body = maybe_add_to_query(body, ""requested_token_type"",+                              requested_token_type_.get());+    body = maybe_add_to_query(body, ""actor_token"", actor_token_.get());+    body =+        maybe_add_to_query(body, ""actor_token_type"", actor_token_type_.get());++    memset(&request, 0, sizeof(grpc_httpcli_request));+    request.host = (char*)sts_url_->authority;+    request.http.path = (char*)sts_url_->path;+    request.http.hdr_count = 1;+    request.http.hdrs = &header;+    request.handshaker = (strcmp(sts_url_->scheme, ""https"") == 0)+                             ? &grpc_httpcli_ssl+                             : &grpc_httpcli_plaintext;+    /* TODO(ctiller): Carry the resource_quota in ctx and share it with the host",Maybe in another PR as there are a bunch of these on the same pattern. What do you think?,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18909,284543759,2019-05-16T05:30:41Z,include/grpcpp/server_builder_impl.h,"@@ -248,6 +265,16 @@ class ServerBuilder {     ServerBuilder& RegisterCallbackGenericService(         grpc::experimental::CallbackGenericService* service); +    enum ExternalConnectionType {+      CONNECTION_FROM_FD = 0  // in the form of a file descriptor","I'm ok with what you just said. But now that it's an ""enum class"", the CONNECTION prefix is redundant with the class scope. So it could just be FROM_FD so that the full specification is ExternalConnectionType::FROM_FD . I'll leave that decision to you and the eventual gRFC.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/19035,284933200,2019-05-16T23:24:53Z,test/cpp/client/client_channel_stress_test.cc,"@@ -289,10 +314,32 @@ class ClientChannelStressTest {           ""balancer"", server_host_, balancers_.back().get()));     }     // Start sending RPCs in multiple threads.-    CreateStub();-    for (size_t i = 0; i < kNumClientThreads; ++i) {-      client_threads_.emplace_back(-          std::thread(&ClientChannelStressTest::KeepSendingRequests, this));+    static const char* kServiceConfigs[] = {+        // No service config -- will use grpclb with no health checking.+        nullptr,+        // Use pick_first.+        ""{\""loadBalancingConfig\"":[{\""pick_first\"":{}}]}"",+        // Use round_robin with client-side health checking.+        ""{""+        ""  \""loadBalancingConfig\"":[{\""round_robin\"":{}}],""+        ""  \""healthCheckConfig\"": {\""serviceName\"": \""\""}""+        ""}"",+        // Same as pervious, but with a different (unhealthy) health+        // check service name.+        ""{""+        ""  \""loadBalancingConfig\"":[{\""round_robin\"":{}}],""+        ""  \""healthCheckConfig\"": {\""serviceName\"": \""unhealthy\""}""+        ""}"",+        };+    for (size_t j = 0; j < GPR_ARRAY_SIZE(kServiceConfigs); ++j) {+      std::unique_ptr<ClientHandle> client_handle =+          CreateClientHandle(kServiceConfigs[j]);+      for (size_t i = 0; i < kNumClientThreadsPerChannel; ++i) {+        client_threads_.emplace_back(+            std::thread(&ClientChannelStressTest::KeepSendingRequests, this,","No, I'm not asking you to duplicate the code. I'm asking for not taking the address of the function, so```[this]{KeepSendingRequests(...);}```or whatever",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/19035,284934028,2019-05-16T23:28:56Z,test/cpp/client/client_channel_stress_test.cc,"@@ -289,10 +314,32 @@ class ClientChannelStressTest {           ""balancer"", server_host_, balancers_.back().get()));     }     // Start sending RPCs in multiple threads.-    CreateStub();-    for (size_t i = 0; i < kNumClientThreads; ++i) {-      client_threads_.emplace_back(-          std::thread(&ClientChannelStressTest::KeepSendingRequests, this));+    static const char* kServiceConfigs[] = {+        // No service config -- will use grpclb with no health checking.+        nullptr,+        // Use pick_first.+        ""{\""loadBalancingConfig\"":[{\""pick_first\"":{}}]}"",+        // Use round_robin with client-side health checking.+        ""{""+        ""  \""loadBalancingConfig\"":[{\""round_robin\"":{}}],""+        ""  \""healthCheckConfig\"": {\""serviceName\"": \""\""}""+        ""}"",+        // Same as pervious, but with a different (unhealthy) health+        // check service name.+        ""{""+        ""  \""loadBalancingConfig\"":[{\""round_robin\"":{}}],""+        ""  \""healthCheckConfig\"": {\""serviceName\"": \""unhealthy\""}""+        ""}"",+        };+    for (size_t j = 0; j < GPR_ARRAY_SIZE(kServiceConfigs); ++j) {+      std::unique_ptr<ClientHandle> client_handle =+          CreateClientHandle(kServiceConfigs[j]);+      for (size_t i = 0; i < kNumClientThreadsPerChannel; ++i) {+        client_threads_.emplace_back(+            std::thread(&ClientChannelStressTest::KeepSendingRequests, this,","Basically constructs like taking function addresses or std::bind are vestiges from the bad-old-days before the lambda. Since the lambda is part of the language, the compiler actually has a better shot of analyzing that than a function address (or a ...shudder... bind). It also seems more readable.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/19035,284934484,2019-05-16T23:31:26Z,test/cpp/client/client_channel_stress_test.cc,"@@ -133,6 +134,7 @@ class BalancerServiceImpl : public LoadBalancer::Service { class ClientChannelStressTest {  public:   void Run() {+    EnableDefaultHealthCheckService(true);",Sounds good. As long as both cases are well-tested.,
14166415,sanjaypujare,https://api.github.com/repos/grpc/grpc/pulls/19055,284937594,2019-05-16T23:48:45Z,src/core/lib/security/credentials/ssl/ssl_credentials.h,"@@ -28,7 +28,7 @@ class grpc_ssl_credentials : public grpc_channel_credentials {  public:   grpc_ssl_credentials(const char* pem_root_certs,                        grpc_ssl_pem_key_cert_pair* pem_key_cert_pair,-                       const verify_peer_options* verify_options);+                       const grpc_verify_peer_options* verify_options);","If you have client code compiled using previous `grpc_ssl_credentials` class definition, the signature of the constructor `grpc_ssl_credentials` doesn't match the new signature. Wouldn't you get build/run-time failures because of this mismatch?",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/19016,285236129,2019-05-17T18:17:12Z,include/grpcpp/impl/codegen/message_allocator.h,"@@ -22,31 +22,42 @@ namespace grpc { namespace experimental { -// This is per rpc struct for the allocator. We can potentially put the grpc-// call arena in here in the future.+// NOTE: This is an API for advanced users who need custom allocators.+// Per rpc struct for the allocator. This is the interface to return to user.+class RpcAllocatorState {+ public:+  virtual ~RpcAllocatorState() = default;+  // Optionally deallocate request early to reduce the size of working set.+  // A custom MessageAllocator needs to be registered to make use of this.+  // This is not abstract because implementing it is optional.+  virtual void FreeRequest() {}+};++// This is the interface returned by the allocator.+// grpc library will call the methods to get request/response pointers and to+// release the object when it is done. template <typename RequestT, typename ResponseT>-struct RpcAllocatorInfo {-  RequestT* request;-  ResponseT* response;-  // per rpc allocator internal state. MessageAllocator can set it when-  // AllocateMessages is called and use it later.-  void* allocator_state;+class MessageHolder : public RpcAllocatorState {+ public:+  virtual void Release() { delete this; }",Should have a strong comment then since self-deletion is a somewhat big deal,OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/19016,285237007,2019-05-17T18:19:35Z,include/grpcpp/impl/codegen/message_allocator.h,"@@ -22,31 +22,44 @@ namespace grpc { namespace experimental { -// This is per rpc struct for the allocator. We can potentially put the grpc-// call arena in here in the future.+// NOTE: This is an API for advanced users who need custom allocators.+// Per rpc struct for the allocator. This is the interface to return to user.+class RpcAllocatorState {+ public:+  virtual ~RpcAllocatorState() = default;+  // Optionally deallocate request early to reduce the size of working set.+  // A custom MessageAllocator needs to be registered to make use of this.+  // This is not abstract because implementing it is optional.+  virtual void FreeRequest() {}+};++// This is the interface returned by the allocator.+// grpc library will call the methods to get request/response pointers and to+// release the object when it is done. template <typename RequestT, typename ResponseT>-struct RpcAllocatorInfo {-  RequestT* request;-  ResponseT* response;-  // per rpc allocator internal state. MessageAllocator can set it when-  // AllocateMessages is called and use it later.-  void* allocator_state;+class MessageHolder : public RpcAllocatorState {+ public:+  virtual void Release() { delete this; }+  RequestT* request() { return request_; }+  ResponseT* response() { return response_; }+  void set_request(RequestT* request) { request_ = request; }+  void set_response(ResponseT* response) { response_ = response; }+",setters as protected since they are only going to be set by a derived class?,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19035,285238627,2019-05-17T18:24:00Z,test/cpp/client/client_channel_stress_test.cc,"@@ -289,10 +314,32 @@ class ClientChannelStressTest {           ""balancer"", server_host_, balancers_.back().get()));     }     // Start sending RPCs in multiple threads.-    CreateStub();-    for (size_t i = 0; i < kNumClientThreads; ++i) {-      client_threads_.emplace_back(-          std::thread(&ClientChannelStressTest::KeepSendingRequests, this));+    static const char* kServiceConfigs[] = {+        // No service config -- will use grpclb with no health checking.+        nullptr,+        // Use pick_first.+        ""{\""loadBalancingConfig\"":[{\""pick_first\"":{}}]}"",+        // Use round_robin with client-side health checking.+        ""{""+        ""  \""loadBalancingConfig\"":[{\""round_robin\"":{}}],""+        ""  \""healthCheckConfig\"": {\""serviceName\"": \""\""}""+        ""}"",+        // Same as pervious, but with a different (unhealthy) health+        // check service name.+        ""{""+        ""  \""loadBalancingConfig\"":[{\""round_robin\"":{}}],""+        ""  \""healthCheckConfig\"": {\""serviceName\"": \""unhealthy\""}""+        ""}"",+        };+    for (size_t j = 0; j < GPR_ARRAY_SIZE(kServiceConfigs); ++j) {+      std::unique_ptr<ClientHandle> client_handle =+          CreateClientHandle(kServiceConfigs[j]);+      for (size_t i = 0; i < kNumClientThreadsPerChannel; ++i) {+        client_threads_.emplace_back(+            std::thread(&ClientChannelStressTest::KeepSendingRequests, this,","I was not aware that taking a function's address is a deprecated thing.  Can you point me some documentation for this?I'm not sure that I see the readability argument here.  It seems like it's an extra level of indirection, and it's not obvious what that buys us.Also, doesn't the lambda actually incur the overhead of an additional function call, since we will need to first call the lambda and then it will need to call the original function?",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/19035,285243037,2019-05-17T18:36:34Z,test/cpp/client/client_channel_stress_test.cc,"@@ -289,10 +314,32 @@ class ClientChannelStressTest {           ""balancer"", server_host_, balancers_.back().get()));     }     // Start sending RPCs in multiple threads.-    CreateStub();-    for (size_t i = 0; i < kNumClientThreads; ++i) {-      client_threads_.emplace_back(-          std::thread(&ClientChannelStressTest::KeepSendingRequests, this));+    static const char* kServiceConfigs[] = {+        // No service config -- will use grpclb with no health checking.+        nullptr,+        // Use pick_first.+        ""{\""loadBalancingConfig\"":[{\""pick_first\"":{}}]}"",+        // Use round_robin with client-side health checking.+        ""{""+        ""  \""loadBalancingConfig\"":[{\""round_robin\"":{}}],""+        ""  \""healthCheckConfig\"": {\""serviceName\"": \""\""}""+        ""}"",+        // Same as pervious, but with a different (unhealthy) health+        // check service name.+        ""{""+        ""  \""loadBalancingConfig\"":[{\""round_robin\"":{}}],""+        ""  \""healthCheckConfig\"": {\""serviceName\"": \""unhealthy\""}""+        ""}"",+        };+    for (size_t j = 0; j < GPR_ARRAY_SIZE(kServiceConfigs); ++j) {+      std::unique_ptr<ClientHandle> client_handle =+          CreateClientHandle(kServiceConfigs[j]);+      for (size_t i = 0; i < kNumClientThreadsPerChannel; ++i) {+        client_threads_.emplace_back(+            std::thread(&ClientChannelStressTest::KeepSendingRequests, this,","So it's not deprecated. Our official guidance is [""Use lambda expressions where appropriate.""](https://google.github.io/styleguide/cppguide.html#Lambda_expressions)  (Thanks for the helpful tip, srsly). The ABSL API contract, OTOH, [forbids taking the address of APIs](https://abseil.io/about/compatibility) since  that prevents the addition of overloads in the future. That's a standard that I propose that we follow in our API. Now this is not that; it's an internal test code, so it's not really a strong need: it just requires you to manually interpret that this is a member function that is being called on the this pointer with the 3rd argument specified as the first argument, whereas the lambda lets you actually see it as a function call. I'm not going to sweat this, but I find the lambda use preferable.The lambda doesn't typically add a function call. This is because the lambda internals are understood by the compiler and can be inlined as a result. Once you pass something as a function pointer, that chance is gone.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19035,285250490,2019-05-17T18:57:57Z,test/cpp/client/client_channel_stress_test.cc,"@@ -289,10 +314,32 @@ class ClientChannelStressTest {           ""balancer"", server_host_, balancers_.back().get()));     }     // Start sending RPCs in multiple threads.-    CreateStub();-    for (size_t i = 0; i < kNumClientThreads; ++i) {-      client_threads_.emplace_back(-          std::thread(&ClientChannelStressTest::KeepSendingRequests, this));+    static const char* kServiceConfigs[] = {+        // No service config -- will use grpclb with no health checking.+        nullptr,+        // Use pick_first.+        ""{\""loadBalancingConfig\"":[{\""pick_first\"":{}}]}"",+        // Use round_robin with client-side health checking.+        ""{""+        ""  \""loadBalancingConfig\"":[{\""round_robin\"":{}}],""+        ""  \""healthCheckConfig\"": {\""serviceName\"": \""\""}""+        ""}"",+        // Same as pervious, but with a different (unhealthy) health+        // check service name.+        ""{""+        ""  \""loadBalancingConfig\"":[{\""round_robin\"":{}}],""+        ""  \""healthCheckConfig\"": {\""serviceName\"": \""unhealthy\""}""+        ""}"",+        };+    for (size_t j = 0; j < GPR_ARRAY_SIZE(kServiceConfigs); ++j) {+      std::unique_ptr<ClientHandle> client_handle =+          CreateClientHandle(kServiceConfigs[j]);+      for (size_t i = 0; i < kNumClientThreadsPerChannel; ++i) {+        client_threads_.emplace_back(+            std::thread(&ClientChannelStressTest::KeepSendingRequests, this,","I think you make a good argument for avoiding taking addresses when using a public API.  And I appreciate you pointing it out -- I'd heard that absl had that rule but somehow failed to extrapolate a more general rule for that.  I will definitely keep this in mind for the future.That having been said, it seems like this argument doesn't really apply for internal use, especially within the same class.  So I think this particular usage is fine as-is.",OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/19012,285271303,2019-05-17T20:05:08Z,src/core/ext/transport/chttp2/transport/hpack_encoder.cc,"@@ -488,27 +494,33 @@ static void hpack_enc(grpc_chttp2_hpack_compressor* c, grpc_mdelem elem,     return;   } -  uint32_t key_hash = grpc_slice_hash(GRPC_MDKEY(elem));   uint32_t elem_hash = 0;    if (elem_interned) {-    uint32_t value_hash = grpc_slice_hash(GRPC_MDVALUE(elem));-    elem_hash = GRPC_MDSTR_KV_HASH(key_hash, value_hash);+    if (GRPC_MDELEM_STORAGE(elem) == GRPC_MDELEM_STORAGE_INTERNED) {+      elem_hash =+          reinterpret_cast<grpc_core::InternedMetadata*>(GRPC_MDELEM_DATA(elem))+              ->hash();+    } else {+      elem_hash =+          reinterpret_cast<grpc_core::StaticMetadata*>(GRPC_MDELEM_DATA(elem))","Just to confirm my understanding: for StaticMetadata, we only reach this codepath for metadata whose static table indices are > GRPC_CHTTP2_LAST_STATIC_ENTRY, right?",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19018,285287393,2019-05-17T21:00:49Z,test/cpp/end2end/xds_end2end_test.cc,"@@ -1015,6 +1015,23 @@ TEST_F(SingleBalancerTest, FallbackEarlyWhenBalancerCallFails) {                  /* wait_for_ready */ false); } +TEST_F(SingleBalancerTest, FallbackIfResponseReceivedButChildNotReady) {+  const int kFallbackTimeoutMs = 500 * grpc_test_slowdown_factor();+  const int kServerlistDelayMs = 200 * grpc_test_slowdown_factor();+  ResetStub(kFallbackTimeoutMs);+  SetNextResolution({backends_[0]->port_}, kDefaultServiceConfig_.c_str());+  SetNextResolutionForLbChannelAllBalancers();+  // Send a serverlist that only contains an unreachable backend before fallback+  // timeout.+  ScheduleResponseForBalancer(0,+                              BalancerServiceImpl::BuildResponseForBackends(+                                  {grpc_pick_unused_port_or_die()}, {}),+                              kServerlistDelayMs);","Might as well use 0 here, since we only care about what happens after this serverlist is received.",
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19012,285290739,2019-05-17T21:13:31Z,src/core/ext/transport/chttp2/transport/hpack_encoder.cc,"@@ -488,27 +494,33 @@ static void hpack_enc(grpc_chttp2_hpack_compressor* c, grpc_mdelem elem,     return;   } -  uint32_t key_hash = grpc_slice_hash(GRPC_MDKEY(elem));   uint32_t elem_hash = 0;    if (elem_interned) {-    uint32_t value_hash = grpc_slice_hash(GRPC_MDVALUE(elem));-    elem_hash = GRPC_MDSTR_KV_HASH(key_hash, value_hash);+    if (GRPC_MDELEM_STORAGE(elem) == GRPC_MDELEM_STORAGE_INTERNED) {+      elem_hash =+          reinterpret_cast<grpc_core::InternedMetadata*>(GRPC_MDELEM_DATA(elem))+              ->hash();+    } else {+      elem_hash =+          reinterpret_cast<grpc_core::StaticMetadata*>(GRPC_MDELEM_DATA(elem))","We reach lines 505-506 (StaticMetadata reinterpret_cast) if:1) GRPC_MDELEM_IS_INTERNED(elem) && GRPC_MDELEM_STORAGE(elem) != GRPC_MDELEM_STORAGE_INTERNED.That means the MD storage is set explicitly to GRPC_MDELEM_STORAGE_STATIC.Now, this codepath exists in hpack_enc(), called in three places. In the first case, within deadline_enc(), the mdelem is explicitly not static - so this codepath is never reached. Otherwise, hpack_enc() is explicitly called when the index is *not* static: (static_index = grpc_chttp2_get_static_hpack_table_index(l->md)   == false) so we reach here because the md was static but the index was not <= GRPC_CHTTP2_LAST_STATIC_ENTRY. So in all instances we reach the code, it is indeed as you have said.",OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/19031,285297771,2019-05-17T21:43:19Z,src/core/lib/transport/metadata.h,"@@ -321,24 +294,35 @@ inline grpc_mdelem grpc_mdelem_ref(grpc_mdelem gmd) {  #ifndef NDEBUG #define GRPC_MDELEM_UNREF(s) grpc_mdelem_unref((s), __FILE__, __LINE__)-void grpc_mdelem_do_unref(grpc_mdelem gmd, const char* file, int line);+void grpc_mdelem_finalize_unref(grpc_mdelem_data_storage storage, void* ptr,+                                uint32_t hash, const char* file, int line); inline void grpc_mdelem_unref(grpc_mdelem gmd, const char* file, int line) { #else #define GRPC_MDELEM_UNREF(s) grpc_mdelem_unref((s))-void grpc_mdelem_do_unref(grpc_mdelem gmd);+void grpc_mdelem_finalize_unref(grpc_mdelem_data_storage storage, void* ptr,+                                uint32_t hash); inline void grpc_mdelem_unref(grpc_mdelem gmd) { #endif-  switch (GRPC_MDELEM_STORAGE(gmd)) {+  const grpc_mdelem_data_storage storage = GRPC_MDELEM_STORAGE(gmd);+  switch (storage) {     case GRPC_MDELEM_STORAGE_EXTERNAL:     case GRPC_MDELEM_STORAGE_STATIC:       return;     case GRPC_MDELEM_STORAGE_INTERNED:     case GRPC_MDELEM_STORAGE_ALLOCATED:+      auto* md =+          reinterpret_cast<grpc_core::RefcountedMdBase*> GRPC_MDELEM_DATA(gmd);+      /* once the refcount hits zero, some other thread can come along and+         free an interned md at any time: it's unsafe from this point on to+         access it so we read the hash now. */+      uint32_t hash = md->hash();+      if (GPR_UNLIKELY(md->Unref())) {",Why is it unlikely for md->Unref() to return true? Is that because it's common to have multiple references to some metadata?,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18813,285297935,2019-05-17T21:44:05Z,src/core/lib/surface/completion_queue.cc,"@@ -821,15 +817,19 @@ static void cq_end_op_for_pluck(grpc_completion_queue* cq, void* tag,   GRPC_ERROR_UNREF(error); } +static void functor_callback(void* arg, grpc_error* error) {+  auto* functor = static_cast<grpc_experimental_completion_queue_functor*>(arg);+  functor->functor_run(functor, error == GRPC_ERROR_NONE);+}+ /* Complete an event on a completion queue of type GRPC_CQ_CALLBACK */ static void cq_end_op_for_callback(     grpc_completion_queue* cq, void* tag, grpc_error* error,     void (*done)(void* done_arg, grpc_cq_completion* storage), void* done_arg,-    grpc_cq_completion* storage) {+    grpc_cq_completion* storage, bool internal) {","I think I may have completely mislead you on the internal thing. The thing is that the CQ tag for incoming server calls will actually call out to user code (the user method handler), so even the internal things are actually external.  I would have said that they are also initiated by the library and not under a lock, but we can envision a particularly insidious example using an in-process transport where both sides of the RPC share the same lock and that the server method handler grabs the lock as part of its work and then initiates a client RPC. Does removing the internal option destroy performance?",
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19031,285303025,2019-05-17T22:07:40Z,src/core/lib/transport/metadata.h,"@@ -85,12 +85,12 @@ typedef enum {   GRPC_MDELEM_STORAGE_EXTERNAL = 0,   /* memory pointed to by grpc_mdelem::payload is interned by the metadata      system */-  GRPC_MDELEM_STORAGE_INTERNED = GRPC_MDELEM_STORAGE_INTERNED_BIT,+  GRPC_MDELEM_STORAGE_STATIC = GRPC_MDELEM_STORAGE_INTERNED_BIT,",This was intentional - it's for slightly better code generation for the switch() cases. No tests fail since the semantics of the enum have not changed; all we want is for GRPC_MDELEM_STORAGE_STATIC and GRPC_MDELEM_STORAGE_INTERNED to be different values which nonetheless have GRPC_MDELEM_STORAGE_INTERNED_BIT set; and flipping the order does not change any of the expectations.In other words: there is nothing to test here since we didn't change anything in the high level semantics; only we improved slightly the resulting code generation.,OK
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19031,285303635,2019-05-17T22:11:00Z,src/core/lib/transport/metadata.h,"@@ -321,24 +294,35 @@ inline grpc_mdelem grpc_mdelem_ref(grpc_mdelem gmd) {  #ifndef NDEBUG #define GRPC_MDELEM_UNREF(s) grpc_mdelem_unref((s), __FILE__, __LINE__)-void grpc_mdelem_do_unref(grpc_mdelem gmd, const char* file, int line);+void grpc_mdelem_finalize_unref(grpc_mdelem_data_storage storage, void* ptr,+                                uint32_t hash, const char* file, int line); inline void grpc_mdelem_unref(grpc_mdelem gmd, const char* file, int line) { #else #define GRPC_MDELEM_UNREF(s) grpc_mdelem_unref((s))-void grpc_mdelem_do_unref(grpc_mdelem gmd);+void grpc_mdelem_finalize_unref(grpc_mdelem_data_storage storage, void* ptr,+                                uint32_t hash); inline void grpc_mdelem_unref(grpc_mdelem gmd) { #endif-  switch (GRPC_MDELEM_STORAGE(gmd)) {+  const grpc_mdelem_data_storage storage = GRPC_MDELEM_STORAGE(gmd);+  switch (storage) {     case GRPC_MDELEM_STORAGE_EXTERNAL:     case GRPC_MDELEM_STORAGE_STATIC:       return;     case GRPC_MDELEM_STORAGE_INTERNED:     case GRPC_MDELEM_STORAGE_ALLOCATED:+      auto* md =+          reinterpret_cast<grpc_core::RefcountedMdBase*> GRPC_MDELEM_DATA(gmd);+      /* once the refcount hits zero, some other thread can come along and+         free an interned md at any time: it's unsafe from this point on to+         access it so we read the hash now. */+      uint32_t hash = md->hash();+      if (GPR_UNLIKELY(md->Unref())) {","Unref() return true if the last ref was dropped, and metadata can be referenced by different filters or users (e.g. http_client_filter, http_server_filter, the hpack_encoder and parser, various bits of the security code...)Most unrefs will return false; only one returns true, and so it is Unlikely for the Unref() to trigger the final cleanup.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/19035,285325265,2019-05-18T02:05:23Z,src/core/ext/filters/client_channel/subchannel.cc,"@@ -503,20 +504,22 @@ class Subchannel::HealthWatcherMap::HealthWatcher         health_check_service_name_.get(), subchannel_->connected_subchannel_,         subchannel_->pollset_set_, subchannel_->channelz_node_);     Ref().release();  // Ref for health callback tracked manually.-    health_check_client_->NotifyOnHealthChange(&state_, &on_health_changed_);+    health_check_client_->NotifyOnHealthChange(&pending_state_,+                                               &on_health_changed_);   }    static void OnHealthChanged(void* arg, grpc_error* error) {     auto* self = static_cast<HealthWatcher*>(arg);     Subchannel* c = self->subchannel_;     {       MutexLock lock(&c->mu_);+      self->state_ = self->pending_state_;","It looks like this code that reads pending_state_ holds the subchannel lock while the other one that writes the same data is under the health-check-client's lock (SetHealthStatus). As a result, there's no ordering between them and will still have a TSAN issue.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18813,285703824,2019-05-20T17:53:28Z,test/core/surface/completion_queue_test.cc,"@@ -365,18 +366,31 @@ static void test_callback(void) {       GRPC_CQ_DEFAULT_POLLING, GRPC_CQ_NON_LISTENING, GRPC_CQ_NON_POLLING};   grpc_completion_queue_attributes attr;   unsigned i;+  static gpr_mu mu, shutdown_mu;+  static gpr_cv cv, shutdown_cv;+  static int cb_counter;+  gpr_mu_init(&mu);+  gpr_mu_init(&shutdown_mu);+  gpr_cv_init(&cv);+  gpr_cv_init(&shutdown_cv);    LOG_TEST(""test_callback""); +  gpr_mu_lock(&shutdown_mu);   bool got_shutdown = false;+  gpr_mu_unlock(&shutdown_mu);","Are the locks around this initialization of shutdown_mu really needed? There's a happens-before relationship between later uses through the RPC call and executor enqueueing, correct? Generally speaking, locks around an initialization or in  a destructor are a code smell that something else is wrong.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/19021,286247221,2019-05-21T22:19:57Z,include/grpcpp/support/channel_arguments_impl.h,"@@ -31,6 +31,15 @@ namespace grpc { namespace testing { class ChannelArgumentsTest; }  // namespace testing++namespace experimental {+/// Validates \a service_config_json. If valid, returns an empty string.+/// Otherwise, returns the validation error.+/// TODO(yashykt): Promote it to out of experimental once it is proved useful+/// and gRFC is accepted.+grpc::string ValidateServiceConfigJSON(const grpc::string& service_config_json);","This only gets fed to a ChannelArguments method, correct? It seems like it should better be a static method of that class rather than a free function then.",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/19101,286616477,2019-05-22T18:02:29Z,src/core/lib/surface/validate_metadata.h,"@@ -24,7 +24,18 @@ #include <grpc/slice.h> #include ""src/core/lib/iomgr/error.h"" -grpc_error* grpc_validate_header_key_is_legal(grpc_slice slice);-grpc_error* grpc_validate_header_nonbin_value_is_legal(grpc_slice slice);+grpc_error* grpc_validate_header_key_is_legal(const grpc_slice& slice);+grpc_error* grpc_validate_header_nonbin_value_is_legal(const grpc_slice& slice);++int grpc_is_binary_header_internal(const grpc_slice& slice);",validate_metadata.h does not seem to be the right place for this,
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19101,286740906,2019-05-23T00:55:00Z,src/core/ext/transport/chttp2/transport/hpack_parser.cc,"@@ -1494,7 +1495,7 @@ static grpc_error* parse_key_string(grpc_chttp2_hpack_parser* p, /* check if a key represents a binary header or not */  static bool is_binary_literal_header(grpc_chttp2_hpack_parser* p) {-  return grpc_is_binary_header(+  return grpc_is_binary_header_refcounted(","Two cases: is_binary_literal_header, and is_binary_indexed_header.In the indexed case: elem is a result of grpc_chttp2_hptbl_lookup. That means either elem was in the static entries (which have a refcount) or they were added via grpc_chttp2_hptbl_add, which is only performed if the elem was static or intern specified storage - in both cases, the key has a refcount.In the literal case: either we look at the output of slice_from_static_buffer (has a refcount) or p->key.data.referenced. p->key.data.referenced is either the output of grpc_empty_slice() (NULL refcount!) or it has a refcount set in begin_parse_string(). The act of setting that refcount determines which of the two actions we take; if we set the refcount, we use p->key.data.referenced, which is guaranteed to have a non-null refcount. If we do not set the refcount (in which case, sure, p->key.data.referenced could be grpc_empty_slice()) then we do not read it anyways. So in either case the refcount is set.So in both places it is refcounted.",OK
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19101,286740972,2019-05-23T00:55:30Z,src/core/lib/surface/validate_metadata.h,"@@ -24,7 +24,18 @@ #include <grpc/slice.h> #include ""src/core/lib/iomgr/error.h"" -grpc_error* grpc_validate_header_key_is_legal(grpc_slice slice);-grpc_error* grpc_validate_header_nonbin_value_is_legal(grpc_slice slice);+grpc_error* grpc_validate_header_key_is_legal(const grpc_slice& slice);+grpc_error* grpc_validate_header_nonbin_value_is_legal(const grpc_slice& slice);++int grpc_is_binary_header_internal(const grpc_slice& slice);",Where would you recommend? The validate_metadata.cc file has the concrete implementations.,
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/19101,287078949,2019-05-23T18:33:24Z,src/core/lib/surface/call.cc,"@@ -99,8 +99,14 @@ struct batch_control {   } completion_data;   grpc_closure start_batch;   grpc_closure finish_batch;-  gpr_refcount steps_to_complete;+  grpc_core::Atomic<uintptr_t> steps_to_complete;",Does this belong in a separate PR as well?,
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19101,287118731,2019-05-23T20:21:48Z,src/core/ext/transport/chttp2/transport/hpack_parser.cc,"@@ -1494,7 +1495,7 @@ static grpc_error* parse_key_string(grpc_chttp2_hpack_parser* p, /* check if a key represents a binary header or not */  static bool is_binary_literal_header(grpc_chttp2_hpack_parser* p) {-  return grpc_is_binary_header(+  return grpc_is_binary_header_refcounted(","Ack on adding the comment and renaming the method -  will do both shortly.Re: the implementation: for the indexed case I believe that it will be always be refcounted - assuming we're indexing in the first place for cheaper slice operations I think it will be unlikely that externally allocated or inlined slices would make it into an index table.For the literal case: right now the parser implementation dictates that it's always a refcounted slice. I think that in this case, maybe it could change in the future; that said, if it ever did, I think having a debug assert in our fastpath method would make it very obvious that our prior assumptions no longer held.At that point, it would be easy enough to change it back to the more general method that can take either kind. I don't think it's fragile in the sense that if we ever changed it to break, we'd immediately catch the break - so it's not like we'd be introducing a heisenbug.",OK
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19101,287119191,2019-05-23T20:23:04Z,src/core/ext/transport/chttp2/transport/hpack_encoder.cc,"@@ -323,9 +324,13 @@ typedef struct {   bool insert_null_before_wire_value; } wire_value; +template <bool mdkey_definitely_interned>","Mostly to avoid typing up two almost identical methods. If we kept it as a single method that takes mdkey_definitely_interned as a parameter, we introduce an unnecessary branch.",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/18919,287429434,2019-05-24T16:20:08Z,src/objective-c/tests/Tests.xcodeproj/xcshareddata/xcschemes/InteropTests.xcscheme,"@@ -69,9 +60,9 @@       <MacroExpansion>          <BuildableReference             BuildableIdentifier = ""primary""-            BlueprintIdentifier = ""63DC84331BE15294000708E8""-            BuildableName = ""InteropTestsLocalSSL.xctest""-            BlueprintName = ""InteropTestsLocalSSL""+            BlueprintIdentifier = ""5EA476F32272816A000F72FC""+            BuildableName = ""InteropTests.xctest""+            BlueprintName = ""InteropTests""","Yes, they will be built with Cronet, but not necessarily use Cronet. Some V2API tests do test the behavior of parallel CFStream and Cronet calls.",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/18919,287430813,2019-05-24T16:24:10Z,src/objective-c/tests/CronetTests/CronetUnitTests.mm,"@@ -37,10 +39,10 @@ #import ""test/core/end2end/data/ssl_test_data.h"" #import ""test/core/util/test_config.h"" +#define GRPC_SHADOW_BORINGSSL_SYMBOLS","This test's target is some core functions and invokes BoringSSL. BoringSSL-GRPC already shadows all symbols. So to call those functions, we need to shadow invokes to BoringSSL functions in this file too.In core, all files are compiled with `GRPC_SHADOW_BORINGSSL_SYMBOLS` flag (https://github.com/grpc/grpc/blob/master/gRPC-Core.podspec#L188). ",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/19129,287441069,2019-05-24T16:55:17Z,src/core/lib/surface/call.cc,"@@ -99,8 +99,14 @@ struct batch_control {   } completion_data;   grpc_closure start_batch;   grpc_closure finish_batch;-  gpr_refcount steps_to_complete;+  grpc_core::Atomic<uintptr_t> steps_to_complete;",Why not use the RefCount class in src/core/lib/gprpp/ref_counted.h?https://github.com/grpc/grpc/blob/f4ce5fc2510c342adc86afa41a9354d9956a9092/src/core/lib/gprpp/ref_counted.h#L73,
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/19012,287477370,2019-05-24T18:46:52Z,src/core/lib/transport/metadata.h,"@@ -227,8 +254,8 @@ class InternedMetadata {   grpc_slice value_;    /* private only data */-  grpc_core::Atomic<intptr_t> refcnt_;   uint32_t hash_;+  grpc_core::Atomic<intptr_t> refcnt_;",Note that we have Refcount class available,OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/18852,287539764,2019-05-24T23:43:31Z,src/objective-c/GRPCClient/private/GRPCCall+V2API.h,"@@ -0,0 +1,36 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++@interface GRPCCall (V2API)","I'm a bit confused by the naming. Isn't `GRPCCall` V1 API, not V2?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19125,288150225,2019-05-28T14:58:00Z,src/core/lib/surface/server.cc,"@@ -1166,6 +1166,7 @@ void grpc_server_setup_transport(   chand->server = s;   server_ref(s);   chand->channel = channel;+  chand->socket_node.release();",Similar issue here.  It would probably be cleaner to give `channel_data` its own ctor and then change `init_channel_elem()` to use placement-new to initialize it.,OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/18852,288232914,2019-05-28T18:04:42Z,src/objective-c/GRPCClient/private/GRPCCallInternal.m,"@@ -0,0 +1,342 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#import ""GRPCCallInternal.h""++#import <GRPCClient/GRPCCall.h>+#import <RxLibrary/GRXBufferedPipe.h>++#import ""GRPCCall+V2API.h""++@implementation GRPCCall2Internal {+  /** Request for the call. */+  GRPCRequestOptions *_requestOptions;+  /** Options for the call. */+  GRPCCallOptions *_callOptions;+  /** The handler of responses. */+  id<GRPCResponseHandler> _handler;++  /**+   * Make use of legacy GRPCCall to make calls. Nullified when call is finished.+   */+  GRPCCall *_call;+  /** Flags whether initial metadata has been published to response handler. */+  BOOL _initialMetadataPublished;+  /** Streaming call writeable to the underlying call. */+  GRXBufferedPipe *_pipe;+  /** Serial dispatch queue for tasks inside the call. */+  dispatch_queue_t _dispatchQueue;+  /** Flags whether call has started. */+  BOOL _started;+  /** Flags whether call has been canceled. */+  BOOL _canceled;+  /** Flags whether call has been finished. */+  BOOL _finished;+  /** The number of pending messages receiving requests. */+  NSUInteger _pendingReceiveNextMessages;+}++- (instancetype)init {+  if ((self = [super init])) {+  // Set queue QoS only when iOS version is 8.0 or above and Xcode version is 9.0 or above+#if __IPHONE_OS_VERSION_MAX_ALLOWED >= 110000 || __MAC_OS_X_VERSION_MAX_ALLOWED >= 101300+    if (@available(iOS 8.0, macOS 10.10, *)) {+      _dispatchQueue = dispatch_queue_create(+          NULL,+          dispatch_queue_attr_make_with_qos_class(DISPATCH_QUEUE_SERIAL, QOS_CLASS_DEFAULT, 0));+    } else {+#else+    {+#endif+      _dispatchQueue = dispatch_queue_create(NULL, DISPATCH_QUEUE_SERIAL);+    }+    _pipe = [GRXBufferedPipe pipe];+  }+  return self;+}++- (void)setResponseHandler:(id<GRPCResponseHandler>)responseHandler {+  @synchronized(self) {+    NSAssert(!_started, @""Call already started."");+    if (_started) {+      return;+    }+    _handler = responseHandler;+    _initialMetadataPublished = NO;+    _started = NO;+    _canceled = NO;+    _finished = NO;+  }+}++- (dispatch_queue_t)requestDispatchQueue {+  return _dispatchQueue;+}++- (void)startWithRequestOptions:(GRPCRequestOptions *)requestOptions+                    callOptions:(GRPCCallOptions *)callOptions {+  NSAssert(requestOptions.host.length != 0 && requestOptions.path.length != 0,+           @""Neither host nor path can be nil."");+  NSAssert(requestOptions.safety <= GRPCCallSafetyCacheableRequest, @""Invalid call safety value."");+  if (requestOptions.host.length == 0 || requestOptions.path.length == 0) {+    NSLog(@""Invalid host and path."");+    return;+  }+  if (requestOptions.safety > GRPCCallSafetyCacheableRequest) {+    NSLog(@""Invalid call safety."");+    return;+  }++  @synchronized(self) {+    NSAssert(_handler != nil, @""Response handler required."");+    if (_handler == nil) {+      NSLog(@""Invalid response handler."");+      return;+    }+    _requestOptions = requestOptions;+    if (callOptions == nil) {+      _callOptions = [[GRPCCallOptions alloc] init];+    } else {+      _callOptions = [callOptions copy];+    }+  }++  [self start];+}++- (void)start {+  GRPCCall *copiedCall = nil;+  @synchronized(self) {+    NSAssert(!_started, @""Call already started."");+    NSAssert(!_canceled, @""Call already canceled."");+    if (_started) {+      return;+    }+    if (_canceled) {+      return;+    }++    _started = YES;++    _call = [[GRPCCall alloc] initWithHost:_requestOptions.host+                                      path:_requestOptions.path+                                callSafety:_requestOptions.safety+                            requestsWriter:_pipe+                               callOptions:_callOptions+                                 writeDone:^{+                                   @synchronized(self) {+                                     if (self->_handler) {+                                       [self issueDidWriteData];+                                     }+                                   }+                                 }];+    [_call setResponseDispatchQueue:_dispatchQueue];+    if (_callOptions.initialMetadata) {+      [_call.requestHeaders addEntriesFromDictionary:_callOptions.initialMetadata];+    }+    if (_pendingReceiveNextMessages > 0) {+      [_call receiveNextMessages:_pendingReceiveNextMessages];+      _pendingReceiveNextMessages = 0;+    }+    copiedCall = _call;+  }++  void (^valueHandler)(id value) = ^(id value) {+    @synchronized(self) {+      if (self->_handler) {+        if (!self->_initialMetadataPublished) {+          self->_initialMetadataPublished = YES;+          [self issueInitialMetadata:self->_call.responseHeaders];+        }+        if (value) {+          [self issueMessage:value];+        }+      }+    }+  };+  void (^completionHandler)(NSError *errorOrNil) = ^(NSError *errorOrNil) {+    @synchronized(self) {+      if (self->_handler) {+        if (!self->_initialMetadataPublished) {+          self->_initialMetadataPublished = YES;+          [self issueInitialMetadata:self->_call.responseHeaders];+        }+        [self issueClosedWithTrailingMetadata:self->_call.responseTrailers error:errorOrNil];+      }+      // Clearing _call must happen *after* dispatching close in order to get trailing+      // metadata from _call.+      if (self->_call) {+        // Clean up the request writers. This should have no effect to _call since its+        // response writeable is already nullified.+        [self->_pipe writesFinishedWithError:nil];+        self->_call = nil;+        self->_pipe = nil;+      }+    }+  };+  id<GRXWriteable> responseWriteable =+      [[GRXWriteable alloc] initWithValueHandler:valueHandler completionHandler:completionHandler];+  [copiedCall startWithWriteable:responseWriteable];+}++- (void)cancel {+  GRPCCall *copiedCall = nil;+  @synchronized(self) {+    if (_canceled) {+      return;+    }++    _canceled = YES;++    copiedCall = _call;+    _call = nil;+    _pipe = nil;++    if ([_handler respondsToSelector:@selector(didCloseWithTrailingMetadata:error:)]) {+      id<GRPCResponseHandler> copiedHandler = _handler;+      _handler = nil;+      dispatch_async(copiedHandler.dispatchQueue, ^{+        [copiedHandler didCloseWithTrailingMetadata:nil+                                              error:[NSError errorWithDomain:kGRPCErrorDomain+                                                                        code:GRPCErrorCodeCancelled+                                                                    userInfo:@{+                                                                      NSLocalizedDescriptionKey :+                                                                          @""Canceled by app""+                                                                    }]];+      });+    } else {+      _handler = nil;+    }+  }+  [copiedCall cancel];+}++- (void)writeData:(id)data {+  GRXBufferedPipe *copiedPipe = nil;+  @synchronized(self) {+    NSAssert(!_canceled, @""Call already canceled."");+    NSAssert(!_finished, @""Call is half-closed before sending data."");+    if (_canceled) {+      return;+    }+    if (_finished) {+      return;+    }++    if (_pipe) {+      copiedPipe = _pipe;+    }+  }+  [copiedPipe writeValue:data];+}++- (void)finish {+  GRXBufferedPipe *copiedPipe = nil;+  @synchronized(self) {+    NSAssert(_started, @""Call not started."");+    NSAssert(!_canceled, @""Call already canceled."");+    NSAssert(!_finished, @""Call already half-closed."");+    if (!_started) {+      return;+    }+    if (_canceled) {+      return;+    }+    if (_finished) {+      return;+    }++    if (_pipe) {+      copiedPipe = _pipe;+      _pipe = nil;+    }+    _finished = YES;+  }+  [copiedPipe writesFinishedWithError:nil];+}++- (void)issueInitialMetadata:(NSDictionary *)initialMetadata {+  @synchronized(self) {+    if (initialMetadata != nil &&+        [_handler respondsToSelector:@selector(didReceiveInitialMetadata:)]) {+      id<GRPCResponseHandler> copiedHandler = _handler;+      dispatch_async(_handler.dispatchQueue, ^{+        [copiedHandler didReceiveInitialMetadata:initialMetadata];+      });+    }+  }+}++- (void)issueMessage:(id)message {+  @synchronized(self) {+    if (message != nil) {+      if ([_handler respondsToSelector:@selector(didReceiveData:)]) {+        id<GRPCResponseHandler> copiedHandler = _handler;+        dispatch_async(_handler.dispatchQueue, ^{+          [copiedHandler didReceiveData:message];+        });+      } else if ([_handler respondsToSelector:@selector(didReceiveRawMessage:)]) {+        id<GRPCResponseHandler> copiedHandler = _handler;+        dispatch_async(_handler.dispatchQueue, ^{+          [copiedHandler didReceiveRawMessage:message];+        });+      }+    }+  }+}++- (void)issueClosedWithTrailingMetadata:(NSDictionary *)trailingMetadata error:(NSError *)error {+  @synchronized(self) {+    if ([_handler respondsToSelector:@selector(didCloseWithTrailingMetadata:error:)]) {+      id<GRPCResponseHandler> copiedHandler = _handler;+      // Clean up _handler so that no more responses are reported to the handler.+      _handler = nil;+      dispatch_async(copiedHandler.dispatchQueue, ^{+        [copiedHandler didCloseWithTrailingMetadata:trailingMetadata error:error];+      });+    } else {+      _handler = nil;+    }+  }+}++- (void)issueDidWriteData {+  @synchronized(self) {+    if (_callOptions.flowControlEnabled && [_handler respondsToSelector:@selector(didWriteData)]) {+      id<GRPCResponseHandler> copiedHandler = _handler;","If I understand correctly, we're copying the handler to handle the race where the handler is set to `nil` by `issueClosedWithTrailingMetadata` or `cancel` called from another thread. Is is possible that `_handler==nil` when we enter this function, so `copiedHandler.dispatchQueue` results in a nullptr dereference?",
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/18852,288248680,2019-05-28T18:42:45Z,src/objective-c/GRPCClient/GRPCInterceptor.h,"@@ -0,0 +1,269 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++/**+ * API for interceptors implementation. This feature is currently EXPERIMENTAL and is subject to+ * breaking changes without prior notice.+ *+ * The interceptors in the gRPC system forms a chain. When a call is made by the user, each+ * interceptor on the chain has chances to react to events of the call and make necessary+ * modifications to the call's parameters, data, metadata, or flow.+ *+ *+ *                                   -----------+ *                                  | GRPCCall2 |+ *                                   -----------+ *                                        |+ *                                        |+ *                           --------------------------+ *                          | GRPCInterceptorManager 1 |+ *                           --------------------------+ *                          | GRPCInterceptor 1        |+ *                           --------------------------+ *                                        |+ *                                       ...+ *                                        |+ *                           --------------------------+ *                          | GRPCInterceptorManager N |+ *                           --------------------------+ *                          | GRPCInterceptor N        |+ *                           --------------------------+ *                                        |+ *                                        |+ *                               ------------------+ *                              | GRPCCallInternal |+ *                               ------------------+ *+ * The chain of interceptors is initialized when the corresponding GRPCCall2 object or proto call+ * object (GRPCUnaryProtoCall and GRPCStreamingProtoCall) is initialized. The initialization of the+ * chain is controlled by the property interceptorFactories in the callOptions parameter of the+ * corresponding call object. Property interceptorFactories is an array of+ * id<GRPCInterceptorFactory> objects provided by the user. When a call object is initialized, each+ * interceptor factory generates an interceptor object for the call. gRPC internally links the+ * interceptors with each other and with the actual call object. The order of the interceptors in+ * the chain is exactly the same as the order of factory objects in interceptorFactories property.+ * All requests (start, write, finish, cancel, receive next) initiated by the user will be processed+ * in the order of interceptors, and all responses (initial metadata, data, trailing metadata, write+ * data done) are processed in the reverse order.+ *+ * Each interceptor in the interceptor chain should behave as a user of the next interceptor, and at+ * the same time behave as a call to the previous interceptor. Therefore interceptor implementations+ * must follow the state transition of gRPC calls and must also forward events that are consistent+ * with the current state of the next/previous interceptor. They should also make sure that the+ * events they forwarded to the next and previous interceptors will, in the end, make the neighbour+ * interceptor terminate correctly and reaches ""finished"" state. The diagram below shows the state+ * transitions. Any event not appearing on the diagram means the event is not permitted for that+ * particular state.+ *+ *                                      writeData+ *                                  receiveNextMessages+ *                               didReceiveInitialMetadata+ *                                    didReceiveData+ *                                     didWriteData+ *           writeData  -----             -----                 ----  didReceiveInitialMetadata+ * receiveNextMessages |     |           |     |               |    | didReceiveData+ *                     |     V           |     V               |    V didWriteData+ *               -------------  start   ---------   finish    ------------+ *              | initialized | -----> | started | --------> | half-close |+ *               -------------          ---------             ------------+ *                     |                     |                      |+ *                     |                     | didClose             | didClose+ *                     |cancel               | cancel               | cancel+ *                     |                     V                      |+ *                     |                 ----------                 |+ *                      --------------> | finished | <--------------+ *                                       ----------+ *                                        |      ^ writeData+ *                                        |      | finish+ *                                         ------  cancel+ *                                                 receiveNextMessages+ *+ * Events of requests and responses are dispatched to interceptor objects using the interceptor's+ * dispatch queue. The dispatch queue should be serial queue to make sure the events are processed","Can we ensure that the interceptor's dispatch queue is serial? According to https://stackoverflow.com/a/14431197/3126412, we can guarantee serial execution using `dispatch_set_target_queue`. Maybe we should consider something along those lines to protect ourselves from API misuse resulting in hard to debug issues.",OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/18852,288252749,2019-05-28T18:53:17Z,src/objective-c/examples/InterceptorSample/InterceptorSample/CacheInterceptor.m,"@@ -0,0 +1,303 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#import ""CacheInterceptor.h""++@implementation RequestCacheEntry {+ @protected+  NSString *_path;+  id<NSObject> _message;+}++@synthesize path = _path;+@synthesize message = _message;++- (instancetype)initWithPath:(NSString *)path message:(id)message {+  if ((self = [super init])) {+    _path = [path copy];+    _message = [message copy];+  }+  return self;+}++- (id)copyWithZone:(NSZone *)zone {+  return [[RequestCacheEntry allocWithZone:zone] initWithPath:_path message:_message];+}++- (BOOL)isEqual:(id)object {+  if ([self class] != [object class]) return NO;+  RequestCacheEntry *rhs = (RequestCacheEntry *)object;+  return ([_path isEqualToString:rhs.path] && [_message isEqual:rhs.message]);+}++- (NSUInteger)hash {+  return _path.hash ^ _message.hash;+}++@end++@implementation MutableRequestCacheEntry++@dynamic path;+@dynamic message;++- (void)setPath:(NSString *)path {+  _path = [path copy];+}++- (void)setMessage:(id)message {+  _message = [message copy];+}++@end++@implementation ResponseCacheEntry {+ @protected+  NSDate *_deadline;+  NSDictionary *_headers;+  id _message;+  NSDictionary *_trailers;+}++@synthesize deadline = _deadline;+@synthesize headers = _headers;+@synthesize message = _message;+@synthesize trailers = _trailers;++- (instancetype)initWithDeadline:(NSDate *)deadline+                         headers:(NSDictionary *)headers+                         message:(id)message+                        trailers:(NSDictionary *)trailers {+  if (([super init])) {+    _deadline = [deadline copy];+    _headers = [[NSDictionary alloc] initWithDictionary:headers copyItems:YES];+    _message = [message copy];+    _trailers = [[NSDictionary alloc] initWithDictionary:trailers copyItems:YES];+  }+  return self;+}++- (id)copyWithZone:(NSZone *)zone {+  return [[ResponseCacheEntry allocWithZone:zone] initWithDeadline:_deadline+                                                           headers:_headers+                                                           message:_message+                                                          trailers:_trailers];+}++@end++@implementation MutableResponseCacheEntry++@dynamic deadline;+@dynamic headers;+@dynamic message;+@dynamic trailers;++- (void)setDeadline:(NSDate *)deadline {+  _deadline = [deadline copy];+}++- (void)setHeaders:(NSDictionary *)headers {+  _headers = [[NSDictionary alloc] initWithDictionary:headers copyItems:YES];+}++- (void)setMessage:(id)message {+  _message = [message copy];+}++- (void)setTrailers:(NSDictionary *)trailers {+  _trailers = [[NSDictionary alloc] initWithDictionary:trailers copyItems:YES];+}++@end++@implementation CacheContext {+  NSCache<RequestCacheEntry *, ResponseCacheEntry *> *_cache;+}++- (instancetype)init {+  if ((self = [super init])) {+    _cache = [[NSCache alloc] init];+  }+  return self;+}++- (GRPCInterceptor *)createInterceptorWithManager:(GRPCInterceptorManager *)interceptorManager {+  return [[CacheInterceptor alloc] initWithInterceptorManager:interceptorManager cacheContext:self];+}++- (ResponseCacheEntry *)getCachedResponseForRequest:(RequestCacheEntry *)request {+  ResponseCacheEntry *response = nil;+  @synchronized(self) {+    response = [_cache objectForKey:request];+  }+  return response;+}++- (void)setCachedResponse:(ResponseCacheEntry *)response forRequest:(RequestCacheEntry *)request {+  @synchronized(self) {+    [_cache setObject:response forKey:request];+  }+}++@end++@implementation CacheInterceptor {+  GRPCInterceptorManager *_manager;+  CacheContext *_context;+  dispatch_queue_t _dispatchQueue;++  BOOL _cacheable;+  BOOL _messageSeen;+  GRPCCallOptions *_callOptions;+  GRPCRequestOptions *_requestOptions;+  id _requestMessage;+  MutableRequestCacheEntry *_request;+  MutableResponseCacheEntry *_response;+}++- (dispatch_queue_t)requestDispatchQueue {+  return _dispatchQueue;+}++- (dispatch_queue_t)dispatchQueue {+  return _dispatchQueue;+}++- (instancetype)initWithInterceptorManager:(GRPCInterceptorManager *_Nonnull)intercepterManager+                              cacheContext:(CacheContext *_Nonnull)cacheContext {+  if ((self = [super initWithInterceptorManager:intercepterManager+                           requestDispatchQueue:dispatch_get_main_queue()+                          responseDispatchQueue:dispatch_get_main_queue()])) {+    _manager = intercepterManager;+    _context = cacheContext;+    _dispatchQueue = dispatch_queue_create(NULL, DISPATCH_QUEUE_SERIAL);++    _cacheable = YES;+    _messageSeen = NO;+    _request = nil;+    _response = nil;+  }+  return self;+}++- (void)startWithRequestOptions:(GRPCRequestOptions *)requestOptions+                    callOptions:(GRPCCallOptions *)callOptions {+  NSLog(@""start"");+  if (requestOptions.safety != GRPCCallSafetyCacheableRequest) {+    NSLog(@""no cache"");+    _cacheable = NO;+    [_manager startNextInterceptorWithRequest:requestOptions callOptions:callOptions];+  } else {+    _requestOptions = [requestOptions copy];+    _callOptions = [callOptions copy];+  }+}++- (void)writeData:(id)data {+  NSLog(@""writeData"");+  if (!_cacheable) {+    [_manager writeNextInterceptorWithData:data];+  } else {+    NSAssert(!_messageSeen, @""CacheInterceptor does not support streaming call"");+    if (_messageSeen) {+      NSLog(@""CacheInterceptor does not support streaming call"");+    }+    _messageSeen = YES;+    _requestMessage = [data copy];+  }+}++- (void)finish {+  NSLog(@""finish"");+  if (!_cacheable) {+    [_manager finishNextInterceptor];+  } else {+    _request = [[MutableRequestCacheEntry alloc] init];+    _request.path = _requestOptions.path;+    _request.message = [_requestMessage copy];+    _response = [[_context getCachedResponseForRequest:_request] copy];+    NSLog(@""Read cache for %@"", _request);+    if (!_response) {+      [_manager startNextInterceptorWithRequest:_requestOptions callOptions:_callOptions];+      [_manager writeNextInterceptorWithData:_requestMessage];+      [_manager finishNextInterceptor];+    } else {",We need to check that deadline has not been exceeded.,OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/18852,288254005,2019-05-28T18:56:15Z,src/objective-c/examples/InterceptorSample/InterceptorSample/CacheInterceptor.m,"@@ -0,0 +1,303 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#import ""CacheInterceptor.h""++@implementation RequestCacheEntry {+ @protected+  NSString *_path;+  id<NSObject> _message;+}++@synthesize path = _path;+@synthesize message = _message;++- (instancetype)initWithPath:(NSString *)path message:(id)message {+  if ((self = [super init])) {+    _path = [path copy];+    _message = [message copy];+  }+  return self;+}++- (id)copyWithZone:(NSZone *)zone {+  return [[RequestCacheEntry allocWithZone:zone] initWithPath:_path message:_message];+}++- (BOOL)isEqual:(id)object {+  if ([self class] != [object class]) return NO;+  RequestCacheEntry *rhs = (RequestCacheEntry *)object;+  return ([_path isEqualToString:rhs.path] && [_message isEqual:rhs.message]);+}++- (NSUInteger)hash {+  return _path.hash ^ _message.hash;+}++@end++@implementation MutableRequestCacheEntry++@dynamic path;+@dynamic message;++- (void)setPath:(NSString *)path {+  _path = [path copy];+}++- (void)setMessage:(id)message {+  _message = [message copy];+}++@end++@implementation ResponseCacheEntry {+ @protected+  NSDate *_deadline;+  NSDictionary *_headers;+  id _message;+  NSDictionary *_trailers;+}++@synthesize deadline = _deadline;+@synthesize headers = _headers;+@synthesize message = _message;+@synthesize trailers = _trailers;++- (instancetype)initWithDeadline:(NSDate *)deadline+                         headers:(NSDictionary *)headers+                         message:(id)message+                        trailers:(NSDictionary *)trailers {+  if (([super init])) {+    _deadline = [deadline copy];+    _headers = [[NSDictionary alloc] initWithDictionary:headers copyItems:YES];+    _message = [message copy];+    _trailers = [[NSDictionary alloc] initWithDictionary:trailers copyItems:YES];+  }+  return self;+}++- (id)copyWithZone:(NSZone *)zone {+  return [[ResponseCacheEntry allocWithZone:zone] initWithDeadline:_deadline+                                                           headers:_headers+                                                           message:_message+                                                          trailers:_trailers];+}++@end++@implementation MutableResponseCacheEntry++@dynamic deadline;+@dynamic headers;+@dynamic message;+@dynamic trailers;++- (void)setDeadline:(NSDate *)deadline {+  _deadline = [deadline copy];+}++- (void)setHeaders:(NSDictionary *)headers {+  _headers = [[NSDictionary alloc] initWithDictionary:headers copyItems:YES];+}++- (void)setMessage:(id)message {+  _message = [message copy];+}++- (void)setTrailers:(NSDictionary *)trailers {+  _trailers = [[NSDictionary alloc] initWithDictionary:trailers copyItems:YES];+}++@end++@implementation CacheContext {+  NSCache<RequestCacheEntry *, ResponseCacheEntry *> *_cache;+}++- (instancetype)init {+  if ((self = [super init])) {+    _cache = [[NSCache alloc] init];+  }+  return self;+}++- (GRPCInterceptor *)createInterceptorWithManager:(GRPCInterceptorManager *)interceptorManager {+  return [[CacheInterceptor alloc] initWithInterceptorManager:interceptorManager cacheContext:self];+}++- (ResponseCacheEntry *)getCachedResponseForRequest:(RequestCacheEntry *)request {+  ResponseCacheEntry *response = nil;+  @synchronized(self) {+    response = [_cache objectForKey:request];+  }+  return response;+}++- (void)setCachedResponse:(ResponseCacheEntry *)response forRequest:(RequestCacheEntry *)request {+  @synchronized(self) {+    [_cache setObject:response forKey:request];+  }+}++@end++@implementation CacheInterceptor {+  GRPCInterceptorManager *_manager;+  CacheContext *_context;+  dispatch_queue_t _dispatchQueue;++  BOOL _cacheable;+  BOOL _messageSeen;+  GRPCCallOptions *_callOptions;+  GRPCRequestOptions *_requestOptions;+  id _requestMessage;+  MutableRequestCacheEntry *_request;+  MutableResponseCacheEntry *_response;+}++- (dispatch_queue_t)requestDispatchQueue {+  return _dispatchQueue;+}++- (dispatch_queue_t)dispatchQueue {+  return _dispatchQueue;+}++- (instancetype)initWithInterceptorManager:(GRPCInterceptorManager *_Nonnull)intercepterManager+                              cacheContext:(CacheContext *_Nonnull)cacheContext {+  if ((self = [super initWithInterceptorManager:intercepterManager+                           requestDispatchQueue:dispatch_get_main_queue()+                          responseDispatchQueue:dispatch_get_main_queue()])) {+    _manager = intercepterManager;+    _context = cacheContext;+    _dispatchQueue = dispatch_queue_create(NULL, DISPATCH_QUEUE_SERIAL);++    _cacheable = YES;+    _messageSeen = NO;+    _request = nil;+    _response = nil;+  }+  return self;+}++- (void)startWithRequestOptions:(GRPCRequestOptions *)requestOptions+                    callOptions:(GRPCCallOptions *)callOptions {+  NSLog(@""start"");+  if (requestOptions.safety != GRPCCallSafetyCacheableRequest) {+    NSLog(@""no cache"");+    _cacheable = NO;+    [_manager startNextInterceptorWithRequest:requestOptions callOptions:callOptions];+  } else {+    _requestOptions = [requestOptions copy];+    _callOptions = [callOptions copy];+  }+}++- (void)writeData:(id)data {+  NSLog(@""writeData"");+  if (!_cacheable) {+    [_manager writeNextInterceptorWithData:data];+  } else {+    NSAssert(!_messageSeen, @""CacheInterceptor does not support streaming call"");+    if (_messageSeen) {",We might want to add a similar check in `didReceiveData` to assert that server streaming calls are not supported.,OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/18852,288294710,2019-05-28T20:45:45Z,src/objective-c/tests/InteropTests.m,"@@ -151,6 +152,230 @@ - (dispatch_queue_t)dispatchQueue {  @end +@interface DefaultInterceptorFactory : NSObject<GRPCInterceptorFactory>++- (GRPCInterceptor *)createInterceptorWithManager:(GRPCInterceptorManager *)interceptorManager;++@end++@implementation DefaultInterceptorFactory++- (GRPCInterceptor *)createInterceptorWithManager:(GRPCInterceptorManager *)interceptorManager {+  dispatch_queue_t queue = dispatch_queue_create(NULL, DISPATCH_QUEUE_SERIAL);+  return [[GRPCInterceptor alloc] initWithInterceptorManager:interceptorManager+                                        requestDispatchQueue:queue+                                       responseDispatchQueue:queue];+}++@end++@interface HookInterceptorFactory : NSObject<GRPCInterceptorFactory>++- (instancetype)+  initWithDispatchQueue:(dispatch_queue_t)dispatchQueue+              startHook:(void (^)(GRPCRequestOptions *requestOptions, GRPCCallOptions *callOptions,+                                  GRPCInterceptorManager *manager))startHook+          writeDataHook:(void (^)(id data, GRPCInterceptorManager *manager))writeDataHook+             finishHook:(void (^)(GRPCInterceptorManager *manager))finishHook+receiveNextMessagesHook:(void (^)(NSUInteger numberOfMessages,+                                  GRPCInterceptorManager *manager))receiveNextMessagesHook+     responseHeaderHook:(void (^)(NSDictionary *initialMetadata,+                                  GRPCInterceptorManager *manager))responseHeaderHook+       responseDataHook:(void (^)(id data, GRPCInterceptorManager *manager))responseDataHook+      responseCloseHook:(void (^)(NSDictionary *trailingMetadata, NSError *error,+                                  GRPCInterceptorManager *manager))responseCloseHook+       didWriteDataHook:(void (^)(GRPCInterceptorManager *manager))didWriteDataHook;++- (GRPCInterceptor *)createInterceptorWithManager:(GRPCInterceptorManager *)interceptorManager;++@end++@interface HookIntercetpor : GRPCInterceptor++- (instancetype)+initWithInterceptorManager:(GRPCInterceptorManager *)interceptorManager+             dispatchQueue:(dispatch_queue_t)dispatchQueue+                 startHook:(void (^)(GRPCRequestOptions *requestOptions,+                                     GRPCCallOptions *callOptions,+                                     GRPCInterceptorManager *manager))startHook+             writeDataHook:(void (^)(id data, GRPCInterceptorManager *manager))writeDataHook+                finishHook:(void (^)(GRPCInterceptorManager *manager))finishHook+   receiveNextMessagesHook:(void (^)(NSUInteger numberOfMessages,+                                     GRPCInterceptorManager *manager))receiveNextMessagesHook+        responseHeaderHook:(void (^)(NSDictionary *initialMetadata,+                                     GRPCInterceptorManager *manager))responseHeaderHook+          responseDataHook:(void (^)(id data, GRPCInterceptorManager *manager))responseDataHook+         responseCloseHook:(void (^)(NSDictionary *trailingMetadata, NSError *error,+                                     GRPCInterceptorManager *manager))responseCloseHook+          didWriteDataHook:(void (^)(GRPCInterceptorManager *manager))didWriteDataHook;++@end++@implementation HookInterceptorFactory {+  void (^_startHook)(GRPCRequestOptions *requestOptions, GRPCCallOptions *callOptions,+                     GRPCInterceptorManager *manager);+  void (^_writeDataHook)(id data, GRPCInterceptorManager *manager);+  void (^_finishHook)(GRPCInterceptorManager *manager);+  void (^_receiveNextMessagesHook)(NSUInteger numberOfMessages, GRPCInterceptorManager *manager);+  void (^_responseHeaderHook)(NSDictionary *initialMetadata, GRPCInterceptorManager *manager);+  void (^_responseDataHook)(id data, GRPCInterceptorManager *manager);+  void (^_responseCloseHook)(NSDictionary *trailingMetadata, NSError *error,+                             GRPCInterceptorManager *manager);+  void (^_didWriteDataHook)(GRPCInterceptorManager *manager);+  dispatch_queue_t _dispatchQueue;+}++- (instancetype)+  initWithDispatchQueue:(dispatch_queue_t)dispatchQueue+              startHook:(void (^)(GRPCRequestOptions *requestOptions, GRPCCallOptions *callOptions,+                                  GRPCInterceptorManager *manager))startHook+          writeDataHook:(void (^)(id data, GRPCInterceptorManager *manager))writeDataHook+             finishHook:(void (^)(GRPCInterceptorManager *manager))finishHook+receiveNextMessagesHook:(void (^)(NSUInteger numberOfMessages,+                                  GRPCInterceptorManager *manager))receiveNextMessagesHook+     responseHeaderHook:(void (^)(NSDictionary *initialMetadata,+                                  GRPCInterceptorManager *manager))responseHeaderHook+       responseDataHook:(void (^)(id data, GRPCInterceptorManager *manager))responseDataHook+      responseCloseHook:(void (^)(NSDictionary *trailingMetadata, NSError *error,+                                  GRPCInterceptorManager *manager))responseCloseHook+       didWriteDataHook:(void (^)(GRPCInterceptorManager *manager))didWriteDataHook {+  if ((self = [super init])) {+    _dispatchQueue = dispatchQueue;+    _startHook = startHook;+    _writeDataHook = writeDataHook;+    _finishHook = finishHook;+    _receiveNextMessagesHook = receiveNextMessagesHook;+    _responseHeaderHook = responseHeaderHook;+    _responseDataHook = responseDataHook;+    _responseCloseHook = responseCloseHook;+    _didWriteDataHook = didWriteDataHook;+    _dispatchQueue = dispatchQueue;+  }+  return self;+}++- (GRPCInterceptor *)createInterceptorWithManager:(GRPCInterceptorManager *)interceptorManager {+  return [[HookIntercetpor alloc] initWithInterceptorManager:interceptorManager+                                               dispatchQueue:_dispatchQueue+                                                   startHook:_startHook+                                               writeDataHook:_writeDataHook+                                                  finishHook:_finishHook+                                     receiveNextMessagesHook:_receiveNextMessagesHook+                                          responseHeaderHook:_responseHeaderHook+                                            responseDataHook:_responseDataHook+                                           responseCloseHook:_responseCloseHook+                                            didWriteDataHook:_didWriteDataHook];+}++@end++@implementation HookIntercetpor {+  void (^_startHook)(GRPCRequestOptions *requestOptions, GRPCCallOptions *callOptions,+                     GRPCInterceptorManager *manager);+  void (^_writeDataHook)(id data, GRPCInterceptorManager *manager);+  void (^_finishHook)(GRPCInterceptorManager *manager);+  void (^_receiveNextMessagesHook)(NSUInteger numberOfMessages, GRPCInterceptorManager *manager);+  void (^_responseHeaderHook)(NSDictionary *initialMetadata, GRPCInterceptorManager *manager);+  void (^_responseDataHook)(id data, GRPCInterceptorManager *manager);+  void (^_responseCloseHook)(NSDictionary *trailingMetadata, NSError *error,+                             GRPCInterceptorManager *manager);+  void (^_didWriteDataHook)(GRPCInterceptorManager *manager);+  GRPCInterceptorManager *_manager;+  dispatch_queue_t _dispatchQueue;","All of our examples, tests use a single dispatch queue for requests and responses, which means that requests and responses won't be processed in parallel. Can we add a test where we use different queues for requests and responses so that we have test coverage for concurrent requests, responses?",
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/18852,288405850,2019-05-29T06:08:28Z,src/objective-c/GRPCClient/GRPCInterceptor.m,"@@ -0,0 +1,209 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#import <Foundation/Foundation.h>++#import ""GRPCInterceptor.h""++@implementation GRPCInterceptorManager {+  id<GRPCInterceptorInterface> _nextInterceptor;+  id<GRPCResponseHandler> _previousInterceptor;+}++- (instancetype)initWithNextInterceptor:(id<GRPCInterceptorInterface>)nextInterceptor {+  if ((self = [super init])) {+    _nextInterceptor = nextInterceptor;+  }++  return self;+}++- (void)setPreviousInterceptor:(id<GRPCResponseHandler>)previousInterceptor {+  _previousInterceptor = previousInterceptor;+}++- (void)shutDown {+  _nextInterceptor = nil;+  _previousInterceptor = nil;+}++- (void)startNextInterceptorWithRequest:(GRPCRequestOptions *)requestOptions+                            callOptions:(GRPCCallOptions *)callOptions {+  id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;+  dispatch_async(copiedNextInterceptor.requestDispatchQueue, ^{+    [copiedNextInterceptor startWithRequestOptions:requestOptions callOptions:callOptions];+  });+}++- (void)writeNextInterceptorWithData:(id)data {+  id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;",Do we need some synchronization/checks to ensure that the interceptor is non-null? Similar comment for other functions in this class.,OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/19142,288418610,2019-05-29T06:59:36Z,test/cpp/end2end/client_interceptors_end2end_test.cc,"@@ -501,7 +501,14 @@ class BidiStreamingRpcHijackingInterceptorFactory  class LoggingInterceptor : public experimental::Interceptor {  public:-  LoggingInterceptor(experimental::ClientRpcInfo* info) { info_ = info; }+  LoggingInterceptor(experimental::ClientRpcInfo* info) {+    pre_send_initial_metadata_ = false;","Doing all the interception work through static class members is like doing all the interception work through global variables; it looks stylistically bad. Can this not be replaced with something more ""normal"" or an explanation of why this is normal? As it stands, it looks like a singleton structure that is not explicitly called a singleton or anything like that.",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/18852,288621309,2019-05-29T15:14:18Z,src/objective-c/examples/InterceptorSample/InterceptorSample/CacheInterceptor.m,"@@ -0,0 +1,303 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#import ""CacheInterceptor.h""++@implementation RequestCacheEntry {+ @protected+  NSString *_path;+  id<NSObject> _message;+}++@synthesize path = _path;+@synthesize message = _message;++- (instancetype)initWithPath:(NSString *)path message:(id)message {+  if ((self = [super init])) {+    _path = [path copy];+    _message = [message copy];+  }+  return self;+}++- (id)copyWithZone:(NSZone *)zone {+  return [[RequestCacheEntry allocWithZone:zone] initWithPath:_path message:_message];+}++- (BOOL)isEqual:(id)object {+  if ([self class] != [object class]) return NO;+  RequestCacheEntry *rhs = (RequestCacheEntry *)object;","Well lhs is the object itself. Think of it, when you call `a == b`, you actually calls `operator==` with `a` as `this` and `b` as the parameter.",OK
43831800,sheenaqotj,https://api.github.com/repos/grpc/grpc/pulls/18856,288820799,2019-05-30T00:44:58Z,include/grpcpp/impl/codegen/server_callback.h,"@@ -998,9 +996,9 @@ class CallbackServerStreamingHandler : public MethodHandler { template <class RequestType, class ResponseType> class CallbackBidiHandler : public MethodHandler {  public:-  CallbackBidiHandler(-      std::function<-          experimental::ServerBidiReactor<RequestType, ResponseType>*()>+  explicit CallbackBidiHandler(+      std::function<experimental::ServerBidiReactor<RequestType, ResponseType>*(+          ServerContext*)>           func)","How about ""get_reactor_func""... to distinguish from callback_func or some other naming for the user-supplied function we run in the SimpleUnaryReactor in OnStarted",OK
219470,benjaminp,https://api.github.com/repos/grpc/grpc/pulls/19013,288854009,2019-05-30T04:29:06Z,src/core/ext/filters/client_channel/lb_policy/grpclb/load_balancer_api.cc,"@@ -67,8 +68,9 @@ grpc_grpclb_request* grpc_grpclb_request_create(const char* lb_service_name) {   req->has_client_stats = false;   req->has_initial_request = true;   req->initial_request.has_name = true;-  strncpy(req->initial_request.name, lb_service_name,-          GRPC_GRPCLB_SERVICE_NAME_MAX_LENGTH);+  memcpy(req->initial_request.name, lb_service_name,+         GPR_MIN(GRPC_GRPCLB_SERVICE_NAME_MAX_LENGTH,+                 strlen(lb_service_name) + 1));","I don't understand your concern with the new code. We're copying the minimium of the destination buffer size and another quantity, so it should be impossible to overwrite.As for the old code, I describe in the commit message why it's okay. Namely, nanopb serializes up to NUL or the buffer size.Requiring the service name to be <= 128 bytes including the terminating NUL seems quite reasonable to me, but it would technically be a backwards incompatibility.",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/19013,288858767,2019-05-30T05:02:34Z,src/core/ext/filters/client_channel/lb_policy/grpclb/load_balancer_api.cc,"@@ -67,8 +68,9 @@ grpc_grpclb_request* grpc_grpclb_request_create(const char* lb_service_name) {   req->has_client_stats = false;   req->has_initial_request = true;   req->initial_request.has_name = true;-  strncpy(req->initial_request.name, lb_service_name,-          GRPC_GRPCLB_SERVICE_NAME_MAX_LENGTH);+  memcpy(req->initial_request.name, lb_service_name,+         GPR_MIN(GRPC_GRPCLB_SERVICE_NAME_MAX_LENGTH,+                 strlen(lb_service_name) + 1));","I looked at all the code paths this leads to and this one seems to be fed to nanopb and should be fine. nanopb treatment of buffer sizes is super dangerous in general. The response lb message seems unused in gRPC code so far, but that also has the max limit of 64 bytes, and things can easily go wrong when that string is used.I noticed another issue: `GPR_MIN` being a macro makes `strlen(x) + 1` to be evaluated *twice*. In general, after all this I am opposed to this change. Seems like we are obfuscating a line of code with clear intent and (hopefully) understood risks just to silence the compiler. Instead of doing this and replacing with worse performing code, we should just disable the diagnostic directly for that line of code, which has the added benefit of documenting the risk and communicating that the author thought about this. Looks like the following works:```#pragma GCC diagnostic push#pragma GCC diagnostic ignored ""-Wstringop-truncation""// strncpy(...)#pragma GCC diagnostic pop```",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/18856,289100553,2019-05-30T17:53:00Z,include/grpcpp/impl/codegen/server_callback.h,"@@ -435,23 +429,25 @@ class ServerUnaryReactor : public internal::ServerReactor { };  template <typename Request, typename Response, typename F>-ServerUnaryReactor<Request, Response>* ServeRpc(F&& func) {+ServerUnaryReactor<Request, Response>* ServeRpc(ServerContext* context,+                                                F&& func) {   // TODO(vjpai): Specialize this to prevent counting OnCancel conditions   class SimpleUnaryReactor final       : public ServerUnaryReactor<Request, Response> {    public:     explicit SimpleUnaryReactor(F&& func) : on_started_func_(std::move(func)) {}     private:-    void OnStarted(ServerContext* context, const Request* req,-                   Response* resp) override {-      on_started_func_(context, req, resp, this);+    void OnStarted(const Request* req, Response* resp) override {+      on_started_func_(req, resp, this);","The user still has to call Finish to indicate done-ness. We could have a ""super-simple-reactor"" where the user returns a status and the library calls Finish; it could even be an overload, though the user would have to know that using that mode wouldn't allow any sort of blocking or waiting. I think I should add another overload.",OK
219470,benjaminp,https://api.github.com/repos/grpc/grpc/pulls/19013,289117208,2019-05-30T18:34:55Z,src/core/ext/filters/client_channel/lb_policy/grpclb/load_balancer_api.cc,"@@ -67,8 +68,9 @@ grpc_grpclb_request* grpc_grpclb_request_create(const char* lb_service_name) {   req->has_client_stats = false;   req->has_initial_request = true;   req->initial_request.has_name = true;-  strncpy(req->initial_request.name, lb_service_name,-          GRPC_GRPCLB_SERVICE_NAME_MAX_LENGTH);+  memcpy(req->initial_request.name, lb_service_name,+         GPR_MIN(GRPC_GRPCLB_SERVICE_NAME_MAX_LENGTH,+                 strlen(lb_service_name) + 1));","> The reason `std::min` cannot be used is that gRPC Core cannot depend on `libstdc++` for various reasons; it just uses C++ as a language--not due to someone's preference at all.This doesn't seem be true:```$ git grep -E 'std::(min|max)' srcsrc/boringssl/crypto_test_data.cc:    size_t chunk = std::min(static_cast<size_t>(8192), len - i);src/core/ext/filters/client_channel/subchannel.cc:  args.deadline = std::max(next_attempt_deadline_, min_deadline);src/core/lib/backoff/backoff.cc:      std::min(current_backoff_ * options_.multiplier(),src/core/lib/iomgr/tcp_posix.cc:      std::min<size_t>(MAX_READ_IOVEC, tcp->incoming_buffer->count);```",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/19013,289118563,2019-05-30T18:38:29Z,src/core/ext/filters/client_channel/lb_policy/grpclb/load_balancer_api.cc,"@@ -67,8 +68,9 @@ grpc_grpclb_request* grpc_grpclb_request_create(const char* lb_service_name) {   req->has_client_stats = false;   req->has_initial_request = true;   req->initial_request.has_name = true;-  strncpy(req->initial_request.name, lb_service_name,-          GRPC_GRPCLB_SERVICE_NAME_MAX_LENGTH);+  memcpy(req->initial_request.name, lb_service_name,+         GPR_MIN(GRPC_GRPCLB_SERVICE_NAME_MAX_LENGTH,+                 strlen(lb_service_name) + 1));","@benjaminp that's interesting! It's certainly the case that grpc core not link against libstdc++, but `std::min` is probably declared inline in the headers. @nicolasnoble @markdroth Are the above uses of `std::min` intentional or accidental?",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/19013,289134278,2019-05-30T19:19:45Z,src/core/ext/filters/client_channel/lb_policy/grpclb/load_balancer_api.cc,"@@ -67,8 +68,9 @@ grpc_grpclb_request* grpc_grpclb_request_create(const char* lb_service_name) {   req->has_client_stats = false;   req->has_initial_request = true;   req->initial_request.has_name = true;-  strncpy(req->initial_request.name, lb_service_name,-          GRPC_GRPCLB_SERVICE_NAME_MAX_LENGTH);+  memcpy(req->initial_request.name, lb_service_name,+         GPR_MIN(GRPC_GRPCLB_SERVICE_NAME_MAX_LENGTH,+                 strlen(lb_service_name) + 1));","gRPC Core library (i.e. `//:grpc` Bazel target) is not supposed to. That library is wrapped in other contexts, some may choose to bring in `libstdc++`.  An ancient version of `libstdc++` (one that exists in `manylinux1` docker image) may have been picked up during the Python wheel build process, likely due to the compilation flags noted in `setup.py` and folks did not care to actively fight such linkage, but none of the symbols are directly used by gRPC Core library code.",
19604104,bigfacebear,https://api.github.com/repos/grpc/grpc/pulls/19187,289227273,2019-05-31T01:12:18Z,src/core/lib/transport/transport.cc,"@@ -36,9 +36,6 @@ #include ""src/core/lib/slice/slice_string_helpers.h"" #include ""src/core/lib/transport/transport_impl.h"" -grpc_core::DebugOnlyTraceFlag grpc_trace_stream_refcount(false,",This is my bad. But seems like this declaration should remain in the .h file because some inline functions are referring it.,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19013,289406999,2019-05-31T14:13:56Z,src/core/ext/filters/client_channel/lb_policy/grpclb/load_balancer_api.cc,"@@ -67,8 +68,9 @@ grpc_grpclb_request* grpc_grpclb_request_create(const char* lb_service_name) {   req->has_client_stats = false;   req->has_initial_request = true;   req->initial_request.has_name = true;-  strncpy(req->initial_request.name, lb_service_name,-          GRPC_GRPCLB_SERVICE_NAME_MAX_LENGTH);+  memcpy(req->initial_request.name, lb_service_name,+         GPR_MIN(GRPC_GRPCLB_SERVICE_NAME_MAX_LENGTH,+                 strlen(lb_service_name) + 1));","@mehrdada In principle, nothing from the `std::` namespace should be used outside of a small number of directories where we allow such things (primarily lib/gpr, lib/gprpp, and lib/iomgr).  If we want to use something like `std::min()`, which is a header-only implementation, the right approach would be to create a file in lib/gprpp that defines `grpc_core::Min<>` in terms of `std::min()`, and then use `grpc_core::Min<>` everywhere else in our code.  In practice, it looks like no one has bothered to do this, and for something as simple as `std::min()`, it's probably not that big of a deal.That having been said, I agree that iterating over the string twice is unnecessarily inefficient.  Ideally, the right answer here would be to use the BSD `strlcpy()` function, but that's unfortunately not portable.  Instead, it might be better to do something like this:```memcpy(req->initial_request.name, lb_service_name,       GRPC_GRPCLB_SERVICE_NAME_MAX_LENGTH - 1);req->initial_request.name[GRPC_GRPCLB_SERVICE_NAME_MAX_LENGTH - 1] = '\0';```",
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/19013,289565621,2019-05-31T22:12:06Z,src/core/ext/filters/client_channel/lb_policy/grpclb/load_balancer_api.cc,"@@ -67,8 +68,9 @@ grpc_grpclb_request* grpc_grpclb_request_create(const char* lb_service_name) {   req->has_client_stats = false;   req->has_initial_request = true;   req->initial_request.has_name = true;-  strncpy(req->initial_request.name, lb_service_name,-          GRPC_GRPCLB_SERVICE_NAME_MAX_LENGTH);+  memcpy(req->initial_request.name, lb_service_name,+         GPR_MIN(GRPC_GRPCLB_SERVICE_NAME_MAX_LENGTH,+                 strlen(lb_service_name) + 1));","@AspirinSJL I knew some things like `if (x = y) { }` where you intentionally want to write to `x` but the compiler thinks you accidentally typed `==` as `=` are fixable with one additional set of parentheses: `if ((x=y)) {}`, so I just tried to see if that works in this case and it does.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19182,289780702,2019-06-03T10:27:22Z,bazel/grpc_deps.bzl,"@@ -115,9 +115,9 @@ def grpc_deps():             url = ""https://boringssl.googlesource.com/boringssl/+archive/afc30d43eef92979b05776ec0963c9cede5fb80f.tar.gz"",         ) -    if ""com_github_madler_zlib"" not in native.existing_rules():",why exactly is this change needed? It looks like you're only renaming the library. Is that because we need to use the same name that protobuf uses?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19214,289941772,2019-06-03T16:56:42Z,src/core/lib/gprpp/map.h,"@@ -373,34 +376,42 @@ Map<Key, T, Compare>::RebalanceTreeAfterDeletion(Entry* root) { }  template <class Key, class T, class Compare>-typename Map<Key, T, Compare>::Entry* Map<Key, T, Compare>::RemoveRecursive(-    Entry* root, const key_type& k) {-  if (root == nullptr) return root;+typename ::grpc_core::Pair<typename Map<Key, T, Compare>::iterator,+                           typename Map<Key, T, Compare>::Entry*>+Map<Key, T, Compare>::RemoveRecursive(Entry* root, const key_type& k) {+  Pair<iterator, Entry*> ret = MakePair(end(), root);+  if (root == nullptr) return ret;   int comp = CompareKeys(root->pair.first, k);   if (comp > 0) {-    root->left = RemoveRecursive(root->left, k);+    ret = RemoveRecursive(root->left, k);+    root->left = ret.second;   } else if (comp < 0) {-    root->right = RemoveRecursive(root->right, k);+    ret = RemoveRecursive(root->right, k);+    root->right = ret.second;   } else {-    Entry* ret;+    Entry* retEntry;","As per C++ style guide naming rules, this should be called `ret_entry` -- or better yet, just `entry`.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19214,289964302,2019-06-03T17:56:59Z,test/core/gprpp/map_test.cc,"@@ -319,43 +321,46 @@ TEST_F(MapTest, MapRandomInsertions) { // Test Map iterator TEST_F(MapTest, Iteration) {   Map<const char*, Payload, StringLess> test_map;-  for (int i = 0; i < 5; i++) {+  for (int i = 4; i >= 0; --i) {     test_map.emplace(kKeys[i], Payload(i));   }-  int count = 0;-  for (auto iter = test_map.begin(); iter != test_map.end(); iter++) {-    EXPECT_EQ(iter->second.data(), count);-    count++;+  int i = 0;+  for (auto it = test_map.begin(); i < 5 && it != test_map.end(); ++it) {+    EXPECT_STREQ(kKeys[i], it->first);+    EXPECT_EQ(i, it->second.data());+    ++i;   }-  EXPECT_EQ(count, 5);+  EXPECT_EQ(i, 5);","I just noticed that this check isn't very meaningful, because the loop above exits when `i` is 5.  Instead, I suggest looping based on `i` and then checking `it` at the end:```auto it = test_map.begin();for (size_t i = 0; i < 5; ++i) {  ASSERT_NE(it, test_map.end());  EXPECT_STREQ(kKeys[i], it->first);  EXPECT_EQ(i, it->second.data());  ++it;}EXPECT_EQ(it, test_map.end());```Same thing in the other iteration tests.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19214,290000775,2019-06-03T19:29:51Z,test/core/gprpp/map_test.cc,"@@ -377,9 +380,17 @@ TEST_F(MapTest, EraseUsingIterator) {     } else {       ++iter;     }-    count++;+    ++count;   }   EXPECT_EQ(count, 5);+  int expected_data = 0;","Suggest writing this as:```auto it = test_map.begin();for (size_t i = 0; i < 5; ++i) {  if (i % 2 == 0) {    EXPECT_STREQ(kKeys[i], it->first.get());    EXPECT_EQ(i, it->second.data());    ++it;  }}EXPECT_EQ(it, test_map.end());```",OK
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/19216,290010450,2019-06-03T19:58:08Z,test/cpp/end2end/port_sharing_end2end_test.cc,"@@ -176,14 +179,15 @@ class TestTcpServer {       Slice data(buf, read_bytes);       p.read_buffer = ByteBuffer(&data, 1);     }-    gpr_log(GPR_INFO, ""Handing off fd %d with data size %d"", fd_,-            static_cast<int>(p.read_buffer.Length()));+    gpr_log(GPR_INFO, ""Handing off fd %d with data size %d from listener fd %d"",+            fd_, static_cast<int>(p.read_buffer.Length()), listener_fd_);     connection_acceptor_->HandleNewConnection(&p);   }    std::mutex mu_;   bool shutdown_; +  int listener_fd_;",nit: int listener_fd_ = -1;int fd_ = -1;bool queue_data_ = false;int port_ = -1;,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19202,290359988,2019-06-04T15:32:05Z,src/core/lib/channel/channelz_registry.cc,"@@ -29,39 +32,84 @@ #include <grpc/support/log.h> #include <grpc/support/sync.h> -#include <cstring>- namespace grpc_core { namespace channelz {+ namespace {+const int kPaginationLimit = 100;+const grpc_millis kSweepIntervalMs = 5000;+}  // anonymous namespace -// singleton instance of the registry.-ChannelzRegistry* g_channelz_registry = nullptr;+//+// ChannelzRegistry+// -const int kPaginationLimit = 100;+OrphanablePtr<ChannelzRegistry::Registry>* ChannelzRegistry::registry_ =+    nullptr; -}  // anonymous namespace+void ChannelzRegistry::Init() {+  GPR_ASSERT(registry_ == nullptr);+  registry_ = New<OrphanablePtr<Registry>>(New<Registry>());+}++void ChannelzRegistry::Shutdown() {+  GPR_ASSERT(registry_ != nullptr);+  Delete(registry_);+  registry_ = nullptr;+} -void ChannelzRegistry::Init() { g_channelz_registry = New<ChannelzRegistry>(); }+//+// ChannelzRegistry::Registry+// -void ChannelzRegistry::Shutdown() { Delete(g_channelz_registry); }+ChannelzRegistry::Registry::Registry() {+  ExecCtx exec_ctx;+  Ref().release();  // Ref held by timer callback.+  GRPC_CLOSURE_INIT(&gc_closure_, &OnGarbageCollectionTimer, this,+                    grpc_schedule_on_exec_ctx);+  grpc_timer_init(&gc_timer_, ExecCtx::Get()->Now() + kSweepIntervalMs,+                  &gc_closure_);+} -ChannelzRegistry* ChannelzRegistry::Default() {-  GPR_DEBUG_ASSERT(g_channelz_registry != nullptr);-  return g_channelz_registry;+void ChannelzRegistry::Registry::Orphan() {+  ExecCtx exec_ctx;+  {+    MutexLock lock(&mu_);+    shutdown_ = true;+    grpc_timer_cancel(&gc_timer_);+  }+  Unref(); } -ChannelzRegistry::ChannelzRegistry() { gpr_mu_init(&mu_); }+void ChannelzRegistry::Registry::OnGarbageCollectionTimer(void* arg,+                                                          grpc_error* error) {+  Registry* self = static_cast<Registry*>(arg);+  ReleasableMutexLock lock(&self->mu_);+  if (error != GRPC_ERROR_NONE || self->shutdown_) {+    lock.Unlock();+    self->Unref();+    return;+  }+  self->DoGarbageCollectionLocked();+  grpc_timer_init(&self->gc_timer_, ExecCtx::Get()->Now() + kSweepIntervalMs,+                  &self->gc_closure_);+} -ChannelzRegistry::~ChannelzRegistry() { gpr_mu_destroy(&mu_); }+void ChannelzRegistry::Registry::DoGarbageCollectionLocked() {+  for (size_t i = 0; i < entities_.size(); ++i) {+    MaybeRemoveUnusedNodeLocked(i);+  }+  MaybePerformCompactionLocked();+} -void ChannelzRegistry::InternalRegister(BaseNode* node) {-  MutexLock lock(&mu_);-  entities_.push_back(node);-  node->uuid_ = ++uuid_generator_;+void ChannelzRegistry::Registry::MaybeRemoveUnusedNodeLocked(size_t idx) {+  if (entities_[idx] != nullptr && entities_[idx]->HasOnlyOneRef()) {+    entities_[idx].reset();","I think I'm missing something here (which is not surprising when it comes to atomics).  Why is `HasOnlyOneRef() && Unref()` better than `if (HasOnlyOneRef()) reset()`?  Don't they have essentially the same result?BTW, I don't think it's safe to do `entities_[idx]->Unref()` here, because that would remove the ref while leaving `entities_[idx]` thinking that it still holds the ref.  So we'd probably have to do `entities_[idx].release()` afterwards -- and note that calling `Unref()` followed by `release()` is basically the same as calling `reset()` in the first place.In any case, I've changed `HasOnlyOneRef()` to use acq_rel semantics, which should hopefully fix the problem.",OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/19202,290366496,2019-06-04T15:44:57Z,src/core/lib/channel/channelz_registry.cc,"@@ -29,39 +32,84 @@ #include <grpc/support/log.h> #include <grpc/support/sync.h> -#include <cstring>- namespace grpc_core { namespace channelz {+ namespace {+const int kPaginationLimit = 100;+const grpc_millis kSweepIntervalMs = 5000;+}  // anonymous namespace -// singleton instance of the registry.-ChannelzRegistry* g_channelz_registry = nullptr;+//+// ChannelzRegistry+// -const int kPaginationLimit = 100;+OrphanablePtr<ChannelzRegistry::Registry>* ChannelzRegistry::registry_ =+    nullptr; -}  // anonymous namespace+void ChannelzRegistry::Init() {+  GPR_ASSERT(registry_ == nullptr);+  registry_ = New<OrphanablePtr<Registry>>(New<Registry>());+}++void ChannelzRegistry::Shutdown() {+  GPR_ASSERT(registry_ != nullptr);+  Delete(registry_);+  registry_ = nullptr;+} -void ChannelzRegistry::Init() { g_channelz_registry = New<ChannelzRegistry>(); }+//+// ChannelzRegistry::Registry+// -void ChannelzRegistry::Shutdown() { Delete(g_channelz_registry); }+ChannelzRegistry::Registry::Registry() {+  ExecCtx exec_ctx;+  Ref().release();  // Ref held by timer callback.+  GRPC_CLOSURE_INIT(&gc_closure_, &OnGarbageCollectionTimer, this,+                    grpc_schedule_on_exec_ctx);+  grpc_timer_init(&gc_timer_, ExecCtx::Get()->Now() + kSweepIntervalMs,+                  &gc_closure_);+} -ChannelzRegistry* ChannelzRegistry::Default() {-  GPR_DEBUG_ASSERT(g_channelz_registry != nullptr);-  return g_channelz_registry;+void ChannelzRegistry::Registry::Orphan() {+  ExecCtx exec_ctx;+  {+    MutexLock lock(&mu_);+    shutdown_ = true;+    grpc_timer_cancel(&gc_timer_);+  }+  Unref(); } -ChannelzRegistry::ChannelzRegistry() { gpr_mu_init(&mu_); }+void ChannelzRegistry::Registry::OnGarbageCollectionTimer(void* arg,+                                                          grpc_error* error) {+  Registry* self = static_cast<Registry*>(arg);+  ReleasableMutexLock lock(&self->mu_);+  if (error != GRPC_ERROR_NONE || self->shutdown_) {+    lock.Unlock();+    self->Unref();+    return;+  }+  self->DoGarbageCollectionLocked();+  grpc_timer_init(&self->gc_timer_, ExecCtx::Get()->Now() + kSweepIntervalMs,+                  &self->gc_closure_);+} -ChannelzRegistry::~ChannelzRegistry() { gpr_mu_destroy(&mu_); }+void ChannelzRegistry::Registry::DoGarbageCollectionLocked() {+  for (size_t i = 0; i < entities_.size(); ++i) {+    MaybeRemoveUnusedNodeLocked(i);+  }+  MaybePerformCompactionLocked();+} -void ChannelzRegistry::InternalRegister(BaseNode* node) {-  MutexLock lock(&mu_);-  entities_.push_back(node);-  node->uuid_ = ++uuid_generator_;+void ChannelzRegistry::Registry::MaybeRemoveUnusedNodeLocked(size_t idx) {+  if (entities_[idx] != nullptr && entities_[idx]->HasOnlyOneRef()) {+    entities_[idx].reset();","Thank you for the change. Yes, that's what I meant by ""making it an acq_rel load"". The main difference between this change and `HasOnlyOneRef && Unref` would be for performance of the GC. Assuming that in most cases the ref counting is larger than 1, we would by pass the ACQ_REL atomic in most cases, and only do that when we think it's necessary.That said, I really don't think it would matter here at all, given the frequency of the timer. ",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/18878,290601362,2019-06-05T06:57:23Z,tools/run_tests/run_interop_tests.py,"@@ -1515,6 +1506,8 @@ def aggregate_http2_results(stdout):                                 transport_security = 'compute_engine_channel_creds'                             else:                                 transport_security = 'tls'+                            if transport_security not in args.custom_credentials_type:",Ah I pretty much missed that --custom_credentials_type here is a list.,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19177,290842048,2019-06-05T17:04:21Z,src/objective-c/tests/run_one_test.sh,"@@ -0,0 +1,49 @@+#!/bin/bash+# Copyright 2019 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++# Don't run this script standalone. Instead, run from the repository root:+# ./tools/run_tests/run_tests.py -l objc++set -ev++cd $(dirname $0)++BINDIR=../../../bins/$CONFIG++[ -f $BINDIR/interop_server ] || {+    echo >&2 ""Can't find the test server. Make sure run_tests.py is making"" \+             ""interop_server before calling this script.""+    exit 1+}+$BINDIR/interop_server --port=5050 --max_send_message_size=8388608 &","exposing interop_server on fixed ports assumes that objc are the only tests running on the test machine at the moment. That currently is true (because of the `-j 1` argument here https://github.com/grpc/grpc/blob/4dd3afbad9acd09a5b24b312e5820bb82f22b1e1/tools/internal_ci/macos/grpc_basictests_objc_dbg.cfg#L30), but it's a very fragile assumption.Fixed ports make it easy for the tests to collide with each other when not careful. Also ObjC is the only language that relies on fixed ports for running tests.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19177,290844006,2019-06-05T17:09:32Z,tools/internal_ci/macos/grpc_basictests_objc.cfg,"@@ -29,3 +29,8 @@ env_vars {   key: ""RUN_TESTS_FLAGS""   value: ""-f basictests macos objc dbg --internal_ci -j 1 --inner_jobs 4 --bq_result_table aggregate_results"" }++env_vars {",You'd have to explicitly allow that new variable in the kokoro's job configuration (in google3) Why don't you just add an extra argument to `RUN_TEST_FLAGS` (which is already whitelisted)?,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19244,290846933,2019-06-05T17:17:22Z,src/core/lib/channel/channelz_registry.cc,"@@ -211,14 +227,20 @@ char* ChannelzRegistry::InternalGetServers(intptr_t start_server_id) { }  void ChannelzRegistry::InternalLogAllEntities() {-  MutexLock lock(&mu_);-  for (size_t i = 0; i < entities_.size(); ++i) {-    if (entities_[i] != nullptr) {-      char* json = entities_[i]->RenderJsonString();-      gpr_log(GPR_INFO, ""%s"", json);-      gpr_free(json);+  InlinedVector<RefCountedPtr<BaseNode>, 10> nodes;+  {+    MutexLock lock(&mu_);","That may actually be too large if there are a lot of empty slots.  And I'm not really too worried about performance here, since this method is used solely for debugging.",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19022,290980419,2019-06-06T00:05:05Z,src/objective-c/tests/InteropTests/InteropTests.m,"@@ -1014,6 +1021,92 @@ - (void)testCancelAfterBeginRPCWithV2API {   [self waitForExpectationsWithTimeout:TEST_TIMEOUT handler:nil]; } +- (void)testInitialMetadataWithV2API {+  __weak XCTestExpectation *expectation =+      [self expectationWithDescription:@""Received initial metadata.""];+  __block NSDictionary *init_md =+      [NSDictionary dictionaryWithObjectsAndKeys:@""FOOBAR"", @""x-grpc-test-echo-initial"", nil];+  GRPCMutableCallOptions *options = [[GRPCMutableCallOptions alloc] init];+  options.initialMetadata = init_md;+  options.transportType = self.class.transportType;+  options.PEMRootCertificates = self.class.PEMRootCertificates;+  options.hostNameOverride = [[self class] hostNameOverride];+  RMTSimpleRequest *request = [RMTSimpleRequest message];+  request.responseType = RMTPayloadType_Compressable;+  request.responseSize = 1000;+  request.payload.body = [NSMutableData dataWithLength:100];+  __block bool init_md_received = NO;+  GRPCUnaryProtoCall *call = [_service+      unaryCallWithMessage:request+           responseHandler:[[InteropTestsBlockCallbacks alloc]+                               initWithInitialMetadataCallback:^(NSDictionary *initialMetadata) {+                                 XCTAssertEqualObjects(initialMetadata[@""x-grpc-test-echo-initial""],+                                                       init_md[@""x-grpc-test-echo-initial""]);+                               }+                               messageCallback:^(id message) {","It is a good practice to let test cases focus on what they test without including much noise. If this test's purpose is to testing initial metadata, I think we can skip unrelated things like those in `messageCallback`.",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19022,290980786,2019-06-06T00:07:31Z,src/objective-c/tests/InteropTests/InteropTests.m,"@@ -1014,6 +1021,92 @@ - (void)testCancelAfterBeginRPCWithV2API {   [self waitForExpectationsWithTimeout:TEST_TIMEOUT handler:nil]; } +- (void)testInitialMetadataWithV2API {+  __weak XCTestExpectation *expectation =+      [self expectationWithDescription:@""Received initial metadata.""];+  __block NSDictionary *init_md =+      [NSDictionary dictionaryWithObjectsAndKeys:@""FOOBAR"", @""x-grpc-test-echo-initial"", nil];+  GRPCMutableCallOptions *options = [[GRPCMutableCallOptions alloc] init];+  options.initialMetadata = init_md;+  options.transportType = self.class.transportType;+  options.PEMRootCertificates = self.class.PEMRootCertificates;+  options.hostNameOverride = [[self class] hostNameOverride];+  RMTSimpleRequest *request = [RMTSimpleRequest message];+  request.responseType = RMTPayloadType_Compressable;+  request.responseSize = 1000;+  request.payload.body = [NSMutableData dataWithLength:100];+  __block bool init_md_received = NO;+  GRPCUnaryProtoCall *call = [_service+      unaryCallWithMessage:request+           responseHandler:[[InteropTestsBlockCallbacks alloc]+                               initWithInitialMetadataCallback:^(NSDictionary *initialMetadata) {+                                 XCTAssertEqualObjects(initialMetadata[@""x-grpc-test-echo-initial""],+                                                       init_md[@""x-grpc-test-echo-initial""]);+                               }+                               messageCallback:^(id message) {+                                 RMTSimpleResponse *expectedResponse = [RMTSimpleResponse message];+                                 expectedResponse.payload.type = RMTPayloadType_Compressable;+                                 expectedResponse.payload.body =+                                     [NSMutableData dataWithLength:1000];+                                 XCTAssertEqualObjects(message, expectedResponse);+                                 init_md_received = YES;+                               }+                               closeCallback:^(NSDictionary *trailingMetadata, NSError *error) {+                                 XCTAssertNil(error, @""Unexpected error: %@"", error);+                                 if (init_md_received) {+                                   [expectation fulfill];","How about using two expectations, one for initial metadata and one for close?",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19022,290981084,2019-06-06T00:09:15Z,src/objective-c/tests/InteropTests/InteropTests.m,"@@ -1014,6 +1021,92 @@ - (void)testCancelAfterBeginRPCWithV2API {   [self waitForExpectationsWithTimeout:TEST_TIMEOUT handler:nil]; } +- (void)testInitialMetadataWithV2API {+  __weak XCTestExpectation *expectation =+      [self expectationWithDescription:@""Received initial metadata.""];+  __block NSDictionary *init_md =+      [NSDictionary dictionaryWithObjectsAndKeys:@""FOOBAR"", @""x-grpc-test-echo-initial"", nil];+  GRPCMutableCallOptions *options = [[GRPCMutableCallOptions alloc] init];+  options.initialMetadata = init_md;+  options.transportType = self.class.transportType;+  options.PEMRootCertificates = self.class.PEMRootCertificates;+  options.hostNameOverride = [[self class] hostNameOverride];+  RMTSimpleRequest *request = [RMTSimpleRequest message];+  request.responseType = RMTPayloadType_Compressable;+  request.responseSize = 1000;+  request.payload.body = [NSMutableData dataWithLength:100];+  __block bool init_md_received = NO;+  GRPCUnaryProtoCall *call = [_service+      unaryCallWithMessage:request+           responseHandler:[[InteropTestsBlockCallbacks alloc]+                               initWithInitialMetadataCallback:^(NSDictionary *initialMetadata) {+                                 XCTAssertEqualObjects(initialMetadata[@""x-grpc-test-echo-initial""],+                                                       init_md[@""x-grpc-test-echo-initial""]);+                               }+                               messageCallback:^(id message) {+                                 RMTSimpleResponse *expectedResponse = [RMTSimpleResponse message];+                                 expectedResponse.payload.type = RMTPayloadType_Compressable;+                                 expectedResponse.payload.body =+                                     [NSMutableData dataWithLength:1000];+                                 XCTAssertEqualObjects(message, expectedResponse);+                                 init_md_received = YES;+                               }+                               closeCallback:^(NSDictionary *trailingMetadata, NSError *error) {+                                 XCTAssertNil(error, @""Unexpected error: %@"", error);+                                 if (init_md_received) {+                                   [expectation fulfill];+                                 }+                               }]+               callOptions:options];++  [call start];+  [self waitForExpectationsWithTimeout:TEST_TIMEOUT handler:nil];+}++- (void)testTrailingMetadataWithV2API {+  // This test needs to be disabled for remote test because interop server grpc-test+  // does not send trailing binary metadata.+  if (isRemoteInteropTest([[self class] host])) {+    return;+  }++  __weak XCTestExpectation *expectation =+      [self expectationWithDescription:@""Received trailing metadata.""];+  const unsigned char raw_bytes[] = {0x1, 0x2, 0x3, 0x4};+  NSData *trailer_data = [NSData dataWithBytes:raw_bytes length:sizeof(raw_bytes)];+  __block NSDictionary *trailer = [NSDictionary+      dictionaryWithObjectsAndKeys:trailer_data, @""x-grpc-test-echo-trailing-bin"", nil];+  GRPCMutableCallOptions *options = [[GRPCMutableCallOptions alloc] init];+  options.initialMetadata = trailer;+  options.transportType = self.class.transportType;+  options.PEMRootCertificates = self.class.PEMRootCertificates;+  options.hostNameOverride = [[self class] hostNameOverride];+  RMTSimpleRequest *request = [RMTSimpleRequest message];+  request.responseType = RMTPayloadType_Compressable;+  request.responseSize = 1000;+  request.payload.body = [NSMutableData dataWithLength:100];+  GRPCUnaryProtoCall *call = [_service+      unaryCallWithMessage:request+           responseHandler:[[InteropTestsBlockCallbacks alloc] initWithInitialMetadataCallback:nil+                               messageCallback:^(id message) {","(Same comment as above.) If the purpose of this test is only for trailing metadata, it's better to keep it clean and get unrelated logics removed.",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19022,290981534,2019-06-06T00:12:07Z,src/objective-c/tests/InteropTests/InteropTests.m,"@@ -1148,21 +1241,15 @@ - (void)testRPCAfterClosingOpenConnections {   [self waitForExpectationsWithTimeout:TEST_TIMEOUT handler:nil]; } -- (void)testCompressedUnaryRPC {-  // This test needs to be disabled for remote test because interop server grpc-test-  // does not support compression.-  if (isRemoteInteropTest([[self class] host])) {-    return;-  }-  XCTAssertNotNil([[self class] host]);+- (void)testRPCWithCompressMethod:(GRPCCompressionAlgorithm)compressMethod {","I'm not sure if this is a problem, but methods prefixed by `test` in `XCTestCase` class have special meaning that they will be recognized as test case. However I don't know if the rule only applies to those methods without parameter. But to make less confusion I guess it's worth renaming the method?",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19022,290982435,2019-06-06T00:17:39Z,src/objective-c/tests/InteropTests/InteropTests.m,"@@ -1179,6 +1266,36 @@ - (void)testCompressedUnaryRPC {   [self waitForExpectationsWithTimeout:TEST_TIMEOUT handler:nil]; } +- (void)testGzipCompressedUnaryRPC {+  // This test needs to be disabled for remote test because interop server grpc-test+  // does not support compression.+  if (isRemoteInteropTest([[self class] host])) {+    return;+  }+  XCTAssertNotNil([[self class] host]);+  [self testRPCWithCompressMethod:GRPCCompressGzip];+}++- (void)testStreamGzipCompressedUnaryRPC {+  // This test needs to be disabled for remote test because interop server grpc-test+  // does not support compression.+  if (isRemoteInteropTest([[self class] host])) {+    return;+  }+  XCTAssertNotNil([[self class] host]);+  [self testRPCWithCompressMethod:GRPCStreamCompressGzip];+}++- (void)testDeflateCompressedUnaryRPC {+  // This test needs to be disabled for remote test because interop server grpc-test+  // does not support compression.+  if (isRemoteInteropTest([[self class] host])) {",Something like this is hard to maintain when we add more interop test dimensions. It might be better adding something like `canRunCompressionTest` to the base class and override it in each sub class with corresponding value.,OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19022,290984693,2019-06-06T00:31:25Z,src/objective-c/tests/UnitTests/APIv2Tests.m,"@@ -770,4 +843,319 @@ - (void)testFlowControlReadNonBlockingFailure {   [self waitForExpectationsWithTimeout:kTestTimeout handler:nil]; } +- (void)testChannelReuseIdentical {",I believe there's a similar test in `ChannelTests`. Consider merging them.,
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19177,291030971,2019-06-06T06:05:54Z,tools/internal_ci/macos/grpc_buildtests_objc.cfg,"@@ -0,0 +1,36 @@+# Copyright 2018 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++# Config file for the internal CI (in protobuf text format)++# Location of the continuous shell script in repository.","Currently there are the 4 categories of tests (what you listed above), 3 build test of examples, and one `cfstream_test`. As discussed in previous comment threads above, there will potentially be dbg, opt configs for each of them (and probably also asan and tsan). All of them run on both PRs and master. I did not completely split them according to these categories but kept some of them together, ended up with 3 categories of test ""ios tests"", ""ios build tests"" and ""mac tests"". The reason I pulled ios build tests out from ios tests is to reduce test time. I could merge ios tests and ios build tests in the same ""ios tests"" category, but that keeps the test time high in the >60 min region.",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19022,291264407,2019-06-06T16:18:23Z,test/cpp/interop/interop_server.cc,"@@ -118,7 +118,8 @@ bool CheckExpectedCompression(const ServerContext& context,               ""Expected compression but got uncompressed request from client."");       return false;     }-    if (!(inspector.GetMessageFlags() & GRPC_WRITE_INTERNAL_COMPRESS)) {+    if (!(inspector.GetMessageFlags() & GRPC_WRITE_INTERNAL_COMPRESS) &&+        received_compression != GRPC_COMPRESS_STREAM_GZIP) {",Why this additional condition?,OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19138,291266187,2019-06-06T16:22:51Z,test/cpp/end2end/cfstream_test.cc,"@@ -393,21 +412,19 @@ TEST_P(CFStreamTest, ConcurrentRpc) {   std::thread thd = std::thread([this, &rpcs_sent]() {     void* got_tag;     bool ok = false;-    bool network_down = true;     int total_completions = 0;      while (CQNext(&got_tag, &ok)) {       ++total_completions;       GPR_ASSERT(ok);       AsyncClientCall* call = static_cast<AsyncClientCall*>(got_tag);+      int stream_id = GetStreamID(call->context);       if (!call->status.ok()) {-        gpr_log(GPR_DEBUG, ""RPC failed: %s"",-                call->status.error_message().c_str());+        gpr_log(GPR_DEBUG, ""RPC with stream_id %d failed with error: %s"",+                stream_id, call->status.error_message().c_str());         // Bring network up when RPCs start failing-        if (network_down) {-          NetworkUp();",Could you explain why `NetworkUp()` is no longer needed?,
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19251,291288836,2019-06-06T17:22:40Z,setup.py,"@@ -87,7 +97,6 @@ # present, then it will still attempt to use Cython.",Should we remove Python 2 classifiers @ line 84-85? And add new ones.,
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19022,291319967,2019-06-06T18:42:13Z,src/objective-c/tests/InteropTests/InteropTests.m,"@@ -1014,6 +1021,92 @@ - (void)testCancelAfterBeginRPCWithV2API {   [self waitForExpectationsWithTimeout:TEST_TIMEOUT handler:nil]; } +- (void)testInitialMetadataWithV2API {+  __weak XCTestExpectation *expectation =+      [self expectationWithDescription:@""Received initial metadata.""];+  __block NSDictionary *init_md =+      [NSDictionary dictionaryWithObjectsAndKeys:@""FOOBAR"", @""x-grpc-test-echo-initial"", nil];+  GRPCMutableCallOptions *options = [[GRPCMutableCallOptions alloc] init];+  options.initialMetadata = init_md;+  options.transportType = self.class.transportType;+  options.PEMRootCertificates = self.class.PEMRootCertificates;+  options.hostNameOverride = [[self class] hostNameOverride];+  RMTSimpleRequest *request = [RMTSimpleRequest message];+  request.responseType = RMTPayloadType_Compressable;+  request.responseSize = 1000;+  request.payload.body = [NSMutableData dataWithLength:100];+  __block bool init_md_received = NO;+  GRPCUnaryProtoCall *call = [_service+      unaryCallWithMessage:request+           responseHandler:[[InteropTestsBlockCallbacks alloc]+                               initWithInitialMetadataCallback:^(NSDictionary *initialMetadata) {+                                 XCTAssertEqualObjects(initialMetadata[@""x-grpc-test-echo-initial""],+                                                       init_md[@""x-grpc-test-echo-initial""]);+                               }+                               messageCallback:^(id message) {+                                 RMTSimpleResponse *expectedResponse = [RMTSimpleResponse message];+                                 expectedResponse.payload.type = RMTPayloadType_Compressable;+                                 expectedResponse.payload.body =+                                     [NSMutableData dataWithLength:1000];+                                 XCTAssertEqualObjects(message, expectedResponse);+                                 init_md_received = YES;",Moved to metadataCallback,OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/19251,291320159,2019-06-06T18:42:44Z,tools/dockerfile/test/python_alpine_x64/Dockerfile,"@@ -32,14 +34,21 @@ RUN apk update && apk add \   strace \   python-dev \   py-pip \+  python3-dev \   unzip \   wget \   zip -# Install Python packages from PyPI-RUN pip install --upgrade pip==10.0.1-RUN pip install virtualenv-RUN pip install futures==2.2.0 enum34==1.0.4 protobuf==3.5.0.post1 six==1.10.0+# Install Python 2 for tooling code.+RUN pip install --upgrade pip==10.0.1 && \+	pip install virtualenv futures==2.2.0 enum34==1.0.4 \+		protobuf==3.5.0.post1 six==1.10.0++# Install Python 3 packages from PyPI+RUN python3 -m ensurepip && \+	python3 -m pip install --upgrade pip==10.0.1 && \",I don't think it would be a bad idea to just do `pip install --upgrade pip` with no version specifier. But I was trying to follow the patterns set by the existing Dockerfiles. You could argue that there's value in knowing that you work with old versions of Pip.,
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19251,291377644,2019-06-06T21:24:16Z,tools/run_tests/run_tests.py,"@@ -752,14 +752,12 @@ def dockerfile_dir(self):      def _python_manager_name(self):         """"""Choose the docker image to use based on python version.""""""-        if self.args.compiler in [-                'python2.7', 'python3.5', 'python3.6', 'python3.7'-        ]:+        if self.args.compiler in ['python3.5', 'python3.7']:             return 'stretch_' + self.args.compiler[len('python'):]+        elif self.args.compiler == 'python3.6':+            return 'phusion_' + self.args.compiler[len('python'):]","In offline discussion, my point is that, ideally, I hope we can use one set of images to test all Python. It would help us reduce the complexity of our infrastructure.Yes, it shouldn't be a blocker for this PR.",OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19022,291395687,2019-06-06T22:28:20Z,src/objective-c/tests/UnitTests/APIv2Tests.m,"@@ -770,4 +843,319 @@ - (void)testFlowControlReadNonBlockingFailure {   [self waitForExpectationsWithTimeout:kTestTimeout handler:nil]; } +- (void)testChannelReuseIdentical {+  __weak XCTestExpectation *completion1 = [self expectationWithDescription:@""RPC1 completed.""];+  __weak XCTestExpectation *completion2 = [self expectationWithDescription:@""RPC2 completed.""];+  NSArray *rpcDone = [NSArray arrayWithObjects:completion1, completion2, nil];+  __weak XCTestExpectation *metadata1 =+      [self expectationWithDescription:@""Received initial metadata for RPC1.""];+  __weak XCTestExpectation *metadata2 =+      [self expectationWithDescription:@""Received initial metadata for RPC2.""];+  NSArray *initialMetadataDone = [NSArray arrayWithObjects:metadata1, metadata2, nil];++  RMTStreamingOutputCallRequest *request = [RMTStreamingOutputCallRequest message];+  RMTResponseParameters *parameters = [RMTResponseParameters message];+  parameters.size = kSimpleDataLength;+  [request.responseParametersArray addObject:parameters];+  request.payload.body = [NSMutableData dataWithLength:kSimpleDataLength];++  GRPCRequestOptions *requestOptions =+      [[GRPCRequestOptions alloc] initWithHost:kHostAddress+                                          path:kFullDuplexCallMethod.HTTPPath+                                        safety:GRPCCallSafetyDefault];+  GRPCMutableCallOptions *callOptions = [[GRPCMutableCallOptions alloc] init];+  callOptions.transportType = GRPCTransportTypeInsecure;+  GRPCCall2 *call1 = [[GRPCCall2 alloc]+      initWithRequestOptions:requestOptions+             responseHandler:[[ClientTestsBlockCallbacks alloc]+                                 initWithInitialMetadataCallback:^(NSDictionary *initialMetadata) {+                                   [metadata1 fulfill];+                                 }+                                 messageCallback:nil+                                 closeCallback:^(NSDictionary *trailingMetadata, NSError *error) {+                                   [completion1 fulfill];+                                 }]+                 callOptions:callOptions];+  GRPCCall2 *call2 = [[GRPCCall2 alloc]+      initWithRequestOptions:requestOptions+             responseHandler:[[ClientTestsBlockCallbacks alloc]+                                 initWithInitialMetadataCallback:^(NSDictionary *initialMetadata) {+                                   [metadata2 fulfill];+                                 }+                                 messageCallback:nil+                                 closeCallback:^(NSDictionary *trailingMetadata, NSError *error) {+                                   [completion2 fulfill];+                                 }]+                 callOptions:callOptions];+  [call1 start];+  [call2 start];+  [call1 writeData:[request data]];+  [call2 writeData:[request data]];+  [self waitForExpectations:initialMetadataDone timeout:kTestTimeout];+  GRPCCall2Internal *internalCall1 = call1->_firstInterceptor;+  GRPCCall2Internal *internalCall2 = call2->_firstInterceptor;+  XCTAssertEqual(+      internalCall1->_call->_wrappedCall->_pooledChannel->_wrappedChannel->_unmanagedChannel,+      internalCall2->_call->_wrappedCall->_pooledChannel->_wrappedChannel->_unmanagedChannel);+  [call1 finish];+  [call2 finish];+  [self waitForExpectations:rpcDone timeout:kTestTimeout];+}++- (void)testChannelReuseDifferentPath {","Oh sorry, the path's were the same so this test was useless. I've removed this testcase.",OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19022,291400363,2019-06-06T22:49:03Z,src/objective-c/tests/UnitTests/APIv2Tests.m,"@@ -770,4 +843,319 @@ - (void)testFlowControlReadNonBlockingFailure {   [self waitForExpectationsWithTimeout:kTestTimeout handler:nil]; } +- (void)testChannelReuseIdentical {","`ChannelTests` are different - they test the relationship between a GRPCPooledChannel and its wrapped channel. While I was looking at GRPCChannelPool, I found and fixed a bug in `wrappedCallWithPath:completionQueue:callOptions:` : we were ignoring the GRPCCompletionQueue param and using the default completion queue (singleton).",
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19022,291452581,2019-06-07T05:01:08Z,src/objective-c/tests/MacTests/StressTests.m,"@@ -519,21 +493,19 @@ - (void)testTimeoutOnFullDuplexCallWithV2API {   }    for (int i = 0; i < num_rpcs; ++i) {-    dispatch_async(q, ^{-      GRPCStreamingProtoCall *call = calls[i];-      [call start];-      RMTStreamingOutputCallRequest *request = [RMTStreamingOutputCallRequest message];-      RMTResponseParameters *parameters = [RMTResponseParameters message];-      parameters.size = 1000;-      // delay response by 100-200 milliseconds-      parameters.intervalUs = [self getRandomNumberBetween:100 * 1000 max:200 * 1000];-      [request.responseParametersArray addObject:parameters];-      request.payload.body = [NSMutableData dataWithLength:100];+    GRPCStreamingProtoCall *call = calls[i];+    [call start];+    RMTStreamingOutputCallRequest *request = [RMTStreamingOutputCallRequest message];+    RMTResponseParameters *parameters = [RMTResponseParameters message];+    parameters.size = 1000;+    // delay response by 100-200 milliseconds+    parameters.intervalUs = [self getRandomNumberBetween:100 * 1000 max:200 * 1000];+    [request.responseParametersArray addObject:parameters];+    request.payload.body = [NSMutableData dataWithLength:100]; -      [call writeMessage:request];-      [call writeMessage:request];-      [call finish];-    });+    [call writeMessage:request];+    [call writeMessage:request];+    [call finish];","Sleep is not needed here. RPCs have a deadline of 0.3 seconds, client sends 2 messages as part of each RPC, and server responds to each message with a delay of 100-200ms. So total delay per RPC is 200-300ms. Some RPCs will timeout while others will succeed.",
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19022,291453137,2019-06-07T05:05:26Z,src/objective-c/GRPCClient/GRPCCallOptions.h,"@@ -319,7 +319,8 @@ typedef NS_ENUM(NSUInteger, GRPCTransportType) { // HTTP/2 keep-alive feature. The parameter \a keepaliveInterval specifies the interval between two // PING frames. The parameter \a keepaliveTimeout specifies the length of the period for which the // call should wait for PING ACK. If PING ACK is not received after this period, the call fails.-// Negative values are not allowed.+// Negative values are invalid; setting these parameters to negative value will reset the","Not sure if I understood correctly. The same comment "" Negative values are invalid; setting these parameters to negative value will reset the corresponding parameter to the internal default value"" is also on line 160.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/19274,291465855,2019-06-07T06:27:49Z,tools/run_tests/run_interop_tests.py,"@@ -807,23 +807,17 @@ def compute_engine_creds_required(language, test_case):     return False  -def auth_options(language,-                 test_case,-                 google_default_creds_use_key_file,-                 service_account_key_file=None):+def auth_options(language, test_case, google_default_creds_use_key_file,",small nit: the vertical parameters are slightly neater,OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19292,291707236,2019-06-07T18:31:51Z,src/python/grpcio/grpc/_channel.py,"@@ -1104,5 +1100,9 @@ def __del__(self):         # effect closure of the underlying cygrpc.Channel instance.         # This prevent the failed-at-initializing object removal from failing.",1101-1102. This two lines of comment is no longer needed with your update.,
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/19292,291709335,2019-06-07T18:37:46Z,src/python/grpcio/grpc/_channel.py,"@@ -1026,6 +1016,7 @@ def __init__(self, target, options, credentials, compression):           compression: An optional value indicating the compression method to be             used over the lifetime of the channel.         """"""+        self._connectivity_state = None  # ensure attribute exists for __del__","`try/catch` will catch this, but ideally we should move towards fixing the logic so exception never occurs and perhaps remove try/catch afterwards.",OK
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/19292,291746541,2019-06-07T20:39:04Z,src/python/grpcio/grpc/_channel.py,"@@ -1026,6 +1016,7 @@ def __init__(self, target, options, credentials, compression):           compression: An optional value indicating the compression method to be             used over the lifetime of the channel.         """"""+        self._connectivity_state = None  # ensure attribute exists for __del__",What if the `__init__` is not executed properly? i.e. what if `cygrpc.Channel` constructor raises an exception?  We don't have the `_channel` instance to initialize `_connectivity_state` before calling that constructor of `cygrpc.Channel` so there's a chicken-and-egg problem here. That was the purpose of `hasattr` check as well: the cygrpc.Channel constructor potentially raising.,OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19292,291753211,2019-06-07T21:01:13Z,src/python/grpcio/grpc/_channel.py,"@@ -1026,6 +1016,7 @@ def __init__(self, target, options, credentials, compression):           compression: An optional value indicating the compression method to be             used over the lifetime of the channel.         """"""+        self._connectivity_state = None  # ensure attribute exists for __del__","I would say in the case of `cygrpc.Channel` constructor raises. Your update should catch the exception anyway. Alternatively, you can specify which kind of exception you want to silent in the `__del__` function.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19292,291763078,2019-06-07T21:40:06Z,src/python/grpcio/grpc/_channel.py,"@@ -1026,6 +1016,7 @@ def __init__(self, target, options, credentials, compression):           compression: An optional value indicating the compression method to be             used over the lifetime of the channel.         """"""+        self._connectivity_state = None  # ensure attribute exists for __del__",I think remove this line is easier for you than the alternative solution of guarding all known conditions in `__del__`.,OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19298,291781461,2019-06-07T23:34:22Z,src/objective-c/tests/InteropTests/InteropTests.m,"@@ -701,21 +703,21 @@ - (void)testResponsesOver4MBAreAcceptedIfOptedIn {   XCTAssertNotNil([[self class] host]);   __weak XCTestExpectation *expectation =       [self expectationWithDescription:@""HigherResponseSizeLimit""];+  __block NSError *callError = nil;    RMTSimpleRequest *request = [RMTSimpleRequest message];   const size_t kPayloadSize = 5 * 1024 * 1024;  // 5MB   request.responseSize = kPayloadSize;    [GRPCCall setResponseSizeLimit:6 * 1024 * 1024 forHost:[[self class] host]];-   [_service unaryCallWithRequest:request                          handler:^(RMTSimpleResponse *response, NSError *error) {-                           XCTAssertNil(error, @""Finished with unexpected error: %@"", error);-                           XCTAssertEqual(response.payload.body.length, kPayloadSize);","Don't we need to move this assert to after waitForExpectationsWithTimeout, similar to callError?",
1270,haberman,https://api.github.com/repos/grpc/grpc/pulls/18745,292224540,2019-06-10T23:06:10Z,src/core/ext/filters/client_channel/lb_policy/xds/xds_load_balancer_api.cc,"@@ -18,62 +18,167 @@  #include <grpc/support/port_platform.h> +#include <grpc/impl/codegen/log.h>+#include <grpc/support/alloc.h>+#include <grpc/support/string_util.h>+ #include ""pb_decode.h"" #include ""pb_encode.h""-#include ""src/core/ext/filters/client_channel/lb_policy/xds/xds_load_balancer_api.h""--#include <grpc/support/alloc.h> -/* invoked once for every Server in ServerList */-static bool count_serverlist(pb_istream_t* stream, const pb_field_t* field,-                             void** arg) {-  xds_grpclb_serverlist* sl = static_cast<xds_grpclb_serverlist*>(*arg);-  xds_grpclb_server server;-  if (GPR_UNLIKELY(!pb_decode(stream, grpc_lb_v1_Server_fields, &server))) {-    gpr_log(GPR_ERROR, ""nanopb error: %s"", PB_GET_ERROR(stream));-    return false;+#include ""src/core/ext/filters/client_channel/lb_policy/xds/xds_load_balancer_api.h""+#include ""src/core/lib/iomgr/error.h""+#include ""src/core/lib/iomgr/sockaddr_utils.h""++namespace grpc_core {++namespace {++constexpr char kEdsTypeUrl[] =+    ""type.googleapis.com/grpc.lb.v2.ClusterLoadAssignment"";+constexpr char kEndpointRequired[] = ""endpointRequired"";++}  // namespace++grpc_slice XdsEdsRequestCreateAndEncode(const char* service_name) {+  upb::Arena arena;+  // Create a request.+  XdsDiscoveryRequest* request = envoy_api_v2_DiscoveryRequest_new(arena.ptr());+  XdsNode* node =+      envoy_api_v2_DiscoveryRequest_mutable_node(request, arena.ptr());+  google_protobuf_Struct* metadata =+      envoy_api_v2_core_Node_mutable_metadata(node, arena.ptr());+  google_protobuf_Struct_FieldsEntry* field =+      google_protobuf_Struct_add_fields(metadata, arena.ptr());+  google_protobuf_Struct_FieldsEntry_set_key(+      field,+      upb_strview_make(kEndpointRequired, sizeof(kEndpointRequired) - 1));+  google_protobuf_Value* value =+      google_protobuf_Struct_FieldsEntry_mutable_value(field, arena.ptr());+  google_protobuf_Value_set_bool_value(value, true);+  envoy_api_v2_DiscoveryRequest_add_resource_names(+      request, upb_strview_makez(service_name), arena.ptr());+  envoy_api_v2_DiscoveryRequest_set_type_url(+      request, upb_strview_make(kEdsTypeUrl, sizeof(kEdsTypeUrl) - 1));+  // Encode the request.+  size_t output_length;+  char* output = envoy_api_v2_DiscoveryRequest_serialize(request, arena.ptr(),+                                                         &output_length);+  return grpc_slice_from_copied_buffer(output, output_length);+}++namespace {++grpc_error* ServerAddressParseAndAppend(const XdsLbEndpoint* lb_endpoint,+                                        ServerAddressList* list) {+  // Find the ip:port.+  const XdsEndpoint* endpoint =+      envoy_api_v2_endpoint_LbEndpoint_endpoint(lb_endpoint);+  const XdsAddress* address = envoy_api_v2_endpoint_Endpoint_address(endpoint);+  const XdsSocketAddress* socket_address =+      envoy_api_v2_core_Address_socket_address(address);+  upb_strview address_strview =+      envoy_api_v2_core_SocketAddress_address(socket_address);+  uint32_t port = envoy_api_v2_core_SocketAddress_port_value(socket_address);+  if (GPR_UNLIKELY(port >> 16) != 0) {+    return GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Invalid port."");   }-  ++sl->num_servers;-  return true;-}--typedef struct decode_serverlist_arg {-  /* The decoding callback is invoked once per server in serverlist. Remember-   * which index of the serverlist are we currently decoding */-  size_t decoding_idx;-  /* The decoded serverlist */-  xds_grpclb_serverlist* serverlist;-} decode_serverlist_arg;--/* invoked once for every Server in ServerList */-static bool decode_serverlist(pb_istream_t* stream, const pb_field_t* field,-                              void** arg) {-  decode_serverlist_arg* dec_arg = static_cast<decode_serverlist_arg*>(*arg);-  GPR_ASSERT(dec_arg->serverlist->num_servers >= dec_arg->decoding_idx);-  xds_grpclb_server* server =-      static_cast<xds_grpclb_server*>(gpr_zalloc(sizeof(xds_grpclb_server)));-  if (GPR_UNLIKELY(!pb_decode(stream, grpc_lb_v1_Server_fields, server))) {-    gpr_free(server);-    gpr_log(GPR_ERROR, ""nanopb error: %s"", PB_GET_ERROR(stream));-    return false;+  // Populate grpc_resolved_address.+  grpc_resolved_address addr;+  char* address_str = static_cast<char*>(gpr_malloc(address_strview.size + 1));+  memcpy(address_str, address_strview.data, address_strview.size);+  address_str[address_strview.size] = '\0';+  grpc_string_to_sockaddr(&addr, address_str, port);+  gpr_free(address_str);+  // Append the address to the list.+  list->emplace_back(addr, nullptr);+  return GRPC_ERROR_NONE;+}++grpc_error* LocalityParse(const XdsLocalityLbEndpoints* locality_lb_endpoints,+                          XdsLocalityInfo* locality_info) {+  upb::Arena arena;",This appears to be unused?,OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19306,292455977,2019-06-11T13:32:16Z,src/csharp/Grpc.Tools/build/_grpc/_Grpc.Tools.targets,"@@ -38,6 +38,7 @@       </Protobuf_Compile>       <Protobuf_Compile Condition="" '%(Protobuf_Compile.GrpcServices)' == 'Client' "">         <_GrpcOutputOptions>%(Protobuf_Compile._GrpcOutputOptions);no_server</_GrpcOutputOptions>+        <_GrpcOutputOptions Condition="" '%(Protobuf_Compile.ClientType)' == 'LiteClient' "">%(Protobuf_Compile._GrpcOutputOptions);lite_client</_GrpcOutputOptions>","You need to update https://github.com/grpc/grpc/blob/master/src/csharp/Grpc.Tools/build/_grpc/Grpc.CSharp.xml to define a new EnumProperty ""ClientType""?",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19259,292521788,2019-06-11T15:34:36Z,src/csharp/Grpc.Tools/ProtoCompile.cs,"@@ -211,7 +211,7 @@ public class ProtoCompile : ToolTask             new ErrorListFilter             {                 Pattern = new Regex(-                    pattern: ""(?'FILENAME'.+): ?(?'TEXT'.*)"",+                    pattern: ""^(?'FILENAME'.+?): ?(?'TEXT'.*)"",","I think we can't really do much better here. This rule is only a heuristic and if someone really wants to have .proto file called e.g. `""foo bar: the final version.proto""` we can't stop him. I think it's acceptable if VS error will be parsed incorrectly in such case.  In my experience the colon .proto file names would be less common that parenthesis (some editors create copies of files in form `foobar (copy 1).proto` so it's good to handle that case)the nongreedy version of filename group is good here because at least we won't spend too much time matching the file name if the error message is long.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19177,292545801,2019-06-11T16:22:46Z,tools/run_tests/run_tests_matrix.py,"@@ -536,6 +541,8 @@ def _runs_per_test_type(arg_str):         extra_args.append('--bq_result_table')         extra_args.append('%s' % args.bq_result_table)         extra_args.append('--measure_cpu_costs')+    if args.extra_args:+        extra_args.append('%s' % args.extra_args)","extra_args is a list and you are adding all extra args as just one item of the list. (`-r foo` will be added as just one arg, but it should be added as two separate items to the list: `['-r', 'foo']`. If this works, it's more of a concidence.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19182,292566368,2019-06-11T17:09:06Z,bazel/grpc_deps.bzl,"@@ -115,9 +115,9 @@ def grpc_deps():             url = ""https://boringssl.googlesource.com/boringssl/+archive/afc30d43eef92979b05776ec0963c9cede5fb80f.tar.gz"",         ) -    if ""com_github_madler_zlib"" not in native.existing_rules():","Yea. Because protobuf somehow expects @zlib//:zlib to be present, and I don't want to build zlib twice: https://github.com/protocolbuffers/protobuf/blob/master/BUILD#L22",
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/19310,292705487,2019-06-12T00:09:11Z,examples/python/debug/test/_debug_example_test.py,"@@ -0,0 +1,63 @@+# Copyright 2019 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Test for gRPC Python debug example.""""""++from __future__ import absolute_import+from __future__ import division+from __future__ import print_function++import logging+import unittest+from contextlib import contextmanager+import socket++from examples.python.debug import debug_server+from examples.python.debug import send_message+from examples.python.debug import get_stats++_LOGGER = logging.getLogger(__name__)+_LOGGER.setLevel(logging.INFO)++_FAILURE_RATE = 0.5+_NUMBER_OF_MESSAGES = 100+++@contextmanager+def get_free_loopback_tcp_port():","I'm not sure of the best way to deal with this, but I've noticed that we've duplicated this code a lot in both example code and test code. I wish we didn't have to copy-paste every time. I'm also not thrilled about including it in our API surface. Thoughts? Maybe we could create an entirely separate utility library for it?",
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/19218,292742090,2019-06-12T04:24:20Z,src/core/lib/security/security_connector/fake/fake_security_connector.cc,"@@ -102,39 +102,34 @@ class grpc_fake_channel_security_connector final         tsi_create_fake_handshaker(/*is_client=*/true), this));   } -  bool check_call_host(const char* host, grpc_auth_context* auth_context,+  bool check_call_host(grpc_core::StringView host,+                       grpc_auth_context* auth_context,                        grpc_closure* on_call_host_checked,                        grpc_error** error) override {-    char* authority_hostname = nullptr;-    char* authority_ignored_port = nullptr;-    char* target_hostname = nullptr;-    char* target_ignored_port = nullptr;-    gpr_split_host_port(host, &authority_hostname, &authority_ignored_port);-    gpr_split_host_port(target_, &target_hostname, &target_ignored_port);+    grpc_core::StringView authority_hostname;+    grpc_core::StringView authority_ignored_port;+    grpc_core::StringView target_hostname;+    grpc_core::StringView target_ignored_port;+    grpc_core::SplitHostPort(host, &authority_hostname,+                             &authority_ignored_port);+    grpc_core::SplitHostPort(target_, &target_hostname, &target_ignored_port);     if (target_name_override_ != nullptr) {-      char* fake_security_target_name_override_hostname = nullptr;-      char* fake_security_target_name_override_ignored_port = nullptr;-      gpr_split_host_port(target_name_override_,-                          &fake_security_target_name_override_hostname,-                          &fake_security_target_name_override_ignored_port);-      if (strcmp(authority_hostname,-                 fake_security_target_name_override_hostname) != 0) {+      grpc_core::StringView fake_security_target_name_override_hostname;+      grpc_core::StringView fake_security_target_name_override_ignored_port;+      grpc_core::SplitHostPort(+          target_name_override_, &fake_security_target_name_override_hostname,+          &fake_security_target_name_override_ignored_port);+      if (authority_hostname != fake_security_target_name_override_hostname) {         gpr_log(GPR_ERROR,                 ""Authority (host) '%s' != Fake Security Target override '%s'"",-                host, fake_security_target_name_override_hostname);+                host.data(), target_name_override_);","nit, s/target_name_override_/fake_security_target_name_override_hostname.data()",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19299,293122925,2019-06-12T21:20:07Z,src/python/grpcio/grpc/__init__.py,"@@ -1447,6 +1447,20 @@ def stop(self, grace):         """"""         raise NotImplementedError() +    def wait_for_termination(self, grace=None):+        """"""Block current thread until the server stops.++        The wait will not consume computational resources during blocking, and it+        will block indefinitely. There are two ways to unblock:++        1) Calling `stop` on the server in another thread;+        2) The `__del__` of the server object is invoked.++        Args:+          grace: A duration of time in seconds or None.","The `grace` variable is removed. Now, the `wait_for_termination` function accepts no argument.My original design is to replace our internal API which have both `delay` and `grace`. However, the semantic will become a lot messy. And it is hard to explain that:1) The `grace` variable set here is not necessary the source of truth, because other thread can call `server.Stop` as well;2) The `delay` variable will only work in main thread, what should it do in other thread;3) The semantic of `delay` is hard to define that which signal should it react to.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19310,293125605,2019-06-12T21:28:14Z,examples/python/debug/debug_server.py,"@@ -0,0 +1,91 @@+# Copyright 2019 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""The Python example of utilizing Channelz feature.""""""++from __future__ import absolute_import+from __future__ import division+from __future__ import print_function++import argparse+import logging+import time+from concurrent import futures+import random++import grpc+from grpc_channelz.v1 import channelz++from examples import helloworld_pb2+from examples import helloworld_pb2_grpc++_LOGGER = logging.getLogger(__name__)+_LOGGER.setLevel(logging.INFO)++_ONE_DAY_IN_SECONDS = 60 * 60 * 24","I'm not sure how long would that be. And it might be in ""experimental"" state for a while.It's a little bit controversial to recommend usage of an ""experimental"" API.I'll update all example code once the new API got in.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19310,293129186,2019-06-12T21:40:16Z,examples/python/debug/test/_debug_example_test.py,"@@ -0,0 +1,63 @@+# Copyright 2019 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Test for gRPC Python debug example.""""""++from __future__ import absolute_import+from __future__ import division+from __future__ import print_function++import logging+import unittest+from contextlib import contextmanager+import socket++from examples.python.debug import debug_server+from examples.python.debug import send_message+from examples.python.debug import get_stats++_LOGGER = logging.getLogger(__name__)+_LOGGER.setLevel(logging.INFO)++_FAILURE_RATE = 0.5+_NUMBER_OF_MESSAGES = 100+++@contextmanager+def get_free_loopback_tcp_port():","Alternatively, we can talk to our local port server. But it wouldn't make any sense to people who doesn't know about it.What kind of utility library are you talking about? 1) Like grpc-* packages? 2) Or a completely separate Python package; 3) Or a common utility module inside `grpcio-tests` that only we have access to?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19309,293160616,2019-06-12T23:48:56Z,src/core/lib/iomgr/cfstream_handle.cc,"@@ -188,7 +189,7 @@ void CFStreamHandle::Unref(const char* file, int line, const char* reason) {             reason, val, val - 1);   }   if (gpr_unref(&refcount_)) {","Rather than implementing your own ref-counting, I suggest having this inherit from `RefCounted<>`:https://github.com/grpc/grpc/blob/master/src/core/lib/gprpp/ref_counted.h#L169You can then use `RefCountedPtr<>` with it:https://github.com/grpc/grpc/blob/master/src/core/lib/gprpp/ref_counted_ptr.h",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19330,293411427,2019-06-13T14:32:51Z,src/core/lib/slice/slice_internal.h,"@@ -312,4 +312,21 @@ grpc_slice grpc_slice_from_moved_string(grpc_core::UniquePtr<char> p); // 0. All other slices will return the size of the allocated chars. size_t grpc_slice_memory_usage(grpc_slice s); +void grpc_slice_buffer_transfer(grpc_slice_buffer* src, grpc_slice_buffer* dst);+void grpc_do_slice_buffer_move_into(grpc_slice_buffer* src,","In the global C namespace, it's very important that functions are prefixed for the area of code that they belong to.  This name should start with `grpc_slice_buffer_`.",
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/19299,293471393,2019-06-13T16:33:50Z,src/python/grpcio/grpc/__init__.py,"@@ -1447,6 +1447,19 @@ def stop(self, grace):         """"""         raise NotImplementedError() +    def wait_for_termination(self):+        """"""Block current thread until the server stops.++        This is an EXPERIMENTAL API.++        The wait will not consume computational resources during blocking, and it+        will block indefinitely. There are two ways to unblock:","Nit: It's a bit contradictory to say it will block indefinitely and then to define to conditions under which it will stop blocking. How about ""...and it will block until one of the two following conditions are met:""",OK
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/19299,293523511,2019-06-13T18:40:43Z,src/python/grpcio/grpc/_server.py,"@@ -959,6 +958,17 @@ def add_secure_port(self, address, server_credentials):     def start(self):         _start(self._state) +    def wait_for_termination(self):+        termination_event = threading.Event()++        with self._state.lock:+            if self._state.stage is _ServerStage.STOPPED:+                raise ValueError('Failed to wait for a stopped server.')",Why raise an exception at all. If we are already stopped it should just return.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/18496,293574398,2019-06-13T21:00:00Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -1435,18 +1435,15 @@ ChannelData::ChannelData(grpc_channel_element_args* args, grpc_error** error)       std::move(target_uri), ProcessResolverResultLocked, this, error));   grpc_channel_args_destroy(new_args);   if (*error != GRPC_ERROR_NONE) {-    // Orphan the resolving LB policy and flush the exec_ctx to ensure-    // that it finishes shutting down.  This ensures that if we are-    // failing, we destroy the ClientChannelControlHelper (and thus-    // unref the channel stack) before we return.+    // Before we return, shut down the resolving LB policy, which destroys+    // the ClientChannelControlHelper and therefore unrefs the channel stack.     // TODO(roth): This is not a complete solution, because it only     // catches the case where channel stack initialization fails in this     // particular filter.  If there is a failure in a different filter, we     // will leave a dangling ref here, which can cause a crash.  Fortunately,     // in practice, there are no other filters that can cause failures in     // channel stack initialization, so this works for now.     resolving_lb_policy_.reset();","We're not technically in the combiner here, but it doesn't matter, because if we fail this early (we're still in the ChannelData ctor), there can't possibly be anything happening in any other thread yet.",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19299,293600237,2019-06-13T22:26:31Z,src/python/grpcio/grpc/_server.py,"@@ -959,6 +958,17 @@ def add_secure_port(self, address, server_credentials):     def start(self):         _start(self._state) +    def wait_for_termination(self):+        termination_event = threading.Event()++        with self._state.lock:+            if self._state.stage is _ServerStage.STOPPED:+                raise ValueError('Failed to wait for a stopped server.')",Make sense. And it still align with the semantic of blocking until the server is stopped.,
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/19299,293609674,2019-06-13T23:09:08Z,src/python/grpcio/grpc/_server.py,"@@ -764,7 +764,7 @@ def __init__(self, completion_queue, server, generic_handlers,         self.interceptor_pipeline = interceptor_pipeline         self.thread_pool = thread_pool         self.stage = _ServerStage.STOPPED-        self.shutdown_events = None+        self.shutdown_events = []","This is not giving applications access to `Event`; it's just simplifying your implementation (no locks, just a single event to keep track of all waiters). All of this belongs to the `_state` object, which is private, no?",OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/19343,293646624,2019-06-14T03:13:16Z,src/core/lib/slice/slice_buffer.cc,"@@ -87,13 +87,18 @@ void grpc_slice_buffer_destroy(grpc_slice_buffer* sb) {   } } -uint8_t* grpc_slice_buffer_tiny_add(grpc_slice_buffer* sb, size_t n) {+template <bool maybe_empty>+static uint8_t* tiny_add_internal(grpc_slice_buffer* sb, size_t n) {","did you try changing the code to something like the following?  compiler should be able to merge the `sb->count == 0` branches and with that you won't need a template param.```maybe_embiggen(sb);if (sb->count == 0) goto add_first;```Also note that when count is 0, calling maybe_embigen can (and probably does) make a difference because we would potentially reset the slices pointer and save ourselves some allocations.  So, probably pulling it up the stack is going to help too.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/19348,293901499,2019-06-14T17:15:54Z,include/grpcpp/impl/codegen/server_callback.h,"@@ -348,7 +348,8 @@ class ServerBidiReactor : public internal::ServerReactor {   private:   friend class ServerCallbackReaderWriter<Request, Response>;-  void BindStream(ServerCallbackReaderWriter<Request, Response>* stream) {+  virtual void BindStream(","non-abstract virtual functions in the private section probably deserve a comment, IMO. Because although ServerBidiReactor (and the other classes changed here) are meant to be overridden by the application-level programmer, private functions are not meant as such.",OK
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19343,294056085,2019-06-15T18:39:44Z,src/core/lib/slice/slice_buffer.cc,"@@ -87,13 +87,18 @@ void grpc_slice_buffer_destroy(grpc_slice_buffer* sb) {   } } -uint8_t* grpc_slice_buffer_tiny_add(grpc_slice_buffer* sb, size_t n) {+template <bool maybe_empty>+static uint8_t* tiny_add_internal(grpc_slice_buffer* sb, size_t n) {","Not yet, but will give it a shot.For hpack_enc, however, count will demonstrably never be 0. That's the main reason for the template parameter, to save that branch.For now, I'm happy to split this into two PRs; one which does the coalescing sans API change, which I think is a must do - and the other with the API change. That way we can also tease out whether the API change is worth the change in specific performance or not.",OK
2606303,klolos,https://api.github.com/repos/grpc/grpc/pulls/19329,294257705,2019-06-17T11:45:03Z,src/python/grpcio/grpc/_cython/_cygrpc/grpc_gevent.pxd.pxi,"@@ -102,7 +102,7 @@ cdef extern from ""src/core/lib/iomgr/timer_custom.h"": cdef extern from ""src/core/lib/iomgr/pollset_custom.h"":   struct grpc_custom_poller_vtable:     void (*init)()-    void (*poll)(size_t timeout_ms)+    grpc_error* (*poll)(size_t timeout_ms) except <grpc_error *>4","I'm afraid Cython does not allow using anything other than a literal there. I tried using a variable, a function call, a `const` variable etc, the compiler always complains (in fact, `const` [does not seem to work at all in declarations](https://stackoverflow.com/questions/23873652/how-to-use-const-in-cython)):```    cdef grpc_error* run_loop(size_t timeout_ms) except GRPC_ERROR_CANCELLED with gil:                                                       ^    ------------------------------------------------------------    src/python/grpcio/grpc/_cython/_cygrpc/grpc_gevent.pyx.pxi:388:52: Not allowed in a constant expression```One alternative that should work however would be to not rely on Cython's `except` syntax to return a value upon failure, but instead set the exception and return the value manually. This would look something like this:```try:    g_event.wait(timeout)    g_event.clear()    return grpc_error_none()except BaseException:    exc_info = sys.exc_info()    g_event.clear()    # Avoid running any Python code after setting the exception    cpython.PyErr_SetObject(exc_info[0], exc_info[1])    return grpc_error_cancelled()```",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19239,294419277,2019-06-17T17:53:34Z,src/core/ext/filters/http/message_compress/message_compress_filter.cc,"@@ -93,130 +103,102 @@ struct call_data {   grpc_closure on_send_message_next_done; }; -struct channel_data {-  /** The default, channel-level, compression algorithm */-  grpc_compression_algorithm default_compression_algorithm;-  /** Bitset of enabled compression algorithms */-  uint32_t enabled_algorithms_bitset;-  /** Supported compression algorithms */-  uint32_t supported_message_compression_algorithms;-  /** Supported stream compression algorithms */-  uint32_t supported_stream_compression_algorithms;-}; }  // namespace -static bool skip_compression(grpc_call_element* elem, uint32_t flags,-                             bool has_compression_algorithm) {+// Returns true if we should skip message compression for the current message.+static bool skip_message_compression(grpc_call_element* elem) {   call_data* calld = static_cast<call_data*>(elem->call_data);-  channel_data* channeld = static_cast<channel_data*>(elem->channel_data);-+  // If the flags of this message indicate that it shouldn't be compressed, we+  // skip message compression.+  uint32_t flags =+      calld->send_message_batch->payload->send_message.send_message->flags();   if (flags & (GRPC_WRITE_NO_COMPRESS | GRPC_WRITE_INTERNAL_COMPRESS)) {     return true;   }-  if (has_compression_algorithm) {-    if (calld->message_compression_algorithm == GRPC_MESSAGE_COMPRESS_NONE) {-      return true;-    }-    return false; /* we have an actual call-specific algorithm */-  }-  /* no per-call compression override */-  return channeld->default_compression_algorithm == GRPC_COMPRESS_NONE;+  // If this call doesn't have any message compression algorithm set, skip+  // message compression.+  return calld->message_compression_algorithm == GRPC_MESSAGE_COMPRESS_NONE; } -/** Filter initial metadata */-static grpc_error* process_send_initial_metadata(-    grpc_call_element* elem, grpc_metadata_batch* initial_metadata,-    bool* has_compression_algorithm) GRPC_MUST_USE_RESULT;-static grpc_error* process_send_initial_metadata(-    grpc_call_element* elem, grpc_metadata_batch* initial_metadata,-    bool* has_compression_algorithm) {-  call_data* calld = static_cast<call_data*>(elem->call_data);-  channel_data* channeld = static_cast<channel_data*>(elem->channel_data);-  *has_compression_algorithm = false;-  grpc_compression_algorithm compression_algorithm;-  grpc_stream_compression_algorithm stream_compression_algorithm =-      GRPC_STREAM_COMPRESS_NONE;+// Determines the compression algorithm from the initial metadata and the+// channel's default setting.+static grpc_compression_algorithm find_compression_algorithm(+    grpc_metadata_batch* initial_metadata, channel_data* channeld) {+  grpc_compression_algorithm compression_algorithm =+      channeld->default_compression_algorithm;   if (initial_metadata->idx.named.grpc_internal_encoding_request != nullptr) {+    // Parse the compression algorithm from the initial metadata.     grpc_mdelem md =         initial_metadata->idx.named.grpc_internal_encoding_request->md;-    if (GPR_UNLIKELY(!grpc_compression_algorithm_parse(-            GRPC_MDVALUE(md), &compression_algorithm))) {-      char* val = grpc_slice_to_c_string(GRPC_MDVALUE(md));-      gpr_log(GPR_ERROR,-              ""Invalid compression algorithm: '%s' (unknown). Ignoring."", val);-      gpr_free(val);-      calld->message_compression_algorithm = GRPC_MESSAGE_COMPRESS_NONE;-      stream_compression_algorithm = GRPC_STREAM_COMPRESS_NONE;-    }-    if (GPR_UNLIKELY(!GPR_BITGET(channeld->enabled_algorithms_bitset,-                                 compression_algorithm))) {-      char* val = grpc_slice_to_c_string(GRPC_MDVALUE(md));-      gpr_log(GPR_ERROR,-              ""Invalid compression algorithm: '%s' (previously disabled). ""-              ""Ignoring."",-              val);-      gpr_free(val);-      calld->message_compression_algorithm = GRPC_MESSAGE_COMPRESS_NONE;-      stream_compression_algorithm = GRPC_STREAM_COMPRESS_NONE;-    }-    *has_compression_algorithm = true;+    GPR_ASSERT(grpc_compression_algorithm_parse(GRPC_MDVALUE(md),+                                                &compression_algorithm));+    // Remove this metadata since it's an internal one (i.e., it won't be+    // transmitted out).     grpc_metadata_batch_remove(         initial_metadata,         initial_metadata->idx.named.grpc_internal_encoding_request);-    calld->message_compression_algorithm =-        grpc_compression_algorithm_to_message_compression_algorithm(-            compression_algorithm);-    stream_compression_algorithm =-        grpc_compression_algorithm_to_stream_compression_algorithm(-            compression_algorithm);-  } else {-    /* If no algorithm was found in the metadata and we aren't-     * exceptionally skipping compression, fall back to the channel-     * default */-    if (channeld->default_compression_algorithm != GRPC_COMPRESS_NONE) {-      calld->message_compression_algorithm =-          grpc_compression_algorithm_to_message_compression_algorithm(-              channeld->default_compression_algorithm);-      stream_compression_algorithm =-          grpc_compression_algorithm_to_stream_compression_algorithm(-              channeld->default_compression_algorithm);-    }-    *has_compression_algorithm = true;   }+  // Check if that algorithm is enabled. Note that GRPC_COMPRESS_NONE is always+  // enabled.+  // TODO(juanlishen): Maybe use channel default or abort() if the algorithm+  // from the initial metadata is disabled.+  if (GPR_LIKELY(GPR_BITGET(channeld->enabled_compression_algorithms_bitset,",How about moving this into the previous `if`? We have already checked whether the default algorithm is enabled (when constructing `call_data`) so no longer needed to check again here.,OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19239,294430296,2019-06-17T18:05:22Z,src/core/ext/filters/http/message_compress/message_compress_filter.cc,"@@ -93,130 +103,102 @@ struct call_data {   grpc_closure on_send_message_next_done; }; -struct channel_data {-  /** The default, channel-level, compression algorithm */-  grpc_compression_algorithm default_compression_algorithm;-  /** Bitset of enabled compression algorithms */-  uint32_t enabled_algorithms_bitset;-  /** Supported compression algorithms */-  uint32_t supported_message_compression_algorithms;-  /** Supported stream compression algorithms */-  uint32_t supported_stream_compression_algorithms;-}; }  // namespace -static bool skip_compression(grpc_call_element* elem, uint32_t flags,-                             bool has_compression_algorithm) {+// Returns true if we should skip message compression for the current message.+static bool skip_message_compression(grpc_call_element* elem) {   call_data* calld = static_cast<call_data*>(elem->call_data);-  channel_data* channeld = static_cast<channel_data*>(elem->channel_data);-+  // If the flags of this message indicate that it shouldn't be compressed, we+  // skip message compression.+  uint32_t flags =+      calld->send_message_batch->payload->send_message.send_message->flags();   if (flags & (GRPC_WRITE_NO_COMPRESS | GRPC_WRITE_INTERNAL_COMPRESS)) {     return true;   }-  if (has_compression_algorithm) {-    if (calld->message_compression_algorithm == GRPC_MESSAGE_COMPRESS_NONE) {-      return true;-    }-    return false; /* we have an actual call-specific algorithm */-  }-  /* no per-call compression override */-  return channeld->default_compression_algorithm == GRPC_COMPRESS_NONE;+  // If this call doesn't have any message compression algorithm set, skip+  // message compression.+  return calld->message_compression_algorithm == GRPC_MESSAGE_COMPRESS_NONE; } -/** Filter initial metadata */-static grpc_error* process_send_initial_metadata(-    grpc_call_element* elem, grpc_metadata_batch* initial_metadata,-    bool* has_compression_algorithm) GRPC_MUST_USE_RESULT;-static grpc_error* process_send_initial_metadata(-    grpc_call_element* elem, grpc_metadata_batch* initial_metadata,-    bool* has_compression_algorithm) {-  call_data* calld = static_cast<call_data*>(elem->call_data);-  channel_data* channeld = static_cast<channel_data*>(elem->channel_data);-  *has_compression_algorithm = false;-  grpc_compression_algorithm compression_algorithm;-  grpc_stream_compression_algorithm stream_compression_algorithm =-      GRPC_STREAM_COMPRESS_NONE;+// Determines the compression algorithm from the initial metadata and the+// channel's default setting.+static grpc_compression_algorithm find_compression_algorithm(+    grpc_metadata_batch* initial_metadata, channel_data* channeld) {+  grpc_compression_algorithm compression_algorithm =+      channeld->default_compression_algorithm;   if (initial_metadata->idx.named.grpc_internal_encoding_request != nullptr) {+    // Parse the compression algorithm from the initial metadata.     grpc_mdelem md =         initial_metadata->idx.named.grpc_internal_encoding_request->md;-    if (GPR_UNLIKELY(!grpc_compression_algorithm_parse(-            GRPC_MDVALUE(md), &compression_algorithm))) {-      char* val = grpc_slice_to_c_string(GRPC_MDVALUE(md));-      gpr_log(GPR_ERROR,-              ""Invalid compression algorithm: '%s' (unknown). Ignoring."", val);-      gpr_free(val);-      calld->message_compression_algorithm = GRPC_MESSAGE_COMPRESS_NONE;-      stream_compression_algorithm = GRPC_STREAM_COMPRESS_NONE;-    }-    if (GPR_UNLIKELY(!GPR_BITGET(channeld->enabled_algorithms_bitset,-                                 compression_algorithm))) {-      char* val = grpc_slice_to_c_string(GRPC_MDVALUE(md));-      gpr_log(GPR_ERROR,-              ""Invalid compression algorithm: '%s' (previously disabled). ""-              ""Ignoring."",-              val);-      gpr_free(val);-      calld->message_compression_algorithm = GRPC_MESSAGE_COMPRESS_NONE;-      stream_compression_algorithm = GRPC_STREAM_COMPRESS_NONE;-    }-    *has_compression_algorithm = true;+    GPR_ASSERT(grpc_compression_algorithm_parse(GRPC_MDVALUE(md),+                                                &compression_algorithm));+    // Remove this metadata since it's an internal one (i.e., it won't be+    // transmitted out).     grpc_metadata_batch_remove(         initial_metadata,         initial_metadata->idx.named.grpc_internal_encoding_request);-    calld->message_compression_algorithm =-        grpc_compression_algorithm_to_message_compression_algorithm(-            compression_algorithm);-    stream_compression_algorithm =-        grpc_compression_algorithm_to_stream_compression_algorithm(-            compression_algorithm);-  } else {-    /* If no algorithm was found in the metadata and we aren't-     * exceptionally skipping compression, fall back to the channel-     * default */-    if (channeld->default_compression_algorithm != GRPC_COMPRESS_NONE) {-      calld->message_compression_algorithm =-          grpc_compression_algorithm_to_message_compression_algorithm(-              channeld->default_compression_algorithm);-      stream_compression_algorithm =-          grpc_compression_algorithm_to_stream_compression_algorithm(-              channeld->default_compression_algorithm);-    }-    *has_compression_algorithm = true;   }+  // Check if that algorithm is enabled. Note that GRPC_COMPRESS_NONE is always+  // enabled.+  // TODO(juanlishen): Maybe use channel default or abort() if the algorithm+  // from the initial metadata is disabled.+  if (GPR_LIKELY(GPR_BITGET(channeld->enabled_compression_algorithms_bitset,+                            compression_algorithm))) {+    return compression_algorithm;+  }+  const char* algorithm_name;+  grpc_compression_algorithm_name(compression_algorithm, &algorithm_name);+  gpr_log(GPR_ERROR,+          ""Invalid compression algorithm: '%s' (previously disabled). ""+          ""Will not compress."",+          algorithm_name);+  return GRPC_COMPRESS_NONE;+} +static grpc_error* process_send_initial_metadata(+    grpc_call_element* elem,+    grpc_metadata_batch* initial_metadata) GRPC_MUST_USE_RESULT;+static grpc_error* process_send_initial_metadata(+    grpc_call_element* elem, grpc_metadata_batch* initial_metadata) {+  call_data* calld = static_cast<call_data*>(elem->call_data);+  channel_data* channeld = static_cast<channel_data*>(elem->channel_data);+  // Find the compression algorithm.+  grpc_compression_algorithm compression_algorithm =+      find_compression_algorithm(initial_metadata, channeld);+  // Note that at most one of the following algorithms can be set.+  calld->message_compression_algorithm =+      grpc_compression_algorithm_to_message_compression_algorithm(+          compression_algorithm);+  grpc_stream_compression_algorithm stream_compression_algorithm =+      grpc_compression_algorithm_to_stream_compression_algorithm(+          compression_algorithm);+  // Hint compression algorithm.   grpc_error* error = GRPC_ERROR_NONE;-  /* hint compression algorithm */-  if (stream_compression_algorithm != GRPC_STREAM_COMPRESS_NONE) {+  if (calld->message_compression_algorithm != GRPC_MESSAGE_COMPRESS_NONE) {","So the logic here needs think twice: if the channel's default compression algorithm is message compression, but the call's initial metadata says it should use stream compression, which one to use? The current logic here says ""use the default compression algorithm"", but I think the expected behavior should be to use stream compression.",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19239,294435002,2019-06-17T18:10:33Z,src/core/ext/filters/http/message_compress/message_compress_filter.cc,"@@ -45,18 +45,30 @@ static void send_message_on_complete(void* arg, grpc_error* error); static void on_send_message_next_done(void* arg, grpc_error* error);  namespace {-enum initial_metadata_state {-  // Initial metadata not yet seen.-  INITIAL_METADATA_UNSEEN = 0,-  // Initial metadata seen; compression algorithm set.-  HAS_COMPRESSION_ALGORITHM,-  // Initial metadata seen; no compression algorithm set.-  NO_COMPRESSION_ALGORITHM,++struct channel_data {+  /** The default, channel-level, compression algorithm */+  grpc_compression_algorithm default_compression_algorithm;+  /** Bitset of enabled compression algorithms */+  uint32_t enabled_compression_algorithms_bitset;+  /** Supported compression algorithms */+  uint32_t supported_message_compression_algorithms;",What I mean is this looks more appropriate to be constants rather than variables in the channel data.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19220,294486408,2019-06-17T19:41:05Z,src/core/lib/slice/slice_internal.h,"@@ -168,9 +168,12 @@ struct grpc_slice_refcount {   void* destroy_fn_arg_ = nullptr; }; +static_assert(std::is_trivially_destructible<grpc_slice_refcount>::value,","I don't think we need this assertion, since we have the one for `kNoopRefcount` elsewhere.  This check is really about the instance being defined as a global variable, not about the class itself.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19282,294809792,2019-06-18T13:03:55Z,examples/csharp/HelloworldUWP/GreeterClient/GreeterClient.csproj,"@@ -0,0 +1,176 @@+﻿<?xml version=""1.0"" encoding=""utf-8""?>+<Project ToolsVersion=""15.0"" DefaultTargets=""Build"" xmlns=""http://schemas.microsoft.com/developer/msbuild/2003"">+  <Import Project=""$(MSBuildExtensionsPath)\$(MSBuildToolsVersion)\Microsoft.Common.props"" Condition=""Exists('$(MSBuildExtensionsPath)\$(MSBuildToolsVersion)\Microsoft.Common.props')"" />+  <PropertyGroup>+    <Configuration Condition="" '$(Configuration)' == '' "">Debug</Configuration>+    <Platform Condition="" '$(Platform)' == '' "">x86</Platform>+    <ProjectGuid>{C39F18D7-5058-4DCC-81BF-97079B1089AC}</ProjectGuid>+    <OutputType>AppContainerExe</OutputType>+    <AppDesignerFolder>Properties</AppDesignerFolder>+    <RootNamespace>GreeterClient</RootNamespace>+    <AssemblyName>GreeterClient</AssemblyName>+    <DefaultLanguage>en-US</DefaultLanguage>+    <TargetPlatformIdentifier>UAP</TargetPlatformIdentifier>+    <TargetPlatformVersion Condition="" '$(TargetPlatformVersion)' == '' "">10.0.17763.0</TargetPlatformVersion>+    <TargetPlatformMinVersion>10.0.17763.0</TargetPlatformMinVersion>+    <MinimumVisualStudioVersion>14</MinimumVisualStudioVersion>+    <FileAlignment>512</FileAlignment>+    <ProjectTypeGuids>{A5A43C5B-DE2A-4C0C-9213-0A381AF9435A};{FAE04EC0-301F-11D3-BF4B-00C04F79EFBC}</ProjectTypeGuids>+    <WindowsXamlEnableOverview>true</WindowsXamlEnableOverview>+  </PropertyGroup>+  <PropertyGroup Condition=""'$(Configuration)|$(Platform)' == 'Debug|x86'"">+    <DebugSymbols>true</DebugSymbols>+    <OutputPath>bin\x86\Debug\</OutputPath>+    <DefineConstants>DEBUG;TRACE;NETFX_CORE;WINDOWS_UWP</DefineConstants>+    <NoWarn>;2008</NoWarn>+    <DebugType>full</DebugType>+    <PlatformTarget>x86</PlatformTarget>+    <UseVSHostingProcess>false</UseVSHostingProcess>+    <ErrorReport>prompt</ErrorReport>+    <Prefer32Bit>true</Prefer32Bit>+  </PropertyGroup>+  <PropertyGroup Condition=""'$(Configuration)|$(Platform)' == 'Release|x86'"">+    <OutputPath>bin\x86\Release\</OutputPath>+    <DefineConstants>TRACE;NETFX_CORE;WINDOWS_UWP</DefineConstants>+    <Optimize>true</Optimize>+    <NoWarn>;2008</NoWarn>+    <DebugType>pdbonly</DebugType>+    <PlatformTarget>x86</PlatformTarget>+    <UseVSHostingProcess>false</UseVSHostingProcess>+    <ErrorReport>prompt</ErrorReport>+    <Prefer32Bit>true</Prefer32Bit>+    <UseDotNetNativeToolchain>true</UseDotNetNativeToolchain>+  </PropertyGroup>+  <PropertyGroup Condition=""'$(Configuration)|$(Platform)' == 'Debug|ARM'"">+    <DebugSymbols>true</DebugSymbols>+    <OutputPath>bin\ARM\Debug\</OutputPath>+    <DefineConstants>DEBUG;TRACE;NETFX_CORE;WINDOWS_UWP</DefineConstants>+    <NoWarn>;2008</NoWarn>+    <DebugType>full</DebugType>+    <PlatformTarget>ARM</PlatformTarget>+    <UseVSHostingProcess>false</UseVSHostingProcess>+    <ErrorReport>prompt</ErrorReport>+    <Prefer32Bit>true</Prefer32Bit>+  </PropertyGroup>+  <PropertyGroup Condition=""'$(Configuration)|$(Platform)' == 'Release|ARM'"">+    <OutputPath>bin\ARM\Release\</OutputPath>+    <DefineConstants>TRACE;NETFX_CORE;WINDOWS_UWP</DefineConstants>+    <Optimize>true</Optimize>+    <NoWarn>;2008</NoWarn>+    <DebugType>pdbonly</DebugType>+    <PlatformTarget>ARM</PlatformTarget>+    <UseVSHostingProcess>false</UseVSHostingProcess>+    <ErrorReport>prompt</ErrorReport>+    <Prefer32Bit>true</Prefer32Bit>+    <UseDotNetNativeToolchain>true</UseDotNetNativeToolchain>+  </PropertyGroup>+  <PropertyGroup Condition=""'$(Configuration)|$(Platform)' == 'Debug|ARM64'"">+    <DebugSymbols>true</DebugSymbols>+    <OutputPath>bin\ARM64\Debug\</OutputPath>+    <DefineConstants>DEBUG;TRACE;NETFX_CORE;WINDOWS_UWP</DefineConstants>+    <NoWarn>;2008</NoWarn>+    <DebugType>full</DebugType>+    <PlatformTarget>ARM64</PlatformTarget>+    <UseVSHostingProcess>false</UseVSHostingProcess>+    <ErrorReport>prompt</ErrorReport>+    <Prefer32Bit>true</Prefer32Bit>+    <UseDotNetNativeToolchain>true</UseDotNetNativeToolchain>+  </PropertyGroup>+  <PropertyGroup Condition=""'$(Configuration)|$(Platform)' == 'Release|ARM64'"">+    <OutputPath>bin\ARM64\Release\</OutputPath>+    <DefineConstants>TRACE;NETFX_CORE;WINDOWS_UWP</DefineConstants>+    <Optimize>true</Optimize>+    <NoWarn>;2008</NoWarn>+    <DebugType>pdbonly</DebugType>+    <PlatformTarget>ARM64</PlatformTarget>+    <UseVSHostingProcess>false</UseVSHostingProcess>+    <ErrorReport>prompt</ErrorReport>+    <Prefer32Bit>true</Prefer32Bit>+    <UseDotNetNativeToolchain>true</UseDotNetNativeToolchain>+  </PropertyGroup>+  <PropertyGroup Condition=""'$(Configuration)|$(Platform)' == 'Debug|x64'"">+    <DebugSymbols>true</DebugSymbols>+    <OutputPath>bin\x64\Debug\</OutputPath>+    <DefineConstants>DEBUG;TRACE;NETFX_CORE;WINDOWS_UWP</DefineConstants>+    <NoWarn>;2008</NoWarn>+    <DebugType>full</DebugType>+    <PlatformTarget>x64</PlatformTarget>+    <UseVSHostingProcess>false</UseVSHostingProcess>+    <ErrorReport>prompt</ErrorReport>+    <Prefer32Bit>true</Prefer32Bit>+  </PropertyGroup>+  <PropertyGroup Condition=""'$(Configuration)|$(Platform)' == 'Release|x64'"">+    <OutputPath>bin\x64\Release\</OutputPath>+    <DefineConstants>TRACE;NETFX_CORE;WINDOWS_UWP</DefineConstants>+    <Optimize>true</Optimize>+    <NoWarn>;2008</NoWarn>+    <DebugType>pdbonly</DebugType>+    <PlatformTarget>x64</PlatformTarget>+    <UseVSHostingProcess>false</UseVSHostingProcess>+    <ErrorReport>prompt</ErrorReport>+    <Prefer32Bit>true</Prefer32Bit>+    <UseDotNetNativeToolchain>true</UseDotNetNativeToolchain>+  </PropertyGroup>+  <PropertyGroup>+    <RestoreProjectStyle>PackageReference</RestoreProjectStyle>+  </PropertyGroup>+  <ItemGroup>+    <Compile Include=""App.xaml.cs"">+      <DependentUpon>App.xaml</DependentUpon>+    </Compile>+    <Compile Include=""MainPage.xaml.cs"">+      <DependentUpon>MainPage.xaml</DependentUpon>+    </Compile>+    <Compile Include=""Pregenerated Client Stubs\Greet.cs"" />+    <Compile Include=""Pregenerated Client Stubs\GreetGrpc.cs"" />+    <Compile Include=""Properties\AssemblyInfo.cs"" />+  </ItemGroup>+  <ItemGroup>+    <AppxManifest Include=""Package.appxmanifest"">+      <SubType>Designer</SubType>+    </AppxManifest>+  </ItemGroup>+  <ItemGroup>+    <Content Include=""Assets\grpc-logo.png"" />","I'd imagine having a more minimalistic example. A big portion of the example are .png files that are not really important for demonstrating the functionality, but only make the example more complicated. Please try to minimize the amount of boilerplate.",OK
2793282,veblush,https://api.github.com/repos/grpc/grpc/pulls/19376,295053108,2019-06-18T22:21:02Z,test/core/bad_client/tests/bad_streaming_id.cc,"@@ -0,0 +1,132 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <string>++#include <gtest/gtest.h>++#include <grpc/support/string_util.h>+#include ""src/core/lib/surface/server.h""+#include ""test/core/bad_client/bad_client.h""++#define HEADER_FRAME_ID_1                                                  \","Would it be better to place this in the test function to make it clearer? like```TEST(BadStreamingId, RegularHeader) {  grpc_bad_client_arg args[2];  args[0] = connection_preface_arg;  args[1].client_validator = nullptr;  SET_CLIENT_PAYLOAD(     args[1],       ""~~~~"")  grpc_run_bad_client_test(verifier, args, 2, GRPC_BAD_CLIENT_DISCONNECT);}```Also you can use C preprocessor to concat given string literals. [link](https://stackoverflow.com/questions/5106280/string-concatenation-using-preprocessor)",OK
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/19376,295068346,2019-06-18T23:26:12Z,test/core/bad_client/tests/bad_streaming_id.cc,"@@ -0,0 +1,132 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <string>++#include <gtest/gtest.h>++#include <grpc/support/string_util.h>+#include ""src/core/lib/surface/server.h""+#include ""test/core/bad_client/bad_client.h""++#define HEADER_FRAME_ID_1                                                  \","To avoid code duplication, i made it a macro. I intended to use the same frames at multiple places.Which string literals are you suggesting concatenation for?",
2793282,veblush,https://api.github.com/repos/grpc/grpc/pulls/19376,295571321,2019-06-20T00:11:48Z,test/core/bad_client/tests/bad_streaming_id.cc,"@@ -0,0 +1,132 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <string>++#include <gtest/gtest.h>++#include <grpc/support/string_util.h>+#include ""src/core/lib/surface/server.h""+#include ""test/core/bad_client/bad_client.h""++#define HEADER_FRAME_ID_1                                                  \","Ah you already used it for concatenation.``` ""HEADER""                                                                 \ ""\x10\x07:scheme\x04http""                                                \ ""\x10\x07:method\x04POST""                                                \```Literal \ had to be used here because it's part of macro but it might not be necessary once it's used a parameter for a macro.",OK
28123841,guantaol,https://api.github.com/repos/grpc/grpc/pulls/19358,296039524,2019-06-20T22:37:33Z,src/core/lib/iomgr/executor/mpmcqueue.h,"@@ -0,0 +1,130 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_IOMGR_EXECUTOR_MPMCQUEUE_H+#define GRPC_CORE_LIB_IOMGR_EXECUTOR_MPMCQUEUE_H++#include <grpc/support/port_platform.h>++#include <grpc/support/alloc.h>+#include <grpc/support/time.h>++#include ""src/core/lib/debug/stats.h""+#include ""src/core/lib/gprpp/abstract.h""+#include ""src/core/lib/gprpp/atomic.h""+#include ""src/core/lib/gprpp/sync.h""++namespace grpc_core {++extern DebugOnlyTraceFlag thread_pool_trace;++// Abstract base class of a MPMC queue interface+class MPMCQueueInterface {+ public:+  virtual ~MPMCQueueInterface() {}++  // Put elem into queue immediately at the end of queue.+  // This might cause to block on full queue depending on implementation.+  virtual void Put(void* elem) GRPC_ABSTRACT;++  // Remove the oldest element from the queue and return it.+  // This might cause to block on empty queue depending on implementation.+  virtual void* Get() GRPC_ABSTRACT;++  // Return number of elements in the queue currently+  virtual int count() const GRPC_ABSTRACT;++  GRPC_ABSTRACT_BASE_CLASS+};++class MPMCQueue : public MPMCQueueInterface {+ public:+  // Create a new Multiple-Producer-Multiple-Consumer Queue. The queue created+  // will have infinite length.+  MPMCQueue();++  // Release all resources hold by the queue. The queue must be empty, and no+  // one waiting on conditional variables.+  ~MPMCQueue();++  // Put elem into queue immediately at the end of queue. Since the queue has+  // infinite length, this routine will never block and should never fail.+  void Put(void* elem);++  // Remove the oldest element from the queue and return it.+  // This routine will cause the thread to block if queue is currently empty.+  void* Get();++  // Return number of elements in queue currently.+  // There might be concurrently add/remove on queue, so count might change+  // quickly.+  int count() const { return count_.Load(MemoryOrder::RELAXED); }++  GRPC_ABSTRACT_BASE_CLASS",This is only needed in abstract base classes.,
28123841,guantaol,https://api.github.com/repos/grpc/grpc/pulls/19358,296053584,2019-06-20T23:51:54Z,test/core/iomgr/mpmcqueue_test.cc,"@@ -0,0 +1,231 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/core/lib/iomgr/executor/mpmcqueue.h""++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>++#include ""src/core/lib/gpr/useful.h""+#include ""src/core/lib/gprpp/thd.h""+#include ""test/core/util/test_config.h""++#define THREAD_SMALL_ITERATION 100+#define THREAD_LARGE_ITERATION 10000++static void test_no_op(void) {+  gpr_log(GPR_DEBUG, ""test_no_op"");+  grpc_core::MPMCQueue mpmcqueue;+  gpr_log(GPR_DEBUG, ""Checking count..."");+  GPR_ASSERT(mpmcqueue.count() == 0);+  gpr_log(GPR_DEBUG, ""Done."");+}++// Testing items for queue+struct WorkItem {+  int index;+  bool done;++  WorkItem(int i) : index(i) { done = false; }+};++static void test_small_queue(void) {",This can be combined with test_large_queue.,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19428,296264346,2019-06-21T14:38:53Z,src/core/ext/transport/chttp2/transport/chttp2_transport.cc,"@@ -1194,6 +1196,13 @@ static void maybe_start_some_streams(grpc_chttp2_transport* t) {         GPR_INFO, ""HTTP:%s: Allocating new grpc_chttp2_stream %p to id %d"",         t->is_client ? ""CLI"" : ""SVR"", s, t->next_stream_id)); +    if (t->goaway_error != GRPC_ERROR_NONE) {+      gpr_log(GPR_ERROR,+              ""CAUTION: Starting new streams after receiving a GOAWAY frame. ""","This seems overly verbose to always report, especially with GRP_ERROR, since it's really a completely normal condition.  Maybe just log this under a tracer?",OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19412,296330080,2019-06-21T17:38:15Z,bazel/grpc_deps.bzl,"@@ -66,11 +66,6 @@ def grpc_deps():         actual = ""@com_github_google_googletest//:gtest"",     ) -    native.bind(","In v1.8.1, gtest includes gmock. https://github.com/google/googletest/blob/release-1.8.1/BUILD.bazel#L56. ",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/19428,296383923,2019-06-21T20:28:53Z,src/core/ext/transport/chttp2/transport/chttp2_transport.cc,"@@ -1194,6 +1196,13 @@ static void maybe_start_some_streams(grpc_chttp2_transport* t) {         GPR_INFO, ""HTTP:%s: Allocating new grpc_chttp2_stream %p to id %d"",         t->is_client ? ""CLI"" : ""SVR"", s, t->next_stream_id)); +    if (t->goaway_error != GRPC_ERROR_NONE) {+      gpr_log(GPR_ERROR,+              ""CAUTION: Starting new streams after receiving a GOAWAY frame. ""","Given that the HTTP2 spec says, ""Receivers of a GOAWAY frame MUST NOT open   additional streams on the connection, although a new connection can   be established for new streams."", this is NOT a normal condition, and would be considered as bad behavior by a client.",
28123841,guantaol,https://api.github.com/repos/grpc/grpc/pulls/19358,296401874,2019-06-21T21:36:50Z,BUILD,"@@ -837,6 +837,7 @@ grpc_cc_library(         ""src/core/lib/iomgr/tcp_server_windows.cc"",         ""src/core/lib/iomgr/tcp_uv.cc"",         ""src/core/lib/iomgr/tcp_windows.cc"",+        ""src/core/lib/iomgr/executor/mpmcqueue.cc"",",This list is sorted by alphabetical order.,
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19427,296405551,2019-06-21T21:54:37Z,src/core/ext/filters/client_channel/health/health_check_client.cc,"@@ -354,7 +354,8 @@ void HealthCheckClient::CallState::StartCall() {   grpc_metadata_batch_init(&send_initial_metadata_);   error = grpc_metadata_batch_add_head(       &send_initial_metadata_, &path_metadata_storage_,-      grpc_mdelem_from_slices(+      // TODO(arjunroy): They're both static.",The fastpath I have right now assumes a static first parameter and an interned second parameter - a fairly common occurrence. In this case both inputs are static so I could create a fastpath that assumes even more - but I have not done so thus far. So I'm just using the fastpath I've already created (which does a couple more ops than necessary for this case but is correct).,OK
28123841,guantaol,https://api.github.com/repos/grpc/grpc/pulls/19358,296414104,2019-06-21T22:43:21Z,src/core/lib/iomgr/executor/mpmcqueue.cc,"@@ -0,0 +1,130 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/support/port_platform.h>++#include ""src/core/lib/iomgr/executor/mpmcqueue.h""++#include <grpc/support/alloc.h>+#include <grpc/support/cpu.h>+#include <grpc/support/log.h>+#include <grpc/support/sync.h>+#include <grpc/support/time.h>+#include <inttypes.h>+#include <string.h>++#include ""src/core/lib/debug/stats.h""+#include ""src/core/lib/gprpp/memory.h""+#include ""src/core/lib/gprpp/sync.h""++namespace grpc_core {++DebugOnlyTraceFlag thread_pool(false, ""thread_pool_trace"");++inline void* InfLenFIFOQueue::PopFront() {+  void* result = queue_head_->content;+  Node* head_to_remove = queue_head_;+  queue_head_ = queue_head_->next;++  count_.FetchSub(1, MemoryOrder::RELAXED);++  if (GRPC_TRACE_FLAG_ENABLED(thread_pool)) {+    gpr_timespec wait_time =+        gpr_time_sub(gpr_now(GPR_CLOCK_PRECISE), head_to_remove->insert_time);++    // Updates Stats info+    stats_.num_completed++;+    stats_.total_queue_cycles =+        gpr_time_add(stats_.total_queue_cycles, wait_time);+    stats_.max_queue_cycles = gpr_time_max(+        gpr_convert_clock_type(stats_.max_queue_cycles, GPR_TIMESPAN),+        wait_time);++    if (count_.Load(MemoryOrder::RELAXED) == 0) {+      stats_.busy_time_cycles =+          gpr_time_add(stats_.busy_time_cycles,+                       gpr_time_sub(gpr_now(GPR_CLOCK_PRECISE), busy_time));+    }++    gpr_log(GPR_INFO,+            ""[InfLenFIFOQueue Get] num_completed:        %"" PRIu64+            "" total_queue_cycles: %"" PRId32 "" max_queue_cycles:   %"" PRId32+            "" busy_time_cycles:   %"" PRId32,+            stats_.num_completed, gpr_time_to_millis(stats_.total_queue_cycles),+            gpr_time_to_millis(stats_.max_queue_cycles),+            gpr_time_to_millis(stats_.busy_time_cycles));+  }++  Delete(head_to_remove);+  // Singal waiting thread+  if (count_.Load(MemoryOrder::RELAXED) > 0 && num_waiters_ > 0) {+    wait_nonempty_.Signal();+  }++  return result;+}++InfLenFIFOQueue::InfLenFIFOQueue()+    : num_waiters_(0), queue_head_(nullptr), queue_tail_(nullptr) {}","If you prefer setting default values for class members (like count_), let us keep it consistent.",
28123841,guantaol,https://api.github.com/repos/grpc/grpc/pulls/19358,296419265,2019-06-21T23:17:30Z,test/core/iomgr/mpmcqueue_test.cc,"@@ -0,0 +1,196 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/core/lib/iomgr/executor/mpmcqueue.h""++#include <grpc/grpc.h>+#include <grpc/support/alloc.h>+#include <grpc/support/log.h>++#include ""src/core/lib/gpr/useful.h""+#include ""src/core/lib/gprpp/thd.h""+#include ""test/core/util/test_config.h""++#define THREAD_SMALL_ITERATION 100+#define THREAD_LARGE_ITERATION 10000++// Testing items for queue+struct WorkItem {+  int index;+  bool done;++  WorkItem(int i) : index(i) { done = false; }+};++// Thread for put items into queue+class ProducerThread {+ public:+  ProducerThread(grpc_core::InfLenFIFOQueue* queue, int start_index,+                 int num_items)+      : start_index_(start_index), num_items_(num_items), queue_(queue) {+    items_ = nullptr;+    thd_ = grpc_core::Thread(+        ""mpmcq_test_mt_put_thd"",+        [](void* th) { static_cast<ProducerThread*>(th)->Run(); }, this);+  }+  ~ProducerThread() {+    for (int i = 0; i < num_items_; ++i) {+      GPR_ASSERT(items_[i]->done);+      delete items_[i];+    }+    delete[] items_;+  }++  void Start() { thd_.Start(); }+  void Join() { thd_.Join(); }++ private:+  void Run() {+    items_ = new WorkItem*[num_items_];+    for (int i = 0; i < num_items_; ++i) {+      items_[i] = new WorkItem(start_index_ + i);+      queue_->Put(items_[i]);+    }+  }++  int start_index_;+  int num_items_;+  grpc_core::InfLenFIFOQueue* queue_;+  grpc_core::Thread thd_;+  WorkItem** items_;+};++static void ConsumerThread(void* args) {",Any reason not to make ConsumerThread a class?,OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/18607,296865803,2019-06-24T18:51:28Z,tools/run_tests/sanity/sanity_tests.yaml,"@@ -24,4 +24,5 @@ - script: tools/distrib/yapf_code.sh - script: tools/distrib/python/check_grpcio_tools.py - script: tools/distrib/check_shadow_boringssl_symbol_list.sh+- script: tools/distrib/check_protobuf_pod_version.sh   cpu_cost: 1000",I think you need to reorder L27 and L28. Otherwise `cpu_cost: 1000` will be applied to `check_protobuf_pod_version.sh` instead of `check_shadow_boringssl_symbol_list.sh`,OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19395,296962217,2019-06-25T00:09:57Z,test/cpp/codegen/proto_utils_test.cc,"@@ -136,36 +147,46 @@ void BufferWriterTest(int block_size, int total_size, int backup_size) {   grpc_byte_buffer_reader_destroy(&reader); } -TEST(WriterTest, TinyBlockTinyBackup) {+class WriterTest : public ::testing::Test {+ protected:+  static void SetUpTestCase() {+    grpc::internal::GrpcLibraryInitializer init;+    init.summon();+    grpc::GrpcLibraryCodegen lib;+    // Ensure the ProtoBufferWriter internals are initialized.+    grpc_init();+  }++  static void TearDownTestCase() { grpc_shutdown(); }+};++TEST_F(WriterTest, TinyBlockTinyBackup) {   for (int i = 2; i < static_cast<int> GRPC_SLICE_INLINED_SIZE; i++) {     BufferWriterTest(i, 256, 1);   } } -TEST(WriterTest, SmallBlockTinyBackup) { BufferWriterTest(64, 256, 1); }+TEST_F(WriterTest, SmallBlockTinyBackup) { BufferWriterTest(64, 256, 1); } -TEST(WriterTest, SmallBlockNoBackup) { BufferWriterTest(64, 256, 0); }+TEST_F(WriterTest, SmallBlockNoBackup) { BufferWriterTest(64, 256, 0); } -TEST(WriterTest, SmallBlockFullBackup) { BufferWriterTest(64, 256, 64); }+TEST_F(WriterTest, SmallBlockFullBackup) { BufferWriterTest(64, 256, 64); } -TEST(WriterTest, LargeBlockTinyBackup) { BufferWriterTest(4096, 8192, 1); }+TEST_F(WriterTest, LargeBlockTinyBackup) { BufferWriterTest(4096, 8192, 1); } -TEST(WriterTest, LargeBlockNoBackup) { BufferWriterTest(4096, 8192, 0); }+TEST_F(WriterTest, LargeBlockNoBackup) { BufferWriterTest(4096, 8192, 0); } -TEST(WriterTest, LargeBlockFullBackup) { BufferWriterTest(4096, 8192, 4096); }+TEST_F(WriterTest, LargeBlockFullBackup) { BufferWriterTest(4096, 8192, 4096); } -TEST(WriterTest, LargeBlockLargeBackup) { BufferWriterTest(4096, 8192, 4095); }+TEST_F(WriterTest, LargeBlockLargeBackup) {+  BufferWriterTest(4096, 8192, 4095);+}  }  // namespace }  // namespace internal }  // namespace grpc  int main(int argc, char** argv) {-  // Ensure the ProtoBufferWriter internals are initialized.-  grpc::internal::GrpcLibraryInitializer init;-  init.summon();-  grpc::GrpcLibraryCodegen lib;-   ::testing::InitGoogleTest(&argc, argv);","`main()` is executed when the test is run on non-iOS platforms, so these lines are still required. On iOS, [GTMGoogleTestRunner](https://github.com/google/google-toolbox-for-mac/blob/master/UnitTesting/GTMGoogleTestRunner.mm) calls [InitGoogleTest](https://github.com/google/google-toolbox-for-mac/blob/master/UnitTesting/GTMGoogleTestRunner.mm#L151) and [RUN_ALL_TESTS](https://github.com/google/google-toolbox-for-mac/blob/master/UnitTesting/GTMGoogleTestRunner.mm#L230)",OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/19456,296963430,2019-06-25T00:16:53Z,examples/python/auth/customize_auth_server.py,"@@ -0,0 +1,115 @@+# Copyright 2019 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Server of the Python example of customizing authentication mechanism.""""""++from __future__ import absolute_import+from __future__ import division+from __future__ import print_function++import argparse+import contextlib+import logging+import os+import time+from concurrent import futures++import grpc+from examples import helloworld_pb2, helloworld_pb2_grpc+from examples.python.auth import _credentials++_LOGGER = logging.getLogger(__name__)+_LOGGER.setLevel(logging.INFO)++_ONE_DAY_IN_SECONDS = 60 * 60 * 24++_LISTEN_ADDRESS_TEMPLATE = 'localhost:%d'+_SIGNATURE_HEADER_KEY = 'x-signautre'+++class SignatureValidationInterceptor(grpc.ServerInterceptor):++    def __init__(self):++        def abort(ignored_request, context):+            context.abort(grpc.StatusCode.UNAUTHENTICATED, 'Invalid signature')++        self._abortion = grpc.unary_unary_rpc_method_handler(abort)++    def intercept_service(self, continuation, handler_call_details):+        # Example HandlerCallDetails object:+        #     _HandlerCallDetails(+        #       method=u'/helloworld.Greeter/SayHello',+        #       invocation_metadata=...)+        method_name = handler_call_details.method.split('/')[-1]+        expected_metadata = (_SIGNATURE_HEADER_KEY, method_name[::-1])+        if expected_metadata in handler_call_details.invocation_metadata:+            return continuation(handler_call_details)+        else:+            return self._abortion+++class SimpleGreeter(helloworld_pb2_grpc.GreeterServicer):++    @staticmethod+    def SayHello(request, unused_context):+        return helloworld_pb2.HelloReply(message='Hello, %s!' % request.name)+++def _load_credential_from_file(filepath):+    real_path = os.path.join(os.path.dirname(__file__), filepath)+    with open(real_path, 'r') as f:+        return f.read()+++@contextlib.contextmanager+def run_server(port):+    # Bind interceptor to server+    server = grpc.server(+        futures.ThreadPoolExecutor(),+        interceptors=(SignatureValidationInterceptor(),))+    helloworld_pb2_grpc.add_GreeterServicer_to_server(SimpleGreeter(), server)++    # Loading credentials+    server_credentials = grpc.ssl_server_credentials(((+        _credentials.SERVER_CERTIFICATE_KEY,+        _credentials.SERVER_CERTIFICATE,+    ),))++    # Pass down credentails+    port = server.add_secure_port(_LISTEN_ADDRESS_TEMPLATE % port,+                                  server_credentials)++    server.start()+    yield port",Should probably be```pythontry:    yield portfinally:    server.stop(None)```since the caller may throw an exception.,
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19456,296966688,2019-06-25T00:36:53Z,examples/python/auth/README.md,"@@ -0,0 +1,48 @@+# Authentication Extension Example in gRPC Python++## Check Our Guide First++For most common usage of authentication in gRPC Python, please see our [Authentication](https://grpc.io/docs/guides/auth/) guide's Python section, it includes:++1. Server SSL credential setup+2. Client SSL credential setup+3. Authenticate with Google using a JWT+4. Authenticate with Google using an Oauth2 token++Also, the guide talks about gRPC specific credential types.++### Channel credentials++Channel credentials are attached to a `Channel` object, the most common use case are SSL credentials.++### Call credentials++Call credentials are attached to a `Call` object (corresponding to an RPC). Under the hood, the call credentials is a function that takes in information of the RPC and modify metadata through callback.++## About This Example++This example focuses on extending gRPC authentication mechanism:+1) Customize authentication plugin;+2) Composite client side credentials;+3) Validation through interceptor on server side.++## AuthMetadataPlugin: Manipulate metadata for each call++Unlike TLS/SSL based authentication, the authentication extension in gRPC Python lives in a much higher level of abstraction. It relies on the transmit of metadata (HTTP Header) between client and server. gRPC Python provides a way to intercept an RPC and append authentication related metadata through [`AuthMetadataPlugin`](https://grpc.github.io/grpc/python/grpc.html#grpc.AuthMetadataPlugin).","Thank you for pointing out. I re-wrote this paragraph into:> Unlike TLS/SSL based authentication, the authentication extension in gRPC Python> lives at a much higher level of networking. It relies on the transmission of> metadata (HTTP Header) between client and server, instead of alternating the> transport protocol.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19456,296967808,2019-06-25T00:44:07Z,examples/python/auth/customize_auth_server.py,"@@ -0,0 +1,115 @@+# Copyright 2019 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Server of the Python example of customizing authentication mechanism.""""""++from __future__ import absolute_import+from __future__ import division+from __future__ import print_function++import argparse+import contextlib+import logging+import os+import time+from concurrent import futures++import grpc+from examples import helloworld_pb2, helloworld_pb2_grpc+from examples.python.auth import _credentials++_LOGGER = logging.getLogger(__name__)+_LOGGER.setLevel(logging.INFO)++_ONE_DAY_IN_SECONDS = 60 * 60 * 24++_LISTEN_ADDRESS_TEMPLATE = 'localhost:%d'+_SIGNATURE_HEADER_KEY = 'x-signautre'+++class SignatureValidationInterceptor(grpc.ServerInterceptor):++    def __init__(self):++        def abort(ignored_request, context):+            context.abort(grpc.StatusCode.UNAUTHENTICATED, 'Invalid signature')++        self._abortion = grpc.unary_unary_rpc_method_handler(abort)++    def intercept_service(self, continuation, handler_call_details):+        # Example HandlerCallDetails object:+        #     _HandlerCallDetails(+        #       method=u'/helloworld.Greeter/SayHello',+        #       invocation_metadata=...)+        method_name = handler_call_details.method.split('/')[-1]+        expected_metadata = (_SIGNATURE_HEADER_KEY, method_name[::-1])+        if expected_metadata in handler_call_details.invocation_metadata:+            return continuation(handler_call_details)+        else:+            return self._abortion+++class SimpleGreeter(helloworld_pb2_grpc.GreeterServicer):++    @staticmethod","It is simply because the `self` is not used at all.Although there is no convention to name `self` into `unused_self` if not used, it still feel a bit strange to me.I'm okay with either solution. Removed `staticmethod`.",OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/19456,296977215,2019-06-25T01:43:48Z,examples/python/auth/customize_auth_server.py,"@@ -0,0 +1,115 @@+# Copyright 2019 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Server of the Python example of customizing authentication mechanism.""""""++from __future__ import absolute_import+from __future__ import division+from __future__ import print_function++import argparse+import contextlib+import logging+import os+import time+from concurrent import futures++import grpc+from examples import helloworld_pb2, helloworld_pb2_grpc+from examples.python.auth import _credentials++_LOGGER = logging.getLogger(__name__)+_LOGGER.setLevel(logging.INFO)++_ONE_DAY_IN_SECONDS = 60 * 60 * 24++_LISTEN_ADDRESS_TEMPLATE = 'localhost:%d'+_SIGNATURE_HEADER_KEY = 'x-signautre'+++class SignatureValidationInterceptor(grpc.ServerInterceptor):++    def __init__(self):++        def abort(ignored_request, context):+            context.abort(grpc.StatusCode.UNAUTHENTICATED, 'Invalid signature')++        self._abortion = grpc.unary_unary_rpc_method_handler(abort)++    def intercept_service(self, continuation, handler_call_details):+        # Example HandlerCallDetails object:+        #     _HandlerCallDetails(+        #       method=u'/helloworld.Greeter/SayHello',+        #       invocation_metadata=...)+        method_name = handler_call_details.method.split('/')[-1]+        expected_metadata = (_SIGNATURE_HEADER_KEY, method_name[::-1])+        if expected_metadata in handler_call_details.invocation_metadata:+            return continuation(handler_call_details)+        else:+            return self._abortion+++class SimpleGreeter(helloworld_pb2_grpc.GreeterServicer):++    @staticmethod","I'm honestly fine either way, as long as it works. I would have suspected that changing the signature would break it.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19460,297242095,2019-06-25T15:12:22Z,src/csharp/Grpc.Core.Api/DeserializationContext.cs,"@@ -48,6 +96,23 @@ public virtual byte[] PayloadAsNewBuffer()             throw new NotImplementedException();         } +        /// <summary>+        /// Gets the entire payload as a leased byte array.+        /// The caller is expected to call Dispose exactly once, returning the buffer to the pool. Accessing+        /// the data after disposal or calling Dispose multiple times will result in undefined behavior.+        /// Only the range defined by Offset and Count shoud be accessed by the consumer.+        /// </summary>+        /// <returns>a leased buffer containing the entire payload</returns>+        public virtual LeasedBuffer PayloadAsLeasedBuffer()","I've experimented with similar concept in the past ( PayloadAsRentedBuffer() ) which was using ArrayPool.Shared.Rent internally, but I decided not to add that method as I wasn't sure it was providing much extra value.Once you're on netstandard2.0 (= GRPC_CSHARP_SUPPORT_SYSTEM_MEMORY is true), the can provide a deserializer that can easily perform pooling (custom or using ArrayPool) and read the content from PayloadAsReadOnlySequence().    This doesn't help .NET desktop users, but my assumption was is that most users that would care about performance would already be using .NET core.",
17328,mgravell,https://api.github.com/repos/grpc/grpc/pulls/19460,297286912,2019-06-25T16:42:56Z,src/csharp/Grpc.Core.Api/DeserializationContext.cs,"@@ -48,6 +96,23 @@ public virtual byte[] PayloadAsNewBuffer()             throw new NotImplementedException();         } +        /// <summary>+        /// Gets the entire payload as a leased byte array.+        /// The caller is expected to call Dispose exactly once, returning the buffer to the pool. Accessing+        /// the data after disposal or calling Dispose multiple times will result in undefined behavior.+        /// Only the range defined by Offset and Count shoud be accessed by the consumer.+        /// </summary>+        /// <returns>a leased buffer containing the entire payload</returns>+        public virtual LeasedBuffer PayloadAsLeasedBuffer()",I don't think that final assumption is valid: many folks care deeply but are still attempting gradual migration of large code-bases. But it may be moot - see other comment,OK
17328,mgravell,https://api.github.com/repos/grpc/grpc/pulls/19460,297287722,2019-06-25T16:44:50Z,src/csharp/Grpc.Core.Api/Marshaller.cs,"@@ -41,12 +42,51 @@ public Marshaller(Func<T, byte[]> serializer, Func<byte[], T> deserializer)         {             this.serializer = GrpcPreconditions.CheckNotNull(serializer, nameof(serializer));             this.deserializer = GrpcPreconditions.CheckNotNull(deserializer, nameof(deserializer));+             // contextual serialization/deserialization is emulated to make the marshaller             // usable with the grpc library (required for backward compatibility).             this.contextualSerializer = EmulateContextualSerializer;-            this.contextualDeserializer = EmulateContextualDeserializer;++            if (!TryFindArraySegmentDeserializer(deserializer, out this.contextualDeserializer))+            {+                this.contextualDeserializer = EmulateContextualDeserializer;+            }         } +        /// <summary>+        /// Given a deserializer of the form foo.Bar(byte[]), see if we can find a similar foo.Bar(byte[], int, int); if so,+        /// prefer that; this allows the existing protoc code-gen to be identified to use pooled buffers+        /// </summary>+        private static bool TryFindArraySegmentDeserializer(Func<byte[], T> deserializer, out Func<DeserializationContext, T> contextualDeserializer)",We could perhaps further restrict it to where the first parameter matches name and the second parameters are named `offset` and `count`? I think that's pretty unambiguous about the intent...,OK
28123841,guantaol,https://api.github.com/repos/grpc/grpc/pulls/19358,297446233,2019-06-26T00:40:14Z,src/core/lib/iomgr/executor/mpmcqueue.cc,"@@ -0,0 +1,117 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/support/port_platform.h>++#include ""src/core/lib/iomgr/executor/mpmcqueue.h""++namespace grpc_core {++DebugOnlyTraceFlag thread_pool(false, ""thread_pool_trace"");","Trace name: ""thread_pool""Also, thread_pool is too generic as the name of a trace flag. Consistent with the existing naming convention, grpc_thread_pool_trace may be more appropriate.",
17328,mgravell,https://api.github.com/repos/grpc/grpc/pulls/19460,297709519,2019-06-26T14:49:27Z,src/csharp/Grpc.Core/Grpc.Core.csproj,"@@ -100,6 +100,7 @@    <ItemGroup>     <PackageReference Include=""System.Interactive.Async"" Version=""3.2.0"" />+    <PackageReference Include=""System.Buffers"" Version=""4.5.0"" />","that was a hangover from when I wasn't using System.Memory for this; no longer needed, removing",OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/19465,297760543,2019-06-26T16:33:59Z,examples/python/cancellation/client.py,"@@ -0,0 +1,151 @@+# Copyright the 2019 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""An example of cancelling requests in gRPC.""""""++from __future__ import absolute_import+from __future__ import division+from __future__ import print_function++from concurrent import futures+import argparse+import datetime+import logging+import time+import signal+import threading++try:+    from queue import Queue+    from queue import Empty as QueueEmpty+except ImportError:+    from Queue import Queue+    from Queue import Empty as QueueEmpty",Agree. I didn't really want to take the dependency. But going for it.,
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/19465,297766292,2019-06-26T16:48:01Z,examples/python/cancellation/README.md,"@@ -0,0 +1,183 @@+### Cancelling RPCs++RPCs may be cancelled by both the client and the server.++#### The Example++In the example, we implement a silly algorithm. We search for bytestrings whose+hashes are similar to a given search string. For example, say we're looking for+the string ""doctor"". Our algorithm may `JrqhZVkTDoctYrUlXDbL6pfYQHU=` or+`RC9/7mlM3ldy4TdoctOc6WzYbO4=`. This is a brute force algorithm, so the server+performing the search must be conscious the resources it allows to each client+and each client must be conscientious of the resources demanded of the server.++In particular, we ensure that client processes cancel the stream explicitly+before terminating and we ensure the server cancels RPCs that have gone on longer+than a certain number of iterations.","Discussed offline. But I feel strongly that examples are meant to show not just *how* to use APIs, but also *when* to use APIs. The point of the algorithm is to teach potential users why they should use certain portions of our API.I agree on the complexity though. I have moved the search algorithm to a separate file so that users won't have to look at it unless they're curious. People can simply treat is a black box `search` function with the properties described in the `README`.",
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/19465,297767046,2019-06-26T16:49:50Z,examples/python/cancellation/README.md,"@@ -0,0 +1,183 @@+### Cancelling RPCs++RPCs may be cancelled by both the client and the server.++#### The Example++In the example, we implement a silly algorithm. We search for bytestrings whose+hashes are similar to a given search string. For example, say we're looking for+the string ""doctor"". Our algorithm may `JrqhZVkTDoctYrUlXDbL6pfYQHU=` or+`RC9/7mlM3ldy4TdoctOc6WzYbO4=`. This is a brute force algorithm, so the server+performing the search must be conscious the resources it allows to each client+and each client must be conscientious of the resources demanded of the server.++In particular, we ensure that client processes cancel the stream explicitly+before terminating and we ensure the server cancels RPCs that have gone on longer+than a certain number of iterations.++#### Cancellation on the Client Side++A client may cancel an RPC for several reasons. Perhaps the data it requested+has been made irrelevant. Perhaps you, as the client, want to be a good citizen+of the server and are conserving compute resources.++##### Cancelling a Server-Side Unary RPC from the Client++The default RPC methods on a stub will simply return the result of an RPC.++```python+>>> stub = hash_name_pb2_grpc.HashFinderStub(channel)+>>> stub.Find(hash_name_pb2.HashNameRequest(desired_name=name))+<hash_name_pb2.HashNameResponse object at 0x7fe2eb8ce2d0>+```++But you may use the `future()` method to receive an instance of `grpc.Future`.+This interface allows you to wait on a response with a timeout, add a callback+to be executed when the RPC completes, or to cancel the RPC before it has+completed.++In the example, we use this interface to cancel our in-progress RPC when the+user interrupts the process with ctrl-c.++```python+stub = hash_name_pb2_grpc.HashFinderStub(channel)+future = stub.Find.future(hash_name_pb2.HashNameRequest(desired_name=name))+def cancel_request(unused_signum, unused_frame):+    future.cancel()+signal.signal(signal.SIGINT, cancel_request)+```++It's also important that you not block indefinitely on the RPC. Otherwise, the+signal handler will never have a chance to run.","Yes. And I have added a TODO in the example to get rid of the workaround once the bug has been fixed. But until it *has*, this is the only way that this can be accomplished using our library.",OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/19465,297767323,2019-06-26T16:50:28Z,examples/python/cancellation/README.md,"@@ -0,0 +1,179 @@+#### The Example++In the example, we implement a silly algorithm. We search for bytestrings whose+hashes are similar to a given search string. For example, say we're looking for+the string ""doctor"". Our algorithm may return `JrqhZVkTDoctYrUlXDbL6pfYQHU=` or+`RC9/7mlM3ldy4TdoctOc6WzYbO4=`. This is a brute force algorithm, so the server+performing the search must be conscious of the resources it allows to each client+and each client must be conscientious of the resources it demands of the server.++In particular, we ensure that client processes cancel the stream explicitly+before terminating and we ensure that server processes cancel RPCs that have gone on longer+than a certain number of iterations.++#### Cancellation on the Client Side++A client may cancel an RPC for several reasons. Perhaps the data it requested+has been made irrelevant. Perhaps you, as the client, want to be a good citizen+of the server and are conserving compute resources.++##### Cancelling a Server-Side Unary RPC from the Client++The default RPC methods on a stub will simply return the result of an RPC.++```python+>>> stub = hash_name_pb2_grpc.HashFinderStub(channel)+>>> stub.Find(hash_name_pb2.HashNameRequest(desired_name=name))+<hash_name_pb2.HashNameResponse object at 0x7fe2eb8ce2d0>+```++But you may use the `future()` method to receive an instance of `grpc.Future`.+This interface allows you to wait on a response with a timeout, add a callback+to be executed when the RPC completes, or to cancel the RPC before it has+completed.++In the example, we use this interface to cancel our in-progress RPC when the+user interrupts the process with ctrl-c.++```python+stub = hash_name_pb2_grpc.HashFinderStub(channel)+future = stub.Find.future(hash_name_pb2.HashNameRequest(desired_name=name))+def cancel_request(unused_signum, unused_frame):+    future.cancel()+signal.signal(signal.SIGINT, cancel_request)+```++It's also important that you not block indefinitely on the RPC. Otherwise, the+signal handler will never have a chance to run.++```python+while True:+    try:+        result = future.result(timeout=_TIMEOUT_SECONDS)+    except grpc.FutureTimeoutError:+        continue+    except grpc.FutureCancelledError:+        break+    print(""Got response: \n{}"".format(result))+    break+```++Here, we repeatedly block on a result for up to `_TIMEOUT_SECONDS`. Doing so+gives the signal handlers a chance to run. In the case that our timeout+was reached, we simply continue on in the loop. In the case that the RPC was+cancelled (by our user's ctrl+c), we break out of the loop cleanly. Finally, if+we received the result of the RPC, we print it out for the user and exit the+loop.+++##### Cancelling a Server-Side Streaming RPC from the Client++Cancelling a Server-side streaming RPC is even simpler from the perspective of+the gRPC API. The default stub method is already an instance of `grpc.Future`,+so the methods outlined above still apply. It is also a generator, so we may+iterate over it to yield the results of our RPC.++```python+stub = hash_name_pb2_grpc.HashFinderStub(channel)+result_generator = stub.FindRange(hash_name_pb2.HashNameRequest(desired_name=name))+def cancel_request(unused_signum, unused_frame):+    result_generator.cancel()+signal.signal(signal.SIGINT, cancel_request)+```++However, the streaming case is complicated by the fact that there is no way to+propagate a timeout to Python generators. As a result, simply iterating over the+results of the RPC can block indefinitely and the signal handler may never run.+Instead, we iterate over the generator on another thread and retrieve the+results on the main thread with a synchronized `Queue`.","Agree it would be better to fix the bug. But until then, a workaround is the next best thing. This is an example. It can always be changed once our library supports a simpler workflow.",
2754995,sreecha,https://api.github.com/repos/grpc/grpc/pulls/18970,297776108,2019-06-26T17:12:16Z,doc/core/combiner-explainer.md,"@@ -114,40 +114,30 @@ if we know that it is valid to do so: while (q.pop(&f)) {   f();   if (control_can_be_returned && some_still_queued_thing_is_covered_by_poller) {-    offload_combiner_work_to_some_other_thread();+    queue_offload(); // Queue offload work to some other thread   } } ``` -`offload` is more than `break`; it does `break` but also causes some-other thread that is currently waiting on a poll to break out of its-poll. This is done by setting up a per-polling-island work-queue-(distributor) wakeup FD. The work-queue is the converse of the combiner; it-tries to spray events onto as many threads as possible to get as much concurrency as possible.+`queue_offload` detaches the combiner from the current thread's executor and+ offloads to the work to `executor` which is an internal pool of threads.","Should I phrase it as _""offloads the remaining work to the `executor`""_  ? or is the term ""work"" ambiguous?If so, I can rewrite it the following way:_""Offloads the remaining list of closures (that were scheduled on this combiner) to the `executor`""_",OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/19453,297796616,2019-06-26T18:00:50Z,src/core/ext/transport/chttp2/transport/hpack_table.h,"@@ -46,41 +46,65 @@ #endif  /* hpack decoder table */-typedef struct {+struct grpc_chttp2_hptbl {+  static uint32_t entries_for_bytes(uint32_t bytes) {+    return (bytes + GRPC_CHTTP2_HPACK_ENTRY_OVERHEAD - 1) /+           GRPC_CHTTP2_HPACK_ENTRY_OVERHEAD;+  }+  static constexpr uint32_t InitialCapacity =+      (/*bytes=*/GRPC_CHTTP2_INITIAL_HPACK_TABLE_SIZE ++       GRPC_CHTTP2_HPACK_ENTRY_OVERHEAD - 1) /+      GRPC_CHTTP2_HPACK_ENTRY_OVERHEAD;++  grpc_chttp2_hptbl() = default;+   /* the first used entry in ents */-  uint32_t first_ent;+  uint32_t first_ent = 0;   /* how many entries are in the table */-  uint32_t num_ents;+  uint32_t num_ents = 0;   /* the amount of memory used by the table, according to the hpack algorithm */-  uint32_t mem_used;+  uint32_t mem_used = 0;   /* the max memory allowed to be used by the table, according to the hpack      algorithm */-  uint32_t max_bytes;+  uint32_t max_bytes = GRPC_CHTTP2_INITIAL_HPACK_TABLE_SIZE;   /* the currently agreed size of the table, according to the hpack algorithm */-  uint32_t current_table_bytes;+  uint32_t current_table_bytes = GRPC_CHTTP2_INITIAL_HPACK_TABLE_SIZE;   /* Maximum number of entries we could possibly fit in the table, given defined      overheads */-  uint32_t max_entries;+  uint32_t max_entries = InitialCapacity;   /* Number of entries allocated in ents */-  uint32_t cap_entries;+  uint32_t cap_entries = InitialCapacity;   /* a circular buffer of headers - this is stored in the opposite order to      what hpack specifies, in order to simplify table management a little...      meaning lookups need to SUBTRACT from the end position */-  grpc_mdelem* ents;-  grpc_mdelem static_ents[GRPC_CHTTP2_LAST_STATIC_ENTRY];-} grpc_chttp2_hptbl;+  grpc_mdelem* ents = nullptr;+};  /* initialize a hpack table */-void grpc_chttp2_hptbl_init(grpc_chttp2_hptbl* tbl);+inline void grpc_chttp2_hptbl_init(grpc_chttp2_hptbl* tbl) {+  new (tbl) grpc_chttp2_hptbl();+  constexpr uint32_t AllocSize =+      sizeof(*tbl->ents) * grpc_chttp2_hptbl::InitialCapacity;+  tbl->ents = static_cast<grpc_mdelem*>(gpr_malloc(AllocSize));+  memset(tbl->ents, 0, AllocSize);+}+ void grpc_chttp2_hptbl_destroy(grpc_chttp2_hptbl* tbl); void grpc_chttp2_hptbl_set_max_bytes(grpc_chttp2_hptbl* tbl,                                      uint32_t max_bytes); grpc_error* grpc_chttp2_hptbl_set_current_table_size(grpc_chttp2_hptbl* tbl,                                                      uint32_t bytes);  /* lookup a table entry based on its hpack index */-grpc_mdelem grpc_chttp2_hptbl_lookup(const grpc_chttp2_hptbl* tbl,-                                     uint32_t index);+grpc_mdelem grpc_chttp2_hptbl_lookup_slow(const grpc_chttp2_hptbl* tbl,+                                          uint32_t tbl_index);+inline grpc_mdelem grpc_chttp2_hptbl_lookup(const grpc_chttp2_hptbl* tbl,+                                            uint32_t index) {+  /* Static table comes first, just return an entry from it */+  return index <= GRPC_CHTTP2_LAST_STATIC_ENTRY+             ? grpc_static_mdelem_manifested[index - 1]","Does this mean that the first GRPC_CHTTP_LAST_STATIC_ENTRY elements of grpc_static_mdelem_manifested must adhere to the hpack spec for static hpack table ordering?  If so, please add a comment to the static_metadata files as well as to gen_static_metadata.py so that someone doesn't accidentally change this in the future.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19474,297803607,2019-06-26T18:18:32Z,src/csharp/Grpc.Core.Tests/Grpc.Core.Tests.csproj,"@@ -8,7 +8,7 @@     <TreatWarningsAsErrors>true</TreatWarningsAsErrors>   </PropertyGroup> -  <PropertyGroup Condition="" '$(TargetFramework)' == 'netcoreapp2.1' "">+  <PropertyGroup Condition="" '$(TargetFramework)' == 'netcoreapp2.1' or '$(TargetFramework)' == 'net45' "">","btw, the test project uses `<TargetFrameworks>net45;netcoreapp2.1</TargetFrameworks>` so by making this change, we are no longer testing the codepath in Grpc.Core with GRPC_CSHARP_SUPPORT_SYSTEM_MEMORY=false.I might need to add an extra testing project to make sure we visit that codepath.",
2811396,ejona86,https://api.github.com/repos/grpc/grpc/pulls/19450,297812046,2019-06-26T18:38:24Z,doc/PROTOCOL-HTTP2.md,"@@ -138,6 +138,8 @@ implementation can decode valid portions while leaving broken %-encodings as-is or replacing them with a replacement character (e.g., '?' or the Unicode replacement character). +The repeated sequence of **Length-Prefixed-Message** has the same format as request.","Hmm... This also applies to Custom-Metadata. Add it as well? I normally wouldn't be excited about listing all the things repeated here, but since it's just those two it seems fine.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/19395,297823947,2019-06-26T19:09:15Z,test/cpp/end2end/client_lb_end2end_test.cc,"@@ -1481,9 +1487,6 @@ TEST_F(ClientLbInterceptTrailingMetadataTest, InterceptsRetriesEnabled) { }  // namespace grpc  int main(int argc, char** argv) {-  // Make the backup poller poll very frequently in order to pick up-  // updates from all the subchannels's FDs.-  GPR_GLOBAL_CONFIG_SET(grpc_client_channel_backup_poll_interval_ms, 1);",(similar question for other uses),OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19395,297826864,2019-06-26T19:17:57Z,test/cpp/end2end/client_lb_end2end_test.cc,"@@ -1481,9 +1487,6 @@ TEST_F(ClientLbInterceptTrailingMetadataTest, InterceptsRetriesEnabled) { }  // namespace grpc  int main(int argc, char** argv) {-  // Make the backup poller poll very frequently in order to pick up-  // updates from all the subchannels's FDs.-  GPR_GLOBAL_CONFIG_SET(grpc_client_channel_backup_poll_interval_ms, 1);","[GTMGoogleTestRunner](https://github.com/google/google-toolbox-for-mac/blob/master/UnitTesting/GTMGoogleTestRunner.mm) is used to convert googletest cases to XCTest that can be run on iOS. GTMGoogleTestRunner doesn't execute the main() function, so any setup/teardown in main needs to be moved to SetUpTestCase/TearDownTestCase.",
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19395,297828889,2019-06-26T19:24:06Z,test/cpp/end2end/client_lb_end2end_test.cc,"@@ -1481,9 +1487,6 @@ TEST_F(ClientLbInterceptTrailingMetadataTest, InterceptsRetriesEnabled) { }  // namespace grpc  int main(int argc, char** argv) {-  // Make the backup poller poll very frequently in order to pick up-  // updates from all the subchannels's FDs.-  GPR_GLOBAL_CONFIG_SET(grpc_client_channel_backup_poll_interval_ms, 1);","GTMGoogleTestRunner calls [InitGoogleTest](https://github.com/google/google-toolbox-for-mac/blob/master/UnitTesting/GTMGoogleTestRunner.mm#L151), so we can leave it in main. grpc::testing::TestEnvironment just does some test initialization (install crash handler, seed RNG) that's not strictly required to run testcases on iOS, so I left it in main.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19465,297872569,2019-06-26T21:23:08Z,examples/python/cancellation/search.py,"@@ -0,0 +1,158 @@+# Copyright the 2019 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""A search algorithm over the space of all bytestrings.""""""++from __future__ import absolute_import+from __future__ import division+from __future__ import print_function++import base64+import hashlib+import logging+import struct++from examples.python.cancellation import hash_name_pb2++_LOGGER = logging.getLogger(__name__)+_BYTE_MAX = 255+++def _get_hamming_distance(a, b):+    """"""Calculates hamming distance between strings of equal length.""""""+    distance = 0+    for char_a, char_b in zip(a, b):+        if char_a.lower() != char_b.lower():+            distance += 1+    return distance+++def _get_substring_hamming_distance(candidate, target):+    """"""Calculates the minimum hamming distance between between the target+        and any substring of the candidate.++    Args:+      candidate: The string whose substrings will be tested.+      target: The target string.++    Returns:+      The minimum Hamming distance between candidate and target.+    """"""+    min_distance = None+    for i in range(len(candidate) - len(target) + 1):","What if application decided to supply a super long ""search string""?",OK
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19343,297897687,2019-06-26T22:53:09Z,src/core/ext/transport/chttp2/transport/hpack_encoder.cc,"@@ -380,10 +382,11 @@ static void emit_lithdr_incidx(grpc_chttp2_hpack_compressor* c,   uint32_t len_val_len;   GPR_ASSERT(len_val <= UINT32_MAX);   len_val_len = GRPC_CHTTP2_VARINT_LENGTH((uint32_t)len_val, 1);-  GRPC_CHTTP2_WRITE_VARINT(key_index, 2, 0x40,-                           add_tiny_header_data(st, len_pfx), len_pfx);+  GPR_DEBUG_ASSERT(len_pfx + len_val_len < GRPC_SLICE_INLINED_SIZE);","The initial assumption, though there was no debug assert for it, is that the size of an inlined slice is > than the binary encoding of a single qword + 2 bytes (6 total).Since the assumption was not explicit, theoretically if inline slice buffers get really tiny, we'd have issues.Here I'm just making the assumption explicit. Inline slices have 23 bytes max capacity, and here we use 12.In terms of being brittle: the only way this breaks is if someone reduces the size of inline slice data segments to be smaller than the size of a refcounted slice, which I consider very unlikely.",OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/19427,297904644,2019-06-26T23:25:12Z,src/core/ext/filters/client_channel/health/health_check_client.cc,"@@ -354,7 +354,8 @@ void HealthCheckClient::CallState::StartCall() {   grpc_metadata_batch_init(&send_initial_metadata_);   error = grpc_metadata_batch_add_head(       &send_initial_metadata_, &path_metadata_storage_,-      grpc_mdelem_from_slices(+      // TODO(arjunroy): They're both static.","Could you update your comment to reflect that? Something like: ""// TODO(arjunroy): Both parameters are static so we could use that knowledge to create an even faster fastpath here."" This is so that a general reader of this code can understand what this comment means.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/19393,298255811,2019-06-27T16:07:28Z,src/core/lib/gprpp/thd_posix.cc,"@@ -48,6 +49,24 @@ struct thd_arg {   bool tracked; }; +const size_t page_size = static_cast<size_t>(sysconf(_SC_PAGESIZE));","That article is about C, though. This code is C++. static doesn't have to be initialized that way in C++. See for example the compiler results window for https://godbolt.org/z/3qyTTd",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/19393,298257113,2019-06-27T16:10:39Z,src/core/lib/gprpp/thd_posix.cc,"@@ -48,6 +49,24 @@ struct thd_arg {   bool tracked; }; +const size_t page_size = static_cast<size_t>(sysconf(_SC_PAGESIZE));","Ah, seeing the error link, though, the issue is a different one. This is in core but function-level static initialization uses standard-library locks for making sure that static variables are only initialized once, and we can't use standard-library in core.So I'll approve this PR but I'm going to ask you to add a TODO comment on that line indicating that we should find a way to move this to a function-level static or remove the use of a non-constexpr initializer when possible.",
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19343,298416408,2019-06-28T00:25:33Z,src/core/ext/transport/chttp2/transport/hpack_encoder.cc,"@@ -171,10 +171,12 @@ static void add_header_data(framer_state* st, grpc_slice slice) {   } } +extern uint8_t* grpc_slice_buffer_tiny_add_non_empty(grpc_slice_buffer* sb,","That was misplaced, removing.",OK
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19487,298751716,2019-06-28T21:21:50Z,src/core/ext/transport/chttp2/transport/hpack_encoder.cc,"@@ -711,18 +711,28 @@ void grpc_chttp2_encode_header(grpc_chttp2_hpack_compressor* c,   }   for (size_t i = 0; i < extra_headers_size; ++i) {     grpc_mdelem md = *extra_headers[i];-    uintptr_t static_index = grpc_chttp2_get_static_hpack_table_index(md);-    if (static_index) {-      emit_indexed(c, static_cast<uint32_t>(static_index), &st);+    const bool is_static =+        GRPC_MDELEM_STORAGE(md) == GRPC_MDELEM_STORAGE_STATIC;+    uintptr_t static_index;+    if (is_static &&","No, because there H2 only uses a subset of the static metadata in core. GRPC_CHTTP2_LAST_STATIC_ENTRY is 61, while there's something like 80+ in core.",OK
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19487,298751781,2019-06-28T21:22:06Z,src/core/ext/transport/chttp2/transport/hpack_encoder.cc,"@@ -711,18 +711,28 @@ void grpc_chttp2_encode_header(grpc_chttp2_hpack_compressor* c,   }   for (size_t i = 0; i < extra_headers_size; ++i) {     grpc_mdelem md = *extra_headers[i];-    uintptr_t static_index = grpc_chttp2_get_static_hpack_table_index(md);-    if (static_index) {-      emit_indexed(c, static_cast<uint32_t>(static_index), &st);+    const bool is_static =+        GRPC_MDELEM_STORAGE(md) == GRPC_MDELEM_STORAGE_STATIC;+    uintptr_t static_index;+    if (is_static &&+        (static_index =+             reinterpret_cast<grpc_core::StaticMetadata*>(GRPC_MDELEM_DATA(md))+                 ->StaticIndex()) < GRPC_CHTTP2_LAST_STATIC_ENTRY) {+      emit_indexed(c, static_cast<uint32_t>(static_index + 1), &st);     } else {       hpack_enc(c, md, &st);     }   }   grpc_metadata_batch_assert_ok(metadata);   for (grpc_linked_mdelem* l = metadata->list.head; l; l = l->next) {-    uintptr_t static_index = grpc_chttp2_get_static_hpack_table_index(l->md);-    if (static_index) {-      emit_indexed(c, static_cast<uint32_t>(static_index), &st);+    const bool is_static =+        GRPC_MDELEM_STORAGE(l->md) == GRPC_MDELEM_STORAGE_STATIC;+    uintptr_t static_index;+    if (is_static &&+        (static_index = reinterpret_cast<grpc_core::StaticMetadata*>(+                            GRPC_MDELEM_DATA(l->md))+                            ->StaticIndex()) < GRPC_CHTTP2_LAST_STATIC_ENTRY) {",Closing duplicate.,
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19481,299256788,2019-07-01T23:46:33Z,src/python/grpcio_tests/tests/unit/_signal_client.py,"@@ -0,0 +1,60 @@+""""""Client for testing responsiveness to signals.""""""++from __future__ import print_function++import argparse+import functools+import logging+import signal+import sys++import grpc++SIGTERM_MESSAGE = ""Handling sigterm!""++UNARY_UNARY = ""/test/Unary""+UNARY_STREAM = ""/test/ServerStreaming""++_MESSAGE = b'\x00\x00\x00'++_ASSERTION_MESSAGE = ""Control flow should never reach here.""+++def handle_sigint(rpc_future, unused_signum, unused_frame):+    print(SIGTERM_MESSAGE)",Then we can remove the unused `logging`?,OK
17328,mgravell,https://api.github.com/repos/grpc/grpc/pulls/19515,299343812,2019-07-02T07:45:07Z,src/csharp/Grpc.Microbenchmarks/CommonThreadedBase.cs,"@@ -0,0 +1,66 @@+#region Copyright notice and license++// Copyright 2015 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Threading;+using System.Threading.Tasks;+using BenchmarkDotNet.Attributes;+using Grpc.Core;++namespace Grpc.Microbenchmarks+{++    // common base-type for tests that need to run with some level of concurrency;+    // note there's nothing *special* about this type - it is just to save some+    // boilerplate++    [ClrJob, CoreJob] // test .NET Core and .NET Framework+    [MemoryDiagnoser] // allocations+    public abstract class CommonThreadedBase+    {+        protected virtual bool NeedsEnvironment => true;++        [Params(1, 1, 2, 4, 8, 12)]+        public int ThreadCount { get; set; }++        protected GrpcEnvironment Environment { get; private set; }++        [GlobalSetup]+        public virtual void Setup()+        {+            ThreadPool.GetMinThreads(out var workers, out var iocp);+            if (workers <= ThreadCount) ThreadPool.SetMinThreads(ThreadCount + 1, iocp);+            if (NeedsEnvironment) Environment = GrpcEnvironment.AddRef();+        }++        [GlobalCleanup]+        public virtual void Cleanup()+        {+            if (Environment != null)+            {+                Environment = null;+                GrpcEnvironment.ReleaseAsync().Wait();+            }+        }++        protected void RunConcurrent(Action operation)+        {+            Parallel.For(0, ThreadCount, _ => operation());","My understanding here is that benchmarkdotnet doesn't have any *specific features* for multi-threaded tests, and yes it isn't it's strong suit; but I don't think that it is any better or worse than doing the same thing manually with a hand-written rig. But with benchmarkdotnet you can still get a lot more additional data / features etc for free, despite it not being the perfect scenario.What *is* for sure is that global allocations (all threads) is missing an API on .NET Core < v3, but that this new API is already hooked up in the v3 bits including benchmarkdotnet - so when v3 lands, I strongly recommend updating any benchmarks to netcoreapp3.0 (either additional-to or instead-of) - this will make the ""Allocated"" column more reliable.For my money: we only gain by switching to benchmarkdotnet; but: your call.",
17328,mgravell,https://api.github.com/repos/grpc/grpc/pulls/19515,299358320,2019-07-02T08:20:28Z,src/csharp/Grpc.Microbenchmarks/CommonThreadedBase.cs,"@@ -0,0 +1,66 @@+#region Copyright notice and license++// Copyright 2015 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Threading;+using System.Threading.Tasks;+using BenchmarkDotNet.Attributes;+using Grpc.Core;++namespace Grpc.Microbenchmarks+{++    // common base-type for tests that need to run with some level of concurrency;+    // note there's nothing *special* about this type - it is just to save some+    // boilerplate++    [ClrJob, CoreJob] // test .NET Core and .NET Framework+    [MemoryDiagnoser] // allocations+    public abstract class CommonThreadedBase+    {+        protected virtual bool NeedsEnvironment => true;++        [Params(1, 1, 2, 4, 8, 12)]+        public int ThreadCount { get; set; }++        protected GrpcEnvironment Environment { get; private set; }++        [GlobalSetup]+        public virtual void Setup()+        {+            ThreadPool.GetMinThreads(out var workers, out var iocp);+            if (workers <= ThreadCount) ThreadPool.SetMinThreads(ThreadCount + 1, iocp);+            if (NeedsEnvironment) Environment = GrpcEnvironment.AddRef();+        }++        [GlobalCleanup]+        public virtual void Cleanup()+        {+            if (Environment != null)+            {+                Environment = null;+                GrpcEnvironment.ReleaseAsync().Wait();+            }+        }++        protected void RunConcurrent(Action operation)+        {+            Parallel.For(0, ThreadCount, _ => operation());","since the async operation is sync, not async, there won't be massive numbers of thread jumps involved here; the main risk is that some of the operations end up getting queued rather than running in parallel; I've tried making sure that we have at least as many workers as we need, but indeed - the cost of spinning up an entire thread *in the `[Benchmark]` method isn't really viable*; that said, because of the warmup etc, we should be fairly happy that the thread-pool will have adapted to our usage reasonably. While thread-pool growth is pretty sedate by default, once they are there: they *really, really* don't like to terminate themselves.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19511,300053295,2019-07-03T16:33:05Z,src/csharp/Grpc.Core/Internal/MetadataArraySafeHandle.cs,"@@ -66,16 +65,50 @@ public static Metadata ReadMetadataFromPtrUnsafe(IntPtr metadataArray)                 var index = new UIntPtr(i);                 UIntPtr keyLen;                 IntPtr keyPtr = Native.grpcsharp_metadata_array_get_key(metadataArray, index, out keyLen);-                string key = Marshal.PtrToStringAnsi(keyPtr, (int)keyLen.ToUInt32());+                int keyLen32 = checked((int)keyLen.ToUInt32());+                string key = WellKnownStrings.TryIdentify((byte*)keyPtr.ToPointer(), keyLen32)+                    ?? Marshal.PtrToStringAnsi(keyPtr, keyLen32);                 UIntPtr valueLen;                 IntPtr valuePtr = Native.grpcsharp_metadata_array_get_value(metadataArray, index, out valueLen);-                var bytes = new byte[valueLen.ToUInt64()];-                Marshal.Copy(valuePtr, bytes, 0, bytes.Length);-                metadata.Add(Metadata.Entry.CreateUnsafe(key, bytes));+                int len32 = checked((int)valueLen.ToUInt64());+                metadata.Add(Metadata.Entry.CreateUnsafe(key, (byte*)valuePtr.ToPointer(), len32));             }             return metadata;         } +        private static class WellKnownStrings","this is looking good, but I think it would be better to make WellKnownString a top-level class under Grpc.Core.Internal and provide unit tests for it (that checks that well known strings are identified correctly and that other strings are not recognized as well-known by mistake).I think it's fine to leave as is in this PR, provided that there'll be a followup PR that makes the refactoring and adds tests. WDYT?",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19511,300054734,2019-07-03T16:36:31Z,src/csharp/Grpc.Core/Internal/NativeMethods.Generated.cs,"@@ -266,7 +266,10 @@ public NativeMethods(DllImportsFromStaticLib unusedInstance)             this.grpcsharp_call_start_duplex_streaming = DllImportsFromStaticLib.grpcsharp_call_start_duplex_streaming;             this.grpcsharp_call_send_message = DllImportsFromStaticLib.grpcsharp_call_send_message;             this.grpcsharp_call_send_close_from_client = DllImportsFromStaticLib.grpcsharp_call_send_close_from_client;-            this.grpcsharp_call_send_status_from_server = DllImportsFromStaticLib.grpcsharp_call_send_status_from_server;+            unsafe","Sanity checks are complaining:```269,272c269<             unsafe<             {<                 this.grpcsharp_call_send_status_from_server = DllImportsFromStaticLib.grpcsharp_call_send_status_from_server;<             }--->             this.grpcsharp_call_send_status_from_server = DllImportsFromStaticLib.grpcsharp_call_send_status_from_server;372,375c369<             unsafe<             {<                 this.grpcsharp_call_send_status_from_server = DllImportsFromSharedLib.grpcsharp_call_send_status_from_server;<             }--->             this.grpcsharp_call_send_status_from_server = DllImportsFromSharedLib.grpcsharp_call_send_status_from_server;478c472<             public unsafe delegate CallError grpcsharp_call_send_status_from_server_delegate(CallSafeHandle call, BatchContextSafeHandle ctx, StatusCode statusCode, byte* statusMessage, UIntPtr statusMessageLen, MetadataArraySafeHandle metadataArray, int sendEmptyInitialMetadata, byte[] optionalSendBuffer, UIntPtr optionalSendBufferLen, WriteFlags writeFlags);--->             public delegate CallError grpcsharp_call_send_status_from_server_delegate(CallSafeHandle call, BatchContextSafeHandle ctx, StatusCode statusCode, byte[] statusMessage, UIntPtr statusMessageLen, MetadataArraySafeHandle metadataArray, int sendEmptyInitialMetadata, byte[] optionalSendBuffer, UIntPtr optionalSendBufferLen, WriteFlags writeFlags);646c640<             public static unsafe extern CallError grpcsharp_call_send_status_from_server(CallSafeHandle call, BatchContextSafeHandle ctx, StatusCode statusCode, byte* statusMessage, UIntPtr statusMessageLen, MetadataArraySafeHandle metadataArray, int sendEmptyInitialMetadata, byte[] optionalSendBuffer, UIntPtr optionalSendBufferLen, WriteFlags writeFlags);--->             public static extern CallError grpcsharp_call_send_status_from_server(CallSafeHandle call, BatchContextSafeHandle ctx, StatusCode statusCode, byte[] statusMessage, UIntPtr statusMessageLen, MetadataArraySafeHandle metadataArray, int sendEmptyInitialMetadata, byte[] optionalSendBuffer, UIntPtr optionalSendBufferLen, WriteFlags writeFlags);942c936<             public static unsafe extern CallError grpcsharp_call_send_status_from_server(CallSafeHandle call, BatchContextSafeHandle ctx, StatusCode statusCode, byte* statusMessage, UIntPtr statusMessageLen, MetadataArraySafeHandle metadataArray, int sendEmptyInitialMetadata, byte[] optionalSendBuffer, UIntPtr optionalSendBufferLen, WriteFlags writeFlags);--->             public static extern CallError grpcsharp_call_send_status_from_server(CallSafeHandle call, BatchContextSafeHandle ctx, StatusCode statusCode, byte[] statusMessage, UIntPtr statusMessageLen, MetadataArraySafeHandle metadataArray, int sendEmptyInitialMetadata, byte[] optionalSendBuffer, UIntPtr optionalSendBufferLen, WriteFlags writeFlags);Traceback (most recent call last):  File ""tools/buildgen/generate_projects.py"", line 100, in <module>    assert 0 == os.system('diff %s %s' % (s, g)), sAssertionError: ./src/csharp/Grpc.Core/Internal/NativeMethods.Generated.cs```Let's not make the entire method ""unsafe"" but rather use unsafe block inside that method to avoid needing to regenerate this file (also not hard, but removing ""unsafe"" is even more trivial.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19511,300055303,2019-07-03T16:37:55Z,src/csharp/Grpc.Core.Api/Metadata.cs,"@@ -345,15 +346,44 @@ internal byte[] GetSerializedValueUnsafe()             /// Creates a binary value or ascii value metadata entry from data received from the native layer.             /// We trust C core to give us well-formed data, so we don't perform any checks or defensive copying.             /// </summary>-            internal static Entry CreateUnsafe(string key, byte[] valueBytes)+            internal static unsafe Entry CreateUnsafe(string key, byte* source, int length)             {                 if (HasBinaryHeaderSuffix(key))                 {-                    return new Entry(key, null, valueBytes);+                    byte[] arr;+                    if (length == 0)+                    {+                        arr = EmptyBlob;+                    }+                    else+                    {   // create a local copy in a fresh array+                        arr = new byte[length];+                        Marshal.Copy(new IntPtr(source), arr, 0, length);+                    }+                    return new Entry(key, null, arr);+                }+                else+                {+                    string s;+                    if (length == 0)+                    {+                        s = """";+                    }+                    else+                    {+                        int charCount = EncodingASCII.GetCharCount(source, length);+                        s = new string('\0', charCount);+                        fixed (char* cPtr = s)+                        {+                            EncodingASCII.GetChars(source, length, cPtr, charCount);+                        }+                    }+                    return new Entry(key, s, null);                 }-                return new Entry(key, EncodingASCII.GetString(valueBytes), null);             } +            static readonly byte[] EmptyBlob = new byte[0];","nit: not fan of the name as ""Blob"" feel like large data.  `EmptyByteArray` seems more descriptive.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19511,300059689,2019-07-03T16:48:09Z,src/csharp/Grpc.Core/Internal/CallSafeHandle.cs,"@@ -127,16 +128,52 @@ public void StartSendCloseFromClient(ISendCompletionCallback callback)             }         } -        public void StartSendStatusFromServer(ISendStatusFromServerCompletionCallback callback, Status status, MetadataArraySafeHandle metadataArray, bool sendEmptyInitialMetadata,+        public unsafe void StartSendStatusFromServer(ISendStatusFromServerCompletionCallback callback, Status status, MetadataArraySafeHandle metadataArray, bool sendEmptyInitialMetadata,             byte[] optionalPayload, WriteFlags writeFlags)         {             using (completionQueue.NewScope())             {                 var ctx = completionQueue.CompletionRegistry.RegisterBatchCompletion(CompletionHandler_ISendStatusFromServerCompletionCallback, callback);                 var optionalPayloadLength = optionalPayload != null ? new UIntPtr((ulong)optionalPayload.Length) : UIntPtr.Zero;-                var statusDetailBytes = MarshalUtils.GetBytesUTF8(status.Detail);-                Native.grpcsharp_call_send_status_from_server(this, ctx, status.StatusCode, statusDetailBytes, new UIntPtr((ulong)statusDetailBytes.Length), metadataArray, sendEmptyInitialMetadata ? 1 : 0,-                    optionalPayload, optionalPayloadLength, writeFlags).CheckOk();++                const int MaxStackAllocBytes = 256;+                int maxBytes = MarshalUtils.GetMaxByteCountUTF8(status.Detail);+                if (maxBytes > MaxStackAllocBytes)+                {+                    // pay the extra to get the *actual* size; this could mean that+                    // it ends up fitting on the stack after all, but even if not+                    // it will mean that we ask for a *much* smaller buffer+                    maxBytes = MarshalUtils.GetByteCountUTF8(status.Detail);+                }++                if (maxBytes <= MaxStackAllocBytes)+                {   // for small status, we can encode on the stack without touching arrays+                    // note: if init-locals is disabled, it would be more efficient+                    // to just stackalloc[MaxStackAllocBytes]; but by default, since we+                    // expect this to be small and it needs to wipe, just use maxBytes+                    byte* ptr = stackalloc byte[maxBytes];+                    int statusBytes = MarshalUtils.GetBytesUTF8(status.Detail, ptr, maxBytes);+                    Native.grpcsharp_call_send_status_from_server(this, ctx, status.StatusCode, ptr, new UIntPtr((ulong)statusBytes), metadataArray, sendEmptyInitialMetadata ? 1 : 0,","just FYI, even with this optimization, the data gets copied in the native code because it needs to be converted to grpc_slice that needs to stay valid until the send_status_from_server operation finishes.https://github.com/grpc/grpc/blob/d7bd178b31fb4953db17c72a238bd745cb4d9ca6/src/csharp/ext/grpc_csharp_ext.c#L800Your change avoids at least one of the copies, so there's an improvement, I just wanted to make it clear that there are still opportunities to improve further.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19548,300061420,2019-07-03T16:52:46Z,src/csharp/Grpc.Core/Internal/DefaultDeserializationContext.cs,"@@ -46,10 +46,12 @@ public DefaultDeserializationContext()          public override byte[] PayloadAsNewBuffer()         {+            if (payloadLength == 0) return EmptyBlob;",In this case we should also update the xmldoc of the `PayloadAsNewBuffer` method:https://github.com/grpc/grpc/blob/72b95e18fafbd3e2c66b0480f9879478da95ab65/src/csharp/Grpc.Core.Api/DeserializationContext.cs#L34,
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/19543,300065567,2019-07-03T17:03:02Z,src/core/lib/slice/slice.cc,"@@ -399,7 +399,8 @@ grpc_slice grpc_slice_split_tail(grpc_slice* source, size_t split) {   return grpc_slice_split_tail_maybe_ref(source, split, GRPC_SLICE_REF_BOTH); } -grpc_slice grpc_slice_split_head(grpc_slice* source, size_t split) {+template <bool do_ref = true>","Since this is internal only, can you avoid a default parameter? It obscures intent IMO. It looks like the default is never used anyway.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/19543,300068072,2019-07-03T17:09:04Z,src/core/lib/slice/slice_buffer.cc,"@@ -36,16 +36,21 @@  * memmove/malloc/realloc) - only if we were up against the full capacity of the  * slice buffer. If do_embiggen is inlined, the compiler clobbers multiple  * registers pointlessly in the common case. */+template <bool grow_past_minimum = false> static void GPR_ATTRIBUTE_NOINLINE do_embiggen(grpc_slice_buffer* sb,                                                const size_t slice_count,-                                               const size_t slice_offset) {+                                               const size_t slice_offset,+                                               const size_t minimum_size = 0) {","Again, let me suggest avoiding the use of default parameters and arguments for internal functions.",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/19543,300068863,2019-07-03T17:10:59Z,src/core/lib/slice/slice_buffer.cc,"@@ -262,54 +276,79 @@ void grpc_slice_buffer_move_into(grpc_slice_buffer* src,   src->length = 0; } +template <bool incref>+static void slice_buffer_move_single_slice(grpc_slice_buffer* src,+                                           grpc_slice_buffer* dst,+                                           size_t bytes_extra) {+  // Last slice in batch for slice_buffer_move_first_maybe_ref.+  // We may have to consume it  whole, or just a chunk.+  if (bytes_extra) {+    // Just a chunk.+    if (incref) {+      dst->slices[dst->count] = grpc_slice_split_head(+          &src->slices[0], GRPC_SLICE_LENGTH(src->slices[0]) - bytes_extra);+    } else {+      dst->slices[dst->count] = grpc_slice_split_head_noref(+          &src->slices[0], GRPC_SLICE_LENGTH(src->slices[0]) - bytes_extra);+    }+  } else {+    // The whole thing.+    dst->slices[dst->count] = src->slices[0];+    ++src->slices;+    --src->count;+  }+  ++dst->count;+}++template <bool incref> static void slice_buffer_move_first_maybe_ref(grpc_slice_buffer* src, size_t n,-                                              grpc_slice_buffer* dst,-                                              bool incref) {-  GPR_ASSERT(src->length >= n);-  if (src->length == n) {+                                              grpc_slice_buffer* dst) {+  if (n == 0) {+    return;+  }+  if (n == src->length) {",This looks like a Yoda comparison even though it technically isn't; any reason for the change?,
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19543,300110996,2019-07-03T18:57:40Z,src/core/lib/slice/slice_buffer.cc,"@@ -262,54 +276,79 @@ void grpc_slice_buffer_move_into(grpc_slice_buffer* src,   src->length = 0; } +template <bool incref>+static void slice_buffer_move_single_slice(grpc_slice_buffer* src,+                                           grpc_slice_buffer* dst,+                                           size_t bytes_extra) {+  // Last slice in batch for slice_buffer_move_first_maybe_ref.+  // We may have to consume it  whole, or just a chunk.+  if (bytes_extra) {+    // Just a chunk.+    if (incref) {+      dst->slices[dst->count] = grpc_slice_split_head(+          &src->slices[0], GRPC_SLICE_LENGTH(src->slices[0]) - bytes_extra);+    } else {+      dst->slices[dst->count] = grpc_slice_split_head_noref(+          &src->slices[0], GRPC_SLICE_LENGTH(src->slices[0]) - bytes_extra);+    }+  } else {+    // The whole thing.+    dst->slices[dst->count] = src->slices[0];+    ++src->slices;+    --src->count;+  }+  ++dst->count;+}++template <bool incref> static void slice_buffer_move_first_maybe_ref(grpc_slice_buffer* src, size_t n,-                                              grpc_slice_buffer* dst,-                                              bool incref) {-  GPR_ASSERT(src->length >= n);-  if (src->length == n) {+                                              grpc_slice_buffer* dst) {+  if (n == 0) {+    return;+  }+  if (n == src->length) {","On a related note, have you heard about Yoda's other programming tips? He only uses do{} while() style loops, and eschews exception handling.  From the master himself: https://i.pinimg.com/originals/4c/31/6e/4c316ea2ae01be634bc9783ca982f55f.jpgI put the n == 0 change up high to give our callers a fast-path out when n is 0 (there is one caller in CH2 that does this) and for the next comparison I just flipped it for consistency. If desired I can flip it back so it's src->length == n; but I do believe the n == 0 check should come first.",
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/19543,300136841,2019-07-03T20:14:48Z,src/core/lib/slice/slice_buffer.cc,"@@ -262,54 +276,85 @@ void grpc_slice_buffer_move_into(grpc_slice_buffer* src,   src->length = 0; } +template <bool incref>+static void slice_buffer_move_single_slice(grpc_slice_buffer* src,+                                           grpc_slice_buffer* dst,+                                           size_t bytes_extra) {+  // Last slice in batch for slice_buffer_move_first_maybe_ref.+  // We may have to consume it  whole, or just a chunk.+  if (bytes_extra) {+    // Just a chunk.+    if (incref) {+      dst->slices[dst->count] = grpc_slice_split_head(+          &src->slices[0], GRPC_SLICE_LENGTH(src->slices[0]) - bytes_extra);+    } else {+      dst->slices[dst->count] = grpc_slice_split_head_noref(+          &src->slices[0], GRPC_SLICE_LENGTH(src->slices[0]) - bytes_extra);+    }+  } else {+    // The whole thing.+    dst->slices[dst->count] = src->slices[0];+    ++src->slices;+    --src->count;+  }+  ++dst->count;+}++template <bool incref> static void slice_buffer_move_first_maybe_ref(grpc_slice_buffer* src, size_t n,-                                              grpc_slice_buffer* dst,-                                              bool incref) {-  GPR_ASSERT(src->length >= n);-  if (src->length == n) {+                                              grpc_slice_buffer* dst) {+  if (n == 0) {+    return;+  }+  if (n == src->length) {     grpc_slice_buffer_move_into(src, dst);     return;   }+  GPR_ASSERT(src->length > n);++  size_t slices_to_copy = 0;+  size_t bytes_so_far = 0;+  size_t curr_idx = 0;+  /* There are two general ways to architect this kind of method; we can copy a+   * slice at a time, or we can pre-iterate the slices to see how many slices in+   * total we need to copy. Given that the last slice may need to be split, the+   * former approach suffers from the need for an additional comparison per+   * slice to see if such a split is necessary. Pre-iterating as we've done here+   * does require iterating the array twice, but saves the branches. */+  while (bytes_so_far < n) {+    bytes_so_far += GRPC_SLICE_LENGTH(src->slices[curr_idx]);+    slices_to_copy++;+    curr_idx++;+  }+  const size_t bytes_extra = bytes_so_far - n;+  maybe_embiggen<true>(dst, slices_to_copy); -  size_t output_len = dst->length + n;-  size_t new_input_len = src->length - n;--  while (src->count > 0) {-    grpc_slice slice = grpc_slice_buffer_take_first(src);-    size_t slice_len = GRPC_SLICE_LENGTH(slice);-    if (n > slice_len) {-      grpc_slice_buffer_add(dst, slice);-      n -= slice_len;-    } else if (n == slice_len) {-      grpc_slice_buffer_add(dst, slice);-      break;-    } else if (incref) { /* n < slice_len */-      grpc_slice_buffer_undo_take_first(-          src, grpc_slice_split_tail_maybe_ref(&slice, n, GRPC_SLICE_REF_BOTH));-      GPR_ASSERT(GRPC_SLICE_LENGTH(slice) == n);-      grpc_slice_buffer_add(dst, slice);-      break;-    } else { /* n < slice_len */-      grpc_slice_buffer_undo_take_first(-          src, grpc_slice_split_tail_maybe_ref(&slice, n, GRPC_SLICE_REF_TAIL));-      GPR_ASSERT(GRPC_SLICE_LENGTH(slice) == n);-      grpc_slice_buffer_add_indexed(dst, slice);-      break;-    }+  if (slices_to_copy == 1) {+    slice_buffer_move_single_slice<incref>(src, dst, bytes_extra);+  } else {+    // memcpy all but the last slice to dst.+    const size_t all_but_last = slices_to_copy - 1;+    memcpy(&dst->slices[dst->count], &src->slices[0],+           sizeof(grpc_slice) * all_but_last);+    dst->count += all_but_last;+    src->count -= all_but_last;+    src->slices += all_but_last;+    slice_buffer_move_single_slice<incref>(src, dst, bytes_extra);   }-  GPR_ASSERT(dst->length == output_len);-  GPR_ASSERT(src->length == new_input_len);-  GPR_ASSERT(src->count > 0);++  src->length -= n;+  dst->length += n;+  GPR_DEBUG_ASSERT(src->count > 0); }  void grpc_slice_buffer_move_first(grpc_slice_buffer* src, size_t n,                                   grpc_slice_buffer* dst) {-  slice_buffer_move_first_maybe_ref(src, n, dst, true);+  slice_buffer_move_first_maybe_ref<true>(src, n, dst);",I'd suggest splitting this patch into multiple PRs.  At least an easy one can be just converting this boolean argument to a template parameter.,OK
17328,mgravell,https://api.github.com/repos/grpc/grpc/pulls/19511,300258702,2019-07-04T07:17:18Z,src/csharp/Grpc.Core.Api/Metadata.cs,"@@ -345,15 +346,44 @@ internal byte[] GetSerializedValueUnsafe()             /// Creates a binary value or ascii value metadata entry from data received from the native layer.             /// We trust C core to give us well-formed data, so we don't perform any checks or defensive copying.             /// </summary>-            internal static Entry CreateUnsafe(string key, byte[] valueBytes)+            internal static unsafe Entry CreateUnsafe(string key, byte* source, int length)             {                 if (HasBinaryHeaderSuffix(key))                 {-                    return new Entry(key, null, valueBytes);+                    byte[] arr;+                    if (length == 0)+                    {+                        arr = EmptyBlob;+                    }+                    else+                    {   // create a local copy in a fresh array+                        arr = new byte[length];+                        Marshal.Copy(new IntPtr(source), arr, 0, length);+                    }+                    return new Entry(key, null, arr);+                }+                else+                {+                    string s;+                    if (length == 0)+                    {+                        s = """";+                    }+                    else+                    {+                        int charCount = EncodingASCII.GetCharCount(source, length);","you've made me think; there *is* actually a way to do this with `Encoding`, except on NET45; I propose we make use of this, using a shim/polyfill only for the NET45 (see new `Grpc.Core.Api.Utils.EncodingExtensions` class) - then how the actual alloc happens is a BCL concern, and can use evils if desired - specifically, it uses `string str = FastAllocateString(length)`, which does an alloc **without wipe**, then over-writes. What is *really* interesting to me here is the implication re transitive dependencies and nuget resolution: a NET472 application will use the NET45 bits, which means it *wouldn't* use this API; what are your thoughts on adding an additional NET46 TFM? (NET46 is when this API becomes available). Or if not NET46, NET48 - i.e. ""add an additional .NET Framework TFM that will allow the maximum level of API surface, leaving NET45 as the down-level fallback; nothing in-between"" ?",
28123841,guantaol,https://api.github.com/repos/grpc/grpc/pulls/19544,301362389,2019-07-09T01:23:00Z,src/core/lib/iomgr/executor/threadpool.cc,"@@ -0,0 +1,136 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/support/port_platform.h>++#include ""src/core/lib/iomgr/executor/threadpool.h""++namespace grpc_core {++void ThreadPoolWorker::Run() {+  while (true) {+    void* elem;++    if (GRPC_TRACE_FLAG_ENABLED(grpc_thread_pool_trace)) {+      // Updates stats and print+      gpr_timespec wait_time = gpr_time_0(GPR_TIMESPAN);+      elem = static_cast<InfLenFIFOQueue*>(queue_)->Get(&wait_time);+      stats_.sleep_cycles = gpr_time_add(stats_.sleep_cycles, wait_time);+      gpr_log(GPR_INFO,+              ""ThreadPool Worker [%s %d] Stats:  sleep_cycles          %f"",+              thd_name_, index_, gpr_timespec_to_micros(stats_.sleep_cycles));+    } else {+      elem = static_cast<InfLenFIFOQueue*>(queue_)->Get();+    }+    if (elem == nullptr) {+      break;+    }+    // Runs closure+    grpc_experimental_completion_queue_functor* closure =+        static_cast<grpc_experimental_completion_queue_functor*>(elem);+    closure->functor_run(closure->internal_next, closure->internal_success);","This should be ""closure->functor_run(closure, closure->...)"", right?https://github.com/grpc/grpc/blob/master/src/core/lib/surface/completion_queue.cc#L822",
28123841,guantaol,https://api.github.com/repos/grpc/grpc/pulls/19544,301379463,2019-07-09T03:06:39Z,src/core/lib/iomgr/executor/threadpool.h,"@@ -0,0 +1,153 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_IOMGR_EXECUTOR_THREADPOOL_H+#define GRPC_CORE_LIB_IOMGR_EXECUTOR_THREADPOOL_H++#include <grpc/support/port_platform.h>++#include <grpc/grpc.h>++#include ""src/core/lib/gprpp/thd.h""+#include ""src/core/lib/iomgr/executor/mpmcqueue.h""++namespace grpc_core {++// A base abstract base class for threadpool.+// Threadpool is an executor that maintains a pool of threads sitting around+// and waiting for closures. A threadpool also maintains a queue of pending+// closures, when closures appearing in the queue, the threads in pool will+// pull them out and execute them.+class ThreadPoolInterface {+ public:+  // Waits for all pending closures to complete, then shuts down thread pool.+  virtual ~ThreadPoolInterface() {}++  // Schedules a given closure for execution later.+  // Depending on specific subclass implementation, this routine might cause+  // current thread to be blocked (in case of unable to schedule).+  // Closure should contain a function pointer and arguments it will take, more+  // details for closure struct at /grpc/include/grpc/impl/codegen/grpc_types.h+  virtual void Add(grpc_experimental_completion_queue_functor* closure)+      GRPC_ABSTRACT;++  // Returns the current number of pending closures+  virtual int num_pending_closures() const GRPC_ABSTRACT;++  // Returns the capacity of pool (number of worker threads in pool)+  virtual int pool_capacity() const GRPC_ABSTRACT;++  // Thread option accessor+  virtual const Thread::Options& thread_options() const GRPC_ABSTRACT;++  // Returns the thread name for threads in this ThreadPool.+  virtual const char* thread_name() const GRPC_ABSTRACT;++  GRPC_ABSTRACT_BASE_CLASS+};++// Worker thread for threadpool. Executes closures in the queue, until getting a+// NULL closure.+class ThreadPoolWorker {+ public:+  ThreadPoolWorker(const char* thd_name, ThreadPoolInterface* pool,+                   MPMCQueueInterface* queue, Thread::Options& options,+                   int index)+      : queue_(queue), thd_name_(thd_name), index_(index) {+    thd_ = Thread(thd_name,+                  [](void* th) { static_cast<ThreadPoolWorker*>(th)->Run(); },+                  this, nullptr, options);+  }++  ~ThreadPoolWorker() {}++  void Start() { thd_.Start(); }+  void Join() { thd_.Join(); }++  GRPC_ABSTRACT_BASE_CLASS","ThreadPoolWorker is not an abstract base class, right?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/15460,301758568,2019-07-09T19:35:24Z,doc/PROTOCOL-SEMANTICS.md,"@@ -0,0 +1,268 @@+# gRPC semantics++gRPC has many features, but the most fundamental core is the ability to perform+RPCs. The goal of this document is defining the semantics of gRPC's RPCs.++## Channels++Most implementations will have Channel and Server concepts. A Channel is a+virtual connection to an endpoint, capable of sending RPCs. Channel is ""virtual""+because the Channel is free to have zero or many actual connections. A Channel+is free to determine which actual endpoint to use and may change it every RPC,+permitting client-side load balancing. A Server is capable of receiving incoming+connections and receiving RPCs.++A ""connection"" is not a gRPC semantic concept and thus users should not assume a+correlation between connections and RPCs. Although, practically, users should be+aware of the common restriction that RPCs are unable to survive longer than the+connection on which they exist.++The exact details of how the communication is performed and higher level+abstractions can change when necessary and are thus not a focus for this+document. Although implementations SHOULD support the [HTTP/2+transport](PROTOCOL-HTTP2.md) to provide a basis for interoperability.++## Methods++An RPC is performed on a Method. The Method has a name, defines the intended+operation, the message types involved with the RPC, and the cardinality of+those messages.  It does not define the endpoint to send the RPC to; this is+normally handled by the Channel.++A Method's intended operation is just normal documentation describing what a+Method does, intended for a developer. gRPC itself is not generally aware of the+intended operation.++A Method has a request message type and a separate response message type. gRPC+is only aware of these types well enough to serialize and deserialize them.+Messages are considered opaque byte sequences of a known length to gRPC itself.++A Method's request and response each have a cardinality: either one (""unary""),+or zero to many (a ""stream""). This produces four possible configurations which,+for convenience, each have a name:++|                       | **unary response** | **streaming response** |+| --------------------- | ------------------ | ---------------------- |+| **unary request**     | unary              | server-streaming       |+| **streaming request** | client-streaming   | bidirectional (bidi)   |++While we use the term ""method,"" pedantically it is closer to ""function"" as it is+not object oriented and there is no ""receiver"" involved (the `this` variable in+many languages) other than the destination machine. gRPC is based on message+passing, not object orientation.++Related Methods are typically grouped into a Service. To gRPC, a Service is a+group of methods that tend to be implemented together and that all share the+Service's namespace. A Service is a higher-level abstraction and may not be+present explicitly in all implementations. However, the namespace provided by a+Service is a core distinguishing feature of its Methods; if two Methods have the+same name but exist in different Services they must be considered distinct and+not be confused. A Method name including its Service namespace prefix with a ""/""+separator is a ""full method name"".++## Calls++RPCs, or ""Calls,"" are initiated by a client to a server, typically via a+Channel. There may be multiple servers that _could_ have received the Call (as+is common for load balancing), but only a single server may process an+individual Call. Calls are assumed to be non-idempotent and may not be+""replayed"" except for when gRPC is explicitly informed it is safe to do so.++Calls are natively two independent streams (i.e., full duplex bidirectional) of+Messages. The request stream is started with Request Headers and ended by Half+Close. The response stream is started with Response Headers and ended by+Trailers, or consistes only of Trailers. Messages may exist between the headers+and the end of the stream. Request Headers, Response Headers, Messages, Half+Close, and Trailers are the units of communication and, absent the Call's+termination, will be communicated to the remote without the need to send further+units on the stream. However, see the optimizations permitted for unary Calls+below.++Request Headers contain the Full Method Name and Metadata. Response Headers+contain Metadata. Trailers contain the Status and Metadata. Messages contain the+Message Payload. These contents are not exhaustive; gRPC features may extend+these concepts. It is quite common for features to add additional fields to+Request Headers, Response Headers, and Trailers.++The Call initiation is with Request Headers, within which the client+indicates the method to be run by its Full Method Name. The Call is gracefully+completed when the server responds with Trailers, which contains a Status+communicating the success or failure of the RPC. If a server responds with+Trailers before receiving the client's Half Close, then any unprocessed+client-sent Messages and Half Close is lost. Note that on the server there is a+period of time between when the server application responds with a Trailers and+when that Trailers is actually sent; the Call is only truly complete when the+Trailers is sent. Similarly, on the client there is a period between the gRPC+implementation receiving the Trailers and when the application receives the+Trailers; the Call is only truly complete when the Trailers is received by the+application.++Calls may terminate early by being ""cancelled."" Implementations must allow+clients to cancel Calls, but cancellations may occur in other ways like I/O+failures. A cancellation appears as a Trailers with a Status Code of CANCELLED+to clients and is a special state on servers. Cancellation is an abrupt killing+of the Call; inbound and outbound buffered data should be cleared. Cancellation+trumps graceful completion; if the client gRPC implementation received the+Trailers before the cancellation, yet the client application has not received+the Trailers, then cancellation generally should win. No auxiliary information+is included in cancellation signals between the client and server. Server+implementations may fail a Call and respond with Trailers while claiming to the+server application that the Call was cancelled.++The two independent streams are each unidirectional and do not provide any+information in the reverse direction other than Flow Control. Flow Control+is a signal from the receiver to the sender to temporarily pause sending+additional messages to avoid excessive buffering. Flow Control only applies to+messages, but since streams are in-order Half Close or Trailers may be delayed+waiting for message Flow Control in the same stream. No message receipt+acknowledgement information is provided. However applications may use messages+for such signals, as a response naturally acknowledges its request. Note in+particular that there is no provision for the server application to not know+whether the client application received a unary Call's response or a streaming+Call's Status.++Unary Calls may be optimized to be half-duplex and treat each stream as a single+communication unit. That is, on the client a unary Call may be delayed from+being sent until the Half Close is ready to be sent and on the server the+response may be delayed until the Trailers is ready.++Unary Calls that terminate with a Status Code of OK must contain a response+message. Unary Calls that terminate with a Status Code other than OK do not need","@vjpai @hcaseyal This last sentence touches on the issue we were discussing earlier today.Although this spec says that discarding the message is optional, I think that in the C++ server-side sync and callback APIs, it would be a mistake to send the payload for a unary RPC that returns a non-OK status, because we have no guarantee that the payload's data contains anything useful.",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19586,301824555,2019-07-09T22:47:13Z,src/python/grpcio_tests/tests/unit/_signal_handling_test.py,"@@ -104,6 +115,15 @@ def _read_stream(stream):     return stream.read()  +def _start_client(args, stdout, stderr):+    invocation = None+    if sys.executable is not None:+        invocation = (sys.executable, _CLIENT_PATH) + tuple(args)","Interestingly, concatenation on tuples is faster than lists.```>>> import timeit>>> a =[1,3,4,5]>>> def t1():...   return (7,) + tuple(a)...>>> timeit.timeit(t1)0.21551179885864258>>> def t2():...   return [7] + a...>>> timeit.timeit(t2)0.2819240093231201```",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19536,302026570,2019-07-10T11:59:28Z,src/csharp/Grpc.Core/Channel.cs,"@@ -35,7 +35,7 @@ public class Channel         static readonly ILogger Logger = GrpcEnvironment.Logger.ForType<Channel>();          readonly object myLock = new object();-        readonly AtomicCounter activeCallCounter = new AtomicCounter();",A channel is supposed to be a heavy-weight object that doesn't get created very often and the overhead of creating it (including the native code) is much much larger than this single allocation.,OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19536,302030720,2019-07-10T12:11:14Z,src/csharp/Grpc.Core/Internal/CompletionQueueSafeHandle.cs,"@@ -29,7 +29,7 @@ internal class CompletionQueueSafeHandle : SafeHandleZeroIsInvalid     {         static readonly NativeMethods Native = NativeMethods.Get(); -        AtomicCounter shutdownRefcount = new AtomicCounter(1);+        long shutdownRefcount = AtomicCounter.Create(1);","The async completion queues (used by the threadpool) are only initialized when GrpcEnvironment (and the internal threadpool) is started, so this overhead is negligible compared to the costs of initializing the grpc stack.On the other hand, if you're using sync unary calls, a new completion queue is created for each call (that's how the C-core native API works) - I think in this case you're onto something and we actually might be initializing one AtomicCounter per RPC. Let me look into that.https://github.com/grpc/grpc/blob/4a2f2dd1f1a65a8463e4002d6edaf9ddcbd9db7a/src/csharp/Grpc.Core/Internal/AsyncCall.cs#L81All the other allocations of AtomicCounter in this pull request are in situations that happen too rarely to actually matter IMHO.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19330,302149384,2019-07-10T16:04:59Z,src/core/lib/slice/slice_internal.h,"@@ -312,4 +312,21 @@ grpc_slice grpc_slice_from_moved_string(grpc_core::UniquePtr<char> p); // 0. All other slices will return the size of the allocated chars. size_t grpc_slice_memory_usage(grpc_slice s); +void grpc_slice_buffer_transfer(grpc_slice_buffer* src, grpc_slice_buffer* dst);+void grpc_do_slice_buffer_move_into(grpc_slice_buffer* src,","Sorry, this is insufficient.  The only case where you can ignore these naming rules is for something defined in a .cc file as `static` or in an anonymous namespace, because those are purely local -- they do not get turned into symbols visible to the linker and therefore cannot conflict with anything defined in any other module.  Functions like this that are defined in a .h file are actually turned into symbols visible to the linker and must follow naming rules to avoid conflicts.Note that if we converted this to a C++ class, these could be private methods instead of standalone functions, in which case this namespacing issue would go away.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19330,302151561,2019-07-10T16:09:41Z,src/core/lib/slice/slice_internal.h,"@@ -327,4 +327,32 @@ inline grpc_slice grpc_slice_from_static_string_internal(const char* s) {   return grpc_slice_from_static_buffer_internal(s, strlen(s)); } +/* Helper method for grpc_slice_buffer_move_into_internal only - used when+   dst is empty. Only grpc_slice_buffer_move_into_internal() should be used.+   Think of this as a static method, not part of the internal API. */+void _helper_grpc_slice_buffer_move_into_empty_buf(grpc_slice_buffer* src,+                                                   grpc_slice_buffer* dst);+/* Helper method for grpc_slice_buffer_move_into_internal only - used when both+   src and dst are non-empty. While this method still executes correctly+   if directly called (including when src and/or dst are empty), only+   grpc_slice_buffer_move_into_internal() should be used. Think of this as a+   static method, not part of the internal API. */+void _helper_grpc_slice_buffer_move_into_buf(grpc_slice_buffer* src,+                                             grpc_slice_buffer* dst);+/* Move all of the elements of src into dst. This is part of the internal API.+   It makes no assumptions on either src or dst. */","I think this explanation is too vague from the perspective of someone reading this and trying to understand the API.  What does it mean to ""make no assumptions""?I think it would be better to state the preconditions (e.g., both `src` and `dst` must be initialized) and postconditions (e.g., any pre-existing slices in `dst` will be unreffed).",
50905639,weiyongji,https://api.github.com/repos/grpc/grpc/pulls/19544,302339632,2019-07-11T02:13:07Z,src/core/lib/iomgr/executor/threadpool.h,"@@ -0,0 +1,154 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_IOMGR_EXECUTOR_THREADPOOL_H+#define GRPC_CORE_LIB_IOMGR_EXECUTOR_THREADPOOL_H++#include <grpc/support/port_platform.h>++#include <grpc/grpc.h>++#include ""src/core/lib/gprpp/thd.h""+#include ""src/core/lib/iomgr/executor/mpmcqueue.h""++namespace grpc_core {++// A base abstract base class for threadpool.+// Threadpool is an executor that maintains a pool of threads sitting around+// and waiting for closures. A threadpool also maintains a queue of pending+// closures, when closures appearing in the queue, the threads in pool will+// pull them out and execute them.+class ThreadPoolInterface {+ public:+  // Waits for all pending closures to complete, then shuts down thread pool.+  virtual ~ThreadPoolInterface() {}++  // Schedules a given closure for execution later.+  // Depending on specific subclass implementation, this routine might cause+  // current thread to be blocked (in case of unable to schedule).+  // Closure should contain a function pointer and arguments it will take, more+  // details for closure struct at /grpc/include/grpc/impl/codegen/grpc_types.h+  virtual void Add(grpc_experimental_completion_queue_functor* closure)+      GRPC_ABSTRACT;++  // Returns the current number of pending closures+  virtual int num_pending_closures() const GRPC_ABSTRACT;+",suggest unify the function name format of the class.,OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/19453,302678963,2019-07-11T18:14:52Z,src/core/ext/transport/chttp2/transport/hpack_table.h,"@@ -46,41 +47,67 @@ #endif  /* hpack decoder table */-typedef struct {+struct grpc_chttp2_hptbl {+  static uint32_t entries_for_bytes(uint32_t bytes) {+    return (bytes + GRPC_CHTTP2_HPACK_ENTRY_OVERHEAD - 1) /+           GRPC_CHTTP2_HPACK_ENTRY_OVERHEAD;+  }+  static constexpr uint32_t kInitialCapacity =+      (GRPC_CHTTP2_INITIAL_HPACK_TABLE_SIZE + GRPC_CHTTP2_HPACK_ENTRY_OVERHEAD -+       1) /+      GRPC_CHTTP2_HPACK_ENTRY_OVERHEAD;++  grpc_chttp2_hptbl() {+    constexpr uint32_t AllocSize = sizeof(ents[0]) * kInitialCapacity;+    grpc_mdelem* ents_new = static_cast<grpc_mdelem*>(gpr_malloc(AllocSize));+    memset(ents_new, 0, AllocSize);+    ents.reset(ents_new);+  }+   /* the first used entry in ents */-  uint32_t first_ent;+  uint32_t first_ent = 0;   /* how many entries are in the table */-  uint32_t num_ents;+  uint32_t num_ents = 0;   /* the amount of memory used by the table, according to the hpack algorithm */-  uint32_t mem_used;+  uint32_t mem_used = 0;   /* the max memory allowed to be used by the table, according to the hpack      algorithm */-  uint32_t max_bytes;+  uint32_t max_bytes = GRPC_CHTTP2_INITIAL_HPACK_TABLE_SIZE;   /* the currently agreed size of the table, according to the hpack algorithm */-  uint32_t current_table_bytes;+  uint32_t current_table_bytes = GRPC_CHTTP2_INITIAL_HPACK_TABLE_SIZE;   /* Maximum number of entries we could possibly fit in the table, given defined      overheads */-  uint32_t max_entries;+  uint32_t max_entries = kInitialCapacity;   /* Number of entries allocated in ents */-  uint32_t cap_entries;+  uint32_t cap_entries = kInitialCapacity;   /* a circular buffer of headers - this is stored in the opposite order to      what hpack specifies, in order to simplify table management a little...      meaning lookups need to SUBTRACT from the end position */-  grpc_mdelem* ents;-  grpc_mdelem static_ents[GRPC_CHTTP2_LAST_STATIC_ENTRY];-} grpc_chttp2_hptbl;+  grpc_core::UniquePtr<grpc_mdelem[], grpc_core::DefaultDelete<grpc_mdelem>>","similar to strings that use `UniquePtr<char>`, I would just use `grpc_core::UniquePtr<grpc_mdelem>` here too. It basically is an array.",OK
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19453,302770169,2019-07-11T22:43:56Z,src/core/ext/transport/chttp2/transport/hpack_table.h,"@@ -46,41 +47,67 @@ #endif  /* hpack decoder table */-typedef struct {+struct grpc_chttp2_hptbl {+  static uint32_t entries_for_bytes(uint32_t bytes) {+    return (bytes + GRPC_CHTTP2_HPACK_ENTRY_OVERHEAD - 1) /+           GRPC_CHTTP2_HPACK_ENTRY_OVERHEAD;+  }+  static constexpr uint32_t kInitialCapacity =+      (GRPC_CHTTP2_INITIAL_HPACK_TABLE_SIZE + GRPC_CHTTP2_HPACK_ENTRY_OVERHEAD -+       1) /+      GRPC_CHTTP2_HPACK_ENTRY_OVERHEAD;++  grpc_chttp2_hptbl() {+    constexpr uint32_t AllocSize = sizeof(ents[0]) * kInitialCapacity;+    grpc_mdelem* ents_new = static_cast<grpc_mdelem*>(gpr_malloc(AllocSize));+    memset(ents_new, 0, AllocSize);+    ents.reset(ents_new);+  }+   /* the first used entry in ents */-  uint32_t first_ent;+  uint32_t first_ent = 0;   /* how many entries are in the table */-  uint32_t num_ents;+  uint32_t num_ents = 0;   /* the amount of memory used by the table, according to the hpack algorithm */-  uint32_t mem_used;+  uint32_t mem_used = 0;   /* the max memory allowed to be used by the table, according to the hpack      algorithm */-  uint32_t max_bytes;+  uint32_t max_bytes = GRPC_CHTTP2_INITIAL_HPACK_TABLE_SIZE;   /* the currently agreed size of the table, according to the hpack algorithm */-  uint32_t current_table_bytes;+  uint32_t current_table_bytes = GRPC_CHTTP2_INITIAL_HPACK_TABLE_SIZE;   /* Maximum number of entries we could possibly fit in the table, given defined      overheads */-  uint32_t max_entries;+  uint32_t max_entries = kInitialCapacity;   /* Number of entries allocated in ents */-  uint32_t cap_entries;+  uint32_t cap_entries = kInitialCapacity;   /* a circular buffer of headers - this is stored in the opposite order to      what hpack specifies, in order to simplify table management a little...      meaning lookups need to SUBTRACT from the end position */-  grpc_mdelem* ents;-  grpc_mdelem static_ents[GRPC_CHTTP2_LAST_STATIC_ENTRY];-} grpc_chttp2_hptbl;+  grpc_core::UniquePtr<grpc_mdelem[], grpc_core::DefaultDelete<grpc_mdelem>>","We do not need to worry about this.1) The only time the memory gets de-allocated is if we're re-hashing the table on grow(), or freeing the table at the end with destroy().2) If we're growing, we explicitly do not want to call the destructor.3) If we're destroying, we already call Unref() on the metadata before we free the memory.",
28123841,guantaol,https://api.github.com/repos/grpc/grpc/pulls/19544,302773370,2019-07-11T22:57:44Z,src/core/lib/iomgr/executor/threadpool.h,"@@ -0,0 +1,154 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPC_CORE_LIB_IOMGR_EXECUTOR_THREADPOOL_H+#define GRPC_CORE_LIB_IOMGR_EXECUTOR_THREADPOOL_H++#include <grpc/support/port_platform.h>++#include <grpc/grpc.h>++#include ""src/core/lib/gprpp/thd.h""+#include ""src/core/lib/iomgr/executor/mpmcqueue.h""++namespace grpc_core {++// A base abstract base class for threadpool.+// Threadpool is an executor that maintains a pool of threads sitting around+// and waiting for closures. A threadpool also maintains a queue of pending+// closures, when closures appearing in the queue, the threads in pool will+// pull them out and execute them.+class ThreadPoolInterface {+ public:+  // Waits for all pending closures to complete, then shuts down thread pool.+  virtual ~ThreadPoolInterface() {}++  // Schedules a given closure for execution later.+  // Depending on specific subclass implementation, this routine might cause+  // current thread to be blocked (in case of unable to schedule).+  // Closure should contain a function pointer and arguments it will take, more+  // details for closure struct at /grpc/include/grpc/impl/codegen/grpc_types.h+  virtual void Add(grpc_experimental_completion_queue_functor* closure)+      GRPC_ABSTRACT;++  // Returns the current number of pending closures+  virtual int num_pending_closures() const GRPC_ABSTRACT;++  // Returns the capacity of pool (number of worker threads in pool)+  virtual int pool_capacity() const GRPC_ABSTRACT;++  // Thread option accessor+  virtual const Thread::Options& thread_options() const GRPC_ABSTRACT;++  // Returns the thread name for threads in this ThreadPool.+  virtual const char* thread_name() const GRPC_ABSTRACT;++  GRPC_ABSTRACT_BASE_CLASS+};++// Worker thread for threadpool. Executes closures in the queue, until getting a+// NULL closure.+class ThreadPoolWorker {+ public:+  ThreadPoolWorker(const char* thd_name, ThreadPoolInterface* pool,+                   MPMCQueueInterface* queue, Thread::Options& options,+                   int index)+      : queue_(queue), thd_name_(thd_name), index_(index) {+    thd_ = Thread(thd_name,+                  [](void* th) { static_cast<ThreadPoolWorker*>(th)->Run(); },+                  this, nullptr, options);+  }++  ~ThreadPoolWorker() {}++  void Start() { thd_.Start(); }+  void Join() { thd_.Join(); }++  // GRPC_ABSTRACT_BASE_CLASS++ private:+  // struct for tracking stats of thread+  struct Stats {+    gpr_timespec sleep_time;+    Stats() { sleep_time = gpr_time_0(GPR_TIMESPAN); }+  };++  void Run();  // Pulls closures from queue and executes them++  MPMCQueueInterface* queue_;  // Queue in thread pool to pull closures from+  Thread thd_;                 // Thread wrapped in+  Stats stats_;                // Stats to be collected in run time+  const char* thd_name_;       // Name of thread+  int index_;                  // Index in thread pool+};++// A fixed size thread pool implementation of abstract thread pool interface.+// In this implementation, the number of threads in pool is fixed, but the+// capacity of closure queue is unlimited.",We already have grpc_core::Executor https://github.com/grpc/grpc/blob/master/src/core/lib/iomgr/executor.h as a thread pool with dynamic size. We may add another implementation of ThreadPoolInterface with dynamic size in the future.,OK
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19427,302780264,2019-07-11T23:32:04Z,src/core/ext/filters/client_channel/health/health_check_client.cc,"@@ -354,7 +354,8 @@ void HealthCheckClient::CallState::StartCall() {   grpc_metadata_batch_init(&send_initial_metadata_);   error = grpc_metadata_batch_add_head(       &send_initial_metadata_, &path_metadata_storage_,-      grpc_mdelem_from_slices(+      // TODO(arjunroy): They're both static.","Added an overload for this case, so this comment no longer applies.",
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19427,302781449,2019-07-11T23:37:58Z,src/core/lib/transport/metadata.cc,"@@ -365,14 +404,101 @@ grpc_mdelem grpc_mdelem_create(   return GRPC_MAKE_MDELEM(md, GRPC_MDELEM_STORAGE_INTERNED); } -grpc_mdelem grpc_mdelem_from_slices(const grpc_slice& key,-                                    const grpc_slice& value) {-  grpc_mdelem out = grpc_mdelem_create(key, value, nullptr);-  grpc_slice_unref_internal(key);+template <bool key_definitely_static>+static grpc_mdelem md_create_maybe_static(const grpc_slice& key,+                                          const grpc_slice& value) {+  const bool key_is_static_mdstr =+      key_definitely_static || GRPC_IS_STATIC_METADATA_STRING(key);+  const intptr_t kidx = GRPC_STATIC_METADATA_INDEX(key);++  // Not all static slice input yields a statically stored metadata element.+  // It may be worth documenting why.+  if (key_is_static_mdstr && GRPC_IS_STATIC_METADATA_STRING(value)) {+    grpc_mdelem static_elem = grpc_static_mdelem_for_static_strings(+        kidx, GRPC_STATIC_METADATA_INDEX(value));+    if (!GRPC_MDISNULL(static_elem)) {+      return static_elem;+    }+  }++  uint32_t khash = key_definitely_static+                       ? grpc_static_metadata_hash_values[kidx]+                       : grpc_slice_hash_refcounted(key);++  uint32_t hash = GRPC_MDSTR_KV_HASH(khash, grpc_slice_hash_refcounted(value));+  return md_create_must_intern<key_definitely_static>(key, value, hash);+}++grpc_mdelem grpc_mdelem_create_static_key_interned_val(+    const grpc_slice& key, const grpc_slice& value) {+  grpc_mdelem ret = md_create_maybe_static<true>(key, value);+  grpc_slice_unref_internal(value);+  return ret;+}++template <bool key_definitely_static>+static grpc_mdelem md_create(","Updated PR has comments, but more importantly, the programmer need no longer actively think about which method to pick due to the strongly typed slices.",OK
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19552,303668398,2019-07-15T22:50:03Z,src/core/ext/transport/chttp2/transport/hpack_parser.cc,"@@ -1499,6 +1521,18 @@ static bool is_binary_literal_header(grpc_chttp2_hpack_parser* p) {                     : p->key.data.referenced); } +/* Cache the metadata for the given index during initial parsing. This avoids a+   pointless recomputation of the metadata when finishing a header. */+static void set_precomputed_md_idx(grpc_chttp2_hpack_parser* p,+                                   grpc_mdelem md) {+  GPR_DEBUG_ASSERT(p->md_for_index.payload == 0);+  GPR_DEBUG_ASSERT(p->precomputed_md_index == -1);+  p->md_for_index = md;+#ifndef NDEBUG+  p->precomputed_md_index = p->index;+#endif+}+ static grpc_error* is_binary_indexed_header(grpc_chttp2_hpack_parser* p,","I don't think we should change the function name here since it's just a caching optimization, not the overall point of the function. I did add a comment for the function explaining that it is doing the caching, however, and where the cached value is read. The only way to use the function incorrectly is if we call get_precomputed_md_for_idx() without a preceding call to set_precomputed_md_idx(), in which case the debug assert should tell us we did something bad.",OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/19405,304125229,2019-07-16T21:22:22Z,src/core/ext/filters/client_channel/lb_policy.h,"@@ -92,14 +92,51 @@ class LoadBalancingPolicy : public InternallyRefCounted<LoadBalancingPolicy> {     GRPC_ABSTRACT_BASE_CLASS   }; +  /// Interface for access metadata.+  class MetadataInterface {","Sorry I have a rather stupid question: There would be significant overheads just because of this is an abstract class.  Looking at the usage, I cannot tell whether this interface would have other implementations.  Are you envisioning some other immediate implementation of the interface?If not, would it make sense to eliminate the `Interface` and replace with `Metadata`?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19405,304134306,2019-07-16T21:46:20Z,src/core/ext/filters/client_channel/lb_policy.h,"@@ -92,14 +92,51 @@ class LoadBalancingPolicy : public InternallyRefCounted<LoadBalancingPolicy> {     GRPC_ABSTRACT_BASE_CLASS   }; +  /// Interface for access metadata.+  class MetadataInterface {","One of the goals is to allow the LB policy API to be used in systems other than gRPC.  LB policy implementations should not know or care which system they're being used from, which means that we need to isolate them from internal APIs like `grpc_metadata_batch`.  So what I'm trying to do here is to provide a generic interface for accessing metadata from within an LB policy, where each system can have its own implementation of the interface, and the LB policy implementations can just go through the interface and not care which implementation they're being used from.",OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/19405,304150584,2019-07-16T22:21:16Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -310,6 +310,75 @@ class CallData {  private:   class QueuedPickCanceller; +  class Metadata : public LoadBalancingPolicy::MetadataInterface {+   public:+    class Iterator : public MetadataInterface::IteratorInterface {+     public:+      explicit Iterator(grpc_linked_mdelem* linked_mdelem)+          : linked_mdelem_(linked_mdelem) {}++      grpc_linked_mdelem* linked_mdelem() const { return linked_mdelem_; }++      virtual IteratorInterface& operator=(+          const IteratorInterface& other) override {+        const Iterator* it = static_cast<const Iterator*>(&other);+        linked_mdelem_ = it->linked_mdelem_;+        return *this;+      }++      virtual IteratorInterface& operator++() override {+        linked_mdelem_ = linked_mdelem_->next;+        return *this;+      }++      bool operator==(const IteratorInterface& other) const override {+        const Iterator* it = static_cast<const Iterator*>(&other);+        return linked_mdelem_ == it->linked_mdelem_;+      }++      virtual StringView Key() const override {+        return StringView(GRPC_MDKEY(linked_mdelem_->md));+      }++      virtual StringView Value() const override {+        return StringView(GRPC_MDVALUE(linked_mdelem_->md));+      }++     private:+      grpc_linked_mdelem* linked_mdelem_;+    };++    Metadata(CallData* calld, grpc_metadata_batch* batch)+        : calld_(calld), batch_(batch) {}++    void Add(const StringView& key, const StringView& value) override {+      grpc_linked_mdelem* linked_mdelem = static_cast<grpc_linked_mdelem*>(+          calld_->arena_->Alloc(sizeof(grpc_linked_mdelem)));+      bool returned_slice_is_different;+      linked_mdelem->md = grpc_mdelem_from_slices(+          grpc_slice_maybe_static_intern(+              grpc_slice_from_static_buffer_internal(key.data(), key.size()),+              &returned_slice_is_different),+          grpc_slice_from_static_buffer_internal(value.data(), value.size()));+      GPR_ASSERT(grpc_metadata_batch_link_tail(batch_, linked_mdelem) ==+                 GRPC_ERROR_NONE);+    }++    IteratorInterface Begin() override { return Iterator(batch_->list.head); }","I see. Another option to avoid a dynamic allocation is have the `Iterator` as a final class in `MetdataInterface`, and then having the `Iterator` call a private abstract method from  `MetdataInterface` which returns `next` based on the current `iter`. For instance, the interface can provide `Size()` and `At(size index, string_view& key, string_view& val)`.",OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/19405,304157947,2019-07-16T22:48:19Z,src/core/ext/filters/client_channel/lb_policy/grpclb/client_load_reporting_filter.cc,"@@ -95,22 +98,27 @@ static void start_transport_stream_op_batch(   GPR_TIMER_SCOPE(""clr_start_transport_stream_op_batch"", 0);   // Handle send_initial_metadata.   if (batch->send_initial_metadata) {-    // Grab client stats object from user_data for LB token metadata.-    grpc_linked_mdelem* lb_token =+    // Grab client stats object from metadata.+    grpc_linked_mdelem* client_stats_md =         batch->payload->send_initial_metadata.send_initial_metadata->idx.named-            .lb_token;-    if (lb_token != nullptr) {-      grpc_core::GrpcLbClientStats* client_stats =-          static_cast<grpc_core::GrpcLbClientStats*>(grpc_mdelem_get_user_data(-              lb_token->md, grpc_core::GrpcLbClientStats::Destroy));+            .grpclb_client_stats;+    if (client_stats_md != nullptr) {+      const char* client_stats_addr_str = reinterpret_cast<const char*>(+          GRPC_SLICE_START_PTR(GRPC_MDVALUE(client_stats_md->md)));+      grpc_core::GrpcLbClientStats* client_stats = nullptr;+      sscanf(client_stats_addr_str, ""%p"", &client_stats);","I have  two random ideas (please feel free to ignore):1) `StringView(ptr, 0)` is a valid pointer.  We can potentially pass that as the value instead. `grpc_slice_from_static_string` respects that, so we can send the pointer as a string. :-)2) We can add a `Get/SetStat()` to `MetadataInterface`.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19405,304158158,2019-07-16T22:49:15Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -310,6 +310,75 @@ class CallData {  private:   class QueuedPickCanceller; +  class Metadata : public LoadBalancingPolicy::MetadataInterface {+   public:+    class Iterator : public MetadataInterface::IteratorInterface {+     public:+      explicit Iterator(grpc_linked_mdelem* linked_mdelem)+          : linked_mdelem_(linked_mdelem) {}++      grpc_linked_mdelem* linked_mdelem() const { return linked_mdelem_; }++      virtual IteratorInterface& operator=(+          const IteratorInterface& other) override {+        const Iterator* it = static_cast<const Iterator*>(&other);+        linked_mdelem_ = it->linked_mdelem_;+        return *this;+      }++      virtual IteratorInterface& operator++() override {+        linked_mdelem_ = linked_mdelem_->next;+        return *this;+      }++      bool operator==(const IteratorInterface& other) const override {+        const Iterator* it = static_cast<const Iterator*>(&other);+        return linked_mdelem_ == it->linked_mdelem_;+      }++      virtual StringView Key() const override {+        return StringView(GRPC_MDKEY(linked_mdelem_->md));+      }++      virtual StringView Value() const override {+        return StringView(GRPC_MDVALUE(linked_mdelem_->md));+      }++     private:+      grpc_linked_mdelem* linked_mdelem_;+    };++    Metadata(CallData* calld, grpc_metadata_batch* batch)+        : calld_(calld), batch_(batch) {}++    void Add(const StringView& key, const StringView& value) override {+      grpc_linked_mdelem* linked_mdelem = static_cast<grpc_linked_mdelem*>(+          calld_->arena_->Alloc(sizeof(grpc_linked_mdelem)));+      bool returned_slice_is_different;+      linked_mdelem->md = grpc_mdelem_from_slices(+          grpc_slice_maybe_static_intern(+              grpc_slice_from_static_buffer_internal(key.data(), key.size()),+              &returned_slice_is_different),+          grpc_slice_from_static_buffer_internal(value.data(), value.size()));+      GPR_ASSERT(grpc_metadata_batch_link_tail(batch_, linked_mdelem) ==+                 GRPC_ERROR_NONE);+    }++    IteratorInterface Begin() override { return Iterator(batch_->list.head); }","An interface using `Size()` and `At()` assumes that the implementation is keeping the values in an array.  If possible, I'd rather have a more abstract interface that allows the implementation to choose its underlying data structure -- e.g., it should also work if the metadata is stored in a map.That having been said, I don't yet have a better idea, so I might wind up doing this anyway.  But let me see if I can think of a better alternative first.",OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/19405,304447283,2019-07-17T14:48:41Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -310,6 +310,75 @@ class CallData {  private:   class QueuedPickCanceller; +  class Metadata : public LoadBalancingPolicy::MetadataInterface {+   public:+    class Iterator : public MetadataInterface::IteratorInterface {+     public:+      explicit Iterator(grpc_linked_mdelem* linked_mdelem)+          : linked_mdelem_(linked_mdelem) {}++      grpc_linked_mdelem* linked_mdelem() const { return linked_mdelem_; }++      virtual IteratorInterface& operator=(+          const IteratorInterface& other) override {+        const Iterator* it = static_cast<const Iterator*>(&other);+        linked_mdelem_ = it->linked_mdelem_;+        return *this;+      }++      virtual IteratorInterface& operator++() override {+        linked_mdelem_ = linked_mdelem_->next;+        return *this;+      }++      bool operator==(const IteratorInterface& other) const override {+        const Iterator* it = static_cast<const Iterator*>(&other);+        return linked_mdelem_ == it->linked_mdelem_;+      }++      virtual StringView Key() const override {+        return StringView(GRPC_MDKEY(linked_mdelem_->md));+      }++      virtual StringView Value() const override {+        return StringView(GRPC_MDVALUE(linked_mdelem_->md));+      }++     private:+      grpc_linked_mdelem* linked_mdelem_;+    };++    Metadata(CallData* calld, grpc_metadata_batch* batch)+        : calld_(calld), batch_(batch) {}++    void Add(const StringView& key, const StringView& value) override {+      grpc_linked_mdelem* linked_mdelem = static_cast<grpc_linked_mdelem*>(+          calld_->arena_->Alloc(sizeof(grpc_linked_mdelem)));+      bool returned_slice_is_different;+      linked_mdelem->md = grpc_mdelem_from_slices(+          grpc_slice_maybe_static_intern(+              grpc_slice_from_static_buffer_internal(key.data(), key.size()),+              &returned_slice_is_different),+          grpc_slice_from_static_buffer_internal(value.data(), value.size()));+      GPR_ASSERT(grpc_metadata_batch_link_tail(batch_, linked_mdelem) ==+                 GRPC_ERROR_NONE);+    }++    IteratorInterface Begin() override { return Iterator(batch_->list.head); }","Another random idea to be able to support different containers:Most iterators can fit in a pointer, so if we add a `void*` scratch space to the `Iterator` final class, the implementations of `MetadataInterface` should be able to handle the details on their own.  If some implementation needs more space, they would have to allocate their internal iterator data on the heap, but for `Metadata` there would be no allocation. ```class MDInterface { public:  class Iterator {    public:      StringView key() const { return md_->GetKey(scratch_); }      StringView val() const { return md_->GetValue(scratch_); }     ... operator++() {       scratch_ = md_->Next(scratch_);    }    private:      MetadataInterface* md_;      void* scratch_;      friend class MDInterface;  } protected:   Iterator CreateIter(void* scratch) {        return {this, scratch};   }};```Next(const Iterator& iter) ",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/19662,304543976,2019-07-17T17:04:39Z,src/core/lib/transport/static_metadata.h,"@@ -521,11 +524,16 @@ typedef union {   } named; } grpc_metadata_batch_callouts; -#define GRPC_BATCH_INDEX_OF(slice)                                        \-  (GRPC_IS_STATIC_METADATA_STRING((slice))                                \-       ? static_cast<grpc_metadata_batch_callouts_index>(                 \-             GPR_CLAMP(GRPC_STATIC_METADATA_INDEX((slice)), 0,            \-                       static_cast<intptr_t>(GRPC_BATCH_CALLOUTS_COUNT))) \+#define GRPC_BATCH_INDEX_OF(slice)                                            \+  (GRPC_IS_STATIC_METADATA_STRING((slice))                                    \","Can we rewrite this so it's more readable? E.g.,:GRPC_IS_STATIC_METADATA_STRING(slice) && reinterpret_cast<grpc_core::StaticSliceRefcount*>((slice).refcount)->index <= static_cast<uint32_t>(GRPC_BATCH_CALLOUTS_COUNT) ? static_cast<grpc_metadata_batch_callouts_index>(reinterpret_cast<grpc_core::StaticSliceRefcount*>(     (slice).refcount)->index)) : GRPC_BATCH_CALLOUTS_COUNT",
24697473,Tony1023,https://api.github.com/repos/grpc/grpc/pulls/19621,304548873,2019-07-17T17:16:53Z,bazel/grpc_build_system.bzl,"@@ -248,3 +276,42 @@ def grpc_package(name, visibility = ""private"", features = []):             default_visibility = visibility,             features = features,         )++def grpc_objc_library(name, hdrs, srcs, includes = [], deps = []):+    textual_hdrs = []+    sdk_frameworks = []+    defines = []+    if len(includes) == 0:+        includes = []+    if len(deps) == 0:+        deps = [] # unfreezes object+    +    if name == ""grpc_objc_client"":","@muxi I was trying to only expose the public headers like the old `grpc_objc_client` in Google3. Do you think it's better to have those `textual_hdrs`, `defines`, etc. in BUILD and then ignore them in Google3's `grpc_objc_library` ?",
24697473,Tony1023,https://api.github.com/repos/grpc/grpc/pulls/19621,304550224,2019-07-17T17:20:24Z,bazel/grpc_build_system.bzl,"@@ -248,3 +276,42 @@ def grpc_package(name, visibility = ""private"", features = []):             default_visibility = visibility,             features = features,         )++def grpc_objc_library(name, hdrs, srcs, includes = [], deps = []):+    textual_hdrs = []+    sdk_frameworks = []+    defines = []+    if len(includes) == 0:+        includes = []+    if len(deps) == 0:+        deps = [] # unfreezes object","So given `def grpc_objc_library(... deps = []):` it seems that `deps += [""whatever""]` will fail due to ""frozen object""",
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19663,304576319,2019-07-17T18:20:17Z,src/objective-c/GRPCClient/GRPCCall.m,"@@ -794,12 +790,6 @@ - (void)startCallWithWriteable:(id<GRXWriteable>)writeable {      [self sendHeaders];     [self invokeCall];--    // Connectivity monitor is not required for CFStream-    char *enableCFStream = getenv(kCFStreamVarName);-    if (enableCFStream != nil && enableCFStream[0] != '1') {-      [GRPCConnectivityMonitor registerObserver:self selector:@selector(connectivityChanged:)];",`connectivityChanged` seems to be unused now. Can it be removed? Same comemnt for `connectivityChange` in GRPCChannelPool.m.,
10135909,dklempner,https://api.github.com/repos/grpc/grpc/pulls/19544,304632513,2019-07-17T20:43:26Z,src/core/lib/iomgr/executor/threadpool.cc,"@@ -0,0 +1,138 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpc/support/port_platform.h>++#include ""src/core/lib/iomgr/executor/threadpool.h""++namespace grpc_core {++void ThreadPoolWorker::Run() {+  while (true) {+    void* elem;++    if (GRPC_TRACE_FLAG_ENABLED(grpc_thread_pool_trace)) {+      // Updates stats and print+      gpr_timespec wait_time = gpr_time_0(GPR_TIMESPAN);+      elem = queue_->Get(&wait_time);+      stats_.sleep_time = gpr_time_add(stats_.sleep_time, wait_time);+      gpr_log(GPR_INFO,+              ""ThreadPool Worker [%s %d] Stats:  sleep_time          %f"",+              thd_name_, index_, gpr_timespec_to_micros(stats_.sleep_time));+    } else {+      elem = queue_->Get(nullptr);+    }+    if (elem == nullptr) {+      break;+    }+    // Runs closure+    auto* closure =+        static_cast<grpc_experimental_completion_queue_functor*>(elem);+    closure->functor_run(closure, closure->internal_success);+  }+}++void ThreadPool::SharedThreadPoolConstructor() {+  // All worker threads in thread pool must be joinable.+  thread_options_.set_joinable(true);++  // Create at least 1 worker thread.+  if (num_threads_ <= 0) num_threads_ = 1;++  queue_ = New<InfLenFIFOQueue>();+  threads_ = static_cast<ThreadPoolWorker**>(+      gpr_zalloc(num_threads_ * sizeof(ThreadPoolWorker*)));+  for (int i = 0; i < num_threads_; ++i) {+    threads_[i] =+        New<ThreadPoolWorker>(thd_name_, this, queue_, thread_options_, i);+    threads_[i]->Start();+  }+}++size_t ThreadPool::DefaultStackSize() {+#if defined(__ANDROID__) || defined(__APPLE__)+  return 1952 * 1024;+#else+  return 64 * 1024;+#endif+}++bool ThreadPool::HasBeenShutDown() {","Since the only usage of this method is an assert, and it is not correct to use Relaxed for general usage, how about an AssertHasBeenShutDown()? This way we won't accidentally use this method incorrectly later.(Note that it is mildly important that the implementation be visible from the caller so the function call can get optimized out)",OK
10135909,dklempner,https://api.github.com/repos/grpc/grpc/pulls/19634,304639205,2019-07-17T21:00:39Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -1502,19 +1515,28 @@ void ChannelData::StartTransportOpLocked(void* arg, grpc_error* ignored) {       chand->resolving_lb_policy_->ResetBackoffLocked();     }   }-  // Disconnect.+  // Disconnect or enter IDLE.   if (op->disconnect_with_error != GRPC_ERROR_NONE) {-    grpc_error* error = GRPC_ERROR_NONE;-    GPR_ASSERT(chand->disconnect_error_.CompareExchangeStrong(-        &error, op->disconnect_with_error, MemoryOrder::ACQ_REL,-        MemoryOrder::ACQUIRE));     chand->DestroyResolvingLoadBalancingPolicyLocked();-    // Will delete itself.-    New<ConnectivityStateAndPickerSetter>(-        chand, GRPC_CHANNEL_SHUTDOWN, ""shutdown from API"",-        UniquePtr<LoadBalancingPolicy::SubchannelPicker>(-            New<LoadBalancingPolicy::TransientFailurePicker>(-                GRPC_ERROR_REF(op->disconnect_with_error))));+    intptr_t value;+    if (grpc_error_get_int(op->disconnect_with_error,+                           GRPC_ERROR_INT_CHANNEL_CONNECTIVITY_STATE, &value) &&+        static_cast<grpc_connectivity_state>(value) == GRPC_CHANNEL_IDLE) {+      // Enter IDLE state.+      New<ConnectivityStateAndPickerSetter>(chand, GRPC_CHANNEL_IDLE,+                                            ""channel entering IDLE"", nullptr);+    } else {+      // Disconnect.+      grpc_error* error = GRPC_ERROR_NONE;+      GPR_ASSERT(chand->disconnect_error_.CompareExchangeStrong(+          &error, op->disconnect_with_error, MemoryOrder::ACQ_REL,+          MemoryOrder::ACQUIRE));","Assuming the assert is correct, these do not require acquire semantics at all. if our reaction to seeing the wrong value is just to immediately crash the process and not otherwise touch anything we don't need acquire. Meanwhile we already knew the old value was NONE and couldn't race (or else the assert would be invalid) so we don't need acquire in the success case either.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19405,304659554,2019-07-17T21:57:50Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -310,6 +310,75 @@ class CallData {  private:   class QueuedPickCanceller; +  class Metadata : public LoadBalancingPolicy::MetadataInterface {+   public:+    class Iterator : public MetadataInterface::IteratorInterface {+     public:+      explicit Iterator(grpc_linked_mdelem* linked_mdelem)+          : linked_mdelem_(linked_mdelem) {}++      grpc_linked_mdelem* linked_mdelem() const { return linked_mdelem_; }++      virtual IteratorInterface& operator=(+          const IteratorInterface& other) override {+        const Iterator* it = static_cast<const Iterator*>(&other);+        linked_mdelem_ = it->linked_mdelem_;+        return *this;+      }++      virtual IteratorInterface& operator++() override {+        linked_mdelem_ = linked_mdelem_->next;+        return *this;+      }++      bool operator==(const IteratorInterface& other) const override {+        const Iterator* it = static_cast<const Iterator*>(&other);+        return linked_mdelem_ == it->linked_mdelem_;+      }++      virtual StringView Key() const override {+        return StringView(GRPC_MDKEY(linked_mdelem_->md));+      }++      virtual StringView Value() const override {+        return StringView(GRPC_MDVALUE(linked_mdelem_->md));+      }++     private:+      grpc_linked_mdelem* linked_mdelem_;+    };++    Metadata(CallData* calld, grpc_metadata_batch* batch)+        : calld_(calld), batch_(batch) {}++    void Add(const StringView& key, const StringView& value) override {+      grpc_linked_mdelem* linked_mdelem = static_cast<grpc_linked_mdelem*>(+          calld_->arena_->Alloc(sizeof(grpc_linked_mdelem)));+      bool returned_slice_is_different;+      linked_mdelem->md = grpc_mdelem_from_slices(+          grpc_slice_maybe_static_intern(+              grpc_slice_from_static_buffer_internal(key.data(), key.size()),+              &returned_slice_is_different),+          grpc_slice_from_static_buffer_internal(value.data(), value.size()));+      GPR_ASSERT(grpc_metadata_batch_link_tail(batch_, linked_mdelem) ==+                 GRPC_ERROR_NONE);+    }++    IteratorInterface Begin() override { return Iterator(batch_->list.head); }","I've come up with a new API that eliminates the iterator class and instead has callers use methods on the `MetadataInterface` class for iteration.  I'm not super happy with requiring implementations to cast their iterator type, but I couldn't see another way to do it.",
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19595,304671001,2019-07-17T22:38:36Z,src/objective-c/examples/SampleCpp/SampleCpp/ViewController.m,"@@ -0,0 +1,54 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#import ""ViewController.h""++#import <Cronet/Cronet.h>+#import <RemoteTestCpp/messages.grpc.pb.h>+#import <RemoteTestCpp/test.grpc.pb.h>+#import <grpc/grpc_cronet.h>+#import <grpcpp/create_channel.h>+#import <grpcpp/impl/codegen/client_context.h>+#import <grpcpp/security/credentials.h>++@implementation ViewController++- (void)viewDidLoad {+  [super viewDidLoad];++  [Cronet setHttp2Enabled:YES];",Couple things need to be done if we choose to migrate to Cronet C API:1. Need to update Cronet.Framework to a newer version that supports the C API2. Cronet needs to provide a C API to mock the certificate verifier similar to Objective-C API `enableTestCertVerifierForTesting`,OK
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19685,305100058,2019-07-18T20:25:36Z,src/core/lib/gprpp/fork.cc,"@@ -212,38 +213,38 @@ Fork::child_postfork_func Fork::GetResetChildPollingEngineFunc() { }  bool Fork::BlockExecCtx() {-  if (support_enabled_) {+  if (support_enabled_.Load(MemoryOrder::RELAXED)) {     return exec_ctx_state_->BlockExecCtx();   }   return false; }  void Fork::AllowExecCtx() {-  if (support_enabled_) {+  if (support_enabled_.Load(MemoryOrder::RELAXED)) {     exec_ctx_state_->AllowExecCtx();   } }  void Fork::IncThreadCount() {-  if (support_enabled_) {+  if (support_enabled_.Load(MemoryOrder::RELAXED)) {     thread_state_->IncThreadCount();   } }  void Fork::DecThreadCount() {-  if (support_enabled_) {+  if (support_enabled_.Load(MemoryOrder::RELAXED)) {     thread_state_->DecThreadCount();   } } void Fork::AwaitThreads() {-  if (support_enabled_) {+  if (support_enabled_.Load(MemoryOrder::RELAXED)) {     thread_state_->AwaitThreads();   } }  internal::ExecCtxState* Fork::exec_ctx_state_ = nullptr; internal::ThreadState* Fork::thread_state_ = nullptr;-std::atomic<bool> Fork::support_enabled_;+Atomic<bool> Fork::support_enabled_;","Done, initializing to false to maintain same semantics as std::atomic<bool> default initialization.",
11674202,stanley-cheung,https://api.github.com/repos/grpc/grpc/pulls/19691,305188494,2019-07-19T03:18:04Z,src/core/lib/gpr/env_linux.cc,"@@ -38,40 +38,29 @@ #include ""src/core/lib/gpr/string.h"" #include ""src/core/lib/gpr/useful.h"" -static const char* gpr_getenv_silent(const char* name, char** dst) {","Sorry I don't fully know the history - but why to remove `gpr_getenv_silent` here? If I read this correctly, `gpr_getenv_silent` was a previous attempt to refactor some code that is no longer needed and is never called outside?",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19621,305191906,2019-07-19T03:40:57Z,BUILD,"@@ -2469,3 +2470,72 @@ filegroup(     ],     visibility = [""//visibility:public""], )++objc_library(",Use `grpc_objc_library`,
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19621,305194784,2019-07-19T04:00:43Z,BUILD,"@@ -2469,3 +2470,72 @@ filegroup(     ],     visibility = [""//visibility:public""], )++objc_library(+    name = ""rx_library"",+    srcs = glob([+        ""src/objective-c/RxLibrary/*.m"",+        ""src/objective-c/RxLibrary/transformations/*.m"",+    ]),+    hdrs = glob([+        ""src/objective-c/RxLibrary/*.h"",+        ""src/objective-c/RxLibrary/transformations/*.h"",+    ]),+    includes = [""src/objective-c""],+    deps = [+        "":rx_library_private"",+    ],+)++objc_library(+    name = ""rx_library_private"",+    srcs = glob([+        ""src/objective-c/RxLibrary/private/*.m"",+    ]),+    textual_hdrs = glob([+        ""src/objective-c/RxLibrary/private/*.h"",+    ]),+    visibility = [""//visibility:private""],+)++grpc_objc_library(+    name = ""grpc_objc_client"",+    srcs = glob(+        [+            ""src/objective-c/GRPCClient/*.m"",+            ""src/objective-c/GRPCClient/private/*.m"",+        ],+        exclude = [""src/objective-c/GRPCClient/GRPCCall+GID.m""],+    ),+    hdrs = glob(+        [""src/objective-c/GRPCClient/*.h""],+        exclude = [""src/objective-c/GRPCClient/GRPCCall+GID.h""],+    ),+    includes = [""src/objective-c""],+    textual_hdrs = glob([+        ""src/objective-c/GRPCClient/private/*.h"",+        ""src/objective-c/GRPCClient/internal/*.h"",","Sorry but I think this should be in `hdrs` not `textual_hdrs`, after I think about it twice. My bad 😨. The reason is that this header is used by other targets internally",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19621,305197450,2019-07-19T04:22:25Z,bazel/grpc_build_system.bzl,"@@ -248,3 +253,34 @@ def grpc_package(name, visibility = ""private"", features = []):             default_visibility = visibility,             features = features,         )++def grpc_objc_library(+        name,+        hdrs,+        srcs,+        deps,+        textual_hdrs = [],+        defines = [],+        includes = [],+        ):+    """"""The grpc version of objc_library, only used for the Objective-C library compilation++    Args:+        name: name of target, either grpc_objc_client or proto_objc_rpc","Unless there's any special instruction that any future user of this rule (which likely would be a team member) should know of about these parameters when using this rule, I think we probably don't need to comment them since they are quite common and their definitions are well known.",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19621,305197515,2019-07-19T04:23:01Z,bazel/grpc_build_system.bzl,"@@ -248,3 +253,34 @@ def grpc_package(name, visibility = ""private"", features = []):             default_visibility = visibility,             features = features,         )++def grpc_objc_library(+        name,+        hdrs,+        srcs,+        deps,+        textual_hdrs = [],+        defines = [],+        includes = [],+        ):+    """"""The grpc version of objc_library, only used for the Objective-C library compilation++    Args:+        name: name of target, either grpc_objc_client or proto_objc_rpc","for the `name` parameter, don't limit it to `grpc_objc_client` or `proto_objc_rpc`. We will need to put `rx_library` in and maybe some more in the future",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19621,305198037,2019-07-19T04:27:55Z,bazel/grpc_objc_library.bzl,"@@ -0,0 +1,93 @@+load(",ok. but name it `objc_grpc_library.bzl` instead,OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19621,305423835,2019-07-19T16:04:06Z,bazel/generate_objc.bzl,"@@ -0,0 +1,243 @@+load(+    ""//bazel:protobuf.bzl"",+    ""get_include_protoc_args"",+    ""get_plugin_args"",+    ""get_proto_root"",+    ""proto_path_to_generated_filename"",+)+load(+    "":grpc_util.bzl"", +    ""to_upper_camel_with_extension"",+    ""label_to_file"",+)++_GRPC_PROTO_HEADER_FMT = ""{}.pbrpc.h""+_GRPC_PROTO_SRC_FMT = ""{}.pbrpc.m""+_PROTO_HEADER_FMT = ""{}.pbobjc.h""+_PROTO_SRC_FMT = ""{}.pbobjc.m""+_GENERATED_PROTOS_DIR = ""_generated_protos""++def _generate_objc_impl(ctx):++    """"""Implementation of the generate_cc rule.""""""+    protos = [+        f+        for src in ctx.attr.srcs+        for f in src[ProtoInfo].transitive_imports.to_list()+    ]+    outs = []+    proto_root = get_proto_root(+        ctx.label.workspace_root,+    )++    label_package = _join_directories([ctx.label.workspace_root, ctx.label.package])++    files_with_rpc = [label_to_file(f) for f in ctx.attr.files_with_service]+    for proto in protos:+        outs += [+            proto_path_to_generated_filename(+                _GENERATED_PROTOS_DIR + ""/"" ++                _get_directory_from_proto(proto) + _get_slash_from_proto(proto) ++                to_upper_camel_with_extension(_get_file_name_from_proto(proto), ""proto""),+                _PROTO_HEADER_FMT,+            )+        ]+        outs += [+            proto_path_to_generated_filename(+                _GENERATED_PROTOS_DIR + ""/"" ++                _get_directory_from_proto(proto) + _get_slash_from_proto(proto) ++                to_upper_camel_with_extension(_get_file_name_from_proto(proto), ""proto""),+                _PROTO_SRC_FMT,+            )+        ]++        file_path = _strip_package_from_path(label_package, proto)+        if not file_path.startswith(""//""):+            pass # TODO: check package boundary+        if file_path in files_with_rpc or proto.path in files_with_rpc:+            outs += [+                proto_path_to_generated_filename(+                    _GENERATED_PROTOS_DIR + ""/"" ++                    _get_directory_from_proto(proto) + _get_slash_from_proto(proto) ++                    to_upper_camel_with_extension(_get_file_name_from_proto(proto), ""proto""),+                    _GRPC_PROTO_HEADER_FMT,+                )+            ]+            outs += [+                proto_path_to_generated_filename(+                    _GENERATED_PROTOS_DIR + ""/"" ++                    _get_directory_from_proto(proto) + _get_slash_from_proto(proto) ++                    to_upper_camel_with_extension(_get_file_name_from_proto(proto), ""proto""),+                    _GRPC_PROTO_SRC_FMT,+                )+            ]+    +    out_files = [ctx.actions.declare_file(out) for out in outs]+    dir_out = _join_directories([+        str(ctx.genfiles_dir.path + proto_root), label_package, _GENERATED_PROTOS_DIR+    ])++    arguments = []+    if ctx.executable.plugin:+        arguments += get_plugin_args(+            ctx.executable.plugin,+            [],+            dir_out,+            False,+        )+        tools = [ctx.executable.plugin]+    arguments += [""--objc_out="" + dir_out]+    arguments += get_include_protoc_args(protos)++    # Include the output directory so that protoc puts the generated code in the+    # right directory.+    arguments += [""--proto_path={0}{1}"".format(dir_out, proto_root)]+    arguments += [""--proto_path={}"".format(_get_directory_from_proto(proto)) for proto in protos]+    arguments += [_get_srcs_file_path(proto) for proto in protos]++    # create a list of well known proto files if the argument is non-None+    well_known_proto_files = []+    if ctx.attr.use_well_known_protos:+        f = ctx.attr.well_known_protos.files.to_list()[0].dirname+        arguments += [""-I{0}"".format(f + ""/../.."")]+        well_known_proto_files = [+            f+            for f in ctx.attr.well_known_protos.files.to_list()",`to_list()` is already a list :),
24697473,Tony1023,https://api.github.com/repos/grpc/grpc/pulls/19621,305467945,2019-07-19T18:07:39Z,bazel/grpc_objc_library.bzl,"@@ -0,0 +1,114 @@+load(+    ""//bazel:generate_objc.bzl"",+    ""generate_objc"",+    ""generate_objc_hdrs"",+    ""generate_objc_srcs"",+    ""generate_objc_non_arc_srcs""+)+load(""//bazel:protobuf.bzl"", ""well_known_proto_libs"")++def objc_proto_grpc_library(name, deps, use_well_known_protos = False, **kwargs):","@muxi Yeah, since there is a not-working `objc_proto_library`",
42048362,mhaidrygoog,https://api.github.com/repos/grpc/grpc/pulls/19682,305528378,2019-07-19T21:20:58Z,test/cpp/end2end/generic_end2end_test.cc,"@@ -330,6 +381,29 @@ TEST_F(GenericEnd2endTest, Deadline) {                        gpr_time_from_seconds(10, GPR_TIMESPAN))); } +TEST_F(GenericEnd2endTest, ShortDeadline) {+  ResetStub();++  ClientContext cli_ctx;+  EchoRequest request;+  EchoResponse response;++  shutting_down_ = false;+  std::thread driver([this] { DriveCompletionQueue(); });++  request.set_message("""");+  cli_ctx.set_deadline(gpr_time_add(gpr_now(GPR_CLOCK_MONOTONIC),+                                    gpr_time_from_micros(500, GPR_TIMESPAN)));+  Status s = stub_->Echo(&cli_ctx, request, &response);+  EXPECT_FALSE(s.ok());+  {+    std::lock_guard<std::mutex> lock(shutting_down_mu_);+    shutting_down_ = true;+  }+  TearDown();",Added a shut_down_ member and using that as a condition in ShutDownServerAndCQs(). This method is called from both TearDown and the ShortDeadlineTest.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19698,305875005,2019-07-22T14:28:22Z,src/core/lib/channel/channelz.h,"@@ -58,12 +58,8 @@ namespace channelz { grpc_arg MakeParentUuidArg(intptr_t parent_uuid); intptr_t GetParentUuidFromArgs(const grpc_channel_args& args); -// TODO(ncteisen), this only contains the uuids of the children for now,","We should probably retain this TODO somewhere.  API-wise, we'll probably want to do this by adding a string parameter to all of the `AddChild*()` methods in both `ChannelNode` and `ServerNode`.",
28123841,guantaol,https://api.github.com/repos/grpc/grpc/pulls/19695,306049808,2019-07-22T21:53:47Z,test/cpp/microbenchmarks/bm_threadpool.cc,"@@ -0,0 +1,342 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <benchmark/benchmark.h>+#include <grpc/grpc.h>++#include <condition_variable>+#include <mutex>++#include ""src/core/lib/iomgr/executor/threadpool.h""+#include ""test/cpp/microbenchmarks/helpers.h""+#include ""test/cpp/util/test_config.h""++namespace grpc {+namespace testing {++// This helper class allows a thread to block for a pre-specified number of+// actions. BlockingCounter has an initial non-negative count on initialization+// Each call to DecrementCount will decrease the count by 1. When making a call+// to Wait, if the count is greater than 0, the thread will be block, until+// the count reaches 0.+class BlockingCounter {+ public:+  BlockingCounter(int count) : count_(count) {}+  void DecrementCount() {+    std::lock_guard<std::mutex> l(mu_);+    count_--;+    if (count_ == 0) cv_.notify_one();+  }++  void Wait() {+    std::unique_lock<std::mutex> l(mu_);+    while (count_ > 0) {+      cv_.wait(l);+    }+  }++ private:+  int count_;+  std::mutex mu_;+  std::condition_variable cv_;+};++// This is a functor/closure class for threadpool microbenchmark.+// This functor (closure) class will add another functor into pool if the+// number passed in (num_add) is greater than 0. Otherwise, it will decrement+// the counter to indicate that task is finished. This functor will suicide at+// the end, therefore, no need for caller to do clean-ups.+class AddAnotherFunctor : public grpc_experimental_completion_queue_functor {+ public:+  AddAnotherFunctor(grpc_core::ThreadPool* pool, BlockingCounter* counter,+                    int num_add)+      : pool_(pool), counter_(counter), num_add_(num_add) {+    functor_run = &AddAnotherFunctor::Run;+    internal_next = this;+    internal_success = 0;+  }+  ~AddAnotherFunctor() {}+  // When the functor gets to run in thread pool, it will take itself as first+  // argument and internal_success as second one.+  static void Run(grpc_experimental_completion_queue_functor* cb, int ok) {+    auto* callback = static_cast<AddAnotherFunctor*>(cb);+    if (--callback->num_add_ > 0) {+      callback->pool_->Add(new AddAnotherFunctor(+          callback->pool_, callback->counter_, callback->num_add_));+    } else {+      callback->counter_->DecrementCount();+    }+    // Suicide+    delete callback;+  }++ private:+  grpc_core::ThreadPool* pool_;+  BlockingCounter* counter_;+  int num_add_;+};++void ThreadPoolAddAnotherHelper(benchmark::State& state,+                                int concurrent_functor) {+  const int num_threads = state.range(1);+  const int num_iterations = state.range(0);+  // number of adds done by each closure+  const int num_add = num_iterations / concurrent_functor;+  grpc_core::ThreadPool pool(num_threads);+  while (state.KeepRunningBatch(num_iterations)) {+    BlockingCounter counter(concurrent_functor);+    for (int i = 0; i < concurrent_functor; ++i) {+      pool.Add(new AddAnotherFunctor(&pool, &counter, num_add));+    }+    counter.Wait();+  }+  state.SetItemsProcessed(state.iterations());+}++static void BM_ThreadPool1AddAnother(benchmark::State& state) {+  ThreadPoolAddAnotherHelper(state, 1);+}+// first pair is range for batch_size, second pair is range for thread pool size+BENCHMARK(BM_ThreadPool1AddAnother)->RangePair(524288, 524288, 1, 1024);++static void BM_ThreadPool4AddAnother(benchmark::State& state) {+  ThreadPoolAddAnotherHelper(state, 4);+}+BENCHMARK(BM_ThreadPool4AddAnother)->RangePair(524288, 524288, 1, 1024);++static void BM_ThreadPool8AddAnother(benchmark::State& state) {+  ThreadPoolAddAnotherHelper(state, 8);+}+BENCHMARK(BM_ThreadPool8AddAnother)->RangePair(524288, 524288, 1, 1024);++static void BM_ThreadPool16AddAnother(benchmark::State& state) {+  ThreadPoolAddAnotherHelper(state, 16);+}+BENCHMARK(BM_ThreadPool16AddAnother)->RangePair(524288, 524288, 1, 1024);++static void BM_ThreadPool32AddAnother(benchmark::State& state) {+  ThreadPoolAddAnotherHelper(state, 32);+}+BENCHMARK(BM_ThreadPool32AddAnother)->RangePair(524288, 524288, 1, 1024);++static void BM_ThreadPool64AddAnother(benchmark::State& state) {+  ThreadPoolAddAnotherHelper(state, 64);+}+BENCHMARK(BM_ThreadPool64AddAnother)->RangePair(524288, 524288, 1, 1024);++static void BM_ThreadPool128AddAnother(benchmark::State& state) {+  ThreadPoolAddAnotherHelper(state, 128);+}+BENCHMARK(BM_ThreadPool128AddAnother)->RangePair(524288, 524288, 1, 1024);++static void BM_ThreadPool512AddAnother(benchmark::State& state) {+  ThreadPoolAddAnotherHelper(state, 512);+}+BENCHMARK(BM_ThreadPool512AddAnother)->RangePair(524288, 524288, 1, 1024);++static void BM_ThreadPool2048AddAnother(benchmark::State& state) {+  ThreadPoolAddAnotherHelper(state, 2048);+}+BENCHMARK(BM_ThreadPool2048AddAnother)->RangePair(524288, 524288, 1, 1024);++// A functor class that will delete self on end of running.+class SuicideFunctorForAdd : public grpc_experimental_completion_queue_functor {+ public:+  SuicideFunctorForAdd(BlockingCounter* counter) : counter_(counter) {+    functor_run = &SuicideFunctorForAdd::Run;+    internal_next = this;+    internal_success = 0;+  }+  ~SuicideFunctorForAdd() {}+  static void Run(grpc_experimental_completion_queue_functor* cb, int ok) {+    // On running, the first argument would be itself.+    auto* callback = static_cast<SuicideFunctorForAdd*>(cb);+    callback->counter_->DecrementCount();+    delete callback;+  }++ private:+  BlockingCounter* counter_;+};++// Performs the scenario of external thread(s) adding closures into pool.+static void BM_ThreadPoolExternalAdd(benchmark::State& state) {+  static grpc_core::ThreadPool* external_add_pool = nullptr;+  // Setup for each run of test+  if (state.thread_index == 0) {+    const int num_threads = state.range(1);+    external_add_pool = new grpc_core::ThreadPool(num_threads);+  }+  const int num_iterations = state.range(0);+  while (state.KeepRunningBatch(num_iterations)) {+    BlockingCounter counter(num_iterations);+    for (int i = 0; i < num_iterations; ++i) {+      external_add_pool->Add(new SuicideFunctorForAdd(&counter));+    }+    counter.Wait();+  }+  state.SetItemsProcessed(num_iterations);","Should this be ""state.SetItemsProcessed(num_iterations * threads)""?Also, isn't it a data race to SetItemsProcessed in concurrent threads?",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19712,306161343,2019-07-23T07:17:39Z,src/csharp/Grpc.Core.Api/ChannelCredentialsConfiguratorBase.cs,"@@ -0,0 +1,44 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System.Collections.Generic;++namespace Grpc.Core+{+    /// <summary>+    /// Base class for objects that can consume configuration from <c>CallCredentials</c> objects.+    /// Note: experimental API that can change or be removed without any prior notice.+    /// </summary>+    public abstract class ChannelCredentialsConfiguratorBase","Yes. grpc-dotnet would implement these: - the ""default"" SslCredentials() would be interpreted as standard https- ChannelCredentials.Insecure would be interpreted as http- composite channel credentials would be decomposed and checked that it's using the default SslCredentials and the call credentials will be used for all calls on a given channel.All other configurations could just throw as ""unsupported"" (it needs to actually fail, not just log an error, otherwise this would be a security problem). In the future, we could also implement functionality that converts the SslCredentials arguments into X509 certificate objects and passes them to the HTTPClient.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19712,306162921,2019-07-23T07:22:24Z,src/csharp/Grpc.Core.Api/ChannelCredentials.cs,"@@ -0,0 +1,113 @@+#region Copyright notice and license++// Copyright 2015 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Generic;+using System.Threading.Tasks;++using Grpc.Core.Internal;+using Grpc.Core.Utils;++namespace Grpc.Core+{+    /// <summary>+    /// Client-side channel credentials. Used for creation of a secure channel.+    /// </summary>+    public abstract class ChannelCredentials","I verified that Grpc.Auth can be made to depend on Grpc.Core.Api only, but removing the Grpc.Core dependency can break users, so this change should only be done as a followup once other breaking changes are in.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19690,306179944,2019-07-23T08:04:48Z,tools/internal_ci/linux/grpc_bazel_build_in_docker.sh,"@@ -24,4 +24,6 @@ git clone /var/local/jenkins/grpc /var/local/git/grpc && git submodule update --init --reference /var/local/jenkins/grpc/${name} \ ${name}') cd /var/local/git/grpc-bazel build --spawn_strategy=standalone --genrule_strategy=standalone :all test/... examples/...+# grep lines not starting with INFO to avoid messages when using Bazel wrapper+bazel build --spawn_strategy=standalone --genrule_strategy=standalone \+$(bazel query 'kind(cc_.*, :all)' | grep -v ""^INFO\: "") test/... examples/...","looking at this command,how come the https://github.com/grpc/grpc/blob/809e7c951358a80182d7126b255c3a40881fb3fa/tools/internal_ci/linux/grpc_bazel_on_foundry_base.sh#L39 is not broken by https://github.com/grpc/grpc/pull/19621?",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19621,306617795,2019-07-24T03:50:30Z,bazel/grpc_objc_library.bzl,"@@ -0,0 +1,114 @@+load(+    ""//bazel:generate_objc.bzl"",+    ""generate_objc"",+    ""generate_objc_hdrs"",+    ""generate_objc_srcs"",+    ""generate_objc_non_arc_srcs""+)+load(""//bazel:protobuf.bzl"", ""well_known_proto_libs"")++def objc_proto_grpc_library(name, deps, use_well_known_protos = False, **kwargs):","Err... I actually mean, I don't see any reference to it in the changes. Do we expect some user to use it? (I don't quite see much reason for that since if they use it with gRPC, `objc_grpc_library` generates all the proto files for them already)",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/19712,306682321,2019-07-24T08:16:26Z,src/csharp/Grpc.Core/Internal/DefaultChannelCredentialsConfigurator.cs,"@@ -0,0 +1,173 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Generic;+using System.Runtime.InteropServices;+using System.Runtime.CompilerServices;+using Grpc.Core.Utils;+using Grpc.Core.Logging;++namespace Grpc.Core.Internal+{+    /// <summary>+    /// Creates native call credential objects from instances of <c>ChannelCredentials</c>.+    /// </summary>+    internal class DefaultChannelCredentialsConfigurator : ChannelCredentialsConfiguratorBase+    {+        static readonly ILogger Logger = GrpcEnvironment.Logger.ForType<DefaultCallCredentialsConfigurator>();++        // Native credentials object need to be kept alive once initialized for subchannel sharing to work correctly+        // with secure connections. See https://github.com/grpc/grpc/issues/15207.+        // We rely on finalizer to clean up the native portion of ChannelCredentialsSafeHandle after the ChannelCredentials+        // instance becomes unused.+        static readonly ConditionalWeakTable<ChannelCredentials, Lazy<ChannelCredentialsSafeHandle>> CachedNativeCredentials = new ConditionalWeakTable<ChannelCredentials, Lazy<ChannelCredentialsSafeHandle>>();++        bool configured;+        ChannelCredentialsSafeHandle nativeCredentials;++        public ChannelCredentialsSafeHandle NativeCredentials => nativeCredentials;+        +        public override void SetInsecureCredentials(object state)+        {+            GrpcPreconditions.CheckState(!configured);+            // null corresponds to insecure credentials.+            configured = true;+            nativeCredentials = null;+        }++        public override void SetSslCredentials(object state, string rootCertificates, KeyCertificatePair keyCertificatePair, VerifyPeerCallback verifyPeerCallback)+        {+            GrpcPreconditions.CheckState(!configured);+            configured = true;+            nativeCredentials = GetOrCreateNativeCredentials((ChannelCredentials) state,+                () => CreateNativeSslCredentials(rootCertificates, keyCertificatePair, verifyPeerCallback));+        }++        public override void SetCompositeCredentials(object state, ChannelCredentials channelCredentials, CallCredentials callCredentials)+        {+            GrpcPreconditions.CheckState(!configured);+            configured = true;+            nativeCredentials = GetOrCreateNativeCredentials((ChannelCredentials) state,+                () => CreateNativeCompositeCredentials(channelCredentials, callCredentials));+        }++        private ChannelCredentialsSafeHandle CreateNativeSslCredentials(string rootCertificates, KeyCertificatePair keyCertificatePair, VerifyPeerCallback verifyPeerCallback)+        {+            IntPtr verifyPeerCallbackTag = IntPtr.Zero;+            if (verifyPeerCallback != null)+            {+                verifyPeerCallbackTag = new VerifyPeerCallbackRegistration(verifyPeerCallback).CallbackRegistration.Tag;+            }+            return ChannelCredentialsSafeHandle.CreateSslCredentials(rootCertificates, keyCertificatePair, verifyPeerCallbackTag);+        }++        private ChannelCredentialsSafeHandle CreateNativeCompositeCredentials(ChannelCredentials channelCredentials, CallCredentials callCredentials)+        {+            using (var callCreds = callCredentials.ToNativeCredentials())+            {+                var nativeComposite = ChannelCredentialsSafeHandle.CreateComposite(channelCredentials.ToNativeCredentials(), callCreds);+                if (nativeComposite.IsInvalid)+                {+                    throw new ArgumentException(""Error creating native composite credentials. Likely, this is because you are trying to compose incompatible credentials."");+                }+                return nativeComposite;+            }+        }++        private ChannelCredentialsSafeHandle GetOrCreateNativeCredentials(ChannelCredentials key, Func<ChannelCredentialsSafeHandle> nativeCredentialsFactory)+        {+            Lazy<ChannelCredentialsSafeHandle> lazyValue;","I think this could be simpler if we just used a mutex here and did a simple cache ""lookup or create"".... vould then get rid of the while lookup, `Lazy` type, and exception catching.Personally I wouldn't be concerned about acquiring a global mutex here, since this is only used on the channel construction path (if I'm correct).",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19712,306841915,2019-07-24T14:29:20Z,src/csharp/Grpc.Core/Internal/DefaultChannelCredentialsConfigurator.cs,"@@ -0,0 +1,173 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Generic;+using System.Runtime.InteropServices;+using System.Runtime.CompilerServices;+using Grpc.Core.Utils;+using Grpc.Core.Logging;++namespace Grpc.Core.Internal+{+    /// <summary>+    /// Creates native call credential objects from instances of <c>ChannelCredentials</c>.+    /// </summary>+    internal class DefaultChannelCredentialsConfigurator : ChannelCredentialsConfiguratorBase+    {+        static readonly ILogger Logger = GrpcEnvironment.Logger.ForType<DefaultCallCredentialsConfigurator>();++        // Native credentials object need to be kept alive once initialized for subchannel sharing to work correctly+        // with secure connections. See https://github.com/grpc/grpc/issues/15207.+        // We rely on finalizer to clean up the native portion of ChannelCredentialsSafeHandle after the ChannelCredentials+        // instance becomes unused.+        static readonly ConditionalWeakTable<ChannelCredentials, Lazy<ChannelCredentialsSafeHandle>> CachedNativeCredentials = new ConditionalWeakTable<ChannelCredentials, Lazy<ChannelCredentialsSafeHandle>>();++        bool configured;+        ChannelCredentialsSafeHandle nativeCredentials;++        public ChannelCredentialsSafeHandle NativeCredentials => nativeCredentials;+        +        public override void SetInsecureCredentials(object state)+        {+            GrpcPreconditions.CheckState(!configured);+            // null corresponds to insecure credentials.+            configured = true;+            nativeCredentials = null;+        }++        public override void SetSslCredentials(object state, string rootCertificates, KeyCertificatePair keyCertificatePair, VerifyPeerCallback verifyPeerCallback)+        {+            GrpcPreconditions.CheckState(!configured);+            configured = true;+            nativeCredentials = GetOrCreateNativeCredentials((ChannelCredentials) state,+                () => CreateNativeSslCredentials(rootCertificates, keyCertificatePair, verifyPeerCallback));+        }++        public override void SetCompositeCredentials(object state, ChannelCredentials channelCredentials, CallCredentials callCredentials)+        {+            GrpcPreconditions.CheckState(!configured);+            configured = true;+            nativeCredentials = GetOrCreateNativeCredentials((ChannelCredentials) state,+                () => CreateNativeCompositeCredentials(channelCredentials, callCredentials));+        }++        private ChannelCredentialsSafeHandle CreateNativeSslCredentials(string rootCertificates, KeyCertificatePair keyCertificatePair, VerifyPeerCallback verifyPeerCallback)+        {+            IntPtr verifyPeerCallbackTag = IntPtr.Zero;+            if (verifyPeerCallback != null)+            {+                verifyPeerCallbackTag = new VerifyPeerCallbackRegistration(verifyPeerCallback).CallbackRegistration.Tag;+            }+            return ChannelCredentialsSafeHandle.CreateSslCredentials(rootCertificates, keyCertificatePair, verifyPeerCallbackTag);+        }++        private ChannelCredentialsSafeHandle CreateNativeCompositeCredentials(ChannelCredentials channelCredentials, CallCredentials callCredentials)+        {+            using (var callCreds = callCredentials.ToNativeCredentials())+            {+                var nativeComposite = ChannelCredentialsSafeHandle.CreateComposite(channelCredentials.ToNativeCredentials(), callCreds);+                if (nativeComposite.IsInvalid)+                {+                    throw new ArgumentException(""Error creating native composite credentials. Likely, this is because you are trying to compose incompatible credentials."");+                }+                return nativeComposite;+            }+        }++        private ChannelCredentialsSafeHandle GetOrCreateNativeCredentials(ChannelCredentials key, Func<ChannelCredentialsSafeHandle> nativeCredentialsFactory)+        {+            Lazy<ChannelCredentialsSafeHandle> lazyValue;","I thought of using a global lock here, but it seemed more complex than what I have in this PR. I also don't like the idea of holding a global lock when invoking native functions (creating the credentials) and if I wanted to avoid that, it would add even more complexity. ",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19729,306880017,2019-07-24T15:35:57Z,src/core/ext/filters/client_channel/lb_policy/xds/xds_load_balancer_api.cc,"@@ -43,9 +44,23 @@ constexpr char kEdsTypeUrl[] = constexpr char kEndpointRequired[] = ""endpointRequired"";  using LocalityStats = envoy_api_v2_endpoint_UpstreamLocalityStats;+using DropOverload = envoy_api_v2_ClusterLoadAssignment_Policy_DropOverload;  }  // namespace +bool XdsDropConfig::ShouldDrop(const UniquePtr<char>** category_name) const {+  for (size_t i = 0; i < drop_category_list_.size(); ++i) {+    const auto& drop_category = drop_category_list_[i];+    // Generate a random number in [0, 1000000).+    const int random = rand() % 1000000;+    if (random < drop_category.parts_per_million) {","See the comment thread in the internal design doc about this.  I think we may wind up needing to do something similar to what Go is doing, whereby we model this the same way we do the locality picks.",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19702,306880580,2019-07-24T15:37:08Z,BUILD,"@@ -323,39 +323,36 @@ grpc_cc_library( )  grpc_cc_library(-    name = ""grpc"",+    name = ""grpc_init"",",The `srcs` is duplicate with the next target `grpc`. Is this intentional? How about have a dependency from `grpc` to `grpc_init` and remove `init.cc` from `grpc`,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19729,306882616,2019-07-24T15:41:01Z,src/core/ext/filters/client_channel/lb_policy/xds/xds_client_stats.h,"@@ -208,7 +208,7 @@ class XdsLbClientStats {   LocalityStats* FindLocalityStats(       const RefCountedPtr<XdsLocalityName>& locality_name);   void PruneLocalityStats();-  void AddCallDropped(UniquePtr<char> category);+  void AddCallDropped(const UniquePtr<char>& category);","There's almost never a good reason to pass in a smart pointer as a const reference.  If you don't actually need to pass ownership, then the parameter should just be a `const char*`.  That way, it can also be used by callers that have a string that is not already wrapped inside of a smart pointer.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19729,306887571,2019-07-24T15:50:31Z,src/core/ext/filters/client_channel/lb_policy/xds/xds.cc,"@@ -1092,21 +1105,25 @@ void XdsLb::LbChannelState::EdsCallState::OnResponseReceivedLocked(       GRPC_ERROR_UNREF(parse_error);       return;     }-    if (update.locality_list.empty()) {+    if (update.locality_list.empty() &&+        update.drop_config->drop_category_list().empty()) {","I think this isn't quite right.  If the locality list is empty and the drop list is present but does not add up to 100%, then we still have a problem.  Maybe this should check `drop_all` instead?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19729,306888684,2019-07-24T15:52:41Z,src/core/ext/filters/client_channel/lb_policy/xds/xds.cc,"@@ -1147,10 +1173,12 @@ void XdsLb::LbChannelState::EdsCallState::OnResponseReceivedLocked(       xdslb_policy->lb_chand_ = std::move(xdslb_policy->pending_lb_chand_);     }     // Ignore identical update.-    if (xdslb_policy->locality_list_ == update.locality_list) {+    if (xdslb_policy->locality_list_ == update.locality_list &&","We should probably update the locality list and the drop list independently.  If the drop list changes but the locality list does not, then there's no reason to kick off an update of the locality list.",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19729,306897084,2019-07-24T16:09:25Z,test/cpp/end2end/xds_end2end_test.cc,"@@ -1652,7 +1835,71 @@ TEST_F(SingleBalancerWithClientLoadReportingTest, BalancerRestart) {   EXPECT_EQ(0U, client_stats->total_dropped_requests()); } -// TODO(juanlishen): Add TEST_F(SingleBalancerWithClientLoadReportingTest, Drop)+TEST_F(SingleBalancerWithClientLoadReportingTest, Drop) {+  SetNextResolution({}, kDefaultServiceConfig_.c_str());+  SetNextResolutionForLbChannelAllBalancers();+  const size_t kNumRpcs = 1000;+  const uint32_t drop_per_million_for_lb = 100000;+  const uint32_t drop_per_million_for_throttle = 200000;+  const double drop_rate_for_lb = drop_per_million_for_lb / 1000000.0;+  const double drop_rate_for_throttle =+      drop_per_million_for_throttle / 1000000.0;+  const double drop_rate_for_lb_and_throttle =+      drop_rate_for_lb + (1 - drop_rate_for_lb) * drop_rate_for_throttle;+  // The EDS response contains two drop categories.+  ScheduleResponseForBalancer(+      0,+      EdsServiceImpl::BuildResponse(+          GetBackendPortsInGroups(),+          {{""lb"", drop_per_million_for_lb},+           {""throttle"", drop_per_million_for_throttle}}),+      0);+  int num_ok = 0;+  int num_failure = 0;+  int num_drops = 0;+  std::tie(num_ok, num_failure, num_drops) = WaitForAllBackends();+  const size_t num_warmup = num_ok + num_failure + num_drops;+  // Send kNumRpcs RPCs and count the drops.+  for (size_t i = 0; i < kNumRpcs; ++i) {+    EchoResponse response;+    const Status status = SendRpc(&response);+    if (!status.ok() &&+        status.error_message() == ""Call dropped by load balancing policy"") {+      ++num_drops;+    } else {+      EXPECT_TRUE(status.ok()) << ""code="" << status.error_code()+                               << "" message="" << status.error_message();+      EXPECT_EQ(response.message(), kRequestMessage_);+    }+  }+  // The drop rate should be roughly equal to the expectation.+  const double seen_drop_rate = static_cast<double>(num_drops) / kNumRpcs;+  const double error_tolerance = 0.2;+  EXPECT_THAT(seen_drop_rate,+              ::testing::AllOf(::testing::Ge(drop_rate_for_lb_and_throttle *+                                             (1 - error_tolerance)),+                               ::testing::Le(drop_rate_for_lb_and_throttle *+                                             (1 + error_tolerance))));+  // Check client stats.+  ClientStats* client_stats = balancers_[0]->lrs_service()->WaitForLoadReport();+  EXPECT_EQ(num_drops, client_stats->total_dropped_requests());+  const size_t total_rpc = num_warmup + kNumRpcs;+  EXPECT_THAT(+      client_stats->dropped_requests(""lb""),+      ::testing::AllOf(+          ::testing::Ge(total_rpc * drop_rate_for_lb * (1 - error_tolerance)),+          ::testing::Le(total_rpc * drop_rate_for_lb * (1 + error_tolerance))));+  EXPECT_THAT(+      client_stats->dropped_requests(""throttle""),+      ::testing::AllOf(+          ::testing::Ge(total_rpc * (1 - drop_rate_for_lb) *",I don't think we should need to account for `drop_rate_for_lb` when looking at `drop_rate_for_throttle`.  See my comment elsewhere about not wanting to do a different roll of the dice for each drop category.,
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/19713,306934439,2019-07-24T17:35:58Z,src/core/lib/transport/metadata_batch.cc,"@@ -163,17 +172,28 @@ grpc_error* grpc_metadata_batch_link_head(grpc_metadata_batch* batch,   return GRPC_ERROR_NONE; } +grpc_error* grpc_metadata_batch_link_head(","How do these changes handle the ""Unallowed duplicate metadata"" case that's handled in the maybe_link_callout case? Is it just through the GPR_DEBUG_ASSERT on line 100?",OK
24697473,Tony1023,https://api.github.com/repos/grpc/grpc/pulls/19621,306938048,2019-07-24T17:44:17Z,bazel/grpc_objc_library.bzl,"@@ -0,0 +1,114 @@+load(+    ""//bazel:generate_objc.bzl"",+    ""generate_objc"",+    ""generate_objc_hdrs"",+    ""generate_objc_srcs"",+    ""generate_objc_non_arc_srcs""+)+load(""//bazel:protobuf.bzl"", ""well_known_proto_libs"")++def objc_proto_grpc_library(name, deps, use_well_known_protos = False, **kwargs):","If they are not planning to use services (or no service is declared in any of the proto files), the current `objc_grpc_library` does not work because it must deterministically generate service stubs which require ARC to feed the `srcs` field... But it is doable branch on whether `srcs` is empty in `objc_grpc_library`. If it's empty then we do not pass any thing in field `srcs` for `native.objc_library` that gets invoked. So should I adapt to that?",
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19713,306945289,2019-07-24T18:00:05Z,src/core/lib/transport/metadata_batch.cc,"@@ -163,17 +172,28 @@ grpc_error* grpc_metadata_batch_link_head(grpc_metadata_batch* batch,   return GRPC_ERROR_NONE; } +grpc_error* grpc_metadata_batch_link_head(","My view is:1) Our code should only be setting the relevant metadata exactly once,2) If a user tries to set these metadata specifically, the existing behaviour is we give them a runtime error. IMO the way to do it is to give them a 'stop the world' error during their initial coding/debug phase so it is known that they should not be doing it.",OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/19713,306972731,2019-07-24T19:01:52Z,src/core/lib/transport/metadata_batch.cc,"@@ -163,17 +172,28 @@ grpc_error* grpc_metadata_batch_link_head(grpc_metadata_batch* batch,   return GRPC_ERROR_NONE; } +grpc_error* grpc_metadata_batch_link_head(","Just to confirm: Are the grpc_metadata_batch_callouts_index indices added only by our internal code? And there's no metadata we could receive that would cause us to add duplicates? In that case, I agree that we can rely on our code having the correct behavior.",
2793282,veblush,https://api.github.com/repos/grpc/grpc/pulls/19702,307025993,2019-07-24T21:18:24Z,src/cpp/client/cronet_credentials.cc,"@@ -1,64 +0,0 @@-/*- *- * Copyright 2016 gRPC authors.- *- * Licensed under the Apache License, Version 2.0 (the ""License"");- * you may not use this file except in compliance with the License.- * You may obtain a copy of the License at- *- *     http://www.apache.org/licenses/LICENSE-2.0- *- * Unless required by applicable law or agreed to in writing, software- * distributed under the License is distributed on an ""AS IS"" BASIS,- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.- * See the License for the specific language governing permissions and- * limitations under the License.- *- */--#include <grpcpp/security/credentials.h>--#include <grpc/grpc_cronet.h>-#include <grpcpp/channel.h>-#include <grpcpp/support/channel_arguments.h>-#include ""src/cpp/client/create_channel_internal.h""--namespace grpc {--class CronetChannelCredentialsImpl final : public ChannelCredentials {","It's removed because it belongs to the main BUILD file which cannot have cronet-related rules. It can have a separate BUILD file like Objective-C does. Even though it's removed in this CL, it's possible to revive it with the separate BUILD file.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19712,307279753,2019-07-25T12:54:09Z,src/csharp/Grpc.Core/Internal/DefaultChannelCredentialsConfigurator.cs,"@@ -0,0 +1,173 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Generic;+using System.Runtime.InteropServices;+using System.Runtime.CompilerServices;+using Grpc.Core.Utils;+using Grpc.Core.Logging;++namespace Grpc.Core.Internal+{+    /// <summary>+    /// Creates native call credential objects from instances of <c>ChannelCredentials</c>.+    /// </summary>+    internal class DefaultChannelCredentialsConfigurator : ChannelCredentialsConfiguratorBase+    {+        static readonly ILogger Logger = GrpcEnvironment.Logger.ForType<DefaultCallCredentialsConfigurator>();++        // Native credentials object need to be kept alive once initialized for subchannel sharing to work correctly+        // with secure connections. See https://github.com/grpc/grpc/issues/15207.+        // We rely on finalizer to clean up the native portion of ChannelCredentialsSafeHandle after the ChannelCredentials+        // instance becomes unused.+        static readonly ConditionalWeakTable<ChannelCredentials, Lazy<ChannelCredentialsSafeHandle>> CachedNativeCredentials = new ConditionalWeakTable<ChannelCredentials, Lazy<ChannelCredentialsSafeHandle>>();++        bool configured;+        ChannelCredentialsSafeHandle nativeCredentials;++        public ChannelCredentialsSafeHandle NativeCredentials => nativeCredentials;+        +        public override void SetInsecureCredentials(object state)+        {+            GrpcPreconditions.CheckState(!configured);+            // null corresponds to insecure credentials.+            configured = true;+            nativeCredentials = null;+        }++        public override void SetSslCredentials(object state, string rootCertificates, KeyCertificatePair keyCertificatePair, VerifyPeerCallback verifyPeerCallback)+        {+            GrpcPreconditions.CheckState(!configured);+            configured = true;+            nativeCredentials = GetOrCreateNativeCredentials((ChannelCredentials) state,+                () => CreateNativeSslCredentials(rootCertificates, keyCertificatePair, verifyPeerCallback));+        }++        public override void SetCompositeCredentials(object state, ChannelCredentials channelCredentials, CallCredentials callCredentials)+        {+            GrpcPreconditions.CheckState(!configured);+            configured = true;+            nativeCredentials = GetOrCreateNativeCredentials((ChannelCredentials) state,+                () => CreateNativeCompositeCredentials(channelCredentials, callCredentials));+        }++        private ChannelCredentialsSafeHandle CreateNativeSslCredentials(string rootCertificates, KeyCertificatePair keyCertificatePair, VerifyPeerCallback verifyPeerCallback)+        {+            IntPtr verifyPeerCallbackTag = IntPtr.Zero;+            if (verifyPeerCallback != null)+            {+                verifyPeerCallbackTag = new VerifyPeerCallbackRegistration(verifyPeerCallback).CallbackRegistration.Tag;+            }+            return ChannelCredentialsSafeHandle.CreateSslCredentials(rootCertificates, keyCertificatePair, verifyPeerCallbackTag);+        }++        private ChannelCredentialsSafeHandle CreateNativeCompositeCredentials(ChannelCredentials channelCredentials, CallCredentials callCredentials)+        {+            using (var callCreds = callCredentials.ToNativeCredentials())+            {+                var nativeComposite = ChannelCredentialsSafeHandle.CreateComposite(channelCredentials.ToNativeCredentials(), callCreds);+                if (nativeComposite.IsInvalid)+                {+                    throw new ArgumentException(""Error creating native composite credentials. Likely, this is because you are trying to compose incompatible credentials."");+                }+                return nativeComposite;+            }+        }++        private ChannelCredentialsSafeHandle GetOrCreateNativeCredentials(ChannelCredentials key, Func<ChannelCredentialsSafeHandle> nativeCredentialsFactory)+        {+            Lazy<ChannelCredentialsSafeHandle> lazyValue;",I think the problem with that approach is:- you need to make ChannelCredentials (the shared API) remember an instance of channelCredentialsConfiguratorBase just because one of the implementations happens to need it- the same instance of ChannelCredentials can be used by multiple different configurators (coming from different impls) multiple times. It's not clear what exact configurator should be remembered by the channelCredentials object (the first one ever used?  all of them? - it seems that this can get complex pretty fast).,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/19712,307433044,2019-07-25T18:12:30Z,src/csharp/Grpc.Core/Internal/DefaultChannelCredentialsConfigurator.cs,"@@ -0,0 +1,173 @@+#region Copyright notice and license++// Copyright 2019 The gRPC Authors+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Generic;+using System.Runtime.InteropServices;+using System.Runtime.CompilerServices;+using Grpc.Core.Utils;+using Grpc.Core.Logging;++namespace Grpc.Core.Internal+{+    /// <summary>+    /// Creates native call credential objects from instances of <c>ChannelCredentials</c>.+    /// </summary>+    internal class DefaultChannelCredentialsConfigurator : ChannelCredentialsConfiguratorBase+    {+        static readonly ILogger Logger = GrpcEnvironment.Logger.ForType<DefaultCallCredentialsConfigurator>();++        // Native credentials object need to be kept alive once initialized for subchannel sharing to work correctly+        // with secure connections. See https://github.com/grpc/grpc/issues/15207.+        // We rely on finalizer to clean up the native portion of ChannelCredentialsSafeHandle after the ChannelCredentials+        // instance becomes unused.+        static readonly ConditionalWeakTable<ChannelCredentials, Lazy<ChannelCredentialsSafeHandle>> CachedNativeCredentials = new ConditionalWeakTable<ChannelCredentials, Lazy<ChannelCredentialsSafeHandle>>();++        bool configured;+        ChannelCredentialsSafeHandle nativeCredentials;++        public ChannelCredentialsSafeHandle NativeCredentials => nativeCredentials;+        +        public override void SetInsecureCredentials(object state)+        {+            GrpcPreconditions.CheckState(!configured);+            // null corresponds to insecure credentials.+            configured = true;+            nativeCredentials = null;+        }++        public override void SetSslCredentials(object state, string rootCertificates, KeyCertificatePair keyCertificatePair, VerifyPeerCallback verifyPeerCallback)+        {+            GrpcPreconditions.CheckState(!configured);+            configured = true;+            nativeCredentials = GetOrCreateNativeCredentials((ChannelCredentials) state,+                () => CreateNativeSslCredentials(rootCertificates, keyCertificatePair, verifyPeerCallback));+        }++        public override void SetCompositeCredentials(object state, ChannelCredentials channelCredentials, CallCredentials callCredentials)+        {+            GrpcPreconditions.CheckState(!configured);+            configured = true;+            nativeCredentials = GetOrCreateNativeCredentials((ChannelCredentials) state,+                () => CreateNativeCompositeCredentials(channelCredentials, callCredentials));+        }++        private ChannelCredentialsSafeHandle CreateNativeSslCredentials(string rootCertificates, KeyCertificatePair keyCertificatePair, VerifyPeerCallback verifyPeerCallback)+        {+            IntPtr verifyPeerCallbackTag = IntPtr.Zero;+            if (verifyPeerCallback != null)+            {+                verifyPeerCallbackTag = new VerifyPeerCallbackRegistration(verifyPeerCallback).CallbackRegistration.Tag;+            }+            return ChannelCredentialsSafeHandle.CreateSslCredentials(rootCertificates, keyCertificatePair, verifyPeerCallbackTag);+        }++        private ChannelCredentialsSafeHandle CreateNativeCompositeCredentials(ChannelCredentials channelCredentials, CallCredentials callCredentials)+        {+            using (var callCreds = callCredentials.ToNativeCredentials())+            {+                var nativeComposite = ChannelCredentialsSafeHandle.CreateComposite(channelCredentials.ToNativeCredentials(), callCreds);+                if (nativeComposite.IsInvalid)+                {+                    throw new ArgumentException(""Error creating native composite credentials. Likely, this is because you are trying to compose incompatible credentials."");+                }+                return nativeComposite;+            }+        }++        private ChannelCredentialsSafeHandle GetOrCreateNativeCredentials(ChannelCredentials key, Func<ChannelCredentialsSafeHandle> nativeCredentialsFactory)+        {+            Lazy<ChannelCredentialsSafeHandle> lazyValue;","Ok, in keeping the current scheme, I think this loop can still be simplified though.What do you think about something like this:```        private ChannelCredentialsSafeHandle GetOrCreateNativeCredentials(ChannelCredentials key, Func<ChannelCredentialsSafeHandle> nativeCredentialsFactory)        {            Lazy<ChannelCredentialsSafeHandle> lazyValue;            lock (myLock) {                if (!CachedNativeCredentials.TryGetValue(key, out lazyValue))                {                        lazyValue = new Lazy<ChannelCredentialsSafeHandle>(nativeCredentialsFactory);                        CachedNativeCredentials.Add(key, lazyValue);                }            }            return lazyValue.Value;        }```this would still avoid calling into C-core while holding a c# lock",
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19744,307451225,2019-07-25T18:55:03Z,src/core/lib/surface/call.cc,"@@ -157,6 +158,7 @@ struct grpc_call {   gpr_timespec start_time = gpr_now(GPR_CLOCK_MONOTONIC);   /* parent_call* */ gpr_atm parent_call_atm = 0;   child_call* child = nullptr;+  grpc_core::Atomic<intptr_t> batches_completed;","Two-fold reason: RELAXED semantics, and no branch on Ref() (while Unref() has a branch to see if the Ref is now 0).",
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/19622,307521844,2019-07-25T22:11:42Z,BUILD,"@@ -2317,6 +2317,81 @@ grpc_cc_library(     tags = [""no_windows""], ) +grpc_cc_library(","No, you need to use the new grpc_upb_proto_library for this.",
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/19622,307535963,2019-07-25T23:12:36Z,tools/codegen/core/gen_upb_api.sh,"@@ -36,6 +43,11 @@ proto_files=( \   ""google/protobuf/wrappers.proto"" \   ""google/rpc/status.proto"" \   ""gogoproto/gogo.proto"" \+  ""grpc/health/v1/health.proto"" \+  ""grpc/lb/v1/load_balancer.proto"" \+  ""src/core/tsi/alts/handshaker/proto/handshaker.proto"" \",Maybe we should alphabetize this list. I didn't realize it wasn't.,
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19747,307578010,2019-07-26T03:42:05Z,test/cpp/ios/RemoteTestClientCpp/RemoteTestCpp.podspec,"@@ -0,0 +1,93 @@+Pod::Spec.new do |s|+  s.name     = ""RemoteTestCpp""+  s.version  = ""0.0.1""+  s.license  = ""Apache License, Version 2.0""+  s.authors  = { 'gRPC contributors' => 'grpc-io@googlegroups.com' }+  s.homepage = ""https://grpc.io/""+  s.summary = ""RemoteTest example""+  s.source = { :git => 'https://github.com/grpc/grpc.git' }++  s.ios.deployment_target = '7.1'+  s.osx.deployment_target = '10.9'++  # Run protoc with the C++ and gRPC plugins to generate protocol messages and gRPC clients.+  s.dependency ""!ProtoCompiler-gRPCCppPlugin""+  s.dependency ""Protobuf-C++""+  s.dependency ""gRPC-C++""+  s.source_files = ""src/proto/grpc/testing/*.pb.{h,cc}""+  s.header_mappings_dir = ""RemoteTestCpp""+  s.requires_arc = false++  repo_root = '../../../..'+  config = ENV['CONFIG'] || 'opt'+  bin_dir = ""#{repo_root}/bins/#{config}""++  protoc = ""#{bin_dir}/protobuf/protoc""+  well_known_types_dir = ""#{repo_root}/third_party/protobuf/src""+  plugin = ""#{bin_dir}/grpc_cpp_plugin""+  proto_dir = ""#{repo_root}/src/proto/grpc/testing""++  s.prepare_command = <<-CMD+    if [ -f #{protoc} ]; then+      #{protoc} \+          --plugin=protoc-gen-grpc=#{plugin} \+          --cpp_out=. \+          --grpc_out=. \+          -I #{repo_root} \+          -I #{proto_dir} \+          -I #{well_known_types_dir} \+          #{proto_dir}/echo.proto+      #{protoc} \+          --plugin=protoc-gen-grpc=#{plugin} \+          --cpp_out=. \+          --grpc_out=. \+          -I #{repo_root} \+          -I #{proto_dir} \+          -I #{well_known_types_dir} \+          #{proto_dir}/echo_messages.proto+      #{protoc} \+          --plugin=protoc-gen-grpc=#{plugin} \+          --cpp_out=. \+          --grpc_out=. \+          -I #{repo_root} \+          -I #{proto_dir} \+          -I #{well_known_types_dir} \+          #{proto_dir}/simple_messages.proto+    else+      # protoc was not found bin_dir, use installed version instead+      (>&2 echo ""\nWARNING: Using installed version of protoc. It might be incompatible with gRPC"")++      protoc \","Yea. I mean, how about provide an error message saying that `protoc` is not found? It's not a big problem so it's up to you.",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19747,307578696,2019-07-26T03:46:47Z,test/cpp/ios/CronetTests/TestHelper.h,"@@ -46,8 +46,8 @@ class DummyInterceptor : public grpc::experimental::Interceptor {   static int GetNumTimesRun();   private:-  static std::atomic<int> num_times_run_;-  static std::atomic<int> num_times_run_reverse_;+  static std::atomic<int> num_times_run;",This is still member variable of the class so if it was me I would have put `_` at the end... but maybe you removed it due to some style guide somewhere? Just a question; not really comment to the code.,OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19621,307583082,2019-07-26T04:18:12Z,bazel/generate_objc.bzl,"@@ -0,0 +1,225 @@+load(+    ""//bazel:protobuf.bzl"",+    ""get_include_protoc_args"",+    ""get_plugin_args"",+    ""proto_path_to_generated_filename"",+)+load(+    "":grpc_util.bzl"", +    ""to_upper_camel_with_extension"",+    ""label_to_file"",+)++_GRPC_PROTO_HEADER_FMT = ""{}.pbrpc.h""+_GRPC_PROTO_SRC_FMT = ""{}.pbrpc.m""+_PROTO_HEADER_FMT = ""{}.pbobjc.h""+_PROTO_SRC_FMT = ""{}.pbobjc.m""+_GENERATED_PROTOS_DIR = ""_generated_protos""++_GENERATE_HDRS = 1+_GENERATE_SRCS = 2+_GENERATE_NON_ARC_SRCS = 3++def _generate_objc_impl(ctx):+    """"""Implementation of the generate_objc rule.""""""+    protos = [+        f+        for src in ctx.attr.deps+        for f in src[ProtoInfo].transitive_imports.to_list()+    ]+    outs = []++    label_package = _join_directories([ctx.label.workspace_root, ctx.label.package])++    files_with_rpc = [label_to_file(f) for f in ctx.attr.srcs]+    for proto in protos:+        outs += [_get_output_file_name_from_proto(proto, _PROTO_HEADER_FMT)]+        outs += [_get_output_file_name_from_proto(proto, _PROTO_SRC_FMT)]++        file_path = _strip_package_from_path(label_package, proto)+        if not file_path.startswith(""//""):+            pass # TODO(tonyzhehaolu): check package boundary+        if file_path in files_with_rpc or proto.path in files_with_rpc:+            outs += [_get_output_file_name_from_proto(proto, _GRPC_PROTO_HEADER_FMT)]+            outs += [_get_output_file_name_from_proto(proto, _GRPC_PROTO_SRC_FMT)]+    +    out_files = [ctx.actions.declare_file(out) for out in outs]+    dir_out = _join_directories([+        str(ctx.genfiles_dir.path), label_package, _GENERATED_PROTOS_DIR+    ])++    arguments = []+    if ctx.executable.plugin:+        arguments += get_plugin_args(+            ctx.executable.plugin,+            [],+            dir_out,+            False,+        )+        tools = [ctx.executable.plugin]+    arguments += [""--objc_out="" + dir_out]++    arguments += [""--proto_path=.""]+    arguments += get_include_protoc_args(protos)+    # Include the output directory so that protoc puts the generated code in the+    # right directory.+    arguments += [""--proto_path={}"".format(dir_out)]+    arguments += [""--proto_path={}"".format(_get_directory_from_proto(proto)) for proto in protos]+    arguments += [_get_srcs_file_path(proto) for proto in protos]++    # create a list of well known proto files if the argument is non-None+    well_known_proto_files = []+    if ctx.attr.use_well_known_protos:+        f = ctx.attr.well_known_protos.files.to_list()[0].dirname+        arguments += [""-I{0}"".format(f + ""/../.."")]+        well_known_proto_files = ctx.attr.well_known_protos.files.to_list()+    ctx.actions.run(+        inputs = protos + well_known_proto_files,+        tools = tools,+        outputs = out_files,+        executable = ctx.executable._protoc,+        arguments = arguments,+    )++    return struct(files = depset(out_files))++def _get_output_file_name_from_proto(proto, fmt):+    return proto_path_to_generated_filename(+        _GENERATED_PROTOS_DIR + ""/"" ++        _get_directory_from_proto(proto) + _get_slash_or_null_from_proto(proto) ++        to_upper_camel_with_extension(_get_file_name_from_proto(proto), ""proto""),+        fmt,+    )++def _get_file_name_from_proto(proto):+    return proto.path.rpartition(""/"")[2]++def _get_slash_or_null_from_proto(proto):+    """"""Potentially returns empty (if the file is in the root directory)""""""+    return proto.path.rpartition(""/"")[1]++def _get_directory_from_proto(proto):+    return proto.path.rpartition(""/"")[0]++def _strip_package_and_to_camel_case(label_package, file):+    return to_upper_camel_with_extension(+        _strip_package_from_path(label_package, file),+        ""proto""+    )++def _strip_package_from_path(label_package, file):+    """"""strips the label's package from the file path+    e.g. In package src/objective-c: src/objective-c/foo/bar.proto -> foo/bar.proto+    If the file is not in the same package, then the files path prepended with ""//"" is returned+    """"""+    prefix_len = 0+    if not file.is_source and file.path.startswith(file.root.path):","Comment this please.It was not very intuitive that the ""prefix"" is something you want to exclude from matching. Consider renaming it.",
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19747,307588338,2019-07-26T04:57:24Z,test/cpp/ios/CronetTests/TestHelper.h,"@@ -46,8 +46,8 @@ class DummyInterceptor : public grpc::experimental::Interceptor {   static int GetNumTimesRun();   private:-  static std::atomic<int> num_times_run_;-  static std::atomic<int> num_times_run_reverse_;+  static std::atomic<int> num_times_run;",I wasn't sure about the guidelines for naming static members. I have reverted this change and restored the trailing `_`.,
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19733,308293332,2019-07-29T15:27:26Z,src/compiler/objective_c_plugin.cc,"@@ -74,6 +80,24 @@ class ObjectiveCGrpcGenerator : public grpc::protobuf::compiler::CodeGenerator {       return true;     } +    ::grpc::string framework;+    std::vector<::grpc::string> params_list =+        grpc_generator::tokenize(parameter, "","");+    for (auto param_str = params_list.begin(); param_str != params_list.end();+         ++param_str) {+      std::vector<::grpc::string> param =+          grpc_generator::tokenize(*param_str, ""="");+      if (param[0] == ""generate_for_named_framework"") {+        if (param[1].empty()) {",I wonder if it will be index out of bound if someone writes `--grpc_out=generate_for_named_framework:.`. I don't think `tokenize` adds an empty element as the second parameter in this case.,
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19733,308301102,2019-07-29T15:43:52Z,src/objective-c/examples/InterceptorSample/Podfile,"@@ -2,6 +2,8 @@ platform :ios, '8.0'  install! 'cocoapods', :deterministic_uuids => false +use_frameworks! if ENV['FRAMEWORKS'] != 'NO'",Comment on why negative condition is needed here,
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19733,308357532,2019-07-29T17:51:37Z,src/compiler/objective_c_plugin.cc,"@@ -87,7 +87,11 @@ class ObjectiveCGrpcGenerator : public grpc::protobuf::compiler::CodeGenerator {          ++param_str) {       std::vector<::grpc::string> param =           grpc_generator::tokenize(*param_str, ""="");-      if (param[0] == ""generate_for_named_framework"") {+      cerr << param[0];+      if (param.size() != 2) {+        *error = grpc::string(""Input format: <key1>=<value1>,<key2>=<value2>"");","Some parameters need to allow key-only, without value. I think this check should be in the `if` statement of `generate_for_named_framework` itself, like `generate_for_named_framework parameter requires a value.`",OK
10135909,dklempner,https://api.github.com/repos/grpc/grpc/pulls/19727,308425896,2019-07-29T20:36:33Z,src/core/ext/filters/client_idle/client_idle_filter.cc,"@@ -115,37 +182,105 @@ void ChannelData::StartTransportOp(grpc_channel_element* elem,   ChannelData* chand = static_cast<ChannelData*>(elem->channel_data);   // Catch the disconnect_with_error transport op.   if (op->disconnect_with_error != nullptr) {-    // Disconnect. Cancel the timer if we set it before.-    // IncreaseCallCount() introduces a dummy call. It will cancel the timer and-    // prevent the timer from being reset by other threads.+    // IncreaseCallCount() introduces a dummy call and prevent the timer from+    // being reset by other threads.     chand->IncreaseCallCount();+    // If the timer has been set, cancel the timer.+    // No synchronization issues here. grpc_timer_cancel() is valid as long as+    // the timer has been init()ed before.+    grpc_timer_cancel(&chand->idle_timer_);   }   // Pass the op to the next filter.   grpc_channel_next_op(elem, op); }  void ChannelData::IncreaseCallCount() {-  MutexLock lock(&call_count_mu_);-  if (call_count_++ == 0) {-    grpc_timer_cancel(&idle_timer_);+  const intptr_t previous_value = call_count_.FetchAdd(1, MemoryOrder::RELAXED);+  GRPC_IDLE_FILTER_LOG(""call counter has increased to %"" PRIuPTR,+                       previous_value + 1);+  if (previous_value == 0) {+    // This call is the one that makes the channel busy.+    // Loop here to make sure the previous decrease operation has finished.+    ChannelState state = state_.Load(MemoryOrder::RELAXED);+    while (true) {+      switch (state) {+        // Timer has been set. Switch to TIMER_PENDING_CALLS_ACTIVE.+        case TIMER_PENDING:+        case TIMER_PENDING_CALLS_SEEN_SINCE_TIMER_START:+          // At this point, the state may have been switched to IDLE by the+          // idle timer callback. Therefore, use CAS operation to change the+          // state atomically.+          // Use MemoryOrder::ACQUIRE on success to ensure last_idle_time_ has+          // been properly set in DecreaseCallCount().+          if (state_.CompareExchangeWeak(&state, TIMER_PENDING_CALLS_ACTIVE,+                                         MemoryOrder::ACQUIRE,+                                         MemoryOrder::RELAXED)) {+            return;+          }+          break;+        // Timer has not been set. Switch to CALLS_ACTIVE.+        case IDLE:+          // In this case, no other threads will modify the state, so we can+          // just store the value.+          state_.Store(CALLS_ACTIVE, MemoryOrder::RELAXED);+          return;+        default:+          // The state has not been switched to desired value yet, try again.+          state = state_.Load(MemoryOrder::RELAXED);+          break;+      }+    }   }-  GRPC_IDLE_FILTER_LOG(""call counter has increased to %"" PRIuPTR, call_count_); }  void ChannelData::DecreaseCallCount() {-  MutexLock lock(&call_count_mu_);-  if (call_count_-- == 1) {-    StartIdleTimer();+  const intptr_t previous_value = call_count_.FetchSub(1, MemoryOrder::RELAXED);+  GRPC_IDLE_FILTER_LOG(""call counter has decreased to %"" PRIuPTR,+                       previous_value - 1);+  if (previous_value == 1) {+    // This call is the one that makes the channel idle.+    // last_idle_time_ does not need to be Atomic<> because busy-loops in+    // IncreaseCallCount(), DecreaseCallCount() and IdleTimerCallback() will+    // prevent multiple threads from simultaneously accessing this variable.+    last_idle_time_ = ExecCtx::Get()->Now();+    ChannelState state = state_.Load(MemoryOrder::RELAXED);+    while (true) {+      switch (state) {+        // Timer has been set. Switch to+        // TIMER_PENDING_CALLS_SEEN_SINCE_TIMER_START+        case TIMER_PENDING_CALLS_ACTIVE:+          // At this point, the state may have been switched to CALLS_ACTIVE by+          // the idle timer callback. Therefore, use CAS operation to change the+          // state atomically.+          // Release store here to make the idle timer callback see the updated+          // value of last_idle_time_ to properly reset the idle timer.+          if (state_.CompareExchangeWeak(+                  &state, TIMER_PENDING_CALLS_SEEN_SINCE_TIMER_START,+                  MemoryOrder::RELEASE, MemoryOrder::RELAXED)) {","I'm a little concerned here that if the common case involves connections going between 0 and 1 outstanding calls, this is going to make things no better than before -- we're going from an essentially uncontended mutex lock/unlock to two atomics, which would be of comparable cost but increased complexity.",
10135909,dklempner,https://api.github.com/repos/grpc/grpc/pulls/19727,308435722,2019-07-29T21:01:18Z,src/core/ext/filters/client_idle/client_idle_filter.cc,"@@ -115,37 +182,105 @@ void ChannelData::StartTransportOp(grpc_channel_element* elem,   ChannelData* chand = static_cast<ChannelData*>(elem->channel_data);   // Catch the disconnect_with_error transport op.   if (op->disconnect_with_error != nullptr) {-    // Disconnect. Cancel the timer if we set it before.-    // IncreaseCallCount() introduces a dummy call. It will cancel the timer and-    // prevent the timer from being reset by other threads.+    // IncreaseCallCount() introduces a dummy call and prevent the timer from+    // being reset by other threads.     chand->IncreaseCallCount();+    // If the timer has been set, cancel the timer.+    // No synchronization issues here. grpc_timer_cancel() is valid as long as+    // the timer has been init()ed before.+    grpc_timer_cancel(&chand->idle_timer_);   }   // Pass the op to the next filter.   grpc_channel_next_op(elem, op); }  void ChannelData::IncreaseCallCount() {-  MutexLock lock(&call_count_mu_);-  if (call_count_++ == 0) {-    grpc_timer_cancel(&idle_timer_);+  const intptr_t previous_value = call_count_.FetchAdd(1, MemoryOrder::RELAXED);+  GRPC_IDLE_FILTER_LOG(""call counter has increased to %"" PRIuPTR,+                       previous_value + 1);+  if (previous_value == 0) {+    // This call is the one that makes the channel busy.+    // Loop here to make sure the previous decrease operation has finished.+    ChannelState state = state_.Load(MemoryOrder::RELAXED);+    while (true) {+      switch (state) {+        // Timer has been set. Switch to TIMER_PENDING_CALLS_ACTIVE.+        case TIMER_PENDING:+        case TIMER_PENDING_CALLS_SEEN_SINCE_TIMER_START:+          // At this point, the state may have been switched to IDLE by the+          // idle timer callback. Therefore, use CAS operation to change the+          // state atomically.+          // Use MemoryOrder::ACQUIRE on success to ensure last_idle_time_ has+          // been properly set in DecreaseCallCount().+          if (state_.CompareExchangeWeak(&state, TIMER_PENDING_CALLS_ACTIVE,+                                         MemoryOrder::ACQUIRE,+                                         MemoryOrder::RELAXED)) {+            return;+          }+          break;+        // Timer has not been set. Switch to CALLS_ACTIVE.+        case IDLE:+          // In this case, no other threads will modify the state, so we can+          // just store the value.+          state_.Store(CALLS_ACTIVE, MemoryOrder::RELAXED);+          return;+        default:+          // The state has not been switched to desired value yet, try again.+          state = state_.Load(MemoryOrder::RELAXED);+          break;+      }+    }   }-  GRPC_IDLE_FILTER_LOG(""call counter has increased to %"" PRIuPTR, call_count_); }  void ChannelData::DecreaseCallCount() {-  MutexLock lock(&call_count_mu_);-  if (call_count_-- == 1) {-    StartIdleTimer();+  const intptr_t previous_value = call_count_.FetchSub(1, MemoryOrder::RELAXED);+  GRPC_IDLE_FILTER_LOG(""call counter has decreased to %"" PRIuPTR,+                       previous_value - 1);+  if (previous_value == 1) {","Assuming that the call to decrement must (independently) happen after the call to increment, I think the only failure modes local to here involve failing to clean up the alarm while an RPC is in flight.For disarm to win -- that is, we have a channel with no idle timer and no traffic -- one of the final racing calls has to be an increment, which means the channel has an RPC on it and we're fine.",
7281574,nicolasnoble,https://api.github.com/repos/grpc/grpc/pulls/19621,308465649,2019-07-29T22:34:37Z,WORKSPACE,"@@ -66,6 +66,32 @@ rbe_autoconfig(     ), ) +git_repository(","Dependencies need to go in `bazel/grpc_deps.bzl`, so that whomever imports us can grab the same list of dependencies, just like what you're doing below with the `apple_rules_dependencies()`",
24697473,Tony1023,https://api.github.com/repos/grpc/grpc/pulls/19621,309014863,2019-07-31T02:15:52Z,bazel/grpc_build_system.bzl,"@@ -240,6 +254,42 @@ def grpc_package(name, visibility = ""private"", features = []):             features = features,         ) +def grpc_objc_library(",`grpc_objc_library` has been merged in Google3 as well by CL 258434245,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/19799,309046778,2019-07-31T05:45:54Z,src/csharp/experimental/build_unitypackage.sh,"@@ -1,32 +0,0 @@-#!/bin/sh",I assume this bash script was just unused?,
42475716,mqingli,https://api.github.com/repos/grpc/grpc/pulls/19814,310683244,2019-08-05T16:15:27Z,CMakeLists.txt,"@@ -3477,6 +3477,360 @@ endif (gRPC_BUILD_CODEGEN)  endif (gRPC_BUILD_TESTS) +add_library(grpc++_cronet+  src/cpp/client/cronet_credentials.cc+  src/cpp/client/channel_cc.cc+  src/cpp/client/client_context.cc+  src/cpp/client/client_interceptor.cc+  src/cpp/client/create_channel.cc+  src/cpp/client/create_channel_internal.cc+  src/cpp/client/create_channel_posix.cc+  src/cpp/client/credentials_cc.cc+  src/cpp/client/generic_stub.cc+  src/cpp/common/alarm.cc+  src/cpp/common/channel_arguments.cc+  src/cpp/common/channel_filter.cc+  src/cpp/common/completion_queue_cc.cc+  src/cpp/common/core_codegen.cc+  src/cpp/common/resource_quota_cc.cc+  src/cpp/common/rpc_method.cc+  src/cpp/common/validate_service_config.cc+  src/cpp/common/version_cc.cc+  src/cpp/server/async_generic_service.cc+  src/cpp/server/channel_argument_option.cc+  src/cpp/server/create_default_thread_pool.cc+  src/cpp/server/dynamic_thread_pool.cc+  src/cpp/server/external_connection_acceptor_impl.cc+  src/cpp/server/health/default_health_check_service.cc+  src/cpp/server/health/health_check_service.cc+  src/cpp/server/health/health_check_service_server_builder_option.cc+  src/cpp/server/server_builder.cc+  src/cpp/server/server_cc.cc+  src/cpp/server/server_context.cc+  src/cpp/server/server_credentials.cc+  src/cpp/server/server_posix.cc+  src/cpp/thread_manager/thread_manager.cc+  src/cpp/util/byte_buffer_cc.cc+  src/cpp/util/status.cc+  src/cpp/util/string_ref.cc+  src/cpp/util/time_cc.cc+  src/core/ext/filters/client_channel/health/health.pb.c",The following source code files are included in both grpc_cronet and grpc++_cronet library. They cause duplicate symbols when linking with both libgrpc_cronet and libgrpc++_cronet. Probably remove these 4 files from grpc++_cronet?src/core/ext/filters/client_channel/health/health.pb.c third_party/nanopb/pb_common.c third_party/nanopb/pb_decode.c third_party/nanopb/pb_encode.c,OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19814,310725845,2019-08-05T18:06:00Z,CMakeLists.txt,"@@ -3477,6 +3477,360 @@ endif (gRPC_BUILD_CODEGEN)  endif (gRPC_BUILD_TESTS) +add_library(grpc++_cronet+  src/cpp/client/cronet_credentials.cc","If you're using cronet client, why does your code depend on:1. server credentials. gRPC cronet is client only, why is there a server dependency?2. secure_credentials.cc. Why is there a dependency on this file? I thought you just needed `CronetChannelCredentials` which is defined in src/cpp/client/cronet_credentials.cc.",
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/19822,311219247,2019-08-06T18:46:42Z,examples/python/debug/get_stats.py,"@@ -20,8 +20,13 @@ import logging import argparse import grpc-from grpc_channelz.v1 import channelz_pb2-from grpc_channelz.v1 import channelz_pb2_grpc++try:+    from src.python.grpcio_channelz.grpc_channelz.v1 import channelz_pb2+    from src.python.grpcio_channelz.grpc_channelz.v1 import channelz_pb2_grpc+except ImportError:+    from grpc_channelz.v1 import channelz_pb2+    from grpc_channelz.v1 import channelz_pb2_grpc","I'm afraid this isn't quite the same problem. The generated code references `src.python.grpcio_channelz.grpc_channelz.v1.channelz_pb2`, whereas user-written code references `grpc_channelz.v1`. While both of these import paths refer to the same file, they end up instantiating two separate module objects with incompatible classes.This *could* be solved by https://github.com/grpc/grpc/pull/18808, but in the general case, it would require quite a bit of plumbing and probably an addition to our `py_proto_library` and `py_grpc_library` APIs. Internally, we need to strip `google3.third_party.py.`. As a rule available for general use in OSS, there could be an arbitrary collection of prefixes you'd like to strip. In the case of just our repo, we'd probably need to strip - `src.python.grpcio_channelz.` - `src.python.grpcio_health_checking.` - `src.python.grpcio_reflection.`The same issue will come up every time someone wants to manage code with Bazel and `setuptools` without code changes. That's essentially the problem we've seen internally, anyway.Since this is only currently possible by modifying the C++ code for the plugin, in order to make it extensible, I think we'd need to: - Add a new flag to the `protoc` plugin making this option accessible to users without recompiling. - Add an option to our bazel macro to make use of the new flag.But this is a non-negligible chunk of work that can be done in a backwards-compatible manner. For the moment, I'd rather add a TODO and pay this down in a future PR.",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19822,311282466,2019-08-06T21:26:12Z,bazel/grpc_python_deps.bzl,"@@ -1,8 +1,67 @@-load(""//third_party/py:python_configure.bzl"", ""python_configure"")-load(""@io_bazel_rules_python//python:pip.bzl"", ""pip_repositories"")-load(""@grpc_python_dependencies//:requirements.bzl"", ""pip_install"")+""""""Load dependencies needed to compile and test the grpc python library as a 3rd-party consumer.""""""++load(""@bazel_tools//tools/build_defs/repo:git.bzl"", ""git_repository"")+load(""@bazel_tools//tools/build_defs/repo:http.bzl"", ""http_archive"")+load(""@com_github_grpc_grpc//third_party/py:python_configure.bzl"", ""python_configure"")  def grpc_python_deps():+    native.bind(+        name = ""six"",+        actual = ""@six_archive//:six"",+    )++    # protobuf binds to the name ""six"", so we can't use it here.","Curious: Does ProtoBuf using the name ""six"" for the Python package `six`? In that case, does our external packages prevent our dependents unable to reuse those names?",
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/19822,311298780,2019-08-06T22:16:18Z,bazel/grpc_python_deps.bzl,"@@ -1,8 +1,67 @@-load(""//third_party/py:python_configure.bzl"", ""python_configure"")-load(""@io_bazel_rules_python//python:pip.bzl"", ""pip_repositories"")-load(""@grpc_python_dependencies//:requirements.bzl"", ""pip_install"")+""""""Load dependencies needed to compile and test the grpc python library as a 3rd-party consumer.""""""++load(""@bazel_tools//tools/build_defs/repo:git.bzl"", ""git_repository"")+load(""@bazel_tools//tools/build_defs/repo:http.bzl"", ""http_archive"")+load(""@com_github_grpc_grpc//third_party/py:python_configure.bzl"", ""python_configure"")  def grpc_python_deps():+    native.bind(+        name = ""six"",+        actual = ""@six_archive//:six"",+    )++    # protobuf binds to the name ""six"", so we can't use it here.","The fact that `protobuf` uses `bind` on the name `six` means that no project that transitively depends on it can use the name `six`. I really wanted `six` to be referred to as `@six//:six`, but Bazel throws an esoteric error that does not at all indicate the problem is a name collision. That wall was a tough one to crack through. I don't see any option besides naming the actual repo something besides `six` and binding it to `//external:six`.",
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19814,311314547,2019-08-06T23:21:37Z,CMakeLists.txt,"@@ -3477,6 +3477,360 @@ endif (gRPC_BUILD_CODEGEN)  endif (gRPC_BUILD_TESTS) +add_library(grpc++_cronet+  src/cpp/client/cronet_credentials.cc","Thanks for the explanation. I think we can solve your issues with unresolved symbols, duplicate symbols by packaging all the required code (cronet client, http2 client, server) in libgrpc++_cronet.Then you would only depend on one library - libgrpc++_cronet.I have made made this change - PTAL.",OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19814,311316562,2019-08-06T23:31:44Z,CMakeLists.txt,"@@ -3477,6 +3477,360 @@ endif (gRPC_BUILD_CODEGEN)  endif (gRPC_BUILD_TESTS) +add_library(grpc++_cronet+  src/cpp/client/cronet_credentials.cc",You can experiment with making changes to the lib dependencies yourself. Here's how it works:[CMakelists.txt](https://github.com/grpc/grpc/blob/master/CMakeLists.txt) is generated from a [template](https://github.com/grpc/grpc/blob/master/templates/CMakeLists.txt.template) and data from [build.yaml](https://github.com/grpc/grpc/blob/master/build.yaml).Run tools/buildgen/generate_projects.sh to regenerate CMakelists.txt after updating build.yaml and/or the template. buil.yaml syntax is documented [here](https://github.com/grpc/grpc/blob/master/templates/README.md).,
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/19741,311791408,2019-08-07T22:36:47Z,src/core/tsi/alts/handshaker/alts_handshaker_client.cc,"@@ -150,35 +150,41 @@ void alts_handshaker_client_handle_response(alts_handshaker_client* c,     cb(TSI_DATA_CORRUPTED, user_data, nullptr, 0, nullptr);     return;   }-  grpc_slice* slice = static_cast<grpc_slice*>(resp->out_frames.arg);+  upb_strview out_frames = grpc_gcp_HandshakerResp_out_frames(resp);   unsigned char* bytes_to_send = nullptr;   size_t bytes_to_send_size = 0;-  if (slice != nullptr) {-    bytes_to_send_size = GRPC_SLICE_LENGTH(*slice);+  if (out_frames.size > 0) {+    bytes_to_send_size = out_frames.size;     while (bytes_to_send_size > client->buffer_size) {       client->buffer_size *= 2;       client->buffer = static_cast<unsigned char*>(           gpr_realloc(client->buffer, client->buffer_size));     }-    memcpy(client->buffer, GRPC_SLICE_START_PTR(*slice), bytes_to_send_size);+    memcpy(client->buffer, out_frames.data, bytes_to_send_size);     bytes_to_send = client->buffer;   }   tsi_handshaker_result* result = nullptr;   if (is_handshake_finished_properly(resp)) {     alts_tsi_handshaker_result_create(resp, client->is_client, &result);-    alts_tsi_handshaker_result_set_unused_bytes(result, &client->recv_bytes,-                                                resp->bytes_consumed);-  }-  grpc_status_code code = static_cast<grpc_status_code>(resp->status.code);+    alts_tsi_handshaker_result_set_unused_bytes(+        result, &client->recv_bytes,+        grpc_gcp_HandshakerResp_bytes_consumed(resp));+  }+  const grpc_gcp_HandshakerStatus* resp_status =+      grpc_gcp_HandshakerResp_status(resp);+  grpc_status_code code = (resp_status != nullptr)+                              ? static_cast<grpc_status_code>(+                                    grpc_gcp_HandshakerStatus_code(resp_status))+                              : GRPC_STATUS_OK;","The semantics of code (from lines 175 to 178) is slightly different from that of original. That is if `resp` is invalid, it returns `GRPC_STATUS_OK` while in the original code, it directly returns. Could you please double-check?",
2793282,veblush,https://api.github.com/repos/grpc/grpc/pulls/19741,311798449,2019-08-07T23:06:31Z,src/core/tsi/alts/handshaker/alts_tsi_utils.cc,"@@ -41,18 +41,22 @@ tsi_result alts_tsi_utils_convert_to_tsi_result(grpc_status_code code) {   } } -grpc_gcp_handshaker_resp* alts_tsi_utils_deserialize_response(-    grpc_byte_buffer* resp_buffer) {+grpc_gcp_HandshakerResp* alts_tsi_utils_deserialize_response(+    grpc_byte_buffer* resp_buffer, upb_arena* arena) {   GPR_ASSERT(resp_buffer != nullptr);+  GPR_ASSERT(arena != nullptr);   grpc_byte_buffer_reader bbr;   grpc_byte_buffer_reader_init(&bbr, resp_buffer);   grpc_slice slice = grpc_byte_buffer_reader_readall(&bbr);-  grpc_gcp_handshaker_resp* resp = grpc_gcp_handshaker_resp_create();-  bool ok = grpc_gcp_handshaker_resp_decode(slice, resp);+  size_t buf_size = GPR_SLICE_LENGTH(slice);+  void* buf = upb_arena_malloc(arena, buf_size);+  memcpy(buf, reinterpret_cast<const char*>(GPR_SLICE_START_PTR(slice)),+         buf_size);+  grpc_gcp_HandshakerResp* resp = grpc_gcp_HandshakerResp_parse(","AFAIK, upb heavily depends on arena so any allocation happened by upb will be freed when upb::Arena goes out of scope. Mostly we don't need to worry about memory leak as long as arena is properly freed.",OK
24697473,Tony1023,https://api.github.com/repos/grpc/grpc/pulls/19855,311819968,2019-08-08T01:03:42Z,third_party/cares/cares.BUILD,"@@ -44,6 +44,36 @@ config_setting(     values = {""cpu"": ""ios_arm64""}, ) +config_setting(",These additional CPU's are found in https://github.com/bazelbuild/bazel/blob/master/src/main/java/com/google/devtools/build/lib/rules/apple/ApplePlatform.java,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/19748,311872441,2019-08-08T06:26:56Z,src/csharp/Grpc.Core/Internal/BinaryStringDictionary.cs,"@@ -0,0 +1,130 @@+#region Copyright notice and license++// Copyright 2015 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion++using System;+using System.Collections.Generic;+using System.Text;++using Grpc.Core.Utils;++namespace Grpc.Core.Internal+{+    /// <summary>+    /// Dictionary of string instances that can be looked up by their binary+    /// representation (ASCII encoded).+    /// </summary>+    internal class BinaryStringDictionary+    {+        static readonly Encoding EncodingACII = System.Text.Encoding.ASCII;+        Dictionary<BinaryKey, string> dict = new Dictionary<BinaryKey, string>();++        public BinaryStringDictionary()+        {+        }++        public void Add(string str)+        {+            dict.Add(new BinaryKey(EncodingACII.GetBytes(str)), str);+        }++        /// <summary>+        /// Looks up the string based on its ASCII-encoded binary form.+        /// </summary>+        public string Lookup(IntPtr nativeData, int nativeDataLen)+        {+            var key = new BinaryKey(nativeData, nativeDataLen);+            dict.TryGetValue(key, out string str);+            return str;+        }+        +        private struct BinaryKey : IEquatable<BinaryKey>+        {+            private byte[] data;+            private IntPtr nativeData;+            private int nativeDataLen;++            public BinaryKey(byte[] data)+            {+                this.data = GrpcPreconditions.CheckNotNull(data);+                this.nativeData = IntPtr.Zero;+                this.nativeDataLen = 0;+            }++            public BinaryKey(IntPtr nativeData, int nativeDataLen)+            {+                GrpcPreconditions.CheckArgument(nativeData != IntPtr.Zero);+                GrpcPreconditions.CheckArgument(nativeDataLen >= 0);+                this.data = null;+                this.nativeData = nativeData;+                this.nativeDataLen = nativeDataLen;+            }++            /// <summary>+            /// Indicates whether this instance and a specified object are equal.+            /// </summary>+            public override bool Equals(object obj)+            {+                return obj is BinaryKey && Equals((BinaryKey)obj);+            }++            /// <summary>+            /// Returns the hash code for this instance.+            /// </summary>+            public override int GetHashCode()+            {+                return ComputeHashCode(GetSpan());+            }++            /// <summary>+            /// Indicates whether this instance and a specified object are equal.+            /// </summary>+            public bool Equals(BinaryKey other)+            {+                return GetSpan().SequenceEqual(other.GetSpan());+            }++            private ReadOnlySpan<byte> GetSpan()","Possible simplification: instead of storing all of `data`, `nativeData`, and `nativeDataLen` in this `BinaryKey` object, and then generating new `ReadOnlySpan` objects from them, depending on which ones were provided in the constructor, what do you think about removing those fields and instead storing `ReadOnlySpan` objects in `BinaryKey`'s. We could then remove `GetSpan` and these `nullptr` conditionals and instead construct the right `ReadOnlySpan` objects just depending on which constructor is being called.",OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19885,311878643,2019-08-08T06:50:33Z,third_party/objective_c/google_toolbox_for_mac/UnitTesting/GTMGoogleTestRunner.mm,"@@ -0,0 +1,233 @@+//+//  GTMGoogleTestRunner.mm",This file is copied from https://github.com/google/google-toolbox-for-mac/blob/master/UnitTesting/GTMGoogleTestRunner.mm with 1 minor edit: gtest.h path was fixed,OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19885,311880857,2019-08-08T06:57:56Z,src/proto/grpc/testing/BUILD,"@@ -50,7 +50,6 @@ grpc_proto_library( grpc_proto_library(     name = ""echo_messages_proto"",     srcs = [""echo_messages.proto""],-    has_services = False,","`grpc_proto_library(has_services=False)` => `cc_grpc_library(proto_only = True)`.`proto_only=True` and the recommended replacement is something like this:```proto_library(name = ""echo_proto"", srcs = [""echo.proto"", ""echo_messages.proto"", ""simple_messages.proto""])cc_proto_library(name = ""echo_cc_proto"", deps = [""echo_proto""])cc_grpc_library(name = ""echo_cc_grpc"", srcs = [""echo_proto""], deps = [""echo_cc_proto""], grpc_only=True)```This works for with bazel in github, but it breaks internal builds because of bazel vs blaze compatibility issues.So I have worked around this by removing `has_services=False`. This results in `echo_messages.grpc.pb.*` getting generated, which is unnecessary but seems harmless.",OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19885,311881985,2019-08-08T07:01:40Z,third_party/objective_c/google_toolbox_for_mac/UnitTesting/GTMGoogleTestRunner.mm,"@@ -0,0 +1,233 @@+//+//  GTMGoogleTestRunner.mm","As noted in the comments below, this class is not compiled as part of the Google Toolbox For Mac project. As this is a standalone file in the project, I chose to just copy over this file instead of pulling in the entire Google Toolbox For Mac project which contains a lot more things that we don't need.",OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/19713,312104144,2019-08-08T15:36:07Z,src/core/lib/transport/metadata_batch.h,"@@ -104,6 +112,20 @@ grpc_error* grpc_metadata_batch_add_head(     grpc_metadata_batch* batch, grpc_linked_mdelem* storage,     grpc_mdelem elem_to_add) GRPC_MUST_USE_RESULT; +inline grpc_error* GRPC_MUST_USE_RESULT grpc_metadata_batch_add_head(+    grpc_metadata_batch* batch, grpc_linked_mdelem* storage,+    grpc_metadata_batch_callouts_index idx) {+  return grpc_metadata_batch_link_head(batch, storage, idx);","I might be missing something here, but why do we need this grpc_metadata_batch_add_head function when it seems to be identical to grpc_metadata_batch_link_head?",
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19713,312164207,2019-08-08T17:49:17Z,src/core/lib/transport/metadata_batch.cc,"@@ -163,17 +172,28 @@ grpc_error* grpc_metadata_batch_link_head(grpc_metadata_batch* batch,   return GRPC_ERROR_NONE; } +grpc_error* grpc_metadata_batch_link_head(","The main issue comes from the user being able to add whatever metadata they want - one possibility would be to see if user added metadata necessarily happens after we add our own metadata, and in that case we can have a method for them that does the check, and an internal method that does not.However, properly analyzing that will take some time and require review from @roth - so my thought is to put a TODO here for now.",OK
19913700,jiangtaoli2016,https://api.github.com/repos/grpc/grpc/pulls/19346,312335361,2019-08-09T05:41:45Z,src/core/lib/security/security_connector/ssl_utils.h,"@@ -149,9 +149,19 @@ class PemKeyCertPair {     return *this;   } -  // Not copyable.-  PemKeyCertPair(const PemKeyCertPair&) = delete;-  PemKeyCertPair& operator=(const PemKeyCertPair&) = delete;+  // Copyable.+  PemKeyCertPair(const PemKeyCertPair& other)+      : private_key_(gpr_strdup(other.private_key())),+        cert_chain_(gpr_strdup(other.cert_chain())) {}+  PemKeyCertPair& operator=(const PemKeyCertPair& other) {+    auto private_key =",why not set private_key_ directly?private_key_ = grpc_core::UniquePtr<char>(gpr_strdup(other.private_key()));Same for cert_chain_,OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19704,312338202,2019-08-09T05:58:18Z,src/objective-c/GRPCClient/GRPCInterceptor.m,"@@ -19,146 +19,276 @@ #import <Foundation/Foundation.h>  #import ""GRPCInterceptor.h""+#import ""private/GRPCTransport+Private.h""++@interface GRPCInterceptorManager ()<GRPCInterceptorInterface, GRPCResponseHandler>++@end  @implementation GRPCInterceptorManager {   id<GRPCInterceptorInterface> _nextInterceptor;   id<GRPCResponseHandler> _previousInterceptor;+  GRPCInterceptor *_thisInterceptor;+  dispatch_queue_t _dispatchQueue;+  NSArray<id<GRPCInterceptorFactory>> *_factories;+  GRPCTransportId _transportId;+  BOOL _shutDown; } -- (instancetype)initWithNextInterceptor:(id<GRPCInterceptorInterface>)nextInterceptor {+- (instancetype)initWithFactories:(NSArray<id<GRPCInterceptorFactory>> *)factories+              previousInterceptor:(id<GRPCResponseHandler>)previousInterceptor+                      transportId:(nonnull GRPCTransportId)transportId {   if ((self = [super init])) {-    _nextInterceptor = nextInterceptor;+    if (factories.count == 0) {+      [NSException raise:NSInternalInconsistencyException+                  format:@""Interceptor manager must have factories""];+    }+    _thisInterceptor = [factories[0] createInterceptorWithManager:self];+    if (_thisInterceptor == nil) {+      return nil;+    }+    _previousInterceptor = previousInterceptor;+    _factories = factories;+    // Generate interceptor+#if __IPHONE_OS_VERSION_MAX_ALLOWED >= 110000 || __MAC_OS_X_VERSION_MAX_ALLOWED >= 101300+    if (@available(iOS 8.0, macOS 10.10, *)) {+      _dispatchQueue = dispatch_queue_create(+          NULL,+          dispatch_queue_attr_make_with_qos_class(DISPATCH_QUEUE_SERIAL, QOS_CLASS_DEFAULT, 0));+    } else {+#else+    {+#endif+      _dispatchQueue = dispatch_queue_create(NULL, DISPATCH_QUEUE_SERIAL);+    }+    dispatch_set_target_queue(_dispatchQueue, _thisInterceptor.dispatchQueue);+    _transportId = transportId;   }-   return self; } -- (void)setPreviousInterceptor:(id<GRPCResponseHandler>)previousInterceptor {-  _previousInterceptor = previousInterceptor;-}- - (void)shutDown {   _nextInterceptor = nil;   _previousInterceptor = nil;+  _thisInterceptor = nil;+  _shutDown = YES;+}++- (void)createNextInterceptor {+  NSAssert(_nextInterceptor == nil, @""Starting the next interceptor more than once"");+  NSAssert(_factories.count > 0, @""Interceptor manager of transport cannot start next interceptor"");+  if (_nextInterceptor != nil) {+    NSLog(@""Starting the next interceptor more than once"");+    return;+  }+  NSMutableArray<id<GRPCInterceptorFactory>> *interceptorFactories = [NSMutableArray+      arrayWithArray:[_factories subarrayWithRange:NSMakeRange(1, _factories.count - 1)]];+  while (_nextInterceptor == nil) {+    if (interceptorFactories.count == 0) {+      _nextInterceptor =+          [[GRPCTransportManager alloc] initWithTransportId:_transportId previousInterceptor:self];+      break;+    } else {+      _nextInterceptor = [[GRPCInterceptorManager alloc] initWithFactories:interceptorFactories+                                                       previousInterceptor:self+                                                               transportId:_transportId];+      if (_nextInterceptor == nil) {+        [interceptorFactories removeObjectAtIndex:0];+      }+    }+  }+  NSAssert(_nextInterceptor != nil, @""Failed to create interceptor or transport."");+  if (_nextInterceptor == nil) {+    NSLog(@""Failed to create interceptor or transport."");+  } }  - (void)startNextInterceptorWithRequest:(GRPCRequestOptions *)requestOptions                             callOptions:(GRPCCallOptions *)callOptions {-  if (_nextInterceptor != nil) {-    id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;-    dispatch_async(copiedNextInterceptor.requestDispatchQueue, ^{-      [copiedNextInterceptor startWithRequestOptions:requestOptions callOptions:callOptions];-    });+  if (_nextInterceptor == nil && !_shutDown) {+    [self createNextInterceptor];+  }+  if (_nextInterceptor == nil) {+    return;   }+  id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;+  dispatch_async(copiedNextInterceptor.dispatchQueue, ^{+    [copiedNextInterceptor startWithRequestOptions:requestOptions callOptions:callOptions];+  }); }  - (void)writeNextInterceptorWithData:(id)data {-  if (_nextInterceptor != nil) {-    id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;-    dispatch_async(copiedNextInterceptor.requestDispatchQueue, ^{-      [copiedNextInterceptor writeData:data];-    });+  if (_nextInterceptor == nil && !_shutDown) {+    [self createNextInterceptor];   }+  if (_nextInterceptor == nil) {+    return;+  }+  id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;+  dispatch_async(copiedNextInterceptor.dispatchQueue, ^{+    [copiedNextInterceptor writeData:data];+  }); }  - (void)finishNextInterceptor {-  if (_nextInterceptor != nil) {-    id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;-    dispatch_async(copiedNextInterceptor.requestDispatchQueue, ^{-      [copiedNextInterceptor finish];-    });+  if (_nextInterceptor == nil && !_shutDown) {+    [self createNextInterceptor];   }+  if (_nextInterceptor == nil) {+    return;+  }+  id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;+  dispatch_async(copiedNextInterceptor.dispatchQueue, ^{+    [copiedNextInterceptor finish];+  }); }  - (void)cancelNextInterceptor {-  if (_nextInterceptor != nil) {-    id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;-    dispatch_async(copiedNextInterceptor.requestDispatchQueue, ^{-      [copiedNextInterceptor cancel];-    });+  if (_nextInterceptor == nil && !_shutDown) {+    [self createNextInterceptor];   }+  if (_nextInterceptor == nil) {+    return;+  }+  id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;+  dispatch_async(copiedNextInterceptor.dispatchQueue, ^{+    [copiedNextInterceptor cancel];+  }); }  /** Notify the next interceptor in the chain to receive more messages */ - (void)receiveNextInterceptorMessages:(NSUInteger)numberOfMessages {-  if (_nextInterceptor != nil) {-    id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;-    dispatch_async(copiedNextInterceptor.requestDispatchQueue, ^{-      [copiedNextInterceptor receiveNextMessages:numberOfMessages];-    });+  if (_nextInterceptor == nil && !_shutDown) {+    [self createNextInterceptor];+  }+  if (_nextInterceptor == nil) {+    return;   }+  id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;+  dispatch_async(copiedNextInterceptor.dispatchQueue, ^{+    [copiedNextInterceptor receiveNextMessages:numberOfMessages];+  }); }  // Methods to forward GRPCResponseHandler callbacks to the previous object  /** Forward initial metadata to the previous interceptor in the chain */-- (void)forwardPreviousInterceptorWithInitialMetadata:(nullable NSDictionary *)initialMetadata {-  if ([_previousInterceptor respondsToSelector:@selector(didReceiveInitialMetadata:)]) {-    id<GRPCResponseHandler> copiedPreviousInterceptor = _previousInterceptor;-    dispatch_async(copiedPreviousInterceptor.dispatchQueue, ^{-      [copiedPreviousInterceptor didReceiveInitialMetadata:initialMetadata];-    });+- (void)forwardPreviousInterceptorWithInitialMetadata:(NSDictionary *)initialMetadata {+  if (_nextInterceptor == nil && !_shutDown) {+    [self createNextInterceptor];   }+  if (_nextInterceptor == nil) {",why are we looking at `_nexstInterceptor` here? Shouldn't we be checking that `_previousInterceptor != nil` similar to forwardPreviousInterceptor* methods below?,
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19704,312611018,2019-08-09T19:00:17Z,src/objective-c/GRPCClient/private/GRPCCore/GRPCChannel.m,"@@ -50,32 +51,48 @@ - (instancetype)initWithHost:(NSString *)host callOptions:(GRPCCallOptions *)cal }  - (id<GRPCChannelFactory>)channelFactory {-  GRPCTransportType type = _callOptions.transportType;-  switch (type) {-    case GRPCTransportTypeChttp2BoringSSL:-      // TODO (mxyan): Remove when the API is deprecated-#ifdef GRPC_COMPILE_WITH_CRONET-      if (![GRPCCall isUsingCronet]) {-#else-    {-#endif-        NSError *error;-        id<GRPCChannelFactory> factory = [GRPCSecureChannelFactory-            factoryWithPEMRootCertificates:_callOptions.PEMRootCertificates-                                privateKey:_callOptions.PEMPrivateKey-                                 certChain:_callOptions.PEMCertificateChain-                                     error:&error];-        NSAssert(factory != nil, @""Failed to create secure channel factory"");-        if (factory == nil) {-          NSLog(@""Error creating secure channel factory: %@"", error);+  if (_callOptions.transport != NULL) {+    id<GRPCTransportFactory> transportFactory =+        [[GRPCTransportRegistry sharedInstance] getTransportFactoryWithId:_callOptions.transport];+    if (!+        [transportFactory respondsToSelector:@selector(createCoreChannelFactoryWithCallOptions:)]) {+      // impossible because we are using GRPCCore now+      [NSException raise:NSInternalInconsistencyException+                  format:@""Transport factory type is wrong""];+    }+    id<GRPCCoreTransportFactory> coreTransportFactory =+        (id<GRPCCoreTransportFactory>)transportFactory;+    return [coreTransportFactory createCoreChannelFactoryWithCallOptions:_callOptions];+  } else {+    // To maintain backwards compatibility with tranportType+    GRPCTransportType type = _callOptions.transportType;+    switch (type) {+      case GRPCTransportTypeChttp2BoringSSL:+        // TODO (mxyan): Remove when the API is deprecated+        {+          NSError *error;+          id<GRPCChannelFactory> factory = [GRPCSecureChannelFactory+              factoryWithPEMRootCertificates:_callOptions.PEMRootCertificates+                                  privateKey:_callOptions.PEMPrivateKey+                                   certChain:_callOptions.PEMCertificateChain+                                       error:&error];+          NSAssert(factory != nil, @""Failed to create secure channel factory"");+          if (factory == nil) {+            NSLog(@""Error creating secure channel factory: %@"", error);+          }+          return factory;         }-        return factory;+      case GRPCTransportTypeCronet: {+        id<GRPCCoreTransportFactory> transportFactory = (id<GRPCCoreTransportFactory>)[","Because secure and insecure transports are the default ones when Core is included.If this method is executed, `GRPCChannel.m` exists in the process, hence secure and insecure transports are for sure registered. But Cronet might not be included as a dependency of this process. So we have to query the registry in this case.",OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19704,312658545,2019-08-09T21:49:42Z,src/objective-c/GRPCClient/GRPCInterceptor.m,"@@ -19,146 +19,276 @@ #import <Foundation/Foundation.h>  #import ""GRPCInterceptor.h""+#import ""private/GRPCTransport+Private.h""++@interface GRPCInterceptorManager ()<GRPCInterceptorInterface, GRPCResponseHandler>++@end  @implementation GRPCInterceptorManager {   id<GRPCInterceptorInterface> _nextInterceptor;   id<GRPCResponseHandler> _previousInterceptor;+  GRPCInterceptor *_thisInterceptor;+  dispatch_queue_t _dispatchQueue;+  NSArray<id<GRPCInterceptorFactory>> *_factories;+  GRPCTransportId _transportId;+  BOOL _shutDown; } -- (instancetype)initWithNextInterceptor:(id<GRPCInterceptorInterface>)nextInterceptor {+- (instancetype)initWithFactories:(NSArray<id<GRPCInterceptorFactory>> *)factories+              previousInterceptor:(id<GRPCResponseHandler>)previousInterceptor+                      transportId:(nonnull GRPCTransportId)transportId {   if ((self = [super init])) {-    _nextInterceptor = nextInterceptor;+    if (factories.count == 0) {+      [NSException raise:NSInternalInconsistencyException+                  format:@""Interceptor manager must have factories""];+    }+    _thisInterceptor = [factories[0] createInterceptorWithManager:self];+    if (_thisInterceptor == nil) {+      return nil;+    }+    _previousInterceptor = previousInterceptor;+    _factories = factories;+    // Generate interceptor+#if __IPHONE_OS_VERSION_MAX_ALLOWED >= 110000 || __MAC_OS_X_VERSION_MAX_ALLOWED >= 101300+    if (@available(iOS 8.0, macOS 10.10, *)) {+      _dispatchQueue = dispatch_queue_create(+          NULL,+          dispatch_queue_attr_make_with_qos_class(DISPATCH_QUEUE_SERIAL, QOS_CLASS_DEFAULT, 0));+    } else {+#else+    {+#endif+      _dispatchQueue = dispatch_queue_create(NULL, DISPATCH_QUEUE_SERIAL);+    }+    dispatch_set_target_queue(_dispatchQueue, _thisInterceptor.dispatchQueue);+    _transportId = transportId;   }-   return self; } -- (void)setPreviousInterceptor:(id<GRPCResponseHandler>)previousInterceptor {-  _previousInterceptor = previousInterceptor;-}- - (void)shutDown {   _nextInterceptor = nil;   _previousInterceptor = nil;+  _thisInterceptor = nil;+  _shutDown = YES;+}++- (void)createNextInterceptor {+  NSAssert(_nextInterceptor == nil, @""Starting the next interceptor more than once"");+  NSAssert(_factories.count > 0, @""Interceptor manager of transport cannot start next interceptor"");+  if (_nextInterceptor != nil) {+    NSLog(@""Starting the next interceptor more than once"");+    return;+  }+  NSMutableArray<id<GRPCInterceptorFactory>> *interceptorFactories = [NSMutableArray+      arrayWithArray:[_factories subarrayWithRange:NSMakeRange(1, _factories.count - 1)]];+  while (_nextInterceptor == nil) {+    if (interceptorFactories.count == 0) {+      _nextInterceptor =+          [[GRPCTransportManager alloc] initWithTransportId:_transportId previousInterceptor:self];+      break;+    } else {+      _nextInterceptor = [[GRPCInterceptorManager alloc] initWithFactories:interceptorFactories+                                                       previousInterceptor:self+                                                               transportId:_transportId];+      if (_nextInterceptor == nil) {+        [interceptorFactories removeObjectAtIndex:0];+      }+    }+  }+  NSAssert(_nextInterceptor != nil, @""Failed to create interceptor or transport."");+  if (_nextInterceptor == nil) {+    NSLog(@""Failed to create interceptor or transport."");+  } }  - (void)startNextInterceptorWithRequest:(GRPCRequestOptions *)requestOptions                             callOptions:(GRPCCallOptions *)callOptions {-  if (_nextInterceptor != nil) {-    id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;-    dispatch_async(copiedNextInterceptor.requestDispatchQueue, ^{-      [copiedNextInterceptor startWithRequestOptions:requestOptions callOptions:callOptions];-    });+  if (_nextInterceptor == nil && !_shutDown) {+    [self createNextInterceptor];+  }+  if (_nextInterceptor == nil) {+    return;   }+  id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;+  dispatch_async(copiedNextInterceptor.dispatchQueue, ^{+    [copiedNextInterceptor startWithRequestOptions:requestOptions callOptions:callOptions];+  }); }  - (void)writeNextInterceptorWithData:(id)data {-  if (_nextInterceptor != nil) {-    id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;-    dispatch_async(copiedNextInterceptor.requestDispatchQueue, ^{-      [copiedNextInterceptor writeData:data];-    });+  if (_nextInterceptor == nil && !_shutDown) {+    [self createNextInterceptor];   }+  if (_nextInterceptor == nil) {+    return;+  }+  id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;+  dispatch_async(copiedNextInterceptor.dispatchQueue, ^{+    [copiedNextInterceptor writeData:data];+  }); }  - (void)finishNextInterceptor {-  if (_nextInterceptor != nil) {-    id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;-    dispatch_async(copiedNextInterceptor.requestDispatchQueue, ^{-      [copiedNextInterceptor finish];-    });+  if (_nextInterceptor == nil && !_shutDown) {+    [self createNextInterceptor];   }+  if (_nextInterceptor == nil) {+    return;+  }+  id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;+  dispatch_async(copiedNextInterceptor.dispatchQueue, ^{+    [copiedNextInterceptor finish];+  }); }  - (void)cancelNextInterceptor {-  if (_nextInterceptor != nil) {-    id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;-    dispatch_async(copiedNextInterceptor.requestDispatchQueue, ^{-      [copiedNextInterceptor cancel];-    });+  if (_nextInterceptor == nil && !_shutDown) {+    [self createNextInterceptor];   }+  if (_nextInterceptor == nil) {+    return;+  }+  id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;+  dispatch_async(copiedNextInterceptor.dispatchQueue, ^{+    [copiedNextInterceptor cancel];+  }); }  /** Notify the next interceptor in the chain to receive more messages */ - (void)receiveNextInterceptorMessages:(NSUInteger)numberOfMessages {-  if (_nextInterceptor != nil) {-    id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;-    dispatch_async(copiedNextInterceptor.requestDispatchQueue, ^{-      [copiedNextInterceptor receiveNextMessages:numberOfMessages];-    });+  if (_nextInterceptor == nil && !_shutDown) {+    [self createNextInterceptor];+  }+  if (_nextInterceptor == nil) {+    return;   }+  id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;+  dispatch_async(copiedNextInterceptor.dispatchQueue, ^{+    [copiedNextInterceptor receiveNextMessages:numberOfMessages];+  }); }  // Methods to forward GRPCResponseHandler callbacks to the previous object  /** Forward initial metadata to the previous interceptor in the chain */-- (void)forwardPreviousInterceptorWithInitialMetadata:(nullable NSDictionary *)initialMetadata {-  if ([_previousInterceptor respondsToSelector:@selector(didReceiveInitialMetadata:)]) {-    id<GRPCResponseHandler> copiedPreviousInterceptor = _previousInterceptor;-    dispatch_async(copiedPreviousInterceptor.dispatchQueue, ^{-      [copiedPreviousInterceptor didReceiveInitialMetadata:initialMetadata];-    });+- (void)forwardPreviousInterceptorWithInitialMetadata:(NSDictionary *)initialMetadata {+  if (_nextInterceptor == nil && !_shutDown) {+    [self createNextInterceptor];   }+  if (_nextInterceptor == nil) {+    return;+  }+  id<GRPCResponseHandler> copiedPreviousInterceptor = _previousInterceptor;+  dispatch_async(copiedPreviousInterceptor.dispatchQueue, ^{+    [copiedPreviousInterceptor didReceiveInitialMetadata:initialMetadata];+  }); }  /** Forward a received message to the previous interceptor in the chain */ - (void)forwardPreviousInterceptorWithData:(id)data {-  if ([_previousInterceptor respondsToSelector:@selector(didReceiveData:)]) {-    id<GRPCResponseHandler> copiedPreviousInterceptor = _previousInterceptor;-    dispatch_async(copiedPreviousInterceptor.dispatchQueue, ^{-      [copiedPreviousInterceptor didReceiveData:data];-    });+  if (_previousInterceptor == nil) {","Here an in other places in this class, can we assert that `_previousInterceptor != nil`, or atleast log an error? If we just return then we're silently dropping messages.",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19704,312673127,2019-08-09T23:10:14Z,src/objective-c/GRPCClient/GRPCInterceptor.m,"@@ -19,146 +19,276 @@ #import <Foundation/Foundation.h>  #import ""GRPCInterceptor.h""+#import ""private/GRPCTransport+Private.h""++@interface GRPCInterceptorManager ()<GRPCInterceptorInterface, GRPCResponseHandler>++@end  @implementation GRPCInterceptorManager {   id<GRPCInterceptorInterface> _nextInterceptor;   id<GRPCResponseHandler> _previousInterceptor;+  GRPCInterceptor *_thisInterceptor;+  dispatch_queue_t _dispatchQueue;+  NSArray<id<GRPCInterceptorFactory>> *_factories;+  GRPCTransportId _transportId;+  BOOL _shutDown; } -- (instancetype)initWithNextInterceptor:(id<GRPCInterceptorInterface>)nextInterceptor {+- (instancetype)initWithFactories:(NSArray<id<GRPCInterceptorFactory>> *)factories+              previousInterceptor:(id<GRPCResponseHandler>)previousInterceptor+                      transportId:(nonnull GRPCTransportId)transportId {   if ((self = [super init])) {-    _nextInterceptor = nextInterceptor;+    if (factories.count == 0) {+      [NSException raise:NSInternalInconsistencyException+                  format:@""Interceptor manager must have factories""];+    }+    _thisInterceptor = [factories[0] createInterceptorWithManager:self];+    if (_thisInterceptor == nil) {+      return nil;+    }+    _previousInterceptor = previousInterceptor;+    _factories = factories;+    // Generate interceptor+#if __IPHONE_OS_VERSION_MAX_ALLOWED >= 110000 || __MAC_OS_X_VERSION_MAX_ALLOWED >= 101300+    if (@available(iOS 8.0, macOS 10.10, *)) {+      _dispatchQueue = dispatch_queue_create(+          NULL,+          dispatch_queue_attr_make_with_qos_class(DISPATCH_QUEUE_SERIAL, QOS_CLASS_DEFAULT, 0));+    } else {+#else+    {+#endif+      _dispatchQueue = dispatch_queue_create(NULL, DISPATCH_QUEUE_SERIAL);+    }+    dispatch_set_target_queue(_dispatchQueue, _thisInterceptor.dispatchQueue);+    _transportId = transportId;   }-   return self; } -- (void)setPreviousInterceptor:(id<GRPCResponseHandler>)previousInterceptor {-  _previousInterceptor = previousInterceptor;-}- - (void)shutDown {   _nextInterceptor = nil;   _previousInterceptor = nil;+  _thisInterceptor = nil;+  _shutDown = YES;+}++- (void)createNextInterceptor {+  NSAssert(_nextInterceptor == nil, @""Starting the next interceptor more than once"");+  NSAssert(_factories.count > 0, @""Interceptor manager of transport cannot start next interceptor"");+  if (_nextInterceptor != nil) {+    NSLog(@""Starting the next interceptor more than once"");+    return;+  }+  NSMutableArray<id<GRPCInterceptorFactory>> *interceptorFactories = [NSMutableArray+      arrayWithArray:[_factories subarrayWithRange:NSMakeRange(1, _factories.count - 1)]];+  while (_nextInterceptor == nil) {+    if (interceptorFactories.count == 0) {+      _nextInterceptor =+          [[GRPCTransportManager alloc] initWithTransportId:_transportId previousInterceptor:self];+      break;+    } else {+      _nextInterceptor = [[GRPCInterceptorManager alloc] initWithFactories:interceptorFactories+                                                       previousInterceptor:self+                                                               transportId:_transportId];+      if (_nextInterceptor == nil) {+        [interceptorFactories removeObjectAtIndex:0];+      }+    }+  }+  NSAssert(_nextInterceptor != nil, @""Failed to create interceptor or transport."");+  if (_nextInterceptor == nil) {+    NSLog(@""Failed to create interceptor or transport."");+  } }  - (void)startNextInterceptorWithRequest:(GRPCRequestOptions *)requestOptions                             callOptions:(GRPCCallOptions *)callOptions {-  if (_nextInterceptor != nil) {-    id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;-    dispatch_async(copiedNextInterceptor.requestDispatchQueue, ^{-      [copiedNextInterceptor startWithRequestOptions:requestOptions callOptions:callOptions];-    });+  if (_nextInterceptor == nil && !_shutDown) {+    [self createNextInterceptor];+  }+  if (_nextInterceptor == nil) {+    return;   }+  id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;+  dispatch_async(copiedNextInterceptor.dispatchQueue, ^{+    [copiedNextInterceptor startWithRequestOptions:requestOptions callOptions:callOptions];+  }); }  - (void)writeNextInterceptorWithData:(id)data {-  if (_nextInterceptor != nil) {-    id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;-    dispatch_async(copiedNextInterceptor.requestDispatchQueue, ^{-      [copiedNextInterceptor writeData:data];-    });+  if (_nextInterceptor == nil && !_shutDown) {+    [self createNextInterceptor];   }+  if (_nextInterceptor == nil) {+    return;+  }+  id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;+  dispatch_async(copiedNextInterceptor.dispatchQueue, ^{+    [copiedNextInterceptor writeData:data];+  }); }  - (void)finishNextInterceptor {-  if (_nextInterceptor != nil) {-    id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;-    dispatch_async(copiedNextInterceptor.requestDispatchQueue, ^{-      [copiedNextInterceptor finish];-    });+  if (_nextInterceptor == nil && !_shutDown) {+    [self createNextInterceptor];   }+  if (_nextInterceptor == nil) {+    return;+  }+  id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;+  dispatch_async(copiedNextInterceptor.dispatchQueue, ^{+    [copiedNextInterceptor finish];+  }); }  - (void)cancelNextInterceptor {-  if (_nextInterceptor != nil) {-    id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;-    dispatch_async(copiedNextInterceptor.requestDispatchQueue, ^{-      [copiedNextInterceptor cancel];-    });+  if (_nextInterceptor == nil && !_shutDown) {+    [self createNextInterceptor];   }+  if (_nextInterceptor == nil) {+    return;+  }+  id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;+  dispatch_async(copiedNextInterceptor.dispatchQueue, ^{+    [copiedNextInterceptor cancel];+  }); }  /** Notify the next interceptor in the chain to receive more messages */ - (void)receiveNextInterceptorMessages:(NSUInteger)numberOfMessages {-  if (_nextInterceptor != nil) {-    id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;-    dispatch_async(copiedNextInterceptor.requestDispatchQueue, ^{-      [copiedNextInterceptor receiveNextMessages:numberOfMessages];-    });+  if (_nextInterceptor == nil && !_shutDown) {+    [self createNextInterceptor];+  }+  if (_nextInterceptor == nil) {+    return;   }+  id<GRPCInterceptorInterface> copiedNextInterceptor = _nextInterceptor;+  dispatch_async(copiedNextInterceptor.dispatchQueue, ^{+    [copiedNextInterceptor receiveNextMessages:numberOfMessages];+  }); }  // Methods to forward GRPCResponseHandler callbacks to the previous object  /** Forward initial metadata to the previous interceptor in the chain */-- (void)forwardPreviousInterceptorWithInitialMetadata:(nullable NSDictionary *)initialMetadata {-  if ([_previousInterceptor respondsToSelector:@selector(didReceiveInitialMetadata:)]) {-    id<GRPCResponseHandler> copiedPreviousInterceptor = _previousInterceptor;-    dispatch_async(copiedPreviousInterceptor.dispatchQueue, ^{-      [copiedPreviousInterceptor didReceiveInitialMetadata:initialMetadata];-    });+- (void)forwardPreviousInterceptorWithInitialMetadata:(NSDictionary *)initialMetadata {+  if (_nextInterceptor == nil && !_shutDown) {+    [self createNextInterceptor];   }+  if (_nextInterceptor == nil) {+    return;+  }+  id<GRPCResponseHandler> copiedPreviousInterceptor = _previousInterceptor;+  dispatch_async(copiedPreviousInterceptor.dispatchQueue, ^{+    [copiedPreviousInterceptor didReceiveInitialMetadata:initialMetadata];+  }); }  /** Forward a received message to the previous interceptor in the chain */ - (void)forwardPreviousInterceptorWithData:(id)data {-  if ([_previousInterceptor respondsToSelector:@selector(didReceiveData:)]) {-    id<GRPCResponseHandler> copiedPreviousInterceptor = _previousInterceptor;-    dispatch_async(copiedPreviousInterceptor.dispatchQueue, ^{-      [copiedPreviousInterceptor didReceiveData:data];-    });+  if (_previousInterceptor == nil) {","It could happen that a message is forwarded after `_previousInterceptor` becomes nil. For example, if an interceptor gets a cancel request, while at the same time gets a response data, and the cancel won the race, the response should be dropped silently without an error message.",
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19704,313089067,2019-08-12T19:25:31Z,src/objective-c/GRPCClient/private/GRPCCore/GRPCHost.m,"@@ -21,17 +21,16 @@ #import <GRPCClient/GRPCCall+Cronet.h>",This adds a cronet dependency - is that ok?,OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19704,313100102,2019-08-12T19:54:42Z,src/objective-c/GRPCClient/private/GRPCCore/GRPCHost.m,"@@ -21,17 +21,16 @@ #import <GRPCClient/GRPCCall+Cronet.h>",This is ok. `GRPCCall+Cronet.h` is not dependency to Cronet. It's internal things related to Cronet.,OK
52979934,matthewstevenson88,https://api.github.com/repos/grpc/grpc/pulls/19778,313167392,2019-08-12T23:19:10Z,include/grpcpp/security/tls_credentials_options.h,"@@ -0,0 +1,281 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPCPP_SECURITY_TLS_CREDENTIALS_OPTIONS_H+#define GRPCPP_SECURITY_TLS_CREDENTIALS_OPTIONS_H++#include <functional>+#include <memory>+#include <vector>++#include <grpc/grpc_security.h>+#include <grpc/support/log.h>+#include <grpcpp/support/config.h>++namespace grpc_impl {+namespace experimental {++/** TLS key materials config, wrapper for grpc_tls_key_materials_config. **/+class TlsKeyMaterialsConfig {+ public:+  struct PemKeyCertPair {+    ::grpc::string private_key;+    ::grpc::string cert_chain;+  };++  /** Getters for member fields. **/+  const ::grpc::string pem_root_certs() const { return pem_root_certs_; }+  const ::std::vector<PemKeyCertPair>& pem_key_cert_pair_list() const {+    return pem_key_cert_pair_list_;+  }++  /**Setter for member fields. **/+  void set_key_materials(::grpc::string pem_root_certs,+                         ::std::vector<PemKeyCertPair> pem_key_cert_pair_list);++  /** Creates C struct for key materials. **/+  grpc_tls_key_materials_config* c_key_materials() const;","It is an internal function. I could e.g. make it a private member function instead, and then make `TlsKeyMaterialsConfig` into a friend class of both `TlsCredentialReloadArg` and `TlsCredentialsOptions`. (Note that `c_key_materials` is called by the implementations of `c_credential_reload_arg` and `c_credentials_options`.)",
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/19907,313199644,2019-08-13T02:29:57Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -3684,7 +3684,8 @@ void CallData::ApplyServiceConfigToCallLocked(grpc_call_element* elem) {     // from the client API, reset the deadline timer.     if (chand->deadline_checking_enabled() && method_params_->timeout() != 0) {       const grpc_millis per_method_deadline =-          grpc_timespec_to_millis_round_up(call_start_time_) ++          grpc_timespec_to_millis_round_up(","Good point Arjun, and I agree this is no optimal.  That said, unfortunately, the problem is that `grpc_timespec_to_millis*` is based on IOMGR's `g_start_time` as its origin, and `gpr_cycle_counter` is based on clock precise's `start_cycle` or `CLOCK_REAL`. We will have to convert `CLOCK_PRECISE` to `CLOCK_MONOTONIC` to calculate the time span and then calculate the absolute deadline in `grpc_millis`.  Since we don't have access to `g_start_time` and we cannot make assumption about its clock type, we had to convert the cycles to time :-/Since this only impacts services with `ServiceConfig`, do you mind if we deal with it later if it became a bottleneck?",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19855,313204006,2019-08-13T03:02:00Z,src/objective-c/examples/BUILD,"@@ -15,55 +15,154 @@ # limitations under the License.  +load(""//src/objective-c:grpc_objc_internal_library.bzl"", ""local_objc_grpc_library"") load(""@build_bazel_rules_apple//apple:ios.bzl"", ""ios_application"")-load(-    ""@com_github_grpc_grpc//bazel:objc_grpc_library.bzl"",-    ""objc_grpc_library"",-)+load(""@build_bazel_rules_apple//apple:tvos.bzl"", ""tvos_application"")+load(""@build_bazel_rules_apple//apple:watchos.bzl"", ""watchos_application"", ""watchos_extension"")  proto_library(     name = ""messages_proto"",-    srcs = [""BazelBuildSamples/messages.proto""],-    visibility = [""//visibility:public""],+    srcs = [""RemoteTestClient/messages.proto""],+)++proto_library(+    name = ""test_proto"",+    srcs = [""RemoteTestClient/test.proto""],+    deps = ["":messages_proto""], ) -objc_grpc_library(+# use objc_grpc_library in bazel:objc_grpc_library.bzl when developing outside the repo+local_objc_grpc_library(","What is the benefit of implementing ""local"" as another rule rather than a parameter?",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19855,313204528,2019-08-13T03:05:51Z,src/objective-c/examples/BUILD,"@@ -15,55 +15,154 @@ # limitations under the License.  +load(""//src/objective-c:grpc_objc_internal_library.bzl"", ""local_objc_grpc_library"") load(""@build_bazel_rules_apple//apple:ios.bzl"", ""ios_application"")-load(-    ""@com_github_grpc_grpc//bazel:objc_grpc_library.bzl"",-    ""objc_grpc_library"",-)+load(""@build_bazel_rules_apple//apple:tvos.bzl"", ""tvos_application"")+load(""@build_bazel_rules_apple//apple:watchos.bzl"", ""watchos_application"", ""watchos_extension"")  proto_library(     name = ""messages_proto"",-    srcs = [""BazelBuildSamples/messages.proto""],-    visibility = [""//visibility:public""],+    srcs = [""RemoteTestClient/messages.proto""],+)++proto_library(+    name = ""test_proto"",+    srcs = [""RemoteTestClient/test.proto""],+    deps = ["":messages_proto""], ) -objc_grpc_library(+# use objc_grpc_library in bazel:objc_grpc_library.bzl when developing outside the repo+local_objc_grpc_library(     name = ""test_grpc_objc"",-    srcs = [""BazelBuildSamples/rmt/test.proto""],+    srcs = [""RemoteTestClient/test.proto""],     use_well_known_protos = True,     deps = [-        ""//src/objective-c/examples/BazelBuildSamples/rmt:test_proto"",+        ""//src/objective-c/examples:test_proto"",     ], )  # Proof that without this works without srcs-objc_grpc_library(+local_objc_grpc_library(     name = ""test_objc"",     use_well_known_protos = True,     deps = [-        ""//src/objective-c/examples/BazelBuildSamples/rmt:test_proto"",-    ]+        ""//src/objective-c/examples:test_proto"",+    ], )  objc_library(-    name = ""ios-sample-lib"",-    srcs = glob([""BazelBuildSamples/ios-sample/ios-sample/**/*.m""]),-    hdrs = glob([""BazelBuildSamples/ios-sample/ios-sample/**/*.h""]),+    name = ""Sample-lib"",+    srcs = glob([""Sample/Sample/**/*.m""]),+    hdrs = glob([""Sample/Sample/**/*.h""]),     data = glob([-        ""BazelBuildSamples/ios-sample/ios-sample/Assets.xcassets/**/*"",-        ""BazelBuildSamples/ios-sample/ios-sample/Base.lproj/**/*""+        ""Sample/Sample/Base.lproj/**"",+        ""Sample/Sample/Images.xcassets/**"",     ]),-    deps = [-        "":test_grpc_objc"",-    ]+    deps = ["":test_grpc_objc""], )  ios_application(-    name = ""ios-sample"",-    bundle_id = ""com.google.ios-sample-objc-bazel"",-    families = [""iphone""],-    minimum_os_version = ""9.0"",-    infoplists = [""BazelBuildSamples/ios-sample/ios-sample/Info.plist""],+    name = ""Sample"",+    bundle_id = ""grpc.objc.examples.Sample"",+    minimum_os_version = ""8.0"",+    infoplists = [""Sample/Sample/Info.plist""],+    families = [+        ""iphone"",+        ""ipad"",+    ],+    deps = [""Sample-lib""],     visibility = [""//visibility:public""],-    deps = ["":ios-sample-lib""],-)\ No newline at end of file+)++objc_library(+    name = ""InterceptorSample-lib"",+    srcs = glob([""InterceptorSample/InterceptorSample/**/*.m""]),+    hdrs = glob([""InterceptorSample/InterceptorSample/**/*.h""]),+    data = glob([+        ""InterceptorSample/InterceptorSample/Base.lproj/**"",",How are the `data` section used? Does ios_application recognize the `data` section?,
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19855,313206306,2019-08-13T03:18:41Z,src/objective-c/grpc_objc_internal_library.bzl,"@@ -0,0 +1,174 @@+# Copyright 2019 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++#+# This is for the gRPC build system. This isn't intended to be used outsite of+# the BUILD file for gRPC. It contains the mapping for the template system we+# use to generate other platform's build system files.+#+# Please consider that there should be a high bar for additions and changes to+# this file.+# Each rule listed must be re-written for Google's internal build system, and+# each change must be ported from one to the other.+#++load(+    ""//bazel:generate_objc.bzl"",+    ""generate_objc"",+    ""generate_objc_hdrs"",+    ""generate_objc_srcs"",+    ""generate_objc_non_arc_srcs""+)+load(""//bazel:protobuf.bzl"", ""well_known_proto_libs"")++def grpc_objc_testing_library(",Consider merging into `grpc_objc_library` with a parameter?,
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19855,313206358,2019-08-13T03:19:02Z,src/objective-c/grpc_objc_internal_library.bzl,"@@ -0,0 +1,174 @@+# Copyright 2019 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++#+# This is for the gRPC build system. This isn't intended to be used outsite of+# the BUILD file for gRPC. It contains the mapping for the template system we+# use to generate other platform's build system files.+#+# Please consider that there should be a high bar for additions and changes to+# this file.+# Each rule listed must be re-written for Google's internal build system, and+# each change must be ported from one to the other.+#++load(+    ""//bazel:generate_objc.bzl"",+    ""generate_objc"",+    ""generate_objc_hdrs"",+    ""generate_objc_srcs"",+    ""generate_objc_non_arc_srcs""+)+load(""//bazel:protobuf.bzl"", ""well_known_proto_libs"")++def grpc_objc_testing_library(+        name,+        srcs = [],+        hdrs = [],+        textual_hdrs = [],+        data = [],+        deps = [],+        defines = [],+        includes = []):+    """"""objc_library for testing, only works in //src/objective-c/tests++    Args:+        name: name of target+        hdrs: public headers+        srcs: all source files (.m)+        textual_hdrs: private headers+        data: any other bundle resources+        defines: preprocessors+        includes: added to search path, always [the path to objc directory]+        deps: dependencies+    """"""+    +    additional_deps = [+        "":RemoteTest"",+        ""//src/objective-c:grpc_objc_client_internal_testing"",+    ]++    if not name == ""TestConfigs"":+        additional_deps += ["":TestConfigs""]+    +    native.objc_library(+        name = name,+        hdrs = hdrs,+        srcs = srcs,+        textual_hdrs = textual_hdrs,+        data = data,+        defines = defines,+        includes = includes,+        deps = deps + additional_deps,+    )++def local_objc_grpc_library(name, deps, srcs = [], use_well_known_protos = False, **kwargs):+    """"""!!For local targets within the gRPC repository only!! Will not work outside of the repo",Consider merging in `objc_grpc_library` with a parameter?,
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19855,313206516,2019-08-13T03:20:00Z,src/objective-c/grpc_objc_internal_library.bzl,"@@ -0,0 +1,174 @@+# Copyright 2019 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++#+# This is for the gRPC build system. This isn't intended to be used outsite of+# the BUILD file for gRPC. It contains the mapping for the template system we+# use to generate other platform's build system files.+#+# Please consider that there should be a high bar for additions and changes to+# this file.+# Each rule listed must be re-written for Google's internal build system, and+# each change must be ported from one to the other.+#++load(+    ""//bazel:generate_objc.bzl"",+    ""generate_objc"",+    ""generate_objc_hdrs"",+    ""generate_objc_srcs"",+    ""generate_objc_non_arc_srcs""+)+load(""//bazel:protobuf.bzl"", ""well_known_proto_libs"")++def grpc_objc_testing_library(+        name,+        srcs = [],+        hdrs = [],+        textual_hdrs = [],+        data = [],+        deps = [],+        defines = [],+        includes = []):+    """"""objc_library for testing, only works in //src/objective-c/tests++    Args:+        name: name of target+        hdrs: public headers+        srcs: all source files (.m)+        textual_hdrs: private headers+        data: any other bundle resources+        defines: preprocessors+        includes: added to search path, always [the path to objc directory]+        deps: dependencies+    """"""+    +    additional_deps = [+        "":RemoteTest"",+        ""//src/objective-c:grpc_objc_client_internal_testing"",+    ]++    if not name == ""TestConfigs"":+        additional_deps += ["":TestConfigs""]+    +    native.objc_library(+        name = name,+        hdrs = hdrs,+        srcs = srcs,+        textual_hdrs = textual_hdrs,+        data = data,+        defines = defines,+        includes = includes,+        deps = deps + additional_deps,+    )++def local_objc_grpc_library(name, deps, srcs = [], use_well_known_protos = False, **kwargs):+    """"""!!For local targets within the gRPC repository only!! Will not work outside of the repo+    """"""+    objc_grpc_library_name = ""_"" + name + ""_objc_grpc_library""++    generate_objc(+        name = objc_grpc_library_name,+        srcs = srcs,+        deps = deps,+        use_well_known_protos = use_well_known_protos,+        **kwargs+    )++    generate_objc_hdrs(+        name = objc_grpc_library_name + ""_hdrs"",+        src = "":"" + objc_grpc_library_name,+    )++    generate_objc_non_arc_srcs(+        name = objc_grpc_library_name + ""_non_arc_srcs"",+        src = "":"" + objc_grpc_library_name,+    )++    arc_srcs = None+    if len(srcs) > 0:+        generate_objc_srcs(+            name = objc_grpc_library_name + ""_srcs"",+            src = "":"" + objc_grpc_library_name,+        )+        arc_srcs = ["":"" + objc_grpc_library_name + ""_srcs""]++    native.objc_library(+        name = name,+        hdrs = ["":"" + objc_grpc_library_name + ""_hdrs""],+        non_arc_srcs = ["":"" + objc_grpc_library_name + ""_non_arc_srcs""],+        srcs = arc_srcs,+        defines = [+            ""GPB_USE_PROTOBUF_FRAMEWORK_IMPORTS=0"",+            ""GPB_GRPC_FORWARD_DECLARE_MESSAGE_PROTO=0"",+        ],+        includes = [+            ""_generated_protos"",+            ""src/objective-c"",+        ],+        deps = [+            ""//src/objective-c:proto_objc_rpc"",+            ""@com_google_protobuf//:protobuf_objc"",+        ],+    )++def testing_objc_grpc_library(name, deps, srcs = [], use_well_known_protos = False, **kwargs):",Consider merging in `objc_grpc_library` with a parameter?,
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19885,313212619,2019-08-13T04:06:03Z,bazel/grpc_build_system.bzl,"@@ -137,6 +139,32 @@ def grpc_proto_library(         use_external = use_external,         generate_mocks = generate_mocks,     )+def ios_cc_test(+        name,+        tags = [],+        **kwargs):+    ios_test_adapter = ""//third_party/objective_c/google_toolbox_for_mac:GTM_GoogleTestRunner_GTM_USING_XCTEST"";++    apple_test_lib = name + ""_test_lib_apple""+    apple_tags = tags + [""manual"", ""ios_cc_test""]+    if not any([t for t in tags if t.startswith(""no_test_ios"")]):+        native.objc_library(+            name = apple_test_lib,+            srcs = kwargs.get(""srcs""),","Rather than doing `kwargs.get`, I wonder if you can just pass kwargs as a parameter to `objc_library`",OK
24697473,Tony1023,https://api.github.com/repos/grpc/grpc/pulls/19855,313216212,2019-08-13T04:32:56Z,src/objective-c/examples/tvOS-sample/tvOS-sample/Info.plist,"@@ -3,7 +3,7 @@ <plist version=""1.0""> <dict> 	<key>CFBundleDevelopmentRegion</key>-	<string>$(DEVELOPMENT_LANGUAGE)</string>+	<string>en</string>",I think `en_US` was chosen from a drop-down menu of Xcode's plist editor. `en` is just more universal. I remember typing these two in as opposed to selecting from a drop-down menu. Replacing `$(DEVELOPMENT_LANGUAGE)` with `en` is just because Bazel complains about this being `undefined`. Is it better make all of them the same?,
24697473,Tony1023,https://api.github.com/repos/grpc/grpc/pulls/19855,313217592,2019-08-13T04:42:09Z,src/objective-c/examples/BUILD,"@@ -15,55 +15,154 @@ # limitations under the License.  +load(""//src/objective-c:grpc_objc_internal_library.bzl"", ""local_objc_grpc_library"") load(""@build_bazel_rules_apple//apple:ios.bzl"", ""ios_application"")-load(-    ""@com_github_grpc_grpc//bazel:objc_grpc_library.bzl"",-    ""objc_grpc_library"",-)+load(""@build_bazel_rules_apple//apple:tvos.bzl"", ""tvos_application"")+load(""@build_bazel_rules_apple//apple:watchos.bzl"", ""watchos_application"", ""watchos_extension"")  proto_library(     name = ""messages_proto"",-    srcs = [""BazelBuildSamples/messages.proto""],-    visibility = [""//visibility:public""],+    srcs = [""RemoteTestClient/messages.proto""],+)++proto_library(+    name = ""test_proto"",+    srcs = [""RemoteTestClient/test.proto""],+    deps = ["":messages_proto""], ) -objc_grpc_library(+# use objc_grpc_library in bazel:objc_grpc_library.bzl when developing outside the repo+local_objc_grpc_library(",1. This is not supposed to be used outside the grpc repository (because it refers to local paths).2. We don't use this in Google3So I figured we do not want to merge it with `objc_grpc_library`.,
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19838,313219700,2019-08-13T04:56:49Z,test/cpp/end2end/time_change_test.cc,"@@ -129,25 +129,34 @@ class TimeChangeTest : public ::testing::Test {  protected:   TimeChangeTest() {} -  void SetUp() {+  static void SetUpTestCase() {","`SetUpTestCase` is run once before any testcases in the test fixture are executed (it's executed once per test fixture). `SetUp` in run before every testcase.It's documented [here](https://github.com/google/googletest/blob/master/googletest/docs/advanced.md#sharing-resources-between-tests-in-the-same-test-suite), but note that the name of the static function mentioned in the documentation (`SetUpTestSuite`) is different.  That's because `SetUpTestCase` was recently renamed to `SetUpTestSuite`, but the version of googletest that we're using still uses `SetUpTestCase`.",OK
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19855,313489714,2019-08-13T16:20:12Z,src/objective-c/examples/BUILD,"@@ -15,55 +15,154 @@ # limitations under the License.  +load(""//src/objective-c:grpc_objc_internal_library.bzl"", ""local_objc_grpc_library"") load(""@build_bazel_rules_apple//apple:ios.bzl"", ""ios_application"")-load(-    ""@com_github_grpc_grpc//bazel:objc_grpc_library.bzl"",-    ""objc_grpc_library"",-)+load(""@build_bazel_rules_apple//apple:tvos.bzl"", ""tvos_application"")+load(""@build_bazel_rules_apple//apple:watchos.bzl"", ""watchos_application"", ""watchos_extension"")  proto_library(     name = ""messages_proto"",-    srcs = [""BazelBuildSamples/messages.proto""],-    visibility = [""//visibility:public""],+    srcs = [""RemoteTestClient/messages.proto""],+)++proto_library(+    name = ""test_proto"",+    srcs = [""RemoteTestClient/test.proto""],+    deps = ["":messages_proto""], ) -objc_grpc_library(+# use objc_grpc_library in bazel:objc_grpc_library.bzl when developing outside the repo+local_objc_grpc_library(     name = ""test_grpc_objc"",-    srcs = [""BazelBuildSamples/rmt/test.proto""],+    srcs = [""RemoteTestClient/test.proto""],     use_well_known_protos = True,     deps = [-        ""//src/objective-c/examples/BazelBuildSamples/rmt:test_proto"",+        ""//src/objective-c/examples:test_proto"",     ], )  # Proof that without this works without srcs-objc_grpc_library(+local_objc_grpc_library(     name = ""test_objc"",     use_well_known_protos = True,     deps = [-        ""//src/objective-c/examples/BazelBuildSamples/rmt:test_proto"",-    ]+        ""//src/objective-c/examples:test_proto"",+    ], )  objc_library(-    name = ""ios-sample-lib"",-    srcs = glob([""BazelBuildSamples/ios-sample/ios-sample/**/*.m""]),-    hdrs = glob([""BazelBuildSamples/ios-sample/ios-sample/**/*.h""]),+    name = ""Sample-lib"",+    srcs = glob([""Sample/Sample/**/*.m""]),+    hdrs = glob([""Sample/Sample/**/*.h""]),     data = glob([-        ""BazelBuildSamples/ios-sample/ios-sample/Assets.xcassets/**/*"",-        ""BazelBuildSamples/ios-sample/ios-sample/Base.lproj/**/*""+        ""Sample/Sample/Base.lproj/**"",+        ""Sample/Sample/Images.xcassets/**"",     ]),-    deps = [-        "":test_grpc_objc"",-    ]+    deps = ["":test_grpc_objc""], )  ios_application(-    name = ""ios-sample"",-    bundle_id = ""com.google.ios-sample-objc-bazel"",-    families = [""iphone""],-    minimum_os_version = ""9.0"",-    infoplists = [""BazelBuildSamples/ios-sample/ios-sample/Info.plist""],+    name = ""Sample"",+    bundle_id = ""grpc.objc.examples.Sample"",+    minimum_os_version = ""8.0"",+    infoplists = [""Sample/Sample/Info.plist""],+    families = [+        ""iphone"",+        ""ipad"",+    ],+    deps = [""Sample-lib""],     visibility = [""//visibility:public""],-    deps = ["":ios-sample-lib""],-)\ No newline at end of file+)++objc_library(+    name = ""InterceptorSample-lib"",+    srcs = glob([""InterceptorSample/InterceptorSample/**/*.m""]),+    hdrs = glob([""InterceptorSample/InterceptorSample/**/*.h""]),+    data = glob([+        ""InterceptorSample/InterceptorSample/Base.lproj/**"",","What I meant was, I did not see how the files in `data` section is used at build-time by `objc_library` or `ios_application`. From the [doc](https://docs.bazel.build/versions/master/be/objective-c.html#objc_library) of `objc_library`, it did not say that it is extracting storyboards or assets from `data` section. Can you point me to a doc that said so? Or how did you find out that the storyboards should be placed in `data`?",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/19855,313491003,2019-08-13T16:22:58Z,src/objective-c/grpc_objc_internal_library.bzl,"@@ -0,0 +1,174 @@+# Copyright 2019 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++#+# This is for the gRPC build system. This isn't intended to be used outsite of+# the BUILD file for gRPC. It contains the mapping for the template system we+# use to generate other platform's build system files.+#+# Please consider that there should be a high bar for additions and changes to+# this file.+# Each rule listed must be re-written for Google's internal build system, and+# each change must be ported from one to the other.+#++load(+    ""//bazel:generate_objc.bzl"",+    ""generate_objc"",+    ""generate_objc_hdrs"",+    ""generate_objc_srcs"",+    ""generate_objc_non_arc_srcs""+)+load(""//bazel:protobuf.bzl"", ""well_known_proto_libs"")++def grpc_objc_testing_library(+        name,+        srcs = [],+        hdrs = [],+        textual_hdrs = [],+        data = [],+        deps = [],+        defines = [],+        includes = []):+    """"""objc_library for testing, only works in //src/objective-c/tests++    Args:+        name: name of target+        hdrs: public headers+        srcs: all source files (.m)+        textual_hdrs: private headers+        data: any other bundle resources+        defines: preprocessors+        includes: added to search path, always [the path to objc directory]+        deps: dependencies+    """"""+    +    additional_deps = [+        "":RemoteTest"",+        ""//src/objective-c:grpc_objc_client_internal_testing"",+    ]++    if not name == ""TestConfigs"":+        additional_deps += ["":TestConfigs""]+    +    native.objc_library(+        name = name,+        hdrs = hdrs,+        srcs = srcs,+        textual_hdrs = textual_hdrs,+        data = data,+        defines = defines,+        includes = includes,+        deps = deps + additional_deps,+    )++def local_objc_grpc_library(name, deps, srcs = [], use_well_known_protos = False, **kwargs):+    """"""!!For local targets within the gRPC repository only!! Will not work outside of the repo+    """"""+    objc_grpc_library_name = ""_"" + name + ""_objc_grpc_library""++    generate_objc(+        name = objc_grpc_library_name,+        srcs = srcs,+        deps = deps,+        use_well_known_protos = use_well_known_protos,+        **kwargs+    )++    generate_objc_hdrs(+        name = objc_grpc_library_name + ""_hdrs"",+        src = "":"" + objc_grpc_library_name,+    )++    generate_objc_non_arc_srcs(+        name = objc_grpc_library_name + ""_non_arc_srcs"",+        src = "":"" + objc_grpc_library_name,+    )++    arc_srcs = None+    if len(srcs) > 0:+        generate_objc_srcs(+            name = objc_grpc_library_name + ""_srcs"",+            src = "":"" + objc_grpc_library_name,+        )+        arc_srcs = ["":"" + objc_grpc_library_name + ""_srcs""]++    native.objc_library(+        name = name,+        hdrs = ["":"" + objc_grpc_library_name + ""_hdrs""],+        non_arc_srcs = ["":"" + objc_grpc_library_name + ""_non_arc_srcs""],+        srcs = arc_srcs,+        defines = [+            ""GPB_USE_PROTOBUF_FRAMEWORK_IMPORTS=0"",+            ""GPB_GRPC_FORWARD_DECLARE_MESSAGE_PROTO=0"",+        ],+        includes = [+            ""_generated_protos"",+            ""src/objective-c"",+        ],+        deps = [+            ""//src/objective-c:proto_objc_rpc"",+            ""@com_google_protobuf//:protobuf_objc"",+        ],+    )++def testing_objc_grpc_library(name, deps, srcs = [], use_well_known_protos = False, **kwargs):",Or `local_objc_grpc_library`,
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19885,313550395,2019-08-13T18:34:13Z,bazel/grpc_build_system.bzl,"@@ -137,6 +139,32 @@ def grpc_proto_library(         use_external = use_external,         generate_mocks = generate_mocks,     )+def ios_cc_test(+        name,+        tags = [],+        **kwargs):+    ios_test_adapter = ""//third_party/objective_c/google_toolbox_for_mac:GTM_GoogleTestRunner_GTM_USING_XCTEST"";++    apple_test_lib = name + ""_test_lib_apple""+    apple_tags = tags + [""manual"", ""ios_cc_test""]+    if not any([t for t in tags if t.startswith(""no_test_ios"")]):+        native.objc_library(+            name = apple_test_lib,+            srcs = kwargs.get(""srcs""),","I guess you meant something like this?```        native.objc_library(           name = apple_test_lib_ios,           tags = apple_tags,           alwayslink = 1,            testonly = 1,            **kwargs        )```That does't work because [objc_library](https://docs.bazel.build/versions/master/be/objective-c.html#objc_library) doesn't take dict param.",OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19885,313552224,2019-08-13T18:38:26Z,third_party/objective_c/google_toolbox_for_mac/UnitTesting/GTMGoogleTestRunner.mm,"@@ -0,0 +1,233 @@+//+//  GTMGoogleTestRunner.mm",This is similar to `third_party/objective_c/Cronet/` which is copied from chromium.,
24697473,Tony1023,https://api.github.com/repos/grpc/grpc/pulls/19855,313579087,2019-08-13T19:44:16Z,src/objective-c/examples/BUILD,"@@ -15,55 +15,154 @@ # limitations under the License.  +load(""//src/objective-c:grpc_objc_internal_library.bzl"", ""local_objc_grpc_library"") load(""@build_bazel_rules_apple//apple:ios.bzl"", ""ios_application"")-load(-    ""@com_github_grpc_grpc//bazel:objc_grpc_library.bzl"",-    ""objc_grpc_library"",-)+load(""@build_bazel_rules_apple//apple:tvos.bzl"", ""tvos_application"")+load(""@build_bazel_rules_apple//apple:watchos.bzl"", ""watchos_application"", ""watchos_extension"")  proto_library(     name = ""messages_proto"",-    srcs = [""BazelBuildSamples/messages.proto""],-    visibility = [""//visibility:public""],+    srcs = [""RemoteTestClient/messages.proto""],+)++proto_library(+    name = ""test_proto"",+    srcs = [""RemoteTestClient/test.proto""],+    deps = ["":messages_proto""], ) -objc_grpc_library(+# use objc_grpc_library in bazel:objc_grpc_library.bzl when developing outside the repo+local_objc_grpc_library(     name = ""test_grpc_objc"",-    srcs = [""BazelBuildSamples/rmt/test.proto""],+    srcs = [""RemoteTestClient/test.proto""],     use_well_known_protos = True,     deps = [-        ""//src/objective-c/examples/BazelBuildSamples/rmt:test_proto"",+        ""//src/objective-c/examples:test_proto"",     ], )  # Proof that without this works without srcs-objc_grpc_library(+local_objc_grpc_library(     name = ""test_objc"",     use_well_known_protos = True,     deps = [-        ""//src/objective-c/examples/BazelBuildSamples/rmt:test_proto"",-    ]+        ""//src/objective-c/examples:test_proto"",+    ], )  objc_library(-    name = ""ios-sample-lib"",-    srcs = glob([""BazelBuildSamples/ios-sample/ios-sample/**/*.m""]),-    hdrs = glob([""BazelBuildSamples/ios-sample/ios-sample/**/*.h""]),+    name = ""Sample-lib"",+    srcs = glob([""Sample/Sample/**/*.m""]),+    hdrs = glob([""Sample/Sample/**/*.h""]),     data = glob([-        ""BazelBuildSamples/ios-sample/ios-sample/Assets.xcassets/**/*"",-        ""BazelBuildSamples/ios-sample/ios-sample/Base.lproj/**/*""+        ""Sample/Sample/Base.lproj/**"",+        ""Sample/Sample/Images.xcassets/**"",     ]),-    deps = [-        "":test_grpc_objc"",-    ]+    deps = ["":test_grpc_objc""], )  ios_application(-    name = ""ios-sample"",-    bundle_id = ""com.google.ios-sample-objc-bazel"",-    families = [""iphone""],-    minimum_os_version = ""9.0"",-    infoplists = [""BazelBuildSamples/ios-sample/ios-sample/Info.plist""],+    name = ""Sample"",+    bundle_id = ""grpc.objc.examples.Sample"",+    minimum_os_version = ""8.0"",+    infoplists = [""Sample/Sample/Info.plist""],+    families = [+        ""iphone"",+        ""ipad"",+    ],+    deps = [""Sample-lib""],     visibility = [""//visibility:public""],-    deps = ["":ios-sample-lib""],-)\ No newline at end of file+)++objc_library(+    name = ""InterceptorSample-lib"",+    srcs = glob([""InterceptorSample/InterceptorSample/**/*.m""]),+    hdrs = glob([""InterceptorSample/InterceptorSample/**/*.h""]),+    data = glob([+        ""InterceptorSample/InterceptorSample/Base.lproj/**"",",[bazel.build](https://www.bazel.build/) contains quite some outdated docs and incomplete docs (at least that's the case for ios related stuff). [rules_apple](github.com/bazelbuild/rules_apple/tree/master/doc) repo's ios-related docs are more updated. [Here](https://github.com/bazelbuild/rules_apple/blob/818e795208ae3ca1cf1501205549d46e6bc88d73/doc/resources.md)'s the one you are looking for.,OK
24697473,Tony1023,https://api.github.com/repos/grpc/grpc/pulls/19855,313580248,2019-08-13T19:47:02Z,src/objective-c/examples/BUILD,"@@ -15,55 +15,154 @@ # limitations under the License.  +load(""//src/objective-c:grpc_objc_internal_library.bzl"", ""local_objc_grpc_library"") load(""@build_bazel_rules_apple//apple:ios.bzl"", ""ios_application"")-load(-    ""@com_github_grpc_grpc//bazel:objc_grpc_library.bzl"",-    ""objc_grpc_library"",-)+load(""@build_bazel_rules_apple//apple:tvos.bzl"", ""tvos_application"")+load(""@build_bazel_rules_apple//apple:watchos.bzl"", ""watchos_application"", ""watchos_extension"")  proto_library(     name = ""messages_proto"",-    srcs = [""BazelBuildSamples/messages.proto""],-    visibility = [""//visibility:public""],+    srcs = [""RemoteTestClient/messages.proto""],+)++proto_library(+    name = ""test_proto"",+    srcs = [""RemoteTestClient/test.proto""],+    deps = ["":messages_proto""], ) -objc_grpc_library(+# use objc_grpc_library in bazel:objc_grpc_library.bzl when developing outside the repo+local_objc_grpc_library(     name = ""test_grpc_objc"",-    srcs = [""BazelBuildSamples/rmt/test.proto""],+    srcs = [""RemoteTestClient/test.proto""],     use_well_known_protos = True,     deps = [-        ""//src/objective-c/examples/BazelBuildSamples/rmt:test_proto"",+        ""//src/objective-c/examples:test_proto"",     ], )  # Proof that without this works without srcs-objc_grpc_library(+local_objc_grpc_library(     name = ""test_objc"",     use_well_known_protos = True,     deps = [-        ""//src/objective-c/examples/BazelBuildSamples/rmt:test_proto"",-    ]+        ""//src/objective-c/examples:test_proto"",+    ], )  objc_library(-    name = ""ios-sample-lib"",-    srcs = glob([""BazelBuildSamples/ios-sample/ios-sample/**/*.m""]),-    hdrs = glob([""BazelBuildSamples/ios-sample/ios-sample/**/*.h""]),+    name = ""Sample-lib"",+    srcs = glob([""Sample/Sample/**/*.m""]),+    hdrs = glob([""Sample/Sample/**/*.h""]),     data = glob([-        ""BazelBuildSamples/ios-sample/ios-sample/Assets.xcassets/**/*"",-        ""BazelBuildSamples/ios-sample/ios-sample/Base.lproj/**/*""+        ""Sample/Sample/Base.lproj/**"",+        ""Sample/Sample/Images.xcassets/**"",     ]),-    deps = [-        "":test_grpc_objc"",-    ]+    deps = ["":test_grpc_objc""], )  ios_application(-    name = ""ios-sample"",-    bundle_id = ""com.google.ios-sample-objc-bazel"",-    families = [""iphone""],-    minimum_os_version = ""9.0"",-    infoplists = [""BazelBuildSamples/ios-sample/ios-sample/Info.plist""],+    name = ""Sample"",+    bundle_id = ""grpc.objc.examples.Sample"",+    minimum_os_version = ""8.0"",+    infoplists = [""Sample/Sample/Info.plist""],+    families = [+        ""iphone"",+        ""ipad"",+    ],+    deps = [""Sample-lib""],     visibility = [""//visibility:public""],-    deps = ["":ios-sample-lib""],-)\ No newline at end of file+)++objc_library(+    name = ""InterceptorSample-lib"",+    srcs = glob([""InterceptorSample/InterceptorSample/**/*.m""]),+    hdrs = glob([""InterceptorSample/InterceptorSample/**/*.h""]),+    data = glob([+        ""InterceptorSample/InterceptorSample/Base.lproj/**"",","Although `objc_library` is a native rule, they still put the doc about feeding assets to `data` in the non-native repository. It does feel a bit weird.",OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/19885,313593248,2019-08-13T20:19:02Z,third_party/objective_c/google_toolbox_for_mac/UnitTesting/GTMGoogleTestRunner.mm,"@@ -0,0 +1,233 @@+//+//  GTMGoogleTestRunner.mm",Yeah I believe this is ok to do from a licensing POV. Google Toolbox for Mac is [licensed under Apache2](https://github.com/google/google-toolbox-for-mac/blob/master/LICENSE),OK
730,blowmage,https://api.github.com/repos/grpc/grpc/pulls/19931,313688601,2019-08-14T03:04:01Z,src/ruby/lib/grpc/errors.rb,"@@ -42,12 +42,12 @@ def initialize(code, details = 'unknown cause', metadata = {})       @metadata = metadata     end -    # Converts the exception to a {Struct::Status} for use in the networking+    # Converts the exception to a {GRPC::Core::Status} for use in the networking     # wrapper layer.     #-    # @return [Struct::Status] with the same code and details+    # @return [GRPC::Core::Status] with the same code and details     def to_status-      Struct::Status.new(code, details, metadata)+      GRPC::Core::Status.new(code, details, metadata)","The motivation is only that it looks like the intention would have been to locate these classes in the `GRPC` namespace instead of using the default location under `Struct`.In Ruby I would expect an anonymous struct to be assigned to a constant:```rubyGRPC::Core::Status = Struct.new(:code, :details, :metadata)```Instead of creating a named struct that uses the default location:```rubyStruct.new('Status', :code, :details, :metadata) # Struct::Status```",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/19940,313725485,2019-08-14T06:47:41Z,src/compiler/ruby_generator_string-inl.h,"@@ -125,6 +125,32 @@ inline grpc::string RubyTypeOf(const grpc::string& a_type,   } } +// RubyPackage gets the ruby package in either proto or ruby_package format+inline grpc::string RubyPackage(const grpc::protobuf::FileDescriptor* file) {+  grpc::string package_name = file->package();+  if (file->options().has_ruby_package()) {+      package_name = file->options().ruby_package();+      +      // If :: is in the package convert the Ruby formated name+      //    -> A::B::C+      // to use the dot seperator notation+      //    -> A.B.C+      if (package_name.find(""::"") != grpc::string::npos) {+        package_name = ReplaceAll(package_name, ""::"", ""."");",nit: this `ReplaceAll` doesn't need to be inside this if - it can be done unconditionally,OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19938,314004910,2019-08-14T17:53:02Z,examples/python/easy_start_demo/PyClient.py,"@@ -0,0 +1,93 @@+""""""+Author: Zhongying Wang+Email: kerbalwzy@gmail.com+License: MPL2+DateTime: 2019-08-13T23:30:00Z+PythonVersion: Python3.6.3+""""""+import grpc+import time+from customGrpcPackages import demo_pb2, demo_pb2_grpc++# Constants+PyGrpcServerAddress = ""127.0.0.1:23334""+ClientId = 1+++# 简单模式+# Simple+def simple_method(stub):+    print(""--------------Call SimpleMethod Begin--------------"")+    req = demo_pb2.Request(Cid=ClientId, ReqMsg=""called by Python client"")+    resp = stub.SimpleMethod(req)+    print(f""resp from server({resp.Sid}), the message={resp.RespMsg}"")+    print(""--------------Call SimpleMethod Over---------------"")+++# 客户端流模式（在一次调用中, 客户端可以多次向服务器传输数据, 但是服务器只能返回一次响应）+# Request-streaming (In a single call, the client can transfer data to the server several times,+# but the server can only return a response once.)+def c_stream_method(stub):","Can you extend all the acronyms in your naming? Instead of ""c_stream"", consider ""client_streaming"".",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19938,314007469,2019-08-14T17:58:30Z,examples/python/easy_start_demo/demo.proto,"@@ -0,0 +1,51 @@+// 语法版本声明，必须放在非注释的第一行+// Syntax version declaration, Must be placed on the first line of non-commentary+syntax = ""proto3"";++// 包名定义, Python中使用时可以省略不写(PS:我还要再Go中使用,所以留在这里了)+// Package name definition, which can be omitted in Python (PS: I'll use it again in Go, so stay here)+package demo;++/*+`message`是用来定义传输的数据的格式的, 等号后面的是字段编号+消息定义中的每个字段都有唯一的编号+总体格式类似于Python中定义一个类或者Golang中定义一个结构体+*/+/*+`message` is used to define the structure of the data to be transmitted, After the equal sign is the field number.+Each field in the message definition has a unique number.+The overall format is similar to defining a class in Python or a structure in Golang.+*/+message Request {+    int64 Cid = 1;+    string ReqMsg = 2;+}++message Response {+    int64 Sid = 1;+    string RespMsg = 2;+}++// service是用来给GRPC服务定义方法的, 格式固定, 类似于Golang中定义一个接口+// `service` is used to define methods for GRPC services in a fixed format, similar to defining an interface in Golang+service GRPCDemo {+    // 简单模式+    // Simple+    rpc SimpleMethod (Request) returns (Response);++    // 客户端流模式（在一次调用中, 客户端可以多次向服务器传输数据, 但是服务器只能返回一次响应）+    // Request-streaming (In a single call, the client can transfer data to the server several times,+    // but the server can only return a response once.)+    rpc CStreamMethod (stream Request) returns (Response);",Can you change the naming of rpc methods to full words?,
42475716,mqingli,https://api.github.com/repos/grpc/grpc/pulls/19814,314013978,2019-08-14T18:13:41Z,CMakeLists.txt,"@@ -3477,6 +3477,360 @@ endif (gRPC_BUILD_CODEGEN)  endif (gRPC_BUILD_TESTS) +add_library(grpc++_cronet+  src/cpp/client/cronet_credentials.cc","This single libgrpc++_cronet library works. Thanks! btw, we also explored another approach with build config. We added cornet transport and credentials source code to libgrpc and libgrpc++. It works too by just linking with these updated libgrpc & liggrpc++ only.",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/19939,314042762,2019-08-14T19:22:23Z,src/ruby/lib/grpc/errors.rb,"@@ -57,9 +59,6 @@ def to_status     #     # @return [Google::Rpc::Status, nil]     def to_rpc_status-      # Lazily require google_rpc_status_utils to scope-      # loading protobuf_c.so to the users of this method.-      require_relative './google_rpc_status_utils'","nit: it's outside of the scope of this PR, but while we're here, can we also remove the two lines below here: I believe they are dead/unused code.E.g. this could be change to just `GoogleRpcStatusUtils.extract_google_rpc_status(to_status)`",
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/19940,314147065,2019-08-15T01:32:33Z,src/compiler/ruby_generator_string-inl.h,"@@ -125,6 +125,31 @@ inline grpc::string RubyTypeOf(const grpc::string& a_type,   } } +// RubyPackage gets the ruby package in either proto or ruby_package format+inline grpc::string RubyPackage(const grpc::protobuf::FileDescriptor* file) {+  grpc::string package_name = file->package();+  if (file->options().has_ruby_package()) {+    package_name = file->options().ruby_package();++    // If :: is in the package convert the Ruby formated name+    //    -> A::B::C+    // to use the dot seperator notation+    //    -> A.B.C+    package_name = ReplaceAll(package_name, ""::"", ""."");+  }+  return package_name;+}++// RubyTypeOf gets the fully qualified Ruby name of the given descriptor+inline grpc::string RubyTypeOf(const grpc::protobuf::Descriptor* descriptor,",nit: can we please remove the other (currently overloaded) `RubyTypeOf` definition - it looks like it's now dead code.,OK
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/19940,314148224,2019-08-15T01:40:40Z,src/compiler/ruby_generator_string-inl.h,"@@ -125,6 +125,31 @@ inline grpc::string RubyTypeOf(const grpc::string& a_type,   } } +// RubyPackage gets the ruby package in either proto or ruby_package format+inline grpc::string RubyPackage(const grpc::protobuf::FileDescriptor* file) {+  grpc::string package_name = file->package();+  if (file->options().has_ruby_package()) {+    package_name = file->options().ruby_package();++    // If :: is in the package convert the Ruby formated name+    //    -> A::B::C+    // to use the dot seperator notation+    //    -> A.B.C+    package_name = ReplaceAll(package_name, ""::"", ""."");+  }+  return package_name;+}++// RubyTypeOf gets the fully qualified Ruby name of the given descriptor+inline grpc::string RubyTypeOf(const grpc::protobuf::Descriptor* descriptor,","Sorry, my bad - realize that's not dead code. However, I'd prefer to avoid overloading `RubyTypeOf`.Can we instead just merge this code into the existing `RubyTypeOf`? E.g., we could change the existing `RubyTypeOf` to take these params here, and change the top to something like:```std::string proto_type = descriptor->full_name();if (descriptor->file()->options().has_ruby_package()) {   proto_type = RubyPackage(descriptor->file()) + ""."" + descriptor->name();}grpc::string res(proto_type);....```",OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/19938,314414527,2019-08-15T17:26:59Z,examples/python/easy_start_demo/client.py,"@@ -0,0 +1,98 @@+""""""",Flowerboxes like this aren't part of the style of the codebase. The timestamp and authorship information is tracked by git. Please feel free to add yourself to the [`AUTHORS` file](https://github.com/grpc/grpc/blob/master/AUTHORS) though.,OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19960,314424637,2019-08-15T17:51:14Z,src/python/grpcio/grpc/_cython/_cygrpc/aio/call.pyx.pxi,"@@ -0,0 +1,149 @@+# Copyright 2019 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++cimport cpython++_EMPTY_FLAGS = 0+_EMPTY_METADATA = ()+_OP_ARRAY_LENGTH = 6+++cdef class _AioCall:+++    def __cinit__(self, AioChannel channel):+        self._channel = channel+        self._functor.functor_run = _AioCall.functor_run++        self._cq = grpc_completion_queue_create_for_callback(+            <grpc_experimental_completion_queue_functor *> &self._functor,+            NULL+        )++        self._watcher_call.functor.functor_run = _AioCall.watcher_call_functor_run+        self._watcher_call.waiter = <cpython.PyObject *> self+        self._waiter_call = None++    def __dealloc__(self):+        grpc_completion_queue_shutdown(self._cq)+        grpc_completion_queue_destroy(self._cq)++    def __repr__(self):+        class_name = self.__class__.__name__+        id_ = id(self)+        return f""<{class_name} {id_}>""++    @staticmethod+    cdef void functor_run(grpc_experimental_completion_queue_functor* functor, int succeed):+        pass++    @staticmethod+    cdef void watcher_call_functor_run(grpc_experimental_completion_queue_functor* functor, int succeed):+        call = <_AioCall>(<CallbackContext *>functor).waiter++        assert call._waiter_call++        if succeed == 0:+            call._waiter_call.set_exception(Exception(""Some error ocurred""))+        else:+            call._waiter_call.set_result(None)++    async def unary_unary(self, method, request):+        cdef grpc_call * call+        cdef grpc_slice method_slice+        cdef grpc_op * ops++        cdef Operation initial_metadata_operation+        cdef Operation send_message_operation+        cdef Operation send_close_from_client_operation+        cdef Operation receive_initial_metadata_operation+        cdef Operation receive_message_operation+        cdef Operation receive_status_on_client_operation++        cdef grpc_call_error call_status+++        method_slice = grpc_slice_from_copied_buffer(+            <const char *> method,+            <size_t> len(method)+        )++        call = grpc_channel_create_call(+            self._channel.channel,+            NULL,+            0,+            self._cq,+            method_slice,+            NULL,+            _timespec_from_time(None),+            NULL+        )++        grpc_slice_unref(method_slice)++        ops = <grpc_op *>gpr_malloc(sizeof(grpc_op) * _OP_ARRAY_LENGTH)++        initial_metadata_operation = SendInitialMetadataOperation(_EMPTY_METADATA, GRPC_INITIAL_METADATA_USED_MASK)",How are we planning to pass down metadata from user application to here?,
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19960,314427329,2019-08-15T17:57:38Z,src/python/grpcio/grpc/experimental/aio/__init__.py,"@@ -0,0 +1,123 @@+# Copyright 2019 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""gRPC's Asynchronous Python API.""""""++import abc+import six++from grpc._cython.cygrpc import init_grpc_aio+++class Channel(six.with_metaclass(abc.ABCMeta)):","As discussed, shall we change to concrete classes instead of interfaces?",
1226121,pfreixes,https://api.github.com/repos/grpc/grpc/pulls/19960,314592895,2019-08-16T06:06:47Z,src/python/grpcio/grpc/_cython/_cygrpc/aio/call.pyx.pxi,"@@ -0,0 +1,149 @@+# Copyright 2019 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++cimport cpython++_EMPTY_FLAGS = 0+_EMPTY_METADATA = ()+_OP_ARRAY_LENGTH = 6+++cdef class _AioCall:+++    def __cinit__(self, AioChannel channel):+        self._channel = channel+        self._functor.functor_run = _AioCall.functor_run++        self._cq = grpc_completion_queue_create_for_callback(+            <grpc_experimental_completion_queue_functor *> &self._functor,+            NULL+        )++        self._watcher_call.functor.functor_run = _AioCall.watcher_call_functor_run+        self._watcher_call.waiter = <cpython.PyObject *> self+        self._waiter_call = None++    def __dealloc__(self):+        grpc_completion_queue_shutdown(self._cq)+        grpc_completion_queue_destroy(self._cq)++    def __repr__(self):+        class_name = self.__class__.__name__+        id_ = id(self)+        return f""<{class_name} {id_}>""++    @staticmethod+    cdef void functor_run(grpc_experimental_completion_queue_functor* functor, int succeed):+        pass++    @staticmethod+    cdef void watcher_call_functor_run(grpc_experimental_completion_queue_functor* functor, int succeed):+        call = <_AioCall>(<CallbackContext *>functor).waiter++        assert call._waiter_call++        if succeed == 0:+            call._waiter_call.set_exception(Exception(""Some error ocurred""))+        else:+            call._waiter_call.set_result(None)++    async def unary_unary(self, method, request):+        cdef grpc_call * call+        cdef grpc_slice method_slice+        cdef grpc_op * ops++        cdef Operation initial_metadata_operation+        cdef Operation send_message_operation+        cdef Operation send_close_from_client_operation+        cdef Operation receive_initial_metadata_operation+        cdef Operation receive_message_operation+        cdef Operation receive_status_on_client_operation++        cdef grpc_call_error call_status+++        method_slice = grpc_slice_from_copied_buffer(+            <const char *> method,+            <size_t> len(method)+        )++        call = grpc_channel_create_call(+            self._channel.channel,+            NULL,+            0,+            self._cq,+            method_slice,+            NULL,+            _timespec_from_time(None),+            NULL+        )++        grpc_slice_unref(method_slice)++        ops = <grpc_op *>gpr_malloc(sizeof(grpc_op) * _OP_ARRAY_LENGTH)++        initial_metadata_operation = SendInitialMetadataOperation(_EMPTY_METADATA, GRPC_INITIAL_METADATA_USED_MASK)",I guess that by simply passing a metadata parameter that will be used later for building the operation. Do you anticipate a problem with that?,
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/19971,314814375,2019-08-16T17:21:09Z,src/python/grpcio/grpc/_local_credentials.py,"@@ -0,0 +1,56 @@+# Copyright 2019 The gRPC authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""gRPC's local credential API.""""""++import enum+import grpc+from grpc._cython import cygrpc+++@enum.unique+class LocalConnectType(enum.Enum):",Feels like `LocalConnectionType` reads better alongside the rest of Python API.,OK
900411,mehrdada,https://api.github.com/repos/grpc/grpc/pulls/19971,314815526,2019-08-16T17:24:18Z,src/python/grpcio/grpc/_local_credentials.py,"@@ -0,0 +1,56 @@+# Copyright 2019 The gRPC authors","nit: uppercase ""Authors"" (also in similar places)",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19960,314823206,2019-08-16T17:45:34Z,src/python/grpcio_tests/tests_aio/unit/sync_server.py,"@@ -0,0 +1,61 @@+# Copyright 2019 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import multiprocessing++from concurrent import futures+from time import sleep++import grpc+from src.proto.grpc.testing import messages_pb2+from src.proto.grpc.testing import test_pb2_grpc++# TODO (https://github.com/grpc/grpc/issues/19762)+# Change for an asynchronous server version once it's implemented.+++class TestServiceServicer(test_pb2_grpc.TestServiceServicer):++    def UnaryCall(self, request, context):+        return messages_pb2.SimpleResponse()+++class Server(multiprocessing.Process):+    """"""+    Synchronous server is executed in another process which initializes+    implicitly the grpc using the synchronous configuration. Both worlds+    can not coexist within the same process.+    """"""++    PORT = 3333","Using a fixed port will introduce a flake in our tests, internally, they are ran in parallel. The port number can be conflicted. If you want to pick a random port, you can try this piece of code I wrote for testing. Or use the `portpicker` package.```Python@contextmanagerdef get_free_loopback_tcp_port():    if socket.has_ipv6:        tcp_socket = socket.socket(socket.AF_INET6)    else:        tcp_socket = socket.socket(socket.AF_INET)    tcp_socket.bind(('', 0))    address_tuple = tcp_socket.getsockname()    yield ""localhost:%s"" % (address_tuple[1])    tcp_socket.close()```",OK
2793282,veblush,https://api.github.com/repos/grpc/grpc/pulls/19965,314828654,2019-08-16T17:59:19Z,tools/buildgen/plugins/check_attrs.py,"@@ -0,0 +1,126 @@+# Copyright 2019 gRPC authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""Buildgen attribute validation plugin.""""""+++def anything():+  return lambda v: None+++def one_of(values):+  return lambda v: ('{0} is not in [{1}]'.format(v, values)+                    if v not in values else None)+++def subset_of(values):+  return lambda v: ('{0} is not subset of [{1}]'.format(v, values)+                    if not all(e in values for e in v) else None)+++VALID_ATTRIBUTE_KEYS_MAP = {+    'filegroup': {+        'deps': anything(),+        'headers': anything(),+        'plugin': anything(),+        'public_headers': anything(),+        'src': anything(),+        'uses': anything(),+    },+    'lib': {+        'baselib': anything(),+        'boringssl': one_of((True, )),+        'build_system': anything(),+        'build': anything(),+        'defaults': anything(),+        'deps_linkage': one_of(('static',)),+        'deps': anything(),+        'dll': one_of((True, 'only')),+        'filegroups': anything(),+        'generate_plugin_registry': anything(),+        'headers': anything(),+        'language': one_of(('c', 'c++', 'csharp')),+        'LDFLAGS': anything(),+        'platforms': subset_of(('linux', 'mac', 'posix', 'windows')),+        'public_headers': anything(),+        'secure': one_of(('check', True, False)),+        'src': anything(),+        'vs_proj_dir': anything(),+        'zlib': one_of((True, )),+    },+    'target': {+        'args': anything(),+        'benchmark': anything(),+        'boringssl': one_of((True, )),+        'build': anything(),+        'ci_platforms': anything(),+        'corpus_dirs': anything(),+        'cpu_cost': anything(),+        'defaults': anything(),+        'deps': anything(),+        'dict': anything(),+        'exclude_configs': anything(),+        'exclude_iomgrs': anything(),+        'excluded_poll_engines': anything(),+        'filegroups': anything(),+        'flaky': one_of((True, False)),+        'gtest': one_of((True, False)),+        'headers': anything(),+        'language': one_of(('c', 'c89', 'c++', 'csharp')),+        'maxlen': anything(),+        'platforms': subset_of(('linux', 'mac', 'posix', 'windows')),+        'run': one_of((True, False)),+        'secure': one_of(('check', True, False)),+        'src': anything(),+        'timeout_seconds': anything(),+        'uses_polling': anything(),+        'vs_proj_dir': anything(),+        'zlib': one_of((True, )),+    },+}+++def check_attributes(entity, kind, errors):+  attributes = VALID_ATTRIBUTE_KEYS_MAP[kind]+  name = entity.get('name', anything())+  for key, value in entity.items():+    if key == 'name':+      continue+    validator = attributes.get(key)+    if validator:+      error = validator(value)+      if error:+        errors.append(""{0}({1}) has an invalid value for '{2}': {3}"".format(+            name, kind, key, error))+    else:+      errors.append(""{0}({1}) has an invalid attribute '{2}'"".format(+          name, kind, key))+++def mako_plugin(dictionary):+  """"""The exported plugin code for check_attr.++  This validates that filegroups, libs, and target can have only valid+  attributes. This is mainly for preventing build.yaml from having+  unnecessary and misleading attributes accidently.+  """"""++  errors = []+  for filegroup in dictionary.get('filegroups', {}):+    check_attributes(filegroup, 'filegroup', errors)+  for lib in dictionary.get('libs', {}):+    check_attributes(lib, 'lib', errors)+  for target in dictionary.get('targets', {}):+    check_attributes(target, 'target', errors)+  #if errors:+  #  raise Exception('\n'.join(errors))",oh my bad. it should be uncommented. thanks!,OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19971,314831300,2019-08-16T18:06:26Z,src/python/grpcio/grpc/_local_credentials.py,"@@ -0,0 +1,56 @@+# Copyright 2019 The gRPC authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.+""""""gRPC's local credential API.""""""++import enum+import grpc+from grpc._cython import cygrpc+++@enum.unique+class LocalConnectType(enum.Enum):",This API is exposed internally. Change the naming might need another large scale change.EDIT: Turn out there are only a few call sites that I can manually change. Updated.,OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/19971,314904769,2019-08-16T22:03:30Z,src/python/grpcio/grpc/__init__.py,"@@ -1744,6 +1744,44 @@ def dynamic_ssl_server_credentials(initial_certificate_configuration,             certificate_configuration_fetcher, require_client_authentication))  +@enum.unique+class LocalConnectionType(enum.Enum):+    """"""Type of local connections for which local channel/server credentials will be applied.++    Attributes:+      UDS: Unix domain socket connections+      LOCAL_TCP: Local TCP connections.+    """"""+    UDS = _cygrpc.LocalConnectType.uds+    LOCAL_TCP = _cygrpc.LocalConnectType.local_tcp+++def local_channel_credentials(local_connect_type=LocalConnectionType.LOCAL_TCP):+    """"""Creates a local ChannelCredentials used for local connections.","I think we're going to want a longer docstring describing what local credentials are and perhaps naming potential use cases. Without context, this won't be useful to very many users.",OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/19971,314916871,2019-08-16T23:13:10Z,src/python/grpcio/grpc/__init__.py,"@@ -1744,6 +1744,44 @@ def dynamic_ssl_server_credentials(initial_certificate_configuration,             certificate_configuration_fetcher, require_client_authentication))  +@enum.unique+class LocalConnectionType(enum.Enum):+    """"""Type of local connections for which local channel/server credentials will be applied.++    Attributes:+      UDS: Unix domain socket connections+      LOCAL_TCP: Local TCP connections.+    """"""+    UDS = _cygrpc.LocalConnectType.uds+    LOCAL_TCP = _cygrpc.LocalConnectType.local_tcp+++def local_channel_credentials(local_connect_type=LocalConnectionType.LOCAL_TCP):+    """"""Creates a local ChannelCredentials used for local connections.","Huh. Apparently, [this is still considered an experimental API](https://github.com/grpc/grpc/blob/13fb5066390b51bf457725a91fe3a93daed40940/include/grpc/grpc_security.h#L687) within core. At any rate, we probably want some explanation about exactly what sort of authentication/authorization mechanism is used. Without looking into the code, even I'm still scratching my head about what exactly this feature is.Edit: [This comment](https://github.com/grpc/grpc/pull/15909#issue-198162785) is the most information I can find on the topic. Maybe something like ""Peer authentication and channel confidentiality are established for channels using local_channel_credentials by native kernel permission checks.""CC @yihuazhang ",
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/19971,314926242,2019-08-17T00:36:46Z,src/python/grpcio/grpc/__init__.py,"@@ -1744,6 +1744,44 @@ def dynamic_ssl_server_credentials(initial_certificate_configuration,             certificate_configuration_fetcher, require_client_authentication))  +@enum.unique+class LocalConnectionType(enum.Enum):+    """"""Type of local connections for which local channel/server credentials will be applied.++    Attributes:+      UDS: Unix domain socket connections+      LOCAL_TCP: Local TCP connections.+    """"""+    UDS = _cygrpc.LocalConnectType.uds+    LOCAL_TCP = _cygrpc.LocalConnectType.local_tcp+++def local_channel_credentials(local_connect_type=LocalConnectionType.LOCAL_TCP):+    """"""Creates a local ChannelCredentials used for local connections.","Thanks Lidi for exposing the local credential in OSS. The current status is C-core, Java and Go teams agreed on the semantics of channel and call credentials (I shared with you and Lidi) which will be a building block for designing local credentials in all languages. I still need to update the existing API's in those three languages to conform to the semantics (Sorry for taking so long), and after that we can design local credentials for Java and Go and remove experimental namespace in C-core. W.r.t explanation, TCP loopback does not provide either peer authentication or channel confidentiality while UDS provides both of them and can be treated as secure as transport security. ",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19988,315408474,2019-08-19T20:57:54Z,src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi,"@@ -307,8 +329,14 @@ cdef class SegregatedCall:     def on_success(tag):       _process_segregated_call_tag(         self._channel_state, self._call_state, self._c_completion_queue, tag)+    def on_failure():+      self._call_state.due.clear()+      grpc_call_unref(self._call_state.c_call)","Is double `unref` going to be a problem or not? The `__dealloc__` in cdef class `Call` also invokes the `grpc_call_unref`, is it possible to have a race and end up calling `unref` twice?",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19988,315410443,2019-08-19T21:02:59Z,src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi,"@@ -146,12 +146,34 @@ cdef _cancel(  cdef _next_call_event(     _ChannelState channel_state, grpc_completion_queue *c_completion_queue,-    on_success, deadline):-  tag, event = _latent_event(c_completion_queue, deadline)-  with channel_state.condition:-    on_success(tag)-    channel_state.condition.notify_all()-  return event+    on_success, on_failure, deadline):+  """"""Block on the next event out of the completion queue.++  On success, `on_success` will be invoked with the tag taken from the CQ.+  In the case of a failure due to an exception raised in a signal handler,+  `on_failure` will be invoked with no arguments. Note that this situation+  can only occur on the main thread.++  Args:+    channel_state: The state for the channel on which the RPC is running.+    c_completion_queue: The CQ which will be polled.+    on_success: A callable object to be invoked upon successful receipt of a+      tag from the CQ.+    on_failure: A callable object to be invoked in case a Python exception is+      raised from a signal handler during polling.+    deadline: The point after which the RPC will time out.+  """"""+  try:+    tag, event = _latent_event(c_completion_queue, deadline)+  except:",Should we expose the actual exception? Does it help debugging?,OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/19988,315413530,2019-08-19T21:11:46Z,src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi,"@@ -146,12 +146,34 @@ cdef _cancel(  cdef _next_call_event(     _ChannelState channel_state, grpc_completion_queue *c_completion_queue,-    on_success, deadline):-  tag, event = _latent_event(c_completion_queue, deadline)-  with channel_state.condition:-    on_success(tag)-    channel_state.condition.notify_all()-  return event+    on_success, on_failure, deadline):+  """"""Block on the next event out of the completion queue.++  On success, `on_success` will be invoked with the tag taken from the CQ.+  In the case of a failure due to an exception raised in a signal handler,+  `on_failure` will be invoked with no arguments. Note that this situation+  can only occur on the main thread.++  Args:+    channel_state: The state for the channel on which the RPC is running.+    c_completion_queue: The CQ which will be polled.+    on_success: A callable object to be invoked upon successful receipt of a+      tag from the CQ.+    on_failure: A callable object to be invoked in case a Python exception is+      raised from a signal handler during polling.+    deadline: The point after which the RPC will time out.+  """"""+  try:+    tag, event = _latent_event(c_completion_queue, deadline)+  except:",Check out how [the default `SIGINT` handler](https://github.com/python/cpython/blob/master/Modules/signalmodule.c#L201) works.,OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19988,315413661,2019-08-19T21:12:05Z,src/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi,"@@ -146,12 +146,34 @@ cdef _cancel(  cdef _next_call_event(     _ChannelState channel_state, grpc_completion_queue *c_completion_queue,-    on_success, deadline):-  tag, event = _latent_event(c_completion_queue, deadline)-  with channel_state.condition:-    on_success(tag)-    channel_state.condition.notify_all()-  return event+    on_success, on_failure, deadline):+  """"""Block on the next event out of the completion queue.++  On success, `on_success` will be invoked with the tag taken from the CQ.+  In the case of a failure due to an exception raised in a signal handler,+  `on_failure` will be invoked with no arguments. Note that this situation+  can only occur on the main thread.++  Args:+    channel_state: The state for the channel on which the RPC is running.+    c_completion_queue: The CQ which will be polled.+    on_success: A callable object to be invoked upon successful receipt of a+      tag from the CQ.+    on_failure: A callable object to be invoked in case a Python exception is+      raised from a signal handler during polling.+    deadline: The point after which the RPC will time out.+  """"""+  try:+    tag, event = _latent_event(c_completion_queue, deadline)+  except:","I wasn't express clearly, I mean should we pass the exception to the callback, or log it as `DEBUG`?",
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/19938,315835228,2019-08-20T18:19:10Z,examples/python/easy_start_demo/client.py,"@@ -0,0 +1,98 @@+""""""+Author: Zhongying Wang+Email: kerbalwzy@gmail.com+DateTime: 2019-08-13T23:30:00Z+PythonVersion: Python3.6.3+""""""+import os+import sys+import time+import grpc++# add the `demo_grpc_dps` dir into python package search paths+BaseDir = os.path.dirname(os.path.abspath(__file__))+sys.path.insert(0, os.path.join(BaseDir, ""demo_grpc_pbs""))",Agree. You shouldn't have to modify the generated code *or* manipulate the path. Check out the [`hello_world` example](https://github.com/grpc/grpc/blob/master/examples/python/helloworld/greeter_server.py) or [this key-value store example](https://github.com/gnossen/grpc-example/blob/master/grpc_kv_server/src/grpc_kv_server/__init__.py#L12). I would actually discourage users from checking generated code into source control at all.,
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/20015,315913576,2019-08-20T21:33:12Z,src/python/grpcio_tests/tests/unit/_channel_close_test.py,"@@ -181,6 +217,20 @@ def sleep_some_time_then_close():          self.assertIs(response_iterator.code(), grpc.StatusCode.CANCELLED) +    def test_exception_in_callback(self):+        with grpc.insecure_channel('localhost:{}'.format(+                self._port)) as channel:+            stream_multi_callable = channel.stream_stream(_STREAM_URI)+            endless_iterator = EndlessIterator(b'abc')",You can use `itertools.cycle` to avoid creating additional class.,OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/20023,316419171,2019-08-21T21:53:19Z,bazel/grpc_deps.bzl,"@@ -141,9 +141,16 @@ def grpc_deps():     if ""com_github_google_googletest"" not in native.existing_rules():         http_archive(             name = ""com_github_google_googletest"",-            sha256 = ""d0d447b4feeedca837a0d46a289d4223089b32ac2f84545fa4982755cc8919be"",-            strip_prefix = ""googletest-2fe3bd994b3189899d93f1d5a881e725e046fdc2"",-            url = ""https://github.com/google/googletest/archive/2fe3bd994b3189899d93f1d5a881e725e046fdc2.tar.gz"",+            sha256 = ""443d383db648ebb8e391382c0ab63263b7091d03197f304390baac10f178a468"",+            strip_prefix = ""googletest-c9ccac7cb7345901884aabf5d1a786cfa6e2f397"",+            url = ""https://github.com/google/googletest/archive/c9ccac7cb7345901884aabf5d1a786cfa6e2f397.tar.gz"", # 2019-08-19+        )++        http_archive(","Any reason not to guard it in its own `if ""rules_cc"" not in native.existing_rules()`? If it's not guarded, I think this may cause a collision with our downstream repos like https://github.com/census-instrumentation/opencensus-cpp/blob/master/WORKSPACE#L20.**Edit**: After some experimentation, this wouldn't cause a name collision, but it *would* make the version of `rules_cc` the project ultimately uses dependent on the placement of `grpc_deps()` in the user's `WORKSPACE`.",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19960,316878613,2019-08-22T20:48:08Z,src/python/grpcio/grpc/_cython/_cygrpc/aio/iomgr/iomgr.pyx.pxi,"@@ -12,7 +12,14 @@ # See the License for the specific language governing permissions and # limitations under the License. -import asyncio+try:+    import asyncio+except ImportError:+    # TODO(https://github.com/grpc/grpc/issues/19728) Improve how Aio Cython is+    # distributed without breaking none compatible Python versions. For now, if+    # Asyncio package is not available we just skip it.+    pass+","Nit: all these `.pxi` files will be concatenated into one, so we can import the libraries once in `cygrpc.pyx`. I didn't mention it before because it doesn't hurt performance and increases readability. But this case we don't want to duplicate TODO comment and create burden (one change apply to multiple places) for future changes.",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19960,316905742,2019-08-22T22:10:29Z,src/python/grpcio/grpc/_cython/_cygrpc/aio/iomgr/iomgr.pyx.pxi,"@@ -12,7 +12,14 @@ # See the License for the specific language governing permissions and # limitations under the License. -import asyncio+try:+    import asyncio+except ImportError:+    # TODO(https://github.com/grpc/grpc/issues/19728) Improve how Aio Cython is+    # distributed without breaking none compatible Python versions. For now, if+    # Asyncio package is not available we just skip it.+    pass+","Yes, that's what I mean. In the top of `cygrpc.pyx`, there is multiple imports.https://github.com/grpc/grpc/blob/master/src/python/grpcio/grpc/_cython/cygrpc.pyx#L19",
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/19778,316925035,2019-08-22T23:30:38Z,include/grpcpp/security/tls_credentials_options.h,"@@ -0,0 +1,260 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPCPP_SECURITY_TLS_CREDENTIALS_OPTIONS_H+#define GRPCPP_SECURITY_TLS_CREDENTIALS_OPTIONS_H++#include <memory>+#include <vector>++#include <grpc/grpc_security.h>+#include <grpc/support/log.h>+#include <grpcpp/support/config.h>++namespace grpc_impl {+namespace experimental {++/** TLS key materials config, wrapper for grpc_tls_key_materials_config. **/+class TlsKeyMaterialsConfig {+ public:+  struct PemKeyCertPair {+    grpc::string private_key;+    grpc::string cert_chain;+  };++  /** Getters for member fields. **/+  const grpc::string pem_root_certs() const { return pem_root_certs_; }+  const std::vector<PemKeyCertPair>& pem_key_cert_pair_list() const {+    return pem_key_cert_pair_list_;+  }+  int version() const { return version_; }++  /** Setter for key materials that will be called by the user. The setter+   * transfers ownership of the arguments to the config. **/+  void set_key_materials(grpc::string pem_root_certs,+                         std::vector<PemKeyCertPair> pem_key_cert_pair_list);+  void set_version(int version) { version_ = version; };++ private:+  int version_;+  std::vector<PemKeyCertPair> pem_key_cert_pair_list_;+  grpc::string pem_root_certs_;+};++/** The following 2 functions are exposed for testing purposes. **/+grpc_tls_key_materials_config* c_key_materials(","Could you please use C++ naming style for these exposed functions, e.g., `ConvertToCKeyMaterialsConfig()`? - ""functions should start with a capital letter and have a capital letter for each new word."" I also noticed there are other functions exposed for testing in this file, and how about placing them all in a new file - `tls_credentials_options_util.{h, cc}`? which I think it will be much cleaner. After all they are internal implementation details, and should not be exposed to the users. ",OK
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/20044,317223210,2019-08-23T17:07:51Z,src/core/lib/gprpp/map.h,"@@ -209,6 +233,53 @@ class Map<Key, T, Compare>::iterator   GrpcMap* map_; }; +template <class Key, class T, class Compare>+class Map<Key, T, Compare>::const_iterator+    : public std::iterator<std::input_iterator_tag, Pair<Key, T>, int32_t,+                           Pair<Key, T>*, Pair<Key, T>&> {+ public:+  const_iterator(const const_iterator& iter)+      : curr_(iter.curr_), map_(iter.map_) {}+  bool operator==(const const_iterator& rhs) const {+    return (curr_ == rhs.curr_);+  }+  bool operator!=(const const_iterator& rhs) const {+    return (curr_ != rhs.curr_);+  }++  const_iterator& operator++() {+    curr_ = map_->InOrderSuccessor(curr_);+    return *this;+  }++  const_iterator operator++(int) {+    Entry* prev = curr_;+    curr_ = map_->InOrderSuccessor(curr_);+    return const_iterator(map_, prev);+  }++  const_iterator& operator=(const const_iterator& other) {+    if (this != &other) {+      this->curr_ = other.curr_;+      this->map_ = other.map_;+    }+    return *this;+  }++  // operator*()+  const value_type& operator*() const { return curr_->pair; }++  // operator->()+  const value_type* operator->() const { return &curr_->pair; }++ private:+  friend class Map<key_type, mapped_type, key_compare>;+  using GrpcMap = typename ::grpc_core::Map<Key, T, Compare>;+  const_iterator(const GrpcMap* map, Entry* curr) : curr_(curr), map_(map) {}",Nit: make the order in arg list the same as declaration?,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/20044,317280990,2019-08-23T19:55:58Z,src/core/lib/gprpp/map.h,"@@ -209,6 +233,53 @@ class Map<Key, T, Compare>::iterator   GrpcMap* map_; }; +template <class Key, class T, class Compare>+class Map<Key, T, Compare>::const_iterator+    : public std::iterator<std::input_iterator_tag, Pair<Key, T>, int32_t,+                           Pair<Key, T>*, Pair<Key, T>&> {+ public:+  const_iterator(const const_iterator& iter)+      : curr_(iter.curr_), map_(iter.map_) {}+  bool operator==(const const_iterator& rhs) const {+    return (curr_ == rhs.curr_);+  }+  bool operator!=(const const_iterator& rhs) const {+    return (curr_ != rhs.curr_);+  }++  const_iterator& operator++() {+    curr_ = map_->InOrderSuccessor(curr_);+    return *this;+  }++  const_iterator operator++(int) {+    Entry* prev = curr_;+    curr_ = map_->InOrderSuccessor(curr_);+    return const_iterator(map_, prev);+  }++  const_iterator& operator=(const const_iterator& other) {+    if (this != &other) {+      this->curr_ = other.curr_;+      this->map_ = other.map_;+    }+    return *this;+  }++  // operator*()+  const value_type& operator*() const { return curr_->pair; }++  // operator->()+  const value_type* operator->() const { return &curr_->pair; }++ private:+  friend class Map<key_type, mapped_type, key_compare>;+  using GrpcMap = typename ::grpc_core::Map<Key, T, Compare>;+  const_iterator(const GrpcMap* map, Entry* curr) : curr_(curr), map_(map) {}","This is copied from the `iterator` class.  I'll leave it as-is for consistency.Ideally, this code will go away soon, once we are able to use the C++ standard library.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/20044,317281035,2019-08-23T19:56:08Z,src/core/lib/gprpp/map.h,"@@ -209,6 +233,53 @@ class Map<Key, T, Compare>::iterator   GrpcMap* map_; }; +template <class Key, class T, class Compare>+class Map<Key, T, Compare>::const_iterator+    : public std::iterator<std::input_iterator_tag, Pair<Key, T>, int32_t,+                           Pair<Key, T>*, Pair<Key, T>&> {+ public:+  const_iterator(const const_iterator& iter)+      : curr_(iter.curr_), map_(iter.map_) {}+  bool operator==(const const_iterator& rhs) const {+    return (curr_ == rhs.curr_);+  }+  bool operator!=(const const_iterator& rhs) const {+    return (curr_ != rhs.curr_);+  }++  const_iterator& operator++() {+    curr_ = map_->InOrderSuccessor(curr_);+    return *this;+  }++  const_iterator operator++(int) {",Same here -- this was copied from the `iterator` class.,OK
52979934,matthewstevenson88,https://api.github.com/repos/grpc/grpc/pulls/19778,317313892,2019-08-23T21:53:26Z,include/grpcpp/security/tls_credentials_options.h,"@@ -0,0 +1,260 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPCPP_SECURITY_TLS_CREDENTIALS_OPTIONS_H+#define GRPCPP_SECURITY_TLS_CREDENTIALS_OPTIONS_H++#include <memory>+#include <vector>++#include <grpc/grpc_security.h>+#include <grpc/support/log.h>+#include <grpcpp/support/config.h>++namespace grpc_impl {+namespace experimental {++/** TLS key materials config, wrapper for grpc_tls_key_materials_config. **/+class TlsKeyMaterialsConfig {+ public:+  struct PemKeyCertPair {+    grpc::string private_key;+    grpc::string cert_chain;+  };++  /** Getters for member fields. **/+  const grpc::string pem_root_certs() const { return pem_root_certs_; }+  const std::vector<PemKeyCertPair>& pem_key_cert_pair_list() const {+    return pem_key_cert_pair_list_;+  }+  int version() const { return version_; }++  /** Setter for key materials that will be called by the user. The setter+   * transfers ownership of the arguments to the config. **/+  void set_key_materials(grpc::string pem_root_certs,+                         std::vector<PemKeyCertPair> pem_key_cert_pair_list);+  void set_version(int version) { version_ = version; };++ private:+  int version_;+  std::vector<PemKeyCertPair> pem_key_cert_pair_list_;+  grpc::string pem_root_certs_;+};++/** The following 2 functions are exposed for testing purposes. **/+grpc_tls_key_materials_config* c_key_materials(","I've changed the naming for these two functions. However, for some other of the exposed functions (e.g. ""tls_credential_reload_config_c_schedule""), I have put them in the util file, but left the C-style naming. The reason for this is that these are functions called by the C-core API's (in this case, the C version of the user-provided schedule function). Does that work? Or would you prefer these also be named as C++-style functions?",OK
52979934,matthewstevenson88,https://api.github.com/repos/grpc/grpc/pulls/19778,317317008,2019-08-23T22:08:16Z,include/grpcpp/security/tls_credentials_options.h,"@@ -0,0 +1,260 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPCPP_SECURITY_TLS_CREDENTIALS_OPTIONS_H+#define GRPCPP_SECURITY_TLS_CREDENTIALS_OPTIONS_H++#include <memory>+#include <vector>++#include <grpc/grpc_security.h>+#include <grpc/support/log.h>+#include <grpcpp/support/config.h>++namespace grpc_impl {+namespace experimental {++/** TLS key materials config, wrapper for grpc_tls_key_materials_config. **/+class TlsKeyMaterialsConfig {+ public:+  struct PemKeyCertPair {+    grpc::string private_key;+    grpc::string cert_chain;+  };++  /** Getters for member fields. **/+  const grpc::string pem_root_certs() const { return pem_root_certs_; }+  const std::vector<PemKeyCertPair>& pem_key_cert_pair_list() const {+    return pem_key_cert_pair_list_;+  }+  int version() const { return version_; }++  /** Setter for key materials that will be called by the user. The setter+   * transfers ownership of the arguments to the config. **/+  void set_key_materials(grpc::string pem_root_certs,+                         std::vector<PemKeyCertPair> pem_key_cert_pair_list);+  void set_version(int version) { version_ = version; };++ private:+  int version_;+  std::vector<PemKeyCertPair> pem_key_cert_pair_list_;+  grpc::string pem_root_certs_;+};++/** The following 2 functions are exposed for testing purposes. **/+grpc_tls_key_materials_config* c_key_materials(+    const std::shared_ptr<TlsKeyMaterialsConfig>& config);++std::shared_ptr<TlsKeyMaterialsConfig> tls_key_materials_c_to_cpp(+    const grpc_tls_key_materials_config* config);++/** TLS credential reload arguments, wraps grpc_tls_credential_reload_arg. **/+class TlsCredentialReloadArg {+ public:+  TlsCredentialReloadArg();","It was unused, so I removed it. Same for the analogous constructor in TlsServerAuthorizationCheckArg.",OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/20065,317335137,2019-08-24T00:14:43Z,test/cpp/common/timer_test.cc,"@@ -157,8 +157,7 @@ TEST_F(TimerTest, CancelSomeTimers) {  // Enable the following test after // https://github.com/grpc/grpc/issues/20049 has been fixed.-#if 0-TEST_F(TimerTest, TimerNotCanceled) {+TEST_F(TimerTest, DISABLED_TimerNotCanceled) {",`DISABLED_` prefix is preferred instead of commenting out disabled tests as it ensures that the test is compiled (and thus won't rot) while it's disabled. More details in https://github.com/google/googletest/blob/master/googletest/docs/advanced.md#temporarily-disabling-tests.,
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/20065,317371691,2019-08-24T19:07:52Z,test/cpp/common/timer_test.cc,"@@ -157,17 +157,69 @@ TEST_F(TimerTest, CancelSomeTimers) {  // Enable the following test after // https://github.com/grpc/grpc/issues/20049 has been fixed.-#if 0-TEST_F(TimerTest, TimerNotCanceled) {+TEST_F(TimerTest, DISABLED_TimerNotCanceled) {   grpc_core::ExecCtx exec_ctx;   grpc_timer timer;   grpc_timer_init(&timer, 10000,-                  GRPC_CLOSURE_CREATE(-                      [](void*, grpc_error*) {-                      },-                      nullptr, grpc_schedule_on_exec_ctx));+                  GRPC_CLOSURE_CREATE([](void*, grpc_error*) {}, nullptr,+                                      grpc_schedule_on_exec_ctx));+}++// Enable the following test after+// https://github.com/grpc/grpc/issues/20064 has been fixed.+TEST_F(TimerTest, DISABLED_CancelRace) {+  MAYBE_SKIP_TEST;+  grpc_core::ExecCtx exec_ctx;+  const int kNumTimers = 10;+  grpc_timer timers[kNumTimers];+  for (int i = 0; i < kNumTimers; ++i) {+    grpc_timer* arg = nullptr;+    if (i != 0) {+      arg = &timers[i - 1];+    }+    grpc_timer_init(&timers[i], 100,",The second param of this function is deadline. Do you intent to use `100` as deadline here? Or timeout?,OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/20008,317457573,2019-08-26T05:45:09Z,BUILDING.md,"@@ -112,6 +114,12 @@ From the grpc repository root ```sh  $ make ```+NOTE: if you get an error on linux such as 'aclocal-1.15: command not found', which can happen if you ran 'make' before installing the pre-reqs, try the following:","What if we included ""Common Problems"" / ""Build Troubleshooting"" section at the end of the doc and listed a few most common build problems? The one you mentioned would be a good candidate to include (but it seems a bit random to include it here), another one is forgetting to update/fetch the submodules etc.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/20059,317639247,2019-08-26T14:46:58Z,src/core/ext/filters/client_channel/lb_policy/xds/xds_load_balancer_api.cc,"@@ -315,7 +315,11 @@ grpc_slice XdsLrsRequestCreateAndEncode(const char* server_name) { namespace {  void LocalityStatsPopulate(envoy_api_v2_endpoint_UpstreamLocalityStats* output,+#if GRPC_USE_CPP_STD_LIB+                           Pair<const RefCountedPtr<XdsLocalityName>,","This smells like a bug in our existing `grpc_core::Map<>` implementation.  Can we try to fix it such that it has the same API as `std::map<>`, so that this conditional is not required?",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/20059,317676319,2019-08-26T16:07:35Z,src/core/ext/filters/client_channel/lb_policy/xds/xds_load_balancer_api.cc,"@@ -315,7 +315,11 @@ grpc_slice XdsLrsRequestCreateAndEncode(const char* server_name) { namespace {  void LocalityStatsPopulate(envoy_api_v2_endpoint_UpstreamLocalityStats* output,+#if GRPC_USE_CPP_STD_LIB+                           Pair<const RefCountedPtr<XdsLocalityName>,","It might be worth checking with @mhaidrygoog about the changes that would be needed in the current map implementation.  He might be able to figure out a fairly quick way to do this.Failing that, I'm fine with this conditional as a temporary thing, but please add a TODO indicating that it should go away once we've switched to always using the C++ standard library.",
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/19778,317799707,2019-08-26T21:08:40Z,include/grpcpp/security/tls_credentials_options.h,"@@ -0,0 +1,260 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPCPP_SECURITY_TLS_CREDENTIALS_OPTIONS_H+#define GRPCPP_SECURITY_TLS_CREDENTIALS_OPTIONS_H++#include <memory>+#include <vector>++#include <grpc/grpc_security.h>+#include <grpc/support/log.h>+#include <grpcpp/support/config.h>++namespace grpc_impl {+namespace experimental {++/** TLS key materials config, wrapper for grpc_tls_key_materials_config. **/+class TlsKeyMaterialsConfig {+ public:+  struct PemKeyCertPair {+    grpc::string private_key;+    grpc::string cert_chain;+  };++  /** Getters for member fields. **/+  const grpc::string pem_root_certs() const { return pem_root_certs_; }+  const std::vector<PemKeyCertPair>& pem_key_cert_pair_list() const {+    return pem_key_cert_pair_list_;+  }+  int version() const { return version_; }++  /** Setter for key materials that will be called by the user. The setter+   * transfers ownership of the arguments to the config. **/+  void set_key_materials(grpc::string pem_root_certs,+                         std::vector<PemKeyCertPair> pem_key_cert_pair_list);+  void set_version(int version) { version_ = version; };++ private:+  int version_;+  std::vector<PemKeyCertPair> pem_key_cert_pair_list_;+  grpc::string pem_root_certs_;+};++/** The following 2 functions are exposed for testing purposes. **/+grpc_tls_key_materials_config* c_key_materials(","I think it's fine to pass C++-style function parameters to C-core API's. It's also a little weird to me to mix C-style functions  with that of C++ in C++ implementations (i.e., cpp/ directory). ",OK
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/19778,317805083,2019-08-26T21:23:44Z,include/grpcpp/security/tls_credentials_options.h,"@@ -0,0 +1,260 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPCPP_SECURITY_TLS_CREDENTIALS_OPTIONS_H+#define GRPCPP_SECURITY_TLS_CREDENTIALS_OPTIONS_H++#include <memory>+#include <vector>++#include <grpc/grpc_security.h>+#include <grpc/support/log.h>+#include <grpcpp/support/config.h>++namespace grpc_impl {+namespace experimental {++/** TLS key materials config, wrapper for grpc_tls_key_materials_config. **/+class TlsKeyMaterialsConfig {+ public:+  struct PemKeyCertPair {+    grpc::string private_key;+    grpc::string cert_chain;+  };++  /** Getters for member fields. **/+  const grpc::string pem_root_certs() const { return pem_root_certs_; }+  const std::vector<PemKeyCertPair>& pem_key_cert_pair_list() const {+    return pem_key_cert_pair_list_;+  }+  int version() const { return version_; }++  /** Setter for key materials that will be called by the user. The setter+   * transfers ownership of the arguments to the config. **/+  void set_key_materials(grpc::string pem_root_certs,+                         std::vector<PemKeyCertPair> pem_key_cert_pair_list);+  void set_version(int version) { version_ = version; };++ private:+  int version_;+  std::vector<PemKeyCertPair> pem_key_cert_pair_list_;+  grpc::string pem_root_certs_;+};++/** The following 2 functions are exposed for testing purposes. **/+grpc_tls_key_materials_config* c_key_materials(+    const std::shared_ptr<TlsKeyMaterialsConfig>& config);++std::shared_ptr<TlsKeyMaterialsConfig> tls_key_materials_c_to_cpp(+    const grpc_tls_key_materials_config* config);++/** TLS credential reload arguments, wraps grpc_tls_credential_reload_arg. **/+class TlsCredentialReloadArg {+ public:+  TlsCredentialReloadArg();+  TlsCredentialReloadArg(grpc_tls_credential_reload_arg arg);+  ~TlsCredentialReloadArg();++  /** Getters for member fields. The callback function is not exposed. **/+  void* cb_user_data() const;+  std::shared_ptr<TlsKeyMaterialsConfig> key_materials_config() const;+  grpc_ssl_certificate_config_reload_status status() const;+  std::shared_ptr<grpc::string> error_details() const;++  /** Setters for member fields. **/+  void set_cb_user_data(void* cb_user_data);+  void set_key_materials_config(+      const std::shared_ptr<TlsKeyMaterialsConfig>& key_materials_config);+  void set_status(grpc_ssl_certificate_config_reload_status status);+  void set_error_details(const grpc::string& error_details);++  /** Calls the C arg's callback function. **/+  void callback();++ private:+  grpc_tls_credential_reload_arg c_arg_;+};++// Exposed for testing purposes.+int tls_credential_reload_config_c_schedule(+    void* config_user_data, grpc_tls_credential_reload_arg* arg);+void tls_credential_reload_config_c_cancel(void* config_user_data,+                                           grpc_tls_credential_reload_arg* arg);++/** TLS credential reloag config, wraps grpc_tls_credential_reload_config. **/+class TlsCredentialReloadConfig {+ public:+  TlsCredentialReloadConfig(const void* config_user_data,+                            int (*schedule)(void* config_user_data,+                                            TlsCredentialReloadArg* arg),+                            void (*cancel)(void* config_user_data,+                                           TlsCredentialReloadArg* arg),+                            void (*destruct)(void* config_user_data));+  ~TlsCredentialReloadConfig();++  int Schedule(TlsCredentialReloadArg* arg) const {+    return schedule_(config_user_data_, arg);+  }++  void Cancel(TlsCredentialReloadArg* arg) const {+    if (cancel_ == nullptr) {+      gpr_log(GPR_ERROR, ""cancel API is nullptr"");+      return;+    }+    cancel_(config_user_data_, arg);+  }+  /** Returns a C struct for the credential reload config. **/+  grpc_tls_credential_reload_config* c_credential_reload() const {+    return c_config_;+  }++ private:+  grpc_tls_credential_reload_config* c_config_;+  void* config_user_data_;+  int (*schedule_)(void* config_user_data, TlsCredentialReloadArg* arg);+  void (*cancel_)(void* config_user_data, TlsCredentialReloadArg* arg);+  void (*destruct_)(void* config_user_data);+};++/** TLS server authorization check arguments, wraps+ *  grpc_tls_server_authorization_check_arg. **/++class TlsServerAuthorizationCheckArg {+ public:+  TlsServerAuthorizationCheckArg();+  TlsServerAuthorizationCheckArg(grpc_tls_server_authorization_check_arg arg);+  ~TlsServerAuthorizationCheckArg();++  /** Getters for member fields. **/+  void* cb_user_data() const;+  int success() const;+  std::shared_ptr<grpc::string> target_name() const;+  std::shared_ptr<grpc::string> peer_cert() const;+  grpc_status_code status() const;+  std::shared_ptr<grpc::string> error_details() const;++  /** Setters for member fields. **/+  void set_cb_user_data(void* cb_user_data);+  void set_success(int success);+  void set_target_name(const grpc::string& target_name);+  void set_peer_cert(const grpc::string& peer_cert);+  void set_status(grpc_status_code status);+  void set_error_details(const grpc::string& error_details);++  /** Calls the C arg's callback function. **/+  void callback();++ private:+  grpc_tls_server_authorization_check_arg c_arg_;+};++// Exposed for testing purposes.+int tls_server_authorization_check_config_c_schedule(+    void* config_user_data, grpc_tls_server_authorization_check_arg* arg);+void tls_server_authorization_check_config_c_cancel(+    void* config_user_data, grpc_tls_server_authorization_check_arg* arg);++/** TLS server authorization check config, wraps+ *  grps_tls_server_authorization_check_config. **/+class TlsServerAuthorizationCheckConfig {+ public:+  TlsServerAuthorizationCheckConfig(+      const void* config_user_data,+      int (*schedule)(void* config_user_data,+                      TlsServerAuthorizationCheckArg* arg),+      void (*cancel)(void* config_user_data,+                     TlsServerAuthorizationCheckArg* arg),+      void (*destruct)(void* config_user_data));+  ~TlsServerAuthorizationCheckConfig();++  int Schedule(TlsServerAuthorizationCheckArg* arg) const {+    return schedule_(config_user_data_, arg);+  }++  void Cancel(TlsServerAuthorizationCheckArg* arg) const {+    if (cancel_ == nullptr) {+      gpr_log(GPR_ERROR, ""cancel API is nullptr"");+      return;+    }+    cancel_(config_user_data_, arg);+  }++  /** Creates C struct for the credential reload config. **/+  grpc_tls_server_authorization_check_config* c_server_authorization_check()+      const {+    return c_config_;+  }++ private:+  grpc_tls_server_authorization_check_config* c_config_;+  void* config_user_data_;+  int (*schedule_)(void* config_user_data, TlsServerAuthorizationCheckArg* arg);+  void (*cancel_)(void* config_user_data, TlsServerAuthorizationCheckArg* arg);+  void (*destruct_)(void* config_user_data);+};++/** TLS credentials options, wrapper for grpc_tls_credentials_options. **/+class TlsCredentialsOptions {+ public:+  /** Getters for member fields. **/+  grpc_ssl_client_certificate_request_type cert_request_type() const {+    return cert_request_type_;+  }+  std::shared_ptr<TlsKeyMaterialsConfig> key_materials_config() const {+    return key_materials_config_;+  }+  std::shared_ptr<TlsCredentialReloadConfig> credential_reload_config() const {+    return credential_reload_config_;+  }+  std::shared_ptr<TlsServerAuthorizationCheckConfig>+  server_authorization_check_config() const {+    return server_authorization_check_config_;+  }++  /** Setters for member fields. **/+  void set_cert_request_type(+      const grpc_ssl_client_certificate_request_type type) {+    cert_request_type_ = type;+  }+  void set_key_materials_config(std::shared_ptr<TlsKeyMaterialsConfig> config) {+    key_materials_config_ = std::move(config);+  }+  void set_credential_reload_config(+      std::shared_ptr<TlsCredentialReloadConfig> config) {+    credential_reload_config_ = std::move(config);+  }+  void set_server_authorization_check_config(+      std::shared_ptr<TlsServerAuthorizationCheckConfig> config) {+    server_authorization_check_config_ = std::move(config);+  }++  /** Creates C struct for TLS credential options. **/+  grpc_tls_credentials_options* c_credentials_options() const;","Sorry for making it unclear. I meant for `c_credentials_options()` API. It seems a little redundant to me to expose this API. Because 1) there will be always one-to-one mapping between C++ and C options (C options should not be created more than once for a C++ option), and 2) users should not call this API to create C version of option (i.e., it belongs to internal details). Instead I will propose to have it as a private member field which will be created within the constructor, and provide a getter API for it. HDYT?",OK
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/19778,317821527,2019-08-26T22:15:59Z,src/cpp/common/tls_credentials_options.cc,"@@ -0,0 +1,209 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpcpp/security/tls_credentials_options.h>++#include ""src/core/lib/security/credentials/tls/grpc_tls_credentials_options.h""+#include ""src/cpp/common/tls_credentials_options_util.h""++namespace grpc_impl {+namespace experimental {++/** TLS key materials config API implementation **/+void TlsKeyMaterialsConfig::set_key_materials(+    grpc::string pem_root_certs,+    std::vector<PemKeyCertPair> pem_key_cert_pair_list) {+  pem_key_cert_pair_list_ = std::move(pem_key_cert_pair_list);+  pem_root_certs_ = std::move(pem_root_certs);+}++/** TLS credential reload arg API implementation **/+TlsCredentialReloadArg::TlsCredentialReloadArg(+    grpc_tls_credential_reload_arg arg) {+  c_arg_ = arg;+}++TlsCredentialReloadArg::~TlsCredentialReloadArg() {}++void* TlsCredentialReloadArg::cb_user_data() const {+  return c_arg_.cb_user_data;+}++/** This function creates a new TlsKeyMaterialsConfig instance whose fields are+ * not shared with the corresponding key materials config fields of the+ * TlsCredentialReloadArg instance. **/+std::shared_ptr<TlsKeyMaterialsConfig>+TlsCredentialReloadArg::key_materials_config() const {+  return ConvertToCppKeyMaterialsConfig(c_arg_.key_materials_config);+}++grpc_ssl_certificate_config_reload_status TlsCredentialReloadArg::status()+    const {+  return c_arg_.status;+}++grpc::string TlsCredentialReloadArg::error_details() const {+  grpc::string cpp_error_details(c_arg_.error_details);+  return cpp_error_details;+}++void TlsCredentialReloadArg::set_cb_user_data(void* cb_user_data) {+  c_arg_.cb_user_data = cb_user_data;+}++void TlsCredentialReloadArg::set_key_materials_config(+    const std::shared_ptr<TlsKeyMaterialsConfig>& key_materials_config) {+  c_arg_.key_materials_config =+      ConvertToCKeyMaterialsConfig(key_materials_config);+}++void TlsCredentialReloadArg::set_status(+    grpc_ssl_certificate_config_reload_status status) {+  c_arg_.status = status;+}++void TlsCredentialReloadArg::set_error_details(+    const grpc::string& error_details) {+  c_arg_.error_details = gpr_strdup(error_details.c_str());+}++void TlsCredentialReloadArg::OnCredentialReloadDoneCallback() {+  c_arg_.cb(&c_arg_);+}++/** gRPC TLS credential reload config API implementation **/+TlsCredentialReloadConfig::TlsCredentialReloadConfig(",Could you please use member initializer list?,OK
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/19778,317823297,2019-08-26T22:23:06Z,src/cpp/common/tls_credentials_options.cc,"@@ -0,0 +1,209 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpcpp/security/tls_credentials_options.h>++#include ""src/core/lib/security/credentials/tls/grpc_tls_credentials_options.h""+#include ""src/cpp/common/tls_credentials_options_util.h""++namespace grpc_impl {+namespace experimental {++/** TLS key materials config API implementation **/+void TlsKeyMaterialsConfig::set_key_materials(+    grpc::string pem_root_certs,+    std::vector<PemKeyCertPair> pem_key_cert_pair_list) {+  pem_key_cert_pair_list_ = std::move(pem_key_cert_pair_list);+  pem_root_certs_ = std::move(pem_root_certs);+}++/** TLS credential reload arg API implementation **/+TlsCredentialReloadArg::TlsCredentialReloadArg(+    grpc_tls_credential_reload_arg arg) {+  c_arg_ = arg;+}++TlsCredentialReloadArg::~TlsCredentialReloadArg() {}++void* TlsCredentialReloadArg::cb_user_data() const {+  return c_arg_.cb_user_data;+}++/** This function creates a new TlsKeyMaterialsConfig instance whose fields are+ * not shared with the corresponding key materials config fields of the+ * TlsCredentialReloadArg instance. **/+std::shared_ptr<TlsKeyMaterialsConfig>+TlsCredentialReloadArg::key_materials_config() const {+  return ConvertToCppKeyMaterialsConfig(c_arg_.key_materials_config);+}++grpc_ssl_certificate_config_reload_status TlsCredentialReloadArg::status()+    const {+  return c_arg_.status;+}++grpc::string TlsCredentialReloadArg::error_details() const {+  grpc::string cpp_error_details(c_arg_.error_details);+  return cpp_error_details;+}++void TlsCredentialReloadArg::set_cb_user_data(void* cb_user_data) {+  c_arg_.cb_user_data = cb_user_data;+}++void TlsCredentialReloadArg::set_key_materials_config(+    const std::shared_ptr<TlsKeyMaterialsConfig>& key_materials_config) {+  c_arg_.key_materials_config =+      ConvertToCKeyMaterialsConfig(key_materials_config);+}++void TlsCredentialReloadArg::set_status(+    grpc_ssl_certificate_config_reload_status status) {+  c_arg_.status = status;+}++void TlsCredentialReloadArg::set_error_details(+    const grpc::string& error_details) {+  c_arg_.error_details = gpr_strdup(error_details.c_str());+}++void TlsCredentialReloadArg::OnCredentialReloadDoneCallback() {+  c_arg_.cb(&c_arg_);+}++/** gRPC TLS credential reload config API implementation **/+TlsCredentialReloadConfig::TlsCredentialReloadConfig(+    const void* config_user_data,+    int (*schedule)(void* config_user_data, TlsCredentialReloadArg* arg),+    void (*cancel)(void* config_user_data, TlsCredentialReloadArg* arg),+    void (*destruct)(void* config_user_data)) {+  config_user_data_ = const_cast<void*>(config_user_data);+  schedule_ = schedule;+  cancel_ = cancel;+  destruct_ = destruct;+  c_config_ = grpc_tls_credential_reload_config_create(+      config_user_data_, &tls_credential_reload_config_c_schedule,+      &tls_credential_reload_config_c_cancel, destruct_);+  c_config_->set_context(static_cast<void*>(this));+}++TlsCredentialReloadConfig::~TlsCredentialReloadConfig() {}++/** gRPC TLS server authorization check arg API implementation **/+TlsServerAuthorizationCheckArg::TlsServerAuthorizationCheckArg(+    grpc_tls_server_authorization_check_arg arg) {+  c_arg_ = arg;+}++TlsServerAuthorizationCheckArg::~TlsServerAuthorizationCheckArg() {}++void* TlsServerAuthorizationCheckArg::cb_user_data() const {+  return c_arg_.cb_user_data;+}++int TlsServerAuthorizationCheckArg::success() const { return c_arg_.success; }++grpc::string TlsServerAuthorizationCheckArg::target_name() const {+  grpc::string cpp_target_name(c_arg_.target_name);+  return cpp_target_name;+}++grpc::string TlsServerAuthorizationCheckArg::peer_cert() const {+  grpc::string cpp_peer_cert(c_arg_.peer_cert);+  return cpp_peer_cert;+}++grpc_status_code TlsServerAuthorizationCheckArg::status() const {+  return c_arg_.status;+}++grpc::string TlsServerAuthorizationCheckArg::error_details() const {+  grpc::string cpp_error_details(c_arg_.error_details);+  return cpp_error_details;+}++void TlsServerAuthorizationCheckArg::set_cb_user_data(void* cb_user_data) {+  c_arg_.cb_user_data = cb_user_data;+}++void TlsServerAuthorizationCheckArg::set_success(int success) {+  c_arg_.success = success;+}++void TlsServerAuthorizationCheckArg::set_target_name(+    const grpc::string& target_name) {+  c_arg_.target_name = gpr_strdup(target_name.c_str());+}++void TlsServerAuthorizationCheckArg::set_peer_cert(+    const grpc::string& peer_cert) {+  c_arg_.peer_cert = gpr_strdup(peer_cert.c_str());+}++void TlsServerAuthorizationCheckArg::set_status(grpc_status_code status) {+  c_arg_.status = status;+}++void TlsServerAuthorizationCheckArg::set_error_details(+    const grpc::string& error_details) {+  c_arg_.error_details = gpr_strdup(error_details.c_str());+}++void TlsServerAuthorizationCheckArg::OnServerAuthorizationCheckDoneCallback() {+  c_arg_.cb(&c_arg_);+}++/** gRPC TLS server authorization check config API implementation **/+TlsServerAuthorizationCheckConfig::TlsServerAuthorizationCheckConfig(",Please use initializer member list.,OK
26934891,yihuazhang,https://api.github.com/repos/grpc/grpc/pulls/19778,317830004,2019-08-26T22:49:51Z,src/cpp/common/tls_credentials_options_util.cc,"@@ -0,0 +1,137 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/cpp/common/tls_credentials_options_util.h""+#include <grpcpp/security/tls_credentials_options.h>++namespace grpc_impl {+namespace experimental {++/** Creates a new C struct for the key materials. Note that the user must free+ * the underlying pointer to private key and cert chain duplicates; they are not+ * freed when the UniquePtr<char> member variables of PemKeyCertPair are unused.+ * Similarly, the user must free the underlying pointer to c_pem_root_certs. **/+grpc_tls_key_materials_config* ConvertToCKeyMaterialsConfig(+    const std::shared_ptr<TlsKeyMaterialsConfig>& config) {+  grpc_tls_key_materials_config* c_config =+      grpc_tls_key_materials_config_create();+  ::grpc_core::InlinedVector<::grpc_core::PemKeyCertPair, 1>+      c_pem_key_cert_pair_list;+  for (auto key_cert_pair = config->pem_key_cert_pair_list().begin();+       key_cert_pair != config->pem_key_cert_pair_list().end();+       key_cert_pair++) {+    grpc_ssl_pem_key_cert_pair* ssl_pair =+        (grpc_ssl_pem_key_cert_pair*)gpr_malloc(+            sizeof(grpc_ssl_pem_key_cert_pair));+    ssl_pair->private_key = gpr_strdup(key_cert_pair->private_key.c_str());+    ssl_pair->cert_chain = gpr_strdup(key_cert_pair->cert_chain.c_str());+    ::grpc_core::PemKeyCertPair c_pem_key_cert_pair =+        ::grpc_core::PemKeyCertPair(ssl_pair);+    c_pem_key_cert_pair_list.push_back(::std::move(c_pem_key_cert_pair));+  }+  ::grpc_core::UniquePtr<char> c_pem_root_certs(+      gpr_strdup(config->pem_root_certs().c_str()));+  c_config->set_key_materials(std::move(c_pem_root_certs),+                              std::move(c_pem_key_cert_pair_list));+  c_config->set_version(config->version());+  return c_config;+}++/** Creates a new TlsKeyMaterialsConfig from a C struct config. **/+std::shared_ptr<TlsKeyMaterialsConfig> ConvertToCppKeyMaterialsConfig(+    const grpc_tls_key_materials_config* config) {+  std::shared_ptr<TlsKeyMaterialsConfig> cpp_config(+      new TlsKeyMaterialsConfig());+  std::vector<TlsKeyMaterialsConfig::PemKeyCertPair> cpp_pem_key_cert_pair_list;+  grpc_tls_key_materials_config::PemKeyCertPairList pem_key_cert_pair_list =+      config->pem_key_cert_pair_list();+  for (size_t i = 0; i < pem_key_cert_pair_list.size(); i++) {+    ::grpc_core::PemKeyCertPair key_cert_pair = pem_key_cert_pair_list[i];+    TlsKeyMaterialsConfig::PemKeyCertPair p = {+        // gpr_strdup(key_cert_pair.private_key()),+        // gpr_strdup(key_cert_pair.cert_chain())};+        key_cert_pair.private_key(), key_cert_pair.cert_chain()};+    cpp_pem_key_cert_pair_list.push_back(::std::move(p));+  }+  cpp_config->set_key_materials(std::move(config->pem_root_certs()),+                                std::move(cpp_pem_key_cert_pair_list));+  cpp_config->set_version(config->version());+  return cpp_config;+}++/** The C schedule and cancel functions for the credential reload config. **/+int tls_credential_reload_config_c_schedule(+    void* config_user_data, grpc_tls_credential_reload_arg* arg) {+  TlsCredentialReloadConfig* cpp_config =+      static_cast<TlsCredentialReloadConfig*>(arg->config->context());+  TlsCredentialReloadArg cpp_arg(*arg);+  int schedule_output = cpp_config->Schedule(&cpp_arg);+  arg->cb_user_data = cpp_arg.cb_user_data();+  arg->key_materials_config =+      ConvertToCKeyMaterialsConfig(cpp_arg.key_materials_config());+  arg->status = cpp_arg.status();+  arg->error_details = gpr_strdup(cpp_arg.error_details().c_str());+  return schedule_output;+}++void tls_credential_reload_config_c_cancel(+    void* config_user_data, grpc_tls_credential_reload_arg* arg) {+  TlsCredentialReloadConfig* cpp_config =+      static_cast<TlsCredentialReloadConfig*>(arg->config->context());+  TlsCredentialReloadArg cpp_arg(*arg);+  cpp_config->Cancel(&cpp_arg);+  arg->cb_user_data = cpp_arg.cb_user_data();+  arg->key_materials_config =+      ConvertToCKeyMaterialsConfig(cpp_arg.key_materials_config());+  arg->status = cpp_arg.status();+  arg->error_details = gpr_strdup(cpp_arg.error_details().c_str());+}++/** The C schedule and cancel functions for the server authorization check+ * config. **/+int tls_server_authorization_check_config_c_schedule(+    void* config_user_data, grpc_tls_server_authorization_check_arg* arg) {+  TlsServerAuthorizationCheckConfig* cpp_config =+      static_cast<TlsServerAuthorizationCheckConfig*>(arg->config->context());+  TlsServerAuthorizationCheckArg cpp_arg(*arg);+  int schedule_output = cpp_config->Schedule(&cpp_arg);+  arg->cb_user_data = cpp_arg.cb_user_data();+  arg->success = cpp_arg.success();+  arg->target_name = gpr_strdup(cpp_arg.target_name().c_str());+  arg->peer_cert = gpr_strdup(cpp_arg.peer_cert().c_str());+  arg->status = cpp_arg.status();+  arg->error_details = gpr_strdup(cpp_arg.error_details().c_str());+  return schedule_output;+}++void tls_server_authorization_check_config_c_cancel(+    void* config_user_data, grpc_tls_server_authorization_check_arg* arg) {+  TlsServerAuthorizationCheckConfig* cpp_config =+      static_cast<TlsServerAuthorizationCheckConfig*>(arg->config->context());+  TlsServerAuthorizationCheckArg cpp_arg(*arg);+  cpp_config->Cancel(&cpp_arg);+  arg->cb_user_data = cpp_arg.cb_user_data();+  arg->success = cpp_arg.success();+  arg->target_name = gpr_strdup(cpp_arg.target_name().c_str());",A similar memory leakage here.,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/20052,318201205,2019-08-27T17:21:09Z,src/core/lib/slice/slice_utils.h,"@@ -153,10 +153,11 @@ struct ExternallyManagedSlice : public UnmanagedMemorySlice { };  struct StaticMetadataSlice : public ManagedMemorySlice {-  StaticMetadataSlice(grpc_slice_refcount* ref, size_t length, uint8_t* bytes) {+  StaticMetadataSlice(grpc_slice_refcount* ref, size_t length,+                      const uint8_t* bytes) {     refcount = ref;     data.refcounted.length = length;-    data.refcounted.bytes = bytes;+    data.refcounted.bytes = const_cast<uint8_t*>(bytes);","`const_cast<>` is generally a code-smell indicative of a structural problem.  Why is this necessary?  We can probably live with this as a short-term thing if we know a better long-term solution that we're working toward, but I'm reticent to use this permanently.",OK
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/20052,318214630,2019-08-27T17:50:48Z,src/core/lib/slice/slice_utils.h,"@@ -153,10 +153,11 @@ struct ExternallyManagedSlice : public UnmanagedMemorySlice { };  struct StaticMetadataSlice : public ManagedMemorySlice {-  StaticMetadataSlice(grpc_slice_refcount* ref, size_t length, uint8_t* bytes) {+  StaticMetadataSlice(grpc_slice_refcount* ref, size_t length,+                      const uint8_t* bytes) {     refcount = ref;     data.refcounted.length = length;-    data.refcounted.bytes = bytes;+    data.refcounted.bytes = const_cast<uint8_t*>(bytes);","It's because grpc_slice's data pointer is uint8_t* and not const, while g_bytes is fundamentally a const bytes array since it's never-changing data.Strictly speaking, I could just change g_bytes back to non-const, and remove this const cast - this isn't something we're going to be able to match up exactly since we're not changing grpc_slice.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/20052,318222794,2019-08-27T18:08:48Z,src/core/lib/slice/slice_utils.h,"@@ -153,10 +153,11 @@ struct ExternallyManagedSlice : public UnmanagedMemorySlice { };  struct StaticMetadataSlice : public ManagedMemorySlice {-  StaticMetadataSlice(grpc_slice_refcount* ref, size_t length, uint8_t* bytes) {+  StaticMetadataSlice(grpc_slice_refcount* ref, size_t length,+                      const uint8_t* bytes) {     refcount = ref;     data.refcounted.length = length;-    data.refcounted.bytes = bytes;+    data.refcounted.bytes = const_cast<uint8_t*>(bytes);","Okay, I just took a deeper look at this, and I understand why it's happening -- it's basically a mismatch between the fact that this is a static slice whose data is known to be const and the C slice API that we're inheritting from, which can't assume that the data is const.I think I'm actually okay with this as-is, since it's a side-effect of the fact that we're inheritting from a C struct.  But please add a comment explaining why this is happening, so that it's clear why we have this code-smell.",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19938,318228436,2019-08-27T18:21:22Z,examples/python/data_transmission/README.cn.md,"@@ -0,0 +1,36 @@+## Data transmission demo for using gRPC in Python++在Python中使用gRPC时, 进行数据传输的四种方式。++- #### 简单模式 ++  没啥好说的,跟调普通方法没差","Also, can you change the Chinese naming from 简单模式 to 一元模式. I know it looks weird, but describes the semantic better.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/20092,318323160,2019-08-27T22:27:26Z,templates/tools/dockerfile/test/python_stretch_3.6_x64/Dockerfile.template,"@@ -16,5 +16,17 @@    <%include file=""../../python_stretch.include""/> -  RUN apt-get update && apt-get -t testing install -y python3.6 python3-all-dev-  RUN curl https://bootstrap.pypa.io/get-pip.py | python3.6+  RUN apt-get install -y jq zlib1g-dev libssl-dev++  RUN apt-get install -y jq build-essential libffi-dev++  RUN cd /tmp && ${'\\'}+    wget -q https://github.com/python/cpython/archive/v3.6.9.tar.gz && ${'\\'}+    tar xzvf v3.6.9.tar.gz && ${'\\'}+    cd cpython-3.6.9 && ${'\\'}+    ./configure && ${'\\'}+    make install",it seems that debian stretch no longer has python3.6 package (I tried),
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/20097,318688462,2019-08-28T16:54:32Z,third_party/py/BUILD.tpl,"@@ -2,35 +2,36 @@  package(default_visibility=[""//visibility:public""]) -# To build Python C/C++ extension on Windows, we need to link to python import library pythonXY.lib-# See https://docs.python.org/3/extending/windows.html-cc_import(-    name=""python_lib"",-    interface_library=select({-        "":windows"": "":python_import_lib"",-        # A placeholder for Unix platforms which makes --no_build happy.-        ""//conditions:default"": ""not-existing.lib"",-    }),-    system_provided=1,-)--cc_library(-    name=""python_headers"",-    hdrs=["":python_include""],-    deps=select({-        "":windows"": ["":python_lib""],-        ""//conditions:default"": [],-    }),-    includes=[""python_include""],-)- config_setting(     name=""windows"",     values={""cpu"": ""x64_windows""},     visibility=[""//visibility:public""], ) -%{PYTHON_INCLUDE_GENRULE}-%{PYTHON_IMPORT_LIB_GENRULE}+config_setting(+    name=""python2"",+    flag_values = {""@rules_python//python:python_version"": ""PY2""}+)++config_setting(+    name=""python3"",+    flag_values = {""@rules_python//python:python_version"": ""PY3""}+) +cc_library(+    name = ""python_lib"",+    deps = select({+        "":python2"": [""//_python2:_python2_lib""],+        "":python3"": [""//_python3:_python3_lib""],",No. We generate these [here](https://github.com/grpc/grpc/blob/abc384164ae9414dbd35507b0d06c62b83c798b1/third_party/py/python_configure.bzl#L282) and [here](https://github.com/grpc/grpc/blob/abc384164ae9414dbd35507b0d06c62b83c798b1/third_party/py/python_configure.bzl#L287).,
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/20097,318688650,2019-08-28T16:54:59Z,tools/bazel,"@@ -32,7 +32,7 @@ then   exec -a ""$0"" ""${BAZEL_REAL}"" ""$@"" fi -VERSION=0.26.0+VERSION=0.28.1","It should be. Sorry for the typo. Bazel 0.27 is when all of the breaking Python changes were introduced, so I had it on the brain.",
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/20097,318689485,2019-08-28T16:56:41Z,third_party/py/python_configure.bzl,"@@ -3,14 +3,15 @@  `python_configure` depends on the following environment variables: -  * `PYTHON_BIN_PATH`: location of python binary.-  * `PYTHON_LIB_PATH`: Location of python libraries.+  * `PYTHON2_BIN_PATH`: location of python binary.+  * `PYTHON2_LIB_PATH`: Location of python libraries. """"""  _BAZEL_SH = ""BAZEL_SH""-_PYTHON_BIN_PATH = ""PYTHON_BIN_PATH""-_PYTHON_LIB_PATH = ""PYTHON_LIB_PATH""-_PYTHON_CONFIG_REPO = ""PYTHON_CONFIG_REPO""+_PYTHON2_BIN_PATH = ""PYTHON2_BIN_PATH""+_PYTHON2_LIB_PATH = ""PYTHON2_LIB_PATH""+_PYTHON3_BIN_PATH = ""PYTHON3_BIN_PATH""+_PYTHON3_LIB_PATH = ""PYTHON3_LIB_PATH""","In CI, these variables are not being set. Instead, it falls back to the system defaults of `python` and `python3`. But they're available if we need to use them. This follows the pattern that Tensorflow uses, which is the only other project I know of building Cython with Bazel.",OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/20097,318689733,2019-08-28T16:57:12Z,third_party/py/variety.tpl,"@@ -0,0 +1,26 @@+package(default_visibility=[""//visibility:public""])",https://github.com/grpc/grpc/blob/abc384164ae9414dbd35507b0d06c62b83c798b1/third_party/py/python_configure.bzl#L271,
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/20097,318690856,2019-08-28T16:59:50Z,BUILD,"@@ -65,7 +65,7 @@ config_setting(  config_setting(     name = ""python3"",-    values = {""python_path"": ""python3""},+    flag_values = {""@bazel_tools//tools/python:python_version"": ""PY3""},","To be honest, I'm not sure I completely understand the intent behind the `config_setting` system in Bazel. My hope was that the `rules_python` repo would define a Python 2 config setting and a Python 3 config setting which we could then reference. Unfortunately, it appears that [the expectation is that each project will define its own `config_setting`s with the flag values provided by `rules_python`](https://github.com/bazelbuild/rules_python/blob/93d8b0af6d8ca1ee37816a829085d7092b04cc7b/python/BUILD#L43).An alternative would be to change all of our `select` statements to refer to `@local_config_python//:python3` instead of `//:python3`. I personally don't have a preference. On the one hand, I like that it allows us to eliminate this `config_setting`, but on the other hand, I've had nothing but problems with repository rules, so I'd like to depend on them as little as possible. (I understand the irony that this PR is mostly an overhaul of a repository rule)",
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/19705,318691130,2019-08-28T17:00:26Z,test/core/transport/metadata_test.cc,"@@ -286,6 +289,13 @@ static void test_user_data_works(void) {   GPR_ASSERT(grpc_mdelem_get_user_data(md, gpr_free) == ud1);   GRPC_MDELEM_UNREF(md); +  md_static = GRPC_MAKE_MDELEM(&grpc_static_mdelem_table[0],+                               GRPC_MDELEM_STORAGE_STATIC);+  grpc_mdelem_set_user_data(md_static, gpr_free, ud3);+  GPR_ASSERT(grpc_mdelem_get_user_data(md_static, gpr_free) == ","Shouldn't this also check that grpc_mdelem_get_user_data(md_static, gpr_free) == ud3?",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/20097,318714551,2019-08-28T17:53:32Z,third_party/py/variety.tpl,"@@ -0,0 +1,26 @@+package(default_visibility=[""//visibility:public""])++# To build Python C/C++ extension on Windows, we need to link to python import library pythonXY.lib+# See https://docs.python.org/3/extending/windows.html","Here is what I understand of this file is doing: this file is deeply coupled with `python_configure.bzl`. The Skylark rule will link (or copy) the Python header files. If the platform is Windows, then it create another link to the Python static library.I'm thinking this comment maybe should goto line 8 and line 19?",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/20097,318714749,2019-08-28T17:54:00Z,third_party/py/variety.tpl,"@@ -0,0 +1,26 @@+package(default_visibility=[""//visibility:public""])++# To build Python C/C++ extension on Windows, we need to link to python import library pythonXY.lib+# See https://docs.python.org/3/extending/windows.html+cc_import(+    name=""%{VARIETY_NAME}_lib"",+    interface_library=select({+        ""//:windows"": "":%{VARIETY_NAME}_import_lib"",+        # A placeholder for Unix platforms which makes --no_build happy.+        ""//conditions:default"": ""not-existing.lib"",",What will happen if Bazel tries to load this library? Is it made-up?,
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/20097,318723333,2019-08-28T18:14:09Z,third_party/py/BUILD.tpl,"@@ -2,35 +2,36 @@  package(default_visibility=[""//visibility:public""]) -# To build Python C/C++ extension on Windows, we need to link to python import library pythonXY.lib-# See https://docs.python.org/3/extending/windows.html-cc_import(-    name=""python_lib"",-    interface_library=select({-        "":windows"": "":python_import_lib"",-        # A placeholder for Unix platforms which makes --no_build happy.-        ""//conditions:default"": ""not-existing.lib"",-    }),-    system_provided=1,-)--cc_library(-    name=""python_headers"",-    hdrs=["":python_include""],-    deps=select({-        "":windows"": ["":python_lib""],-        ""//conditions:default"": [],-    }),-    includes=[""python_include""],-)- config_setting(     name=""windows"",     values={""cpu"": ""x64_windows""},     visibility=[""//visibility:public""], ) -%{PYTHON_INCLUDE_GENRULE}-%{PYTHON_IMPORT_LIB_GENRULE}+config_setting(+    name=""python2"",+    flag_values = {""@rules_python//python:python_version"": ""PY2""}+)++config_setting(+    name=""python3"",+    flag_values = {""@rules_python//python:python_version"": ""PY3""}+) +cc_library(+    name = ""python_lib"",+    deps = select({+        "":python2"": [""//_python2:_python2_lib""],+        "":python3"": [""//_python3:_python3_lib""],+        ""//conditions:default"": [""not-existing.lib""],+    })+) +cc_library(+    name = ""python_headers"",+    deps = select({+        "":python2"": [""//_python2:_python2_headers""],+        "":python3"": [""//_python3:_python3_headers""],+        ""//conditions:default"": [""not-existing.headers""],","In the previous version, the `python_headers` depends on the `python_lib`. Does the new version still need this dependency? If not, can we remove `python_lib`?",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/20097,318725251,2019-08-28T18:18:26Z,BUILD,"@@ -65,7 +65,7 @@ config_setting(  config_setting(     name = ""python3"",-    values = {""python_path"": ""python3""},+    flag_values = {""@bazel_tools//tools/python:python_version"": ""PY3""},","Since we have to add our own `config_setting`, I think we can add a Python 2 version of it.I personally prefer `//:python3` than the longer version, it seems the duplication of the code decouples the `config_setting` with generated repository rule.",OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/20097,318728706,2019-08-28T18:26:44Z,third_party/py/python_configure.bzl,"@@ -3,14 +3,15 @@  `python_configure` depends on the following environment variables: -  * `PYTHON_BIN_PATH`: location of python binary.-  * `PYTHON_LIB_PATH`: Location of python libraries.+  * `PYTHON2_BIN_PATH`: location of python binary.+  * `PYTHON2_LIB_PATH`: Location of python libraries. """"""  _BAZEL_SH = ""BAZEL_SH""-_PYTHON_BIN_PATH = ""PYTHON_BIN_PATH""-_PYTHON_LIB_PATH = ""PYTHON_LIB_PATH""-_PYTHON_CONFIG_REPO = ""PYTHON_CONFIG_REPO""+_PYTHON2_BIN_PATH = ""PYTHON2_BIN_PATH""+_PYTHON2_LIB_PATH = ""PYTHON2_LIB_PATH""+_PYTHON3_BIN_PATH = ""PYTHON3_BIN_PATH""+_PYTHON3_LIB_PATH = ""PYTHON3_LIB_PATH""","`_PYTHON3_BIN_PATH` itself does not get set at all. *If* the environment variable is set by the user or by `bazel.rc`, it will get picked up. If not, the repository rule will supply `python3`. You can see that happening [here](https://github.com/grpc/grpc/blob/d3cd387e03e3cbf99f71c144e371aeade4ad7357/third_party/py/python_configure.bzl#L142) and [here](https://github.com/grpc/grpc/blob/d3cd387e03e3cbf99f71c144e371aeade4ad7357/third_party/py/python_configure.bzl#L289).",
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/20097,318729526,2019-08-28T18:28:27Z,BUILD,"@@ -65,7 +65,7 @@ config_setting(  config_setting(     name = ""python3"",-    values = {""python_path"": ""python3""},+    flag_values = {""@bazel_tools//tools/python:python_version"": ""PY3""},","We *could*, but we don't actually reference it anywhere. We use `//conditions:default`. I suppose we could make them explicit, but I think the way we have things now is also fine.",
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/20097,318729967,2019-08-28T18:29:24Z,third_party/py/variety.tpl,"@@ -0,0 +1,26 @@+package(default_visibility=[""//visibility:public""])++# To build Python C/C++ extension on Windows, we need to link to python import library pythonXY.lib+# See https://docs.python.org/3/extending/windows.html+cc_import(+    name=""%{VARIETY_NAME}_lib"",+    interface_library=select({+        ""//:windows"": "":%{VARIETY_NAME}_import_lib"",+        # A placeholder for Unix platforms which makes --no_build happy.+        ""//conditions:default"": ""not-existing.lib"",","It will fail to load the non-existent target. That's the intent here. Apparently, some linters will fail if you don't supply a `//conditions:default` case.",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/19705,318802509,2019-08-28T21:32:53Z,test/core/transport/metadata_test.cc,"@@ -286,6 +289,13 @@ static void test_user_data_works(void) {   GPR_ASSERT(grpc_mdelem_get_user_data(md, gpr_free) == ud1);   GRPC_MDELEM_UNREF(md); +  md_static = GRPC_MAKE_MDELEM(&grpc_static_mdelem_table[0],+                               GRPC_MDELEM_STORAGE_STATIC);+  grpc_mdelem_set_user_data(md_static, gpr_free, ud3);+  GPR_ASSERT(grpc_mdelem_get_user_data(md_static, gpr_free) == ","Looking at the code, that condition would not hold true. That being said, I am not sure this test is adding necessary value but I'm not against adding it either",
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/19296,318872943,2019-08-29T03:30:31Z,src/core/lib/iomgr/tcp_posix.cc,"@@ -912,6 +1186,133 @@ void tcp_shutdown_buffer_list(grpc_tcp* tcp) { #else #define MAX_WRITE_IOVEC 1000 #endif+static bool do_tcp_flush_zerocopy(grpc_tcp* tcp, TcpZcpSendRecord* record,","Can't; tcp_flush has a fundamentally different handling fo the slice_buffer passed in (proactively unrefs slices that have been sent already, and must yield an empty slice buffer by the time grpc_endpoint_write is done).The zerocopy version is different primarily because of the need for the slices to live longer.",OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/20105,319239996,2019-08-29T19:41:24Z,test/cpp/common/time_jump_test.cc,"@@ -0,0 +1,125 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <spawn.h>+#include <sstream>+#include <string>+#include <thread>+#include <vector>++#include <grpc/grpc.h>+#include <grpc/support/log.h>+#include <gtest/gtest.h>++#include ""src/core/lib/gprpp/sync.h""+#include ""src/core/lib/iomgr/closure.h""+#include ""src/core/lib/iomgr/error.h""+#include ""src/core/lib/iomgr/exec_ctx.h""+#include ""src/core/lib/iomgr/timer.h""+#include ""src/core/lib/iomgr/timer_manager.h""+#include ""test/core/util/test_config.h""++extern char** environ;++void run_cmd(const char* cmd) {+  pid_t pid;+  const char* argv[] = {const_cast<const char*>(""sh""),+                        const_cast<const char*>(""-c""), cmd, nullptr};+  int status;++  status = posix_spawn(&pid, const_cast<const char*>(""/bin/sh""), nullptr,+                       nullptr, const_cast<char**>(argv), environ);+  if (status == 0) {+    if (waitpid(pid, &status, 0) == -1) {+      perror(""waitpid"");+    }+  }+}++class TimeJumpTest : public ::testing::TestWithParam<std::string> {+ protected:+  void SetUp() override { grpc_init(); }+  void TearDown() override {+    run_cmd(""sudo sntp -sS pool.ntp.org"");+    grpc_shutdown_blocking();+  }+};++std::vector<std::string> CreateTestScenarios() {+  return {""-1M"", ""+1M"", ""-1H"", ""+1H"", ""-1d"", ""+1d"", ""-1y"", ""+1y""};+}+INSTANTIATE_TEST_CASE_P(TimeJump, TimeJumpTest,+                        ::testing::ValuesIn(CreateTestScenarios()));++TEST_P(TimeJumpTest, TimerRunning) {+  grpc_core::ExecCtx exec_ctx;+  grpc_timer timer;+  grpc_timer_init(&timer, grpc_core::ExecCtx::Get()->Now() + 3000,+                  GRPC_CLOSURE_CREATE(+                      [](void*, grpc_error* error) {+                        GPR_ASSERT(error == GRPC_ERROR_CANCELLED);+                      },+                      nullptr, grpc_schedule_on_exec_ctx));+  gpr_sleep_until(grpc_timeout_milliseconds_to_deadline(100));+  std::ostringstream cmd;+  cmd << ""sudo date `date -v"" << GetParam() << "" \""+%m%d%H%M%y\""`"";","I was not able to build timer tests in the old code, maybe some incompatibility with gcc version?```./src/core/lib/transport/static_metadata.h:244:14: error: unknown type name 'grpc_slice_refcount_vtable'; did you mean 'grpc_slice_refcount'?extern const grpc_slice_refcount_vtable grpc_static_metadata_vtable;             ^~~~~~~~~~~~~~~~~~~~~~~~~~             grpc_slice_refcount/usr/local/include/grpc/impl/codegen/slice.h:50:8: note: 'grpc_slice_refcount' declared here```",
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/20035,319249620,2019-08-29T20:07:30Z,src/core/ext/filters/client_channel/client_channel.cc,"@@ -1568,13 +1424,84 @@ ChannelData::~ChannelData() {   // Stop backup polling.   grpc_client_channel_stop_backup_polling(interested_parties_);   grpc_pollset_set_destroy(interested_parties_);-  GRPC_COMBINER_UNREF(data_plane_combiner_, ""client_channel"");   GRPC_COMBINER_UNREF(combiner_, ""client_channel"");   GRPC_ERROR_UNREF(disconnect_error_.Load(MemoryOrder::RELAXED));   grpc_connectivity_state_destroy(&state_tracker_);   gpr_mu_destroy(&info_mu_); } +void ChannelData::UpdateStateAndPickerLocked(+    grpc_connectivity_state state, const char* reason,+    UniquePtr<LoadBalancingPolicy::SubchannelPicker> picker) {+  // Clean the control plane when entering IDLE.+  if (picker_ == nullptr) {+    health_check_service_name_.reset();+    saved_service_config_.reset();+    received_first_resolver_result_ = false;+  }+  // Update connectivity state.+  grpc_connectivity_state_set(&state_tracker_, state, reason);+  if (channelz_node_ != nullptr) {+    channelz_node_->SetConnectivityState(state);+    channelz_node_->AddTraceEvent(+        channelz::ChannelTrace::Severity::Info,+        grpc_slice_from_static_string(+            channelz::ChannelNode::GetChannelConnectivityStateChangeString(+                state)));+  }+  // Grab data plane lock to do subchannel updates and update the picker.+  {+    MutexLock lock(&data_plane_mu_);+    // Handle subchannel updates.+    for (auto& p : pending_subchannel_updates_) {+      if (GRPC_TRACE_FLAG_ENABLED(grpc_client_channel_routing_trace)) {+        gpr_log(GPR_INFO,+                ""chand=%p: updating subchannel wrapper %p data plane ""+                ""connected_subchannel to %p"",+                this, p.first.get(), p.second.get());+      }+      p.first->set_connected_subchannel_in_data_plane(std::move(p.second));+    }+    // Update picker.+    picker_ = std::move(picker);+    // Clean the data plane if the updated picker is nullptr.+    if (picker_ == nullptr) {+      received_service_config_data_ = false;+      retry_throttle_data_.reset();",I see. Sorry if I'm missing something but we can probably move the wrapped pointer to a local `unique_ptr` variable by simply swaping the `unique_ptr`s.  This way `retry_throttle_data_` and `service_config_` would be set to `nullptr` under lock but the deallocation process happens outside the critical region.,OK
52979934,matthewstevenson88,https://api.github.com/repos/grpc/grpc/pulls/19778,319577290,2019-08-30T15:59:34Z,src/cpp/common/tls_credentials_options.cc,"@@ -0,0 +1,213 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include <grpcpp/security/tls_credentials_options.h>++#include ""src/core/lib/security/credentials/tls/grpc_tls_credentials_options.h""+#include ""src/cpp/common/tls_credentials_options_util.h""++namespace grpc_impl {+namespace experimental {++/** TLS key materials config API implementation **/+void TlsKeyMaterialsConfig::set_key_materials(+    grpc::string pem_root_certs,+    std::vector<PemKeyCertPair> pem_key_cert_pair_list) {+  pem_key_cert_pair_list_ = std::move(pem_key_cert_pair_list);+  pem_root_certs_ = std::move(pem_root_certs);+}++/** TLS credential reload arg API implementation **/+TlsCredentialReloadArg::~TlsCredentialReloadArg() {}++void* TlsCredentialReloadArg::cb_user_data() const {+  return c_arg_->cb_user_data;+}++/** This function creates a new TlsKeyMaterialsConfig instance whose fields are+ * not shared with the corresponding key materials config fields of the+ * TlsCredentialReloadArg instance. **/+std::shared_ptr<TlsKeyMaterialsConfig>+TlsCredentialReloadArg::key_materials_config() const {+  return ConvertToCppKeyMaterialsConfig(c_arg_->key_materials_config);+}++grpc_ssl_certificate_config_reload_status TlsCredentialReloadArg::status()+    const {+  return c_arg_->status;+}++grpc::string TlsCredentialReloadArg::error_details() const {+  grpc::string cpp_error_details(c_arg_->error_details);+  return cpp_error_details;+}++void TlsCredentialReloadArg::set_cb_user_data(void* cb_user_data) {+  c_arg_->cb_user_data = cb_user_data;+}++void TlsCredentialReloadArg::set_key_materials_config(+    const std::shared_ptr<TlsKeyMaterialsConfig>& key_materials_config) {+  c_arg_->key_materials_config =+      ConvertToCKeyMaterialsConfig(key_materials_config);+}++void TlsCredentialReloadArg::set_status(+    grpc_ssl_certificate_config_reload_status status) {+  c_arg_->status = status;+}++void TlsCredentialReloadArg::set_error_details(+    const grpc::string& error_details) {+  c_arg_->error_details = gpr_strdup(error_details.c_str());+}++void TlsCredentialReloadArg::OnCredentialReloadDoneCallback() {+  c_arg_->cb(c_arg_);+}++/** gRPC TLS credential reload config API implementation **/+TlsCredentialReloadConfig::TlsCredentialReloadConfig(+    const void* config_user_data,+    int (*schedule)(void* config_user_data, TlsCredentialReloadArg* arg),+    void (*cancel)(void* config_user_data, TlsCredentialReloadArg* arg),+    void (*destruct)(void* config_user_data))+    : config_user_data_(const_cast<void*>(config_user_data)),+      schedule_(schedule),+      cancel_(cancel),+      destruct_(destruct) {+  c_config_ = grpc_tls_credential_reload_config_create(+      config_user_data_, &TlsCredentialReloadConfigCSchedule,+      &TlsCredentialReloadConfigCCancel, destruct_);+  c_config_->set_context(static_cast<void*>(this));+}++TlsCredentialReloadConfig::~TlsCredentialReloadConfig() {+  ::grpc_core::Delete(c_config_);+}++/** gRPC TLS server authorization check arg API implementation **/+TlsServerAuthorizationCheckArg::~TlsServerAuthorizationCheckArg() {}++void* TlsServerAuthorizationCheckArg::cb_user_data() const {+  return c_arg_->cb_user_data;+}++int TlsServerAuthorizationCheckArg::success() const { return c_arg_->success; }++grpc::string TlsServerAuthorizationCheckArg::target_name() const {+  grpc::string cpp_target_name(c_arg_->target_name);+  return cpp_target_name;+}++grpc::string TlsServerAuthorizationCheckArg::peer_cert() const {+  grpc::string cpp_peer_cert(c_arg_->peer_cert);+  return cpp_peer_cert;+}++grpc_status_code TlsServerAuthorizationCheckArg::status() const {+  return c_arg_->status;+}++grpc::string TlsServerAuthorizationCheckArg::error_details() const {+  grpc::string cpp_error_details(c_arg_->error_details);+  return cpp_error_details;+}++void TlsServerAuthorizationCheckArg::set_cb_user_data(void* cb_user_data) {+  c_arg_->cb_user_data = cb_user_data;+}++void TlsServerAuthorizationCheckArg::set_success(int success) {+  c_arg_->success = success;+}++void TlsServerAuthorizationCheckArg::set_target_name(+    const grpc::string& target_name) {+  c_arg_->target_name = gpr_strdup(target_name.c_str());+}++void TlsServerAuthorizationCheckArg::set_peer_cert(+    const grpc::string& peer_cert) {+  c_arg_->peer_cert = gpr_strdup(peer_cert.c_str());+}++void TlsServerAuthorizationCheckArg::set_status(grpc_status_code status) {+  c_arg_->status = status;+}++void TlsServerAuthorizationCheckArg::set_error_details(+    const grpc::string& error_details) {+  c_arg_->error_details = gpr_strdup(error_details.c_str());+}++void TlsServerAuthorizationCheckArg::OnServerAuthorizationCheckDoneCallback() {+  c_arg_->cb(c_arg_);+}++/** gRPC TLS server authorization check config API implementation **/+TlsServerAuthorizationCheckConfig::TlsServerAuthorizationCheckConfig(+    const void* config_user_data,+    int (*schedule)(void* config_user_data,+                    TlsServerAuthorizationCheckArg* arg),+    void (*cancel)(void* config_user_data, TlsServerAuthorizationCheckArg* arg),+    void (*destruct)(void* config_user_data))+    : config_user_data_(const_cast<void*>(config_user_data)),+      schedule_(schedule),+      cancel_(cancel),+      destruct_(destruct) {+  c_config_ = grpc_tls_server_authorization_check_config_create(+      config_user_data_, &TlsServerAuthorizationCheckConfigCSchedule,+      &TlsServerAuthorizationCheckConfigCCancel, destruct_);+  c_config_->set_context(static_cast<void*>(this));+}++TlsServerAuthorizationCheckConfig::~TlsServerAuthorizationCheckConfig() {+  ::grpc_core::Delete(c_config_);+}++/** gRPC TLS credential options API implementation **/+TlsCredentialsOptions::TlsCredentialsOptions(+    grpc_ssl_client_certificate_request_type cert_request_type,+    std::shared_ptr<TlsKeyMaterialsConfig> key_materials_config,+    std::shared_ptr<TlsCredentialReloadConfig> credential_reload_config,+    std::shared_ptr<TlsServerAuthorizationCheckConfig>+        server_authorization_check_config)+    : cert_request_type_(cert_request_type),+      key_materials_config_(std::move(key_materials_config)),+      credential_reload_config_(std::move(credential_reload_config)),+      server_authorization_check_config_(+          std::move(server_authorization_check_config)) {+  c_credentials_options_ = grpc_tls_credentials_options_create();+  grpc_tls_credentials_options_set_cert_request_type(c_credentials_options_,+                                                     cert_request_type_);+  grpc_tls_credentials_options_set_key_materials_config(+      c_credentials_options_,+      ConvertToCKeyMaterialsConfig(key_materials_config_));+  grpc_tls_credentials_options_set_credential_reload_config(+      c_credentials_options_, credential_reload_config_->c_config());+  grpc_tls_credentials_options_set_server_authorization_check_config(+      c_credentials_options_, server_authorization_check_config_->c_config());+}++TlsCredentialsOptions::~TlsCredentialsOptions() {+  gpr_free(c_credentials_options_);","Actually I can't use Delete here - doing so creates an error in the `TlsCredentialsOptionsCppToC` unit test. The reason is the following: the user creates `TlsKeyMaterialsConfig`, `TlsCredentialReloadConfig`, and/or `TlsServerAuthorizationCheckConfig` objects, and then passes them to the constructor of `TlsCredentialsOptions`. The constructor assigns the underlying C config of `TlsCredentialReloadConfig` is used to instantiate `c_credentials_options_` (and similarly for server authorization). Now, if the destructor of `TlsCredentialsOptions` uses `Delete`, then it frees the C config underlying `TlsCredentialReloadConfig`. Then, since the `TlsCredentialReloadConfig` object was created prior the `TlsCredentialsOptions` object , its destructor is still called and it tries to free the C config again, hence the error.",OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/19705,319642949,2019-08-30T19:09:17Z,test/core/transport/metadata_test.cc,"@@ -286,6 +289,13 @@ static void test_user_data_works(void) {   GPR_ASSERT(grpc_mdelem_get_user_data(md, gpr_free) == ud1);   GRPC_MDELEM_UNREF(md); +  md_static = GRPC_MAKE_MDELEM(&grpc_static_mdelem_table[0],+                               GRPC_MDELEM_STORAGE_STATIC);+  grpc_mdelem_set_user_data(md_static, gpr_free, ud3);+  GPR_ASSERT(grpc_mdelem_get_user_data(md_static, gpr_free) == ",Why wouldn't it hold true? Aren't we setting md_static to have the user data ud3?,
9566254,apolcyn,https://api.github.com/repos/grpc/grpc/pulls/19792,320402570,2019-09-03T17:56:50Z,src/csharp/Grpc.Core.Api/SerializationContext.cs,"@@ -27,13 +28,31 @@ public abstract class SerializationContext     {         /// <summary>         /// Use the byte array as serialized form of current message and mark serialization process as complete.-        /// Complete() can only be called once. By calling this method the caller gives up the ownership of the+        /// <c>Complete()</c> can only be called once. By calling this method the caller gives up the ownership of the","doc comment nit: the `Complete()` signature here should include the parameter, since it's overloaded?",
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19987,320471299,2019-09-03T20:47:56Z,src/core/lib/surface/server.cc,"@@ -943,9 +943,19 @@ static void destroy_channel_elem(grpc_channel_element* elem) {   channel_data* chand = static_cast<channel_data*>(elem->channel_data);   if (chand->registered_methods) {     for (i = 0; i < chand->registered_method_slots; i++) {-      grpc_slice_unref_internal(chand->registered_methods[i].method);+      // TODO(arjunroy) : Unref is a nop for ExternallyManagedSlice.","It's not clear to me how this is going to work once we add these methods to all slice types.  What I'd ideally like to see here is the ability to use `RefCountedPtr<>` for slices, so that the compiler can enforce ownership semantics.  But maybe that requires making them virtual methods, which will hurt performance?In any case, I'd really prefer to leave the `grpc_slice_unref_internal()` calls in place until we have a full solution for all slice types.  I don't care whether that happens as part of this PR or whether we defer that work to a subsequent PR, but I'd rather not merge a change that does one part without the other.",OK
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/19705,320507349,2019-09-03T22:39:29Z,test/core/transport/metadata_test.cc,"@@ -286,6 +289,13 @@ static void test_user_data_works(void) {   GPR_ASSERT(grpc_mdelem_get_user_data(md, gpr_free) == ud1);   GRPC_MDELEM_UNREF(md); +  md_static = GRPC_MAKE_MDELEM(&grpc_static_mdelem_table[0],+                               GRPC_MDELEM_STORAGE_STATIC);+  grpc_mdelem_set_user_data(md_static, gpr_free, ud3);+  GPR_ASSERT(grpc_mdelem_get_user_data(md_static, gpr_free) == ","for static metadata, we do not make changes to the user data associated with it",OK
8952658,hcaseyal,https://api.github.com/repos/grpc/grpc/pulls/19705,320512744,2019-09-03T23:01:47Z,test/core/transport/metadata_test.cc,"@@ -286,6 +289,13 @@ static void test_user_data_works(void) {   GPR_ASSERT(grpc_mdelem_get_user_data(md, gpr_free) == ud1);   GRPC_MDELEM_UNREF(md); +  md_static = GRPC_MAKE_MDELEM(&grpc_static_mdelem_table[0],+                               GRPC_MDELEM_STORAGE_STATIC);+  grpc_mdelem_set_user_data(md_static, gpr_free, ud3);+  GPR_ASSERT(grpc_mdelem_get_user_data(md_static, gpr_free) == ",Why do we allow users to call grpc_mdelem_set_user_data on static metadata if it's a no-op? That seems like a pretty confusing API.,
730,blowmage,https://api.github.com/repos/grpc/grpc/pulls/17651,320839916,2019-09-04T15:54:50Z,src/ruby/lib/grpc/generic/client_stub.rb,"@@ -334,17 +338,18 @@ def server_streamer(method, req, marshal, unmarshal,       if return_op         # return the operation view of the active_call; define #execute         # as a new method for this instance that invokes #server_streamer-        c.merge_metadata_to_send(metadata)",This is the call that is causing the tests to fail. The metadata is sent before the interceptors have a chance to run and add additional metadata values.,OK
25311427,vam-google,https://api.github.com/repos/grpc/grpc/pulls/20150,320865567,2019-09-04T16:50:31Z,bazel/generate_cc.bzl,"@@ -6,7 +6,7 @@ directly.  load(     ""//bazel:protobuf.bzl"",-    ""get_include_protoc_args"",+    ""get_include_directory"",","I think in ""first version"" of this change it this was required (I do not remember details), but now, when I look at it, yes, I could leave `get_include_protoc_args` untouched. I'm fine with putting `get_include_protoc_args` back, but the main reasons why i would like to keep it as is:- `get_include_protoc_args` did not (and could not) specify `--proto_path` completely (only a portion of it). Notice how every time `get_include_protoc_args` was called there were subsequent explicit additions to `--proto_path` rigth after it. In other words, it is hard for me to find a clear area of responsibility of this method. This method encapsulated the `--proto_path` argument, but it was not doing it completely. Extracting the gist of this method (i.e. `get_include_directory`) in its own top-level method, allows us to specify `--proto_path` consistently everywhere (i.e. `--proto_path` argument name is specified explicitly in the rule implementation multiple times, but the values of the arguments are calculated by functions)- In general its seems like the current pattern in the `grpc/bazel` rules implementaiton is: calculation of argument values is done in shared functions (like `get_include_directory`) but the actual name of the argument (like `--proto_path`, `--python_out`, `--cpp_out` etc) is specified esplicitly in each rule implementation. There is an exception though - the `--plugin` argument.In other words, I'm ok with reverting this, but unless you have strong opinion about it, I would prefer to keep it as is. Please let me know what you think about it. ",
25311427,vam-google,https://api.github.com/repos/grpc/grpc/pulls/20150,320874696,2019-09-04T17:11:41Z,bazel/protobuf.bzl,"@@ -153,19 +155,75 @@ def get_proto_arguments(protos, genfiles_dir_path):     arguments = []     for proto in protos:         massaged_path = proto.path-        if massaged_path.startswith(genfiles_dir_path):+        if is_in_virtual_imports(proto):+            incl_directory = get_include_directory(proto)+            if massaged_path.startswith(incl_directory):+                massaged_path = massaged_path[len(incl_directory) + 1:]+        elif massaged_path.startswith(genfiles_dir_path):             massaged_path = proto.path[len(genfiles_dir_path) + 1:]         arguments.append(massaged_path)+     return arguments  def declare_out_files(protos, context, generated_file_format):     """"""Declares and returns the files to be generated.""""""++    out_file_paths = []+    for proto in protos:+        if not is_in_virtual_imports(proto):+            out_file_paths.append(proto.basename)+        else:+            path = proto.path[proto.path.index(_VIRTUAL_IMPORTS) + 1:]+            # TODO: uncomment if '.' path is chosen over","This is a effectively my question to you: Which one should we prefer (the uncommented path calculation, or the commented). Please check the PR description for more details:- - - - - **Another option would be to skip** the `_virtual_imports/<name_of_proto_library_target>` the suffix for the generated python stubs, which will make the path look like the following:```bazel-bin/google/firestore/v1beta1/google/cloud/firestore_v1beta1/proto/firestore_pb2.py```That will make using generated stubs simpler and cleaner (no need to specify imports argument), but it will make it inconsistent with the other rules (like cc_proto_library) and also more susceptible to naming conflicts (if there is already something under the generated path).- - - - - To turn on the ""other"" option we would need to uncomment the TODO's. If we choose to keep the option 1 (i.e. the current state of this PR), I'll just delete the TODO's and the commented code segments they belong to.",OK
25311427,vam-google,https://api.github.com/repos/grpc/grpc/pulls/20150,320879506,2019-09-04T17:22:33Z,bazel/test/python_test_repo/BUILD,"@@ -60,3 +60,54 @@ py_test(     ],     python_version = ""PY3"", )++# Test compatibility of py_proto_library and py_grpc_library rules with+# proto_library targets as deps when the latter use import_prefix and/or+# strip_import_prefix arguments+proto_library(+    name = ""helloworld_moved_proto"",+    srcs = [""helloworld.proto""],+    deps = [+        ""@com_google_protobuf//:duration_proto"",+        ""@com_google_protobuf//:timestamp_proto"",+    ],+    import_prefix = ""google/cloud"",+    strip_import_prefix = """"+)++py_proto_library(+    name = ""helloworld_moved_py_pb2"",+    deps = ["":helloworld_moved_proto""],+)++py_grpc_library(+    name = ""helloworld_moved_py_pb2_grpc"",+    srcs = ["":helloworld_moved_proto""],+    deps = ["":helloworld_moved_py_pb2""],+)++py_test(+    name = ""import_moved_test"",+    main = ""helloworld.py"",+    srcs = [""helloworld.py""],+    deps = [+        "":helloworld_moved_py_pb2"",+        "":helloworld_moved_py_pb2_grpc"",+        "":duration_py_pb2"",+        "":timestamp_py_pb2"",+    ],+    imports = [+        ""_virtual_imports/helloworld_moved_proto"",","I think it is strictly a bad practice... Enabling the TODOs will allow us to avoid doing this, but with cost of making `py_proto_library` inconsistent with `cc_proto_library`.",
25311427,vam-google,https://api.github.com/repos/grpc/grpc/pulls/20150,320883293,2019-09-04T17:30:49Z,bazel/test/python_test_repo/.bazelrc,"@@ -0,0 +1,3 @@+build:python3 --python_path=python3","Can you please clarify your comment? This is `.bazelrc` file for the test ""sub-workspace"". This is needed, because `py_proot_library` rules break on our workstations with bazel 0.27.0+.Starting from this version Bazel started resolving python differently and instead of resolving to Python 2.7 by default it resolves to Python 3.6. This breaks python builds, because of the `enum34` dependency (imported here https://github.com/grpc/grpc/blob/master/bazel/grpc_python_deps.bzl#L25 (which is not supported after Python3.4 or something and conflicts with the built in enum in python)). ",OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/20150,320887154,2019-09-04T17:39:30Z,bazel/test/python_test_repo/.bazelrc,"@@ -0,0 +1,3 @@+build:python3 --python_path=python3","Right. We dealt with this problem in the PR I linked above. And part of the solution is to explicitly removing the usage of the `python_path` flag. All that should be necessary now is to remove the subworkspace's `.bazelrc` and to explicitly add a `python_version` attribute to the tests.The diff is a bit messed up in the unreversion PR I linked, but in [the original PR](https://github.com/gnossen/grpc/blob/e70788364bf38947e9d3afb820800b14e44829b9/bazel/python_rules.bzl#L183), we switched to using a custom `py2and3_test` for every test.",
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/20150,320888385,2019-09-04T17:42:25Z,bazel/test/python_test_repo/BUILD,"@@ -60,3 +60,54 @@ py_test(     ],     python_version = ""PY3"", )++# Test compatibility of py_proto_library and py_grpc_library rules with+# proto_library targets as deps when the latter use import_prefix and/or+# strip_import_prefix arguments+proto_library(+    name = ""helloworld_moved_proto"",+    srcs = [""helloworld.proto""],+    deps = [+        ""@com_google_protobuf//:duration_proto"",+        ""@com_google_protobuf//:timestamp_proto"",+    ],+    import_prefix = ""google/cloud"",+    strip_import_prefix = """"+)++py_proto_library(+    name = ""helloworld_moved_py_pb2"",+    deps = ["":helloworld_moved_proto""],+)++py_grpc_library(+    name = ""helloworld_moved_py_pb2_grpc"",+    srcs = ["":helloworld_moved_proto""],+    deps = ["":helloworld_moved_py_pb2""],+)++py_test(+    name = ""import_moved_test"",+    main = ""helloworld.py"",+    srcs = [""helloworld.py""],+    deps = [+        "":helloworld_moved_py_pb2"",+        "":helloworld_moved_py_pb2_grpc"",+        "":duration_py_pb2"",+        "":timestamp_py_pb2"",+    ],+    imports = [+        ""_virtual_imports/helloworld_moved_proto"",","If `cc_proto_library` already requires users to reference `_virtual_imports` in their `#include`s, that sounds as good as an API commitment from the Bazel team, but I would like to hear back from them before we make a decision.",
25311427,vam-google,https://api.github.com/repos/grpc/grpc/pulls/20150,320949966,2019-09-04T20:05:40Z,bazel/test/python_test_repo/BUILD,"@@ -60,3 +60,54 @@ py_test(     ],     python_version = ""PY3"", )++# Test compatibility of py_proto_library and py_grpc_library rules with+# proto_library targets as deps when the latter use import_prefix and/or+# strip_import_prefix arguments+proto_library(+    name = ""helloworld_moved_proto"",+    srcs = [""helloworld.proto""],+    deps = [+        ""@com_google_protobuf//:duration_proto"",+        ""@com_google_protobuf//:timestamp_proto"",+    ],+    import_prefix = ""google/cloud"",+    strip_import_prefix = """"+)++py_proto_library(+    name = ""helloworld_moved_py_pb2"",+    deps = ["":helloworld_moved_proto""],+)++py_grpc_library(+    name = ""helloworld_moved_py_pb2_grpc"",+    srcs = ["":helloworld_moved_proto""],+    deps = ["":helloworld_moved_py_pb2""],+)++py_test(+    name = ""import_moved_test"",+    main = ""helloworld.py"",+    srcs = [""helloworld.py""],+    deps = [+        "":helloworld_moved_py_pb2"",+        "":helloworld_moved_py_pb2_grpc"",+        "":duration_py_pb2"",+        "":timestamp_py_pb2"",+    ],+    imports = [+        ""_virtual_imports/helloworld_moved_proto"",","I don't know if _virtual_imports becomes visible for people or no (I would guess no). I know that this is where cc_proto_library puts its generated files, but users of the lib probably import it from different location (cc_proto_library is a native rule so it can do weird things, also C++ is compilable, so sources are just sources, and not used directly, compiled binary is used instead, which is different for python (where source and library are same thing)).",OK
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/20170,321053281,2019-09-05T02:39:32Z,src/core/lib/surface/validate_metadata.cc,"@@ -67,6 +67,10 @@ grpc_error* grpc_validate_header_key_is_legal(const grpc_slice& slice) {     return GRPC_ERROR_CREATE_FROM_STATIC_STRING(         ""Metadata keys cannot be zero length"");   }+  if (GRPC_SLICE_LENGTH(slice) > UINT32_MAX) {","Yes - consider the following (now removed) code in hpack_encoder.cc:""size_t len_val = wire_value_length(value);GPR_ASSERT(len_val <= UINT32_MAX);""This is executed by methods like: emit_lithdr_(inc/no)idx[_v] for any header that ended up taking that path.However:1) If a metadata key/value pair is not provided by the user, we should do a debug assert and not a regular assert, since we control what metadata core and our filters use.2) If a metadata key/value is provided by the user, we should in that case do the length check as a regular assert - but it only needs to be done for user provided metadata.Hence, this check.",
702191,arjunroy,https://api.github.com/repos/grpc/grpc/pulls/20170,321053353,2019-09-05T02:39:58Z,src/core/lib/surface/validate_metadata.cc,"@@ -67,6 +67,10 @@ grpc_error* grpc_validate_header_key_is_legal(const grpc_slice& slice) {     return GRPC_ERROR_CREATE_FROM_STATIC_STRING(         ""Metadata keys cannot be zero length"");   }+  if (GRPC_SLICE_LENGTH(slice) > UINT32_MAX) {","Note that validate_metadata is called in prepare_application_metadata, which handles user provided metadata.",OK
3524818,lberki,https://api.github.com/repos/grpc/grpc/pulls/20150,321131287,2019-09-05T08:20:57Z,bazel/test/python_test_repo/BUILD,"@@ -60,3 +60,54 @@ py_test(     ],     python_version = ""PY3"", )++# Test compatibility of py_proto_library and py_grpc_library rules with+# proto_library targets as deps when the latter use import_prefix and/or+# strip_import_prefix arguments+proto_library(+    name = ""helloworld_moved_proto"",+    srcs = [""helloworld.proto""],+    deps = [+        ""@com_google_protobuf//:duration_proto"",+        ""@com_google_protobuf//:timestamp_proto"",+    ],+    import_prefix = ""google/cloud"",+    strip_import_prefix = """"+)++py_proto_library(+    name = ""helloworld_moved_py_pb2"",+    deps = ["":helloworld_moved_proto""],+)++py_grpc_library(+    name = ""helloworld_moved_py_pb2_grpc"",+    srcs = ["":helloworld_moved_proto""],+    deps = ["":helloworld_moved_py_pb2""],+)++py_test(+    name = ""import_moved_test"",+    main = ""helloworld.py"",+    srcs = [""helloworld.py""],+    deps = [+        "":helloworld_moved_py_pb2"",+        "":helloworld_moved_py_pb2_grpc"",+        "":duration_py_pb2"",+        "":timestamp_py_pb2"",+    ],+    imports = [+        ""_virtual_imports/helloworld_moved_proto"",","Adding our Python expert, @brandjon for a more authoritative answer.I'd much rather no one encodes `_virtual_imports` in BUILD files. That won't change (for a while), but it's considered an implementation detail and it's at Bazel's discretion whether it creates such a directory for any given `proto_library` rule.The ""official"" way to do `LANG_proto_library` is to make them not macros, but rules (i.e. not `def bf_proto_library()` but `bf_proto_library = rule(...)`.) Then they can create language-specific providers (`PyInfo` in this case) and are able to do things like adding a new entry to the import path and are able to figure out he proto source root (by calling `dep[ProtoInfo].proto_source_root`). That way, dependent Python rules don't need to know how exactly they work.",
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/20170,321336150,2019-09-05T15:31:15Z,src/core/lib/slice/slice_internal.h,"@@ -215,22 +215,28 @@ struct InternedSliceRefcount { }  // namespace grpc_core  inline int grpc_slice_refcount::Eq(const grpc_slice& a, const grpc_slice& b) {+  GPR_DEBUG_ASSERT(a.refcount != nullptr);+  GPR_DEBUG_ASSERT(a.refcount == this);   switch (ref_type_) {     case Type::STATIC:-      return GRPC_STATIC_METADATA_INDEX(a) == GRPC_STATIC_METADATA_INDEX(b);+      GPR_DEBUG_ASSERT(+          (GRPC_STATIC_METADATA_INDEX(a) == GRPC_STATIC_METADATA_INDEX(b)) ==+          (a.refcount == b.refcount));     case Type::INTERNED:       return a.refcount == b.refcount;     case Type::NOP:     case Type::REGULAR:       break;   }-  if (GRPC_SLICE_LENGTH(a) != GRPC_SLICE_LENGTH(b)) return false;-  if (GRPC_SLICE_LENGTH(a) == 0) return true;-  return 0 == memcmp(GRPC_SLICE_START_PTR(a), GRPC_SLICE_START_PTR(b),-                     GRPC_SLICE_LENGTH(a));+  if (a.data.refcounted.length != GRPC_SLICE_LENGTH(b)) return false;+  if (a.data.refcounted.length == 0) return true;+  return 0 == memcmp(a.data.refcounted.bytes, GRPC_SLICE_START_PTR(b),","I see but, instead of removing the macros, I would suggest adding inlines function that has `grpc_refcounted_slice_length()` and `grpc_ref_counted_slice_data()` with debug asserts that `refcount` is not nullptr, for readability.",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/19960,321385923,2019-09-05T17:21:40Z,src/python/grpcio_tests/tests_aio/unit/test_base.py,"@@ -0,0 +1,58 @@+# Copyright 2019 The gRPC Authors.+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++import asyncio+import unittest+import socket++from grpc.experimental import aio+from tests_aio.unit import sync_server+++def _get_free_loopback_tcp_port():+    if socket.has_ipv6:+        tcp_socket = socket.socket(socket.AF_INET6)+        host = ""::1""+        host_target = ""[::1]""+    else:+        tcp_socket = socket.socket(socket.AF_INET)+        host = ""127.0.0.1""+        host_target = host+    tcp_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)+    tcp_socket.bind((host, 0))+    address_tuple = tcp_socket.getsockname()+    return tcp_socket, ""%s:%s"" % (host_target, address_tuple[1])+++class AioTestBase(unittest.TestCase):++    def setUp(self):+        self._socket, self._target = _get_free_loopback_tcp_port()+        self._server = sync_server.Server(self._target)+        self._server.start()+        self._loop = asyncio.new_event_loop()+        asyncio.set_event_loop(self._loop)+        aio.init_grpc_aio()++    def tearDown(self):+        self._server.terminate()+        self._socket.close()++    @property+    def loop(self):+        return self._loop++    @property+    def server_target(self):+        return self._target","Internally, there is some special optimization for test case running. If we setup a new process for each test case, the internal test runner will hang. So, I changed this class to initialize the process once per test class.```Pythonclass AioTestBase(unittest.TestCase):    @classmethod    def setUpClass(cls):        super().setUpClass()        cls._socket, cls._target = _get_free_loopback_tcp_port()        cls._server = sync_server.Server(cls._target)        cls._server.start()        cls._loop = asyncio.new_event_loop()        asyncio.set_event_loop(cls._loop)        aio.init_grpc_aio()    @classmethod    def tearDownClass(cls):        cls._server.terminate()        cls._socket.close()        super().tearDownClass()    @property    def loop(self):        return self._loop    @property    def server_target(self):        return self._target```",OK
14166415,sanjaypujare,https://api.github.com/repos/grpc/grpc/pulls/19778,321399401,2019-09-05T17:50:34Z,include/grpc/grpc_security.h,"@@ -819,6 +819,7 @@ struct grpc_tls_credential_reload_arg {   grpc_tls_key_materials_config* key_materials_config;   grpc_ssl_certificate_config_reload_status status;   const char* error_details;+  grpc_tls_credential_reload_config* config;","Few comments:- can you add the new parameter ""config"" in the comment above to describe what it does?- can you split the comment to describe each parameter on a new line?- actual parameter name is key_materials_config but the comment says ""key_materials"" . Pls fix the discrepancy",
14166415,sanjaypujare,https://api.github.com/repos/grpc/grpc/pulls/19778,321400860,2019-09-05T17:53:43Z,include/grpc/grpc_security.h,"@@ -881,6 +882,7 @@ struct grpc_tls_server_authorization_check_arg {   const char* peer_cert;   grpc_status_code status;   const char* error_details;+  grpc_tls_server_authorization_check_config* config;","Similar to my above comment:- can you add the new parameter ""config"" in the comment above to describe what it does?- can you split the comment to describe each parameter on a new line?- fix the discrepancy between ""peer_cert"" and ""certificate"" in the comment",
25311427,vam-google,https://api.github.com/repos/grpc/grpc/pulls/20150,321543574,2019-09-06T01:14:07Z,bazel/test/python_test_repo/BUILD,"@@ -60,3 +60,54 @@ py_test(     ],     python_version = ""PY3"", )++# Test compatibility of py_proto_library and py_grpc_library rules with+# proto_library targets as deps when the latter use import_prefix and/or+# strip_import_prefix arguments+proto_library(+    name = ""helloworld_moved_proto"",+    srcs = [""helloworld.proto""],+    deps = [+        ""@com_google_protobuf//:duration_proto"",+        ""@com_google_protobuf//:timestamp_proto"",+    ],+    import_prefix = ""google/cloud"",+    strip_import_prefix = """"+)++py_proto_library(+    name = ""helloworld_moved_py_pb2"",+    deps = ["":helloworld_moved_proto""],+)++py_grpc_library(+    name = ""helloworld_moved_py_pb2_grpc"",+    srcs = ["":helloworld_moved_proto""],+    deps = ["":helloworld_moved_py_pb2""],+)++py_test(+    name = ""import_moved_test"",+    main = ""helloworld.py"",+    srcs = [""helloworld.py""],+    deps = [+        "":helloworld_moved_py_pb2"",+        "":helloworld_moved_py_pb2_grpc"",+        "":duration_py_pb2"",+        "":timestamp_py_pb2"",+    ],+    imports = [+        ""_virtual_imports/helloworld_moved_proto"",","@lberki **tl;dr;** Is it possible to create `PyInfo` and or `ProtoInfo` provider instance from a Starlark rule? Last time I tried to create ProtoInfo from starlark I could not figure out how to do it and concluded that it could be created only from navite rules (but it was long time ago and I may be wrong here).`py_proto_library` here consists of essentially two calls only: 1) generate python stubs, 2) call native `py_library` rule to make it a ""library"" (compile, if python was static languge). So it is as simple wrapper macro as it can be, and probably it is done this way because it allows to output a legit `py_library` without need to ""re-implement"" `py_library`. `py_library` is a native rule with opaque implementation, so it is hard to figure out how to make py_proto_library in a form of a rule such that it can be consumed as a dependency (by `py_library`, `py_binary` and `py_test`). ",OK
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/20188,321605610,2019-09-06T07:22:17Z,test/cpp/end2end/end2end_test.cc,"@@ -338,7 +338,11 @@ class End2endTest : public ::testing::TestWithParam<TestScenario> {         kMaxMessageSize_);  // For testing max message size.   } -  void ResetChannel() {+  void ResetChannel(+      std::vector<+          std::unique_ptr<experimental::ClientInterceptorFactoryInterface>>+          interceptor_creators = std::vector<std::unique_ptr<",I think you can just do `= {}` to set the default argument to be the empty vector. It works on some simple godbolt codes.,
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/20181,321822175,2019-09-06T16:50:29Z,tools/dockerfile/test/python_stretch_default_x64/Dockerfile,"@@ -0,0 +1,87 @@+# Copyright 2018 The gRPC Authors+#+# Licensed under the Apache License, Version 2.0 (the ""License"");+# you may not use this file except in compliance with the License.+# You may obtain a copy of the License at+#+#     http://www.apache.org/licenses/LICENSE-2.0+#+# Unless required by applicable law or agreed to in writing, software+# distributed under the License is distributed on an ""AS IS"" BASIS,+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+# See the License for the specific language governing permissions and+# limitations under the License.++FROM debian:stretch+  +# Install Git and basic packages.+RUN apt-get update && apt-get install -y \+  autoconf \+  autotools-dev \+  build-essential \+  bzip2 \+  ccache \+  curl \+  dnsutils \+  gcc \+  gcc-multilib \+  git \+  golang \+  gyp \+  lcov \+  libc6 \+  libc6-dbg \+  libc6-dev \+  libgtest-dev \+  libtool \+  make \+  perl \+  strace \+  python-dev \+  python-setuptools \+  python-yaml \+  telnet \+  unzip \+  wget \+  zip && apt-get clean++#================+# Build profiling+RUN apt-get update && apt-get install -y time && apt-get clean++# Google Cloud platform API libraries+RUN apt-get update && apt-get install -y python-pip && apt-get clean+RUN pip install --upgrade google-api-python-client oauth2client++# Install Python 2.7+RUN apt-get update && apt-get install -y python2.7 python-all-dev+RUN curl https://bootstrap.pypa.io/get-pip.py | python2.7++# Add Debian 'buster' repository, we will need it for installing newer versions of python+RUN echo 'deb http://ftp.de.debian.org/debian buster main' >> /etc/apt/sources.list+RUN echo 'APT::Default-Release ""stretch"";' | tee -a /etc/apt/apt.conf.d/00local++RUN mkdir /var/local/jenkins++# Define the default command.+CMD [""bash""]","Is this necessary? I believe this is already the default command for the `debian` base image. Also, is this image ever run without the command specified? I'm pretty sure the `run_tests.py` stack is the only thing that ever instantiates a container from this image.",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/20181,321852302,2019-09-06T18:12:33Z,templates/tools/dockerfile/test/python_stretch_default_x64/Dockerfile.template,"@@ -0,0 +1,36 @@+%YAML 1.2+--- |+  # Copyright 2018 The gRPC Authors+  #+  # Licensed under the Apache License, Version 2.0 (the ""License"");+  # you may not use this file except in compliance with the License.+  # You may obtain a copy of the License at+  #+  #     http://www.apache.org/licenses/LICENSE-2.0+  #+  # Unless required by applicable law or agreed to in writing, software+  # distributed under the License is distributed on an ""AS IS"" BASIS,+  # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+  # See the License for the specific language governing permissions and+  # limitations under the License.++  <%include file=""../../python_stretch.include""/>++  RUN apt-get update && apt-get install -y zlib1g-dev libssl-dev+  RUN apt-get update && apt-get install -y jq build-essential libffi-dev++  RUN cd /tmp && ${'\\'}+    wget -q https://github.com/python/cpython/archive/v3.6.9.tar.gz && ${'\\'}+    tar xzvf v3.6.9.tar.gz && ${'\\'}+    cd cpython-3.6.9 && ${'\\'}+    ./configure && ${'\\'}+    make install++  RUN apt-get update && apt-get -t buster install -y python3.7 python3-all-dev","Sadly, our tests is ran on a single image, so previously we ran 2.7 3.7 tests on the stretch_3.7 image. And I found if I add 3.6 to that image, the naming will be broken. So, I created this new stretch_default image to handle all 3 Python versions.",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/20188,321969086,2019-09-07T13:27:57Z,include/grpcpp/impl/codegen/client_context_impl.h,"@@ -310,11 +310,11 @@ class ClientContext {   /// client’s identity, role, or whether it is authorized to make a particular   /// call.   ///+  /// It is legal to call this only before initial metadata is sent.","to call this only **once and only** before initial metadata is sent **(i.e., in a PRE_SEND_INITIAL_METADATA interceptor).**",
8864912,vjpai,https://api.github.com/repos/grpc/grpc/pulls/20188,321969107,2019-09-07T13:28:42Z,src/cpp/client/client_context.cc,"@@ -72,6 +72,22 @@ ClientContext::~ClientContext() {   g_client_callbacks->Destructor(this); } +void ClientContext::set_credentials(+    const std::shared_ptr<grpc_impl::CallCredentials>& creds) {+  creds_ = creds;+  // If call_ is set, we have already created the call, and set the call+  // credentials. This should only be done before we have started the batch+  // for sending initial metadata.+  if (creds_ != nullptr && call_ != nullptr) {+    if (!creds_->ApplyToCall(call_)) {+      SendCancelToInterceptors();+      grpc_call_cancel_with_status(call_, GRPC_STATUS_CANCELLED,+                                   ""Failed to set credentials to rpc."",+                                   nullptr);","Should the cancellation also trigger if the creds_ has already been set? Although I'm not normally into protecting against API misuse, we already have the handling in place here for other reasons. This is a nit, and I'm ok with the answer being no so long as the API comment above makes it clear that it can only be called once.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/20181,322229804,2019-09-09T13:03:59Z,tools/run_tests/run_tests.py,"@@ -846,6 +846,7 @@ def _get_pythons(self, args):             else:                 return (                     python27_config,+                    python36_config,","The concern here is how much longer are the tests going to take on kokoro. We are generally trying to reduce the test duration on PRs.  If the increase is reasonable and python jobs aren't taking too long, this is probably fine, but we should track how much of an increase adding python36 is.",
4181124,yashykt,https://api.github.com/repos/grpc/grpc/pulls/20188,322489579,2019-09-09T23:01:01Z,src/cpp/client/client_context.cc,"@@ -72,6 +72,22 @@ ClientContext::~ClientContext() {   g_client_callbacks->Destructor(this); } +void ClientContext::set_credentials(+    const std::shared_ptr<grpc_impl::CallCredentials>& creds) {+  creds_ = creds;+  // If call_ is set, we have already created the call, and set the call+  // credentials. This should only be done before we have started the batch+  // for sending initial metadata.+  if (creds_ != nullptr && call_ != nullptr) {+    if (!creds_->ApplyToCall(call_)) {+      SendCancelToInterceptors();+      grpc_call_cancel_with_status(call_, GRPC_STATUS_CANCELLED,+                                   ""Failed to set credentials to rpc."",+                                   nullptr);","I think we should be allowing set_credentials to be called multiple times, especially if it is happening before initial metadata is sent.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/20211,322593508,2019-09-10T07:39:07Z,templates/CMakeLists.txt.template,"@@ -76,7 +76,7 @@   set(PACKAGE_STRING    ""<%text>${PACKAGE_NAME} ${PACKAGE_VERSION}</%text>"")   set(PACKAGE_TARNAME   ""<%text>${PACKAGE_NAME}-${PACKAGE_VERSION}</%text>"")   set(PACKAGE_BUGREPORT ""https://github.com/grpc/grpc/issues/"")-  project(<%text>${PACKAGE_NAME}</%text> C CXX)+  project(<%text>${PACKAGE_NAME}</%text> LANGUAGES C CXX VERSION ${settings.core_version})","core_version is  grpc C core version (the ""grpc"" library, mostly used for other languages to implement their support on top of it), but the C++ libraries (""grpc++"") are at a different version (currently 1.24 ish...)",OK
3314176,AspirinSJL,https://api.github.com/repos/grpc/grpc/pulls/20229,323420232,2019-09-11T19:31:22Z,src/core/ext/filters/http/client/http_client_filter.cc,"@@ -465,16 +465,16 @@ static void hc_start_transport_stream_op_batch( }  /* Constructor for call_data */-static grpc_error* init_call_elem(grpc_call_element* elem,-                                  const grpc_call_element_args* args) {+static grpc_error* hc_init_call_elem(grpc_call_element* elem,",Suggest renaming to `http_client_*`. `hc` sounds more like health checking to me.,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/19987,323804623,2019-09-12T15:25:00Z,src/core/lib/slice/slice_intern.cc,"@@ -172,7 +172,8 @@ static const grpc_core::StaticMetadataSlice* MatchStaticSlice(     const grpc_core::StaticMetadataSlice* static_slice_table =         grpc_static_slice_table();     if (ent.hash == hash && ent.idx < GRPC_STATIC_MDSTR_COUNT &&-        static_slice_table[ent.idx].Equals(std::forward<SliceArgs>(args)...)) {+        static_slice_table[ent.idx].operator==(","Stepping back for a moment, why are we using variadic template args here in the first place?  If we only ever expect there to be a single parameter (either a slice or a pair), can't we just use a single template arg?  If we did that, we probably would not need `std::forward()` here at all.",OK
3578154,argaen,https://api.github.com/repos/grpc/grpc/pulls/20277,325148236,2019-09-17T12:52:35Z,src/python/grpcio/grpc/_cython/_cygrpc/aio/call.pyx.pxi,"@@ -146,4 +168,15 @@ cdef class _AioCall:             grpc_call_unref(call)             gpr_free(ops) -        return receive_message_operation.message()+        if receive_status_on_client_operation.code() == GRPC_STATUS_OK:+            return receive_message_operation.message()++        class _RpcError(_RpcErrorBase, grpc.RpcError):",is there a requirement on declaring this class on every `unary_unary` call? Can't we extract it outside?,
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/20119,325186054,2019-09-17T14:04:25Z,src/core/lib/iomgr/closure.h,"@@ -69,7 +72,9 @@ struct grpc_closure {    *  space */   union {     grpc_closure* next;-    gpr_mpscq_node atm_next;+    grpc_core::ManualConstructor<","Yes, because we still have a lot of places where `grpc_closure` is created using `gpr_malloc()` instead of `New<>()`, in which case its ctor will not be run.  This is exactly the case that `ManualConstructor<>` was designed to address.As we replace `grpc_closure` with something else, we'll make sure that the new thing is properly instantiated, so it won't need `ManualConstructor<>`.",
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19609,325219641,2019-09-17T14:59:52Z,src/csharp/Grpc.Core.Api/AsyncCallState.cs,"@@ -0,0 +1,92 @@+#region Copyright notice and license++// Copyright 2015 gRPC authors.+//+// Licensed under the Apache License, Version 2.0 (the ""License"");+// you may not use this file except in compliance with the License.+// You may obtain a copy of the License at+//+//     http://www.apache.org/licenses/LICENSE-2.0+//+// Unless required by applicable law or agreed to in writing, software+// distributed under the License is distributed on an ""AS IS"" BASIS,+// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+// See the License for the specific language governing permissions and+// limitations under the License.++#endregion+++using System;+using System.Threading.Tasks;++namespace Grpc.Core+{+    /// <summary>+    /// Provides an abstraction over the callback providers+    /// used by AsyncUnaryCall, AsyncDuplexStreamingCall, etc+    /// </summary>+    internal /* readonly */ struct AsyncCallState // can be made readonly in C# 7.2+    {+        readonly object responseHeadersAsync; // Task<Metadata> or Func<object, Task<Metadata>>","I see the point of using `object`, but I'm not a fan of the Task<Metadata> vs Func<object, Task<Metadata>> duality - it's not very readable and hard to maintain.",OK
1331988,rmariano,https://api.github.com/repos/grpc/grpc/pulls/20277,325223925,2019-09-17T15:06:47Z,src/python/grpcio/grpc/_cython/_cygrpc/aio/call.pyx.pxi,"@@ -146,4 +168,15 @@ cdef class _AioCall:             grpc_call_unref(call)             gpr_free(ops) -        return receive_message_operation.message()+        if receive_status_on_client_operation.code() == GRPC_STATUS_OK:+            return receive_message_operation.message()++        class _RpcError(_RpcErrorBase, grpc.RpcError):","If this is declared in the main file, it doesn't compile property because it raises ``ImportError: 'grpc' does not have attribute RpcError`` (becaues it's a cython file calling a Python one), so it was done this way to have it inside the compiled code, so at running time the dependency will be availalble.TL;DR the main constraing is ``grpc.RpcError`` being a Python class needed from a Cython one.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/19609,325229645,2019-09-17T15:17:27Z,src/csharp/Grpc.Core.Api/AsyncCallState.cs,"@@ -0,0 +1,92 @@+#region Copyright notice and license++// Copyright 2015 gRPC authors.",the header should be https://github.com/grpc/grpc/blob/906c12568e9bdf1d8306a2f2ab45efe8beb43f74/src/csharp/Grpc.Core.Api/Properties/AssemblyInfo.cs#L3 for new files,
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/20277,325292294,2019-09-17T17:26:01Z,src/python/grpcio/grpc/_cython/_cygrpc/aio/call.pyx.pxi,"@@ -13,12 +13,34 @@ # limitations under the License.  cimport cpython+import grpc  _EMPTY_FLAGS = 0 _EMPTY_METADATA = ()","Can we change `_EMPTY_METADATA` to `None` instead of `()`? They works similarly, but in existing code base the empty metadata is represented by `None`, and it is semantically more clear.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/20277,325292641,2019-09-17T17:26:48Z,src/python/grpcio/grpc/_cython/_cygrpc/aio/call.pyx.pxi,"@@ -13,12 +13,34 @@ # limitations under the License.  cimport cpython+import grpc  _EMPTY_FLAGS = 0 _EMPTY_METADATA = () _OP_ARRAY_LENGTH = 6  +class _RpcErrorBase:","I would suggest create a separate file for this class, since the server may use it as well.",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/20277,325294164,2019-09-17T17:30:14Z,src/python/grpcio/grpc/_cython/_cygrpc/aio/call.pyx.pxi,"@@ -146,4 +168,15 @@ cdef class _AioCall:             grpc_call_unref(call)             gpr_free(ops) -        return receive_message_operation.message()+        if receive_status_on_client_operation.code() == GRPC_STATUS_OK:+            return receive_message_operation.message()++        class _RpcError(_RpcErrorBase, grpc.RpcError):+            pass++        raise _RpcError(+            receive_status_on_client_operation.error_string(),",`error_string` is not `initial_metadata`,
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/20277,325325625,2019-09-17T18:40:10Z,src/python/grpcio/grpc/_cython/_cygrpc/aio/call.pyx.pxi,"@@ -146,4 +168,15 @@ cdef class _AioCall:             grpc_call_unref(call)             gpr_free(ops) -        return receive_message_operation.message()+        if receive_status_on_client_operation.code() == GRPC_STATUS_OK:+            return receive_message_operation.message()++        class _RpcError(_RpcErrorBase, grpc.RpcError):","Could you raise or return an object not formally implementing `grpc.RpcError`, intercept it in the Python layer, and only then associate it with the `grpc.RpcError` interface? It seems pretty heavy to be instantiating a class on this fastpath. Plus, it would probably be surprising to users that there are many non-pointer-equal types called `_RpcError`:```python>>> for i in range(5):...     class Foo:...             pass...     print(id(Foo))... 4043324040434184404351284043607239677240```",
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/20277,325328036,2019-09-17T18:45:22Z,src/python/grpcio/grpc/experimental/aio/_channel.py,"@@ -20,12 +21,18 @@  class UnaryUnaryMultiCallable(aio.UnaryUnaryMultiCallable): -    def __init__(self, channel, method, request_serializer,-                 response_deserializer):+    def __init__(self, channel: cygrpc.AioChannel, method, request_serializer,+                 response_deserializer) -> None:         self._channel = channel         self._method = method         self._request_serializer = request_serializer         self._response_deserializer = response_deserializer+        self._loop = asyncio.get_event_loop()++    def _timeout_for_deadline(self, timeout=None):+        if timeout is None:+            return None+        return self._loop.time() + timeout      async def __call__(self,","It's occurring to me now that it's probably a good idea to make our keyword arguments [keyword-only arguments](https://www.python.org/dev/peps/pep-3102/). That would mean changing the signature to```python    async def __call__(self,                       request,                       *,                       timeout=None,                       metadata=None,                       credentials=None,                       wait_for_ready=None,                       compression=None):```This will make the API surface smaller and easier to maintain in the long term.",OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/20277,325329888,2019-09-17T18:49:34Z,src/python/grpcio/grpc/_cython/_cygrpc/aio/call.pyx.pxi,"@@ -146,4 +168,15 @@ cdef class _AioCall:             grpc_call_unref(call)             gpr_free(ops) -        return receive_message_operation.message()+        if receive_status_on_client_operation.code() == GRPC_STATUS_OK:",You probably want to make use of [`StatusCode.ok`](https://github.com/grpc/grpc/blob/b3b00ad858f094f742e1e8fd46b2b453ce580c5c/src/python/grpcio/grpc/_cython/_cygrpc/records.pyx.pxi#L62).[ Compare with the current check for this condition](https://github.com/grpc/grpc/blob/b3b00ad858f094f742e1e8fd46b2b453ce580c5c/src/python/grpcio/grpc/_channel.py#L499).,
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/20277,325342324,2019-09-17T19:19:48Z,src/python/grpcio_tests/tests_aio/unit/channel_test.py,"@@ -52,6 +55,26 @@ def test_unary_unary(self):          self.loop.run_until_complete(coro()) +    def test_unary_call_times_out(self):+        async def coro():+            async with aio.insecure_channel(self.server_target) as channel:+                empty_call_with_sleep = channel.unary_unary(+                    ""/grpc.testing.TestService/EmptyCall"",+                    request_serializer=messages_pb2.SimpleRequest.SerializeToString,+                    response_deserializer=messages_pb2.SimpleResponse.FromString,+                )+                timeout = TestServiceServicer.CALL_DELAY / 2+                with self.assertRaises(grpc.RpcError) as exception_context:",I could see this test potentially being flaky depending on how accurate the various timers involved in this RPC are and scheduling of the threads and processes involved. What sort of flake rate do we see when running several thousand instances of this test in parallel?,
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/20277,325343639,2019-09-17T19:23:15Z,src/python/grpcio/grpc/_cython/_cygrpc/aio/channel.pyx.pxi,"@@ -18,13 +18,13 @@ cdef class AioChannel:         self._target = target      def __repr__(self):-        class_name = self.__class__.__name__ +        class_name = self.__class__.__name__         id_ = id(self)         return f""<{class_name} {id_}>""      def close(self):         grpc_channel_destroy(self.channel) -    async def unary_unary(self, method, request):+    async def unary_unary(self, method, request, timeout=None):","Our pattern in the past has been to use keyword arguments on our public API surface for breathing room for API additions, but for internal APIs such as this, we tend to only use positional arguments, since we're completely in control of the call sites as well as the function signature.",
1331988,rmariano,https://api.github.com/repos/grpc/grpc/pulls/20277,325563815,2019-09-18T09:07:50Z,src/python/grpcio/grpc/_cython/_cygrpc/aio/call.pyx.pxi,"@@ -146,4 +168,15 @@ cdef class _AioCall:             grpc_call_unref(call)             gpr_free(ops) -        return receive_message_operation.message()+        if receive_status_on_client_operation.code() == GRPC_STATUS_OK:","I would like to reuse that enum, but ``grpc.StatusCode.OK`` it's an enum whose value is ``(0, 'ok')``, and the result of the ``.code()`` method is just the status code number (``0``), so they don't match. Maybe I would unpack just the status code from the enum, and using that to compare.I've noticed in the current check of that condition, the ``state`` object being compared is of a different kind, whcih is not available in the message operation objects we use here. Would it be worth re-assempling the tuple to use that on the check?",OK
1331988,rmariano,https://api.github.com/repos/grpc/grpc/pulls/20277,325698449,2019-09-18T14:10:39Z,src/python/grpcio_tests/tests_aio/unit/channel_test.py,"@@ -52,6 +55,26 @@ def test_unary_unary(self):          self.loop.run_until_complete(coro()) +    def test_unary_call_times_out(self):+        async def coro():+            async with aio.insecure_channel(self.server_target) as channel:+                empty_call_with_sleep = channel.unary_unary(+                    ""/grpc.testing.TestService/EmptyCall"",+                    request_serializer=messages_pb2.SimpleRequest.SerializeToString,+                    response_deserializer=messages_pb2.SimpleResponse.FromString,+                )+                timeout = TestServiceServicer.CALL_DELAY / 2+                with self.assertRaises(grpc.RpcError) as exception_context:","Now that the code uses ``SHORT_TIMEOUT`` from ``tests_constants.py``, it has a larger value, so I would estimate that reduces the flakyness of the test. Would you agree with this assessment?",
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/19778,325785048,2019-09-18T16:52:59Z,include/grpcpp/security/tls_credentials_options.h,"@@ -0,0 +1,293 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#ifndef GRPCPP_SECURITY_TLS_CREDENTIALS_OPTIONS_H+#define GRPCPP_SECURITY_TLS_CREDENTIALS_OPTIONS_H++#include <memory>+#include <vector>++#include <grpc/grpc_security.h>+#include <grpc/support/log.h>+#include <grpcpp/support/config.h>++namespace grpc_impl {+namespace experimental {++/** TLS key materials config, wrapper for grpc_tls_key_materials_config. It is+ * used for experimental purposes for now and subject to change. **/+class TlsKeyMaterialsConfig {+ public:+  struct PemKeyCertPair {+    grpc::string private_key;+    grpc::string cert_chain;+  };++  /** Getters for member fields. **/+  const grpc::string pem_root_certs() const { return pem_root_certs_; }+  const std::vector<PemKeyCertPair>& pem_key_cert_pair_list() const {+    return pem_key_cert_pair_list_;+  }+  int version() const { return version_; }++  /** Setter for key materials that will be called by the user. The setter+   * transfers ownership of the arguments to the config. **/+  void set_key_materials(grpc::string pem_root_certs,+                         std::vector<PemKeyCertPair> pem_key_cert_pair_list);+  void set_version(int version) { version_ = version; };++ private:+  int version_ = 0;+  std::vector<PemKeyCertPair> pem_key_cert_pair_list_;+  grpc::string pem_root_certs_;+};++/** TLS credential reload arguments, wraps grpc_tls_credential_reload_arg. It is+ * used for experimental purposes for now and it is subject to change.+ *+ * The credential reload arg contains all the info necessary to schedule/cancel+ * a credential reload request. The callback function must be called after+ * finishing the schedule operation. See the description of the+ * grpc_tls_credential_reload_arg struct in grpc_security.h for more details.+ * **/+class TlsCredentialReloadArg {+ public:+  /** TlsCredentialReloadArg does not take ownership of the C arg that is passed+   * to the constructor. One must remember to free any memory allocated to the C+   * arg after using the setter functions below. **/+  TlsCredentialReloadArg(grpc_tls_credential_reload_arg* arg) : c_arg_(arg) {}+  ~TlsCredentialReloadArg();++  /** Getters for member fields. The callback function is not exposed.+   * They return the corresponding fields of the underlying C arg. In the case+   * of the key materials config, it creates a new instance of the C++ key+   * materials config from the underlying C grpc_tls_key_materials_config. **/+  void* cb_user_data() const;+  std::shared_ptr<TlsKeyMaterialsConfig> key_materials_config() const;+  grpc_ssl_certificate_config_reload_status status() const;+  grpc::string error_details() const;++  /** Setters for member fields. They modify the fields of the underlying C arg.+   * The setters for the key_materials_config and the error_details allocate+   * memory when modifying c_arg_, so one must remember to free c_arg_'s+   * original key_materials_config or error_details after using the appropriate+   * setter function.+   * **/+  void set_cb_user_data(void* cb_user_data);+  void set_key_materials_config(+      const std::shared_ptr<TlsKeyMaterialsConfig>& key_materials_config);+  void set_status(grpc_ssl_certificate_config_reload_status status);+  void set_error_details(const grpc::string& error_details);++  /** Calls the C arg's callback function. **/+  void OnCredentialReloadDoneCallback();++ private:+  grpc_tls_credential_reload_arg* c_arg_;+};++/** TLS credential reloag config, wraps grpc_tls_credential_reload_config. It is+ * used for experimental purposes for now and it is subject to change.+ *+ * The config_user_data is read-only user data; schedule is a pointer to an+ * application-provided callback that invokes the credential reload; cancel is a+ * pointer to an application-provided callback that cancels a credential reload+ * request; destruct is a pointer to an application-provided callback that+ * cleans up any data associated to the config. See the description of the+ * grpc_tls_credential_reload_config struct in grpc_security.h. **/+class TlsCredentialReloadConfig {+ public:+  TlsCredentialReloadConfig(const void* config_user_data,+                            int (*schedule)(void* config_user_data,+                                            TlsCredentialReloadArg* arg),+                            void (*cancel)(void* config_user_data,+                                           TlsCredentialReloadArg* arg),+                            void (*destruct)(void* config_user_data));","I do not think there is a general solution for this API. However from the API surface I am curious about the proper usage (the test uses pretty simple construction and I am not sure whether that is representative). I understand this is sort of a thin wrapper of C API where the interface comes from. I am not sure about the purpose of destruct for example. If the user_data is read only as mentioned, maybe the destruct should be more like a release (unref)? Regarding the API, how about something like```struct UserConfigInterface {  // Schedule arg on this.  int Schedule(TlsCredentialReloadArg* arg) = 0;  // Cancel reload with arg.  void Cancel(TlsCredentialReloadArg* arg) = 0;  // Config no longer needs this.  void Release() = 0;};TlsCredentialReloadConfig::TlsCredentialReloadConfig(UserConfigInterface* user_data);```The `TlsServerAuthorizationCheckConfig` ctor may or may not share the same interface.",OK
1644595,gnossen,https://api.github.com/repos/grpc/grpc/pulls/20277,325788980,2019-09-18T17:01:46Z,src/python/grpcio_tests/tests_aio/unit/init_test.py,"@@ -15,10 +15,33 @@ import logging import unittest +import grpc from grpc.experimental import aio from tests_aio.unit import test_base  +class TestAioRpcError(unittest.TestCase):++    def test_attributes(self):+        aio_rpc_error = grpc.AioRpcError(""initial metadata"", 0, ""details"", ""trailing metadata"")+        self.assertEqual(aio_rpc_error.initial_metadata(), ""initial metadata"")+        self.assertEqual(aio_rpc_error.code(), 0)+        self.assertEqual(aio_rpc_error.details(), ""details"")+        self.assertEqual(aio_rpc_error.trailing_metadata(), ""trailing metadata"")++    def test_class_hierarchy(self):+        aio_rpc_error = grpc.AioRpcError(""initial metadata"", 0, ""details"", ""trailing metadata"")++        self.assertEqual(aio_rpc_error.__class__.__name__, ""AioRpcError"")+        self.assertIsInstance(aio_rpc_error, grpc.RpcError)++    def test_class_singleton(self):+        first_aio_rpc_error = grpc.AioRpcError(""initial metadata"", 0, ""details"", ""trailing metadata"")+        second_aio_rpc_error = grpc.AioRpcError(""initial metadata"", 0, ""details"", ""trailing metadata"")++        self.assertEqual(id(first_aio_rpc_error.__class__), id(second_aio_rpc_error.__class__))","Nice test addition! :smiley: There's a built-in assertion for this:```pythonself.assertIs(first_aio_rpc_error.__class__, second_aio_rpc_error.__class__)```",OK
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/19778,326421098,2019-09-19T23:24:11Z,include/grpcpp/security/tls_credentials_options.h,"@@ -113,58 +111,42 @@ class TlsCredentialReloadArg {   grpc_tls_credential_reload_arg* c_arg_; }; -// typedef struct grpc_tls_credential_reload_config-// grpc_tls_credential_reload_config;+/** An interface that the application derives and uses to instantiate a+ * TlsCredentialReloadConfig instance. All 3 methods must be defined. **/+struct TlsCredentialReloadInterface {",I think you will need a `virtual ~TlsCredentialReloadInterface() = default;` to make inheritance work.,
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/19778,326424041,2019-09-19T23:39:54Z,include/grpcpp/security/tls_credentials_options.h,"@@ -113,58 +111,42 @@ class TlsCredentialReloadArg {   grpc_tls_credential_reload_arg* c_arg_; }; -// typedef struct grpc_tls_credential_reload_config-// grpc_tls_credential_reload_config;+/** An interface that the application derives and uses to instantiate a+ * TlsCredentialReloadConfig instance. All 3 methods must be defined. **/+struct TlsCredentialReloadInterface {+  /** An application-provided callback that invokes the credential reload. **/+  virtual int Schedule(TlsCredentialReloadArg* arg) = 0;+  /** An application-provided callback that cancels a credential reload request.+   * **/+  virtual void Cancel(TlsCredentialReloadArg* arg) = 0;+  /** An application-provided callback that cleans up any data associated to the","For these methods, I think there is no need to repeat application-provided :)Maybe mention this will be called when the config is no longer using this object.",OK
52979934,matthewstevenson88,https://api.github.com/repos/grpc/grpc/pulls/19778,326702621,2019-09-20T16:15:43Z,src/cpp/common/tls_credentials_options_util.cc,"@@ -0,0 +1,144 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/cpp/common/tls_credentials_options_util.h""+#include <grpcpp/security/tls_credentials_options.h>++namespace grpc_impl {+namespace experimental {++/** Converts the Cpp key materials to C key materials; this allocates memory for+ * the C key materials. Note that the user must free+ * the underlying pointer to private key and cert chain duplicates; they are not+ * freed when the UniquePtr<char> member variables of PemKeyCertPair are unused.+ * Similarly, the user must free the underlying pointer to c_pem_root_certs. **/+grpc_tls_key_materials_config* ConvertToCKeyMaterialsConfig(+    const std::shared_ptr<TlsKeyMaterialsConfig>& config) {+  if (config == nullptr) {+    return nullptr;+  }+  grpc_tls_key_materials_config* c_config =+      grpc_tls_key_materials_config_create();+  ::grpc_core::InlinedVector<::grpc_core::PemKeyCertPair, 1>+      c_pem_key_cert_pair_list;+  for (auto key_cert_pair = config->pem_key_cert_pair_list().begin();+       key_cert_pair != config->pem_key_cert_pair_list().end();+       key_cert_pair++) {+    grpc_ssl_pem_key_cert_pair* ssl_pair =+        (grpc_ssl_pem_key_cert_pair*)gpr_malloc(+            sizeof(grpc_ssl_pem_key_cert_pair));+    ssl_pair->private_key = gpr_strdup(key_cert_pair->private_key.c_str());+    ssl_pair->cert_chain = gpr_strdup(key_cert_pair->cert_chain.c_str());+    ::grpc_core::PemKeyCertPair c_pem_key_cert_pair =+        ::grpc_core::PemKeyCertPair(ssl_pair);+    c_pem_key_cert_pair_list.push_back(::std::move(c_pem_key_cert_pair));+  }+  ::grpc_core::UniquePtr<char> c_pem_root_certs(+      gpr_strdup(config->pem_root_certs().c_str()));+  c_config->set_key_materials(std::move(c_pem_root_certs),+                              std::move(c_pem_key_cert_pair_list));+  c_config->set_version(config->version());+  return c_config;+}++/** Converts the C key materials config to a Cpp key materials config; it+ * allocates memory for the Cpp config. **/+std::shared_ptr<TlsKeyMaterialsConfig> ConvertToCppKeyMaterialsConfig(+    const grpc_tls_key_materials_config* config) {+  if (config == nullptr) {+    return nullptr;+  }+  std::shared_ptr<TlsKeyMaterialsConfig> cpp_config(+      new TlsKeyMaterialsConfig());+  std::vector<TlsKeyMaterialsConfig::PemKeyCertPair> cpp_pem_key_cert_pair_list;+  grpc_tls_key_materials_config::PemKeyCertPairList pem_key_cert_pair_list =+      config->pem_key_cert_pair_list();+  for (size_t i = 0; i < pem_key_cert_pair_list.size(); i++) {+    ::grpc_core::PemKeyCertPair key_cert_pair = pem_key_cert_pair_list[i];+    TlsKeyMaterialsConfig::PemKeyCertPair p = {key_cert_pair.private_key(),+                                               key_cert_pair.cert_chain()};+    cpp_pem_key_cert_pair_list.push_back(::std::move(p));+  }+  cpp_config->set_key_materials(std::move(config->pem_root_certs()),+                                std::move(cpp_pem_key_cert_pair_list));+  cpp_config->set_version(config->version());+  return cpp_config;+}++/** The C schedule and cancel functions for the credential reload config.+ * They populate a C credential reload arg with the result of a C++ credential+ * reload schedule/cancel API. **/+int TlsCredentialReloadConfigCSchedule(void* config_user_data,+                                       grpc_tls_credential_reload_arg* arg) {+  if (arg == nullptr || arg->config == nullptr ||+      arg->config->context() == nullptr) {+    gpr_log(GPR_ERROR, ""credential reload arg was not properly initialized"");+    return 1;+  }+  TlsCredentialReloadConfig* cpp_config =+      static_cast<TlsCredentialReloadConfig*>(arg->config->context());+  TlsCredentialReloadArg cpp_arg(arg);+  return cpp_config->Schedule(&cpp_arg);","I don't think this is a bug, assuming you are referring to the use of `&cpp_arg' in the line `cpp_config->Schedule(&cpp_arg)'. The reason is the following: -the function `cpp_config->Schedule` calls the `Schedule` function from the user-provided `CredentialReloadInterface` (or derived class, thereof); -this user-provided function takes an argument of type `TlsCredentialReloadArg` and performs some operations on this argument, but all that these operations do is modify the underlying C arg, of type `grpc_tls_credential_reload_arg`; -when the destructor of the `TlsCredentialReloadArg` is called, it does not free this underlying C arg;-thus, the line `cpp_config->Schedule(&cpp_arg)` modifies the variable `arg` using the user-provided `Schedule` function, and using the local `cpp_arg` is just the way that `arg` is passed to the `Schedule` function.Does that make sense? It's possible I've missed something, but this bug (at least as I understood it) doesn't show up in the unit tests. Also if I misunderstood your comment, please let me know!",
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/19778,326779420,2019-09-20T19:51:50Z,test/cpp/client/credentials_test.cc,"@@ -26,7 +27,89 @@  #include ""src/core/lib/gpr/env.h"" #include ""src/core/lib/gpr/tmpfile.h""+#include ""src/core/lib/security/credentials/tls/grpc_tls_credentials_options.h"" #include ""src/cpp/client/secure_credentials.h""+#include ""src/cpp/common/tls_credentials_options_util.h""++namespace {++typedef class ::grpc_impl::experimental::TlsKeyMaterialsConfig+    TlsKeyMaterialsConfig;+typedef class ::grpc_impl::experimental::TlsCredentialReloadArg+    TlsCredentialReloadArg;+typedef struct ::grpc_impl::experimental::TlsCredentialReloadInterface+    TlsCredentialReloadInterface;+typedef class ::grpc_impl::experimental::TlsServerAuthorizationCheckArg+    TlsServerAuthorizationCheckArg;+typedef struct ::grpc_impl::experimental::TlsServerAuthorizationCheckInterface+    TlsServerAuthorizationCheckInterface;++static void tls_credential_reload_callback(+    grpc_tls_credential_reload_arg* arg) {+  GPR_ASSERT(arg != nullptr);+  arg->status = GRPC_SSL_CERTIFICATE_CONFIG_RELOAD_UNCHANGED;+}++class TestTlsCredentialReloadInterface : public TlsCredentialReloadInterface {",Interface class has a special meaning in google coding style :) It needs to be pure virtual to be called an interface.Let's just remove Interface from the name of the class.,OK
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/19778,326783082,2019-09-20T20:02:51Z,src/cpp/common/tls_credentials_options_util.cc,"@@ -0,0 +1,144 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/cpp/common/tls_credentials_options_util.h""+#include <grpcpp/security/tls_credentials_options.h>++namespace grpc_impl {+namespace experimental {++/** Converts the Cpp key materials to C key materials; this allocates memory for+ * the C key materials. Note that the user must free+ * the underlying pointer to private key and cert chain duplicates; they are not+ * freed when the UniquePtr<char> member variables of PemKeyCertPair are unused.+ * Similarly, the user must free the underlying pointer to c_pem_root_certs. **/+grpc_tls_key_materials_config* ConvertToCKeyMaterialsConfig(+    const std::shared_ptr<TlsKeyMaterialsConfig>& config) {+  if (config == nullptr) {+    return nullptr;+  }+  grpc_tls_key_materials_config* c_config =+      grpc_tls_key_materials_config_create();+  ::grpc_core::InlinedVector<::grpc_core::PemKeyCertPair, 1>+      c_pem_key_cert_pair_list;+  for (auto key_cert_pair = config->pem_key_cert_pair_list().begin();+       key_cert_pair != config->pem_key_cert_pair_list().end();+       key_cert_pair++) {+    grpc_ssl_pem_key_cert_pair* ssl_pair =+        (grpc_ssl_pem_key_cert_pair*)gpr_malloc(+            sizeof(grpc_ssl_pem_key_cert_pair));+    ssl_pair->private_key = gpr_strdup(key_cert_pair->private_key.c_str());+    ssl_pair->cert_chain = gpr_strdup(key_cert_pair->cert_chain.c_str());+    ::grpc_core::PemKeyCertPair c_pem_key_cert_pair =+        ::grpc_core::PemKeyCertPair(ssl_pair);+    c_pem_key_cert_pair_list.push_back(::std::move(c_pem_key_cert_pair));+  }+  ::grpc_core::UniquePtr<char> c_pem_root_certs(+      gpr_strdup(config->pem_root_certs().c_str()));+  c_config->set_key_materials(std::move(c_pem_root_certs),+                              std::move(c_pem_key_cert_pair_list));+  c_config->set_version(config->version());+  return c_config;+}++/** Converts the C key materials config to a Cpp key materials config; it+ * allocates memory for the Cpp config. **/+std::shared_ptr<TlsKeyMaterialsConfig> ConvertToCppKeyMaterialsConfig(+    const grpc_tls_key_materials_config* config) {+  if (config == nullptr) {+    return nullptr;+  }+  std::shared_ptr<TlsKeyMaterialsConfig> cpp_config(+      new TlsKeyMaterialsConfig());+  std::vector<TlsKeyMaterialsConfig::PemKeyCertPair> cpp_pem_key_cert_pair_list;+  grpc_tls_key_materials_config::PemKeyCertPairList pem_key_cert_pair_list =+      config->pem_key_cert_pair_list();+  for (size_t i = 0; i < pem_key_cert_pair_list.size(); i++) {+    ::grpc_core::PemKeyCertPair key_cert_pair = pem_key_cert_pair_list[i];+    TlsKeyMaterialsConfig::PemKeyCertPair p = {key_cert_pair.private_key(),+                                               key_cert_pair.cert_chain()};+    cpp_pem_key_cert_pair_list.push_back(::std::move(p));+  }+  cpp_config->set_key_materials(std::move(config->pem_root_certs()),+                                std::move(cpp_pem_key_cert_pair_list));+  cpp_config->set_version(config->version());+  return cpp_config;+}++/** The C schedule and cancel functions for the credential reload config.+ * They populate a C credential reload arg with the result of a C++ credential+ * reload schedule/cancel API. **/+int TlsCredentialReloadConfigCSchedule(void* config_user_data,+                                       grpc_tls_credential_reload_arg* arg) {+  if (arg == nullptr || arg->config == nullptr ||+      arg->config->context() == nullptr) {+    gpr_log(GPR_ERROR, ""credential reload arg was not properly initialized"");+    return 1;+  }+  TlsCredentialReloadConfig* cpp_config =+      static_cast<TlsCredentialReloadConfig*>(arg->config->context());+  TlsCredentialReloadArg cpp_arg(arg);+  return cpp_config->Schedule(&cpp_arg);","As I said I did not look at the test :) From the API point of view, how do I know which reload to cancel if the two pointers are not the same?Let's say I am an application implementing the interface, I would likely to use the passed in arg to look up pending reloads and then cancel the proper one. If you just pass in a random pointer with shared underlying data, I lose the ability to do that.I have been assuming the API says you schedule a reload with `arg` and then later it can be cancelled by calling `Cancel(arg)`. Hence I called it a bug.",
10122250,yang-g,https://api.github.com/repos/grpc/grpc/pulls/19778,327220628,2019-09-23T16:49:25Z,src/cpp/common/tls_credentials_options_util.cc,"@@ -0,0 +1,144 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/cpp/common/tls_credentials_options_util.h""+#include <grpcpp/security/tls_credentials_options.h>++namespace grpc_impl {+namespace experimental {++/** Converts the Cpp key materials to C key materials; this allocates memory for+ * the C key materials. Note that the user must free+ * the underlying pointer to private key and cert chain duplicates; they are not+ * freed when the UniquePtr<char> member variables of PemKeyCertPair are unused.+ * Similarly, the user must free the underlying pointer to c_pem_root_certs. **/+grpc_tls_key_materials_config* ConvertToCKeyMaterialsConfig(+    const std::shared_ptr<TlsKeyMaterialsConfig>& config) {+  if (config == nullptr) {+    return nullptr;+  }+  grpc_tls_key_materials_config* c_config =+      grpc_tls_key_materials_config_create();+  ::grpc_core::InlinedVector<::grpc_core::PemKeyCertPair, 1>+      c_pem_key_cert_pair_list;+  for (auto key_cert_pair = config->pem_key_cert_pair_list().begin();+       key_cert_pair != config->pem_key_cert_pair_list().end();+       key_cert_pair++) {+    grpc_ssl_pem_key_cert_pair* ssl_pair =+        (grpc_ssl_pem_key_cert_pair*)gpr_malloc(+            sizeof(grpc_ssl_pem_key_cert_pair));+    ssl_pair->private_key = gpr_strdup(key_cert_pair->private_key.c_str());+    ssl_pair->cert_chain = gpr_strdup(key_cert_pair->cert_chain.c_str());+    ::grpc_core::PemKeyCertPair c_pem_key_cert_pair =+        ::grpc_core::PemKeyCertPair(ssl_pair);+    c_pem_key_cert_pair_list.push_back(::std::move(c_pem_key_cert_pair));+  }+  ::grpc_core::UniquePtr<char> c_pem_root_certs(+      gpr_strdup(config->pem_root_certs().c_str()));+  c_config->set_key_materials(std::move(c_pem_root_certs),+                              std::move(c_pem_key_cert_pair_list));+  c_config->set_version(config->version());+  return c_config;+}++/** Converts the C key materials config to a Cpp key materials config; it+ * allocates memory for the Cpp config. **/+std::shared_ptr<TlsKeyMaterialsConfig> ConvertToCppKeyMaterialsConfig(+    const grpc_tls_key_materials_config* config) {+  if (config == nullptr) {+    return nullptr;+  }+  std::shared_ptr<TlsKeyMaterialsConfig> cpp_config(+      new TlsKeyMaterialsConfig());+  std::vector<TlsKeyMaterialsConfig::PemKeyCertPair> cpp_pem_key_cert_pair_list;+  grpc_tls_key_materials_config::PemKeyCertPairList pem_key_cert_pair_list =+      config->pem_key_cert_pair_list();+  for (size_t i = 0; i < pem_key_cert_pair_list.size(); i++) {+    ::grpc_core::PemKeyCertPair key_cert_pair = pem_key_cert_pair_list[i];+    TlsKeyMaterialsConfig::PemKeyCertPair p = {key_cert_pair.private_key(),+                                               key_cert_pair.cert_chain()};+    cpp_pem_key_cert_pair_list.push_back(::std::move(p));+  }+  cpp_config->set_key_materials(std::move(config->pem_root_certs()),+                                std::move(cpp_pem_key_cert_pair_list));+  cpp_config->set_version(config->version());+  return cpp_config;+}++/** The C schedule and cancel functions for the credential reload config.+ * They populate a C credential reload arg with the result of a C++ credential+ * reload schedule/cancel API. **/+int TlsCredentialReloadConfigCSchedule(void* config_user_data,+                                       grpc_tls_credential_reload_arg* arg) {+  if (arg == nullptr || arg->config == nullptr ||+      arg->config->context() == nullptr) {+    gpr_log(GPR_ERROR, ""credential reload arg was not properly initialized"");+    return 1;+  }+  TlsCredentialReloadConfig* cpp_config =+      static_cast<TlsCredentialReloadConfig*>(arg->config->context());+  TlsCredentialReloadArg cpp_arg(arg);+  return cpp_config->Schedule(&cpp_arg);","I am not sure how it solves the problem. Basically what I am curious about is the scenario where two `Schedule` are called with different args and one of them needs to be cancelled. Is that a valid use case at all or does it violate the API contract? If it is valid, then in the `Cancel` call we need to somehow relate the Arg in the `Cancel` to one of the previous `Schedule` call. ",
52979934,matthewstevenson88,https://api.github.com/repos/grpc/grpc/pulls/19778,327250799,2019-09-23T17:58:15Z,src/cpp/common/tls_credentials_options_util.cc,"@@ -0,0 +1,144 @@+/*+ *+ * Copyright 2019 gRPC authors.+ *+ * Licensed under the Apache License, Version 2.0 (the ""License"");+ * you may not use this file except in compliance with the License.+ * You may obtain a copy of the License at+ *+ *     http://www.apache.org/licenses/LICENSE-2.0+ *+ * Unless required by applicable law or agreed to in writing, software+ * distributed under the License is distributed on an ""AS IS"" BASIS,+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.+ * See the License for the specific language governing permissions and+ * limitations under the License.+ *+ */++#include ""src/cpp/common/tls_credentials_options_util.h""+#include <grpcpp/security/tls_credentials_options.h>++namespace grpc_impl {+namespace experimental {++/** Converts the Cpp key materials to C key materials; this allocates memory for+ * the C key materials. Note that the user must free+ * the underlying pointer to private key and cert chain duplicates; they are not+ * freed when the UniquePtr<char> member variables of PemKeyCertPair are unused.+ * Similarly, the user must free the underlying pointer to c_pem_root_certs. **/+grpc_tls_key_materials_config* ConvertToCKeyMaterialsConfig(+    const std::shared_ptr<TlsKeyMaterialsConfig>& config) {+  if (config == nullptr) {+    return nullptr;+  }+  grpc_tls_key_materials_config* c_config =+      grpc_tls_key_materials_config_create();+  ::grpc_core::InlinedVector<::grpc_core::PemKeyCertPair, 1>+      c_pem_key_cert_pair_list;+  for (auto key_cert_pair = config->pem_key_cert_pair_list().begin();+       key_cert_pair != config->pem_key_cert_pair_list().end();+       key_cert_pair++) {+    grpc_ssl_pem_key_cert_pair* ssl_pair =+        (grpc_ssl_pem_key_cert_pair*)gpr_malloc(+            sizeof(grpc_ssl_pem_key_cert_pair));+    ssl_pair->private_key = gpr_strdup(key_cert_pair->private_key.c_str());+    ssl_pair->cert_chain = gpr_strdup(key_cert_pair->cert_chain.c_str());+    ::grpc_core::PemKeyCertPair c_pem_key_cert_pair =+        ::grpc_core::PemKeyCertPair(ssl_pair);+    c_pem_key_cert_pair_list.push_back(::std::move(c_pem_key_cert_pair));+  }+  ::grpc_core::UniquePtr<char> c_pem_root_certs(+      gpr_strdup(config->pem_root_certs().c_str()));+  c_config->set_key_materials(std::move(c_pem_root_certs),+                              std::move(c_pem_key_cert_pair_list));+  c_config->set_version(config->version());+  return c_config;+}++/** Converts the C key materials config to a Cpp key materials config; it+ * allocates memory for the Cpp config. **/+std::shared_ptr<TlsKeyMaterialsConfig> ConvertToCppKeyMaterialsConfig(+    const grpc_tls_key_materials_config* config) {+  if (config == nullptr) {+    return nullptr;+  }+  std::shared_ptr<TlsKeyMaterialsConfig> cpp_config(+      new TlsKeyMaterialsConfig());+  std::vector<TlsKeyMaterialsConfig::PemKeyCertPair> cpp_pem_key_cert_pair_list;+  grpc_tls_key_materials_config::PemKeyCertPairList pem_key_cert_pair_list =+      config->pem_key_cert_pair_list();+  for (size_t i = 0; i < pem_key_cert_pair_list.size(); i++) {+    ::grpc_core::PemKeyCertPair key_cert_pair = pem_key_cert_pair_list[i];+    TlsKeyMaterialsConfig::PemKeyCertPair p = {key_cert_pair.private_key(),+                                               key_cert_pair.cert_chain()};+    cpp_pem_key_cert_pair_list.push_back(::std::move(p));+  }+  cpp_config->set_key_materials(std::move(config->pem_root_certs()),+                                std::move(cpp_pem_key_cert_pair_list));+  cpp_config->set_version(config->version());+  return cpp_config;+}++/** The C schedule and cancel functions for the credential reload config.+ * They populate a C credential reload arg with the result of a C++ credential+ * reload schedule/cancel API. **/+int TlsCredentialReloadConfigCSchedule(void* config_user_data,+                                       grpc_tls_credential_reload_arg* arg) {+  if (arg == nullptr || arg->config == nullptr ||+      arg->config->context() == nullptr) {+    gpr_log(GPR_ERROR, ""credential reload arg was not properly initialized"");+    return 1;+  }+  TlsCredentialReloadConfig* cpp_config =+      static_cast<TlsCredentialReloadConfig*>(arg->config->context());+  TlsCredentialReloadArg cpp_arg(arg);+  return cpp_config->Schedule(&cpp_arg);","AFAIK yes, that is a valid use case. But to the user, all they have are the two instances, say `arg1` and `arg2`, of `TlsCredentialReloadArg`, and both belong to the same `TlsCredentialReloadConfig` object `config`. If we have called `Schedule` with both args and we would like to cancel `arg1`, then we can call `config.Cancel(arg1)` to cancel the first one. Why does this necessitate any further connection between what happens in the `Schedule` and `Cancel` functions?As an aside, I just want to point out that the particular function, `TlsCredentialReloadCSchedule`, that this discussion is taking place under is completely internal - it is used only to create a `grpc_tls_credential_reload_config` instance given a user-provided `TlsCredentialReloadConfig` instance. It is only exposed for testing purposes (and I will add further comments to make this evident).My apologies if I'm missing something straightforward here. The reason I added `unique_ptr`'s in the previous commit was to avoid any issues that might come up if schedule calls occurred in different threads, just to guard against anything funny occurring with local variables in that instance.",
224720,zackgalbreath,https://api.github.com/repos/grpc/grpc/pulls/20211,327252431,2019-09-23T18:02:03Z,templates/CMakeLists.txt.template,"@@ -73,10 +73,11 @@    set(PACKAGE_NAME      ""grpc"")   set(PACKAGE_VERSION   ""${settings.cpp_version}"")+  set(CORE_VERSION      ""${settings.core_version}"")   set(PACKAGE_STRING    ""<%text>${PACKAGE_NAME} ${PACKAGE_VERSION}</%text>"")   set(PACKAGE_TARNAME   ""<%text>${PACKAGE_NAME}-${PACKAGE_VERSION}</%text>"")   set(PACKAGE_BUGREPORT ""https://github.com/grpc/grpc/issues/"")-  project(<%text>${PACKAGE_NAME}</%text> C CXX)+  project(<%text>${PACKAGE_NAME}</%text> LANGUAGES C CXX)","At the moment, yes. IMO we should eventually set `(project ... VERSION)` to be either `PACKAGE_VERSION` or `CORE_VERSION`. At that point we will need to use the longer signature of the `project()` command where LANGUAGES are explicitly separated.",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/20337,327433260,2019-09-24T05:33:29Z,tools/remote_build/rbe_common.bazelrc,"@@ -81,6 +81,10 @@ build:tsan --extra_execution_platforms=//third_party/toolchains:rbe_ubuntu1604,/ # undefined behavior sanitizer: most settings are already in %workspace%/.bazelrc # we only need a few additional ones that are Foundry specific build:ubsan --copt=-gmlt+# workaround to use libc++ instead of libstdc++ because gcc 4.9 installed in ubuntu16_04_clang",file an issue against https://github.com/bazelbuild/bazel-toolchains because that's where @bazel_toolchains//configs/experimental/ubuntu16_04_clang is hosted?,
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/20337,327433746,2019-09-24T05:36:30Z,tools/remote_build/rbe_common.bazelrc,"@@ -81,6 +81,10 @@ build:tsan --extra_execution_platforms=//third_party/toolchains:rbe_ubuntu1604,/ # undefined behavior sanitizer: most settings are already in %workspace%/.bazelrc # we only need a few additional ones that are Foundry specific build:ubsan --copt=-gmlt+# workaround to use libc++ instead of libstdc++ because gcc 4.9 installed in ubuntu16_04_clang","Also, you're saying gcc4.9 but we're using clang to build?https://github.com/grpc/grpc/blob/c379323b3140cb62efe7c1aa9ce984fc575cc7b3/tools/bazel.rc#L6",OK
9939684,jtattermusch,https://api.github.com/repos/grpc/grpc/pulls/20100,327500988,2019-09-24T08:56:04Z,src/objective-c/BoringSSL-GRPC.podspec,"@@ -1547,7 +1547,7 @@ Pod::Spec.new do |s|     EOF      sed -i'.back' '/^#define \\([A-Za-z0-9_]*\\) \\1/d' include/openssl/ssl.h-    sed -i'.back' 'N;/^#define \\([A-Za-z0-9_]*\\) *\\\\\\n *\\1/d' include/openssl/ssl.h+    sed -i'.back' '$!N;/^#define \\([A-Za-z0-9_]*\\) *\\\\\\n *\\1/d' include/openssl/ssl.h","Ok, I found this one https://github.com/grpc/grpc/blob/6571386a06a714b9c04c8af8c03b063e5efc23a8/templates/src/objective-c/BoringSSL-GRPC.podspec.template#L210IMHO this is a super dirty hack. Can we come up with a better solution?",
1054404,muxi,https://api.github.com/repos/grpc/grpc/pulls/20336,327673199,2019-09-24T15:10:52Z,src/objective-c/tests/PerfTests/PerfTests.m,"@@ -265,37 +262,40 @@ - (void)testPingPongRPCWithV1API {   }]; } -- (void)unaryRPCWithRequest:(RMTSimpleRequest *)request-                numMessages:(int)numMessages-                callOptions:(GRPCMutableCallOptions *)options {-  const int kOutstandingRPCs = 10;-  NSAssert(numMessages > kOutstandingRPCs, @""Number of RPCs must be > %d"", kOutstandingRPCs);+- (void)unaryRPCWithServices:(NSArray<RMTTestService *> *)services+                     request:(RMTSimpleRequest *)request+                 numMessages:(int)numMessages+              numOutstanding:(int)numOutstanding+                 callOptions:(GRPCMutableCallOptions *)options {   __weak XCTestExpectation *expectation = [self expectationWithDescription:@""unaryRPC""]; -  dispatch_semaphore_t sema = dispatch_semaphore_create(kOutstandingRPCs);+  dispatch_semaphore_t sema = dispatch_semaphore_create(numOutstanding);   __block int index = 0; -  for (int i = 0; i < numMessages; ++i) {-    GRPCUnaryProtoCall *call = [_service-        unaryCallWithMessage:request-             responseHandler:[[PerfTestsBlockCallbacks alloc]-                                 initWithInitialMetadataCallback:nil-                                                 messageCallback:nil-                                                   closeCallback:^(NSDictionary *trailingMetadata,-                                                                   NSError *error) {-                                                     dispatch_semaphore_signal(sema);-                                                     @synchronized(self) {-                                                       ++index;-                                                       if (index == numMessages) {-                                                         [expectation fulfill];+  for (RMTTestService *service in services) {+    for (int i = 0; i < numMessages; ++i) {+      GRPCUnaryProtoCall *call = [service+          unaryCallWithMessage:request+               responseHandler:[[PerfTestsBlockCallbacks alloc]+                                   initWithInitialMetadataCallback:nil+                                                   messageCallback:nil+                                                     closeCallback:^(NSDictionary *trailingMetadata,+                                                                     NSError *error) {+                                                       dispatch_semaphore_signal(sema);+                                                       @synchronized(self) {+                                                         ++index;+                                                         if (index ==+                                                             numMessages * [services count]) {+                                                           [expectation fulfill];+                                                         }                                                        }-                                                     } -                                                   }]-                 callOptions:options];+                                                     }]+                   callOptions:options]; -    dispatch_semaphore_wait(sema, DISPATCH_TIME_FOREVER);-    [call start];+      dispatch_semaphore_wait(sema, DISPATCH_TIME_FOREVER);","Waiting forever is usually not the best thing to do since if it got stuck in CI due to some bug, the process takes looooong time to timeout. I would try to avoid using forever but use some reasonably large number.",OK
2793282,veblush,https://api.github.com/repos/grpc/grpc/pulls/20337,327713871,2019-09-24T16:27:50Z,tools/remote_build/rbe_common.bazelrc,"@@ -81,6 +81,10 @@ build:tsan --extra_execution_platforms=//third_party/toolchains:rbe_ubuntu1604,/ # undefined behavior sanitizer: most settings are already in %workspace%/.bazelrc # we only need a few additional ones that are Foundry specific build:ubsan --copt=-gmlt+# workaround to use libc++ instead of libstdc++ because gcc 4.9 installed in ubuntu16_04_clang","Thank you for the review! (actually it's not ready for the review yet :)I already filed an [issue](https://github.com/GoogleCloudPlatform/layer-definitions/issues/531) because there seems to be no easy fix without their help and they're trying to make a fix by upgrading the existing libstdc++ 4.9 to 5.x. This PR will be discarded once their fix is available.For gcc 4.9, technically clang is used as a compiler but it uses libstdc++ 4.9 (bundled with gcc 4.9) instead of libc++.",
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/20277,327736389,2019-09-24T17:18:19Z,src/python/grpcio/grpc/__init__.py,"@@ -1963,6 +1963,7 @@ class Compression(enum.IntEnum):     'StatusCode',     'Status',     'RpcError',+    'AioRpcError',",I think we shouldn't touch our API surface now. `AioRpcError` should belong to the init file of experimental/aio instead of the main init file.,
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/20277,327740853,2019-09-24T17:28:10Z,src/python/grpcio/grpc/experimental/aio/_channel.py,"@@ -20,24 +21,28 @@  class UnaryUnaryMultiCallable(aio.UnaryUnaryMultiCallable): -    def __init__(self, channel, method, request_serializer,-                 response_deserializer):+    def __init__(self, channel: cygrpc.AioChannel, method, request_serializer,+                 response_deserializer) -> None:","Since you just added type to `channel`, why not add types to all arguments? It would probably be simpler to predefine those types, since they might be reused for other `Callable` class.",OK
7394928,lidizheng,https://api.github.com/repos/grpc/grpc/pulls/20277,327741382,2019-09-24T17:29:20Z,src/python/grpcio/grpc/experimental/aio/_channel.py,"@@ -20,24 +21,28 @@  class UnaryUnaryMultiCallable(aio.UnaryUnaryMultiCallable): -    def __init__(self, channel, method, request_serializer,-                 response_deserializer):+    def __init__(self, channel: cygrpc.AioChannel, method, request_serializer,+                 response_deserializer) -> None:         self._channel = channel         self._method = method         self._request_serializer = request_serializer         self._response_deserializer = response_deserializer+        self._loop = asyncio.get_event_loop()++    def _timeout_for_deadline(self, timeout):",How about s/_timeout_for_deadline/_timeout_to_deadline/,
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/20331,327782259,2019-09-24T18:59:10Z,src/core/ext/transport/chttp2/transport/chttp2_transport.cc,"@@ -2919,30 +2958,28 @@ Chttp2IncomingByteStream::Chttp2IncomingByteStream(   stream->byte_stream_error = GRPC_ERROR_NONE; } -void Chttp2IncomingByteStream::OrphanLocked(void* arg,-                                            grpc_error* error_ignored) {+void Chttp2IncomingByteStream::OrphanLocked(void* arg) {","nit: this is probably not a good name now,  because it'll lock the transport itself, and the transport is not called when it's locked.also the parameter shouldn't be void* now.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/20347,327782528,2019-09-24T18:59:51Z,test/core/channel/channel_args_test.cc,"@@ -111,6 +115,86 @@ static void test_channel_create_with_args(void) {   grpc_channel_destroy(c); } +grpc_channel_args* mutate_channel_args(const char* target,+                                       grpc_channel_args* old_args,+                                       grpc_channel_stack_type type) {+  GPR_ASSERT(old_args != nullptr);+  GPR_ASSERT(grpc_channel_args_find(old_args, ""arg_int"")->value.integer == 0);+  GPR_ASSERT(strcmp(grpc_channel_args_find(old_args, ""arg_str"")->value.string,+                    ""arg_str_val"") == 0);+  GPR_ASSERT(+      grpc_channel_args_find(old_args, ""arg_pointer"")->value.pointer.vtable ==+      &fake_pointer_arg_vtable);++  if (strcmp(target, ""no_op_mutator"") == 0) {+    return old_args;+  }++  GPR_ASSERT(strcmp(target, ""minimal_stack_mutator"") == 0);+  const char* args_to_remove[] = {""arg_int"", ""arg_str"", ""arg_pointer""};++  grpc_arg no_deadline_filter_arg = grpc_channel_arg_integer_create(+      const_cast<char*>(GRPC_ARG_MINIMAL_STACK), 1);+  grpc_channel_args* new_args = nullptr;+  new_args = grpc_channel_args_copy_and_add_and_remove(+      old_args, args_to_remove, GPR_ARRAY_SIZE(args_to_remove),+      &no_deadline_filter_arg, 1);+  grpc_channel_args_destroy(old_args);+  return new_args;+}++// Minimal stack should not have client_idle filter+static bool channel_has_client_idle_filter(grpc_channel* c) {+  grpc_channel_stack* stack = grpc_channel_get_channel_stack(c);+  for (size_t i = 0; i < stack->count; i++) {+    if (strcmp(grpc_channel_stack_element(stack, i)->filter->name,+               ""client_idle"") == 0) {+      return true;+    }+  }+  return false;+}++static void test_channel_create_with_global_mutator(void) {+  grpc_channel_args_set_client_channel_creation_mutator(mutate_channel_args);+  // We also add some custom args to make sure the ownership is correct.+  grpc_arg client_a[3];++  // adds integer arg+  client_a[0].type = GRPC_ARG_INTEGER;",Can use the channel arg creation helper functions here:https://github.com/grpc/grpc/blob/a9533e72477337e4bde1b0f914627dbfe2d77a1b/src/core/lib/channel/channel_args.h#L102,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/20331,327787179,2019-09-24T19:11:16Z,src/core/ext/transport/chttp2/transport/chttp2_transport.cc,"@@ -561,19 +557,21 @@ grpc_chttp2_transport::grpc_chttp2_transport(  static void destroy_transport_locked(void* tp, grpc_error* error) {   grpc_chttp2_transport* t = static_cast<grpc_chttp2_transport*>(tp);+  gpr_mu_lock(&t->mu);   t->destroying = 1;   close_transport_locked(       t, grpc_error_set_int(              GRPC_ERROR_CREATE_FROM_STATIC_STRING(""Transport destroyed""),              GRPC_ERROR_INT_OCCURRED_DURING_WRITE, t->write_state));+  gpr_mu_unlock(&t->mu);   // Must be the last line.   GRPC_CHTTP2_UNREF_TRANSPORT(t, ""destroy""); }  static void destroy_transport(grpc_transport* gt) {   grpc_chttp2_transport* t = reinterpret_cast<grpc_chttp2_transport*>(gt);   GRPC_CLOSURE_SCHED(GRPC_CLOSURE_CREATE(destroy_transport_locked, t,","Is this closure still necessary?  It seems like if we no longer need to bounce into the combiner, we should be able to avoid this level of indirection.  I think we can just move the code from `destroy_transport_locked()` directly into this function.It looks like there are a number of cases like this throughout the code.",OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/20331,327789585,2019-09-24T19:17:20Z,src/core/ext/transport/chttp2/transport/chttp2_transport.cc,"@@ -1083,7 +1087,7 @@ static void write_action(void* gt, grpc_error* error) { static void write_action_end_locked(void* tp, grpc_error* error) {","This function is the callback from `grpc_endpoint_write()` and therefore can't go away, but the `_locked()` suffix is probably no longer appropriate, since it acquires the lock itself instead of being called when the call is already held.In general, any closure callback function ending in `_locked()` should either be removed (by moving its code into the place where the closure was called from) or have its `_locked()` suffix removed.",OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/20331,327789954,2019-09-24T19:18:20Z,src/core/ext/transport/chttp2/transport/chttp2_transport.cc,"@@ -2919,30 +2958,28 @@ Chttp2IncomingByteStream::Chttp2IncomingByteStream(   stream->byte_stream_error = GRPC_ERROR_NONE; } -void Chttp2IncomingByteStream::OrphanLocked(void* arg,-                                            grpc_error* error_ignored) {+void Chttp2IncomingByteStream::OrphanLocked(void* arg) {","OK sounds great to remove.  Problem is that ""XXXLocked"" usually means we are calling it while holding the lock.  Can you remove all similar cases please?",OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/20336,327888137,2019-09-25T00:27:25Z,src/objective-c/tests/PerfTests/PerfTests.m,"@@ -77,8 +77,11 @@ - (GRPCInterceptor *)createInterceptorWithManager:(GRPCInterceptorManager *)inte @end  BOOL isUsingCFStream() {-  NSString *enabled = @(getenv(kCFStreamVarName));-  return [enabled isEqualToString:@""1""];+  char *enabled = getenv(kCFStreamVarName);+  if (enabled == nil) {",The intention here was to only exclude tests that use `tcp_client_cfstream`. I have fixed this by checking the class name instead of env var.,OK
2873805,rmstar,https://api.github.com/repos/grpc/grpc/pulls/20336,327888665,2019-09-25T00:30:26Z,src/objective-c/tests/PerfTests/PerfTests.m,"@@ -265,37 +262,40 @@ - (void)testPingPongRPCWithV1API {   }]; } -- (void)unaryRPCWithRequest:(RMTSimpleRequest *)request-                numMessages:(int)numMessages-                callOptions:(GRPCMutableCallOptions *)options {-  const int kOutstandingRPCs = 10;-  NSAssert(numMessages > kOutstandingRPCs, @""Number of RPCs must be > %d"", kOutstandingRPCs);+- (void)unaryRPCWithServices:(NSArray<RMTTestService *> *)services+                     request:(RMTSimpleRequest *)request+                 numMessages:(int)numMessages+              numOutstanding:(int)numOutstanding+                 callOptions:(GRPCMutableCallOptions *)options {   __weak XCTestExpectation *expectation = [self expectationWithDescription:@""unaryRPC""]; -  dispatch_semaphore_t sema = dispatch_semaphore_create(kOutstandingRPCs);+  dispatch_semaphore_t sema = dispatch_semaphore_create(numOutstanding);   __block int index = 0; -  for (int i = 0; i < numMessages; ++i) {-    GRPCUnaryProtoCall *call = [_service-        unaryCallWithMessage:request-             responseHandler:[[PerfTestsBlockCallbacks alloc]-                                 initWithInitialMetadataCallback:nil-                                                 messageCallback:nil-                                                   closeCallback:^(NSDictionary *trailingMetadata,-                                                                   NSError *error) {-                                                     dispatch_semaphore_signal(sema);-                                                     @synchronized(self) {-                                                       ++index;-                                                       if (index == numMessages) {-                                                         [expectation fulfill];+  for (RMTTestService *service in services) {+    for (int i = 0; i < numMessages; ++i) {+      GRPCUnaryProtoCall *call = [service+          unaryCallWithMessage:request+               responseHandler:[[PerfTestsBlockCallbacks alloc]+                                   initWithInitialMetadataCallback:nil+                                                   messageCallback:nil+                                                     closeCallback:^(NSDictionary *trailingMetadata,+                                                                     NSError *error) {+                                                       dispatch_semaphore_signal(sema);+                                                       @synchronized(self) {+                                                         ++index;+                                                         if (index ==+                                                             numMessages * [services count]) {+                                                           [expectation fulfill];+                                                         }                                                        }-                                                     } -                                                   }]-                 callOptions:options];+                                                     }]+                   callOptions:options]; -    dispatch_semaphore_wait(sema, DISPATCH_TIME_FOREVER);-    [call start];+      dispatch_semaphore_wait(sema, DISPATCH_TIME_FOREVER);",Fixed wait forever -> wait until timeout. Regarding controlling number of outstanding calls: this is something we do in some of our existing benchmarks (see go/grpc-benchmark-comparison-dashboard). I have tried to follow the same pattern here.,OK
18664614,markdroth,https://api.github.com/repos/grpc/grpc/pulls/20405,329662962,2019-09-30T16:08:45Z,src/core/lib/gprpp/memory.h,"@@ -58,33 +56,28 @@ inline T* New(Args&&... args) { }  // Alternative to delete, since we cannot use it (for fear of libstdc++)-// We cannot add a default value for can_be_null, because they are used as-// as friend template methods where we cannot define a default value.-// Instead we simply define two variants, one with and one without the boolean-// argument.-template <typename T, bool can_be_null>+template <typename T> inline void Delete(T* p) {-  GPR_DEBUG_ASSERT(can_be_null || p != nullptr);-  if (can_be_null && p == nullptr) return;+  if (p == nullptr) return;   p->~T();   gpr_free(p); }-template <typename T>-inline void Delete(T* p) {-  Delete<T, /*can_be_null=*/true>(p);-} -template <typename T> class DefaultDelete {  public:+  template <typename T>","Yes, that's actually the whole point of this change.  Previously, the compiler was not able to automatically convert from `UniquePtr<Subclass>` to `UniquePtr<BaseClass>`, because they each had a different deleter type.  Now they have the same deleter type, so the compiler can handle this.This is why previously, when an API takes `UniquePtr<BaseClass>` and we want to pass a `UniquePtr<Subclass>`, we had to do `UniquePtr<BaseClass>(New<Subclass>(...))` instead of just `MakeUnique<Subclass>(...)`.  It also comes into play when we want to use `std::move()` to pass an existing `UniquePtr<Subclass>` into such an API.  (The latter case is actually what prompted me to look into this again.)",OK
394885,soheilhy,https://api.github.com/repos/grpc/grpc/pulls/20405,329663282,2019-09-30T16:09:29Z,src/core/lib/gprpp/memory.h,"@@ -58,33 +56,28 @@ inline T* New(Args&&... args) { }  // Alternative to delete, since we cannot use it (for fear of libstdc++)-// We cannot add a default value for can_be_null, because they are used as-// as friend template methods where we cannot define a default value.-// Instead we simply define two variants, one with and one without the boolean-// argument.-template <typename T, bool can_be_null>+template <typename T> inline void Delete(T* p) {-  GPR_DEBUG_ASSERT(can_be_null || p != nullptr);-  if (can_be_null && p == nullptr) return;+  if (p == nullptr) return;   p->~T();   gpr_free(p); }-template <typename T>-inline void Delete(T* p) {-  Delete<T, /*can_be_null=*/true>(p);-} -template <typename T> class DefaultDelete {  public:+  template <typename T>","Oh yes, my bad. Sorry :-) Thanks for the change!",OK